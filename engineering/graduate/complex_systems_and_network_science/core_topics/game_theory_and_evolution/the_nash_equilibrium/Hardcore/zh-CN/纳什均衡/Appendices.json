{
    "hands_on_practices": [
        {
            "introduction": "理论的掌握始于基础计算。本练习旨在通过一个经典的线性二次博弈模型，巩固纳什均衡的核心定义。你将通过求解一阶最优性条件，亲手推导出纳什均衡点，并将其与最小化总成本的社会最优解进行对比。这个对比过程不仅能让你熟练掌握求解技巧，更能深刻理解个体理性与集体理性之间的差异，即所谓的“无政府代价”()。",
            "id": "3154673",
            "problem": "考虑一个双人线性二次博弈，其中参与者 $i \\in \\{1,2\\}$ 选择一个标量决策变量 $x_i \\in \\mathbb{R}$。成本函数由下式给出\n$$\nf_i(x_1,x_2) \\;=\\; \\frac{1}{2} \\, q_i \\, x_i^{2} \\;+\\; b_i \\, x_i \\, x_{-i} \\;+\\; c_i \\, x_i,\n$$\n其中 $x_{-i}$ 表示另一位参与者的决策。令 $q_1 = 2$, $q_2 = 4$, $b_1 = 1$, $b_2 = 1$, $c_1 = -5$, 且 $c_2 = 1$。假设对于每个参与者都有 $q_i > 0$，因此每个参与者的优化问题对于其自身的决策变量都是严格凸的。\n\n从纳什均衡（NE）的定义出发（即没有参与者可以通过单方面改变策略来降低自己的成本），并使用可微凸函数的一阶最优性条件，推导出描述纳什均衡的分块线性系统，并求解均衡点 $(x_1^{\\ast}, x_2^{\\ast})$。然后，构建旨在最小化社会成本的集中式优化问题\n$$\nF(x_1,x_2) \\;=\\; f_1(x_1,x_2) \\;+\\; f_2(x_1,x_2),\n$$\n推导其一阶最优性条件，并求解集中式最优点 $(x_1^{c}, x_2^{c})$。\n\n将两个解合并为一个行向量 $\\big(x_1^{\\ast}, \\, x_2^{\\ast}, \\, x_1^{c}, \\, x_2^{c}\\big)$ 作为你的最终结果。无需四舍五入。",
            "solution": "该问题要求为一个双人线性二次博弈找到两个不同的解：纳什均衡（NE）和集中式（社会最优）解。\n\n首先，我们确定纳什均衡，记为 $(x_1^{\\ast}, x_2^{\\ast})$。纳什均衡是一种状态，在该状态下，假设另一位参与者的决策保持不变，任何参与者都无法通过单方面改变自己的决策来改善其结果（即降低其成本）。对于参与者 $i \\in \\{1,2\\}$，其成本函数 $f_i(x_1, x_2)$ 对于其自身的决策变量 $x_i$ 是可微且凸的，该条件在数学上由一阶最优性条件 $\\frac{\\partial f_i}{\\partial x_i} = 0$ 表示。\n\n参与者 $i$ 的成本函数如下：\n$$\nf_i(x_1,x_2) = \\frac{1}{2} q_i x_i^{2} + b_i x_i x_{-i} + c_i x_i\n$$\n其中 $x_{-i}$ 是另一位参与者的决策。问题陈述 $q_i > 0$，确保了 $f_i$ 关于 $x_i$ 是严格凸的，这保证了一阶条件能为参与者 $i$ 的优化问题确定一个唯一的最小值。\n\n让我们计算每个参与者的偏导数。\n对于参与者 1：\n$$\nf_1(x_1,x_2) = \\frac{1}{2} q_1 x_1^{2} + b_1 x_1 x_2 + c_1 x_1\n$$\n一阶条件是：\n$$\n\\frac{\\partial f_1}{\\partial x_1} = q_1 x_1 + b_1 x_2 + c_1 = 0\n$$\n\n对于参与者 2：\n$$\nf_2(x_1,x_2) = \\frac{1}{2} q_2 x_2^{2} + b_2 x_2 x_1 + c_2 x_2\n$$\n一阶条件是：\n$$\n\\frac{\\partial f_2}{\\partial x_2} = q_2 x_2 + b_2 x_1 + c_2 = 0\n$$\n\n这两个方程构成了纳什均衡 $(x_1^{\\ast}, x_2^{\\ast})$ 的一个线性系统：\n\\begin{align*}\nq_1 x_1^{\\ast} + b_1 x_2^{\\ast} = -c_1 \\\\\nb_2 x_1^{\\ast} + q_2 x_2^{\\ast} = -c_2\n\\end{align*}\n其矩阵形式为：\n$$\n\\begin{pmatrix} q_1 & b_1 \\\\ b_2 & q_2 \\end{pmatrix} \\begin{pmatrix} x_1^{\\ast} \\\\ x_2^{\\ast} \\end{pmatrix} = \\begin{pmatrix} -c_1 \\\\ -c_2 \\end{pmatrix}\n$$\n给定的参数值为：$q_1 = 2$, $q_2 = 4$, $b_1 = 1$, $b_2 = 1$, $c_1 = -5$ 和 $c_2 = 1$。将这些值代入该系统得到：\n\\begin{align*}\n2 x_1^{\\ast} + 1 x_2^{\\ast} = -(-5) = 5 \\\\\n1 x_1^{\\ast} + 4 x_2^{\\ast} = -1\n\\end{align*}\n从第一个方程中，我们可以用 $x_1^{\\ast}$ 来表示 $x_2^{\\ast}$：\n$$\nx_2^{\\ast} = 5 - 2 x_1^{\\ast}\n$$\n将此代入第二个方程：\n$$\nx_1^{\\ast} + 4(5 - 2 x_1^{\\ast}) = -1\n$$\n$$\nx_1^{\\ast} + 20 - 8 x_1^{\\ast} = -1\n$$\n$$\n-7 x_1^{\\ast} = -21\n$$\n$$\nx_1^{\\ast} = 3\n$$\n现在，我们将 $x_1^{\\ast}$ 的值代回以求得 $x_2^{\\ast}$：\n$$\nx_2^{\\ast} = 5 - 2(3) = 5 - 6 = -1\n$$\n因此，纳什均衡为 $(x_1^{\\ast}, x_2^{\\ast}) = (3, -1)$。\n\n接下来，我们确定集中式最优点，记为 $(x_1^{c}, x_2^{c})$。这是一对决策，可以最小化总成本或社会成本 $F(x_1,x_2) = f_1(x_1,x_2) + f_2(x_1,x_2)$。\n让我们写出社会成本函数 $F(x_1,x_2)$：\n$$\nF(x_1,x_2) = \\left(\\frac{1}{2} q_1 x_1^{2} + b_1 x_1 x_2 + c_1 x_1\\right) + \\left(\\frac{1}{2} q_2 x_2^{2} + b_2 x_1 x_2 + c_2 x_2\\right)\n$$\n$$\nF(x_1,x_2) = \\frac{1}{2} q_1 x_1^{2} + \\frac{1}{2} q_2 x_2^{2} + (b_1 + b_2) x_1 x_2 + c_1 x_1 + c_2 x_2\n$$\n这是一个关于变量 $(x_1, x_2)$ 的联合优化问题。为了找到最小值，我们计算 $F$ 的梯度并将其设为零。一阶条件是 $\\frac{\\partial F}{\\partial x_1} = 0$ 和 $\\frac{\\partial F}{\\partial x_2} = 0$。\n$$\n\\frac{\\partial F}{\\partial x_1} = q_1 x_1 + (b_1 + b_2) x_2 + c_1 = 0\n$$\n$$\n\\frac{\\partial F}{\\partial x_2} = q_2 x_2 + (b_1 + b_2) x_1 + c_2 = 0\n$$\n这为我们提供了一个求解集中式最优点 $(x_1^{c}, x_2^{c})$ 的线性方程组：\n\\begin{align*}\nq_1 x_1^{c} + (b_1 + b_2) x_2^{c} = -c_1 \\\\\n(b_1 + b_2) x_1^{c} + q_2 x_2^{c} = -c_2\n\\end{align*}\n为确保这是一个最小值，我们可以检查 $F$ 的海森矩阵，即 $H_F = \\begin{pmatrix} q_1 & b_1+b_2 \\\\ b_1+b_2 & q_2 \\end{pmatrix}$。使用给定值，$H_F = \\begin{pmatrix} 2 & 2 \\\\ 2 & 4 \\end{pmatrix}$。其主子式为 $2 > 0$ 和 $\\det(H_F) = 2(4) - 2(2) = 4 > 0$。由于海森矩阵是正定的，因此 $F$ 是严格凸的，一阶条件的解是唯一的全局最小值。\n\n将参数值代入集中式解的系统：\n\\begin{align*}\n2 x_1^{c} + (1+1) x_2^{c} = -(-5) \\implies 2 x_1^{c} + 2 x_2^{c} = 5 \\\\\n(1+1) x_1^{c} + 4 x_2^{c} = -1 \\implies 2 x_1^{c} + 4 x_2^{c} = -1\n\\end{align*}\n现在我们求解这个系统。从第二个方程减去第一个方程得到：\n$$\n(2 x_1^{c} + 4 x_2^{c}) - (2 x_1^{c} + 2 x_2^{c}) = -1 - 5\n$$\n$$\n2 x_2^{c} = -6\n$$\n$$\nx_2^{c} = -3\n$$\n将 $x_2^{c} = -3$ 代入第一个方程：\n$$\n2 x_1^{c} + 2(-3) = 5\n$$\n$$\n2 x_1^{c} - 6 = 5\n$$\n$$\n2 x_1^{c} = 11\n$$\n$$\nx_1^{c} = \\frac{11}{2}\n$$\n因此，集中式最优解为 $(x_1^{c}, x_2^{c}) = (\\frac{11}{2}, -3)$。\n\n问题要求将最终结果表示为连接的行向量 $\\big(x_1^{\\ast}, x_2^{\\ast}, x_1^{c}, x_2^{c}\\big)$。\n计算出的值为 $x_1^{\\ast} = 3$， $x_2^{\\ast} = -1$， $x_1^{c} = \\frac{11}{2}$ 和 $x_2^{c} = -3$。\n最终的向量是 $\\big(3, -1, \\frac{11}{2}, -3\\big)$。",
            "answer": "$$\n\\boxed{\\begin{pmatrix} 3 & -1 & \\frac{11}{2} & -3 \\end{pmatrix}}\n$$"
        },
        {
            "introduction": "静态均衡的概念如何在一个由众多主体构成的复杂系统中涌现？本练习将带你从静态分析走向动态模拟。我们将研究一个非原子拥堵博弈模型——这是网络科学中分析交通流或数据包路由的经典框架。你将实现一个模仿者复制动态模型，观察大量自主决策的智能体如何通过简单的学习规则，自发地向纳什均衡（在此场景下也称为瓦尔德罗普均衡）收敛()。",
            "id": "4310494",
            "problem": "考虑一个非原子拥塞博弈，其网络由连接单一源-目的地对的两条平行链路组成。总质量归一化为 $1$ 的连续体代理在链路 $1$ 和链路 $2$ 之间进行选择。令 $p \\in [0,1]$ 表示使用链路 $1$ 的种群份额，因此链路流量为 $x_1 = p$ 和 $x_2 = 1 - p$。每条链路 $k \\in \\{1,2\\}$ 都有一个仿射成本函数 $c_k(x_k) = a_k + b_k x_k$，其参数为 $a_k \\in \\mathbb{R}$ 和 $b_k \\ge 0$。由于代理旨在最小化成本，选择链路 $k$ 的代理的支付为 $u_k = -c_k(x_k)$。\n\n基本定义与基础：\n- 纳什均衡（在非原子路由博弈中称为瓦尔德罗普均衡）是一种种群分布，其中所有被使用的策略都具有最小成本；具体来说，当两条链路都被使用时，均衡条件为 $c_1(x_1) = c_2(x_2)$，而当只有一条链路被使用时，其成本不高于另一条链路。\n- 在包括拥塞博弈在内的势博弈中，诸如模仿者复制动态之类的学习动态具有李雅普诺夫结构。考虑由以下更新规则定义的离散时间模仿者复制动态\n$$\np_{t+1} = p_t + \\eta \\, p_t \\, (1 - p_t) \\, \\big(u_1(p_t) - u_2(p_t)\\big),\n$$\n其中 $\\eta > 0$ 是一个学习率参数，且对于 $x_1 = p$ 和 $x_2 = 1 - p$，有 $u_k(p) = -c_k(x_k)$。此动态的驻点满足 $p \\in \\{0,1\\}$ 或 $u_1(p) = u_2(p)$，这等价于 $c_1(p) = c_2(1 - p)$，即瓦尔德罗普均衡条件。\n\n任务：\n- 通过令两条链路在都被使用时的成本相等，推导解析的瓦尔德罗普均衡份额 $p^\\star$。对于 $b_1 + b_2 > 0$，内部均衡可通过求解下式获得\n$$\na_1 + b_1 p^\\star = a_2 + b_2 (1 - p^\\star),\n$$\n解得\n$$\np^\\star = \\frac{a_2 + b_2 - a_1}{b_1 + b_2}.\n$$\n如果计算出的 $p^\\star$ 位于 $[0,1]$ 之外，则均衡位于边界 $p^\\star = 0$ 或 $p^\\star = 1$ 上，具体取决于哪条链路在极端情况下的成本更低。如果 $b_1 + b_2 = 0$ 且 $a_1 = a_2$，则对于所有 $p$ 都有 $c_1(x_1) = c_2(x_2)$，均衡集是整个区间 $[0,1]$；在这种退化情况下，任何 $p$ 都是一个纳什均衡。\n- 实现具有上述更新规则的离散时间模仿者复制动态。使用 $u_1(p) = -\\big(a_1 + b_1 p\\big)$ 和 $u_2(p) = -\\big(a_2 + b_2 (1 - p)\\big)$，从初始条件 $p_0 \\in [0,1]$ 开始，迭代指定的步数 $T \\in \\mathbb{N}$。算法应将迭代值裁剪以保持在区间 $[0,1]$ 内。\n\n对于下面列出的每个测试用例，您的程序必须：\n$1.$ 根据参数计算解析均衡 $p^\\star$。\n$2.$ 从 $p_0$ 开始，以学习率 $\\eta$ 模拟复制动态 $T$ 步。\n$3.$ 计算最终绝对偏差 $|p_T - p^\\star|$。在 $b_1 + b_2 = 0$ 且 $a_1 = a_2$ 的退化情况下，将均衡集视为 $[0,1]$ 并报告偏差为 $0$。\n\n您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表（例如 $[r_1,r_2,\\dots]$）的结果，其中每个 $r_i$ 是相应测试用例的浮点偏差。\n\n测试套件：\n使用以下五个测试用例，每个用例由 $(a_1, b_1, a_2, b_2, \\eta, T, p_0)$ 指定：\n$1.$ $(0.2, 1.0, 0.8, 0.4, 0.05, 20000, 0.1)$\n$2.$ $(0.0, 1.0, 2.0, 1.0, 0.05, 20000, 0.5)$\n$3.$ $(1.5, 1.0, 0.0, 1.0, 0.05, 20000, 0.8)$\n$4.$ $(1.0, 0.0, 1.0, 0.0, 0.2, 1000, 0.3)$\n$5.$ $(0.0, 1.0, 0.1, 3.0, 0.03, 30000, 0.9)$\n\n最终输出格式要求：\n您的程序必须打印一行，其中包含一个由五个浮点数组成的列表 $[r_1,r_2,r_3,r_4,r_5]$，其中 $r_i$ 是测试用例 $i$ 的偏差。不应打印任何其他文本。",
            "solution": "我们从博弈论和网络科学的核心定义开始。在一个具有仿射成本函数 $c_k(x_k) = a_k + b_k x_k$ 的两条平行链路上的非原子路由博弈中，代理会最小化成本，此时瓦尔德罗普均衡与纳什均衡一致：被使用的策略（具有正流量的链路）必须具有相等且最小的成本。\n\n令 $p \\in [0,1]$ 表示选择链路 $1$ 的种群份额，因此 $x_1 = p$ 且 $x_2 = 1 - p$。成本为 $c_1(p) = a_1 + b_1 p$ 和 $c_2(1 - p) = a_2 + b_2 (1 - p)$。纳什均衡条件如下：\n$1.$ 内部均衡：如果两条链路都被使用，则 $c_1(p^\\star) = c_2(1 - p^\\star)$。\n$2.$ 边界均衡：如果内部解位于 $[0,1]$ 之外，则均衡必定在 $p^\\star = 0$ 或 $p^\\star = 1$ 处，具体取决于哪个边界为被使用的策略产生更低的成本。\n\n求解内部方程 $a_1 + b_1 p^\\star = a_2 + b_2 (1 - p^\\star)$ 可得\n$$\np^\\star = \\frac{a_2 + b_2 - a_1}{b_1 + b_2},\n$$\n前提是 $b_1 + b_2 > 0$。如果 $p^\\star \\notin [0,1]$，则均衡位于边界：如果 $p = 0$ 时链路 $2$ 严格更便宜，则 $p^\\star = 0$；如果 $p = 1$ 时链路 $1$ 严格更便宜，则 $p^\\star = 1$。在 $b_1 + b_2 = 0$ 的退化情况下，两个成本都是常数。如果 $a_1 = a_2$，则对于所有 $p$ 都有 $c_1 = c_2$，并且每个 $p \\in [0,1]$ 都是一个纳什均衡；否则，均衡位于边界上，所有质量都集中在更便宜的链路上。\n\n现在我们将学习和自适应动态与均衡联系起来。双策略种群博弈的离散时间模仿者复制动态为\n$$\np_{t+1} = p_t + \\eta \\, p_t \\, (1 - p_t) \\, \\big(u_1(p_t) - u_2(p_t)\\big),\n$$\n其中 $\\eta > 0$ 是学习率，而 $u_k(p) = -c_k(x_k)$ 是等于负成本的支付。代入 $u_1(p) = -\\big(a_1 + b_1 p\\big)$ 和 $u_2(p) = -\\big(a_2 + b_2 (1 - p)\\big)$，我们得到\n$$\nu_1(p) - u_2(p) = -\\big(a_1 + b_1 p\\big) + \\big(-a_2 - b_2 + b_2 p\\big) = -\\big(a_1 - a_2 - b_2\\big) - (b_1 + b_2) p.\n$$\n等价地，$u_1(p) - u_2(p)$ 的符号反映了 $c_2(1 - p) - c_1(p)$ 的符号，并且更新会使 $p$ 朝着更高支付（更低成本）的方向移动。该动态的驻点满足 $p \\in \\{0,1\\}$ 或 $u_1(p) = u_2(p)$，这恰好是 $c_1(p) = c_2(1 - p)$。在诸如拥塞博弈之类的势博弈中，模仿动态允许一个与势相关的李雅普诺夫函数，并且在合适的步长下，迭代会趋近于均衡集。\n\n算法设计：\n$1.$ 对于每个测试用例 $(a_1, b_1, a_2, b_2, \\eta, T, p_0)$，计算解析均衡 $p^\\star$：\n$1.1.$ 如果 $b_1 + b_2 > 0$，计算 $p^\\star = \\dfrac{a_2 + b_2 - a_1}{b_1 + b_2}$ 并将其投影到 $[0,1]$ 上；如果投影改变了值，则表明存在一个边界均衡。\n$1.2.$ 如果 $b_1 + b_2 = 0$，检查是否 $a_1 = a_2$。如果是，均衡集是整个区间 $[0,1]$；如果不是，则当 $a_1 < a_2$ 时设 $p^\\star = 1$，当 $a_2 < a_1$ 时设 $p^\\star = 0$。\n$2.$ 从 $p_0$ 开始，以学习率 $\\eta$ 模拟离散时间复制动态 $T$ 次迭代：\n$$\np_{t+1} = \\mathrm{clip}\\Big(p_t + \\eta \\, p_t \\, (1 - p_t) \\, \\big(u_1(p_t) - u_2(p_t)\\big), \\, 0, \\, 1\\Big),\n$$\n其中 $\\mathrm{clip}$ 确保 $p_{t+1} \\in [0,1]$。这种裁剪与单纯形约束一致，并能抵消数值漂移。\n$3.$ 计算最终偏差 $|p_T - p^\\star|$。在成本恒定且相等（$b_1 + b_2 = 0$ 且 $a_1 = a_2$）的退化情况下，均衡集是 $[0,1]$；由于任何 $p_T \\in [0,1]$ 都是一个均衡，因此报告偏差为 $0$。\n\n测试套件覆盖的基本原理：\n$1.$ $(0.2, 1.0, 0.8, 0.4, 0.05, 20000, 0.1)$ 代表一个典型的内部均衡。解析解为 $p^\\star = \\dfrac{0.8 + 0.4 - 0.2}{1.0 + 0.4} = \\dfrac{1.0}{1.4} \\approx 0.7142857$，复制动态应趋近于这个内部解。\n$2.$ $(0.0, 1.0, 2.0, 1.0, 0.05, 20000, 0.5)$ 得出 $p^\\star = \\dfrac{2.0 + 1.0 - 0.0}{1.0 + 1.0} = \\dfrac{3.0}{2.0} = 1.5$，该值位于 $[0,1]$ 之外，因此是边界均衡 $p^\\star = 1$；动态应收敛到 $1$。\n$3.$ $(1.5, 1.0, 0.0, 1.0, 0.05, 20000, 0.8)$ 得出 $p^\\star = \\dfrac{0.0 + 1.0 - 1.5}{1.0 + 1.0} = \\dfrac{-0.5}{2.0} = -0.25$，因此是边界均衡 $p^\\star = 0$；动态应收敛到 $0$。\n$4.$ $(1.0, 0.0, 1.0, 0.0, 0.2, 1000, 0.3)$ 中有 $b_1 + b_2 = 0$ 且 $a_1 = a_2$，使得两条链路的成本恒定且相等；均衡集是整个区间 $[0,1]$，且动态具有 $u_1(p) - u_2(p) = 0$，所以 $p_t$ 是常数。报告的偏差为 $0$。\n$5.$ $(0.0, 1.0, 0.1, 3.0, 0.03, 30000, 0.9)$ 中有 $p^\\star = \\dfrac{0.1 + 3.0 - 0.0}{1.0 + 3.0} = \\dfrac{3.1}{4.0} = 0.775$，这是一个靠近边界的内部解，其中链路斜率不对称；动态应收敛到接近此值。\n\n最终程序确定性地执行这些计算，并将偏差输出为包含在方括号内的单个逗号分隔列表，从而确保可复现性和精确的数值答案。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef compute_equilibrium(a1, b1, a2, b2):\n    \"\"\"\n    Compute the Wardrop (Nash) equilibrium share p* for a two-link affine congestion game.\n    Returns (p_star, continuum_flag).\n    continuum_flag is True only when b1 + b2 == 0 and a1 == a2 (continuum of equilibria).\n    \"\"\"\n    denom = b1 + b2\n    if denom == 0.0:\n        # Costs are constant. If equal constants, continuum of equilibria.\n        if np.isclose(a1, a2):\n            return None, True  # Any p in [0,1] is equilibrium\n        else:\n            # All mass on cheaper link\n            return (1.0 if a1  a2 else 0.0), False\n    else:\n        p_star = (a2 + b2 - a1) / denom\n        # Project onto [0,1] due to boundary equilibria\n        if p_star  0.0:\n            p_star = 0.0\n        elif p_star > 1.0:\n            p_star = 1.0\n        return p_star, False\n\ndef simulate_replicator(a1, b1, a2, b2, eta, T, p0):\n    \"\"\"\n    Simulate discrete-time imitative replicator dynamics for T steps:\n        p_{t+1} = p_t + eta * p_t * (1 - p_t) * (u1(p_t) - u2(p_t)),\n    with u1 = -(a1 + b1 * p), u2 = -(a2 + b2 * (1 - p)).\n    Returns p_T.\n    \"\"\"\n    p = float(p0)\n    for _ in range(T):\n        # Payoffs are negative costs\n        u1 = -(a1 + b1 * p)\n        u2 = -(a2 + b2 * (1.0 - p))\n        delta = eta * p * (1.0 - p) * (u1 - u2)\n        p = p + delta\n        # Clip to [0,1] to respect the simplex constraint\n        if p  0.0:\n            p = 0.0\n        elif p > 1.0:\n            p = 1.0\n    return p\n\ndef solve():\n    # Define the test cases from the problem statement.\n    # Each case is a tuple: (a1, b1, a2, b2, eta, T, p0)\n    test_cases = [\n        (0.2, 1.0, 0.8, 0.4, 0.05, 20000, 0.1),\n        (0.0, 1.0, 2.0, 1.0, 0.05, 20000, 0.5),\n        (1.5, 1.0, 0.0, 1.0, 0.05, 20000, 0.8),\n        (1.0, 0.0, 1.0, 0.0, 0.2, 1000, 0.3),\n        (0.0, 1.0, 0.1, 3.0, 0.03, 30000, 0.9),\n    ]\n\n    results = []\n    for a1, b1, a2, b2, eta, T, p0 in test_cases:\n        p_star, continuum = compute_equilibrium(a1, b1, a2, b2)\n        p_T = simulate_replicator(a1, b1, a2, b2, eta, T, p0)\n        if continuum:\n            deviation = 0.0  # Any p in [0,1] is an equilibrium\n        else:\n            deviation = abs(p_T - p_star)\n        # Format with fixed precision for deterministic output\n        results.append(f\"{deviation:.6f}\")\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(results)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "在现实世界的高维复杂博弈中，解析解往往遥不可及，我们必须依赖数值算法。本练习聚焦于求解均衡的计算工具箱，要求你实现并评估多种寻找纳什均衡的迭代方法。通过在一个二次博弈测试平台上对最佳响应、梯度博弈、近端最佳响应和外梯度法等算法进行基准测试，你将获得关于它们收敛性、稳定性及效率的宝贵实践经验()。这对于任何希望在研究或应用中处理大规模博弈问题的学习者来说，都是一项至关重要的技能。",
            "id": "3154618",
            "problem": "本任务要求您设计、实现并比较四种迭代方法，用于计算光滑、严格凸二次双人博弈中的纳什均衡，并在系列测试用例上对其收敛行为进行基准测试。纳什均衡的定义为：在给定另一方策略的情况下，每一方玩家的策略都是最优的那个点。对于可微的成本函数，一阶最优性条件将纳什均衡刻画为一个合适算子的零点。您的程序必须是一个完整的、可运行的程序，不接受任何输入，并打印一行包含汇总结果的输出。\n\n此任务的基础如下。\n\n- 两名玩家分别选择向量 $x \\in \\mathbb{R}^{n}$ 和 $y \\in \\mathbb{R}^{m}$。玩家 1 最小化二次目标函数\n$$\nf_1(x,y) = \\tfrac{1}{2} x^\\top Q_1 x + x^\\top C y + b_1^\\top x + c_1,\n$$\n玩家 2 最小化\n$$\nf_2(x,y) = \\tfrac{1}{2} y^\\top Q_2 y + y^\\top D x + b_2^\\top y + c_2,\n$$\n其中 $Q_1 \\in \\mathbb{R}^{n \\times n}$ 和 $Q_2 \\in \\mathbb{R}^{m \\times m}$ 是对称正定矩阵，$C \\in \\mathbb{R}^{n \\times m}$ 和 $D \\in \\mathbb{R}^{m \\times n}$ 是耦合矩阵，$b_1 \\in \\mathbb{R}^n$，$b_2 \\in \\mathbb{R}^m$ 是向量。常数 $c_1$ 和 $c_2$ 对最优性没有影响，可以为任意值。\n\n- 编码一阶最优性条件的算子映射为\n$$\nF(z) = \\begin{bmatrix}\n\\nabla_x f_1(x,y) \\\\\n\\nabla_y f_2(x,y)\n\\end{bmatrix}\n= M z + q,\n\\quad\nz = \\begin{bmatrix} x \\\\ y \\end{bmatrix},\n\\quad\nM = \\begin{bmatrix} Q_1  C \\\\ D  Q_2 \\end{bmatrix},\n\\quad\nq = \\begin{bmatrix} b_1 \\\\ b_2 \\end{bmatrix}.\n$$\n在 $M$ 是对称正定的条件下（例如，当 $D=C^\\top$ 且 $Q_1, Q_2$ 对称正定时），$F$ 是强单调且利普希茨连续的。唯一的纳什均衡 $z^\\star$ 满足 $F(z^\\star) = 0$。\n\n您的任务是基于上述基础，实现以下迭代方法，而不依赖于问题陈述中的任何快捷公式。\n\n- 最佳响应 (BR)：序贯地最小化每个玩家的目标函数，此时对手的当前策略保持不变，使用二次子问题的精确解。\n\n- 梯度博弈 (GP)：使用算子 $F$ 对双方玩家的策略同时应用一个基于梯度的步骤。\n\n- 近端最佳响应 (PBR)：通过在每个玩家的子问题中添加一个二次正则化项来修正最佳响应法，该正则化项惩罚偏离当前迭代点的行为，以引入收缩并稳定迭代。\n\n- 外梯度 (EG)：在主更新之前应用一个额外的“前瞻”梯度步骤，以校正算子的曲率；在两个阶段都使用映射 $F$。\n\n对于梯度博弈和外梯度法，您必须根据 $F$ 的利普希茨常数选择一个步长。对于二次博弈，$F$ 是线性的，利普希茨常数等于 $M$ 的谱范数，记为 $L$。一个安全的选择是步长 $\\gamma$ 满足 $0  \\gamma \\leq 1/L$。对于近端最佳响应法，选择一个正则化参数 $\\rho  0$；一个实用且有理论依据的选择是 $\\rho = L$。\n\n实施细节如下：\n\n- 初始化：所有方法均使用零向量 $z_0 = \\begin{bmatrix} 0 \\\\ 0 \\end{bmatrix}$。\n\n- 终止准则：对于每种方法，迭代直到欧几里得范数误差 $\\lVert z_k - z^\\star \\rVert_2$ 小于容差 $\\varepsilon = 10^{-8}$，或直到达到最大迭代次数 $N_{\\max} = 5000$。如果方法在 $N_{\\max}$ 次迭代内未能达到容差，则报告该方法的迭代次数为 $-1$。\n\n- 输出：对于每个测试用例，报告一个包含 4 个整数的列表，这些整数分别对应于 BR、GP、PBR 和 EG 所需的迭代次数，顺序如此。您的程序应生成一行输出，其中包含用方括号括起来的逗号分隔列表形式的结果，每个元素本身是对应一个测试用例的列表。例如，一个有效的输出格式是\n$$\n[\\,[i_{1,\\mathrm{BR}}, i_{1,\\mathrm{GP}}, i_{1,\\mathrm{PBR}}, i_{1,\\mathrm{EG}}],\\,[i_{2,\\mathrm{BR}}, i_{2,\\mathrm{GP}}, i_{2,\\mathrm{PBR}}, i_{2,\\mathrm{EG}}],\\,\\dots\\,]\n$$\n其中每个 $i_{\\cdot,\\cdot}$ 都是一个整数。\n\n测试套件规范：\n\n提供以下五个凸二次博弈，所有博弈均设置 $D = C^\\top$ 以确保 $M$ 对称。\n\n- 案例 1（标量变量，中等耦合）：\n$$\nn=m=1,\\quad\nQ_1 = [\\,2\\,],\\quad\nQ_2 = [\\,3\\,],\\quad\nC = [\\,0.5\\,],\\quad\nb_1 = [\\,1\\,],\\quad\nb_2 = [\\,-2\\,].\n$$\n\n- 案例 2（标量变量，解耦边界情况）：\n$$\nn=m=1,\\quad\nQ_1 = [\\,1.5\\,],\\quad\nQ_2 = [\\,2.5\\,],\\quad\nC = [\\,0.0\\,],\\quad\nb_1 = [\\,-1.0\\,],\\quad\nb_2 = [\\,3.0\\,].\n$$\n\n- 案例 3（二维变量，中等耦合）：\n$$\nn=m=2,\\quad\nQ_1 = \\begin{bmatrix} 2  0 \\\\ 0  4 \\end{bmatrix},\\quad\nQ_2 = \\begin{bmatrix} 3  0 \\\\ 0  1.5 \\end{bmatrix},\\quad\nC = \\begin{bmatrix} 0.3  -0.1 \\\\ 0.2  0.0 \\end{bmatrix},\\quad\nb_1 = \\begin{bmatrix} 1 \\\\ -1 \\end{bmatrix},\\quad\nb_2 = \\begin{bmatrix} 0.5 \\\\ -0.5 \\end{bmatrix}.\n$$\n\n- 案例 4（二维变量，病态但稳定）：\n$$\nn=m=2,\\quad\nQ_1 = \\begin{bmatrix} 0.01  0 \\\\ 0  100 \\end{bmatrix},\\quad\nQ_2 = \\begin{bmatrix} 0.001  0 \\\\ 0  50 \\end{bmatrix},\\quad\nC = \\begin{bmatrix} 0.05  0.0 \\\\ 0.0  0.05 \\end{bmatrix},\\quad\nb_1 = \\begin{bmatrix} 1 \\\\ 1 \\end{bmatrix},\\quad\nb_2 = \\begin{bmatrix} -1 \\\\ 2 \\end{bmatrix}.\n$$\n\n- 案例 5（三维变量，更强但仍稳定的耦合）：\n$$\nn=m=3,\\quad\nQ_1 = \\mathrm{diag}(1,2,3),\\quad\nQ_2 = \\mathrm{diag}(1.5,2.5,3.5),\\quad\nC = 0.3\\,I_3,\\quad\nb_1 = \\begin{bmatrix} 1 \\\\ -2 \\\\ 0.5 \\end{bmatrix},\\quad\nb_2 = \\begin{bmatrix} -1 \\\\ 1 \\\\ 2 \\end{bmatrix},\n$$\n其中 $I_3$ 是 $3 \\times 3$ 的单位矩阵。\n\n实现约束：\n\n- 通过求解线性系统 $M z^\\star + q = 0$ 来精确计算 $z^\\star$。\n\n- 对于梯度博弈和外梯度法，将 $L$ 计算为 $M$ 的谱范数，并使用 $\\gamma = 1/L$。\n\n- 对于近端最佳响应法，使用 $\\rho = L$。\n\n- 确保所有迭代从 $z_0 = 0$ 开始，并使用欧几里得范数误差容差 $\\varepsilon = 10^{-8}$。\n\n您的最终程序必须按指定格式单行打印所有五个案例的结果，每个内部列表给出相应案例的迭代次数 $[i_{\\mathrm{BR}}, i_{\\mathrm{GP}}, i_{\\mathrm{PBR}}, i_{\\mathrm{EG}}]$。",
            "solution": "我们从可微、严格凸二次博弈中纳什均衡和一阶最优性的基本定义开始。玩家 1 相对于 $x$ 的梯度是\n$$\n\\nabla_x f_1(x,y) = Q_1 x + C y + b_1,\n$$\n玩家 2 相对于 $y$ 的梯度是\n$$\n\\nabla_y f_2(x,y) = Q_2 y + D x + b_2.\n$$\n将变量 $z = \\begin{bmatrix} x \\\\ y \\end{bmatrix}$ 和梯度堆叠起来，得到算子 $F(z) = M z + q$，其中\n$$\nM = \\begin{bmatrix} Q_1  C \\\\ D  Q_2 \\end{bmatrix}, \\quad q = \\begin{bmatrix} b_1 \\\\ b_2 \\end{bmatrix}.\n$$\n当 $M$ 是对称正定矩阵时（对于测试套件，通过取 $D=C^\\top$ 以及 $Q_1, Q_2$ 为对称正定且耦合足够小来满足），则 $F$ 是强单调且利普希茨连续的。唯一的纳什均衡解满足 $F(z^\\star) = 0$。因为 $F$ 是线性的，我们得到\n$$\nM z^\\star + q = 0 \\quad \\Rightarrow \\quad z^\\star = - M^{-1} q,\n$$\n这可以通过线性求解器计算得出。\n\n我们现在从核心原理推导每种迭代方法。\n\n- 最佳响应 (BR)。固定对手的策略，将每个玩家的问题简化为关于其自身变量的严格凸二次问题。二次函数 $x \\mapsto \\tfrac{1}{2} x^\\top Q_1 x + (C y_k + b_1)^\\top x$ 的最小化点由一阶条件 $Q_1 x_{k+1} + C y_k + b_1 = 0$ 刻画，即\n$$\nx_{k+1} = -Q_1^{-1}(C y_k + b_1).\n$$\n然后，给定 $x_{k+1}$，玩家 2 的最佳响应满足 $Q_2 y_{k+1} + D x_{k+1} + b_2 = 0$，即\n$$\ny_{k+1} = -Q_2^{-1}(D x_{k+1} + b_2).\n$$\n这两个更新实现了求解 $M z + q = 0$ 的块高斯-赛德尔 (Gauss–Seidel) 方法。\n\n- 梯度博弈 (GP)。使用算子 $F$ 对双方玩家同时进行一个梯度步骤，可表示为\n$$\nz_{k+1} = z_k - \\gamma F(z_k) = z_k - \\gamma (M z_k + q).\n$$\n对于线性利普希茨算子，其常数为 $L = \\lVert M \\rVert_2$（谱范数），稳定性的一个充分条件是 $0  \\gamma \\le 1/L$。我们选择 $\\gamma = 1/L$ 作为安全的步长。\n\n- 近端最佳响应 (PBR)。近端修正方法增加了一个二次正则化项，用于惩罚与当前迭代点的变化。对于玩家 1，子问题是\n$$\n\\min_x \\left\\{ \\tfrac{1}{2} x^\\top Q_1 x + (C y_k + b_1)^\\top x + \\tfrac{\\rho}{2} \\lVert x - x_k \\rVert_2^2 \\right\\}.\n$$\n其一阶条件是\n$$\nQ_1 x_{k+1} + C y_k + b_1 + \\rho (x_{k+1} - x_k) = 0 \\quad \\Rightarrow \\quad (Q_1 + \\rho I) x_{k+1} = \\rho x_k - C y_k - b_1,\n$$\n得到\n$$\nx_{k+1} = (Q_1 + \\rho I)^{-1}(\\rho x_k - C y_k - b_1).\n$$\n类似地，玩家 2 的更新是\n$$\ny_{k+1} = (Q_2 + \\rho I)^{-1}(\\rho y_k - D x_{k+1} - b_2).\n$$\n选择 $\\rho = L$ 会产生强收缩，从而稳定并通常加速收敛，与未正则化的 BR 相比。\n\n- 外梯度 (EG)。Korpelevich 的外梯度法用于单调变分不等式，它在主更新前计算一个前瞻点并在该点评估算子。对于我们的无约束线性 $F$，\n$$\nz_{k+\\tfrac{1}{2}} = z_k - \\gamma F(z_k), \\quad\nz_{k+1} = z_k - \\gamma F(z_{k+\\tfrac{1}{2}}),\n$$\n使用同样的安全步长选择 $\\gamma = 1/L$。这可以校正曲率，并提供比普通梯度博弈更好的鲁棒性，在许多情况下收敛也更快。\n\n所有方法都从 $z_0 = 0$ 开始。当欧几里得范数误差满足\n$$\n\\lVert z_k - z^\\star \\rVert_2 \\le \\varepsilon, \\quad \\varepsilon = 10^{-8},\n$$\n时终止，或当迭代次数超过 $N_{\\max} = 5000$ 时终止，此时我们报告失败代码 $-1$。\n\n对于由 $(Q_1, Q_2, C, D, b_1, b_2)$ 定义的每个测试用例，我们：\n\n1. 构建 $M$ 和 $q$。\n2. 计算均衡点 $z^\\star = -M^{-1} q$。\n3. 通过奇异值计算谱范数 $L = \\lVert M \\rVert_2$，并设置 $\\gamma = 1/L$ 和 $\\rho = L$。\n4. 从 $z_0 = 0$ 开始运行 BR、GP、PBR 和 EG，计算迭代次数直到达到容差或失败。\n5. 记录四个整数 $[i_{\\mathrm{BR}}, i_{\\mathrm{GP}}, i_{\\mathrm{PBR}}, i_{\\mathrm{EG}}]$。\n\n测试套件中的设计覆盖范围：\n\n- 案例 2 设置 $C = 0$，创建了解耦问题。BR 和 PBR 在一次迭代中即可获得精确解，因为每个玩家的子问题是独立的；GP 和 EG 仍然线性收敛，但通常需要多次迭代。这是一个测试正确性和精确性的边界情况。\n\n- 案例 4 使用了病态的 $Q_1$ 和 $Q_2$ 以及小但非零的耦合。由于条件数问题，GP 显著减慢；EG 和 PBR 改善了稳定性。这测试了对条件数的敏感性以及正则化和前瞻步骤的好处。\n\n- 案例 1、3 和 5 分别在一维、二维和三维设置中提供了“理想路径”和更强耦合的场景，测试了算法在不同维度下的可扩展性和鲁棒性。\n\n最终的程序将精确实现这些步骤，并按指定的格式打印一行包含五个测试用例的嵌套迭代次数列表。这通过在固定容差下，使用相同的初始化和从算子利普希茨常数推导出的理论安全参数选择，来通过迭代次数定量地对收敛行为（“速率”）进行基准测试。",
            "answer": "```python\n# Python 3.12; numpy 1.23.5; scipy not used.\nimport numpy as np\n\ndef spectral_norm(M: np.ndarray) - float:\n    # Spectral norm (largest singular value)\n    return np.linalg.svd(M, compute_uv=False)[0]\n\ndef equilibrium(M: np.ndarray, q: np.ndarray) - np.ndarray:\n    # Solve M z* + q = 0 = z* = - M^{-1} q\n    return -np.linalg.solve(M, q)\n\ndef best_response(Q1, Q2, C, D, b1, b2, z_star, tol=1e-8, max_iters=5000):\n    n = Q1.shape[0]\n    m = Q2.shape[0]\n    x = np.zeros(n)\n    y = np.zeros(m)\n    for k in range(1, max_iters + 1):\n        # Player 1 best response\n        rhs1 = -C @ y - b1\n        x = np.linalg.solve(Q1, rhs1)\n        # Player 2 best response\n        rhs2 = -D @ x - b2\n        y = np.linalg.solve(Q2, rhs2)\n        z = np.concatenate([x, y])\n        err = np.linalg.norm(z - z_star)\n        if err = tol:\n            return k\n    return -1\n\ndef proximal_best_response(Q1, Q2, C, D, b1, b2, z_star, rho, tol=1e-8, max_iters=5000):\n    n = Q1.shape[0]\n    m = Q2.shape[0]\n    x = np.zeros(n)\n    y = np.zeros(m)\n    Q1p = Q1 + rho * np.eye(n)\n    Q2p = Q2 + rho * np.eye(m)\n    for k in range(1, max_iters + 1):\n        rhs1 = rho * x - C @ y - b1\n        x = np.linalg.solve(Q1p, rhs1)\n        rhs2 = rho * y - D @ x - b2\n        y = np.linalg.solve(Q2p, rhs2)\n        z = np.concatenate([x, y])\n        err = np.linalg.norm(z - z_star)\n        if err = tol:\n            return k\n    return -1\n\ndef gradient_play(M, q, z_star, gamma, tol=1e-8, max_iters=5000):\n    z = np.zeros_like(z_star)\n    for k in range(1, max_iters + 1):\n        Fz = M @ z + q\n        z = z - gamma * Fz\n        err = np.linalg.norm(z - z_star)\n        if err = tol:\n            return k\n    return -1\n\ndef extragradient(M, q, z_star, gamma, tol=1e-8, max_iters=5000):\n    z = np.zeros_like(z_star)\n    for k in range(1, max_iters + 1):\n        Fz = M @ z + q\n        z_half = z - gamma * Fz\n        Fz_half = M @ z_half + q\n        z = z - gamma * Fz_half\n        err = np.linalg.norm(z - z_star)\n        if err = tol:\n            return k\n    return -1\n\ndef build_block_matrix(Q1, Q2, C, D):\n    return np.block([[Q1, C],\n                     [D, Q2]])\n\ndef solve_case(Q1, Q2, C, D, b1, b2):\n    M = build_block_matrix(Q1, Q2, C, D)\n    q = np.concatenate([b1, b2])\n    z_star = equilibrium(M, q)\n    L = spectral_norm(M)\n    gamma = 1.0 / L\n    rho = L\n    it_br = best_response(Q1, Q2, C, D, b1, b2, z_star, tol=1e-8, max_iters=5000)\n    it_gp = gradient_play(M, q, z_star, gamma=gamma, tol=1e-8, max_iters=5000)\n    it_pbr = proximal_best_response(Q1, Q2, C, D, b1, b2, z_star, rho=rho, tol=1e-8, max_iters=5000)\n    it_eg = extragradient(M, q, z_star, gamma=gamma, tol=1e-8, max_iters=5000)\n    return [it_br, it_gp, it_pbr, it_eg]\n\ndef solve():\n    test_cases = []\n\n    # Case 1: scalar, moderate coupling\n    Q1 = np.array([[2.0]])\n    Q2 = np.array([[3.0]])\n    C = np.array([[0.5]])\n    D = C.T\n    b1 = np.array([1.0])\n    b2 = np.array([-2.0])\n    test_cases.append((Q1, Q2, C, D, b1, b2))\n\n    # Case 2: scalar, decoupled\n    Q1 = np.array([[1.5]])\n    Q2 = np.array([[2.5]])\n    C = np.array([[0.0]])\n    D = C.T\n    b1 = np.array([-1.0])\n    b2 = np.array([3.0])\n    test_cases.append((Q1, Q2, C, D, b1, b2))\n\n    # Case 3: 2D, moderate coupling\n    Q1 = np.array([[2.0, 0.0],\n                   [0.0, 4.0]])\n    Q2 = np.array([[3.0, 0.0],\n                   [0.0, 1.5]])\n    C = np.array([[0.3, -0.1],\n                  [0.2,  0.0]])\n    D = C.T\n    b1 = np.array([1.0, -1.0])\n    b2 = np.array([0.5, -0.5])\n    test_cases.append((Q1, Q2, C, D, b1, b2))\n\n    # Case 4: 2D, ill-conditioned\n    Q1 = np.array([[0.01, 0.0],\n                   [0.0, 100.0]])\n    Q2 = np.array([[0.001, 0.0],\n                   [0.0, 50.0]])\n    C = np.array([[0.05, 0.0],\n                  [0.0, 0.05]])\n    D = C.T\n    b1 = np.array([1.0, 1.0])\n    b2 = np.array([-1.0, 2.0])\n    test_cases.append((Q1, Q2, C, D, b1, b2))\n\n    # Case 5: 3D, stronger but stable coupling\n    Q1 = np.diag([1.0, 2.0, 3.0])\n    Q2 = np.diag([1.5, 2.5, 3.5])\n    C = 0.3 * np.eye(3)\n    D = C.T\n    b1 = np.array([1.0, -2.0, 0.5])\n    b2 = np.array([-1.0, 1.0, 2.0])\n    test_cases.append((Q1, Q2, C, D, b1, b2))\n\n    results = []\n    for Q1, Q2, C, D, b1, b2 in test_cases:\n        res = solve_case(Q1, Q2, C, D, b1, b2)\n        results.append(res)\n\n    print(str(results).replace(' ', ''))\n\nif __name__ == \"__main__\":\n    solve()\n```"
        }
    ]
}