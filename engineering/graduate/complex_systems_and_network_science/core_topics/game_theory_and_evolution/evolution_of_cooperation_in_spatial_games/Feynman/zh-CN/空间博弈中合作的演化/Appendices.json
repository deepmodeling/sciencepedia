{
    "hands_on_practices": [
        {
            "introduction": "合作的演化通常取决于合作者与背叛者集群边界处的动态。这个练习将提供一个精确的、解析性的视角来审视一个简化界面上的入侵概率，揭示策略成功与否的核心机制。通过计算一个合作者在特定条件下被模仿的概率，我们能量化地理解局部收益差异如何转化为演化优势或劣势 。",
            "id": "4274998",
            "problem": "考虑一个无限的 $k$-正则空间网络上的囚徒困境（PD），其参数化为捐赠博弈形式。在该网络中，每个参与者都与其所有 $k$ 个邻居进行成对互动。在每次成对互动中，合作者支付成本 $c>0$ 为对手带来收益 $b>c$，而背叛者不支付任何成本，也不带来任何收益。因此，对于任何单次互动，行参与者的收益为：相互合作产生 $R=b-c$，单方面合作对阵背叛产生 $S=-c$，单方面背叛对阵合作产生 $T=b$，相互背叛产生 $P=0$。一个参与者的总收益是其与所有 $k$ 个邻居进行成对互动所得收益的总和。\n\n关注一个半无限的背叛者区域与其互补的合作者区域之间的一条直线界面。考虑界面两侧一对相邻的边界节点，一个为背叛者，一个为合作者。由于界面的规则性，两者都恰好有 $m$ 个合作者邻居和 $k-m$ 个背叛者邻居（其中 $1 \\leq m \\leq k-1$）。策略更新是异步的，并遵循强度参数为 $\\beta=1$ 的 Fermi 成对比较规则：当边界背叛者通过其共享边与边界合作者进行比较时，该背叛者采纳合作策略的概率取决于他们的收益差。\n\n将边界合作者的入侵适应度 $\\phi$ 定义为在上述比较事件中，边界背叛者采纳合作策略的条件概率。计算 $\\phi$ 的闭式表达式，该表达式仅含 $k$ 和 $c$。将您的最终答案表示为单一的解析表达式；无需进行四舍五入。",
            "solution": "问题陈述经评估具有科学依据、问题良定且内容自洽。它描述了网络演化博弈论中的一个经典模型。前提清晰，所要求的任务是既定原则的直接应用。边界合作者和边界背叛者都拥有相同数量的合作者邻居（$m$ 个）这一关键条件，是一个特定的理论简化，其本身并非内在矛盾，并能导出一个定义明确的计算。因此，该问题被视为有效，并且可以推导出解。\n\n问题描述了捐赠博弈形式的囚徒困境。在单次成对互动中，合作者支付成本 $c>0$ 为其对手提供收益 $b>c$。背叛者不支付任何费用，也不提供任何收益。行参与者的收益由以下矩阵给出：\n$$\n\\begin{pmatrix}\nR  S \\\\\nT  P\n\\end{pmatrix}\n=\n\\begin{pmatrix}\nb-c  -c \\\\\nb  0\n\\end{pmatrix}\n$$\n其中 $R$ 是相互合作的收益，$S$ 是与背叛者合作的收益，$T$ 是对合作者进行背叛的收益，$P$ 是相互背叛的收益。在 $k$-正则网络上，一个参与者的总收益是其与 $k$ 个邻居互动所得收益的总和。\n\n我们需要考虑一个焦点合作者（记为 $C^*$）和一个相邻的焦点背叛者（记为 $D^*$）。根据问题陈述，两个参与者都位于合作者区域和背叛者区域之间的边界上，并且具有相同的邻居构成：每个参与者都有 $m$ 个合作者邻居和 $k-m$ 个背叛者邻居，其中 $1 \\leq m \\leq k-1$。\n\n让我们计算焦点合作者 $C^*$ 的总收益 $\\Pi_C$。该参与者有 $m$ 个合作者邻居和 $k-m$ 个背叛者邻居。其总收益是这些互动收益的总和：\n$$\n\\Pi_C = m \\cdot R + (k-m) \\cdot S\n$$\n代入 $R$ 和 $S$ 的表达式：\n$$\n\\Pi_C = m(b-c) + (k-m)(-c) = mb - mc - kc + mc\n$$\n$$\n\\Pi_C = mb - kc\n$$\n接下来，我们计算焦点背叛者 $D^*$ 的总收益 $\\Pi_D$。该参与者同样有 $m$ 个合作者邻居和 $k-m$ 个背叛者邻居。其总收益是这些互动收益的总和：\n$$\n\\Pi_D = m \\cdot T + (k-m) \\cdot P\n$$\n代入 $T$ 和 $P$ 的表达式：\n$$\n\\Pi_D = m(b) + (k-m)(0)\n$$\n$$\n\\Pi_D = mb\n$$\n问题陈述指出策略更新遵循 Fermi 成对比较规则。入侵适应度 $\\phi$ 被定义为当背叛者 $D^*$ 与合作者 $C^*$ 比较时，采纳合作者策略的条件概率。参与者 $i$ 采纳邻居 $j$ 策略的 Fermi 规则的一般形式为：\n$$\nP(i \\to j) = \\frac{1}{1 + \\exp(-\\beta(\\Pi_j - \\Pi_i))}\n$$\n在我们的案例中，参与者 $i$ 是背叛者 $D^*$，参与者 $j$ 是合作者 $C^*$。选择强度给定为 $\\beta = 1$。因此，概率 $\\phi$ 为：\n$$\n\\phi = \\frac{1}{1 + \\exp(-1 \\cdot (\\Pi_C - \\Pi_D))} = \\frac{1}{1 + \\exp(-(\\Pi_C - \\Pi_D))}\n$$\n为了计算 $\\phi$，我们必须首先求出收益差 $\\Pi_C - \\Pi_D$：\n$$\n\\Pi_C - \\Pi_D = (mb - kc) - (mb) = -kc\n$$\n将这个差值代入 $\\phi$ 的表达式中：\n$$\n\\phi = \\frac{1}{1 + \\exp(-(-kc))}\n$$\n$$\n\\phi = \\frac{1}{1 + \\exp(kc)}\n$$\n这个 $\\phi$ 的表达式仅包含 $k$ 和 $c$，符合问题陈述的要求。由于对两个焦点参与者采用了对称邻域的假设，参数 $b$ 和 $m$ 在计算中被消掉了。",
            "answer": "$$\n\\boxed{\\frac{1}{1 + \\exp(kc)}}\n$$"
        },
        {
            "introduction": "虽然微观分析富有洞察力，但我们也需要工具来预测整个系统的宏观、长期行为。本练习将介绍两种关键的理论工具——平均场 (Mean-Field, MF) 理论和对近似 (Pair Approximation, PA) 。通过比较它们的预测结果，你将亲身体会到，考虑局部空间相关性如何显著改变对合作水平的预期结果。",
            "id": "4274916",
            "problem": "考虑一个大型种群，其结构为度为 $k$ 的规则随机图（RRG），其中每个节点与其所有邻居进行二人双策略的雪堆博弈（也称鹰鸽博弈）。设合作收益为 $b>0$，合作成本为 $c>0$，支付矩阵的条目由标准雪堆博弈参数化定义：相互合作给予每个合作者支付 $R=b-\\frac{c}{2}$，单方合作给予合作者支付 $S=b-c$、给予背叛者支付 $T=b$，相互背叛则各得支付 $P=0$。策略更新遵循弱选择下的成对比较（模仿）规则，其中采纳概率是支付差异的单调函数。\n\n使用以下广为接受的事实作为基本依据：\n- 在复制动力学下的双策略博弈的充分混合（平均场，MF）极限中，合作者密度 $x$ 的内部稳态 $x_{\\mathrm{MF}}$ 由合作者与背叛者的期望支付相等来确定，即 $R x + S (1-x) = T x + P (1-x)$。\n- 在弱选择和成对比较（模仿）规则下的 $k$-规则图上，对近似（PA）方法产生了一个图上的有效复制方程，该方程等价于使用变换后支付矩阵 $\\mathbf{A}'=\\mathbf{A}+\\frac{1}{k}\\left(\\mathbf{A}-\\mathbf{A}^{\\top}\\right)$ 的平均场复制方程，其中 $\\mathbf{A}=\\begin{pmatrix}R  S \\\\ T  P\\end{pmatrix}$ 且 ${}^{\\top}$ 表示转置。内部稳态 $x_{\\mathrm{PA}}$ 由使用 $\\mathbf{A}'$ 计算的期望支付相等来确定。\n\n对于特定的图度和参数设置，令 $k=4$，$b=1$，$c=0.6$。推导平均场（MF）预测值 $x_{\\mathrm{MF}}$ 和对近似（PA）预测值 $x_{\\mathrm{PA}}$，并计算数值差异 $\\Delta=x_{\\mathrm{PA}}-x_{\\mathrm{MF}}$。将 $\\Delta$ 表示为无单位小数，并四舍五入到四位有效数字。",
            "solution": "该问题要求计算在规则随机图上由对近似（PA）预测的合作者频率与雪堆博弈的平均场（MF）理论预测的频率之间的差异。该问题定义明确，其前提与演化博弈论中的标准模型一致。\n\n首先，我们使用给定的参数 $b=1$ 和 $c=0.6$ 来定义支付矩阵 $\\mathbf{A}=\\begin{pmatrix} R  S \\\\ T  P \\end{pmatrix}$。\n支付条目为：\n$R = b - \\frac{c}{2} = 1 - \\frac{0.6}{2} = 1 - 0.3 = 0.7$\n$S = b - c = 1 - 0.6 = 0.4$\n$T = b = 1$\n$P = 0$\n因此，支付矩阵为 $\\mathbf{A} = \\begin{pmatrix} 0.7  0.4 \\\\ 1  0 \\end{pmatrix}$。\n雪堆博弈中稳定混合策略均衡的条件是 $T > R > S > P$，对应于 $1 > 0.7 > 0.4 > 0$。此条件已满足。\n\n接下来，我们计算合作者频率的平均场（MF）预测值 $x_{\\mathrm{MF}}$。内部稳态出现在合作者的期望支付 $E_C$ 与背叛者的期望支付 $E_D$ 相等之处。设 $x$ 为合作者的频率。\n$$E_C = x R + (1-x) S$$\n$$E_D = x T + (1-x) P$$\n在 $x=x_{\\mathrm{MF}}$ 处令 $E_C = E_D$：\n$$x_{\\mathrm{MF}} R + (1-x_{\\mathrm{MF}}) S = x_{\\mathrm{MF}} T + (1-x_{\\mathrm{MF}}) P$$\n解出 $x_{\\mathrm{MF}}$ 得到通用公式：\n$$x_{\\mathrm{MF}} = \\frac{P-S}{R-S-T+P}$$\n代入数值支付值：\n$$x_{\\mathrm{MF}} = \\frac{0 - 0.4}{0.7 - 0.4 - 1 + 0} = \\frac{-0.4}{-0.7} = \\frac{4}{7}$$\n\n现在，我们计算对近似（PA）预测值 $x_{\\mathrm{PA}}$。根据问题陈述，这由一个有效支付矩阵 $\\mathbf{A}' = \\mathbf{A} + \\frac{1}{k}(\\mathbf{A} - \\mathbf{A}^{\\top})$ 确定，其中图度 $k=4$。\n首先，我们计算 $\\mathbf{A}-\\mathbf{A}^{\\top}$：\n$$\\mathbf{A} - \\mathbf{A}^{\\top} = \\begin{pmatrix} 0.7  0.4 \\\\ 1  0 \\end{pmatrix} - \\begin{pmatrix} 0.7  1 \\\\ 0.4  0 \\end{pmatrix} = \\begin{pmatrix} 0  -0.6 \\\\ 0.6  0 \\end{pmatrix}$$\n然后我们计算 $k=4$ 的修正项：\n$$\\frac{1}{k}(\\mathbf{A} - \\mathbf{A}^{\\top}) = \\frac{1}{4} \\begin{pmatrix} 0  -0.6 \\\\ 0.6  0 \\end{pmatrix} = \\begin{pmatrix} 0  -0.15 \\\\ 0.15  0 \\end{pmatrix}$$\n有效支付矩阵 $\\mathbf{A}'$ 为：\n$$\\mathbf{A}' = \\mathbf{A} + \\frac{1}{k}(\\mathbf{A} - \\mathbf{A}^{\\top}) = \\begin{pmatrix} 0.7  0.4 \\\\ 1  0 \\end{pmatrix} + \\begin{pmatrix} 0  -0.15 \\\\ 0.15  0 \\end{pmatrix} = \\begin{pmatrix} 0.7  0.25 \\\\ 1.15  0 \\end{pmatrix}$$\n设这个新矩阵的条目为 $\\mathbf{A}'=\\begin{pmatrix} R'  S' \\\\ T'  P' \\end{pmatrix}$。所以，$R'=0.7$，$S'=0.25$，$T'=1.15$，$P'=0$。\nPA稳态 $x_{\\mathrm{PA}}$ 使用相同的均衡条件形式求得，但使用的是有效支付：\n$$x_{\\mathrm{PA}} = \\frac{P'-S'}{R'-S'-T'+P'}$$\n代入新的支付值：\n$$x_{\\mathrm{PA}} = \\frac{0 - 0.25}{0.7 - 0.25 - 1.15 + 0} = \\frac{-0.25}{0.45 - 1.15} = \\frac{-0.25}{-0.7} = \\frac{25}{70} = \\frac{5}{14}$$\n\n最后，我们计算差异 $\\Delta = x_{\\mathrm{PA}} - x_{\\mathrm{MF}}$。\n$$\\Delta = \\frac{5}{14} - \\frac{4}{7} = \\frac{5}{14} - \\frac{8}{14} = -\\frac{3}{14}$$\n为提供数值答案，我们将此分数转换为小数：\n$$\\Delta = -\\frac{3}{14} \\approx -0.2142857...$$\n四舍五入到四位有效数字，我们得到：\n$$\\Delta \\approx -0.2143$$\n这个负值表明，在成对比较更新规则下的雪堆博弈中，由对近似所捕捉的空间结构导致合作者的频率低于充分混合种群中的频率。",
            "answer": "$$\\boxed{-0.2143}$$"
        },
        {
            "introduction": "理论近似有其局限性，而直接模拟是探索复杂空间动态的强大工具。本练习将使用模拟来研究空间博弈论中最著名的发现之一：空间异质性（如网格上的角落和边缘）如何成为合作者的“避难所”，从而显著提高其生存和最终被固定的概率 。这个计算实验直观地展示了网络互惠的关键机制。",
            "id": "4274991",
            "problem": "考虑一个大小为 $N \\times N$ 的有限二维方格网络，其边界为反射边界（非周期性），其中每个顶点代表一个智能体，每条无向边代表两个相邻智能体之间的一次交互。每个智能体永久占据其顶点，并持有两种策略中的一种：合作 $C$ 或背叛 $D$。交互遵循囚徒困境的捐赠博弈形式：合作者支付成本 $c > 0$ 为其每个邻居提供收益 $b > 0$，而背叛者不支付成本也不提供任何收益。对于一个度为 $d_i$、拥有 $n_i^C$ 个合作邻居的智能体 $i$，其瞬时收益 $\\pi_i$ 为\n$$\n\\pi_i = b \\, n_i^C - c \\, d_i \\, \\mathbf{1}\\{s_i = C\\},\n$$\n其中 $s_i \\in \\{C,D\\}$ 是智能体 $i$ 的策略，$\\mathbf{1}\\{\\cdot\\}$ 是指示函数。\n\n时间以离散步长 $t = 0, 1, 2, \\dots$ 演化。在每一步，从网络中随机均匀地选择一条无向边 $(i,j)$。然后，随机均匀地选择两种有向更新中的一种：要么 $i$ 考虑模仿 $j$，要么 $j$ 考虑模仿 $i$。如果 $i$ 考虑 $j$，智能体 $i$ 将根据 Fermi 成对比较规则给出的概率采纳智能体 $j$ 的策略：\n$$\np_{i \\leftarrow j} = \\frac{1}{1 + \\exp\\left(-\\beta \\left(\\pi_j - \\pi_i \\right)\\right)},\n$$\n其中 $\\beta \\ge 0$ 是选择强度。如果更新未导致策略被采纳，则该步的策略保持不变。该过程持续进行，直到所有智能体都成为合作者（全 $C$ 吸收态）或所有智能体都成为背叛者（全 $D$ 吸收态），或达到 $H$ 步的固定时限。\n\n初始条件是一个边长为 $s$ 的连续方形合作者集群，嵌入在一片背叛者之中。考虑两种布局：\n- 角落布局：合作者集群占据的网络坐标，其左上角固定在网络的角落，即行 $i \\in \\{0,1,\\dots,s-1\\}$ 和列 $j \\in \\{0,1,\\dots,s-1\\}$。\n- 中心布局：合作者集群作为一个边长为 $s$ 的连续方块居中，起始于行 $i \\in \\{\\lfloor (N-s)/2 \\rfloor, \\dots, \\lfloor (N-s)/2 \\rfloor + s - 1\\}$ 和列 $j \\in \\{\\lfloor (N-s)/2 \\rfloor, \\dots, \\lfloor (N-s)/2 \\rfloor + s - 1\\}$。\n\n在时限 $H$ 内合作的固定概率定义为：从指定的初始条件开始，在时间 $H$ 前达到全 $C$ 吸收态的独立模拟运行所占的比例（以小数表示）。\n\n您的任务是编写一个完整的程序，为以下每个测试用例计算合作的固定概率。每次运行使用独立的随机性。需要展示的观察结果是边界布局（角落与中心）如何影响固定概率，并且应在您的解决方案中通过界面增长论证来解释其机制。\n\n使用以下固定的捐赠博弈参数和测试套件：\n- 收益 $b = 1.0$。\n- 成本 $c \\in \\{0.25, 0.30\\}$，按各案例指定。\n- 选择强度 $\\beta \\in \\{0.0, 1.0, 2.0\\}$，按各案例指定。\n- 网络大小 $N = 20$。\n- 合作者集群边长 $s \\in \\{1, 4\\}$，按各案例指定。\n- 所有案例的时限均为 $H = 10000$ 步。\n\n测试套件（每个案例都是一个独立的设置，您必须为其输出合作的固定概率，以小数值表示）：\n1. 案例 A（角落，典型选择）：$N = 20$，$s = 4$，角落布局，$b = 1.0$，$c = 0.25$，$\\beta = 1.0$，$H = 10000$，独立运行次数 $R = 80$。\n2. 案例 B（中心，典型选择）：$N = 20$，$s = 4$，中心布局，$b = 1.0$，$c = 0.25$，$\\beta = 1.0$，$H = 10000$，独立运行次数 $R = 80$。\n3. 案例 C（角落，单一种子，强选择）：$N = 20$，$s = 1$，角落布局，$b = 1.0$，$c = 0.30$，$\\beta = 2.0$，$H = 10000$，独立运行次数 $R = 120$。\n4. 案例 D（中心，单一种子，强选择）：$N = 20$，$s = 1$，中心布局，$b = 1.0$，$c = 0.30$，$\\beta = 2.0$，$H = 10000$，独立运行次数 $R = 120$。\n5. 案例 E（中心，中性漂移基线）：$N = 20$，$s = 4$，中心布局，$b = 1.0$，$c = 0.25$，$\\beta = 0.0$，$H = 10000$，独立运行次数 $R = 80$。\n\n科学真实性约束：\n- 边界顶点的度必须反映网络结构（角落顶点度为 $2$，边缘顶点度为 $3$，内部顶点度为 $4$）。\n- 随机动态过程必须遵守指定的带有 Fermi 更新的成对比较规则。\n\n您的程序应生成单行输出，其中包含五个案例的固定概率，格式为一个逗号分隔的小数列表，四舍五入到三位小数并用方括号括起来，例如 $[x_1,x_2,x_3,x_4,x_5]$，其中每个 $x_k$ 对应于上述顺序中第 $k$ 个测试用例的固定概率。不涉及物理单位或角度。所有最终答案必须是小数（而不是分数或百分比）。",
            "solution": "用户要求计算在方格网络上的空间囚徒困境中合作的固定概率。这需要对一个基于智能体的模型进行随机模拟。以下解决方案详细说明了其理论基础、算法设计以及预期结果的科学原理。\n\n### 1. 问题验证\n问题陈述是**有效的**。\n\n- **已知条件提取**：\n    - **网络**：$N \\times N$ 方格网络，$N=20$，具有反射边界。\n    - **策略**：合作（$C$）和背叛（$D$）。\n    - **博弈**：捐赠博弈，收益 $b=1.0$，成本 $c \\in \\{0.25, 0.30\\}$。\n    - **收益函数**：$\\pi_i = b \\, n_i^C - c \\, d_i \\, \\mathbf{1}\\{s_i = C\\}$，其中 $i$ 是智能体，$s_i$ 是其策略，$d_i$ 是其度，$n_i^C$ 是其合作邻居的数量，$\\mathbf{1}\\{\\cdot\\}$ 是指示函数。\n    - **动态过程**：离散时间步。在每一步，随机均匀地选择一条边 $(i,j)$，然后随机选择更新方向（$i \\leftarrow j$ 或 $j \\leftarrow i$）。策略采纳概率由 Fermi 成对比较规则给出：$p_{i \\leftarrow j} = \\frac{1}{1 + \\exp\\left(-\\beta \\left(\\pi_j - \\pi_i \\right)\\right)}$。\n    - **选择强度**：$\\beta \\in \\{0.0, 1.0, 2.0\\}$。\n    - **初始条件**：一个边长为 $s \\in \\{1, 4\\}$ 的连续方形合作者集群，嵌入在一片背叛者之中。\n    - **布局**：“角落”（集群位于 $(0,0)$）和“中心”（集群在网络上居中）。\n    - **终止条件**：模拟在达到全 $C$ 或全 $D$ 吸收态时结束，或在 $H=10000$ 步的时限后结束。\n    - **输出**：针对五个指定的测试用例，计算合作的固定概率（在时限 $H$ 内结束于全 $C$ 状态的运行比例），四舍五入到三位小数。\n    - **测试用例**：\n        - A: $N=20, s=4$, 角落, $c=0.25, \\beta=1.0, R=80$.\n        - B: $N=20, s=4$, 中心, $c=0.25, \\beta=1.0, R=80$.\n        - C: $N=20, s=1$, 角落, $c=0.30, \\beta=2.0, R=120$.\n        - D: $N=20, s=1$, 中心, $c=0.30, \\beta=2.0, R=120$.\n        - E: $N=20, s=4$, 中心, $c=0.25, \\beta=0.0, R=80$.\n\n- **验证结论**：该问题具有科学依据、良定且客观。它描述了演化博弈论和复杂系统领域的一个标准模型。所有参数、规则和条件都已明确定义，为蒙特卡洛模拟构成了一个自洽且一致的规范。因此，该问题是有效的。\n\n### 2. 理论框架与解决方案设计\n\n#### 2.1. 模型规范\n该系统是一个位于二维方格网络上的 $N \\times N = 400$ 个智能体的种群。该网络具有反射（非周期性）边界，意味着位于边缘和角落的智能体比位于内部的智能体邻居更少。\n- 一个智能体的度 $d_i$ 对于内部顶点是 $4$，对于边缘顶点（非角落）是 $3$，对于角落顶点是 $2$。\n- 策略是二元的：合作者（$C$，表示为 $1$）和背叛者（$D$，表示为 $0$）。\n- 智能体 $i$ 的收益 $\\pi_i$ 取决于其自身策略及其直接邻居的策略。合作者为其拥有的每个邻居支付成本 $c$（总成本为 $c \\cdot d_i$），并为每个邻居提供收益 $b$。背叛者不支付成本也不提供收益。因此，收益按指定方式计算：$\\pi_i = b \\cdot n_i^C - c \\cdot d_i \\cdot s_i$，其中如果智能体 $i$ 是合作者，则 $s_i=1$，如果是背叛者，则 $s_i=0$。\n\n#### 2.2. 演化动态过程\n模拟以离散时间步进行，实现一个异步更新规则。在每一步：\n1.  从网络上的所有边中，随机均匀地选择一条连接两个相邻智能体的无向边 $(i, j)$。\n2.  随机选择其中一个智能体，比如 $i$，作为“焦点”智能体，另一个 $j$ 作为“模型”智能体。\n3.  根据网络上当前的策略配置，计算焦点智能体 $i$ 和模型智能体 $j$ 的瞬时收益 $\\pi_i$ 和 $\\pi_j$。\n4.  焦点智能体 $i$ 以 Fermi 概率 $p_{i \\leftarrow j}$ 采纳模型智能体 $j$ 的策略。该概率随着模型收益优势 $\\pi_j - \\pi_i$ 的增加而增加。选择强度 $\\beta$ 控制着对该收益差异的敏感度。\n    - 如果 $\\beta > 0$，收益更高的策略更有可能被模仿。\n    - 如果 $\\beta = 0$，概率变为 $p = 1/2$，意味着模仿是随机的，与收益无关（中性漂移）。\n    - 如果 $\\beta \\to \\infty$，更新变为确定性的：焦点智能体当且仅当 $\\pi_j > \\pi_i$ 时采纳模型的策略。\n\n#### 2.3. 边界对合作影响的原理\n核心的科学问题是，为什么合作者集群的初始布局（角落 vs. 中心）会影响其固定概率。主要机制是由网络边界引入的空间异质性所起的作用。\n\n1.  **边界处的成本降低**：位于网络定义的边界和角落的智能体邻居更少（$d_i  4$）。对于一个合作者，合作的总成本是 $c \\cdot d_i$。因此，位于这些低度位点的合作者支付的成本比网络内部的合作者要小。这给了它们更高的内在收益，使它们对背叛者的入侵更具抵抗力。一个锚定在角落的合作者集群可以利用这些“廉价”位点作为坚固的防守阵地。\n\n2.  **有利的界面几何形状**：一个策略集群的生存和扩张取决于其与对立策略交界处的动态。集群布局的几何形状改变了这一界面。一个边长为 $s$ 的方形集群面积为 $s^2$。\n    - **中心布局**：集群被背叛者包围，形成一个长度约为 $4s$ 的界面。表面（易受攻击的）智能体与核心（受保护的）智能体的比例相对较高。\n    - **角落布局**：集群受网络自身两条边的限制，仅将两面暴露给背叛者之海。界面长度约为 $2s$。这种配置的表面积与体积（或界面与面积）之比要低得多。一小部分合作者与背叛者直接竞争，而一个较大的合作者“核心”为界面上的合作者提供了稳定的收益基础。\n\n综合来看，这些效应预测，与从中心布局开始相比，从角落布局开始的合作更有可能存活并固定下来。本模拟旨在检验和量化这一已被充分证实的理论结果。\n\n#### 2.4. 算法实现\n通过实现一个蒙特卡洛模拟来估计固定概率。对于每个测试用例，执行指定数量（$R$）的独立运行。\n\n1.  **初始化**：对于每次运行，一个 $N \\times N$ 的 `numpy` 数组代表网络。它被初始化为背叛者（$0$），并根据“角落”或“中心”的规范放置一个方形的合作者集群（$1$）。为了提高效率，每个位点的度以及所有边的列表等静态属性被预先计算。\n\n2.  **模拟循环**：单次运行最多演化 $H=10000$ 步。\n    - 在每一步中，随机选择一条边和一个更新方向。\n    - 根据两个交互智能体的局部邻域计算它们的收益。\n    - 计算 Fermi 概率，并抽取一个随机数来决定是否发生策略更新。\n    - 如果系统达到吸收态（全 $C$ 或全 $D$），循环将提前终止。\n\n3.  **结果聚合**：如果一次运行以全 $C$ 状态结束（无论是通过固定还是在时限 $H$ 到达时），则计为一次成功（$1$）。否则，为失败（$0$）。给定测试用例的固定概率是所有 $R$ 次运行这些结果的平均值。\n\n4.  **基线案例（中性漂移）**：$\\beta=0$ 的案例 E 是一个关键的基线。在中性漂移下，一种策略的固定概率等于其初始频率。对于 $N=20$ 的网络上的 $s=4$ 集群，合作者的初始频率为 $s^2/N^2 = 16/400 = 0.04$。案例 E 的模拟结果应与此理论值在统计上一致，从而验证程序的核心随机框架。",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Computes the fixation probability of cooperation for five test cases of a spatial\n    Prisoner's Dilemma on a 2D lattice.\n    \"\"\"\n\n    test_cases = [\n        # Case A: corner, typical selection\n        {'N': 20, 's': 4, 'placement': 'corner', 'b': 1.0, 'c': 0.25, 'beta': 1.0, 'H': 10000, 'R': 80},\n        # Case B: center, typical selection\n        {'N': 20, 's': 4, 'placement': 'center', 'b': 1.0, 'c': 0.25, 'beta': 1.0, 'H': 10000, 'R': 80},\n        # Case C: corner, single seed, strong selection\n        {'N': 20, 's': 1, 'placement': 'corner', 'b': 1.0, 'c': 0.30, 'beta': 2.0, 'H': 10000, 'R': 120},\n        # Case D: center, single seed, strong selection\n        {'N': 20, 's': 1, 'placement': 'center', 'b': 1.0, 'c': 0.30, 'beta': 2.0, 'H': 10000, 'R': 120},\n        # Case E: center, neutral drift baseline\n        {'N': 20, 's': 4, 'placement': 'center', 'b': 1.0, 'c': 0.25, 'beta': 0.0, 'H': 10000, 'R': 80},\n    ]\n\n    def _precompute_lattice_properties(N):\n        \"\"\"Pre-computes degrees and edge list for the NxN lattice.\"\"\"\n        degrees = np.full((N, N), 4, dtype=int)\n        degrees[0, :] -= 1\n        degrees[N - 1, :] -= 1\n        degrees[:, 0] -= 1\n        degrees[:, N - 1] -= 1\n\n        edges = []\n        for r in range(N):\n            for c in range(N):\n                if r + 1  N:\n                    edges.append(((r, c), (r + 1, c)))\n                if c + 1  N:\n                    edges.append(((r, c), (r, c + 1)))\n        return degrees, edges\n\n    def _initialize_grid(N, s, placement):\n        \"\"\"Initializes the grid with a cluster of cooperators.\"\"\"\n        grid = np.zeros((N, N), dtype=int)\n        if s > 0:\n            if placement == 'corner':\n                start_row, start_col = 0, 0\n            else:  # center\n                start_row = (N - s) // 2\n                start_col = (N - s) // 2\n            \n            grid[start_row:start_row + s, start_col:start_col + s] = 1\n        return grid\n\n    def _calculate_payoff(coords, grid, b, c, degrees, N):\n        \"\"\"Calculates the payoff for a single agent.\"\"\"\n        r, col = coords\n        \n        n_C = 0\n        # Check neighbors\n        if r > 0 and grid[r - 1, col] == 1: n_C += 1\n        if r  N - 1 and grid[r + 1, col] == 1: n_C += 1\n        if col > 0 and grid[r, col - 1] == 1: n_C += 1\n        if col  N - 1 and grid[r, col + 1] == 1: n_C += 1\n            \n        payoff = b * n_C\n        \n        if grid[r, col] == 1:  # If agent is a cooperator\n            payoff -= c * degrees[r, col]\n            \n        return payoff\n\n    def run_simulation(params, degrees, edges, rng):\n        \"\"\"Runs a single simulation and returns 1 if cooperation fixates, 0 otherwise.\"\"\"\n        N, s, placement, b, c, beta, H = \\\n            params['N'], params['s'], params['placement'], params['b'], params['c'], params['beta'], params['H']\n        \n        grid = _initialize_grid(N, s, placement)\n        num_edges = len(edges)\n        \n        for _ in range(H):\n            num_cooperators = np.sum(grid)\n            if num_cooperators == N * N:\n                return 1\n            if num_cooperators == 0:\n                return 0\n\n            edge_idx = rng.integers(num_edges)\n            i_coords, j_coords = edges[edge_idx]\n            \n            if rng.random()  0.5:\n                focal_coords, model_coords = i_coords, j_coords\n            else:\n                focal_coords, model_coords = j_coords, i_coords\n            \n            focal_strategy = grid[focal_coords]\n            model_strategy = grid[model_coords]\n\n            if focal_strategy == model_strategy:\n                continue\n\n            pi_focal = _calculate_payoff(focal_coords, grid, b, c, degrees, N)\n            pi_model = _calculate_payoff(model_coords, grid, b, c, degrees, N)\n\n            delta_pi = pi_model - pi_focal\n            \n            prob = 1.0 / (1.0 + np.exp(-beta * delta_pi))\n            \n            if rng.random()  prob:\n                grid[focal_coords] = model_strategy\n\n        # Check state at horizon\n        return 1 if np.sum(grid) == N * N else 0\n\n    results = []\n    # Pre-compute for the only N value\n    degrees, edges = _precompute_lattice_properties(20)\n    rng = np.random.default_rng()\n\n    for case in test_cases:\n        R = case['R']\n        fixation_count = 0\n        for _ in range(R):\n            fixation_count += run_simulation(case, degrees, edges, rng)\n        \n        fixation_prob = fixation_count / R\n        results.append(f\"{fixation_prob:.3f}\")\n\n    print(f\"[{','.join(results)}]\")\n\nsolve()\n```"
        }
    ]
}