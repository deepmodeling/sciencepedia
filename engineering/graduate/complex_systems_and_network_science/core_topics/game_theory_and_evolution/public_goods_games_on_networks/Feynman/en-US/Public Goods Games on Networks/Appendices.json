{
    "hands_on_practices": [
        {
            "introduction": "The first step in analyzing any game is to define the payoffs with precision. In networked public goods games, this requires careful accounting of costs and benefits aggregated from multiple, overlapping groups. This exercise challenges you to construct a payoff function from a description of a novel cost-sharing mechanism and resolve a potential mathematical singularity by reasoning from the game's physical interpretation .",
            "id": "4298946",
            "problem": "Consider a networked public goods game on an undirected simple graph with $4$ players labeled $1,2,3,4$ arranged on a path: there is an edge between $1$ and $2$, between $2$ and $3$, and between $3$ and $4$. The group structure follows the standard affiliation rule: for each node $j$, the group $G_j$ consists of node $j$ together with all its immediate neighbors. Hence $G_1=\\{1,2\\}$, $G_2=\\{1,2,3\\}$, $G_3=\\{2,3,4\\}$, and $G_4=\\{3,4\\}$. Let $g_j=|G_j|$ denote the size of group $G_j$.\n\nEach player $i$ chooses a nonnegative contribution $a_i\\in \\mathbb{R}_{\\ge 0}$. The total contribution in group $G_j$ is $S_j=\\sum_{\\ell\\in G_j} a_\\ell$. Each player who is a member of $G_j$ receives a per-group benefit equal to the enhanced public good $\\displaystyle r\\,S_j$ shared equally among the $g_j$ group members. The project-level cost is accounted at the group level and is shared only among group members who contribute, proportional to their contribution shares within the group. Specifically, a player $i\\in G_j$ pays a cost share proportional to $a_i$ and inversely proportional to the total realized contribution $S_j$. The parameters satisfy $r0$ and $c0$.\n\nStarting from the core definitions of the public goods game on networks and the above accounting rule, derive a mathematically well-defined analytic expression for the individual payoff $\\Pi_i$ that resolves the division-by-zero singularity that occurs when $S_j=0$ (that is, when no one contributes in group $G_j$). Your derivation must construct $\\Pi_i$ by first principles and explicitly handle the $S_j=0$ case using a clear convention or limiting procedure that is consistent with the game’s physical interpretation.\n\nThen, for the specific parameter values $r=3$ and $c=1$ and the contribution profile $(a_1,a_2,a_3,a_4)=(0,0,2,0)$ on the given path graph, compute the payoff of player $i=2$ using your derived expression. Provide your final answer as a single real number. No rounding is required.",
            "solution": "The problem requires two main tasks: first, to derive a well-defined analytic expression for the individual payoff $\\Pi_i$ in a networked public goods game, explicitly resolving a potential singularity; and second, to compute the payoff for a specific player under given conditions.\n\n**Part 1: Derivation of the Payoff Function $\\Pi_i$**\n\nThe total payoff for a player $i$, denoted $\\Pi_i$, is the sum of benefits they receive from participating in various group projects, minus the total cost they incur.\n\n**1. Benefit Calculation**\nA player $i$ is a member of any group $G_j$ where $j$ is either player $i$ itself or one of its immediate neighbors. The set of indices of groups player $i$ belongs to is $\\{j \\mid i \\in G_j\\}$.\nFor each such group $G_j$, the total contribution is $S_j = \\sum_{\\ell \\in G_j} a_\\ell$, where $a_\\ell \\ge 0$ is the contribution of player $\\ell$. The total value of the public good created in group $G_j$ is given as $r S_j$. This total benefit is shared equally among the $g_j = |G_j|$ members of the group.\n\nThe benefit that player $i$ receives from group $G_j$ is therefore:\n$$B_{ij} = \\frac{r S_j}{g_j}$$\nThe total benefit for player $i$, $B_i$, is the sum of benefits received from all groups they are a member of:\n$$B_i = \\sum_{j: i \\in G_j} B_{ij} = \\sum_{j: i \\in G_j} \\frac{r S_j}{g_j}$$\n\n**2. Cost Calculation and Singularity Resolution**\nThe problem specifies a cost structure that is accounted for at the group level. The key phrases are: \"cost is... shared only among group members who contribute\" and \"a player $i\\in G_j$ pays a cost share proportional to $a_i$ and inversely proportional to the total realized contribution $S_j$\".\n\nLet $C_{\\text{total}, j}$ be the total cost of the project for group $G_j$. Standard models often assume this cost is linear in the total contribution, so we posit $C_{\\text{total}, j} = c S_j$, where $c  0$ is the cost parameter.\n\nThe cost for player $i$ from group $G_j$, denoted $C_{ij}$, is their share of this total cost. The share, $\\text{sh}_i(j)$, is for contributors only and is proportional to their individual contribution $a_i$. The standard formulation for this share is $\\text{sh}_i(j) = \\frac{a_i}{\\sum_{k \\in G_j \\text{ and } a_k0} a_k}$. If at least one player contributes, the denominator is simply $S_j$.\nSo, $\\text{sh}_i(j) = \\frac{a_i}{S_j}$. This expression is indeed proportional to $a_i$ and inversely proportional to $S_j$.\n\nCombining these, the cost for player $i$ from group $G_j$ is:\n$$C_{ij} = \\text{sh}_i(j) \\cdot C_{\\text{total}, j} = \\left(\\frac{a_i}{S_j}\\right) (c S_j)$$\nThis expression presents a potential division-by-zero singularity if $S_j = 0$. The problem requires resolving this.\n\n*   **Case 1: $S_j  0$.**\n    In this case, we can algebraically simplify the expression by canceling the $S_j$ terms:\n    $$C_{ij} = c a_i$$\n*   **Case 2: $S_j = 0$.**\n    Since all contributions are non-negative ($a_\\ell \\ge 0$), $S_j = \\sum_{\\ell \\in G_j} a_\\ell = 0$ implies that $a_\\ell = 0$ for all players $\\ell$ in group $G_j$. In particular, for a player $i \\in G_j$, their contribution $a_i$ must be $0$.\n    From a physical standpoint, if no one contributes, no project happens, and thus the cost of the project is zero ($C_{\\text{total}, j}=c S_j = 0$). As player $i$ contributed nothing, their share of a zero cost must also be zero. We thus establish the convention that $C_{ij} = 0$ if $S_j = 0$.\n\nThe formula $C_{ij} = c a_i$ derived for $S_j  0$ also yields the correct result for the $S_j=0$ case. If $S_j=0$, then $a_i=0$ for $i \\in G_j$, and $C_{ij} = c \\cdot 0 = 0$. Thus, the expression $C_{ij} = c a_i$ is the well-defined cost for player $i$ from being in group $G_j$. It is valid for all non-negative contributions and elegantly resolves the apparent singularity.\n\nThe total cost for player $i$, $C_i$, is the sum of costs from each group they belong to:\n$$C_i = \\sum_{j: i \\in G_j} C_{ij} = \\sum_{j: i \\in G_j} c a_i$$\nThe set of groups player $i$ belongs to is $\\{G_j \\mid j=i \\text{ or } j \\text{ is a neighbor of } i\\}$. The size of this set is $1 + \\deg(i)$, where $\\deg(i)$ is the number of neighbors of player $i$. Thus, the total cost can be written as:\n$$C_i = c a_i (1 + \\deg(i))$$\n\n**3. Final Payoff Expression**\nCombining the total benefits and total costs, the payoff for player $i$ is:\n$$\\Pi_i = B_i - C_i = \\left( \\sum_{j: i \\in G_j} \\frac{r S_j}{g_j} \\right) - c a_i (1 + \\deg(i))$$\nThis is the derived, well-defined analytic expression for the individual payoff.\n\n**Part 2: Calculation of $\\Pi_2$**\n\nWe are asked to compute the payoff for player $i=2$ given the parameters $r=3$, $c=1$, and the contribution profile $(a_1, a_2, a_3, a_4)=(0, 0, 2, 0)$.\n\n**1. Player 2's Groups and Network Properties**\nThe graph is a path $1-2-3-4$. Player $2$ has neighbors $1$ and $3$, so $\\deg(2)=2$. Player $2$ belongs to the groups centered at itself and its neighbors: $G_1$, $G_2$, and $G_3$.\nThe groups and their sizes are:\n*   $G_1 = \\{1, 2\\}$, so $g_1 = 2$.\n*   $G_2 = \\{1, 2, 3\\}$, so $g_2 = 3$.\n*   $G_3 = \\{2, 3, 4\\}$, so $g_3 = 3$.\n\n**2. Group Contributions ($S_j$)**\nWith contributions $(a_1, a_2, a_3, a_4) = (0, 0, 2, 0)$:\n*   $S_1 = a_1 + a_2 = 0 + 0 = 0$.\n*   $S_2 = a_1 + a_2 + a_3 = 0 + 0 + 2 = 2$.\n*   $S_3 = a_2 + a_3 + a_4 = 0 + 2 + 0 = 2$.\n\n**3. Player 2's Total Benefit ($B_2$)**\nPlayer $2$'s total benefit is the sum of benefits from groups $G_1, G_2, G_3$:\n$$B_2 = \\frac{r S_1}{g_1} + \\frac{r S_2}{g_2} + \\frac{r S_3}{g_3}$$\nSubstituting the values ($r=3$):\n$$B_2 = \\frac{3 \\cdot 0}{2} + \\frac{3 \\cdot 2}{3} + \\frac{3 \\cdot 2}{3} = 0 + 2 + 2 = 4$$\n\n**4. Player 2's Total Cost ($C_2$)**\nPlayer $2$'s total cost is given by $C_2 = c a_2 (1 + \\deg(2))$.\nWith $c=1$, $a_2=0$, and $\\deg(2)=2$:\n$$C_2 = 1 \\cdot 0 \\cdot (1 + 2) = 0$$\n\n**5. Player 2's Final Payoff ($\\Pi_2$)**\nThe final payoff for player $2$ is the total benefit minus the total cost:\n$$\\Pi_2 = B_2 - C_2 = 4 - 0 = 4$$",
            "answer": "$$\\boxed{4}$$"
        },
        {
            "introduction": "While defection is often the individually rational choice, mechanisms like peer punishment can stabilize cooperation. However, these mechanisms introduce their own complexities, such as the \"second-order free-rider\" problem, where individuals cooperate but shirk the costly duty of punishing defectors. This practice guides you through an analysis of this phenomenon, requiring you to determine the conditions under which punishment can be a sustainable strategy in a population .",
            "id": "4298947",
            "problem": "Consider a large population of agents situated on a $k$-regular network, where each node has degree $k$ and interacts in a Public Goods Game (PGG) in groups of size $G = k + 1$ consisting of a focal node and its neighbors. Each agent participates in exactly $G$ such groups (one centered at itself and one centered at each neighbor). In each group, every cooperator contributes $c  0$ to a common pool, while defectors contribute $0$. The total contribution is multiplied by a synergy factor $r \\in (1, G)$ and divided equally among all $G$ group members.\n\nThere are three strategies: punishers $P$ (who cooperate and punish defectors), second-order free-riding cooperators $C$ (who cooperate but do not punish), and defectors $D$ (who neither cooperate nor punish). After the PGG stage in each group, peer punishment is implemented as follows. Each $P$ in the group punishes each $D$ in the group by imposing a fine $\\beta  0$ on that $D$ and paying a personal cost $\\gamma  0$ per punished defector. An institutional redistribution mechanism allocates a fraction $\\phi \\in [0,1]$ of the total fines collected in the group equally among the punishers in that group as a punisher-specific dividend, while the remaining fraction $(1 - \\phi)$ is dissipated (not returned to any group member). There is no redistribution of fines to non-punishing cooperators $C$.\n\nAssume an infinitely large population, weak selection, and the rare-defector regime where the global fraction of defectors is $d \\to 0$, so that typical groups contain at most a small number of defectors with probability proportional to $d$. Under these assumptions, compare the expected payoffs of a focal $P$ versus a focal $C$ facing the same configuration of the other $G - 1$ group members, and derive the condition under which $P$ is second-order dominated by $C$ (that is, $C$ attains a strictly higher expected payoff than $P$ to first order in $d$). Then, compute the minimal threshold value of the ratio $\\beta/\\gamma$ that exactly eliminates second-order dominance in this limit, expressed as a closed-form function of $\\phi$ only. Provide this threshold ratio as your final answer. No rounding is required and no units are involved. Clearly state any auxiliary assumptions you make that are consistent with the setup above, and justify each step of your derivation from first principles of public goods interactions and punishment accounting. Do not use any formulas that are not derived from these principles within your solution. Your final answer must be a single closed-form analytic expression for the threshold ratio $\\beta/\\gamma$.",
            "solution": "The problem requires the derivation of the minimal threshold for the ratio of punishment fine to cost, $\\beta/\\gamma$, that prevents second-order free-riding cooperators ($C$) from having a higher expected payoff than punishers ($P$). This condition, termed the elimination of second-order dominance, is to be determined in the limit of a rare defector population ($d \\to 0$).\n\nLet $\\Pi_P$ and $\\Pi_C$ denote the total expected payoffs for a focal punisher and a focal non-punishing cooperator, respectively. Both strategies, $P$ and $C$, are cooperators, meaning they contribute an amount $c$ to the public good in every Public Goods Game (PGG) they participate in. A focal agent is situated on a $k$-regular network and participates in $G = k+1$ games: one centered on itself and one centered on each of its $k$ neighbors.\n\nThe payoff for any agent in a single PGG group can be decomposed into two parts: the payoff from the PGG itself and the payoff (or cost) from the punishment stage.\nFor a group of size $G$ with $n_P$ punishers, $n_C$ cooperators, and $n_D$ defectors, where $n_P + n_C + n_D = G$, the total contribution to the public good is $(n_P + n_C)c$. This amount is multiplied by the synergy factor $r$ and distributed equally among all $G$ members. The PGG payoff for any cooperator (either $P$ or $C$) in this group is:\n$$ \\pi_{\\text{PGG}} = \\frac{r(n_P + n_C)c}{G} - c $$\nSince we are comparing a focal $P$ with a focal $C$ under the same conditions (i.e., in the same network location with the same neighbors), the composition of any group they participate in is identical, except for the focal agent's own strategy. However, since both $P$ and $C$ contribute $c$, their PGG payoff component is identical in every group. Therefore, the difference in their total expected payoffs, $\\Pi_P - \\Pi_C$, arises exclusively from the costs and rewards associated with punishment. A non-punishing cooperator $C$ neither pays costs to punish nor receives any reward from collected fines. Thus, its net payoff from punishment is always $0$.\nThe payoff difference is then the total expected net payoff for a punisher from the punishment mechanism:\n$$ \\Pi_P - \\Pi_C = E[\\pi_{P, \\text{punish}}] $$\nLet's analyze the net punishment payoff for a single punisher, $P_i$, in a single group, $g$. Let the group contain $n_D(g)$ defectors and $n_P(g)$ punishers.\nThe cost for $P_i$ to punish is $\\gamma$ for each of the $n_D(g)$ defectors. Total cost for $P_i$ is $n_D(g)\\gamma$.\nThe total value of fines collected in group $g$ is the number of punishers times the number of defectors times the fine per defector, which is $n_P(g)n_D(g)\\beta$.\nA fraction $\\phi$ of these fines is redistributed equally among the $n_P(g)$ punishers. The reward for $P_i$ is:\n$$ \\text{Reward}_i(g) = \\frac{\\phi \\left( n_P(g) n_D(g) \\beta \\right)}{n_P(g)} = \\phi n_D(g) \\beta $$\nThis reward is notably independent of the number of other punishers $n_P(g)$, provided $n_P(g) \\ge 1$.\nThe net punishment payoff for $P_i$ in group $g$ is the reward minus the cost:\n$$ \\pi_{P_i, \\text{punish}}(g) = \\phi n_D(g) \\beta - n_D(g) \\gamma = n_D(g)(\\phi\\beta - \\gamma) $$\nThis expression is valid if $n_D(g)  0$. If $n_D(g) = 0$, the net payoff is $0$.\n\nThe total expected payoff difference is the sum of the expected net punishment payoffs over all $G = k+1$ groups the focal agent participates in. Let the focal agent be at node $i$.\n$$ \\Pi_P - \\Pi_C = \\sum_{g \\in \\mathcal{G}_i} E[\\pi_{P_i, \\text{punish}}(g)] $$\nwhere $\\mathcal{G}_i$ is the set of $G$ groups involving agent $i$. Using the linearity of expectation and the derived net payoff:\n$$ \\Pi_P - \\Pi_C = (\\phi\\beta - \\gamma) \\sum_{g \\in \\mathcal{G}_i} E[n_D(g)] $$\nWe must now calculate the total expected number of defectors a focal agent encounters across all its interactions. We work in the rare defector limit, $d \\to 0$, where $d$ is the global fraction of defectors. We only need to consider terms to first order in $d$. The probability of any given node being a defector is $d$.\n\nThe $G = k+1$ groups are:\n1.  The group centered at the focal agent $i$, let's call it $g_i$. This group consists of agent $i$ and its $k$ neighbors. Since agent $i$ is a punisher, the defectors can only be among its $k$ neighbors. The expected number of defectors in this group is the number of neighbors multiplied by the probability of being a defector:\n    $$ E[n_D(g_i)] = k \\cdot d $$\n2.  The $k$ groups centered at each of the focal agent's neighbors. Let $j$ be a neighbor of $i$. The group $g_j$ is centered at $j$ and consists of $j$ and its $k$ neighbors. Agent $i$ is one of $j$'s neighbors. In the $d \\to 0$ limit, the neighbor $j$ is a non-defector with probability $1-d \\approx 1$. The other members of group $g_j$ are $i$ (who is a $P$) and the other $k-1$ neighbors of $j$. Each of these $k-1$ other neighbors is a defector with an independent probability $d$. The expected number of defectors in group $g_j$ is therefore:\n    $$ E[n_D(g_j)] = (k-1) \\cdot d $$\n    This calculation holds for each of the $k$ groups centered at a neighbor of $i$. The assumption here is that the state of any node is independent of others, which is standard for an infinite population model.\n\nThe total expected number of defectors encountered is the sum over all $G=k+1$ groups:\n$$ \\sum_{g \\in \\mathcal{G}_i} E[n_D(g)] = E[n_D(g_i)] + \\sum_{j \\in \\text{neighbors}(i)} E[n_D(g_j)] = kd + k \\cdot ((k-1)d) $$\n$$ \\sum_{g \\in \\mathcal{G}_i} E[n_D(g)] = kd + (k^2 - k)d = k^2 d $$\n\nSubstituting this back into the expression for the payoff difference:\n$$ \\Pi_P - \\Pi_C = (\\phi\\beta - \\gamma) k^2 d $$\nThis is the payoff difference to the first order in $d$.\n\nSecond-order dominance of $C$ over $P$ means that $C$ has a strictly higher payoff, i.e., $\\Pi_C  \\Pi_P$, which implies $\\Pi_P - \\Pi_C  0$.\n$$ (\\phi\\beta - \\gamma) k^2 d  0 $$\nSince $d  0$ and for any network $k \\ge 1$ (thus $k^2  0$), this inequality simplifies to:\n$$ \\phi\\beta - \\gamma  0 $$\nThe problem asks for the minimal threshold value of $\\beta/\\gamma$ that eliminates this dominance. This occurs when the payoff advantage of $C$ is nullified, meaning $\\Pi_P - \\Pi_C \\ge 0$. The threshold case is the equality:\n$$ \\Pi_P - \\Pi_C = 0 $$\n$$ (\\phi\\beta - \\gamma) k^2 d = 0 $$\nThis requires $\\phi\\beta - \\gamma = 0$.\nSolving for the ratio $\\beta/\\gamma$:\n$$ \\phi\\beta = \\gamma $$\n$$ \\frac{\\beta}{\\gamma} = \\frac{1}{\\phi} $$\nThis threshold is valid for $\\phi \\in (0, 1]$. If $\\phi=0$, the threshold is undefined (infinite), meaning if no fines are redistributed, punishment is always a net cost and the dominance of $C$ cannot be overcome by increasing $\\beta$. The derived expression is a function of $\\phi$ only, as required.",
            "answer": "$$\\boxed{\\frac{1}{\\phi}}$$"
        },
        {
            "introduction": "Understanding the long-term evolutionary trajectory of cooperation requires moving beyond static analysis to dynamic simulation. This computational exercise tasks you with implementing and comparing two common update schemes—synchronous and asynchronous—to see how they affect the speed at which cooperation spreads through a network. By connecting the simulation results to the network's spectral properties, you will gain insight into the deep interplay between dynamics and topology .",
            "id": "4299052",
            "problem": "Consider a networked Public Goods Game (PGG) on a simple, undirected graph with $N$ players, encoded by an $N \\times N$ symmetric adjacency matrix $A$ with entries in $\\{0,1\\}$ and no self-loops. Let each node $i$ hold a mixed strategy $x_i(t) \\in [0,1]$ representing the probability of cooperation at discrete time step $t$. Groups are defined by neighborhoods: for each node $j$, define the group $G_j$ as the set containing node $j$ and all its neighbors. Let $H$ denote the group membership matrix $H = A + I$, where $I$ is the identity matrix; $H_{ij} = 1$ if and only if player $i$ belongs to group $G_j$. Denote the group size by $|G_j| = \\sum_{i=1}^{N} H_{ij}$.\n\nThe benefit in group $G_j$ is modeled by a nonlinear synergy function. Let the expected total cooperative propensity in group $G_j$ at time $t$ be $S_j(t) = \\sum_{i=1}^{N} H_{ij} x_i(t)$. The expected benefit generated by group $G_j$ is $r \\cdot \\left(S_j(t)\\right)^{\\alpha}$, where $r  0$ is the synergy multiplier and $\\alpha  1$ is a nonlinearity exponent producing superlinear returns. Benefits are shared equally among group members, so the expected benefit per member from group $G_j$ is $r \\cdot \\left(S_j(t)\\right)^{\\alpha} / |G_j|$.\n\nEach player has a fixed cooperation endowment $c  0$ that is divided across all of their participation; thus their expected total cooperation cost is $c \\cdot x_i(t)$, regardless of the number of groups they are in. The expected payoff for player $i$ at time $t$ is the sum of benefits received from all groups they belong to minus their cooperation cost.\n\nDefine the synchronous update rule by a discrete-time replicator-like dynamics with step size $\\eta  0$:\n$$\nx_i(t+1) = \\operatorname{clip}\\left(x_i(t) + \\eta \\cdot x_i(t)\\left(1 - x_i(t)\\right) \\cdot \\Delta_i(t), \\, 0, \\, 1 \\right),\n$$\nwhere\n$$\n\\Delta_i(t) = \\sum_{j=1}^{N} H_{ij} \\cdot \\left( \\frac{r \\cdot \\alpha \\cdot \\left(S_j(t)\\right)^{\\alpha - 1}}{|G_j|} \\right) - c,\n$$\nand $\\operatorname{clip}(z,0,1)$ denotes projection of $z$ onto the interval $[0,1]$.\n\nDefine the asynchronous update rule by sequential Gauss-Seidel sweeps. In one macro-step, update nodes $i = 1,2,\\dots,N$ in order; within each micro-update, recompute $S_j$ and use the current $x$ to update only $x_i$ via the same scalar formula:\n$$\nx_i \\leftarrow \\operatorname{clip}\\left(x_i + \\eta \\cdot x_i\\left(1 - x_i\\right) \\cdot \\Delta_i, \\, 0, \\, 1 \\right),\n$$\nwhere at each micro-update $S_j = \\sum_{m=1}^{N} H_{mj} x_m$ and\n$$\n\\Delta_i = \\sum_{j=1}^{N} H_{ij} \\cdot \\left( \\frac{r \\cdot \\alpha \\cdot \\left(S_j\\right)^{\\alpha - 1}}{|G_j|} \\right) - c.\n$$\nOne asynchronous macro-step is defined as a full sweep over all nodes.\n\nDefine the time-to-threshold cooperation as the minimum number of macro-steps $T$ such that the average cooperation\n$$\n\\bar{x}(t) = \\frac{1}{N} \\sum_{i=1}^{N} x_i(t)\n$$\nsatisfies $\\bar{x}(t) \\ge \\theta$, where $\\theta \\in (0,1)$ is a given threshold. If the threshold is not achieved within a prescribed maximum number of macro-steps $T_{\\max}$, report $T = T_{\\max}$.\n\nRelate convergence speeds under synchronous versus asynchronous updates to spectral properties of the network. Let the graph Laplacian be $L = D - A$, where $D$ is the diagonal degree matrix. Compute the adjacency spectral radius $\\rho(A)$, defined as the largest eigenvalue of $A$, and the algebraic connectivity $\\lambda_2(L)$, defined as the second-smallest eigenvalue of $L$.\n\nYour task is to:\n- Implement both update rules exactly as specified.\n- For each test case, starting from the same initial condition $x_i(0) = x_0$ for all $i$, compute the synchronous time-to-threshold $T_{\\mathrm{sync}}$ and the asynchronous time-to-threshold $T_{\\mathrm{async}}$.\n- Compute the ratio $R = T_{\\mathrm{async}} / T_{\\mathrm{sync}}$.\n- Compute $\\rho(A)$ and $\\lambda_2(L)$.\n\nUnits and representation:\n- All quantities are dimensionless and must be represented as real-valued floats or integers.\n- The threshold $\\theta$ must be treated as a decimal fraction in $(0,1)$, not a percentage.\n\nTest Suite:\nUse the following test suite, where adjacency matrices are given explicitly and parameters $(r,\\alpha,c,\\eta,\\theta,T_{\\max},x_0)$ are also provided.\n\n1. Path graph with $N=5$: edges $(0\\text{--}1, 1\\text{--}2, 2\\text{--}3, 3\\text{--}4)$.\n   - Parameters: $r = 1.5$, $\\alpha = 1.2$, $c = 1.0$, $\\eta = 0.08$, $\\theta = 0.8$, $T_{\\max} = 300$, $x_0 = 0.6$.\n\n2. Star graph with $N=6$: node $0$ connected to nodes $1,2,3,4,5$.\n   - Parameters: $r = 1.5$, $\\alpha = 1.2$, $c = 1.0$, $\\eta = 0.08$, $\\theta = 0.8$, $T_{\\max} = 300$, $x_0 = 0.6$.\n\n3. Complete graph with $N=6$: all off-diagonal entries of $A$ are $1$, diagonal entries are $0$.\n   - Parameters: $r = 1.5$, $\\alpha = 1.2$, $c = 1.0$, $\\eta = 0.08$, $\\theta = 0.8$, $T_{\\max} = 200$, $x_0 = 0.6$.\n\n4. Cycle graph with $N=6$: edges $(0\\text{--}1, 1\\text{--}2, 2\\text{--}3, 3\\text{--}4, 4\\text{--}5, 5\\text{--}0)$, near-critical synergy.\n   - Parameters: $r = 1.1$, $\\alpha = 1.05$, $c = 1.0$, $\\eta = 0.08$, $\\theta = 0.8$, $T_{\\max} = 300$, $x_0 = 0.6$.\n\nFinal Output Format:\nYour program should produce a single line of output containing the results for all test cases as a comma-separated list enclosed in square brackets. Each test case result must be a sublist of the form\n$[T_{\\mathrm{sync}}, T_{\\mathrm{async}}, R, \\rho(A), \\lambda_2(L)]$.\nFor example, the output must look like\n$[[t_{1,\\mathrm{sync}}, t_{1,\\mathrm{async}}, r_1, \\rho_1, \\lambda_{2,1}], [t_{2,\\mathrm{sync}}, t_{2,\\mathrm{async}}, r_2, \\rho_2, \\lambda_{2,2}], \\dots]$\nwith numerical values in place of the symbols.",
            "solution": "The problem statement has been meticulously validated and is determined to be sound. It is scientifically grounded in the fields of network science and evolutionary game theory, mathematically well-posed, and provides a complete and consistent set of definitions and parameters for a solvable numerical task. No flaws pertaining to scientific unsoundness, ambiguity, or incompleteness were detected. The model, based on a networked Public Goods Game with nonlinear synergy and replicator-like dynamics, is a standard formulation for studying the evolution of cooperation. The tasks, involving numerical simulation and spectral analysis, are well-defined.\n\nThe solution proceeds by implementing the model and simulation procedures as specified. The core of the problem involves simulating a system of coupled nonlinear difference equations, representing the evolution of cooperation strategies on a network, under two different update schemes: synchronous and asynchronous.\n\nFirst, we formalize the mathematical objects and quantities involved. Let the graph have $N$ nodes.\n- **Adjacency Matrix $A$**: An $N \\times N$ matrix where $A_{ij} = 1$ if nodes $i$ and $j$ are connected, and $A_{ij}=0$ otherwise. For an undirected graph, $A$ is symmetric.\n- **Group Membership Matrix $H$**: Defined as $H = A + I$, where $I$ is the $N \\times N$ identity matrix. $H_{ij}=1$ indicates that player $i$ is a member of the group $G_j$ centered at node $j$.\n- **Group Size $|G_j|$**: The number of members in group $G_j$, calculated as the sum of the $j$-th column of $H$: $|G_j| = \\sum_{i=1}^{N} H_{ij}$. This is equivalent to the degree of node $j$ plus one.\n- **Strategy Vector $x(t)$**: An $N$-dimensional vector where $x_i(t) \\in [0,1]$ is the cooperation probability of player $i$ at time $t$.\n- **Expected Cooperative Propensity $S(t)$**: An $N$-dimensional vector where $S_j(t)$ is the sum of cooperation probabilities in group $G_j$. In matrix form, $S(t) = H^T x(t)$.\n- **Marginal Payoff Gradient $\\Delta(t)$**: An $N$-dimensional vector where $\\Delta_i(t)$ represents the fitness advantage of cooperation over defection for player $i$. It is given by\n$$\n\\Delta_i(t) = \\sum_{j=1}^{N} H_{ij} \\cdot \\left( \\frac{r \\cdot \\alpha \\cdot \\left(S_j(t)\\right)^{\\alpha - 1}}{|G_j|} \\right) - c\n$$\nThis can be computed efficiently using matrix-vector products.\n- **Graph Laplacian $L$**: Defined as $L = D - A$, where $D$ is the diagonal matrix of node degrees. $D_{ii} = \\sum_{j=1}^{N} A_{ij}$.\n- **Spectral Properties**:\n  - The adjacency spectral radius $\\rho(A)$ is the largest eigenvalue of $A$.\n  - The algebraic connectivity $\\lambda_2(L)$ is the second-smallest eigenvalue of the Laplacian $L$.\n\nThe computational procedure for each test case is as follows:\n\n1.  **Graph and Parameter Initialization**: For each test case, the adjacency matrix $A$ is constructed based on the graph description (path, star, complete, cycle). The parameters $(r, \\alpha, c, \\eta, \\theta, T_{\\max}, x_0)$ are set. From $A$, we compute $N$, $D$, $L$, $H$, and a vector of the group sizes $|G_j|$.\n\n2.  **Spectral Analysis**: We compute the eigenvalues of the symmetric matrices $A$ and $L$ using a numerical linear algebra library. Since the eigenvalues will be sorted, $\\rho(A)$ is the last eigenvalue of $A$, and $\\lambda_2(L)$ is the second eigenvalue of $L$ (the first being $0$ for connected graphs).\n\n3.  **Synchronous Simulation ($T_{\\mathrm{sync}}$)**:\n    - Initialize the strategy vector $x(0)$ with all entries equal to $x_0$.\n    - Iterate for time steps $t = 0, 1, \\dots, T_{\\max}-1$.\n    - At the beginning of each step, calculate the average cooperation $\\bar{x}(t) = \\frac{1}{N}\\sum_i x_i(t)$. If $\\bar{x}(t) \\ge \\theta$, the simulation terminates, and $T_{\\mathrm{sync}} = t$.\n    - If the condition is not met, compute the next state $x(t+1)$ for all players simultaneously (a parallel update).\n      a. Compute the propensity vector $S(t) = H^T x(t)$.\n      b. Compute an intermediate vector `term_vec` where the $j$-th component is $\\frac{r \\cdot \\alpha \\cdot (S_j(t))^{\\alpha - 1}}{|G_j|}$.\n      c. Compute the gradient vector $\\Delta(t) = H \\cdot \\text{term\\_vec} - c$.\n      d. Apply the update rule: $x_{\\text{new}} = x(t) + \\eta \\cdot x(t) \\odot (1 - x(t)) \\odot \\Delta(t)$, where $\\odot$ denotes element-wise multiplication.\n      e. Project strategies back into the valid range: $x(t+1) = \\operatorname{clip}(x_{\\text{new}}, 0, 1)$.\n    - If the loop completes without meeting the threshold, set $T_{\\mathrm{sync}} = T_{\\max}$.\n\n4.  **Asynchronous Simulation ($T_{\\mathrm{async}}$)**:\n    - Initialize the strategy vector $x$ as before.\n    - Iterate for macro-steps $t = 0, 1, \\dots, T_{\\max}-1$.\n    - At the start of each macro-step, check the threshold condition $\\bar{x} \\ge \\theta$. If met, terminate with $T_{\\mathrm{async}} = t$.\n    - If not, perform a sequential sweep over all players $i = 1, \\dots, N$. For each player $i$:\n      a. Recompute the propensity vector $S = H^T x$ using the most up-to-date strategy vector $x$ (which includes updates from players $1, \\dots, i-1$ in the current sweep).\n      b. Recompute `term_vec` as in the synchronous case.\n      c. Calculate the specific gradient component $\\Delta_i = (\\text{row } i \\text{ of } H) \\cdot \\text{term\\_vec} - c$.\n      d. Update only the strategy for player $i$: $x_{i, \\text{new}} = x_i + \\eta \\cdot x_i(1-x_i)\\Delta_i$.\n      e. Apply the clip and update $x_i$ in place: $x_i = \\operatorname{clip}(x_{i, \\text{new}}, 0, 1)$.\n    - If the loop completes, set $T_{\\mathrm{async}} = T_{\\max}$.\n\n5.  **Result Aggregation**: After obtaining $T_{\\mathrm{sync}}$ and $T_{\\mathrm{async}}$, the ratio $R = T_{\\mathrm{async}} / T_{\\mathrm{sync}}$ is calculated. The final result for the test case is compiled into the list $[T_{\\mathrm{sync}}, T_{\\mathrm{async}}, R, \\rho(A), \\lambda_2(L)]$. This process is repeated for all test cases, and the results are formatted into a single output string as required.",
            "answer": "```python\nimport numpy as np\n\ndef run_case(graph_def, params):\n    \"\"\"\n    Runs a single test case for the networked Public Goods Game.\n    \"\"\"\n    r, alpha, c, eta, theta, T_max, x_0 = params\n    \n    # 1. Graph and Parameter Initialization\n    if graph_def['type'] == 'path':\n        N = graph_def['N']\n        A = np.zeros((N, N), dtype=float)\n        for i in range(N - 1):\n            A[i, i + 1] = 1\n            A[i + 1, i] = 1\n    elif graph_def['type'] == 'star':\n        N = graph_def['N']\n        A = np.zeros((N, N), dtype=float)\n        center = 0\n        for i in range(1, N):\n            A[center, i] = 1\n            A[i, center] = 1\n    elif graph_def['type'] == 'complete':\n        N = graph_def['N']\n        A = np.ones((N, N), dtype=float)\n        np.fill_diagonal(A, 0)\n    elif graph_def['type'] == 'cycle':\n        N = graph_def['N']\n        A = np.zeros((N, N), dtype=float)\n        for i in range(N - 1):\n            A[i, i + 1] = 1\n            A[i + 1, i] = 1\n        A[N - 1, 0] = 1\n        A[0, N - 1] = 1\n    else:\n        raise ValueError(\"Unknown graph type\")\n\n    N = A.shape[0]\n    H = A + np.identity(N)\n    degrees = A.sum(axis=1)\n    D = np.diag(degrees)\n    L = D - A\n    group_sizes = H.sum(axis=0)\n\n    # 2. Spectral Analysis\n    # A and L are real symmetric matrices, use eigvalsh for efficiency\n    eigvals_A = np.linalg.eigvalsh(A)\n    rho_A = eigvals_A[-1]\n    \n    eigvals_L = np.linalg.eigvalsh(L)\n    # Handle floating point inaccuracies for the smallest eigenvalue\n    lambda2_L = eigvals_L[1] if eigvals_L.size  1 else np.nan\n\n    # 3. Synchronous Simulation\n    x_sync = np.full(N, x_0, dtype=float)\n    T_sync = T_max\n    for t in range(T_max):\n        if np.mean(x_sync) = theta:\n            T_sync = t\n            break\n        \n        S = H.T @ x_sync\n        \n        # To avoid division by zero or NaN for S_j=0 when alpha-1  0\n        S_pow = np.power(S, alpha - 1, where=S0, out=np.zeros_like(S))\n\n        term_vec = (r * alpha * S_pow) / group_sizes\n        Delta = H @ term_vec - c\n        \n        x_sync_new = x_sync + eta * x_sync * (1 - x_sync) * Delta\n        x_sync = np.clip(x_sync_new, 0, 1)\n\n    # 4. Asynchronous Simulation\n    x_async = np.full(N, x_0, dtype=float)\n    T_async = T_max\n    for t in range(T_max):\n        if np.mean(x_async) = theta:\n            T_async = t\n            break\n        \n        # Gauss-Seidel sweep\n        for i in range(N):\n            S = H.T @ x_async\n            \n            S_pow = np.power(S, alpha - 1, where=S0, out=np.zeros_like(S))\n\n            term_vec = (r * alpha * S_pow) / group_sizes\n            delta_i = H[i, :] @ term_vec - c\n            \n            x_i_new = x_async[i] + eta * x_async[i] * (1 - x_async[i]) * delta_i\n            x_async[i] = np.clip(x_i_new, 0, 1)\n            \n    # 5. Result Aggregation\n    R = T_async / T_sync if T_sync != 0 else float('inf')\n    \n    return [T_sync, T_async, R, rho_A, lambda2_L]\n\ndef solve():\n    test_cases = [\n        # Case 1: Path graph\n        (\n            {'type': 'path', 'N': 5},\n            (1.5, 1.2, 1.0, 0.08, 0.8, 300, 0.6)\n        ),\n        # Case 2: Star graph\n        (\n            {'type': 'star', 'N': 6},\n            (1.5, 1.2, 1.0, 0.08, 0.8, 300, 0.6)\n        ),\n        # Case 3: Complete graph\n        (\n            {'type': 'complete', 'N': 6},\n            (1.5, 1.2, 1.0, 0.08, 0.8, 200, 0.6)\n        ),\n        # Case 4: Cycle graph\n        (\n            {'type': 'cycle', 'N': 6},\n            (1.1, 1.05, 1.0, 0.08, 0.8, 300, 0.6)\n        )\n    ]\n    \n    results = []\n    for graph_def, params in test_cases:\n        result = run_case(graph_def, params)\n        results.append(result)\n\n    # Format the final output string exactly as specified\n    formatted_sublists = []\n    for res in results:\n        # Use repr to get high-precision string representations of floats\n        # then join them without spaces.\n        formatted_sublists.append(f\"[{','.join(map(repr, res))}]\")\n    \n    final_output = f\"[{','.join(formatted_sublists)}]\"\n    print(final_output)\n\nsolve()\n```"
        }
    ]
}