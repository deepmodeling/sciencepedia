{
    "hands_on_practices": [
        {
            "introduction": "The Hegselmann-Krause (HK) model is a cornerstone of opinion dynamics, illustrating how global clustering can emerge from a simple rule of local interaction: agents only consider opinions within a certain 'confidence bound' $\\epsilon$. This first exercise provides a direct, hands-on application of the synchronous HK update rule. By manually calculating the new opinions for a small group of agents, you will gain a concrete understanding of how individual neighborhoods are defined and how local averaging drives the system's evolution .",
            "id": "4294959",
            "problem": "Consider a population of $n$ agents whose scalar opinions evolve under the Hegselmann–Krause (HK) bounded-confidence model. In each synchronous update, every agent replaces its opinion by the arithmetic mean of the opinions of all agents (including itself) whose opinions lie within a closed confidence interval of radius $\\epsilon$ centered at its own current opinion. Assume a complete interaction topology and a homogeneous confidence bound.\n\nAt time $t=0$, there are $n=8$ agents with ordered opinions\n$$\nx_{1}(0)=0.03,\\quad x_{2}(0)=0.12,\\quad x_{3}(0)=0.20,\\quad x_{4}(0)=0.36,\\quad x_{5}(0)=0.41,\\quad x_{6}(0)=0.53,\\quad x_{7}(0)=0.74,\\quad x_{8}(0)=0.84,\n$$\nand the confidence bound is $\\epsilon=0.12$. By the HK rule described above, compute the updated opinion vector $x(1)$ after one synchronous iteration. Treat distances exactly at $\\epsilon$ as included in the neighborhood and include each agent’s own opinion in its neighborhood.\n\nProvide your final answer as exact rational numbers in lowest terms, in a single row vector using the $\\text{pmatrix}$ format. No rounding is required and no units are involved.",
            "solution": "The Hegselmann–Krause (HK) bounded-confidence update rule is a foundational opinion dynamics mechanism in which, at each synchronous step, each agent averages the opinions of those agents whose opinions lie within a symmetric confidence interval of radius $\\epsilon$ around its own current opinion. This rule is based on two core definitions: (i) metric proximity in opinion space measured by absolute difference, and (ii) local averaging (arithmetic mean) over the neighborhood defined by the confidence interval. We apply this definition directly.\n\nLet $x_{i}(0)$ denote the opinion of agent $i$ at time $t=0$. For each agent $i\\in\\{1,\\dots,8\\}$, define its neighborhood at time $t=0$ as the set of indices $j$ such that $|x_{j}(0)-x_{i}(0)|\\leq \\epsilon$, with the agent itself included. Then $x_{i}(1)$ is the arithmetic mean of $\\{x_{j}(0): j \\text{ in the neighborhood of } i\\}$.\n\nWe proceed agent by agent with $\\epsilon=0.12$.\n\nAgent $1$: $x_{1}(0)=0.03$.\n- Distances: $|0.12-0.03|=0.09\\leq 0.12$ include, $|0.20-0.03|=0.170.12$ exclude, all others are larger and hence excluded.\n- Neighborhood indices: $\\{1,2\\}$.\n- Update: $x_{1}(1)=\\frac{0.03+0.12}{2}$. In rational form, $0.03=\\frac{3}{100}$ and $0.12=\\frac{3}{25}=\\frac{12}{100}$, so\n$$\nx_{1}(1)=\\frac{\\frac{3}{100}+\\frac{12}{100}}{2}=\\frac{\\frac{15}{100}}{2}=\\frac{15}{200}=\\frac{3}{40}.\n$$\n\nAgent $2$: $x_{2}(0)=0.12$.\n- Distances: $|0.03-0.12|=0.09\\leq 0.12$ include, $|0.20-0.12|=0.08\\leq 0.12$ include, $|0.36-0.12|=0.240.12$ exclude, others are larger and excluded.\n- Neighborhood indices: $\\{1,2,3\\}$.\n- Update: $x_{2}(1)=\\frac{0.03+0.12+0.20}{3}$. In rational form, $0.20=\\frac{1}{5}=\\frac{20}{100}$, so the sum is $\\frac{3}{100}+\\frac{12}{100}+\\frac{20}{100}=\\frac{35}{100}=\\frac{7}{20}$, hence\n$$\nx_{2}(1)=\\frac{\\frac{7}{20}}{3}=\\frac{7}{60}.\n$$\n\nAgent $3$: $x_{3}(0)=0.20$.\n- Distances: $|0.12-0.20|=0.08\\leq 0.12$ include, $|0.36-0.20|=0.160.12$ exclude, $|0.03-0.20|=0.170.12$ exclude, others are larger and excluded.\n- Neighborhood indices: $\\{2,3\\}$.\n- Update: $x_{3}(1)=\\frac{0.12+0.20}{2}$. In rational form, $0.12=\\frac{3}{25}$ and $0.20=\\frac{1}{5}=\\frac{5}{25}$, so\n$$\nx_{3}(1)=\\frac{\\frac{3}{25}+\\frac{5}{25}}{2}=\\frac{\\frac{8}{25}}{2}=\\frac{4}{25}.\n$$\n\nAgent $4$: $x_{4}(0)=0.36$.\n- Distances: $|0.41-0.36|=0.05\\leq 0.12$ include, $|0.53-0.36|=0.170.12$ exclude, $|0.20-0.36|=0.160.12$ exclude, others are larger and excluded.\n- Neighborhood indices: $\\{4,5\\}$.\n- Update: $x_{4}(1)=\\frac{0.36+0.41}{2}$. In rational form, $0.36=\\frac{36}{100}=\\frac{9}{25}$ and $0.41=\\frac{41}{100}$, so the sum is $\\frac{36}{100}+\\frac{41}{100}=\\frac{77}{100}$, hence\n$$\nx_{4}(1)=\\frac{\\frac{77}{100}}{2}=\\frac{77}{200}.\n$$\n\nAgent $5$: $x_{5}(0)=0.41$.\n- Distances: $|0.36-0.41|=0.05\\leq 0.12$ include, $|0.53-0.41|=0.12\\leq 0.12$ include, $|0.20-0.41|=0.210.12$ exclude. Others are larger and excluded.\n- Neighborhood indices: $\\{4,5,6\\}$.\n- Update: $x_{5}(1)=\\frac{0.36+0.41+0.53}{3}$. In rational form, $0.53=\\frac{53}{100}$, so the sum is $\\frac{36+41+53}{100}=\\frac{130}{100}=\\frac{13}{10}$, hence\n$$\nx_{5}(1)=\\frac{\\frac{13}{10}}{3}=\\frac{13}{30}.\n$$\n\nAgent $6$: $x_{6}(0)=0.53$.\n- Distances: $|0.41-0.53|=0.12\\leq 0.12$ include, $|0.74-0.53|=0.210.12$ exclude, others are larger and excluded.\n- Neighborhood indices: $\\{5,6\\}$.\n- Update: $x_{6}(1)=\\frac{0.41+0.53}{2}$. In rational form, this is $\\frac{\\frac{41}{100}+\\frac{53}{100}}{2}=\\frac{\\frac{94}{100}}{2}=\\frac{47}{100}$.\n\nAgent $7$: $x_{7}(0)=0.74$.\n- Distances: $|0.84-0.74|=0.10\\leq 0.12$ include, $|0.53-0.74|=0.210.12$ exclude, others are larger and excluded.\n- Neighborhood indices: $\\{7,8\\}$.\n- Update: $x_{7}(1)=\\frac{0.74+0.84}{2}$. In rational form, $\\frac{\\frac{74}{100}+\\frac{84}{100}}{2}=\\frac{\\frac{158}{100}}{2}=\\frac{79}{100}$.\n\nAgent $8$: $x_{8}(0)=0.84$.\n- Distances: $|0.74-0.84|=0.10\\leq 0.12$ include, others are larger and excluded.\n- Neighborhood indices: $\\{7,8\\}$.\n- Update: $x_{8}(1)=\\frac{0.74+0.84}{2}=\\frac{79}{100}$, identical to agent $7$.\n\nCollecting the updated opinions in order, we have\n$$\nx(1)=\\left(\\frac{3}{40},\\ \\frac{7}{60},\\ \\frac{4}{25},\\ \\frac{77}{200},\\ \\frac{13}{30},\\ \\frac{47}{100},\\ \\frac{79}{100},\\ \\frac{79}{100}\\right).\n$$\nAll entries are exact rational numbers in lowest terms.",
            "answer": "$$\\boxed{\\begin{pmatrix}\\frac{3}{40}  \\frac{7}{60}  \\frac{4}{25}  \\frac{77}{200}  \\frac{13}{30}  \\frac{47}{100}  \\frac{79}{100}  \\frac{79}{100}\\end{pmatrix}}$$"
        },
        {
            "introduction": "While simulation is a powerful tool, many models permit elegant analytical solutions. The DeGroot model, a foundational linear consensus protocol, is a prime example where the final consensus state is not arbitrary but a deterministic function of the initial opinions and the network structure. This practice challenges you to move beyond simulation and use concepts from linear algebra and Markov chain theory—specifically, the stationary distribution of the influence matrix—to precisely predict the final consensus value .",
            "id": "4294973",
            "problem": "Consider a network of three agents labeled $1$, $2$, and $3$. Their interaction structure is a weighted directed graph that induces a row-stochastic influence matrix $W \\in \\mathbb{R}^{3 \\times 3}$ for a DeGroot opinion dynamics, where the update is $x(t+1)=W x(t)$ for the opinion vector $x(t) \\in \\mathbb{R}^{3}$. The nonzero directed edges and their weights are:\n- From agent $1$ to agent $1$ with weight $\\frac{1}{2}$, and to agent $2$ with weight $\\frac{1}{2}$.\n- From agent $2$ to agent $1$ with weight $\\frac{1}{4}$, to agent $2$ with weight $\\frac{1}{2}$, and to agent $3$ with weight $\\frac{1}{4}$.\n- From agent $3$ to agent $2$ with weight $\\frac{1}{2}$, and to agent $3$ with weight $\\frac{1}{2}$.\n\nEquivalently,\n$$\nW=\\begin{pmatrix}\n\\frac{1}{2}  \\frac{1}{2}  0 \\\\\n\\frac{1}{4}  \\frac{1}{2}  \\frac{1}{4} \\\\\n0  \\frac{1}{2}  \\frac{1}{2}\n\\end{pmatrix}.\n$$\n\nAssume the initial opinions are\n$$\nx(0)=\\begin{pmatrix}\n\\frac{3}{2} \\\\\n-\\frac{1}{2} \\\\\n\\frac{5}{2}\n\\end{pmatrix}.\n$$\n\nStarting from the fundamental definition of the DeGroot model and the notion of a stationary distribution for a row-stochastic matrix, determine the stationary distribution $\\pi=(\\pi_{1},\\pi_{2},\\pi_{3})$ satisfying $\\pi^{\\top}W=\\pi^{\\top}$ and $\\sum_{i=1}^{3}\\pi_{i}=1$, and use it to predict the limiting consensus value $c$ that all agents approach as $t \\to \\infty$. Report the single real number $c$. No rounding is required.",
            "solution": "The problem is well-defined and scientifically sound, grounded in the established theory of linear consensus models (the DeGroot model). All necessary components, including the influence matrix $W$, the initial state vector $x(0)$, and the update rule $x(t+1) = Wx(t)$, are provided. The matrix $W$ is explicitly given as\n$$\nW=\\begin{pmatrix}\n\\frac{1}{2}  \\frac{1}{2}  0 \\\\\n\\frac{1}{4}  \\frac{1}{2}  \\frac{1}{4} \\\\\n0  \\frac{1}{2}  \\frac{1}{2}\n\\end{pmatrix}\n$$\nIt is a row-stochastic matrix, as the sum of elements in each row is $1$. The entries $W_{ij}$ represent the weight agent $i$ gives to the opinion of agent $j$. The directed graph associated with $W$ has an edge from node $j$ to node $i$ if $W_{ij}  0$. The edges are $1 \\to 1$, $2 \\to 1$, $1 \\to 2$, $2 \\to 2$, $3 \\to 2$, $2 \\to 3$, and $3 \\to 3$.\nThis graph is strongly connected:\n- From node $1$, one can reach nodes $1$ and $2$. From node $2$, one can reach node $3$. Thus, $1 \\to 2 \\to 3$.\n- From node $2$, one can reach nodes $1$, $2$, and $3$.\n- From node $3$, one can reach nodes $2$ and $3$. From node $2$, one can reach node $1$. Thus, $3 \\to 2 \\to 1$.\nSince every node can reach every other node, the graph is strongly connected. Furthermore, since all diagonal elements $W_{ii}$ are positive, the associated Markov chain is aperiodic. A row-stochastic matrix corresponding to a strongly connected, aperiodic graph is primitive.\n\nBy the Perron-Frobenius theorem for stochastic matrices, such a matrix $W$ has a simple eigenvalue $\\lambda_1 = 1$, and all other eigenvalues have a magnitude strictly less than $1$. The left eigenvector $\\pi^{\\top}$ corresponding to $\\lambda_1 = 1$ is unique (up to scaling) and can be normalized such that its components $\\pi_i$ are positive and sum to $1$. This vector $\\pi$ is the stationary distribution of the Markov chain defined by $W$.\n\nThe opinion dynamics evolve as $x(t) = W^t x(0)$. For a primitive row-stochastic matrix $W$, the limit of $W^t$ as $t \\to \\infty$ exists and is given by $W^\\infty = \\mathbf{1}\\pi^\\top$, where $\\mathbf{1}$ is the column vector of all ones. Therefore, the opinion vector $x(t)$ converges to a consensus state:\n$$\n\\lim_{t \\to \\infty} x(t) = \\lim_{t \\to \\infty} W^t x(0) = (\\mathbf{1}\\pi^\\top) x(0) = \\mathbf{1}(\\pi^\\top x(0)) = \\begin{pmatrix} c \\\\ c \\\\ c \\end{pmatrix}\n$$\nThe consensus value $c$ is the weighted average of the initial opinions, where the weights are the components of the stationary distribution $\\pi$:\n$$\nc = \\pi^\\top x(0) = \\sum_{i=1}^{3} \\pi_i x_i(0)\n$$\nOur first step is to find the stationary distribution $\\pi = (\\pi_1, \\pi_2, \\pi_3)$ by solving the system of linear equations defined by $\\pi^\\top W = \\pi^\\top$, subject to the normalization constraint $\\sum_{i=1}^{3} \\pi_i = 1$. The equation $\\pi^\\top W = \\pi^\\top$ is equivalent to $\\pi^\\top (W - I) = 0$, or $(W^\\top - I)\\pi = 0$.\n\nThe transpose of $W$ is\n$$\nW^\\top = \\begin{pmatrix}\n\\frac{1}{2}  \\frac{1}{4}  0 \\\\\n\\frac{1}{2}  \\frac{1}{2}  \\frac{1}{2} \\\\\n0  \\frac{1}{4}  \\frac{1}{2}\n\\end{pmatrix}\n$$\nSo, $W^\\top - I$ is\n$$\nW^\\top - I = \\begin{pmatrix}\n\\frac{1}{2}-1  \\frac{1}{4}  0 \\\\\n\\frac{1}{2}  \\frac{1}{2}-1  \\frac{1}{2} \\\\\n0  \\frac{1}{4}  \\frac{1}{2}-1\n\\end{pmatrix} = \\begin{pmatrix}\n-\\frac{1}{2}  \\frac{1}{4}  0 \\\\\n\\frac{1}{2}  -\\frac{1}{2}  \\frac{1}{2} \\\\\n0  \\frac{1}{4}  -\\frac{1}{2}\n\\end{pmatrix}\n$$\nThe system of equations $(W^\\top - I)\\pi = 0$ is:\n1. $-\\frac{1}{2}\\pi_1 + \\frac{1}{4}\\pi_2 = 0$\n2. $\\frac{1}{2}\\pi_1 - \\frac{1}{2}\\pi_2 + \\frac{1}{2}\\pi_3 = 0$\n3. $\\frac{1}{4}\\pi_2 - \\frac{1}{2}\\pi_3 = 0$\n\nFrom equation (1), we have $\\frac{1}{4}\\pi_2 = \\frac{1}{2}\\pi_1$, which implies $\\pi_2 = 2\\pi_1$.\nFrom equation (3), we have $\\frac{1}{4}\\pi_2 = \\frac{1}{2}\\pi_3$, which implies $\\pi_2 = 2\\pi_3$, or $\\pi_3 = \\frac{1}{2}\\pi_2$.\nSubstituting $\\pi_1 = \\frac{1}{2}\\pi_2$ and $\\pi_3 = \\frac{1}{2}\\pi_2$ into equation (2) gives:\n$$\n\\frac{1}{2}\\left(\\frac{1}{2}\\pi_2\\right) - \\frac{1}{2}\\pi_2 + \\frac{1}{2}\\left(\\frac{1}{2}\\pi_2\\right) = \\frac{1}{4}\\pi_2 - \\frac{1}{2}\\pi_2 + \\frac{1}{4}\\pi_2 = 0\n$$\nwhich simplifies to $0=0$. This confirms the consistency of the equations. We can express $\\pi_1$ and $\\pi_3$ in terms of $\\pi_2$: $\\pi_1 = \\frac{1}{2}\\pi_2$ and $\\pi_3 = \\frac{1}{2}\\pi_2$.\n\nNow, we use the normalization condition $\\pi_1 + \\pi_2 + \\pi_3 = 1$:\n$$\n\\frac{1}{2}\\pi_2 + \\pi_2 + \\frac{1}{2}\\pi_2 = 1\n$$\n$$\n2\\pi_2 = 1 \\implies \\pi_2 = \\frac{1}{2}\n$$\nUsing this, we find the other components:\n$$\n\\pi_1 = \\frac{1}{2}\\pi_2 = \\frac{1}{2}\\left(\\frac{1}{2}\\right) = \\frac{1}{4}\n$$\n$$\n\\pi_3 = \\frac{1}{2}\\pi_2 = \\frac{1}{2}\\left(\\frac{1}{2}\\right) = \\frac{1}{4}\n$$\nSo, the stationary distribution is $\\pi^\\top = \\left(\\frac{1}{4}, \\frac{1}{2}, \\frac{1}{4}\\right)$.\n\nThe final step is to calculate the consensus value $c$ using the initial opinion vector $x(0) = \\left(\\frac{3}{2}, -\\frac{1}{2}, \\frac{5}{2}\\right)^\\top$:\n$$\nc = \\pi^\\top x(0) = \\pi_1 x_1(0) + \\pi_2 x_2(0) + \\pi_3 x_3(0)\n$$\n$$\nc = \\left(\\frac{1}{4}\\right)\\left(\\frac{3}{2}\\right) + \\left(\\frac{1}{2}\\right)\\left(-\\frac{1}{2}\\right) + \\left(\\frac{1}{4}\\right)\\left(\\frac{5}{2}\\right)\n$$\n$$\nc = \\frac{3}{8} - \\frac{1}{4} + \\frac{5}{8}\n$$\nTo sum these fractions, we use a common denominator of $8$:\n$$\nc = \\frac{3}{8} - \\frac{2}{8} + \\frac{5}{8} = \\frac{3 - 2 + 5}{8} = \\frac{6}{8}\n$$\n$$\nc = \\frac{3}{4}\n$$\nThe limiting consensus value that all agents' opinions will approach is $\\frac{3}{4}$.",
            "answer": "$$\\boxed{\\frac{3}{4}}$$"
        },
        {
            "introduction": "A common condition for guaranteed consensus in the DeGroot model is that the influence graph must be strongly connected. However, this condition is sufficient, not necessary. This exercise explores a crucial exception by presenting a network with a \"stubborn agent,\" or zealot, which leads to a consensus state despite the absence of strong connectivity. By analyzing this case, you will develop a more nuanced understanding of the convergence properties of linear models, grounded in the fundamental structure of the underlying Markov chain .",
            "id": "4294847",
            "problem": "Consider the DeGroot opinion update model $x(t+1)=W x(t)$ on a directed network of $4$ agents, where $W$ is a row-stochastic weight matrix ($W_{ij}\\ge 0$ and $\\sum_{j} W_{ij}=1$ for each $i$), and $W_{ij}0$ encodes that agent $i$ places positive weight on agent $j$'s opinion (equivalently, there is a directed influence edge $j\\to i$). The directed graph has a rooted spanning tree if there exists a node (the root) from which there is a directed path to every other node in the influence graph. Strong connectivity means that for every ordered pair of nodes $(i,j)$ there exists a directed path from $i$ to $j$. You may use fundamental properties of finite Markov chains and the Stochastic, Indecomposable, and Aperiodic (SIA) condition only as a starting point, but you must derive the result without shortcut formulas.\n\nConstruct the following explicit example. Let\n$$\nW=\\begin{pmatrix}\n1  0  0  0 \\\\\n0.6  0.4  0  0 \\\\\n0.5  0  0.5  0 \\\\\n0.7  0  0  0.3\n\\end{pmatrix},\n\\quad\nx(0)=\\begin{pmatrix}2\\\\-1\\\\4\\\\0\\end{pmatrix}.\n$$\nIn the associated influence graph (edge $j\\to i$ if $W_{ij}0$), node $1$ has directed edges to all other nodes and there are self-loops on several nodes, but there are no directed edges from any other node back to node $1$; thus the graph is not strongly connected, yet it contains a rooted spanning tree with root at node $1$.\n\nUsing only core definitions and well-tested facts about stochastic matrices and finite Markov chains, determine whether the DeGroot dynamics on this network reach consensus for the given $W$ and $x(0)$, and, if so, compute the consensus value and justify why consensus occurs despite the lack of strong connectivity.\n\nWhich option correctly characterizes and justifies the asymptotic behavior of $x(t)$, including the consensus value when it exists?\n\nA. The dynamics converge to consensus equal to $x_1(0)=2$, because $W$ is row-stochastic and has a single aperiodic closed class $\\{1\\}$, so the finite-state Markov chain induced by $W$ has a unique stationary distribution concentrated at node $1$, implying $W^t\\to \\mathbf{1}\\,e_1^\\top$ and hence $x(t)\\to (x_1(0))\\,\\mathbf{1}$ despite the graph not being strongly connected.\n\nB. The dynamics do not reach consensus because the graph is not strongly connected; strong connectivity is necessary for consensus under the DeGroot model.\n\nC. The dynamics reach consensus equal to the arithmetic mean $(2-1+4+0)/4=5/4$, since any row-stochastic $W$ yields consensus to the simple average of initial opinions.\n\nD. The dynamics converge but not to consensus; each node $i$ converges to its own self-weighted fixed point so that $x_1(t)\\to 2$, $x_2(t)\\to -1$, $x_3(t)\\to 4$, and $x_4(t)\\to 0$ due to the presence of self-loops on several nodes.",
            "solution": "The problem asks for the asymptotic behavior of the opinion vector $x(t)$ evolving according to the DeGroot model $x(t+1) = W x(t)$, given a specific row-stochastic matrix $W$ and initial opinion vector $x(0)$.\n\nThe given matrix and initial vector are:\n$$ W=\\begin{pmatrix} 1  0  0  0 \\\\ 0.6  0.4  0  0 \\\\ 0.5  0  0.5  0 \\\\ 0.7  0  0  0.3 \\end{pmatrix}, \\quad x(0)=\\begin{pmatrix}2\\\\-1\\\\4\\\\0\\end{pmatrix} $$\nThe asymptotic opinion vector is $x(\\infty) = \\lim_{t\\to\\infty} x(t) = \\left(\\lim_{t\\to\\infty} W^t\\right) x(0)$. To determine the outcome, we must analyze the limit of the matrix power $W^t$.\n\nThe matrix $W$ is a row-stochastic matrix, which can be interpreted as the transition matrix for a finite-state Markov chain on the set of states $S=\\{1, 2, 3, 4\\}$. The entry $W_{ij}$ represents the probability of transitioning from state $i$ to state $j$.\n\nWe analyze the communication classes of this Markov chain.\n- For state $1$, $W_{11}=1$ and $W_{1j}=0$ for $j \\neq 1$. This means that from state $1$, the system can only transition to state $1$. Therefore, state $1$ is an absorbing state, and the set $\\{1\\}$ forms a closed communication class.\n- For state $2$, $W_{21}=0.6  0$. There is a positive probability of transitioning from state $2$ to state $1$. Since it is impossible to leave state $1$, state $2$ cannot be in the same communication class as state $1$ and cannot be part of any closed class other than one containing only absorbing states. Since state $2$ is not absorbing ($W_{22}  1$), it must be a transient state.\n- Similarly, for state $3$, $W_{31}=0.5  0$, so state $3$ is a transient state.\n- For state $4$, $W_{41}=0.7  0$, so state $4$ is a transient state.\n\nThe Markov chain thus consists of a single closed class, $\\{1\\}$, and a set of transient states $\\{2, 3, 4\\}$. All transient states have a path to the closed class.\nA closed class is aperiodic if the greatest common divisor (GCD) of the lengths of all cycles within that class is $1$. The class $\\{1\\}$ has a self-loop because $W_{11}=1  0$, which is a cycle of length $1$. The GCD is therefore $1$, and the class $\\{1\\}$ is aperiodic.\n\nFor any finite-state Markov chain with one or more absorbing states, any state that is not absorbing but from which an absorbing state can be reached is transient. As $t \\to \\infty$, the probability of being in any transient state approaches $0$. The system will be absorbed into one of the closed classes. In this case, since there is only one closed class, $\\{1\\}$, the system is guaranteed to be absorbed into state $1$, regardless of the starting state.\n\nThis implies that for any initial state $i \\in S$, the probability of being in state $j$ after $t$ steps, $(W^t)_{ij}$, converges as $t \\to \\infty$. Specifically, all probability mass flows to the absorbing state $1$.\n$$ \\lim_{t\\to\\infty} (W^t)_{ij} = \\begin{cases} 1  \\text{if } j=1 \\\\ 0  \\text{if } j \\neq 1 \\end{cases} $$\nTherefore, the limiting matrix $W^\\infty = \\lim_{t\\to\\infty} W^t$ is:\n$$ W^\\infty = \\begin{pmatrix} 1  0  0  0 \\\\ 1  0  0  0 \\\\ 1  0  0  0 \\\\ 1  0  0  0 \\end{pmatrix} $$\nThis matrix can be expressed as the outer product $\\mathbf{1} e_1^\\top$, where $\\mathbf{1}$ is the column vector of all ones and $e_1 = (1, 0, 0, 0)^\\top$ is the first standard basis vector.\n$$ \\mathbf{1} e_1^\\top = \\begin{pmatrix} 1 \\\\ 1 \\\\ 1 \\\\ 1 \\end{pmatrix} \\begin{pmatrix} 1  0  0  0 \\end{pmatrix} = \\begin{pmatrix} 1  0  0  0 \\\\ 1  0  0  0 \\\\ 1  0  0  0 \\\\ 1  0  0  0 \\end{pmatrix} $$\nThis is consistent with the general theorem for row-stochastic matrices that correspond to chains with a single aperiodic closed class: the limit $W^t$ is $\\mathbf{1}\\pi^\\top$, where $\\pi^\\top$ is the unique stationary distribution. Here, the unique stationary distribution $\\pi^\\top$ (a row vector satisfying $\\pi^\\top W = \\pi^\\top$ and $\\sum_i \\pi_i=1$) is $\\pi^\\top = (1, 0, 0, 0) = e_1^\\top$.\n\nNow we can compute the final opinion vector $x(\\infty)$:\n$$ x(\\infty) = W^\\infty x(0) = (\\mathbf{1} e_1^\\top) x(0) = \\mathbf{1} (e_1^\\top x(0)) $$\nThe scalar term $e_1^\\top x(0)$ is the dot product of $e_1^\\top$ and $x(0)$:\n$$ e_1^\\top x(0) = \\begin{pmatrix} 1  0  0  0 \\end{pmatrix} \\begin{pmatrix} 2 \\\\ -1 \\\\ 4 \\\\ 0 \\end{pmatrix} = 2 $$\nThis is the initial opinion of agent $1$, $x_1(0)$.\nSo, the final opinion vector is:\n$$ x(\\infty) = \\mathbf{1} \\cdot x_1(0) = \\begin{pmatrix} 1 \\\\ 1 \\\\ 1 \\\\ 1 \\end{pmatrix} (2) = \\begin{pmatrix} 2 \\\\ 2 \\\\ 2 \\\\ 2 \\end{pmatrix} $$\nThe system reaches a consensus, and the consensus value is $2$. This occurs because agent $1$ is a \"stubborn agent\" ($W_{11}=1$) who influences all other agents (directly, in this case, as the graph has a spanning tree rooted at 1), but is influenced by none. All other agents eventually adopt agent 1's unwavering opinion. Strong connectivity is a sufficient condition for consensus, but not a necessary one. The existence of a single aperiodic closed class that is reachable from all other nodes is also sufficient, as demonstrated here.\n\nNow we evaluate the given options.\n\nA. The dynamics converge to consensus equal to $x_1(0)=2$, because $W$ is row-stochastic and has a single aperiodic closed class $\\{1\\}$, so the finite-state Markov chain induced by $W$ has a unique stationary distribution concentrated at node $1$, implying $W^t\\to \\mathbf{1}\\,e_1^\\top$ and hence $x(t)\\to (x_1(0))\\,\\mathbf{1}$ despite the graph not being strongly connected.\nThis option correctly states that consensus is reached at the value $x_1(0)=2$. The justification provided is entirely sound and follows the derivation from the properties of the associated Markov chain. It correctly identifies the single aperiodic closed class $\\{1\\}$, the unique stationary distribution $\\pi^\\top = e_1^\\top$, the limit of $W^t$ as $\\mathbf{1}e_1^\\top$, and the resulting final state $x_1(0)\\mathbf{1}$. The observation that this occurs despite the lack of strong connectivity is also correct.\nVerdict: **Correct**.\n\nB. The dynamics do not reach consensus because the graph is not strongly connected; strong connectivity is necessary for consensus under the DeGroot model.\nThis option is incorrect for two reasons. First, as calculated above, the dynamics do reach consensus. Second, the premise that strong connectivity is a necessary condition for consensus is false. It is a well-known sufficient (but not necessary) condition.\nVerdict: **Incorrect**.\n\nC. The dynamics reach consensus equal to the arithmetic mean $(2-1+4+0)/4=5/4$, since any row-stochastic $W$ yields consensus to the simple average of initial opinions.\nThis option is incorrect. The consensus value is $2$, not $5/4$. The reason provided is also false. Consensus to the arithmetic mean of initial opinions is guaranteed only for a specific class of matrices (e.g., doubly stochastic SIA matrices), and $W$ is not in this class.\nVerdict: **Incorrect**.\n\nD. The dynamics converge but not to consensus; each node $i$ converges to its own self-weighted fixed point so that $x_1(t)\\to 2$, $x_2(t)\\to -1$, $x_3(t)\\to 4$, and $x_4(t)\\to 0$ due to the presence of self-loops on several nodes.\nThis option claims the system does not reach consensus, which is false. It also incorrectly states a convergence to the initial opinions for agents $2$, $3$, and $4$. Our step-by-step analysis of the recurrences for each $x_i(t)$ showed that $x_2(t)$, $x_3(t)$, and $x_4(t)$ all converge to $2$. The presence of self-loops with weight less than $1$ does not prevent an agent from changing its opinion.\nVerdict: **Incorrect**.\n\nThe only correct and well-justified option is A.",
            "answer": "$$\\boxed{A}$$"
        }
    ]
}