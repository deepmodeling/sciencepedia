{
    "hands_on_practices": [
        {
            "introduction": "The Independent Cascade model is a powerful theoretical tool, but its practical application hinges on knowing the activation probabilities along edges. This exercise tackles the fundamental problem of parameter estimation from empirical data. You will derive and apply an update rule from the Expectation-Maximization (EM) algorithm to infer a latent edge probability, a core skill for grounding abstract models in real-world observations .",
            "id": "4309566",
            "problem": "Consider the Independent Cascade (IC) model on a directed graph with nodes $A$, $B$, and $C$, and directed edges $(A \\rightarrow C)$ and $(B \\rightarrow C)$. In the IC model, each newly activated node gets exactly one chance in the immediately following discrete time step to activate each of its out-neighbors, with independent Bernoulli trials along edges. Let the (unknown) activation probability on edge $(A \\rightarrow C)$ be $p \\in (0,1)$ and the (known) activation probability on edge $(B \\rightarrow C)$ be $q \\in (0,1)$. Suppose that across many cascades, you observe only the activation times of nodes, and you aggregate the data into the following two local configurations at the moment just before any attempts to activate $C$ occur:\n- Type I exposures: only node $A$ is newly active (node $B$ is not newly active), so only $A$ attempts to activate $C$. There are $n_{1}$ such exposures, among which $s_{1}$ result in $C$ becoming active at the next time step.\n- Type II exposures: both $A$ and $B$ are newly active simultaneously, so both attempt to activate $C$ in the next time step. There are $n_{2}$ such exposures, among which $s_{2}$ result in $C$ becoming active at the next time step.\n\nFor Type I exposures, whether $C$ activates is fully informative about the success or failure of $A$'s attempt. For Type II exposures, when $C$ activates, you do not observe which parent’s attempt succeeded (either one or both could have succeeded). Assume all activation attempts are conditionally independent given the edge probabilities and that across cascades these exposure events are independent and identically distributed.\n\nStarting from the IC model definition and the Bernoulli complete-data likelihood for edge $(A \\rightarrow C)$ attempts, and using the principle of Expectation-Maximization (EM) to handle the latent attribution in Type II exposures, derive the one-step M-step update for $p$ from an initial value $p^{(0)}$ by maximizing the expected complete-data log-likelihood. Then, evaluate this update numerically for\n- $n_{1} = 12$, $s_{1} = 5$,\n- $n_{2} = 8$, $s_{2} = 6$,\n- $q = 0.3$,\n- $p^{(0)} = 0.4$.\n\nGive your final numerical answer for $p^{(1)}$ rounded to four significant figures.",
            "solution": "The problem is scientifically grounded, well-posed, objective, and contains all necessary information for a unique solution. It describes a standard parameter estimation task in the context of the Independent Cascade (IC) model using the Expectation-Maximization (EM) algorithm, a common statistical method for handling latent variables. Therefore, the problem is valid.\n\nThe goal is to estimate the activation probability $p$ for the edge $(A \\rightarrow C)$. We are given two types of observations.\n-   Type I: $n_{1}$ instances where only node $A$ attempts to activate $C$. The number of successful activations is $s_{1}$. These trials directly inform $p$.\n-   Type II: $n_{2}$ instances where both nodes $A$ and $B$ attempt to activate $C$. The number of successful activations of $C$ is $s_{2}$. In these cases, the cause of activation is not observed (it could be $A$, $B$, or both), which introduces a latent variable.\n\nWe use the EM algorithm to find the maximum likelihood estimate for $p$. This iterative algorithm consists of an Expectation (E) step and a Maximization (M) step.\n\nFirst, we define the \"complete data\". The complete data would specify the outcome (success or failure) of every individual activation attempt. For the edge $(A \\rightarrow C)$, there are a total of $n_{1} + n_{2}$ activation attempts. Let us denote the number of successes and failures from $A$ in Type I exposures as $S_{A,1}$ and $F_{A,1}$, and in Type II exposures as $S_{A,2}$ and $F_{A,2}$.\nFrom the problem statement, for Type I exposures, the outcomes are fully observed:\n$S_{A,1} = s_{1}$\n$F_{A,1} = n_{1} - s_{1}$\n\nFor Type II exposures, the outcomes of individual attempts from $A$ are not observed. They are latent variables. The total number of successes from $A$ over all exposures is $S_{A, \\text{total}} = S_{A,1} + S_{A,2} = s_{1} + S_{A,2}$. The total number of failures is $F_{A, \\text{total}} = F_{A,1} + F_{A,2} = (n_{1} - s_{1}) + F_{A,2}$.\n\nThe complete-data log-likelihood for parameter $p$, given the outcomes of all $n_{1} + n_{2}$ attempts from $A$, is that of a Bernoulli process:\n$$ \\mathcal{L}_c(p; S_{A, \\text{total}}, F_{A, \\text{total}}) = \\log \\left( p^{S_{A, \\text{total}}} (1-p)^{F_{A, \\text{total}}} \\right) $$\n$$ \\mathcal{L}_c(p) = (s_{1} + S_{A,2}) \\log(p) + (n_{1} - s_{1} + F_{A,2}) \\log(1-p) $$\nSince $S_{A,2}$ and $F_{A,2}$ are unobserved, we proceed with the EM algorithm.\n\n**E-Step: Expectation**\n\nIn the E-step, we compute the expectation of the complete-data log-likelihood with respect to the posterior distribution of the latent variables, given the observed data and the current estimate of the parameter, $p^{(t)}$. This function is denoted as $Q(p|p^{(t)})$.\n$$ Q(p|p^{(t)}) = E \\left[ \\mathcal{L}_c(p) \\mid \\text{observed data}, p^{(t)} \\right] $$\n$$ Q(p|p^{(t)}) = \\left(s_{1} + E[S_{A,2}]\\right) \\log(p) + \\left(n_{1} - s_{1} + E[F_{A,2}]\\right) \\log(1-p) $$\nThe expectation is conditioned on the observed data ($n_{1}, s_{1}, n_{2}, s_{2}$) and the current parameters ($p^{(t)}, q$). We need to compute $E[S_{A,2}]$ and $E[F_{A,2}]$.\n\nThe $n_{2}$ Type II exposures are divided into two observable outcomes:\n1.  $s_{2}$ cases where node $C$ becomes active.\n2.  $n_{2} - s_{2}$ cases where node $C$ does not become active.\n\nIn the $n_{2} - s_{2}$ cases where $C$ is not activated, it must be that both attempts from $A$ and $B$ failed. Thus, for these cases, the number of successes from $A$ is exactly $0$.\n\nIn the $s_{2}$ cases where $C$ is activated, at least one of the attempts from $A$ or $B$ was successful. The probability of this event, given $p^{(t)}$ and $q$, is $P(C \\text{ active}) = 1 - P(C \\text{ not active}) = 1 - P(A \\text{ fails AND } B \\text{ fails})$. By independence, this is $1 - (1-p^{(t)})(1-q)$.\n\nWe need the expected number of successes from $A$ in one such trial, which is the conditional probability of $A$ succeeding given that $C$ was activated.\n$$ P(A \\text{ succeeds} | C \\text{ active}) = \\frac{P(A \\text{ succeeds AND } C \\text{ active})}{P(C \\text{ active})} $$\nThe event \"$A$ succeeds\" is a subset of the event \"$C$ active\" in this context (since if $A$ succeeds, $C$ definitely activates), so the numerator is simply $P(A \\text{ succeeds}) = p^{(t)}$.\n$$ P(A \\text{ succeeds} | C \\text{ active}) = \\frac{p^{(t)}}{1 - (1-p^{(t)})(1-q)} $$\nThe expected number of successes from $A$ across the $s_{2}$ successful Type II exposures is this probability multiplied by $s_{2}$. Combining with the $n_2-s_2$ failure cases, the total expected number of successes from $A$ in Type II exposures is:\n$$ E[S_{A,2}] = (n_{2}-s_{2}) \\times 0 + s_{2} \\times \\frac{p^{(t)}}{1 - (1-p^{(t)})(1-q)} = s_{2} \\frac{p^{(t)}}{1 - (1-p^{(t)})(1-q)} $$\nThe total number of attempts from $A$ in Type II exposures is $n_{2}$. The expected number of failures is $E[F_{A,2}] = n_{2} - E[S_{A,2}]$.\n\nThe total expected number of successes for edge $(A \\rightarrow C)$ across all trials is:\n$$ E[S_{A, \\text{total}}] = s_{1} + E[S_{A,2}] = s_{1} + s_{2} \\frac{p^{(t)}}{1 - (1-p^{(t)})(1-q)} $$\n\n**M-Step: Maximization**\n\nIn the M-step, we find the value of $p$ that maximizes $Q(p|p^{(t)})$. The function $Q$ has the form of a log-likelihood for a Bernoulli random variable with $E[S_{A, \\text{total}}]$ expected successes and $E[F_{A, \\text{total}}]$ expected failures out of a total of $n_{1} + n_{2}$ trials.\nDifferentiating $Q(p|p^{(t)})$ with respect to $p$ and setting to zero gives the standard maximum likelihood estimator:\n$$ p^{(t+1)} = \\frac{\\text{Expected number of successes}}{\\text{Total number of trials}} $$\n$$ p^{(t+1)} = \\frac{E[S_{A, \\text{total}}]}{n_{1} + n_{2}} $$\nSubstituting the expression for $E[S_{A, \\text{total}}]$ gives the M-step update rule:\n$$ p^{(t+1)} = \\frac{1}{n_{1} + n_{2}} \\left( s_{1} + s_{2} \\frac{p^{(t)}}{1 - (1-p^{(t)})(1-q)} \\right) $$\n\n**Numerical Evaluation**\n\nWe are asked to compute $p^{(1)}$ starting from $p^{(0)}$. The given values are:\n$n_{1} = 12$\n$s_{1} = 5$\n$n_{2} = 8$\n$s_{2} = 6$\n$q = 0.3$\n$p^{(0)} = 0.4$\n\nWe substitute these values into the update equation for $t=0$:\n$$ p^{(1)} = \\frac{1}{12 + 8} \\left( 5 + 6 \\times \\frac{0.4}{1 - (1-0.4)(1-0.3)} \\right) $$\nFirst, we compute the denominator of the inner fraction:\n$$ 1 - (1 - 0.4)(1 - 0.3) = 1 - (0.6)(0.7) = 1 - 0.42 = 0.58 $$\nNow substitute this back into the equation for $p^{(1)}$:\n$$ p^{(1)} = \\frac{1}{20} \\left( 5 + 6 \\times \\frac{0.4}{0.58} \\right) $$\n$$ p^{(1)} = \\frac{1}{20} \\left( 5 + \\frac{2.4}{0.58} \\right) $$\n$$ p^{(1)} = \\frac{1}{20} \\left( 5 + \\frac{240}{58} \\right) = \\frac{1}{20} \\left( 5 + \\frac{120}{29} \\right) $$\nTo combine the terms in the parenthesis, we find a common denominator:\n$$ 5 + \\frac{120}{29} = \\frac{5 \\times 29}{29} + \\frac{120}{29} = \\frac{145 + 120}{29} = \\frac{265}{29} $$\nFinally, we compute $p^{(1)}$:\n$$ p^{(1)} = \\frac{1}{20} \\times \\frac{265}{29} = \\frac{265}{580} $$\nTo simplify the fraction, we can divide the numerator and denominator by $5$:\n$$ p^{(1)} = \\frac{53}{116} $$\nNow we convert this fraction to a decimal value and round to four significant figures:\n$$ p^{(1)} = \\frac{53}{116} \\approx 0.45689655... $$\nRounding to four significant figures, we get $0.4569$.",
            "answer": "$$\\boxed{0.4569}$$"
        },
        {
            "introduction": "Following parameter estimation, a crucial step is to assess the model's robustness to the inherent uncertainty in those parameters. This practice challenges you to quantify the bounds on the expected cascade size given intervals of possible activation probabilities. By calculating both these robust bounds and the sensitivity of the outcome to each probability, you will learn how to evaluate the reliability of model predictions and identify the most influential links in the network .",
            "id": "4309573",
            "problem": "Consider a directed graph with node set $V$ and edge set $E \\subseteq V \\times V$. In the Independent Cascade (IC) model, a seed set $S \\subseteq V$ is initially active at time $t=0$. Each directed edge $(u,v) \\in E$ has an activation probability $p_{uv} \\in [0,1]$. When node $u$ becomes active, it gets exactly one chance to activate node $v$ via edge $(u,v)$, and succeeds with probability $p_{uv}$. All activation events across edges are mutually independent. The process proceeds in discrete time steps until no more activations occur. Let $X(S,\\mathbf{p})$ denote the random final number of active nodes when the activation probabilities are given by the vector $\\mathbf{p} = (p_e)_{e \\in E}$. The quantity of interest is the expected final cascade size $\\mathbb{E}[X(S,\\mathbf{p})]$.\n\nUnder probability uncertainty, each edge $(u,v)$ has an interval $[\\underline{p}_{uv}, \\overline{p}_{uv}]$ with $\\underline{p}_{uv} \\le \\overline{p}_{uv}$, representing lower and upper bounds on the unknown activation probability. The robustness question is to determine the minimum and maximum of $\\mathbb{E}[X(S,\\mathbf{p})]$ over all $\\mathbf{p}$ consistent with these intervals. The sensitivity question asks for the partial derivative vector $\\nabla \\mathbb{E}[X(S,\\mathbf{p})]$ with respect to $\\mathbf{p}$, evaluated at a specified $\\mathbf{p}$ inside the uncertainty intervals.\n\nStarting only from the fundamental definition of the Independent Cascade model, independence of edge activations, and the definition of expectation, write a complete and runnable program that, for each test case specified below, computes:\n- The robust lower bound $L := \\min_{\\mathbf{p} \\in [\\underline{\\mathbf{p}}, \\overline{\\mathbf{p}}]} \\mathbb{E}[X(S,\\mathbf{p})]$.\n- The robust upper bound $U := \\max_{\\mathbf{p} \\in [\\underline{\\mathbf{p}}, \\overline{\\mathbf{p}}]} \\mathbb{E}[X(S,\\mathbf{p})]$.\n- The sensitivity vector $\\left(\\frac{\\partial}{\\partial p_e} \\mathbb{E}[X(S,\\mathbf{p})]\\right)_{e \\in E}$ evaluated at the midpoint probabilities $\\mathbf{p}^{\\mathrm{mid}} := \\frac{1}{2}(\\underline{\\mathbf{p}} + \\overline{\\mathbf{p}})$, where the addition and division are taken componentwise.\n\nAll computations must be exact in the sense of probability, not asymptotic or heuristic, and must be derived from the definitions. For finite graphs, an exact computation may be performed by enumerating all possible live-edge subgraphs, where each edge is independently included with its activation probability and reachability from $S$ determines the final active set. The final expected value is the sum over all live-edge realizations of the reachability size times its probability.\n\nYour program must solve the following test cases. For each test case, the directed edges $E$ are listed in a specified order, and for each edge $e_i$ in that order, the corresponding lower and upper bounds $\\underline{p}_{e_i}$ and $\\overline{p}_{e_i}$ are given. The seed set $S$ is provided as a list of nodes.\n\nTest Suite:\n- Test Case $1$:\n    - Nodes: $V = \\{0,1,2,3,4\\}$, so $|V| = 5$.\n    - Ordered edges: $E = [(0,1),(1,2),(2,3),(1,3),(0,4),(4,3)]$, so $|E| = 6$.\n    - Lower bounds: $\\underline{\\mathbf{p}} = [0.1,\\,0.2,\\,0.25,\\,0.15,\\,0.05,\\,0.3]$ in the same order as $E$.\n    - Upper bounds: $\\overline{\\mathbf{p}} = [0.3,\\,0.5,\\,0.6,\\,0.5,\\,0.2,\\,0.7]$ in the same order as $E$.\n    - Seed set: $S = \\{0\\}$.\n- Test Case $2$:\n    - Nodes: $V = \\{0,1\\}$, so $|V| = 2$.\n    - Ordered edges: $E = [(0,1)]$, so $|E| = 1$.\n    - Lower bounds: $\\underline{\\mathbf{p}} = [0.2]$.\n    - Upper bounds: $\\overline{\\mathbf{p}} = [0.2]$.\n    - Seed set: $S = \\{0\\}$.\n- Test Case $3$:\n    - Nodes: $V = \\{0,1,2,3\\}$, so $|V| = 4$.\n    - Ordered edges: $E = [(0,1),(0,2),(1,3),(2,3)]$, so $|E| = 4$.\n    - Lower bounds: $\\underline{\\mathbf{p}} = [0.1,\\,0.1,\\,0.2,\\,0.2]$.\n    - Upper bounds: $\\overline{\\mathbf{p}} = [0.9,\\,0.8,\\,0.7,\\,0.6]$.\n    - Seed set: $S = \\{0\\}$.\n\nFor each test case, the required outputs are:\n- The robust lower bound $L$ as a real number.\n- The robust upper bound $U$ as a real number.\n- The sensitivity vector at $\\mathbf{p}^{\\mathrm{mid}}$, listed in the same order as $E$, as real numbers.\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, where each test case contributes a list of real numbers in the following order: first $L$, then $U$, then the components of the sensitivity vector at $\\mathbf{p}^{\\mathrm{mid}}$. For example, a line with three test cases should look like $[[L_1,U_1,d_{1,1},\\dots,d_{1,|E_1|}],[L_2,U_2,d_{2,1},\\dots,d_{2,|E_2|}],[L_3,U_3,d_{3,1},\\dots,d_{3,|E_3|}]]$.\n\nThere are no physical units and no angle units; all outputs are real numbers without units. Express any proportion-related quantities strictly as decimals.\n\nYour program must be self-contained, require no user input, and compute the exact quantities by finite enumeration consistent with the definitions above.",
            "solution": "The problem requires the computation of robust bounds and sensitivities for the expected cascade size in the Independent Cascade (IC) model under probability uncertainty. We begin by formalizing the expected cascade size, $\\mathbb{E}[X(S,\\mathbf{p})]$.\n\nA specific outcome of the stochastic process corresponds to a \"live-edge subgraph\" $G' = (V, E')$, where $E' \\subseteq E$ is the set of edges that successfully activate. Due to the mutual independence of activation events, the probability of realizing a particular live-edge subgraph $G'$ is given by:\n$$\n\\mathbb{P}(G' | \\mathbf{p}) = \\left( \\prod_{e \\in E'} p_e \\right) \\left( \\prod_{e \\in E \\setminus E'} (1 - p_e) \\right)\n$$\nFor a given live-edge subgraph $G'=(V, E')$, the final set of active nodes is the set of all nodes reachable from the initial seed set $S$. Let's denote this set as $R(S, G')$. The size of the cascade is then $|R(S, G')|$.\n\nBy the definition of expectation, the expected cascade size is the sum of the cascade sizes for each possible live-edge subgraph, weighted by their respective probabilities:\n$$\n\\mathbb{E}[X(S,\\mathbf{p})] = \\sum_{E' \\subseteq E} |R(S, (V, E'))| \\cdot \\mathbb{P}((V, E') | \\mathbf{p})\n$$\nThis expression is a multi-linear polynomial in the probability variables $\\{p_e\\}_{e\\in E}$. For finite graphs with a small number of edges, this formula allows for an exact computation by enumerating all $2^{|E|}$ subgraphs.\n\n**Robustness Analysis: Lower and Upper Bounds ($L$ and $U$)**\n\nTo determine the minimum and maximum of $\\mathbb{E}[X(S,\\mathbf{p})]$ over the hyperrectangle defined by $\\mathbf{p} \\in [\\underline{\\mathbf{p}}, \\overline{\\mathbf{p}}]$, we first analyze the function's dependence on a single edge probability, $p_k$, for an arbitrary edge $e_k \\in E$. We compute the partial derivative $\\frac{\\partial}{\\partial p_k} \\mathbb{E}[X(S,\\mathbf{p})]$.\n\nLet's separate the summation over $E' \\subseteq E$ into two parts: one where $e_k \\in E'$ and one where $e_k \\notin E'$. Any $E' \\subseteq E$ not containing $e_k$ can be written as $E'' \\subseteq E \\setminus \\{e_k\\}$. Any $E' \\subseteq E$ containing $e_k$ can be written as $E'' \\cup \\{e_k\\}$ for some $E'' \\subseteq E \\setminus \\{e_k\\}$. Let $\\mathbb{P}_{\\neg k}(E'')$ denote the probability of the subgraph $(V, E'')$ with edges taken from $E \\setminus \\{e_k\\}$.\n$$\n\\mathbb{E}[X(S,\\mathbf{p})] = \\sum_{E'' \\subseteq E \\setminus \\{e_k\\}} \\left[ |R(S, (V, E''))| (1-p_k) + |R(S, (V, E'' \\cup \\{e_k\\}))| p_k \\right] \\mathbb{P}_{\\neg k}(E'')\n$$\nTaking the partial derivative with respect to $p_k$:\n$$\n\\frac{\\partial}{\\partial p_k} \\mathbb{E}[X(S,\\mathbf{p})] = \\sum_{E'' \\subseteq E \\setminus \\{e_k\\}} \\left[ |R(S, (V, E'' \\cup \\{e_k\\}))| - |R(S, (V, E''))| \\right] \\mathbb{P}_{\\neg k}(E'')\n$$\nWhen adding an edge to a graph, the set of reachable nodes from any source can only grow or stay the same. Thus, $|R(S, (V, E'' \\cup \\{e_k\\}))| \\ge |R(S, (V, E''))|$ for any $E''$. Since probabilities $\\mathbb{P}_{\\neg k}(E'')$ are non-negative, each term in the sum is non-negative. Therefore,\n$$\n\\frac{\\partial}{\\partial p_k} \\mathbb{E}[X(S,\\mathbf{p})] \\ge 0\n$$\nThis demonstrates that $\\mathbb{E}[X(S,\\mathbf{p})]$ is a monotonically non-decreasing function of each probability component $p_k$. Consequently, to find the minimum and maximum of the function over the domain $[\\underline{\\mathbf{p}}, \\overline{\\mathbf{p}}]$, we only need to evaluate it at the corners of this hyperrectangle. The minimum value $L$ is achieved when all probabilities are at their lowest possible values, and the maximum value $U$ is achieved when they are all at their highest.\n$$\nL := \\min_{\\mathbf{p}} \\mathbb{E}[X(S,\\mathbf{p})] = \\mathbb{E}[X(S, \\underline{\\mathbf{p}})]\n$$\n$$\nU := \\max_{\\mathbf{p}} \\mathbb{E}[X(S,\\mathbf{p})] = \\mathbb{E}[X(S, \\overline{\\mathbf{p}})]\n$$\n\n**Sensitivity Analysis: Gradient Vector ($\\nabla \\mathbb{E}$)**\n\nThe sensitivity vector is the gradient $\\nabla \\mathbb{E}[X(S,\\mathbf{p})]$, which consists of the partial derivatives $\\frac{\\partial}{\\partial p_k} \\mathbb{E}[X(S,\\mathbf{p})]$ for each edge $e_k \\in E$. The formula derived above for the partial derivative provides a direct method for computation. For each edge $e_k$, we must evaluate:\n$$\n\\frac{\\partial}{\\partial p_k} \\mathbb{E}[X(S,\\mathbf{p})]\\bigg|_{\\mathbf{p}=\\mathbf{p}^{\\mathrm{mid}}} = \\sum_{E'' \\subseteq E \\setminus \\{e_k\\}} \\left[ |R(S, (V, E'' \\cup \\{e_k\\}))| - |R(S, (V, E''))| \\right] \\mathbb{P}_{\\neg k}(E'')\\bigg|_{\\mathbf{p}=\\mathbf{p}^{\\mathrm{mid}}}\n$$\nThe term $|R(S, (V, E'' \\cup \\{e_k\\}))| - |R(S, (V, E''))|$ represents the marginal increase in the number of activated nodes due to the presence of edge $e_k$, given that the other live edges are exactly the set $E''$.\n\n**Algorithmic Design**\n\nThe computations for $L$, $U$, and the sensitivity vector can be implemented based on these derived formulas.\n\n1.  A function `compute_expected_cascade(graph_params, probabilities)` will implement the primary expectation formula. It iterates through all $2^{|E|}$ subgraphs. For each subgraph $E'$, it calculates its probability $\\mathbb{P}((V,E')|\\mathbf{p})$ and the size of the reachable set $|R(S,(V,E'))|$. The latter is found using a Breadth-First Search (BFS) starting from the seed nodes $S$. The products of size and probability are summed to yield the final expectation.\n2.  The lower bound $L$ is computed by calling this function with the lower-bound probability vector $\\underline{\\mathbf{p}}$.\n3.  The upper bound $U$ is computed by calling this function with the upper-bound probability vector $\\overline{\\mathbf{p}}$.\n4.  A function `compute_gradient(graph_params, probabilities)` will compute the sensitivity vector. It iterates through each edge $e_k \\in E$. For each $e_k$, it iterates through all $2^{|E|-1}$ subgraphs $E''$ of $E \\setminus \\{e_k\\}$. In each inner loop, it calculates the probability of $E''$ using the corresponding components of $\\mathbf{p}^{\\mathrm{mid}}$, and computes the difference in cascade size, $|R(S, (V, E'' \\cup \\{e_k\\}))| - |R(S, (V, E''))|$, again using BFS for reachability. These products are summed to find the partial derivative $\\frac{\\partial \\mathbb{E}}{\\partial p_k}$ at $\\mathbf{p}^{\\mathrm{mid}}$.\n\nThis approach, based on enumerating subgraphs, is computationally feasible for the small graph sizes specified in the test cases and provides an exact solution derived from first principles.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom collections import deque\n\ndef solve():\n    \"\"\"\n    Main solver function to process all test cases.\n    \"\"\"\n\n    test_cases = [\n        {\n            \"num_nodes\": 5,\n            \"edges\": [(0, 1), (1, 2), (2, 3), (1, 3), (0, 4), (4, 3)],\n            \"p_lower\": [0.1, 0.2, 0.25, 0.15, 0.05, 0.3],\n            \"p_upper\": [0.3, 0.5, 0.6, 0.5, 0.2, 0.7],\n            \"seed_set\": {0},\n        },\n        {\n            \"num_nodes\": 2,\n            \"edges\": [(0, 1)],\n            \"p_lower\": [0.2],\n            \"p_upper\": [0.2],\n            \"seed_set\": {0},\n        },\n        {\n            \"num_nodes\": 4,\n            \"edges\": [(0, 1), (0, 2), (1, 3), (2, 3)],\n            \"p_lower\": [0.1, 0.1, 0.2, 0.2],\n            \"p_upper\": [0.9, 0.8, 0.7, 0.6],\n            \"seed_set\": {0},\n        },\n    ]\n\n    all_results = []\n    for case in test_cases:\n        result = get_results_for_case(case)\n        all_results.append(result)\n\n    # Format the final output string as specified.\n    # e.g., [[L1,U1,d1,...],[L2,U2,d2,...]]\n    output_str = \"[\" + \",\".join(\n        \"[\" + \",\".join(f\"{x:.10f}\" for x in res) + \"]\" for res in all_results\n    ) + \"]\"\n    print(output_str)\n\n\ndef get_results_for_case(case):\n    \"\"\"\n    Computes L, U, and sensitivity for a single test case.\n    \"\"\"\n    num_nodes = case[\"num_nodes\"]\n    edges = case[\"edges\"]\n    p_lower = np.array(case[\"p_lower\"])\n    p_upper = np.array(case[\"p_upper\"])\n    seed_set = case[\"seed_set\"]\n\n    # Calculate L (lower bound)\n    L = compute_expected_cascade(num_nodes, edges, seed_set, p_lower)\n\n    # Calculate U (upper bound)\n    U = compute_expected_cascade(num_nodes, edges, seed_set, p_upper)\n    \n    # Calculate sensitivities at midpoint\n    p_mid = 0.5 * (p_lower + p_upper)\n    sensitivity_vector = compute_gradient(num_nodes, edges, seed_set, p_mid)\n\n    return [L, U] + sensitivity_vector\n\n\ndef bfs(num_nodes, edge_list, start_nodes):\n    \"\"\"\n    Performs a Breadth-First Search to find all reachable nodes.\n    \n    Args:\n        num_nodes (int): Total number of nodes in the graph.\n        edge_list (list): A list of (u, v) tuples representing live edges.\n        start_nodes (set): The set of starting nodes for the search.\n\n    Returns:\n        set: The set of nodes reachable from start_nodes.\n    \"\"\"\n    if not start_nodes:\n        return set()\n\n    adj = [[] for _ in range(num_nodes)]\n    for u, v in edge_list:\n        adj[u].append(v)\n    \n    q = deque(list(start_nodes))\n    visited = set(start_nodes)\n    \n    while q:\n        u = q.popleft()\n        for v in adj[u]:\n            if v not in visited:\n                visited.add(v)\n                q.append(v)\n    return visited\n\ndef compute_expected_cascade(num_nodes, edges, seed_set, probabilities):\n    \"\"\"\n    Computes the expected cascade size by enumerating all live-edge subgraphs.\n    \"\"\"\n    num_edges = len(edges)\n    total_expected_size = 0.0\n\n    # Iterate through all 2^m possible live-edge subgraphs\n    for i in range(1 << num_edges):\n        live_edges = []\n        subgraph_prob = 1.0\n        \n        for j in range(num_edges):\n            p_j = probabilities[j]\n            if (i >> j) & 1:  # If j-th edge is in the live set\n                live_edges.append(edges[j])\n                subgraph_prob *= p_j\n            else:\n                subgraph_prob *= (1.0 - p_j)\n        \n        # Calculate cascade size for this subgraph\n        reachable_nodes = bfs(num_nodes, live_edges, seed_set)\n        cascade_size = len(reachable_nodes)\n        \n        total_expected_size += cascade_size * subgraph_prob\n        \n    return total_expected_size\n\ndef compute_gradient(num_nodes, edges, seed_set, probabilities):\n    \"\"\"\n    Computes the gradient of the expected cascade size.\n    \"\"\"\n    num_edges = len(edges)\n    gradient = [0.0] * num_edges\n\n    for k in range(num_edges):\n        # Edges excluding e_k\n        other_edges = edges[:k] + edges[k+1:]\n        other_probs = np.concatenate((probabilities[:k], probabilities[k+1:]))\n        num_other_edges = len(other_edges)\n        \n        derivative_k = 0.0\n\n        # Iterate through all subgraphs of E \\ {e_k}\n        for i in range(1 << num_other_edges):\n            subgraph_prime = []\n            prob_subgraph_prime = 1.0\n            \n            for j in range(num_other_edges):\n                p_j = other_probs[j]\n                if (i >> j) & 1:\n                    subgraph_prime.append(other_edges[j])\n                    prob_subgraph_prime *= p_j\n                else:\n                    prob_subgraph_prime *= (1.0 - p_j)\n\n            # Cascade size without edge e_k\n            size_without_ek = len(bfs(num_nodes, subgraph_prime, seed_set))\n            \n            # Cascade size with edge e_k\n            subgraph_with_ek = subgraph_prime + [edges[k]]\n            size_with_ek = len(bfs(num_nodes, subgraph_with_ek, seed_set))\n            \n            derivative_k += (size_with_ek - size_without_ek) * prob_subgraph_prime\n        \n        gradient[k] = derivative_k\n        \n    return gradient\n\nif __name__ == \"__main__\":\n    solve()\n```"
        },
        {
            "introduction": "With a parameterized and analyzed model, we can now turn to its primary application: strategic influence maximization. This hands-on problem asks you to implement and compare the performance of three distinct seeding policies, from a simple greedy algorithm to an adaptive oracle strategy. By computing the exact expected spread for each, you will gain deep insight into the algorithmic challenges of network intervention and the significant value of adaptive decision-making .",
            "id": "4309578",
            "problem": "Consider a directed graph $G = (V, E)$ with $|V| = n$ nodes indexed $0,1,\\dots,n-1$. Each directed edge $(u \\to v) \\in E$ is associated with an independent activation probability $p_{uv} \\in [0,1]$. The Independent Cascade (IC) model proceeds as follows: at time $t=0$, a set of seeds $S \\subseteq V$ is chosen. Thereafter, whenever a node $u$ becomes active at time $t$, it gets exactly one chance to activate each of its out-neighbors $v$ at time $t+1$, independently, succeeding with probability $p_{uv}$. Once active, a node remains active (progressive process). The diffusion continues until no new activations occur. Equivalently, by the live-edge formulation, each edge $(u \\to v)$ is included independently with probability $p_{uv}$ before diffusion; the final active set for seed set $S$ equals the set of nodes reachable from $S$ via directed paths in the sampled live-edge graph.\n\nDefine the expected spread function $F(S)$ to be the expected total number of active nodes at termination when the seed set is $S$, where the expectation is taken over the independent edge activations. Consider a budget $B \\in \\mathbb{N}$ with $0 \\leq B \\leq n$.\n\nYou must implement three seeding policies:\n- Policy A (Non-adaptive greedy): Choose $B$ seeds sequentially at time $t=0$ without feedback, where at each step you add the node $u \\in V \\setminus S$ that maximizes the expected marginal gain $\\Delta(u \\mid S) = F(S \\cup \\{u\\}) - F(S)$ under the prior edge probabilities (evaluated exactly). Break ties by choosing the smallest-index node.\n- Policy B (Adaptive oracle sequential greedy on realizations): For each fixed live-edge realization, select seeds sequentially, one per round, fully observing the diffusion completion after each seed. In this policy, assume oracle knowledge of the realized live-edge graph after each round. At each step, pick the node $u$ that maximizes the realized marginal gain in the number of newly covered nodes beyond those already activated, breaking ties by smallest index. The final spread for a realization is the size of the union of the reachable sets of the selected seeds in that realization. The policy’s expected spread is the expectation of this realized spread over the independent edge activations.\n- Policy C (Uniform random seeding baseline): Choose a seed set $S$ uniformly at random among all $\\binom{n}{B}$ subsets of size $B$ at time $t=0$. The expected spread equals the average of $F(S)$ over all such $S$.\n\nFundamental base to be used:\n- IC model definition as stated above.\n- Live-edge equivalence for IC: the final active set equals the set of nodes reachable from $S$ in a random subgraph where each edge $(u \\to v)$ is independently present with probability $p_{uv}$.\n- Independence of edge activations.\n\nYou must compute all expectations exactly by enumerating all live-edge realizations. For a realization, an edge $(u \\to v)$ is present if it is “live,” and absent otherwise. The probability weight of a realization is the product over edges of $p_{uv}$ for live edges and $(1 - p_{uv})$ for non-live edges. For any seed set $S$, the final active set is the union of nodes reachable from each $s \\in S$ via directed paths of live edges.\n\nTask: For each test case below, compute three values:\n- The expected final number of active nodes under Policy A.\n- The expected final number of active nodes under Policy B.\n- The expected final number of active nodes under Policy C.\n\nAll probabilities must be handled as decimals in $[0,1]$. There are no physical units or angles. The final answers must be numerical floats. Tie-breaking must always choose the smallest-index node whenever multiple choices have equal marginal gain.\n\nTest suite:\n- Test case $1$ (happy path):\n  - $n = 4$\n  - Edges with probabilities: $(0 \\to 1, 0.6)$, $(0 \\to 2, 0.4)$, $(1 \\to 2, 0.5)$, $(1 \\to 3, 0.7)$, $(2 \\to 3, 0.3)$\n  - Budget $B = 2$\n- Test case $2$ (certainty boundary):\n  - $n = 3$\n  - Edges with probabilities: $(0 \\to 1, 1.0)$, $(1 \\to 2, 1.0)$\n  - Budget $B = 1$\n- Test case $3$ (zero-probability boundary):\n  - $n = 3$\n  - Edges with probabilities: $(0 \\to 1, 0.0)$, $(1 \\to 2, 0.0)$\n  - Budget $B = 2$\n- Test case $4$ (overlap and adaptivity stress):\n  - $n = 5$\n  - Edges with probabilities: $(0 \\to 1, 0.9)$, $(0 \\to 2, 0.1)$, $(3 \\to 4, 0.9)$, $(3 \\to 2, 0.1)$, $(1 \\to 2, 0.5)$, $(4 \\to 2, 0.5)$\n  - Budget $B = 2$\n\nOutput specification:\nYour program should produce a single line containing the results as a comma-separated list enclosed in square brackets. For each test case, output the three expected spreads in the fixed order Policy A, Policy B, Policy C. Aggregate all test cases in the order provided, producing a flat list. For example, with two test cases the output format would be $[A_1,B_1,C_1,A_2,B_2,C_2]$, where each entry is a float. There must be no additional text printed.",
            "solution": "The user's request is a valid scientific problem. It asks for the exact computation of the expected spread of influence under three different seeding policies in the Independent Cascade (IC) model. The problem is well-defined, scientifically grounded in network science, and self-contained. The provided test cases have parameters that allow for exact computation by enumerating all possible outcomes.\n\n### Problem Validation\n**Step 1: Extract Givens**\n- Graph: A directed graph $G = (V, E)$ with $n = |V|$ nodes, indexed $0, 1, \\dots, n-1$.\n- Edge Probabilities: Each edge $(u \\to v) \\in E$ has an independent activation probability $p_{uv} \\in [0,1]$.\n- IC Model: At $t=0$, seeds $S$ are active. At each step $t$, newly activated nodes $u$ attempt to activate their out-neighbors $v$ with probability $p_{uv}$. Once active, nodes remain active.\n- Live-Edge Equivalence: The final active set for seeds $S$ is the set of nodes reachable from $S$ in a random \"live-edge\" subgraph, where each edge $(u \\to v)$ is independently included with probability $p_{uv}$.\n- Expected Spread Function: $F(S)$ is the expected number of total active nodes starting from seed set $S$.\n- Budget: An integer $B$ representing the number of seeds to choose.\n- Policy A (Non-adaptive greedy): Sequentially select $B$ seeds. At each step, choose the node $u \\in V \\setminus S$ that maximizes the expected marginal gain $\\Delta(u \\mid S) = F(S \\cup \\{u\\}) - F(S)$.\n- Policy B (Adaptive oracle sequential greedy): For each live-edge realization, sequentially select $B$ seeds. At each step, choose the node $u$ that maximizes the number of newly activated nodes in that specific realization. The final answer is the expected value of the total spread over all realizations.\n- Policy C (Uniform random seeding): Choose a seed set $S$ of size $B$ uniformly at random from all $\\binom{n}{B}$ possibilities. The expected spread is the average of $F(S)$ over all such sets.\n- Computation Method: All expectations must be computed exactly by enumerating all $2^{|E|}$ live-edge realizations.\n- Tie-Breaking: If multiple nodes yield the same maximum gain, choose the one with the smallest index.\n- Test Cases: Four specific instances of $(n, E, \\{p_{uv}\\}, B)$ are provided.\n\n**Step 2: Validate Using Extracted Givens**\n- **Scientifically Grounded:** The problem is based on the Independent Cascade model, a cornerstone of social network analysis and epidemiology. All concepts are standard within this field.\n- **Well-Posed:** The objective is to compute specific, well-defined quantities (expected spreads). The policies are described unambiguously. The small size of the test graphs makes exact enumeration feasible, ensuring a unique solution can be found.\n- **Objective:** The problem is stated in precise mathematical and algorithmic terms, free of subjectivity.\n- **No Flaws Detected:** The problem does not violate any scientific principles, is not incomplete or contradictory, and is a formalizable task. It is a standard, non-trivial problem in the study of influence maximization.\n\n**Step 3: Verdict and Action**\nThe problem is valid. I will proceed with formulating the solution.\n\n### Method and Solution Formulation\n\nThe problem requires exact computation of expectations, which is feasible by enumerating all possible live-edge graph realizations since the number of edges $|E|$ is small. For a graph with $|E|=m$ edges, there are $2^m$ unique realizations.\n\n**1. General Framework: Enumerating Realizations**\nLet a realization be a subgraph $G'=(V, E')$ where $E' \\subseteq E$. The probability of this realization is given by:\n$$Pr(G') = \\prod_{(u,v) \\in E'} p_{uv} \\prod_{(u,v) \\in E \\setminus E'} (1 - p_{uv})$$\nFor each of the $2^m$ realizations, we will pre-compute key information:\n- The probability of the realization, $Pr(G')$.\n- The set of nodes reachable from each individual node $u \\in V$, denoted $R(u, G')$. This can be found using a Breadth-First Search (BFS) or Depth-First Search (DFS) starting from $u$ in the graph $G'$.\n- The set of nodes that can reach a given node $v \\in V$, denoted $P(v, G')$. This is needed for Policy C and can be found by running a traversal on the graph with all edges reversed.\n\n**2. Policy A: Non-adaptive Greedy**\nThis policy builds a seed set $S_A$ of size $B$ by iteratively adding the node with the highest expected marginal gain. The seed set is fixed across all realizations.\n- Initialize $S_A = \\emptyset$.\n- For $k=1, \\dots, B$:\n  - Find the node $u^* \\in V \\setminus S_A$ that maximizes the expected marginal gain:\n    $$u^* = \\arg\\max_{u \\in V \\setminus S_A} \\Delta(u \\mid S_A)$$\n    The marginal gain is calculated as the expected number of newly activated nodes:\n    $$\\Delta(u \\mid S_A) = E[|R(S_A \\cup \\{u\\}, G')| - |R(S_A, G')|] = \\sum_{G'} Pr(G') \\cdot |R(u, G') \\setminus R(S_A, G')|$$\n    Here, $R(S,G') = \\bigcup_{s \\in S} R(s, G')$.\n  - Add $u^*$ to $S_A$.\n- Once the final set $S_A$ is determined, the total expected spread is calculated:\n  $$F(S_A) = E[|R(S_A, G')|] = \\sum_{G'} Pr(G') \\cdot |\\bigcup_{s \\in S_A} R(s, G')|$$\n\n**3. Policy B: Adaptive Oracle Sequential Greedy**\nThis policy makes its decisions adaptively for each realization. The final performance is the average over all realizations.\n- Initialize the total expected spread, $E_B = 0$.\n- For each realization $G'$:\n  - Initialize the seed set for this realization, $S_{B, G'} = \\emptyset$, and the set of already activated nodes, $A_{G'} = \\emptyset$.\n  - For $k=1, \\dots, B$:\n    - Find the node $u^* \\in V \\setminus S_{B, G'}$ that maximizes the *realized* marginal gain in this specific graph $G'$:\n      $$u^* = \\arg\\max_{u \\in V \\setminus S_{B, G'}} |R(u, G') \\setminus A_{G'}|$$\n    - Add $u^*$ to $S_{B, G'}$.\n    - Update the set of activated nodes: $A_{G'} = A_{G'} \\cup R(u^*, G')$.\n  - The final spread for this realization is $|A_{G'}|$.\n  - Add the contribution of this realization to the total expectation: $E_B \\leftarrow E_B + Pr(G') \\cdot |A_{G'}|$.\nThe final value $E_B$ is the answer for Policy B.\n\n**4. Policy C: Uniform Random Seeding**\nThe expected spread is the average of $F(S)$ over all $\\binom{n}{B}$ seed sets $S$ of size $B$.\n$$E_C = \\frac{1}{\\binom{n}{B}} \\sum_{|S|=B} F(S) = \\frac{1}{\\binom{n}{B}} \\sum_{|S|=B} \\sum_{G'} Pr(G') |R(S, G')|$$\nBy linearity of expectation, we can swap the summations:\n$$E_C = \\sum_{G'} Pr(G') \\left( \\frac{1}{\\binom{n}{B}} \\sum_{|S|=B} |R(S, G')| \\right)$$\nThe term in the parenthesis is the average spread for a random seed set of size $B$ in a fixed realization $G'$. Let's analyze it further:\n$$ \\frac{1}{\\binom{n}{B}} \\sum_{|S|=B} |\\bigcup_{s \\in S} R(s, G')| = \\sum_{v \\in V} P(v \\text{ is activated})$$\nA node $v$ is activated if at least one seed is in its predecessor set $P(v, G')$, where $P(v, G') = \\{u \\in V \\mid v \\in R(u, G')\\}$. Let $k_v = |P(v, G')|$. The number of ways to choose a seed set $S$ of size $B$ that does *not* activate $v$ is to choose all seeds from $V \\setminus P(v, G')$, which is $\\binom{n-k_v}{B}$.\nThe probability that a random seed set activates $v$ is:\n$$P(v \\text{ is activated}) = 1 - \\frac{\\binom{n-k_v}{B}}{\\binom{n}{B}}$$\nThe average spread in realization $G'$ is the sum of these probabilities over all nodes $v$:\n$$\\text{AvgSpread}(G', B) = \\sum_{v \\in V} \\left(1 - \\frac{\\binom{n-k_v}{B}}{\\binom{n}{B}}\\right)$$\nThe final expected spread for Policy C is the weighted average of these values over all realizations:\n$$E_C = \\sum_{G'} Pr(G') \\cdot \\text{AvgSpread}(G', B)$$\nWe use `scipy.special.comb` for computing the binomial coefficients, noting that $\\binom{N}{K}=0$ if $N<K$.\n\nThe implementation will follow this three-part structure, with care taken for tie-breaking rules (choosing the smallest node index) and numerical precision.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.special import comb\n\ndef solve():\n    \"\"\"\n    Solves the Independent Cascade model problem for the given test suite.\n    \"\"\"\n    test_cases = [\n        # Test case 1 (happy path)\n        {\n            \"n\": 4,\n            \"edges_with_probs\": [\n                (0, 1, 0.6), (0, 2, 0.4), (1, 2, 0.5), (1, 3, 0.7), (2, 3, 0.3)\n            ],\n            \"B\": 2,\n        },\n        # Test case 2 (certainty boundary)\n        {\n            \"n\": 3,\n            \"edges_with_probs\": [(0, 1, 1.0), (1, 2, 1.0)],\n            \"B\": 1,\n        },\n        # Test case 3 (zero-probability boundary)\n        {\n            \"n\": 3,\n            \"edges_with_probs\": [(0, 1, 0.0), (1, 2, 0.0)],\n            \"B\": 2,\n        },\n        # Test case 4 (overlap and adaptivity stress)\n        {\n            \"n\": 5,\n            \"edges_with_probs\": [\n                (0, 1, 0.9), (0, 2, 0.1), (3, 4, 0.9), (3, 2, 0.1),\n                (1, 2, 0.5), (4, 2, 0.5)\n            ],\n            \"B\": 2,\n        },\n    ]\n\n    results = []\n    for case in test_cases:\n        n, edges_with_probs, B = case[\"n\"], case[\"edges_with_probs\"], case[\"B\"]\n        \n        edges = [(u, v) for u, v, p in edges_with_probs]\n        probs = [p for u, v, p in edges_with_probs]\n        m = len(edges)\n\n        realizations_data = []\n        for i in range(1 << m):\n            live_edges = []\n            realization_prob = 1.0\n            temp_i = i\n            for j in range(m):\n                if (temp_i & 1) == 1:\n                    live_edges.append(edges[j])\n                    realization_prob *= probs[j]\n                else:\n                    realization_prob *= (1.0 - probs[j])\n                temp_i >>= 1\n            \n            if realization_prob == 0:\n                continue\n\n            adj = [[] for _ in range(n)]\n            rev_adj = [[] for _ in range(n)]\n            for u, v in live_edges:\n                adj[u].append(v)\n                rev_adj[v].append(u)\n\n            def bfs(start_node, current_adj):\n                q = [start_node]\n                visited = {start_node}\n                head = 0\n                while head < len(q):\n                    u_ = q[head]\n                    head += 1\n                    for v_ in current_adj[u_]:\n                        if v_ not in visited:\n                            visited.add(v_)\n                            q.append(v_)\n                return visited\n\n            reachable_sets = [bfs(u, adj) for u in range(n)]\n            predecessor_counts = [len(bfs(v, rev_adj)) for v in range(n)]\n\n            realizations_data.append({\n                \"prob\": realization_prob,\n                \"reachable_sets\": reachable_sets,\n                \"predecessor_counts\": predecessor_counts,\n            })\n\n        res_A = calculate_policy_A(B, n, realizations_data)\n        res_B = calculate_policy_B(B, n, realizations_data)\n        res_C = calculate_policy_C(B, n, realizations_data)\n        \n        results.extend([res_A, res_B, res_C])\n\n    print(f\"[{','.join(map(str, results))}]\")\n\ndef calculate_policy_A(B, n, realizations_data):\n    \"\"\"Computes expected spread for Policy A (Non-adaptive greedy).\"\"\"\n    S_A = set()\n    reachable_per_realization = [set() for _ in realizations_data]\n\n    for _ in range(B):\n        best_node = -1\n        max_gain = -1.0\n        \n        candidate_nodes = sorted(list(set(range(n)) - S_A))\n        for u in candidate_nodes:\n            current_gain = 0.0\n            for i, data in enumerate(realizations_data):\n                newly_activated = data[\"reachable_sets\"][u] - reachable_per_realization[i]\n                current_gain += data[\"prob\"] * len(newly_activated)\n            \n            if current_gain > max_gain:\n                max_gain = current_gain\n                best_node = u\n        \n        if best_node != -1:\n            S_A.add(best_node)\n            for i, data in enumerate(realizations_data):\n                reachable_per_realization[i].update(data[\"reachable_sets\"][best_node])\n\n    final_expected_spread = 0.0\n    for i, data in enumerate(realizations_data):\n        final_expected_spread += data[\"prob\"] * len(reachable_per_realization[i])\n        \n    return final_expected_spread\n\n\ndef calculate_policy_B(B, n, realizations_data):\n    \"\"\"Computes expected spread for Policy B (Adaptive oracle greedy).\"\"\"\n    total_expected_spread_B = 0.0\n    for data in realizations_data:\n        S_B = set()\n        A_B = set()\n        \n        for _ in range(B):\n            best_node = -1\n            max_realized_gain = -1\n            \n            candidate_nodes = sorted(list(set(range(n)) - S_B))\n            for u in candidate_nodes:\n                realized_gain = len(data[\"reachable_sets\"][u] - A_B)\n                if realized_gain > max_realized_gain:\n                    max_realized_gain = realized_gain\n                    best_node = u\n\n            if best_node != -1:\n                S_B.add(best_node)\n                A_B.update(data[\"reachable_sets\"][best_node])\n        \n        total_expected_spread_B += data[\"prob\"] * len(A_B)\n        \n    return total_expected_spread_B\n\n\ndef calculate_policy_C(B, n, realizations_data):\n    \"\"\"Computes expected spread for Policy C (Uniform random).\"\"\"\n    if B == 0:\n        return 0.0\n    total_expected_spread_C = 0.0\n    total_combinations = comb(n, B, exact=True)\n    if total_combinations == 0:\n        return float(n) if B > n else 0.0\n        \n    for data in realizations_data:\n        avg_spread_in_realization = 0.0\n        for v in range(n):\n            k_v = data[\"predecessor_counts\"][v]\n            unreachable_combinations = comb(n - k_v, B, exact=True)\n            prob_v_is_activated = 1.0 - (unreachable_combinations / total_combinations)\n            avg_spread_in_realization += prob_v_is_activated\n        \n        total_expected_spread_C += data[\"prob\"] * avg_spread_in_realization\n        \n    return total_expected_spread_C\n\nsolve()\n```"
        }
    ]
}