{
    "hands_on_practices": [
        {
            "introduction": "This first practice will equip you with the generating function formalism, a cornerstone of network science for analyzing random graphs. By deriving the self-consistency equation for the giant component size from first principles, you will gain a deep, analytical understanding of how large-scale connectivity emerges as a sharp phase transition. This exercise provides the fundamental mathematical machinery for studying percolation phenomena on networks described by arbitrary degree distributions .",
            "id": "4310629",
            "problem": "Consider a configuration model (CM) network with degree distribution $P(k)$, where $k \\in \\{0,1,2,\\ldots\\}$. Let $G_0(x)$ denote the generating function (GF) of the degree distribution and $G_1(x)$ denote the GF of the excess-degree distribution. Assume bond percolation (each edge is independently retained with probability $p \\in [0,1]$) on this network, and that the CM is locally tree-like in the thermodynamic limit. Using only the fundamental definitions of generating functions for the degree and excess-degree distributions and the independence of branches in tree-like graphs, do the following:\n\n1. Construct $G_0(x)$ and $G_1(x)$ starting from $P(k)$ and the definition of the excess-degree distribution $q_k$ as the probability that, upon following a uniformly random half-edge to a node, the number of other edges incident to that node equals $k$.\n\n2. Derive a self-consistency relation for the probability $u$ that following a uniformly random occupied edge leads into a finite component (i.e., does not ultimately reach the giant connected component (GCC)), and then derive an expression for the GCC size $S$ in terms of $G_0$ and $u$.\n\n3. Specialize to the case of a $3$-regular CM network, i.e., $P(k)=\\delta_{k,3}$, where $\\delta_{i,j}$ is the Kronecker delta. For this case, explicitly compute $G_0(x)$ and $G_1(x)$, solve your self-consistency equation for $u$ at general $p$, and then obtain a closed-form expression for $S$ as a function of $p$.\n\nFinally, evaluate the GCC size $S$ for bond occupation probability $p=\\tfrac{3}{4}$. Provide your final answer as a single number. No units are required. No rounding is needed unless you choose to approximate instead of giving the exact value; if you do approximate, round your answer to four significant figures.",
            "solution": "The user-provided problem is a valid, well-posed problem in the field of network science and statistical physics. It asks for the derivation of the size of the giant connected component (GCC) in a bond-percolated configuration model (CM) network, specialized to the case of a $3$-regular graph. The derivation will follow the generating function formalism.\n\n### Part 1: Construction of Generating Functions\n\nLet $P(k)$ be the degree distribution of the network. The generating function (GF) for the degree distribution is, by definition:\n$$G_0(x) = \\sum_{k=0}^{\\infty} P(k) x^k$$\n\nThe excess degree distribution, $q_k$, is the probability that a node reached by following a uniformly random edge has $k$ other edges. To find $q_k$, we first find the probability that a random edge connects to a node of degree $j$. The number of edges connected to nodes of degree $j$ is proportional to $j N P(j)$, where $N$ is the total number of nodes. The total number of edge ends (or half-edges) is $\\sum_j j N P(j) = N \\langle k \\rangle$, where $\\langle k \\rangle$ is the average degree. Thus, the probability of a random edge leading to a node of degree $j$ is $\\frac{j P(j)}{\\langle k \\rangle}$.\n\nIf the node has degree $j$, it has $j-1$ other edges. So, the excess degree is $k=j-1$. The probability $q_k$ is therefore given by the probability of reaching a node with original degree $k+1$:\n$$q_k = \\frac{(k+1) P(k+1)}{\\langle k \\rangle}$$\nThe generating function for the excess degree distribution, $G_1(x)$, is:\n$$G_1(x) = \\sum_{k=0}^{\\infty} q_k x^k = \\sum_{k=0}^{\\infty} \\frac{(k+1) P(k+1)}{\\langle k \\rangle} x^k$$\nWe can relate this to the derivative of $G_0(x)$. We have $G_0'(x) = \\sum_{k=1}^{\\infty} k P(k) x^{k-1}$. Let's change the index in the sum for $G_1(x)$ by setting $j=k+1$:\n$$G_1(x) = \\frac{1}{\\langle k \\rangle} \\sum_{j=1}^{\\infty} j P(j) x^{j-1} = \\frac{G_0'(x)}{\\langle k \\rangle}$$\nThe average degree can be found as $\\langle k \\rangle = \\sum_k k P(k) = G_0'(1)$. Thus:\n$$G_1(x) = \\frac{G_0'(x)}{G_0'(1)}$$\n\n### Part 2: Self-Consistency Relation and GCC Size\n\nIn bond percolation, each edge is kept with probability $p$. For a locally tree-like network, we can analyze the size of connected components by tracking paths along edges.\n\nLet $u$ be the probability that following a randomly chosen and occupied edge leads to a finite component. We want to find a self-consistency equation for $u$. Consider following an occupied edge from node A to node B. For this path to lead to a finite component, the component connected to B (excluding the path from A) must be finite. Node B has an excess degree in the original network, described by the GF $G_1(x)$. After percolation, each of its potential edges is kept with probability $p$. The GF for the number of *occupied* edges emerging from B (its excess degree in the percolated graph) is $G_1(1-p+px)$. Let this number be $k'$. For the component containing B to be finite, all $k'$ of these outgoing branches must themselves lead to finite components. The probability for each such branch to be finite is, by definition, $u$. Since the branches are independent in a tree-like structure, the probability for all $k'$ to be finite is $u^{k'}$.\n\nSumming over all possible values of $k'$, weighted by their probabilities (which are the coefficients of the GF $G_1(1-p+px)$), we get the self-consistency equation:\n$$u = \\sum_{k'=0}^{\\infty} \\text{Prob(excess degree is } k') u^{k'} = G_1(1-p+pu)$$\nThis is the required self-consistency relation. A non-trivial solution $u < 1$ exists if and only if the network is above the percolation threshold, indicating the presence of a GCC. The trivial solution $u=1$ always exists and corresponds to all components being finite.\n\nNow, let $S$ be the fractional size of the GCC. $S$ is equal to $1$ minus the probability that a randomly chosen node belongs to a finite component. A randomly chosen node has a degree distribution generated by $G_0(x)$. After percolation, the GF for its degree is $G_0(1-p+px)$. For a node with $k'$ occupied edges to be in a finite component, all $k'$ branches must lead to finite components. The probability of this is $u^{k'}$. The probability that a random node belongs to a finite component is found by averaging $u^{k'}$ over the percolated degree distribution:\n$$\\text{Prob(node is in finite component)} = \\sum_{k'=0}^{\\infty} \\text{Prob(degree is } k') u^{k'} = G_0(1-p+pu)$$\nThe size of the GCC is therefore:\n$$S = 1 - G_0(1-p+pu)$$\n\n### Part 3: Specialization to a 3-Regular Network\n\nFor a $3$-regular network, every node has degree $k=3$. The degree distribution is $P(k) = \\delta_{k,3}$, where $\\delta_{i,j}$ is the Kronecker delta.\n\nFirst, we compute $G_0(x)$ and $G_1(x)$:\n$$G_0(x) = \\sum_{k=0}^{\\infty} \\delta_{k,3} x^k = x^3$$\nThe average degree is $\\langle k \\rangle = G_0'(1)$. Since $G_0'(x) = 3x^2$, we have $\\langle k \\rangle = 3(1)^2=3$.\nThe excess degree GF is:\n$$G_1(x) = \\frac{G_0'(x)}{G_0'(1)} = \\frac{3x^2}{3} = x^2$$\n\nNow, we solve the self-consistency equation for $u$:\n$$u = G_1(1-p+pu) = (1-p+pu)^2$$\nThis is a quadratic equation in $u$:\n$$u = (1-p)^2 + 2p(1-p)u + p^2u^2$$\n$$p^2u^2 + (2p-2p^2-1)u + (1-p)^2 = 0$$\nUsing the quadratic formula $u = \\frac{-b \\pm \\sqrt{b^2-4ac}}{2a}$ with $a=p^2$, $b=2p-2p^2-1$, and $c=(1-p)^2$:\nThe discriminant is $\\Delta = (2p-2p^2-1)^2 - 4p^2(1-p)^2 = (-(1-2p+2p^2))^2 - (2p(1-p))^2$.\nThis is a difference of squares: $\\Delta = (1-2p+2p^2 - (2p-2p^2))(1-2p+2p^2 + (2p-2p^2)) = (1-4p+4p^2)(1) = (1-2p)^2$.\nSo, $\\sqrt{\\Delta} = |1-2p|$.\nThe solutions for $u$ are:\n$$u = \\frac{-(2p-2p^2-1) \\pm |1-2p|}{2p^2} = \\frac{1-2p+2p^2 \\pm |1-2p|}{2p^2}$$\nThe percolation threshold is $p_c = 1/\\langle k-1 \\rangle = 1/G_1'(1) = 1/2$.\nFor $p > p_c = 1/2$, we have $|1-2p| = 2p-1$. We seek the solution $u < 1$.\nThe two solutions are:\n$$u_+ = \\frac{1-2p+2p^2 + (2p-1)}{2p^2} = \\frac{2p^2}{2p^2} = 1$$\n$$u_- = \\frac{1-2p+2p^2 - (2p-1)}{2p^2} = \\frac{2-4p+2p^2}{2p^2} = \\frac{p^2-2p+1}{p^2} = \\left(\\frac{p-1}{p}\\right)^2 = \\left(\\frac{1-p}{p}\\right)^2$$\nFor $p > 1/2$, we have $p > 1-p$, so $\\frac{1-p}{p} < 1$, which makes $u_- < 1$. This is the physically meaningful solution for the percolating phase. So, for $p>1/2$, $u = \\left(\\frac{1-p}{p}\\right)^2$.\n\nFinally, we find the closed-form expression for $S$:\n$$S = 1 - G_0(1-p+pu) = 1 - (1-p+pu)^3$$\nFrom the self-consistency equation, we have $u = (1-p+pu)^2$, which implies $1-p+pu = \\sqrt{u}$ (the positive root must be taken as probabilities are non-negative).\nSubstituting this into the expression for $S$:\n$$S = 1 - (\\sqrt{u})^3 = 1 - u^{3/2}$$\nNow, we substitute the expression for $u$ for $p>1/2$:\n$$S(p) = 1 - \\left[\\left(\\frac{1-p}{p}\\right)^2\\right]^{3/2} = 1 - \\left(\\frac{1-p}{p}\\right)^3$$\nThis is the expression for the GCC size for $p > 1/2$.\n\n### Final Evaluation\n\nWe are asked to evaluate $S$ for $p = \\frac{3}{4}$. Since $\\frac{3}{4} > \\frac{1}{2}$, a GCC exists.\n$$S\\left(\\frac{3}{4}\\right) = 1 - \\left(\\frac{1-\\frac{3}{4}}{\\frac{3}{4}}\\right)^3 = 1 - \\left(\\frac{\\frac{1}{4}}{\\frac{3}{4}}\\right)^3 = 1 - \\left(\\frac{1}{3}\\right)^3$$\n$$S = 1 - \\frac{1}{27} = \\frac{26}{27}$$",
            "answer": "$$\\boxed{\\frac{26}{27}}$$"
        },
        {
            "introduction": "Building on the foundational theory, this exercise applies the percolation framework to a critical question: how robust are networks to node removal? You will use the percolation threshold condition to analyze the dramatic difference between random failures and targeted attacks on scale-free networks, a common topology for many real-world systems. This practice reveals a key vulnerability in heterogeneous networks and demonstrates the predictive power of percolation theory in assessing system resilience .",
            "id": "4310614",
            "problem": "Consider a large network generated by the configuration model with $N$ nodes and a scale-free degree distribution $P(k)$ supported on integer degrees $k \\in [k_{\\min}, k_{\\max}]$, where $k_{\\min} \\geq 1$ and $k_{\\max} < \\infty$. Assume the continuum approximation for sums by integrals is valid and let the degree distribution be $P(k) = C k^{-\\gamma}$ with exponent $\\gamma = 3$ and normalization constant $C > 0$. Two node-removal strategies are applied to this network:\n\n- Random removal: each node is independently removed with probability $q$, and kept with probability $p = 1 - q$.\n- Degree-targeted removal: all nodes with degree $k \\geq K$ are removed for some threshold $K$, and nodes with degree $k < K$ are kept.\n\nStarting from first principles—specifically, the branching-process characterization of the giant component in the configuration model and the site-percolation criterion expressed in terms of the degree-dependent node retention probabilities—derive the condition for the percolation threshold under general degree-dependent removal, and then specialize it to both strategies above. For the random removal, determine the critical removed fraction $q_{c}$ that just fragments the network (eliminates the giant component). For the degree-targeted removal, determine the critical threshold $K_{c}$ that just fragments the network, and from it derive the critical removed fraction $f_{c}$.\n\nExpress your final answers in closed form as functions of $k_{\\min}$ and $k_{\\max}$, allowing special functions if needed, and using the continuum approximation. Report both threshold fractions in a single row, in the order: the degree-targeted critical removed fraction $f_{c}$, followed by the random-removal critical removed fraction $q_{c}$. No physical units are required. No rounding is required; provide exact expressions.",
            "solution": "The user wants to analyze the percolation threshold of a scale-free network under two different node removal strategies.\n\n### Step 1: Extract Givens\n- Network model: Configuration model with $N$ nodes.\n- Degree distribution: $P(k) = C k^{-\\gamma}$ for integers $k \\in [k_{\\min}, k_{\\max}]$, where $k_{\\min} \\geq 1$ and $k_{\\max} < \\infty$.\n- Degree exponent: $\\gamma = 3$.\n- Approximation: The continuum approximation for sums, $\\sum_k \\to \\int dk$, is valid.\n- Removal strategy 1 (Random): Each node is removed with probability $q$, kept with probability $p=1-q$.\n- Removal strategy 2 (Degree-targeted): All nodes with degree $k \\geq K$ are removed; nodes with $k < K$ are kept.\n- Task: Derive the general percolation condition, specialize it to find the critical removed fraction $q_c$ for random removal, and the critical threshold $K_c$ and corresponding critical removed fraction $f_c$ for targeted removal.\n- Output: Express $f_c$ and $q_c$ in closed form as functions of $k_{\\min}$ and $k_{\\max}$.\n\n### Step 2: Validate Using Extracted Givens\n- **Scientific Grounding**: The problem is well-grounded in the statistical mechanics of complex networks. The configuration model, scale-free distributions, percolation theory, and the branching process formalism are all standard and central concepts in this field.\n- **Well-Posed**: The problem is well-posed, providing all necessary information (the form of $P(k)$, the value of $\\gamma$, the degree a range) to derive the requested quantities. The objectives ($q_c$ and $f_c$) are clearly defined.\n- **Objective**: The problem is stated in precise, objective, and formal scientific language.\n- **Completeness**: The problem is self-contained. The constant $C$ is defined via normalization, and all other required quantities can be derived from the givens.\n- **Consistency and Feasibility**: The setup is a standard theoretical model, free of internal contradictions or scientifically implausible conditions.\n- **Conclusion**: The problem is valid and can be solved as stated.\n\n### Step 3: Derivation and Solution\n\n**General Percolation Criterion**\n\nThe existence of a giant component in the configuration model can be determined by analyzing a branching process on the network. A giant component exists if and only if the average number of outgoing edges from a node reached by traversing a random edge is greater than one. Let $\\phi(k)$ be the probability that a node of degree $k$ is kept in the network after a removal process.\n\nThe degree distribution is $P(k)$. The average degree is $\\langle k \\rangle = \\int k P(k) dk$.\nThe probability that a randomly chosen edge leads to a node of degree $k$ is given by the excess degree distribution, proportional to $k P(k)$. The normalized distribution is $\\frac{kP(k)}{\\langle k \\rangle}$.\n\nAfter reaching a node of degree $k$ (which is kept with probability $\\phi(k)$), there are $k-1$ other edges to branch out to. The average number of such new branches, which we denote by $B$, is:\n$$B = \\int_{k_{\\min}}^{k_{\\max}} (k-1) \\phi(k) \\frac{k P(k)}{\\langle k \\rangle} dk$$\nThe percolation threshold corresponds to the critical point where the giant component just disappears, which occurs when $B=1$. The criterion for the percolation threshold is therefore:\n$$ \\int_{k_{\\min}}^{k_{\\max}} k(k-1) \\phi(k) P(k) dk = \\langle k \\rangle = \\int_{k_{\\min}}^{k_{\\max}} k P(k) dk $$\nThis is the general condition we will use.\n\n**Network Properties for $P(k) = Ck^{-3}$**\n\nFirst, we determine the normalization constant $C$.\n$$ \\int_{k_{\\min}}^{k_{\\max}} P(k) dk = 1 \\implies C \\int_{k_{\\min}}^{k_{\\max}} k^{-3} dk = C \\left[ -\\frac{1}{2}k^{-2} \\right]_{k_{\\min}}^{k_{\\max}} = 1 $$\n$$ C \\left( \\frac{1}{2k_{\\min}^2} - \\frac{1}{2k_{\\max}^2} \\right) = 1 \\implies C = \\frac{2}{\\frac{1}{k_{\\min}^2} - \\frac{1}{k_{\\max}^2}} = \\frac{2 k_{\\min}^2 k_{\\max}^2}{k_{\\max}^2 - k_{\\min}^2} $$\nNext, we calculate the first moment (average degree) $\\langle k \\rangle$.\n$$ \\langle k \\rangle = \\int_{k_{\\min}}^{k_{\\max}} k P(k) dk = C \\int_{k_{\\min}}^{k_{\\max}} k^{-2} dk = C \\left[ -k^{-1} \\right]_{k_{\\min}}^{k_{\\max}} = C \\left( \\frac{1}{k_{\\min}} - \\frac{1}{k_{\\max}} \\right) $$\nSubstituting $C$:\n$$ \\langle k \\rangle = \\frac{2 k_{\\min}^2 k_{\\max}^2}{k_{\\max}^2 - k_{\\min}^2} \\frac{k_{\\max} - k_{\\min}}{k_{\\min} k_{\\max}} = \\frac{2 k_{\\min} k_{\\max} (k_{\\max}-k_{\\min})}{(k_{\\max}-k_{\\min})(k_{\\max}+k_{\\min})} = \\frac{2 k_{\\min} k_{\\max}}{k_{\\max} + k_{\\min}} $$\n\n**Strategy 1: Random Removal**\n\nFor random removal, a node is kept with probability $p = 1-q$, independently of its degree. Thus, $\\phi(k) = p$. Let $p_c$ be the critical retention probability. The percolation criterion becomes:\n$$ \\int_{k_{\\min}}^{k_{\\max}} k(k-1) p_c P(k) dk = \\langle k \\rangle $$\n$$ p_c \\left( \\int_{k_{\\min}}^{k_{\\max}} k^2 P(k) dk - \\int_{k_{\\min}}^{k_{\\max}} k P(k) dk \\right) = \\langle k \\rangle $$\n$$ p_c (\\langle k^2 \\rangle - \\langle k \\rangle) = \\langle k \\rangle \\implies p_c = \\frac{\\langle k \\rangle}{\\langle k^2 \\rangle - \\langle k \\rangle} $$\nWe need to calculate the second moment $\\langle k^2 \\rangle$:\n$$ \\langle k^2 \\rangle = \\int_{k_{\\min}}^{k_{\\max}} k^2 P(k) dk = C \\int_{k_{\\min}}^{k_{\\max}} k^{-1} dk = C \\left[ \\ln(k) \\right]_{k_{\\min}}^{k_{\\max}} = C \\ln\\left(\\frac{k_{\\max}}{k_{\\min}}\\right) $$\nThe critical removed fraction is $q_c = 1 - p_c = 1 - \\frac{1}{\\frac{\\langle k^2 \\rangle}{\\langle k \\rangle} - 1} = \\frac{\\frac{\\langle k^2 \\rangle}{\\langle k \\rangle} - 2}{\\frac{\\langle k^2 \\rangle}{\\langle k \\rangle} - 1}$.\nLet's compute the ratio $\\frac{\\langle k^2 \\rangle}{\\langle k \\rangle}$:\n$$ \\frac{\\langle k^2 \\rangle}{\\langle k \\rangle} = \\frac{C \\ln\\left(\\frac{k_{\\max}}{k_{\\min}}\\right)}{C \\left(\\frac{1}{k_{\\min}} - \\frac{1}{k_{\\max}}\\right)} = \\frac{\\ln\\left(\\frac{k_{\\max}}{k_{\\min}}\\right)}{\\frac{k_{\\max} - k_{\\min}}{k_{\\min}k_{\\max}}} = \\frac{k_{\\min}k_{\\max}}{k_{\\max}-k_{\\min}} \\ln\\left(\\frac{k_{\\max}}{k_{\\min}}\\right) $$\nSubstituting this into the expression for $q_c$:\n$$ q_c = \\frac{\\frac{k_{\\min}k_{\\max}}{k_{\\max}-k_{\\min}} \\ln\\left(\\frac{k_{\\max}}{k_{\\min}}\\right) - 2}{\\frac{k_{\\min}k_{\\max}}{k_{\\max}-k_{\\min}} \\ln\\left(\\frac{k_{\\max}}{k_{\\min}}\\right) - 1} $$\n\n**Strategy 2: Degree-Targeted Removal**\n\nFor degree-targeted removal, nodes with degree $k \\geq K$ are removed. The retention probability is $\\phi(k) = 1$ for $k < K$ and $\\phi(k) = 0$ for $k \\geq K$. The critical threshold $K_c$ is found by setting the upper limit of integration to $K_c$ in the left-hand side of the general criterion:\n$$ \\int_{k_{\\min}}^{K_c} k(k-1) P(k) dk = \\langle k \\rangle $$\n$$ C \\int_{k_{\\min}}^{K_c} (k^2-k) k^{-3} dk = C \\int_{k_{\\min}}^{K_c} (k^{-1} - k^{-2}) dk = C\\left(\\frac{1}{k_{\\min}} - \\frac{1}{k_{\\max}}\\right) $$\nThe constant $C$ cancels out.\n$$ \\left[ \\ln(k) + \\frac{1}{k} \\right]_{k_{\\min}}^{K_c} = \\frac{1}{k_{\\min}} - \\frac{1}{k_{\\max}} $$\n$$ \\left( \\ln(K_c) + \\frac{1}{K_c} \\right) - \\left( \\ln(k_{\\min}) + \\frac{1}{k_{\\min}} \\right) = \\frac{1}{k_{\\min}} - \\frac{1}{k_{\\max}} $$\n$$ \\ln(K_c) + \\frac{1}{K_c} = \\ln(k_{\\min}) + \\frac{2}{k_{\\min}} - \\frac{1}{k_{\\max}} $$\nThis is a transcendental equation for $K_c$. Let $A = \\ln(k_{\\min}) + \\frac{2}{k_{\\min}} - \\frac{1}{k_{\\max}}$ and $x=K_c$. The equation $x e^{1/x} = e^A$ can be solved using the Lambert W function, $W(z)$, defined by $W(z)e^{W(z)}=z$. The solution for $K_c$ that is greater than $1$ is given by the principal branch $W_0$:\n$$ K_c = -\\frac{1}{W_0\\left(-e^{-A}\\right)} = -\\frac{1}{W_0\\left(-\\exp\\left(-\\left(\\ln(k_{\\min}) + \\frac{2}{k_{\\min}} - \\frac{1}{k_{\\max}}\\right)\\right)\\right)} $$\nThis can be written as:\n$$ K_c = -\\left(W_0\\left(-\\frac{1}{k_{\\min}}\\exp\\left(\\frac{1}{k_{\\max}}-\\frac{2}{k_{\\min}}\\right)\\right)\\right)^{-1} $$\nThe critical fraction of removed nodes, $f_c$, is the integral of $P(k)$ over the removed degrees, i.e., from $K_c$ to $k_{\\max}$.\n$$ f_c = \\int_{K_c}^{k_{\\max}} P(k) dk = C \\int_{K_c}^{k_{\\max}} k^{-3} dk = C \\left[-\\frac{1}{2}k^{-2}\\right]_{K_c}^{k_{\\max}} = \\frac{C}{2}\\left(\\frac{1}{K_c^2} - \\frac{1}{k_{\\max}^2}\\right) $$\nRecalling that $1 = \\int_{k_{\\min}}^{k_{\\max}} P(k) dk = \\frac{C}{2}\\left(\\frac{1}{k_{\\min}^2} - \\frac{1}{k_{\\max}^2}\\right)$, we can write $f_c$ as:\n$$ f_c = \\frac{\\frac{1}{K_c^2} - \\frac{1}{k_{\\max}^2}}{\\frac{1}{k_{\\min}^2} - \\frac{1}{k_{\\max}^2}} = \\frac{K_c^{-2} - k_{\\max}^{-2}}{k_{\\min}^{-2} - k_{\\max}^{-2}} $$\nSubstituting the expression for $K_c^{-1}$:\n$$ K_c^{-1} = -W_0\\left(-\\frac{1}{k_{\\min}}\\exp\\left(\\frac{1}{k_{\\max}}-\\frac{2}{k_{\\min}}\\right)\\right) $$\nSo, $K_c^{-2} = \\left[W_0\\left(-\\frac{1}{k_{\\min}}\\exp\\left(\\frac{1}{k_{\\max}}-\\frac{2}{k_{\\min}}\\right)\\right)\\right]^2$.\nThe final expression for $f_c$ is:\n$$ f_c = \\frac{\\left[W_0\\left(-\\frac{1}{k_{\\min}}\\exp\\left(\\frac{1}{k_{\\max}}-\\frac{2}{k_{\\min}}\\right)\\right)\\right]^2 - k_{\\max}^{-2}}{k_{\\min}^{-2} - k_{\\max}^{-2}} $$\n\nThe final answer requires both fractions, $f_c$ and $q_c$.",
            "answer": "$$ \\boxed{\\begin{pmatrix} \\frac{\\left[W_0\\left(-\\frac{1}{k_{\\min}}\\exp\\left(\\frac{1}{k_{\\max}}-\\frac{2}{k_{\\min}}\\right)\\right)\\right]^2 - k_{\\max}^{-2}}{k_{\\min}^{-2} - k_{\\max}^{-2}} & \\frac{\\frac{k_{\\min}k_{\\max}}{k_{\\max}-k_{\\min}} \\ln\\left(\\frac{k_{\\max}}{k_{\\min}}\\right) - 2}{\\frac{k_{\\min}k_{\\max}}{k_{\\max}-k_{\\min}} \\ln\\left(\\frac{k_{\\max}}{k_{\\min}}\\right) - 1} \\end{pmatrix}} $$"
        },
        {
            "introduction": "Theoretical predictions are best understood when they can be verified through simulation, which is the focus of this practice. This hands-on coding exercise guides you through implementing an efficient simulation of bond percolation on a lattice using the classic union–find algorithm. You will measure key observables like the giant component fraction $P_\\infty$ and the susceptibility $\\chi$, allowing you to computationally witness the critical phenomena you have studied analytically .",
            "id": "4310671",
            "problem": "Design and implement a complete program that uses the Disjoint Set Union (DSU) data structure to identify connected components in bond percolation on a square lattice and computes two observables, the fraction in the largest connected component $P_\\infty$ and the susceptibility $\\chi$, as functions of the bond occupation probability $p$. Your program must be self-contained, must not read external input, and must produce a single line of output in the format specified below.\n\nBackground and fundamental base:\n- Consider an undirected graph $G = (V, E)$ where $V$ is a set of $|V| = N$ nodes and $E$ is a set of $|E| = M$ bonds (edges). In bond percolation, each bond in $E$ is independently active (present) with probability $p \\in [0,1]$, and inactive (absent) with probability $1 - p$.\n- A connected component is a maximal subset of $V$ such that each pair of nodes in the subset is connected by a path of active bonds. The Disjoint Set Union (DSU) data structure (also called the union–find data structure) maintains a partition of $V$ into disjoint sets representing connected components, supporting two operations: find (to retrieve the representative of a set) and union (to merge two sets).\n- The program must measure two standard percolation observables at specified values of $p$:\n  1. The fraction in the largest connected component $P_\\infty = s_{\\max} / N$, where $s_{\\max}$ is the size of the largest connected component.\n  2. The susceptibility $\\chi$, defined on a finite graph by excluding the largest connected component. Let $s_i$ be the sizes of all connected components, and let $s_{\\max}$ denote the largest. Then\n  $$\\chi = \\frac{\\sum_{i: s_i \\neq s_{\\max}} s_i^2}{\\sum_{i: s_i \\neq s_{\\max}} s_i}.$$\n  If there are no finite components (that is, if $s_{\\max} = N$), define $\\chi = 0$ by convention.\n- You must compute these observables for a monotone coupling of percolation configurations across $p$: generate a single random ordering of the bonds and activate them in that order. For a given $p$, let $k = \\lfloor p \\, M \\rfloor$ be the number of active bonds; then consider the subgraph formed by the first $k$ bonds in that order. This coupling ensures configurations are nested as $p$ increases.\n\nGraph model to use:\n- Use a bond-percolation model on a square lattice of linear size $L$. The node set $V$ is the set of lattice sites on an $L \\times L$ grid with open boundary conditions. The bond set $E$ contains nearest-neighbor horizontal and vertical bonds (no diagonals), so $M = 2 L (L - 1)$ and $N = L^2$.\n\nAlgorithmic requirements:\n- Implement DSU with path compression and union by size (or by rank). Maintain the size of each component so that $s_{\\max}$ can be updated in $\\mathcal{O}(1)$ on each union. Also maintain the sum of squares of component sizes,\n  $$S_2 = \\sum_i s_i^2,$$\n  and update $S_2$ in $\\mathcal{O}(1)$ when two components of sizes $a$ and $b$ are merged, using the identity\n  $$(a + b)^2 - a^2 - b^2 = 2ab.$$\n  Then compute\n  $$P_\\infty = \\frac{s_{\\max}}{N}, \\quad \\chi = \\begin{cases}\n  \\dfrac{S_2 - s_{\\max}^2}{N - s_{\\max}}, & \\text{if } s_{\\max} \\neq N,\\\\\n  0, & \\text{if } s_{\\max} = N.\n  \\end{cases}$$\n- For each test case, generate a single random permutation of all $M$ bonds using a pseudo-random number generator initialized with the specified seed, and activate bonds incrementally according to the permutation up to each checkpoint $p$.\n\nTest suite:\nYour program must compute the observables for the following test cases. For each case, the list of $p$ values is in nondecreasing order.\n- Test case $1$: $L = 16$, seed $= 12345$, checkpoints $p \\in [0.0, 0.2, 0.4, 0.5, 0.6, 0.8, 1.0]$.\n- Test case $2$: $L = 32$, seed $= 2024$, checkpoints $p \\in [0.0, 0.48, 0.5, 0.52, 1.0]$.\n- Test case $3$: $L = 8$, seed $= 7$, checkpoints $p \\in [0.0, 1.0]$.\n- Test case $4$: $L = 24$, seed $= 99$, checkpoints $p \\in [0.3, 0.7]$.\n\nFinal output format:\n- Your program must produce a single line containing a list, where each element corresponds to one test case, in the same order as listed above.\n- For each test case, output a two-element list: the first element is the list of $P_\\infty$ values at the specified checkpoints (in the same order as the checkpoint list), and the second element is the list of $\\chi$ values at those checkpoints.\n- The overall output must therefore be a list of lists of lists of floating-point numbers, with the exact shape\n  $$\\big[ [ [P_{\\infty,1}(p_1), \\dots], [\\chi_1(p_1), \\dots] ],\\ \\dots\\ \\big].$$\n- The output must be printed as a single line, as a comma-separated list enclosed in square brackets, with no additional text. Angles and physical units are not involved; all numerical outputs are real numbers (floating-point) without units.",
            "solution": "The user wants a program to simulate bond percolation on a 2D square lattice and compute key observables.\n\n### Problem Validation\nI have performed a thorough validation of the problem statement.\n- **Extracted Givens**:\n    - Model: Bond percolation on an $L \\times L$ square lattice with open boundaries.\n    - Nodes: $N = L^2$.\n    - Bonds: $M = 2L(L-1)$ nearest-neighbor bonds.\n    - Process: Monotone coupling where bonds are added incrementally from a single random permutation. The number of active bonds is $k = \\lfloor pM \\rfloor$.\n    - Observables:\n        1. Fraction in largest component, $P_\\infty = s_{\\max} / N$.\n        2. Susceptibility, $\\chi = \\frac{\\sum_{i: s_i \\neq s_{\\max}} s_i^2}{\\sum_{i: s_i \\neq s_{\\max}} s_i}$, with the provided computational formula $\\chi = \\frac{S_2 - s_{\\max}^2}{N - s_{\\max}}$ for $s_{\\max} < N$ and $\\chi=0$ for $s_{\\max} = N$.\n    - Algorithm: Disjoint Set Union (DSU) with path compression and union by size. O(1) updates for $s_{\\max}$ and $S_2 = \\sum_i s_i^2$.\n    - Test Cases: Four specific cases are given with parameters $L$, `seed`, and checkpoint probabilities $p$.\n    - Output: A single-line string representation of a list containing the results for each test case.\n- **Validation Verdict**: The problem is **valid**. It is scientifically sound, well-posed, objective, complete, and computationally feasible. The model and observables are standard in statistical physics, and the specified algorithm is the canonical method for this type of simulation. The test cases are well-defined.\n\n### Solution Design\n\nThe solution will be a Python program that implements the simulation as specified. The core of the program will be a function that executes one test case, with helper structures to manage the percolation process.\n\n**1. Lattice and Bonds**\nFor a given linear size $L$, the lattice consists of $N=L^2$ sites, which we can index from $0$ to $N-1$. A site at coordinate $(r, c)$ (where $0 \\le r, c < L$) is mapped to the index $i = r \\cdot L + c$. The $M=2L(L-1)$ possible bonds (horizontal and vertical) between nearest neighbors are generated and stored in a list. A pseudo-random number generator, seeded for reproducibility, is used to create a single random permutation of these bonds. This permutation dictates the order in which bonds are activated.\n\n**2. Disjoint Set Union (DSU) Data Structure**\nTo efficiently track the connected components of the graph as bonds are added, we will implement a DSU data structure. This structure will maintain a partition of the $N$ sites into disjoint sets. Our implementation will:\n- Use a `parent` array, where `parent[i]` stores the parent of site $i$. A component is identified by its root, a site $i$ for which `parent[i] == i`.\n- Implement the **find** operation with **path compression**. This operation finds the root of the component containing a given site and flattens the tree structure along the way, leading to significant long-term speedup.\n- Use a `comp_size` array, where `comp_size[i]` stores the number of sites in the component if $i$ is a root.\n- The **union** operation will be performed using the **union by size** heuristic: when merging two components, the root of the smaller component is always attached to the root of the larger one. This keeps the trees shallow.\n\n**3. Simulation via Monotone Coupling**\nThe simulation proceeds incrementally. We iterate through the sorted list of checkpoint probabilities $p$. For each $p$, we determine the total number of bonds to be active, $k = \\lfloor pM \\rfloor$. We then add bonds from the permuted list, starting from where the previous step left off, until $k$ bonds are active.\n\nFor each bond $(u, v)$ added:\n- We find the roots of the components containing sites $u$ and $v$.\n- If the roots are different, the sites are in different components, and a merger is required. We perform a union operation.\n- Let the sizes of the two components being merged be $s_a$ and $s_b$. The new component will have size $s_a+s_b$. This event triggers updates to our global observables.\n\n**4. Observable Calculation**\nTo compute $P_\\infty$ and $\\chi$ efficiently, we maintain three global quantities throughout the simulation:\n- $N$: The total number of sites, a constant ($L^2$).\n- $s_{\\max}$: The size of the largest connected component. Initially, all sites are in components of size $1$, so $s_{\\max}^{(0)} = 1$.\n- $S_2$: The sum of the squares of all component sizes, $S_2 = \\sum_i s_i^2$. Initially, $S_2^{(0)} = \\sum_{i=1}^{N} 1^2 = N$.\n\nWhen two components of size $s_a$ and $s_b$ merge, these quantities are updated in $\\mathcal{O}(1)$ time:\n- The new size is $s_{new} = s_a+s_b$.\n- The new largest component size is $s'_{\\max} = \\max(s_{\\max}, s_{new})$.\n- The sum of squares is updated using the identity $(s_a+s_b)^2 - s_a^2 - s_b^2 = 2s_as_b$. The new sum is $S'_2 = S_2 - s_a^2 - s_b^2 + (s_a+s_b)^2 = S_2 + 2s_as_b$.\n\nAfter adding the required number of bonds for a given checkpoint $p$, the observables are calculated as:\n- $P_\\infty(p) = \\frac{s_{\\max}}{N}$\n- $\\chi(p) = \\begin{cases} \\frac{S_2 - s_{\\max}^2}{N - s_{\\max}} & \\text{if } s_{\\max} < N \\\\ 0 & \\text{if } s_{\\max} = N \\end{cases}$\n\nThis incremental approach is highly efficient, as we process the entire set of checkpoints for a given lattice in a single pass over the bonds. The overall complexity for a single test case with $C$ checkpoints is dominated by the bond-processing loop, roughly $\\mathcal{O}(M \\alpha(N) + C)$, where $\\alpha(N)$ is the extremely slow-growing inverse Ackermann function arising from the DSU operations.",
            "answer": "```python\nimport numpy as np\n\nclass DSU:\n    \"\"\"A Disjoint Set Union data structure with path compression and union by size.\"\"\"\n    def __init__(self, n):\n        # parent[i] is the parent of site i\n        self.parent = np.arange(n)\n        # comp_size[i] is the size of the component if i is a root\n        self.comp_size = np.ones(n, dtype=np.int64)\n\n    def find(self, i):\n        \"\"\"Finds the root of the component containing site i, with path compression.\"\"\"\n        if self.parent[i] == i:\n            return i\n        self.parent[i] = self.find(self.parent[i])\n        return self.parent[i]\n\ndef run_percolation_simulation(L, seed, p_checkpoints):\n    \"\"\"\n    Runs a bond percolation simulation on an L x L grid.\n\n    Args:\n        L (int): The linear size of the square lattice.\n        seed (int): The seed for the pseudo-random number generator.\n        p_checkpoints (list of float): A non-decreasing list of bond occupation\n                                       probabilities at which to measure observables.\n\n    Returns:\n        list: A list containing two lists:\n              1. A list of P_infinity values for each checkpoint.\n              2. A list of chi values for each checkpoint.\n    \"\"\"\n    N = L * L\n    if L <= 1:\n        M = 0\n    else:\n        M = 2 * L * (L - 1)\n\n    # 1. Generate all possible bonds on the L x L grid\n    bonds = []\n    # Horizontal bonds\n    for r in range(L):\n        for c in range(L - 1):\n            u = r * L + c\n            v = r * L + (c + 1)\n            bonds.append((u, v))\n    # Vertical bonds\n    for r in range(L - 1):\n        for c in range(L):\n            u = r * L + c\n            v = (r + 1) * L + c\n            bonds.append((u, v))\n\n    # 2. Create a single random permutation of bonds for monotone coupling\n    rng = np.random.default_rng(seed)\n    permuted_bonds = rng.permutation(bonds, axis=0)\n\n    # 3. Initialize DSU and observable trackers\n    dsu = DSU(N)\n    \n    # Track sum of squares of component sizes (S2) and max component size (s_max)\n    # Initially N components of size 1.\n    S2 = float(N) if N > 0 else 0.0\n    s_max = 1 if N > 0 else 0\n\n    results_P_inf = []\n    results_chi = []\n    \n    current_bond_idx = 0\n\n    # 4. Monotonically add bonds and compute observables at checkpoints\n    for p in p_checkpoints:\n        target_num_bonds = int(p * M)\n        \n        while current_bond_idx < target_num_bonds:\n            u, v = permuted_bonds[current_bond_idx]\n            \n            root_u = dsu.find(u)\n            root_v = dsu.find(v)\n            \n            if root_u != root_v:\n                size_u = dsu.comp_size[root_u]\n                size_v = dsu.comp_size[root_v]\n                \n                # Union by size: attach smaller tree to larger tree's root\n                if size_u < size_v:\n                    root_u, root_v = root_v, root_u\n                    size_u, size_v = size_v, size_u\n                \n                dsu.parent[root_v] = root_u\n                new_size = size_u + size_v\n                dsu.comp_size[root_u] = new_size\n                \n                # Update observables in O(1)\n                S2 += 2 * size_u * size_v\n                s_max = max(s_max, new_size)\n            \n            current_bond_idx += 1\n            \n        # 5. Calculate and store observables for the current checkpoint\n        if N == 0:\n            P_inf = 0.0\n            chi = 0.0\n        else:\n            P_inf = s_max / N\n            if s_max == N:\n                chi = 0.0\n            else:\n                chi = (S2 - s_max**2) / (N - s_max)\n                \n        results_P_inf.append(P_inf)\n        results_chi.append(chi)\n        \n    return [results_P_inf, results_chi]\n\ndef solve():\n    \"\"\"\n    Defines and runs the test suite for the percolation simulation,\n    then prints the results in the required format.\n    \"\"\"\n    test_cases = [\n        {'L': 16, 'seed': 12345, 'p_checkpoints': [0.0, 0.2, 0.4, 0.5, 0.6, 0.8, 1.0]},\n        {'L': 32, 'seed': 2024, 'p_checkpoints': [0.0, 0.48, 0.5, 0.52, 1.0]},\n        {'L': 8, 'seed': 7, 'p_checkpoints': [0.0, 1.0]},\n        {'L': 24, 'seed': 99, 'p_checkpoints': [0.3, 0.7]},\n    ]\n\n    results = []\n    for case in test_cases:\n        result_for_case = run_percolation_simulation(\n            case['L'], case['seed'], case['p_checkpoints']\n        )\n        results.append(result_for_case)\n\n    # Format the final output string exactly as required\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        }
    ]
}