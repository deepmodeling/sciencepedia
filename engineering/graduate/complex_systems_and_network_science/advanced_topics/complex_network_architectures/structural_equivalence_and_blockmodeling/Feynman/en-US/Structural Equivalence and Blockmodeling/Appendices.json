{
    "hands_on_practices": [
        {
            "introduction": "The foundation of blockmodeling lies in partitioning nodes into roles or positions based on their network connections. Before we can group nodes, we must be precise about what it means for them to be 'equivalent'. This exercise challenges you to contrast two of the most important definitions in network analysis: the strict criterion of structural equivalence and the more flexible concept of regular (or role) equivalence. Understanding this distinction is the first step toward building and interpreting meaningful blockmodels. By analyzing a small, intuitive hierarchy, you will learn to identify nodes that are perfectly interchangeable versus those that simply occupy similar social roles .",
            "id": "4305895",
            "problem": "Consider a directed network intended to represent hierarchical interaction roles. Let the node set be $V=\\{d, m_1, m_2, e_1, e_2, e_3\\}$, and let edges represent a unidirectional relation from a superior to a subordinate. The edge set is\n$$\nE=\\{(d,m_1),(d,m_2),(m_1,e_1),(m_1,e_2),(m_2,e_3)\\}.\n$$\nNo other edges exist. You are to contrast structural equivalence with role (regular) equivalence on this network. Which of the following statements best identifies a pair of nodes that are regularly equivalent but not structurally equivalent in this network, and correctly explains how their neighborhoods differ?\n\nA. Nodes $e_1$ and $e_3$ are structurally equivalent because each has an in-neighbor that is a manager and no out-neighbors; therefore they are also regularly equivalent, and there is no difference to explain in their neighborhoods.\n\nB. Nodes $e_1$ and $e_3$ are regularly equivalent but not structurally equivalent; each receives an edge from a manager and has no out-neighbors, but their neighborhoods differ because the identities of their in-neighbors are distinct ($\\{m_1\\}$ for $e_1$ versus $\\{m_2\\}$ for $e_3$) even though those in-neighbors occupy the same role class.\n\nC. Nodes $d$ and $e_1$ are regularly equivalent because both are adjacent to at least one manager, and they are not structurally equivalent because $d$ has more neighbors; the difference in their neighborhoods is only the number of alters.\n\nD. Nodes $m_1$ and $m_2$ are not regularly equivalent because $m_1$ has out-edges to $e_1$ and $e_2$ while $m_2$ has an out-edge only to $e_3$; for regular equivalence to hold, the exact counts and identities of neighbors must match, so their neighborhoods differ in a way that precludes both structural and regular equivalence.",
            "solution": "To solve this problem, we must first define structural and regular equivalence and then apply these definitions to the given network.\n\n**1. Definitions of Equivalence**\n\n-   **Structural Equivalence**: Two nodes, $u$ and $v$, in a directed network are structurally equivalent if and only if they have the exact same set of in-neighbors and the exact same set of out-neighbors. Let $N_{in}(x)$ be the set of nodes with an edge to node $x$, and $N_{out}(x)$ be the set of nodes to which $x$ has an edge. Then, $u$ and $v$ are structurally equivalent if $N_{in}(u) = N_{in}(v)$ and $N_{out}(u) = N_{out}(v)$. This is the most stringent form of equivalence.\n\n-   **Regular (Role) Equivalence**: Two nodes, $u$ and $v$, are regularly equivalent if they have the same \"role\" in the network structure. Formally, this means that their neighbors belong to the same regular equivalence classes. If we partition the set of nodes $V$ into equivalence classes $\\{C_1, C_2, ..., C_k\\}$, then two nodes $u, v \\in C_i$ are regularly equivalent if for every class $C_j$:\n    1.  There is an edge from a node in $C_j$ to $u$ if and only if there is an edge from a node in $C_j$ to $v$.\n    2.  There is an edge from $u$ to a node in $C_j$ if and only if there is an edge from $v$ to a node in $C_j$.\n    Essentially, regularly equivalent nodes are connected to the same types of nodes, even if not the exact same nodes.\n\n**2. Network Analysis**\n\nFirst, let's list the in-neighborhoods and out-neighborhoods for each node in the network:\n-   $N_{in}(d) = \\emptyset$, $N_{out}(d) = \\{m_1, m_2\\}$\n-   $N_{in}(m_1) = \\{d\\}$, $N_{out}(m_1) = \\{e_1, e_2\\}$\n-   $N_{in}(m_2) = \\{d\\}$, $N_{out}(m_2) = \\{e_3\\}$\n-   $N_{in}(e_1) = \\{m_1\\}$, $N_{out}(e_1) = \\emptyset$\n-   $N_{in}(e_2) = \\{m_1\\}$, $N_{out}(e_2) = \\emptyset$\n-   $N_{in}(e_3) = \\{m_2\\}$, $N_{out}(e_3) = \\emptyset$\n\n**3. Identifying Equivalence Classes**\n\n-   **Structural Equivalence Classes**:\n    We search for pairs of nodes with identical in- and out-neighborhoods.\n    -   Comparing $e_1$ and $e_2$: $N_{in}(e_1) = \\{m_1\\}$ and $N_{in}(e_2) = \\{m_1\\}$. $N_{out}(e_1) = \\emptyset$ and $N_{out}(e_2) = \\emptyset$. Since both neighborhoods are identical, $e_1$ and $e_2$ are structurally equivalent.\n    -   Comparing $m_1$ and $m_2$: Their out-neighborhoods are not identical ($N_{out}(m_1) = \\{e_1, e_2\\}$ vs. $N_{out}(m_2) = \\{e_3\\}$), so they are not structurally equivalent.\n    -   Comparing $e_1$ and $e_3$: Their in-neighborhoods are not identical ($N_{in}(e_1) = \\{m_1\\}$ vs. $N_{in}(e_3) = \\{m_2\\}$), so they are not structurally equivalent.\n\n-   **Regular Equivalence Classes**:\n    We seek a partition of $V$ that satisfies the definition. Let us hypothesize a partition based on the intuitive roles:\n    -   $C_D = \\{d\\}$ (the director)\n    -   $C_M = \\{m_1, m_2\\}$ (the managers)\n    -   $C_E = \\{e_1, e_2, e_3\\}$ (the employees)\n    Now, let's verify this partition:\n    -   **Class $C_M = \\{m_1, m_2\\}$**: Are $m_1$ and $m_2$ regularly equivalent? Yes. Both receive a tie from a node in class $C_D$ and send ties to nodes in class $C_E$.\n    -   **Class $C_E = \\{e_1, e_2, e_3\\}$**: Are these nodes regularly equivalent? Yes. All of them receive a tie from a node in class $C_M$ and have no outgoing ties.\n    -   The partition $\\{C_D, C_M, C_E\\}$ is a valid regular equivalence partition.\n\n-   **Summary**:\n    -   A pair that is regularly equivalent but not structurally equivalent is $(e_1, e_3)$. Another is $(m_1, m_2)$.\n\n### Option-by-Option Analysis\n\n**A. Nodes $e_1$ and $e_3$ are structurally equivalent...**\nThis is false. As shown above, their in-neighbors are different ($m_1$ vs. $m_2$).\n**Verdict: Incorrect.**\n\n**B. Nodes $e_1$ and $e_3$ are regularly equivalent but not structurally equivalent; each receives an edge from a manager and has no out-neighbors, but their neighborhoods differ because the identities of their in-neighbors are distinct ($\\{m_1\\}$ for $e_1$ versus $\\{m_2\\}$ for $e_3$) even though those in-neighbors occupy the same role class.**\nThis statement correctly identifies that $e_1$ and $e_3$ are regularly equivalent but not structurally equivalent. The explanation is also perfect: structural equivalence fails because their in-neighbors are different nodes, but regular equivalence holds because those in-neighbors ($m_1, m_2$) belong to the same role class ($C_M$).\n**Verdict: Correct.**\n\n**C. Nodes $d$ and $e_1$ are regularly equivalent...**\nThis is false. They are in different role classes ($C_D$ and $C_E$). For instance, $d$ has out-neighbors while $e_1$ does not.\n**Verdict: Incorrect.**\n\n**D. Nodes $m_1$ and $m_2$ are not regularly equivalent...**\nThis is false. As shown, $m_1$ and $m_2$ are regularly equivalent. The option incorrectly states that \"exact counts and identities of neighbors must match\" for regular equivalence, which is the definition of structural equivalence.\n**Verdict: Incorrect.**",
            "answer": "$$\\boxed{B}$$"
        },
        {
            "introduction": "In real-world networks, perfect structural equivalence is rare. This prompts us to consider whether we can use statistical similarity measures to find 'approximately' equivalent nodes. This practice explores that very question by pitting the strict, formal definition of structural equivalence against a common statistical tool: the Pearson correlation coefficient. You will calculate the correlation between the connection profiles of two nodes and critically evaluate whether a high correlation score is sufficient to declare them structurally equivalent. This exercise highlights the crucial difference between continuous measures of similarity and the absolute, discrete nature of formal network equivalence, clarifying why specialized blockmodeling criteria are essential .",
            "id": "4305881",
            "problem": "Consider a binary directed network on five nodes with no self-loops. Let the adjacency matrix be\n$$\nA=\\begin{pmatrix}\n0 & 1 & 1 & 0 & 0 \\\\\n1 & 0 & 1 & 0 & 1 \\\\\n1 & 1 & 0 & 0 & 0 \\\\\n0 & 1 & 0 & 0 & 1 \\\\\n1 & 0 & 1 & 0 & 0\n\\end{pmatrix},\n$$\nwhere the entry $A_{ij}=1$ indicates a directed tie from node $i$ to node $j$, and $A_{ij}=0$ indicates no tie. In the theory of structural equivalence and blockmodeling, two nodes are structurally equivalent if and only if they have identical ties to all other nodes and identical ties received from all other nodes. Define the adjacency profile of node $i$ to be the length-$10$ vector\n$$\n\\mathbf{x}^{(i)}=\\big(A_{i1},A_{i2},A_{i3},A_{i4},A_{i5},A_{1i},A_{2i},A_{3i},A_{4i},A_{5i}\\big),\n$$\nwhich concatenates the outgoing ties from node $i$ (its row in $A$) and incoming ties to node $i$ (its column in $A$). Starting from the core definition of structural equivalence and the standard definition of the Pearson correlation coefficient (PCC), compute the PCC between the adjacency profiles of nodes $2$ and $5$. Then, using first principles, interpret whether a high PCC necessarily implies structural equivalence in this context, explicitly linking your reasoning to the definitions provided. Express the final PCC value as an exact number; no rounding is required, and no units are required for the answer.",
            "solution": "This problem requires computing the Pearson correlation coefficient (PCC) between the adjacency profiles of nodes 2 and 5, and then interpreting the result in the context of the formal definition of structural equivalence.\n\n### 1. Computation of the Pearson Correlation Coefficient (PCC)\n\nFirst, we construct the adjacency profiles for nodes 2 and 5. The adjacency profile for node $i$, $\\mathbf{x}^{(i)}$, is the concatenation of the $i$-th row and $i$-th column of the adjacency matrix $A$.\n\nThe given adjacency matrix is:\n$$\nA=\\begin{pmatrix}\n0 & 1 & 1 & 0 & 0 \\\\\n1 & 0 & 1 & 0 & 1 \\\\\n1 & 1 & 0 & 0 & 0 \\\\\n0 & 1 & 0 & 0 & 1 \\\\\n1 & 0 & 1 & 0 & 0\n\\end{pmatrix}\n$$\nFor node 2, we take row 2 $(1, 0, 1, 0, 1)$ and column 2 $(1, 0, 1, 1, 0)^T$. The profile is:\n$$\n\\mathbf{x}^{(2)} = (1, 0, 1, 0, 1, 1, 0, 1, 1, 0)\n$$\nFor node 5, we take row 5 $(1, 0, 1, 0, 0)$ and column 5 $(0, 1, 0, 1, 0)^T$. The profile is:\n$$\n\\mathbf{x}^{(5)} = (1, 0, 1, 0, 0, 0, 1, 0, 1, 0)\n$$\nThe Pearson correlation coefficient $\\rho$ for two vectors $X$ and $Y$ is $\\rho_{X,Y} = \\frac{\\text{cov}(X,Y)}{\\sigma_X \\sigma_Y}$. We first calculate the means:\n$$\n\\bar{x}^{(2)} = \\frac{1}{10}(1+0+1+0+1+1+0+1+1+0) = \\frac{6}{10} = 0.6\n$$\n$$\n\\bar{x}^{(5)} = \\frac{1}{10}(1+0+1+0+0+0+1+0+1+0) = \\frac{4}{10} = 0.4\n$$\nThe numerator is the sum of products of centered variables, $\\sum_{k=1}^{10} (x_k^{(2)} - \\bar{x}^{(2)})(x_k^{(5)} - \\bar{x}^{(5)})$:\n$$\n\\text{Numerator} = 3(1-0.6)(1-0.4) + 3(1-0.6)(0-0.4) + 1(0-0.6)(1-0.4) + 3(0-0.6)(0-0.4)\n$$\n$$\n= 3(0.24) + 3(-0.16) + 1(-0.36) + 3(0.24) = 0.72 - 0.48 - 0.36 + 0.72 = 0.6\n$$\nThe denominator terms are the square roots of the sum of squared deviations. For binary vectors, this is $\\sum (x_k - \\bar{x})^2 = n\\bar{x}(1-\\bar{x})$:\n$$\n\\sum (x_k^{(2)} - \\bar{x}^{(2)})^2 = 10(0.6)(1-0.6) = 2.4\n$$\n$$\n\\sum (x_k^{(5)} - \\bar{x}^{(5)})^2 = 10(0.4)(1-0.4) = 2.4\n$$\nFinally, the PCC is:\n$$\n\\rho = \\frac{0.6}{\\sqrt{2.4} \\sqrt{2.4}} = \\frac{0.6}{2.4} = \\frac{1}{4}\n$$\n\n### 2. Interpretation\n\nStructural equivalence is a strict, binary condition: two nodes are structurally equivalent if and only if their adjacency profiles are identical. If two profiles $\\mathbf{x}^{(i)}$ and $\\mathbf{x}^{(j)}$ are identical (and not constant), their Pearson correlation is exactly $1$.\n\nConversely, a PCC of less than $1$ means the profiles are not identical. Therefore, the nodes are not structurally equivalent. A high PCC (e.g., 0.99) indicates a high degree of similarity in connection patterns, but it does not satisfy the strict definition of structural equivalence. In this case, the PCC of $0.25$ indicates a low level of similarity, and since it is not $1$, nodes $2$ and $5$ are definitively not structurally equivalent. The PCC is a measure of similarity, whereas structural equivalence is a condition of identity.",
            "answer": "$$\n\\boxed{\\frac{1}{4}}\n$$"
        },
        {
            "introduction": "Identifying the best partition of a network into structurally coherent blocks is a computationally intensive task, generally classified as an NP-hard problem. Therefore, researchers rely on heuristic optimization algorithms to find high-quality, though not guaranteed to be perfect, solutions. This advanced practice guides you through the implementation of a powerful and widely used metaheuristic: Tabu Search. You will develop an algorithm that iteratively improves a partition by moving nodes between blocks to minimize an error criterion, which quantifies the misfit between the observed network and an idealized block structure. Implementing this strategy provides direct, hands-on experience with the algorithmic engine of blockmodeling, moving from theoretical concepts to a practical method for discovering latent structure in complex networks .",
            "id": "4305864",
            "problem": "Consider an undirected, simple graph on $n$ nodes represented by a binary adjacency matrix $A \\in \\{0,1\\}^{n \\times n}$ with $A$ symmetric and $A_{ii} = 0$ for all $i$. A blockmodel partitions nodes into $K$ positions. Let $\\pi : \\{1,\\dots,n\\} \\to \\{1,\\dots,K\\}$ be a partition function assigning each node to a block. An ideal image matrix $M \\in \\{0,1\\}^{K \\times K}$ specifies, for each ordered block pair $(r,s)$, whether the ideal relation between blocks $r$ and $s$ is $1$ (complete) or $0$ (null). The generalized blockmodeling criterion $E(A,\\pi,M)$ is defined as the total number of mismatches between observed ties and ideal ties across all ordered node pairs, that is,\n$$\nE(A,\\pi,M) = \\sum_{i=1}^{n}\\sum_{\\substack{j=1 \\\\ j \\neq i}}^{n} \\left| A_{ij} - M_{\\pi(i), \\pi(j)} \\right|.\n$$\nThis criterion penalizes every deviation from the ideal image: a $0$ inside a complete block-region and a $1$ inside a null block-region each contribute $1$ to the sum.\n\nYour task is to implement a heuristic search strategy that uses greedy local moves under Tabu search (TS) to minimize $E(A,\\pi,M)$. Start from an initial partition $\\pi^{(0)}$. At each iteration, consider local moves that reassign a single node $u$ from its current block $r = \\pi(u)$ to a different target block $t \\in \\{1,\\dots,K\\} \\setminus \\{r\\}$. For each candidate move, evaluate the change in the criterion $\\Delta E$ induced by performing the move, without recomputing $E$ from scratch. The search should:\n- Evaluate moves by exact $\\Delta E$ computed from the definition of $E$.\n- Use a Tabu list with tenure $\\tau$. After a node $u$ is moved from block $r$ to block $t$, the reverse move of reassigning $u$ to $r$ is forbidden for $\\tau$ iterations.\n- Employ the standard Aspiration Criterion: allow a tabu move if it yields an objective strictly better than the best seen so far.\n- At each iteration, select the admissible move that yields the smallest post-move objective $E_{\\text{new}} = E_{\\text{current}} + \\Delta E$; break ties deterministically by the smallest $\\Delta E$, then by lexicographically smallest $(u,t)$.\n- Terminate when either no admissible move exists or a fixed iteration budget $T$ is exhausted.\n\nFrom first principles, derive how to compute $\\Delta E$ for a single-node reassignment using only the local row and column of $A$ for that node and the corresponding entries of $M$. Clearly state the acceptance rule and how Tabu status and Aspiration override are determined.\n\nImplement the algorithm and apply it to the following test suite. In every case below, $A$ is symmetric and all listed $M$ are symmetric.\n\nTest case $1$ (community-like structure):\n- $n = 8$, $K = 2$,\n- $$A_1 = \\begin{bmatrix}\n0 & 1 & 1 & 1 & 0 & 0 & 0 & 0 \\\\\n1 & 0 & 1 & 1 & 0 & 0 & 0 & 0 \\\\\n1 & 1 & 0 & 1 & 0 & 0 & 0 & 0 \\\\\n1 & 1 & 1 & 0 & 0 & 0 & 0 & 0 \\\\\n0 & 0 & 0 & 0 & 0 & 1 & 1 & 1 \\\\\n0 & 0 & 0 & 0 & 1 & 0 & 1 & 1 \\\\\n0 & 0 & 0 & 0 & 1 & 1 & 0 & 1 \\\\\n0 & 0 & 0 & 0 & 1 & 1 & 1 & 0\n\\end{bmatrix},\\quad M_1 = \\begin{bmatrix} 1 & 0 \\\\ 0 & 1 \\end{bmatrix},\\quad \\pi^{(0)}_1 = [0,0,1,1,0,0,1,1],\\quad T = 50,\\quad \\tau = 5.$$\n\nTest case $2$ (single-block boundary):\n- $n = 5$, $K = 1$,\n- $$A_2 = \\begin{bmatrix}\n0 & 0 & 0 & 0 & 0 \\\\\n0 & 0 & 0 & 0 & 0 \\\\\n0 & 0 & 0 & 0 & 0 \\\\\n0 & 0 & 0 & 0 & 0 \\\\\n0 & 0 & 0 & 0 & 0\n\\end{bmatrix},\\quad M_2 = \\begin{bmatrix} 1 \\end{bmatrix},\\quad \\pi^{(0)}_2 = [0,0,0,0,0],\\quad T = 10,\\quad \\tau = 3.$$\n\nTest case $3$ (bipartite-like structure):\n- $n = 6$, $K = 2$,\n- $$A_3 = \\begin{bmatrix}\n0 & 0 & 0 & 1 & 1 & 1 \\\\\n0 & 0 & 0 & 1 & 1 & 1 \\\\\n0 & 0 & 0 & 1 & 1 & 1 \\\\\n1 & 1 & 1 & 0 & 0 & 0 \\\\\n1 & 1 & 1 & 0 & 0 & 0 \\\\\n1 & 1 & 1 & 0 & 0 & 0\n\\end{bmatrix},\\quad M_3 = \\begin{bmatrix} 0 & 1 \\\\ 1 & 0 \\end{bmatrix},\\quad \\pi^{(0)}_3 = [0,1,0,1,0,1],\\quad T = 50,\\quad \\tau = 4.$$\n\nTest case $4$ (ambiguous boundary requiring Tabu avoidance):\n- $n = 7$, $K = 2$,\n- $$A_4 = \\begin{bmatrix}\n0 & 1 & 1 & 1 & 0 & 0 & 0 \\\\\n1 & 0 & 1 & 1 & 0 & 0 & 0 \\\\\n1 & 1 & 0 & 0 & 0 & 0 & 0 \\\\\n1 & 1 & 0 & 0 & 1 & 1 & 0 \\\\\n0 & 0 & 0 & 1 & 0 & 1 & 1 \\\\\n0 & 0 & 0 & 1 & 1 & 0 & 1 \\\\\n0 & 0 & 0 & 0 & 1 & 1 & 0\n\\end{bmatrix},\\quad M_4 = \\begin{bmatrix} 1 & 0 \\\\ 0 & 1 \\end{bmatrix},\\quad \\pi^{(0)}_4 = [0,0,0,1,1,1,1],\\quad T = 100,\\quad \\tau = 7.$$\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets. For each test case, the result must be a list of the final objective value and the final partition, that is, $[\\text{objective},[\\text{labels}]]$. The overall output must therefore be of the form\n$$\n[\\,[E_1,[\\pi_1]],\\,[E_2,[\\pi_2]],\\,[E_3,[\\pi_3]],\\,[E_4,[\\pi_4]]\\,],\n$$\nwhere each $E_k$ is an integer and each list $[\\pi_k]$ contains $n$ integers in $\\{0,1,\\dots,K-1\\}$.",
            "solution": "The solution involves two main components: first, deriving an efficient formula to calculate the change in the error criterion ($\\Delta E$) for a single-node move, and second, specifying the Tabu Search algorithm that uses this calculation.\n\n### 1. Derivation of the Change in Error ($\\Delta E$)\nThe objective function to minimize is the total number of mismatches between the observed and ideal block structure:\n$$\nE(A,\\pi,M) = \\sum_{i=1}^{n}\\sum_{\\substack{j=1 \\\\ j \\neq i}}^{n} \\left| A_{ij} - M_{\\pi(i), \\pi(j)} \\right|.\n$$\nWe need to efficiently calculate the change in error, $\\Delta E$, when a single node $u$ is moved from its current block $r = \\pi(u)$ to a new block $t$. The change only affects terms in the sum where $i=u$ or $j=u$. Let $\\pi_{old}$ be the partition before the move and $\\pi_{new}$ be after.\nThe total change is the sum of changes from $u$'s perspective and from all other nodes' perspectives of $u$:\n$$\n\\Delta E = \\sum_{j \\neq u} \\left( |A_{uj} - M_{t, \\pi(j)}| - |A_{uj} - M_{r, \\pi(j)}| \\right) + \\sum_{i \\neq u} \\left( |A_{iu} - M_{\\pi(i), t}| - |A_{iu} - M_{\\pi(i), r}| \\right)\n$$\nSince the graph and image matrices are symmetric ($A_{iu} = A_{uj}$ and $M_{ab} = M_{ba}$), the two summation terms are identical. We can combine them:\n$$\n\\Delta E = 2 \\sum_{j=1, j \\neq u}^{n} \\left( \\left| A_{uj} - M_{t, \\pi(j)} \\right| - \\left| A_{uj} - M_{r, \\pi(j)} \\right| \\right)\n$$\nThis formula allows for a fast update of the error score by only considering the connections of the node being moved, which is far more efficient than recalculating the entire error sum of $n(n-1)$ terms.\n\n### 2. Tabu Search Algorithm Specification\nThe Tabu Search algorithm is implemented as follows:\n1.  **Initialization**: Start with the initial partition $\\pi^{(0)}$ and compute its error $E^{(0)}$. Set this as the current solution ($\\pi_{current}, E_{current}$) and the best-known solution ($\\pi_{best}, E_{best}$). Initialize an empty Tabu list, where entries will store forbidden moves and their remaining tenure.\n2.  **Iteration Loop**: For a maximum of $T$ iterations:\n    a. **Neighborhood Generation**: Identify all possible single-node moves. For each node $u$, consider moving it from its current block $\\pi(u)$ to any other block $t$.\n    b. **Move Evaluation**: For each potential move $(u, t)$, calculate $\\Delta E$ using the formula above. The objective value if this move is taken would be $E_{new} = E_{current} + \\Delta E$.\n    c. **Selection of Best Move**: Find the best admissible move. A move is admissible if it is not on the Tabu list, or if it is on the list but satisfies the Aspiration Criterion (i.e., $E_{new} < E_{best}$).\n        - Among all admissible moves, select the one that leads to the minimum resulting objective value, $E_{new}$.\n        - Break ties by choosing the move with the smallest $\\Delta E$, then by the lexicographically smallest $(u, t)$ pair.\n    d. **Termination Check**: If no admissible moves can be found, terminate the search.\n    e. **State Update**: Perform the best move $(u^*, t^*)$, where $u^*$ was moved from its old block $r^*$.\n        - Update the partition: $\\pi_{current}(u^*) \\leftarrow t^*$.\n        - Update the current error: $E_{current} \\leftarrow E_{current} + \\Delta E^*$.\n        - Update Tabu List: Decrease the tenure of all existing tabu entries by 1. Add the reverse move $(u^*, r^*)$ to the Tabu list with a tenure of $\\tau$.\n        - Update Best-Known Solution: If the new state is better than any seen so far ($E_{current}  E_{best}$), update $\\pi_{best} \\leftarrow \\pi_{current}$ and $E_{best} \\leftarrow E_{current}$.\n3.  **Output**: After $T$ iterations or early termination, the algorithm returns the best solution found, $(\\pi_{best}, E_{best})$.",
            "answer": "```python\nimport numpy as np\n\ndef calculate_E(A, pi, M):\n    \"\"\"\n    Calculates the total blockmodeling error from scratch.\n    \"\"\"\n    n = A.shape[0]\n    error = 0\n    for i in range(n):\n        for j in range(n):\n            if i == j:\n                continue\n            pi_i = pi[i]\n            pi_j = pi[j]\n            error += np.abs(A[i, j] - M[pi_i, pi_j])\n    return int(error)\n\ndef solve():\n    \"\"\"\n    Main solver function to run the Tabu Search for all test cases.\n    \"\"\"\n    test_cases = [\n        {\n            \"A\": np.array([\n                [0, 1, 1, 1, 0, 0, 0, 0],\n                [1, 0, 1, 1, 0, 0, 0, 0],\n                [1, 1, 0, 1, 0, 0, 0, 0],\n                [1, 1, 1, 0, 0, 0, 0, 0],\n                [0, 0, 0, 0, 0, 1, 1, 1],\n                [0, 0, 0, 0, 1, 0, 1, 1],\n                [0, 0, 0, 0, 1, 1, 0, 1],\n                [0, 0, 0, 0, 1, 1, 1, 0]\n            ]),\n            \"M\": np.array([[1, 0], [0, 1]]),\n            \"pi0\": np.array([0, 0, 1, 1, 0, 0, 1, 1]),\n            \"T\": 50, \"tau\": 5, \"K\": 2\n        },\n        {\n            \"A\": np.array([\n                [0, 0, 0, 0, 0],\n                [0, 0, 0, 0, 0],\n                [0, 0, 0, 0, 0],\n                [0, 0, 0, 0, 0],\n                [0, 0, 0, 0, 0]\n            ]),\n            \"M\": np.array([[1]]),\n            \"pi0\": np.array([0, 0, 0, 0, 0]),\n            \"T\": 10, \"tau\": 3, \"K\": 1\n        },\n        {\n            \"A\": np.array([\n                [0, 0, 0, 1, 1, 1],\n                [0, 0, 0, 1, 1, 1],\n                [0, 0, 0, 1, 1, 1],\n                [1, 1, 1, 0, 0, 0],\n                [1, 1, 1, 0, 0, 0],\n                [1, 1, 1, 0, 0, 0]\n            ]),\n            \"M\": np.array([[0, 1], [1, 0]]),\n            \"pi0\": np.array([0, 1, 0, 1, 0, 1]),\n            \"T\": 50, \"tau\": 4, \"K\": 2\n        },\n        {\n            \"A\": np.array([\n                [0, 1, 1, 1, 0, 0, 0],\n                [1, 0, 1, 1, 0, 0, 0],\n                [1, 1, 0, 0, 0, 0, 0],\n                [1, 1, 0, 0, 1, 1, 0],\n                [0, 0, 0, 1, 0, 1, 1],\n                [0, 0, 0, 1, 1, 0, 1],\n                [0, 0, 0, 0, 1, 1, 0]\n            ]),\n            \"M\": np.array([[1, 0], [0, 1]]),\n            \"pi0\": np.array([0, 0, 0, 1, 1, 1, 1]),\n            \"T\": 100, \"tau\": 7, \"K\": 2\n        }\n    ]\n\n    results = []\n    for case in test_cases:\n        final_E, final_pi = run_tabu_search(**case)\n        pi_list = final_pi.tolist()\n        result_str = f\"[{final_E},[{','.join(map(str, pi_list))}]]\"\n        results.append(result_str)\n\n    print(f\"[[{','.join(results)}]]\")\n\ndef run_tabu_search(A, M, pi0, T, tau, K):\n    \"\"\"\n    Performs Tabu Search to minimize the blockmodeling error.\n    \"\"\"\n    n = A.shape[0]\n    pi_current = pi0.copy()\n    E_current = calculate_E(A, pi_current, M)\n    \n    pi_best = pi_current.copy()\n    E_best = E_current\n\n    # Tabu list stores {(node, block): tenure}, forbidding node from moving to block\n    tabu_list = {}\n\n    for iteration in range(T):\n        best_candidate = (float('inf'), float('inf'), (-1, -1)) # (E_new, delta_E, (u, t))\n\n        for u in range(n):\n            r = pi_current[u]\n            for t in range(K):\n                if t == r:\n                    continue\n\n                # Calculate delta_E for move u: r -> t\n                delta_E = 0\n                for j in range(n):\n                    if j == u:\n                        continue\n                    pi_j = pi_current[j]\n                    delta_E += np.abs(A[u, j] - M[t, pi_j]) - np.abs(A[u, j] - M[r, pi_j])\n                delta_E *= 2\n                \n                E_new = E_current + delta_E\n\n                # Admissibility Check\n                is_tabu = tabu_list.get((u, t), 0) > 0\n                is_admissible = not is_tabu or (is_tabu and E_new  E_best)\n\n                if is_admissible:\n                    candidate = (E_new, delta_E, (u, t))\n                    if candidate  best_candidate:\n                        best_candidate = candidate\n\n        # Update tabu list tenures\n        tabu_list = {move: tenure - 1 for move, tenure in tabu_list.items() if tenure > 1}\n\n        # If a best move is found, perform it\n        if best_candidate[0] != float('inf'):\n            E_new, _, move = best_candidate\n            u, t = move\n            r = pi_current[u]\n            \n            # Update state\n            pi_current[u] = t\n            E_current = E_new\n\n            # Add reverse move to tabu list\n            tabu_list[(u, r)] = tau\n            \n            # Update best-so-far solution\n            if E_current  E_best:\n                E_best = E_current\n                pi_best = pi_current.copy()\n        else:\n            # No admissible moves found\n            break\n\n    return E_best, pi_best\n\nsolve()\n```"
        }
    ]
}