{
    "hands_on_practices": [
        {
            "introduction": "单模投影最直接的形式化方法是通过矩阵乘法。这个练习将引导你从第一性原理出发，推导并计算投影矩阵 $W = BB^\\top$ 和 $W' = B^\\top B$。通过这个过程，你将巩固“共享邻居”这一抽象概念与具体线性代数运算之间的联系，并揭示二分网络中节点的度与投影网络中节点加权度之间的重要结构特性 。",
            "id": "4294500",
            "problem": "考虑一个具有节点集 $\\mathcal{U}$ 和 $\\mathcal{V}$ 的二分网络，由一个二元关联矩阵 $B \\in \\{0,1\\}^{|\\mathcal{U}| \\times |\\mathcal{V}|}$ 表示，其中当且仅当节点 $u \\in \\mathcal{U}$ 与节点 $v \\in \\mathcal{V}$ 连接时，$B_{uv} = 1$，否则 $B_{uv} = 0$。标准的到 $\\mathcal{U}$ 上的单模投影定义为：节点 $u,u' \\in \\mathcal{U}$ 之间的权重等于它们在 $\\mathcal{V}$ 中共享的共同邻居的数量；类似地，到 $\\mathcal{V}$ 上的投影将节点 $v,v' \\in \\mathcal{V}$ 之间的权重赋值为它们在 $\\mathcal{U}$ 中的共同邻居数量。这些权重可以分别通过 $B$ 的行向量和列向量的格拉姆矩阵构建。\n\n设\n$$\nB=\\begin{pmatrix}\n1  1  0 \\\\\n0  1  1\n\\end{pmatrix},\n$$\n其中有 $|\\mathcal{U}|=2$ 行和 $|\\mathcal{V}|=3$ 列。\n\n仅使用上述定义和标准的线性代数知识，完成以下任务：\n\n1. 从第一性原理推导到 $\\mathcal{U}$ 上的单模投影的加权邻接矩阵 $W$，并为给定的 $B$ 显式计算它。\n\n2. 从第一性原理推导到 $\\mathcal{V}$ 上的单模投影的加权邻接矩阵 $W'$，并为给定的 $B$ 显式计算它。\n\n3. 令 $k_{\\mathcal{U}} \\in \\mathbb{R}^{|\\mathcal{U}|}$ 和 $k_{\\mathcal{V}} \\in \\mathbb{R}^{|\\mathcal{V}|}$ 分别表示通过对 $B$ 的行和列求和得到的二分度向量。使用与全1向量 $\\mathbf{1}_{\\mathcal{V}} \\in \\mathbb{R}^{|\\mathcal{V}|}$ 和 $\\mathbf{1}_{\\mathcal{U}} \\in \\mathbb{R}^{|\\mathcal{U}|}$ 的矩阵向量乘积来表示 $k_{\\mathcal{U}}$ 和 $k_{\\mathcal{V}}$，并为给定的 $B$ 计算它们。证明 $W$ 的对角线元素等于 $k_{\\mathcal{U}}$ 的元素，且 $W'$ 的对角线元素等于 $k_{\\mathcal{V}}$ 的元素。\n\n4. 将投影中的加权度（也称为强度）向量定义为 $s_{\\mathcal{U}} = W \\,\\mathbf{1}_{\\mathcal{U}}$ 和 $s_{\\mathcal{V}} = W' \\,\\mathbf{1}_{\\mathcal{V}}$。推导将 $s_{\\mathcal{U}}$ 与 $B$ 和 $k_{\\mathcal{V}}$ 联系起来，以及将 $s_{\\mathcal{V}}$ 与 $B$ 和 $k_{\\mathcal{U}}$ 联系起来的恒等式，并为给定的 $B$ 显式计算这些向量。\n\n作为最终数值答案，报告标量\n$$\nD \\equiv \\det(W) + \\operatorname{rank}(W').\n$$\n无需四舍五入。仅提供 $D$ 的值作为最终答案。",
            "solution": "问题陈述已经过验证，被认为是科学上合理的、定义明确的、客观的且内部一致的。它提出了一个网络科学中的标准练习，具体涉及二分网络的单模投影，并要求应用线性代数的基本概念。所有定义都清晰，所有必要数据均已提供。因此，我们可以进行完整解答。\n\n问题要求对由关联矩阵\n$$\nB=\\begin{pmatrix}\n1  1  0 \\\\\n0  1  1\n\\end{pmatrix}\n$$\n定义的二分网络的单模投影进行相关的推导和计算，其中行对应于节点集 $\\mathcal{U}$ (有 $|\\mathcal{U}|=2$ 个)，列对应于节点集 $\\mathcal{V}$ (有 $|\\mathcal{V}|=3$ 个)。\n\n1. 到 $\\mathcal{U}$ 上的投影的加权邻接矩阵 $W$。\n\n根据定义，两个节点 $u, u' \\in \\mathcal{U}$ 之间的权重 $W_{u,u'}$ 是它们在 $\\mathcal{V}$ 中共享的共同邻居的数量。一个节点 $v \\in \\mathcal{V}$ 是 $u$ 和 $u'$ 的共同邻居，当且仅当存在连接 $u$ 到 $v$ 和 $u'$ 到 $v$ 的边。用关联矩阵 $B$ 表示，这意味着 $B_{uv}=1$ 且 $B_{u'v}=1$。由于 $B$ 的元素是 $0$ 或 $1$，如果 $v$ 是一个共同邻居，则乘积 $B_{uv}B_{u'v}$ 为 $1$，否则为 $0$。共同邻居的总数是对所有可能的邻居 $v \\in \\mathcal{V}$ 求和：\n$$\nW_{u,u'} = \\sum_{v \\in \\mathcal{V}} B_{uv}B_{u'v}\n$$\n这个表达式是 $B$ 的第 $u$ 行向量与 $B$ 的第 $u'$ 行向量的点积。设矩阵 $B$ 的维度为 $m \\times n$，其中 $m = |\\mathcal{U}|$ 和 $n = |\\mathcal{V}|$。$B$ 与其转置 $B^T$ 的乘积是一个 $m \\times m$ 的矩阵。乘积 $B B^T$ 的第 $(u,u')$ 个元素由下式给出：\n$$\n(B B^T)_{u,u'} = \\sum_{v=1}^{n} B_{uv} (B^T)_{vu'} = \\sum_{v=1}^{n} B_{uv} B_{u'v}\n$$\n这与 $W_{u,u'}$ 的定义相符。因此，到 $\\mathcal{U}$ 上的投影的加权邻接矩阵由 $W = B B^T$ 给出。\n\n对于给定的矩阵 $B$，我们有：\n$$\nB^T = \\begin{pmatrix} 1  0 \\\\ 1  1 \\\\ 0  1 \\end{pmatrix}\n$$\n因此，\n$$\nW = B B^T = \\begin{pmatrix} 1  1  0 \\\\ 0  1  1 \\end{pmatrix} \\begin{pmatrix} 1  0 \\\\ 1  1 \\\\ 0  1 \\end{pmatrix} = \\begin{pmatrix} (1)(1)+(1)(1)+(0)(0)  (1)(0)+(1)(1)+(0)(1) \\\\ (0)(1)+(1)(1)+(1)(0)  (0)(0)+(1)(1)+(1)(1) \\end{pmatrix} = \\begin{pmatrix} 2  1 \\\\ 1  2 \\end{pmatrix}\n$$\n\n2. 到 $\\mathcal{V}$ 上的投影的加权邻接矩阵 $W'$。\n\n类似地，两个节点 $v, v' \\in \\mathcal{V}$ 之间的权重 $W'_{v,v'}$ 是它们在 $\\mathcal{U}$ 中的共同邻居的数量。遵循同样的逻辑，一个节点 $u \\in \\mathcal{U}$ 是一个共同邻居，如果 $B_{uv}=1$ 且 $B_{uv'}=1$。共同邻居的总数是：\n$$\nW'_{v,v'} = \\sum_{u \\in \\mathcal{U}} B_{uv}B_{uv'}\n$$\n这个表达式可以被识别为矩阵乘积 $B^T B$ 的一个元素。$B^T$ 的维度是 $n \\times m$，$B$ 的维度是 $m \\times n$，所以 $B^T B$ 是一个 $n \\times n$ 的矩阵。$B^T B$ 的第 $(v,v')$ 个元素是：\n$$\n(B^T B)_{v,v'} = \\sum_{u=1}^{m} (B^T)_{vu} B_{uv'} = \\sum_{u=1}^{m} B_{uv} B_{uv'}\n$$\n这与 $W'_{v,v'}$ 的定义相符。因此，到 $\\mathcal{V}$ 上的投影的加权邻接矩阵由 $W' = B^T B$ 给出。\n\n对于给定的矩阵 $B$：\n$$\nW' = B^T B = \\begin{pmatrix} 1  0 \\\\ 1  1 \\\\ 0  1 \\end{pmatrix} \\begin{pmatrix} 1  1  0 \\\\ 0  1  1 \\end{pmatrix} = \\begin{pmatrix} (1)(1)+(0)(0)  (1)(1)+(0)(1)  (1)(0)+(0)(1) \\\\ (1)(1)+(1)(0)  (1)(1)+(1)(1)  (1)(0)+(1)(1) \\\\ (0)(1)+(1)(0)  (0)(1)+(1)(1)  (0)(0)+(1)(1) \\end{pmatrix} = \\begin{pmatrix} 1  1  0 \\\\ 1  2  1 \\\\ 0  1  1 \\end{pmatrix}\n$$\n\n3. 二分度向量及其与 $W$ 和 $W'$ 对角线的关系。\n\n节点 $u \\in \\mathcal{U}$ 的二分度，记为 $k_u$，是 $B$ 的第 $u$ 行元素之和。度向量 $k_{\\mathcal{U}}$ 是这些行和的列向量。使用全1向量 $\\mathbf{1}_{\\mathcal{V}} \\in \\mathbb{R}^{|\\mathcal{V}|}$，乘积 $B \\mathbf{1}_{\\mathcal{V}}$ 的第 $u$ 个分量是 $\\sum_{v \\in \\mathcal{V}} B_{uv} \\cdot 1 = k_u$。因此，$k_{\\mathcal{U}} = B \\mathbf{1}_{\\mathcal{V}}$。\n节点 $v \\in \\mathcal{V}$ 的二分度，记为 $k_v$，是 $B$ 的第 $v$ 列元素之和。度向量 $k_{\\mathcal{V}}$ 是这些列和的列向量。这等同于对 $B^T$ 的行求和。使用全1向量 $\\mathbf{1}_{\\mathcal{U}} \\in \\mathbb{R}^{|\\mathcal{U}|}$，乘积 $B^T \\mathbf{1}_{\\mathcal{U}}$ 的第 $v$ 个分量是 $\\sum_{u \\in \\mathcal{U}} (B^T)_{vu} \\cdot 1 = \\sum_{u \\in \\mathcal{U}} B_{uv} = k_v$。因此，$k_{\\mathcal{V}} = B^T \\mathbf{1}_{\\mathcal{U}}$。\n\n为给定的 $B$ 计算这些向量：\n$$\n\\mathbf{1}_{\\mathcal{U}} = \\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix}, \\quad \\mathbf{1}_{\\mathcal{V}} = \\begin{pmatrix} 1 \\\\ 1 \\\\ 1 \\end{pmatrix}\n$$\n$$\nk_{\\mathcal{U}} = B \\mathbf{1}_{\\mathcal{V}} = \\begin{pmatrix} 1  1  0 \\\\ 0  1  1 \\end{pmatrix} \\begin{pmatrix} 1 \\\\ 1 \\\\ 1 \\end{pmatrix} = \\begin{pmatrix} 1+1+0 \\\\ 0+1+1 \\end{pmatrix} = \\begin{pmatrix} 2 \\\\ 2 \\end{pmatrix}\n$$\n$$\nk_{\\mathcal{V}} = B^T \\mathbf{1}_{\\mathcal{U}} = \\begin{pmatrix} 1  0 \\\\ 1  1 \\\\ 0  1 \\end{pmatrix} \\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix} = \\begin{pmatrix} 1+0 \\\\ 1+1 \\\\ 0+1 \\end{pmatrix} = \\begin{pmatrix} 1 \\\\ 2 \\\\ 1 \\end{pmatrix}\n$$\n\n为了证明与对角线的关系，考虑对角线元素 $W_{u,u}$：\n$$\nW_{u,u} = \\sum_{v \\in \\mathcal{V}} B_{uv}B_{uv} = \\sum_{v \\in \\mathcal{V}} (B_{uv})^2\n$$\n由于 $B_{uv} \\in \\{0,1\\}$，我们有 $(B_{uv})^2 = B_{uv}$。因此，\n$$\nW_{u,u} = \\sum_{v \\in \\mathcal{V}} B_{uv} = k_u\n$$\n这表明 $W$ 的对角线元素是度向量 $k_{\\mathcal{U}}$ 的元素。\n对于我们计算的 $W$，对角线是 $(2, 2)$，与 $k_{\\mathcal{U}}$ 相匹配。\n\n类似地，对于对角线元素 $W'_{v,v}$：\n$$\nW'_{v,v} = \\sum_{u \\in \\mathcal{U}} B_{uv}B_{uv} = \\sum_{u \\in \\mathcal{U}} (B_{uv})^2 = \\sum_{u \\in \\mathcal{U}} B_{uv} = k_v\n$$\n这表明 $W'$ 的对角线元素是度向量 $k_{\\mathcal{V}}$ 的元素。\n对于我们计算的 $W'$，对角线是 $(1, 2, 1)$，与 $k_{\\mathcal{V}}$ 相匹配。\n\n4. 投影中的强度向量。\n\n强度向量 $s_{\\mathcal{U}}$ 定义为 $s_{\\mathcal{U}} = W \\mathbf{1}_{\\mathcal{U}}$。代入 $W = B B^T$：\n$$\ns_{\\mathcal{U}} = (B B^T) \\mathbf{1}_{\\mathcal{U}} = B (B^T \\mathbf{1}_{\\mathcal{U}})\n$$\n从第3部分，我们知道 $k_{\\mathcal{V}} = B^T \\mathbf{1}_{\\mathcal{U}}$。因此，我们得到恒等式 $s_{\\mathcal{U}} = B k_{\\mathcal{V}}$。\n\n强度向量 $s_{\\mathcal{V}}$ 定义为 $s_{\\mathcal{V}} = W' \\mathbf{1}_{\\mathcal{V}}$。代入 $W' = B^T B$：\n$$\ns_{\\mathcal{V}} = (B^T B) \\mathbf{1}_{\\mathcal{V}} = B^T (B \\mathbf{1}_{\\mathcalV})\n$$\n从第3部分，我们知道 $k_{\\mathcal{U}} = B \\mathbf{1}_{\\mathcal{V}}$。因此，我们得到恒等式 $s_{\\mathcal{V}} = B^T k_{\\mathcal{U}}$。\n\n为给定的 $B$ 计算这些向量：\n$$\ns_{\\mathcal{U}} = W \\mathbf{1}_{\\mathcal{U}} = \\begin{pmatrix} 2  1 \\\\ 1  2 \\end{pmatrix} \\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix} = \\begin{pmatrix} 2+1 \\\\ 1+2 \\end{pmatrix} = \\begin{pmatrix} 3 \\\\ 3 \\end{pmatrix}\n$$\n用恒等式验证：\n$s_{\\mathcal{U}} = B k_{\\mathcal{V}} = \\begin{pmatrix} 1  1  0 \\\\ 0  1  1 \\end{pmatrix} \\begin{pmatrix} 1 \\\\ 2 \\\\ 1 \\end{pmatrix} = \\begin{pmatrix} 1+2+0 \\\\ 0+2+1 \\end{pmatrix} = \\begin{pmatrix} 3 \\\\ 3 \\end{pmatrix}$。结果一致。\n\n$$\ns_{\\mathcal{V}} = W' \\mathbf{1}_{\\mathcal{V}} = \\begin{pmatrix} 1  1  0 \\\\ 1  2  1 \\\\ 0  1  1 \\end{pmatrix} \\begin{pmatrix} 1 \\\\ 1 \\\\ 1 \\end{pmatrix} = \\begin{pmatrix} 1+1+0 \\\\ 1+2+1 \\\\ 0+1+1 \\end{pmatrix} = \\begin{pmatrix} 2 \\\\ 4 \\\\ 2 \\end{pmatrix}\n$$\n用恒等式验证：\n$s_{\\mathcal{V}} = B^T k_{\\mathcal{U}} = \\begin{pmatrix} 1  0 \\\\ 1  1 \\\\ 0  1 \\end{pmatrix} \\begin{pmatrix} 2 \\\\ 2 \\end{pmatrix} = \\begin{pmatrix} 2+0 \\\\ 2+2 \\\\ 0+2 \\end{pmatrix} = \\begin{pmatrix} 2 \\\\ 4 \\\\ 2 \\end{pmatrix}$。结果一致。\n\n最终数值答案。\n需要计算的标量是 $D \\equiv \\det(W) + \\operatorname{rank}(W')$。\n首先，我们计算 $W$ 的行列式：\n$$\nW = \\begin{pmatrix} 2  1 \\\\ 1  2 \\end{pmatrix}\n$$\n$$\n\\det(W) = (2)(2) - (1)(1) = 4 - 1 = 3\n$$\n接下来，我们计算 $W'$ 的秩：\n$$\nW' = \\begin{pmatrix} 1  1  0 \\\\ 1  2  1 \\\\ 0  1  1 \\end{pmatrix}\n$$\n线性代数中的一个基本结论是 $\\operatorname{rank}(A^T A) = \\operatorname{rank}(A)$。因此，$\\operatorname{rank}(W') = \\operatorname{rank}(B^T B) = \\operatorname{rank}(B)$。矩阵 $B$ 是：\n$$\nB = \\begin{pmatrix} 1  1  0 \\\\ 0  1  1 \\end{pmatrix}\n$$\n这个矩阵已经是行阶梯形。它有两个非零行，并且它们是线性无关的。因此，$B$ 的秩是 $2$。\n$$\n\\operatorname{rank}(W') = \\operatorname{rank}(B) = 2\n$$\n或者，可以计算 $W'$ 的行列式：\n$$\n\\det(W') = 1 \\begin{vmatrix} 2  1 \\\\ 1  1 \\end{vmatrix} - 1 \\begin{vmatrix} 1  1 \\\\ 0  1 \\end{vmatrix} + 0 = 1(2-1) - 1(1-0) = 1 - 1 = 0\n$$\n由于 $\\det(W')=0$，其秩必须小于 $3$。左上角的 $2 \\times 2$ 子矩阵 $\\begin{pmatrix} 1  1 \\\\ 1  2 \\end{pmatrix}$ 的行列式为 $2-1=1 \\neq 0$，所以秩至少为 $2$。因此，$\\operatorname{rank}(W')=2$。\n\n最后，我们计算 $D$：\n$$\nD = \\det(W) + \\operatorname{rank}(W') = 3 + 2 = 5\n$$",
            "answer": "$$\\boxed{5}$$"
        },
        {
            "introduction": "计算共同邻居的数量只是定义相似性的一种方式。在实践中，不同的加权方案可以揭示不同类型的相似性。这个练习将探讨两种常见的归一化方法：余弦相似度和 Jaccard 指数 。通过在一个假设的用户-物品场景中推导它们的公式并比较其数值，你将深入理解度分布不均时，相似性度量的选择如何影响我们对网络结构的解读。",
            "id": "4294525",
            "problem": "考虑一个用户-物品二分网络，由关联矩阵 $B$ 表示，其元素 $B_{i\\alpha} \\in \\{0,1\\}$。其中，如果用户 $i$ 购买了物品 $\\alpha$，则 $B_{i\\alpha} = 1$，否则 $B_{i\\alpha} = 0$。用户 $i$ 的度为 $d_i = \\sum_{\\alpha} B_{i\\alpha}$，用户 $i$ 和 $j$ 之间的共同物品数量为 $c = \\sum_{\\alpha} B_{i\\alpha} B_{j\\alpha}$。在到用户的单模投影中，一种常见的方法是基于用户 $i$ 和 $j$ 的物品邻域重叠来为他们分配相似度权重。\n\n仅从这些定义出发，推导用户 $i$ 和 $j$ 之间的余弦相似度和 Jaccard 指数的表达式（用 $d_i$、$d_j$ 和 $c$ 表示），然后对 $d_i = 8$、$d_j = 10$ 和 $c = 4$ 的情况计算这两个值。作为这两种相似度概念之间的定量比较，计算此情况下余弦相似度与 Jaccard 指数的比率。给出你的最终答案，形式为一个单一、简化的精确表达式，无单位。不要四舍五入。",
            "solution": "问题陈述有效。它具有科学依据，提法明确，并提供了推导和计算所需量所必需的所有信息，前提是假设余弦相似度和 Jaccard 指数采用标准定义，这在此背景下是合理的预期。\n\n该问题要求推导在一个用户-物品二分网络的单模投影中，用户之间的两种常见相似度度量：余弦相似度和 Jaccard 指数。这些推导将用给定的量来表示：用户 $i$ 的度 $d_i$；用户 $j$ 的度 $d_j$；以及他们之间共同物品的数量 $c$。\n\n设所有物品的集合由 $\\alpha$ 索引。一个用户 $i$ 可以用物品空间中的一个向量 $\\mathbf{v}_i$ 来表示，其中对应于物品 $\\alpha$ 的分量由关联矩阵元素 $B_{i\\alpha}$ 给出。因此，$\\mathbf{v}_i = (B_{i1}, B_{i2}, \\dots, B_{iM})$，其中 $M$ 是物品总数。元素 $B_{i\\alpha}$ 的值为 $1$ 或 $0$。\n\n首先，我们推导余弦相似度的表达式。两个向量 $\\mathbf{v}_i$ 和 $\\mathbf{v}_j$ 之间的余弦相似度定义为它们之间夹角的余弦，计算方法是向量的点积除以它们模长（欧几里得范数或L2范数）的乘积。\n$$ \\cos(\\theta)_{ij} = \\frac{\\mathbf{v}_i \\cdot \\mathbf{v}_j}{\\|\\mathbf{v}_i\\| \\|\\mathbf{v}_j\\|} $$\n点积 $\\mathbf{v}_i \\cdot \\mathbf{v}_j$ 计算如下：\n$$ \\mathbf{v}_i \\cdot \\mathbf{v}_j = \\sum_{\\alpha} B_{i\\alpha} B_{j\\alpha} $$\n乘积 $B_{i\\alpha} B_{j\\alpha}$ 仅当 $B_{i\\alpha}=1$ 和 $B_{j\\alpha}=1$ 都成立时才为 $1$，这意味着用户 $i$ 和 $j$ 都购买了物品 $\\alpha$。否则，该乘积为 $0$。因此，对所有 $\\alpha$ 的求和计算了两个用户共同拥有的物品数量。问题陈述将此量定义为 $c$。因此，\n$$ \\mathbf{v}_i \\cdot \\mathbf{v}_j = c $$\n用户向量 $\\mathbf{v}_i$ 的模长由 $\\|\\mathbf{v}_i\\| = \\sqrt{\\sum_{\\alpha} B_{i\\alpha}^2}$ 给出。由于元素 $B_{i\\alpha}$ 是二元的（$0$ 或 $1$），我们有 $B_{i\\alpha}^2 = B_{i\\alpha}$。因此，模长的平方为：\n$$ \\|\\mathbf{v}_i\\|^2 = \\sum_{\\alpha} B_{i\\alpha}^2 = \\sum_{\\alpha} B_{i\\alpha} $$\n这个和是用户 $i$ 购买的物品总数，被定义为用户的度 $d_i$。所以，$\\|\\mathbf{v}_i\\|^2 = d_i$，这意味着 $\\|\\mathbf{v}_i\\| = \\sqrt{d_i}$。\n类似地，对于用户 $j$，我们有 $\\|\\mathbf{v}_j\\| = \\sqrt{d_j}$。\n将这些表达式代回余弦相似度公式，得到：\n$$ \\cos(\\theta)_{ij} = \\frac{c}{\\sqrt{d_i d_j}} $$\n\n接下来，我们推导 Jaccard 指数的表达式。两个集合之间的 Jaccard 指数定义为它们交集的大小除以它们并集的大小。设 $S_i$ 是用户 $i$ 购买的物品集合，$S_j$ 是用户 $j$ 的物品集合。\n$$ J_{ij} = \\frac{|S_i \\cap S_j|}{|S_i \\cup S_j|} $$\n交集的大小 $|S_i \\cap S_j|$ 是属于两个集合的物品数量。这正是共同物品的数量，定义为 $c$。\n$$ |S_i \\cap S_j| = c $$\n并集的大小 $|S_i \\cup S_j|$ 可以使用容斥原理找到：\n$$ |S_i \\cup S_j| = |S_i| + |S_j| - |S_i \\cap S_j| $$\n集合 $S_i$ 的大小 $|S_i|$ 是用户 $i$ 购买的物品数量，即度 $d_i$。类似地， $|S_j| = d_j$。将这些代入并集公式：\n$$ |S_i \\cup S_j| = d_i + d_j - c $$\n因此，Jaccard 指数为：\n$$ J_{ij} = \\frac{c}{d_i + d_j - c} $$\n\n现在，我们对给定情况 $d_i = 8$，$d_j = 10$ 和 $c = 4$ 计算这两种相似度度量。\n余弦相似度为：\n$$ \\cos(\\theta)_{ij} = \\frac{4}{\\sqrt{8 \\times 10}} = \\frac{4}{\\sqrt{80}} = \\frac{4}{\\sqrt{16 \\times 5}} = \\frac{4}{4\\sqrt{5}} = \\frac{1}{\\sqrt{5}} $$\nJaccard 指数为：\n$$ J_{ij} = \\frac{4}{8 + 10 - 4} = \\frac{4}{14} = \\frac{2}{7} $$\n\n最后，我们计算此情况下余弦相似度与 Jaccard 指数的比率。\n$$ \\text{Ratio} = \\frac{\\cos(\\theta)_{ij}}{J_{ij}} = \\frac{1/\\sqrt{5}}{2/7} = \\frac{1}{\\sqrt{5}} \\times \\frac{7}{2} = \\frac{7}{2\\sqrt{5}} $$\n为了简化这个精确表达式，我们将分母有理化：\n$$ \\text{Ratio} = \\frac{7}{2\\sqrt{5}} \\times \\frac{\\sqrt{5}}{\\sqrt{5}} = \\frac{7\\sqrt{5}}{2 \\times 5} = \\frac{7\\sqrt{5}}{10} $$\n这就是该比率的最终、简化的精确表达式。",
            "answer": "$$\\boxed{\\frac{7\\sqrt{5}}{10}}$$"
        },
        {
            "introduction": "现实世界的数据往往超越了简单的二元连接，包含了更丰富的信息，例如正面（喜欢）和负面（不喜欢）的评价。本练习将演示如何将单模投影的概念扩展到处理这类符号网络，基于用户评价的一致性与分歧来构建相似性 。你将通过计算发现一个有趣的现象——“抵消效应”，即混合的评价（既有一致也有分歧）可能导致投影网络中边的权重变弱甚至为零。",
            "id": "4294513",
            "problem": "考虑一个二分网络，它有两个不相交的节点集：四个用户 $U_1, U_2, U_3, U_4$ 和五个项目 $I_1, I_2, I_3, I_4, I_5$。每个用户-项目对 $(U_u, I_i)$ 都有一个带符号的交互 $r_{u i} \\in \\{-1, 0, +1\\}$，其中 $+1$ 表示喜欢，$-1$ 表示不喜欢，而 $0$ 表示未评价。数据由一个 $4 \\times 5$ 的评分矩阵 $R = \\big(r_{u i}\\big)$ 给出：\n$$\nR \\;=\\;\n\\begin{pmatrix}\n+1  -1  +1  0  -1 \\\\\n+1  +1  -1  +1  0 \\\\\n-1  +1  +1  -1  -1 \\\\\n+1  0  +1  -1  +1\n\\end{pmatrix}.\n$$\n在用户集上的单模投影会产生一个加权的用户-用户网络。请遵循以下原则，从第一性原理出发构建用户-用户边的权重：\n- 在无权情况下，两个用户之间的权重等于他们共同连接的共享项目的数量。\n- 对于带符号的评价 $r_{u i} \\in \\{-1, 0, +1\\}$，当两个用户 $U_u$ 和 $U_v$ 对项目 $I_i$ 的评价符号一致时（同为 $+1$ 或同为 $-1$），该项目对他们之间权重的贡献必须为正；当他们符号不一致时（一个 $+1$ 一个 $-1$），贡献为负；当至少有一方的评价为 $r_{u i} = 0$ 或 $r_{v i} = 0$ 时，贡献为零。\n\n仅从这些原则以及二分邻接和单模投影的核心定义出发，推导用户-用户权重 $w_{u v}$ 关于 $\\{r_{u i}\\}$ 的解析表达式，并用它来计算用户单模投影的完整 $4 \\times 4$ 权重矩阵 $W = \\big(w_{u v}\\big)$。计算结果应包括与相同贡献规则一致的对角线元素 $w_{u u}$。\n\n使用计算出的矩阵 $W$ 解释，由于共同评价的项目上存在混合符号，抵消是如何产生的，并找出至少两对因抵消导致边权重恰好为零的用户对。\n\n最后，报告矩阵 $W$ 中元素 $w_{2 3}$ 的数值。最终数字无需四舍五入。",
            "solution": "用户单模投影的用户-用户权重 $w_{u v}$ 是通过对每个项目 $I_i$ 的贡献求和得出的。设项目 $I_i$ 对用户 $U_u$ 和用户 $U_v$ 之间权重的贡献表示为 $c_i(u, v)$。题目陈述了根据带符号评分 $r_{ui}$ 和 $r_{vi}$ 确定此贡献的原则。\n\n这些原则是：\n1. 如果用户 $U_u$ 和 $U_v$ 对项目 $I_i$ 的评价一致，则贡献 $c_i(u, v)$ 为正。这种情况发生在他们都给出正面评价（$r_{ui}=+1$, $r_{vi}=+1$）或都给出负面评价（$r_{ui}=-1$, $r_{vi}=-1$）时。\n2. 如果用户 $U_u$ 和 $U_v$ 对项目 $I_i$ 的评价不一致，则贡献 $c_i(u, v)$ 为负。这种情况发生在一人给出正面评价而另一人给出负面评价时（$r_{ui}=+1$, $r_{vi}=-1$ 或 $r_{ui}=-1$, $r_{vi}=+1$）。\n3. 如果至少有一个用户没有对该项目进行评价，即 $r_{ui}=0$ 或 $r_{vi}=0$，则贡献 $c_i(u, v)$ 为零。\n\n让我们找到一个满足这些条件的 $c_i(u, v)$ 的简单数学表达式。评分的乘积 $r_{ui} r_{vi}$ 直接满足这些要求：\n- 如果 $r_{ui}=+1$ 且 $r_{vi}=+1$，则 $r_{ui} r_{vi} = (+1)(+1) = +1$（正贡献）。\n- 如果 $r_{ui}=-1$ 且 $r_{vi}=-1$，则 $r_{ui} r_{vi} = (-1)(-1) = +1$（正贡献）。\n- 如果 $r_{ui}=+1$ 且 $r_{vi}=-1$，则 $r_{ui} r_{vi} = (+1)(-1) = -1$（负贡献）。\n- 如果 $r_{ui}=-1$ 且 $r_{vi}=+1$，则 $r_{ui} r_{vi} = (-1)(+1) = -1$（负贡献）。\n- 如果 $r_{ui}=0$ 或 $r_{vi}=0$，则 $r_{ui} r_{vi} = 0$（零贡献）。\n\n因此，项目 $I_i$ 贡献的最简单形式化是 $c_i(u,v) = r_{ui} r_{vi}$。用户 $U_u$ 和 $U_v$ 之间的总权重 $w_{uv}$ 是这些贡献在所有项目 $i=1, \\dots, 5$ 上的总和：\n$$\nw_{uv} = \\sum_{i=1}^{5} c_i(u,v) = \\sum_{i=1}^{5} r_{ui} r_{vi}\n$$\n这个表达式是评分矩阵 $R$ 的第 $u$ 个行向量与 $R$ 的第 $v$ 个行向量的点积。如果 $R_u$ 表示用户 $U_u$ 的行向量，那么 $w_{uv} = R_u \\cdot R_v$。因此，整个权重矩阵 $W = (w_{uv})$ 可以通过矩阵 $R$ 与其转置矩阵 $R^T$ 的乘积来计算：\n$$\nW = R R^T\n$$\n给定的评分矩阵是：\n$$\nR \\;=\\;\n\\begin{pmatrix}\n1  -1  1  0  -1 \\\\\n1  1  -1  1  0 \\\\\n-1  1  1  -1  -1 \\\\\n1  0  1  -1  1\n\\end{pmatrix}\n$$\n其转置矩阵 $R^T$ 是：\n$$\nR^T \\;=\\;\n\\begin{pmatrix}\n1  1  -1  1 \\\\\n-1  1  1  0 \\\\\n1  -1  1  1 \\\\\n0  1  -1  -1 \\\\\n-1  0  -1  1\n\\end{pmatrix}\n$$\n我们现在计算乘积 $W = R R^T$。元素 $w_{uv}$ 是 $R$ 的第 $u$ 行与 $R^T$ 的第 $v$ 列（也就是 $R$ 的第 $v$ 行）的点积。\n\n$w_{11} = (1)(1) + (-1)(-1) + (1)(1) + (0)(0) + (-1)(-1) = 1 + 1 + 1 + 0 + 1 = 4$\n$w_{12} = (1)(1) + (-1)(1) + (1)(-1) + (0)(1) + (-1)(0) = 1 - 1 - 1 + 0 + 0 = -1$\n$w_{13} = (1)(-1) + (-1)(1) + (1)(1) + (0)(-1) + (-1)(-1) = -1 - 1 + 1 + 0 + 1 = 0$\n$w_{14} = (1)(1) + (-1)(0) + (1)(1) + (0)(-1) + (-1)(1) = 1 + 0 + 1 + 0 - 1 = 1$\n\n$w_{21} = w_{12} = -1$\n$w_{22} = (1)(1) + (1)(1) + (-1)(-1) + (1)(1) + (0)(0) = 1 + 1 + 1 + 1 + 0 = 4$\n$w_{23} = (1)(-1) + (1)(1) + (-1)(1) + (1)(-1) + (0)(-1) = -1 + 1 - 1 - 1 + 0 = -2$\n$w_{24} = (1)(1) + (1)(0) + (-1)(1) + (1)(-1) + (0)(1) = 1 + 0 - 1 - 1 + 0 = -1$\n\n$w_{31} = w_{13} = 0$\n$w_{32} = w_{23} = -2$\n$w_{33} = (-1)(-1) + (1)(1) + (1)(1) + (-1)(-1) + (-1)(-1) = 1 + 1 + 1 + 1 + 1 = 5$\n$w_{34} = (-1)(1) + (1)(0) + (1)(1) + (-1)(-1) + (-1)(1) = -1 + 0 + 1 + 1 - 1 = 0$\n\n$w_{41} = w_{14} = 1$\n$w_{42} = w_{24} = -1$\n$w_{43} = w_{34} = 0$\n$w_{44} = (1)(1) + (0)(0) + (1)(1) + (-1)(-1) + (1)(1) = 1 + 0 + 1 + 1 + 1 = 4$\n\n完整的用户-用户权重矩阵 $W$ 是：\n$$\nW \\;=\\;\n\\begin{pmatrix}\n4  -1  0  1 \\\\\n-1  4  -2  -1 \\\\\n0  -2  5  0 \\\\\n1  -1  0  4\n\\end{pmatrix}\n$$\n当用户共同评价了多个项目，并且他们的评分表现出一致和不一致的混合时，就会发生抵消。正贡献（来自一致，$r_{ui}r_{vi}=+1$）和负贡献（来自不一致，$r_{ui}r_{vi}=-1$）的和可能是一个很小的值，甚至恰好为零。\n\n从矩阵 $W$ 中，我们识别出两对边权重为零的用户对：$(U_1, U_3)$，其 $w_{13} = 0$；以及 $(U_3, U_4)$，其 $w_{34} = 0$。\n\n让我们检查用户对 $(U_1, U_3)$ 的抵消情况：\n评分向量为 $R_1 = (1, -1, 1, 0, -1)$ 和 $R_3 = (-1, 1, 1, -1, -1)$。\n各项目的贡献如下：\n- 项目 $I_1$：$r_{11}r_{31} = (1)(-1) = -1$ (不一致)\n- 项目 $I_2$：$r_{12}r_{32} = (-1)(1) = -1$ (不一致)\n- 项目 $I_3$：$r_{13}r_{33} = (1)(1) = +1$ (一致)\n- 项目 $I_4$：$r_{14}r_{34} = (0)(-1) = 0$ (无共同评分)\n- 项目 $I_5$：$r_{15}r_{35} = (-1)(-1) = +1$ (一致)\n总权重为 $w_{13} = -1 - 1 + 1 + 0 + 1 = 0$。两次一致和两次不一致的评价完全抵消了。\n\n接下来，让我们检查用户对 $(U_3, U_4)$ 的抵消情况：\n评分向量为 $R_3 = (-1, 1, 1, -1, -1)$ 和 $R_4 = (1, 0, 1, -1, 1)$。\n各项目的贡献如下：\n- 项目 $I_1$：$r_{31}r_{41} = (-1)(1) = -1$ (不一致)\n- 项目 $I_2$：$r_{32}r_{42} = (1)(0) = 0$ (无共同评分)\n- 项目 $I_3$：$r_{33}r_{43} = (1)(1) = +1$ (一致)\n- 项目 $I_4$：$r_{34}r_{44} = (-1)(-1) = +1$ (一致)\n- 项目 $I_5$：$r_{35}r_{45} = (-1)(1) = -1$ (不一致)\n总权重为 $w_{34} = -1 + 0 + 1 + 1 - 1 = 0$。同样，两次一致和两次不一致的评价相互抵消。\n\n对角线元素 $w_{uu}$ 表示用户 $U_u$ 评价过的项目数量，因为 $r_{ui}r_{ui} = r_{ui}^2$，当 $r_{ui} \\in \\{-1,+1\\}$ 时其值为 $1$，当 $r_{ui}=0$ 时其值为 $0$。例如，$w_{33}=5$ 是因为用户 $U_3$ 评价了所有 $5$ 个项目。\n\n最后，题目要求给出元素 $w_{23}$ 的数值。根据我们对矩阵 $W$ 的计算：\n$w_{23} = (1)(-1) + (1)(1) + (-1)(1) + (1)(-1) + (0)(-1) = -1 + 1 - 1 - 1 + 0 = -2$。\n这个负权重表明，在他们共同评价的项目中，用户 $U_2$ 和 $U_3$ 之间存在净不一致。",
            "answer": "$$\\boxed{-2}$$"
        }
    ]
}