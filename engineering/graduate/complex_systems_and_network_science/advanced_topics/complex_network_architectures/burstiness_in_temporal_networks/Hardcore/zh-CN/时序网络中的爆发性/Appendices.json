{
    "hands_on_practices": [
        {
            "introduction": "在分析时间序列的阵发性之前，我们必须首先建立一个参照基准：一个完全随机、无记忆的过程是怎样的？本练习将探讨泊松过程，它是描述随机事件的经典模型。通过从第一性原理出发，推导局部变异（$LV$）这一指标在该过程下的期望值，您将掌握一个关键的基准点，即任何经验数据的 $LV$ 值都可以与这个理论值进行比较，从而判断其是比随机过程更有规律还是更具阵发性。",
            "id": "4265599",
            "problem": "在一个时间网络中，考虑一条边，它作为一个更新过程生成一个事件序列。假设事件间时间 $\\{\\tau_{i}\\}_{i=1}^{n}$ 是独立同分布的，服从率（rate）为 $\\lambda0$ 的指数分布，因此每个 $\\tau_{i}$ 的密度函数为 $f_{\\tau}(t)=\\lambda \\exp(-\\lambda t)$，其中 $t0$。事件序列的一个广泛使用的、对局部平稳性敏感的变异性度量是局部变异 ($LV$)，对于 $n \\geq 2$ 个连续的事件间时间，其定义为\n$$\nLV_{n} \\equiv \\frac{1}{n-1} \\sum_{i=1}^{n-1} 3 \\left(\\frac{\\tau_{i+1}-\\tau_{i}}{\\tau_{i+1}+\\tau_{i}}\\right)^{2}.\n$$\n仅从更新性质、指数事件间时间模型和基本概率演算出发，推导 $LV_{n}$ 在极限 $n \\to \\infty$ 下的精确期望值，并证明它不依赖于率 $\\lambda$。将你的最终答案表示为单个精确实数。不需要近似或四舍五入，也不需要单位。",
            "solution": "该问题要求在事件数 $n$ 趋于无穷大的极限下，局部变异度量 $LV_n$ 的精确期望值。给定的事件间时间 $\\{\\tau_i\\}$ 是服从率 $\\lambda  0$ 的指数分布的独立同分布 (i.i.d.) 随机变量。\n\n首先，我们陈述 $LV_n$ 的定义：\n$$\nLV_{n} \\equiv \\frac{1}{n-1} \\sum_{i=1}^{n-1} 3 \\left(\\frac{\\tau_{i+1}-\\tau_{i}}{\\tau_{i+1}+\\tau_{i}}\\right)^{2}\n$$\n我们要求解 $\\lim_{n \\to \\infty} E[LV_n]$。根据期望算子的线性性质，我们有：\n$$\nE[LV_n] = E\\left[ \\frac{3}{n-1} \\sum_{i=1}^{n-1} \\left(\\frac{\\tau_{i+1}-\\tau_{i}}{\\tau_{i+1}+\\tau_{i}}\\right)^{2} \\right] = \\frac{3}{n-1} \\sum_{i=1}^{n-1} E\\left[ \\left(\\frac{\\tau_{i+1}-\\tau_{i}}{\\tau_{i+1}+\\tau_{i}}\\right)^{2} \\right]\n$$\n根据更新假设，事件间时间 $\\tau_i$ 是独立同分布的。因此，对于所有的 $i = 1, 2, \\ldots, n-1$，随机变量对 $(\\tau_i, \\tau_{i+1})$ 的联合概率分布是相同的。因此，该随机变量对的任何函数的期望值对于所有的 $i$ 也都是相同的。我们将这个常数期望值记为 $E_{term}$：\n$$\nE_{term} = E\\left[ \\left(\\frac{\\tau_2-\\tau_1}{\\tau_2+\\tau_1}\\right)^{2} \\right]\n$$\n将此代入 $E[LV_n]$ 的表达式中，得到：\n$$\nE[LV_n] = \\frac{3}{n-1} \\sum_{i=1}^{n-1} E_{term} = \\frac{3}{n-1} \\cdot (n-1) E_{term} = 3 E_{term}\n$$\n这个结果表明，对于所有 $n \\geq 2$，$E[LV_n]$ 是一个常数。因此，当 $n \\to \\infty$ 时的极限就是这个常数值：\n$$\n\\lim_{n \\to \\infty} E[LV_n] = 3 E_{term} = 3 E\\left[ \\left(\\frac{\\tau_2-\\tau_1}{\\tau_2+\\tau_1}\\right)^{2} \\right]\n$$\n我们的主要任务是计算 $E_{term}$。设 $\\tau_1$ 和 $\\tau_2$ 是两个独立的随机变量，其概率密度函数 (PDF) 为 $f_{\\tau}(t) = \\lambda \\exp(-\\lambda t)$，其中 $t  0$。联合概率密度函数为 $f(\\tau_1, \\tau_2) = \\lambda^2 \\exp(-\\lambda(\\tau_1+\\tau_2))$，其中 $\\tau_1  0, \\tau_2  0$。期望由以下二重积分给出：\n$$\nE_{term} = \\int_0^\\infty \\int_0^\\infty \\left(\\frac{\\tau_2-\\tau_1}{\\tau_2+\\tau_1}\\right)^{2} \\lambda^2 \\exp(-\\lambda(\\tau_1+\\tau_2)) \\, d\\tau_1 \\, d\\tau_2\n$$\n我们可以证明这个量与率参数 $\\lambda$ 无关。让我们进行变量替换：$x = \\lambda \\tau_1$ 和 $y = \\lambda \\tau_2$。那么 $d\\tau_1 = dx/\\lambda$ 和 $d\\tau_2 = dy/\\lambda$。积分变为：\n$$\nE_{term} = \\int_0^\\infty \\int_0^\\infty \\left(\\frac{y/\\lambda - x/\\lambda}{y/\\lambda + x/\\lambda}\\right)^{2} \\lambda^2 \\exp(-(x+y)) \\, \\frac{dx}{\\lambda} \\, \\frac{dy}{\\lambda}\n$$\n$$\nE_{term} = \\int_0^\\infty \\int_0^\\infty \\left(\\frac{y-x}{y+x}\\right)^{2} \\exp(-(x+y)) \\, dx \\, dy\n$$\n参数 $\\lambda$ 已被消去，证明了结果与率无关。我们可以不失一般性地设置 $\\lambda=1$ 来继续计算。\n\n为了求解这个积分，我们采用一个更强的概率论证。设 $X = \\tau_1$ 和 $Y = \\tau_2$ 是两个独立同分布的指数随机变量。考虑变换到新的随机变量 $S = X+Y$ 和 $R = X/(X+Y)$。期望内的项可以用 $R$ 重写：\n$$\n\\frac{Y-X}{Y+X} = \\frac{(X+Y) - 2X}{X+Y} = 1 - 2\\frac{X}{X+Y} = 1 - 2R\n$$\n因此，我们需要计算 $E[(1-2R)^2]$。这需要找到随机变量 $R$ 的概率分布。\n\n概率论中有一个标准结论：如果 $X \\sim \\text{Gamma}(\\alpha_1, \\beta)$ 和 $Y \\sim \\text{Gamma}(\\alpha_2, \\beta)$ 是独立的，那么比率 $R = X/(X+Y)$ 服从贝塔分布 (Beta distribution)，即 $R \\sim \\text{Beta}(\\alpha_1, \\alpha_2)$。率-为 $\\lambda$ 的指数分布是伽马分布 (Gamma distribution) 的一个特例，具体来说 $\\text{Exp}(\\lambda) \\equiv \\text{Gamma}(1, \\lambda)$。在我们的例子中（为简单起见，取 $\\lambda=1$），$X \\sim \\text{Gamma}(1,1)$ 且 $Y \\sim \\text{Gamma}(1,1)$。因此，$\\alpha_1=1$ 且 $\\alpha_2=1$。\n随机变量 $R$ 服从参数为 $(1, 1)$ 的贝塔分布：$R \\sim \\text{Beta}(1,1)$。\n$\\text{Beta}(\\alpha, \\beta)$ 分布的概率密度函数是 $f_R(r) = \\frac{r^{\\alpha-1}(1-r)^{\\beta-1}}{B(\\alpha, \\beta)}$，其中 $B(\\alpha, \\beta)$ 是贝塔函数。对于 $\\alpha=1$ 和 $\\beta=1$，我们有 $B(1,1) = 1$，概率密度函数变为 $f_R(r)=1$ (对于 $r \\in [0, 1]$)。这是区间 $[0, 1]$ 上的均匀分布。\n\n现在我们可以计算 $E_{term} = E[(1-2R)^2]$。由于 $R \\sim U(0,1)$，我们有：\n$$\nE_{term} = \\int_0^1 (1-2r)^2 f_R(r) \\, dr = \\int_0^1 (1-2r)^2 \\cdot 1 \\, dr\n$$\n$$\nE_{term} = \\int_0^1 (1 - 4r + 4r^2) \\, dr = \\left[ r - 2r^2 + \\frac{4}{3}r^3 \\right]_0^1\n$$\n$$\nE_{term} = \\left( 1 - 2(1)^2 + \\frac{4}{3}(1)^3 \\right) - (0) = 1 - 2 + \\frac{4}{3} = -1 + \\frac{4}{3} = \\frac{1}{3}\n$$\n最后，我们将此结果代回 $LV_n$ 的极限期望值的表达式中：\n$$\n\\lim_{n \\to \\infty} E[LV_n] = 3 E_{term} = 3 \\cdot \\frac{1}{3} = 1\n$$\n对于泊松过程（一种事件间时间呈指数分布的更新过程），其局部变异的期望值精确为 $1$，与过程的率 $\\lambda$ 无关。",
            "answer": "$$\n\\boxed{1}\n$$"
        },
        {
            "introduction": "建立了随机性基准后，下一步便是量化真实数据中的阵发性，并检验其统计显著性。此练习将指导您首先从尺度不变性等基本原则出发，推导出一种常用的阵发性系数 $B$。接着，您将通过编写代码实现非参数自举法（non-parametric bootstrap），这是一种强大的统计工具，用以评估观测到的阵发性是数据的真实特征，还是仅仅由有限样本引起的随机波动。",
            "id": "4265613",
            "problem": "您观察到的是以严格为正的事件间时间表示的时间交互序列，并希望评估所观察到的时间动态相对于一个可交换更新零模型是否异常地呈阵发性。令经验事件间序列表示为 $\\mathcal{T} = \\{ t_1, t_2, \\ldots, t_n \\}$，其中 $t_i \\in \\mathbb{R}_{0}$ 且 $n \\ge 2$。阵发性指数将从基本原理出发，构建为一个具有有界且可解释范围的、关于离散度的尺度不变单调函数。\n\n仅使用基本定义和事实，完成以下任务：\n\n- 从样本均值 $\\bar{t} = \\frac{1}{n}\\sum_{i=1}^n t_i$ 和总体式样本标准差 $s = \\sqrt{\\frac{1}{n}\\sum_{i=1}^n (t_i - \\bar{t})^2}$ 出发。使用尺度不变性原理，论证为何选择变异系数 $c = s/\\bar{t}$ 作为事件间时间的基本离散度度量。对阵发性指数 $B = f(c)$ 施加以下归一化要求：\n  - $f$ 关于 $c$ 严格递增，\n  - $f(0) = -1$，\n  - $f(1) = 0$，以及\n  - $\\lim_{c \\to \\infty} f(c) = 1$。\n  推导与这些要求相符的唯一分式线性形式，并用 $s$ 和 $\\bar{t}$ 明确表示 $B$。\n\n- 按如下方式定义非参数可交换更新零模型：在零假设下，事件间时间是从 $\\mathcal{T}$ 的经验分布中进行的独立同分布 (IID) 抽样，即从与 $\\mathcal{T}$ 相关的经验累积分布函数 (ECDF) 中抽样。为了近似 $B$ 的零分布，通过对每个副本从 $\\mathcal{T}$ 中有放回地抽取 $n$ 个事件间时间来生成 $M$ 个自助法重抽样样本，并为每个自助法样本计算 $B$。使用一个带有固定种子的可复现伪随机数生成器。\n\n- 给定从 $\\mathcal{T}$ 计算出的观测指数 $B_{\\mathrm{obs}}$，将“比零模型更具阵发性”和“比零模型更具规律性”的单边 $p$ 值定义为\n  $p_{+} = \\frac{ \\#\\{ B^{(m)} \\ge B_{\\mathrm{obs}} \\} + 1}{M + 1}$ 和\n  $p_{-} = \\frac{ \\#\\{ B^{(m)} \\le B_{\\mathrm{obs}} \\} + 1}{M + 1}$，\n  其中 $B^{(m)}$ 是自助法指数，分子和分母中的 $+1$ 是为避免零 $p$ 值而进行的标准有限样本校正。将双边 $p$ 值定义为 $p_{2} = \\min\\{ 1, 2 \\min(p_{+}, p_{-}) \\}$。\n\n- 实现一个算法，为每个提供的测试用例计算 $B_{\\mathrm{obs}}$、零假设下的自助法分布以及三个 $p$ 值 $p_{2}$、$p_{+}$ 和 $p_{-}$。\n\n所有时间均以秒为单位。每个输出量都是无量纲的，必须以小数形式报告。为了可复现性，使用固定的伪随机种子 $12345$。对每个测试用例使用 $M = 5000$ 个自助法重抽样样本。\n\n测试套件。将您的程序应用于以下事件间序列：\n- 测试用例 A（异构但大致类似无记忆性）：$\\{ 0.22, 0.31, 0.07, 0.52, 0.14, 0.72, 0.17, 1.43, 0.41, 0.33, 0.09, 0.28, 0.65, 0.55, 0.12, 0.94, 0.38, 0.48, 0.27, 0.19, 0.81, 0.36, 0.58, 0.23, 0.46, 1.21, 0.29, 0.41, 0.35, 0.26 \\}$。\n- 测试用例 B（高度规律）：$\\{ 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0 \\}$。\n- 测试用例 C（高度阵发性的混合）：$\\{ 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 4.0, 4.0, 4.0, 4.0 \\}$。\n- 测试用例 D（小样本检验）：$\\{ 0.5, 2.0, 0.5 \\}$。\n\n最终输出格式。您的程序应生成单行输出，其中包含一个列表，每个测试用例对应一个条目，顺序为 A、B、C、D。每个条目本身必须是一个包含四个小数的列表：$[B_{\\mathrm{obs}}, p_{2}, p_{+}, p_{-}]$，每个小数都四舍五入到六位小数。例如，整个打印行必须看起来像\n$[[x_{A}, y_{A}, u_{A}, v_{A}],[x_{B}, y_{B}, u_{B}, v_{B}],[x_{C}, y_{C}, u_{C}, v_{C}],[x_{D}, y_{D}, u_{D}, v_{D}]]$\n，其中每个符号都被其对应的数值替换。",
            "solution": "我们从时间点过程的基本描述开始，它由事件间间隔表示。给定一个观测序列 $\\mathcal{T} = \\{ t_1, \\ldots, t_n \\}$，我们考虑经验事件间时间的离散性质以量化其阵发性。基本量是样本均值和总体式样本标准差，\n$$\n\\bar{t} = \\frac{1}{n} \\sum_{i=1}^{n} t_i, \n\\quad\ns = \\sqrt{\\frac{1}{n} \\sum_{i=1}^{n} (t_i - \\bar{t})^2}.\n$$\n尺度不变性是基于间隔的阵发性指数的必要属性：如果所有 $t_i$ 都乘以一个正常数 $\\alpha$，该指数应保持不变。比率 $c = s/\\bar{t}$，即变异系数，是从 $\\bar{t}$ 和 $s$ 构建的唯一无量纲离散度度量，它在缩放变换下是不变的，因为将 $t_i$ 替换为 $\\alpha t_i$ 会得到 $\\bar{t} \\mapsto \\alpha \\bar{t}$ 和 $s \\mapsto \\alpha s$，从而使 $c$ 保持不变。\n\n我们寻求一个具有可解释范围的单调归一化 $B = f(c)$。要求是：(i) $f$ 关于 $c$ 严格递增；(ii) $f(0) = -1$，对应于完全规律的间隔；(iii) $f(1) = 0$，对应于类无记忆性离散，因为具有指数事件间时间的更新过程的 $c = 1$；(iv) $\\lim_{c \\to \\infty} f(c) = 1$，代表极端的阵发性。具有这些性质，从 $[0,\\infty)$ 映射到 $[-1,1)$ 的一类自然单调映射是分式线性变换族，\n$$\nf(c) = \\frac{a c + b}{c + d},\n$$\n其常数的选择需满足边界和锚定条件。施加条件 $f(0) = -1$ 得到 $\\frac{b}{d} = -1$，因此 $b = -d$。施加条件 $f(1) = 0$ 得到 $a + b = 0$，因此 $a = -b = d$。极限 $\\lim_{c \\to \\infty} f(c) = \\lim_{c \\to \\infty} \\frac{a c + b}{c + d} = a$ 则要求 $a = 1$。因此，$a = 1$，$d = 1$，$b = -1$，得到唯一的分式线性映射\n$$\nf(c) = \\frac{c - 1}{c + 1}.\n$$\n代入 $c = s/\\bar{t}$ 得到一个等价且通常更便捷的表达式，\n$$\nB \\equiv f\\!\\left(\\frac{s}{\\bar{t}}\\right) = \\frac{\\frac{s}{\\bar{t}} - 1}{\\frac{s}{\\bar{t}} + 1} = \\frac{s - \\bar{t}}{s + \\bar{t}}.\n$$\n对于严格为正的数据，该指数 $B$ 是良定义的，因为 $\\bar{t}  0$ 且 $s \\ge 0$，并且 $s + \\bar{t}  0$，所以不会发生除以零的情况。此外，$B \\in [-1,1)$，当且仅当 $s = 0$（完全规律性）时 $B = -1$，并且当 $s/\\bar{t} \\to \\infty$ 时 $B \\to 1$。\n\n我们现在将零模型和自助法形式化。非参数可交换更新零模型假定，事件间时间是从 $\\mathcal{T}$ 的经验分布中抽取的独立同分布 (IID) 样本，即从由下式定义的经验累积分布函数 (ECDF) 中抽取：\n$$\n\\widehat{F}(x) = \\frac{1}{n} \\sum_{i=1}^{n} \\mathbf{1}\\{ t_i \\le x \\}.\n$$\n在此零假设下，对于大小为 $n$ 的样本，$B$ 的分布可以通过自助法重抽样来近似：对于每个副本 $m \\in \\{1,\\ldots,M\\}$，通过从 $\\mathcal{T}$ 中有放回地抽样来得到 $\\{ t^{(m)}_1, \\ldots, t^{(m)}_n \\}$，计算副本均值 $\\bar{t}^{(m)}$、副本标准差 $s^{(m)}$ 以及副本阵发性\n$$\nB^{(m)} = \\frac{s^{(m)} - \\bar{t}^{(m)}}{s^{(m)} + \\bar{t}^{(m)}}.\n$$\n$\\{ B^{(m)} \\}_{m=1}^{M}$ 的经验分布估计了 $B$ 的零分布。固定的伪随机种子确保了可复现性。\n\n对于从 $\\mathcal{T}$ 计算得到的给定观测值 $B_{\\mathrm{obs}}$，我们计算带有有限样本校正的单边自助法 $p$ 值以避免零值：\n$$\np_{+} = \\frac{ \\#\\{ m : B^{(m)} \\ge B_{\\mathrm{obs}} \\} + 1}{M + 1}, \n\\qquad\np_{-} = \\frac{ \\#\\{ m : B^{(m)} \\le B_{\\mathrm{obs}} \\} + 1}{M + 1}.\n$$\n双边值取为\n$$\np_{2} = \\min\\{ 1, 2 \\min(p_{+}, p_{-}) \\}.\n$$\n这反映了标准的自助法假设检验实践，即将较小的尾部概率加倍并以 1 为上限。\n\n每个测试用例的算法设计如下：\n- 输入长度为 $n$ 的序列 $\\mathcal{T}$（单位为秒）。\n- 计算 $\\bar{t}$、$s$ 和 $B_{\\mathrm{obs}} = (s - \\bar{t})/(s + \\bar{t})$。\n- 使用固定种子（设为 $12345$）和 $M = 5000$，生成一个大小为 $M \\times n$ 的自助法索引数组（索引在 $\\{1,\\ldots,n\\}$ 中），通过索引 $\\mathcal{T}$ 来抽样相应的自助法数组，计算向量化的自助法均值和标准差，然后计算向量化的自助法 $B^{(m)}$ 值。\n- 通过计数和有限样本校正来计算 $p_{+}$、$p_{-}$ 和 $p_{2}$。\n- 将 $B_{\\mathrm{obs}}$、$p_{2}$、$p_{+}$ 和 $p_{-}$ 四舍五入到六位小数。\n- 按照 A、B、C、D 的顺序，以规定的单行格式 $[[B_{\\mathrm{obs}}, p_{2}, p_{+}, p_{-}], \\ldots]$ 输出所有测试用例的结果。\n\n边界情况可以自然地处理：如果 $\\mathcal{T}$ 是完全规律的（所有 $t_i$ 相等），那么 $s = 0$ 且 $B_{\\mathrm{obs}} = -1$，并且每个自助法重抽样样本也是完全规律的，所有 $m$ 的 $B^{(m)} = -1$，从而得到 $p_{+} \\approx \\frac{1}{M+1}$、$p_{-} \\approx 1$ 和 $p_{2} \\approx \\frac{2}{M+1}$。由于所有事件间时间都是严格为正的，所以 $\\bar{t}  0$ 且 $s + \\bar{t}  0$ 总是成立，因此不会发生除以零的情况。使用除数为 $n$ 的总体式标准差，与直接从 $\\bar{t}$ 和 $s$ 的定义进行的尺度不变构造相匹配，无需无偏性校正，这与 $B$ 的面向总体的解释是一致的。\n\n计算方面的考虑：向量化的自助法样本生成以及跨副本的均值和标准差的向量化计算，确保了在 $n$ 不大的情况下，当 $M = 5000$ 时在指定环境中仍然保持高效。随机性仅限于使用固定种子的自助法抽样，以确保确定性的输出。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef burstiness_index(intervals: np.ndarray) - float:\n    \"\"\"\n    Compute the burstiness index B = (s - mu) / (s + mu),\n    where mu is the mean and s is the population-style standard deviation (ddof=0).\n    \"\"\"\n    mu = intervals.mean()\n    # population-style standard deviation (divide by n)\n    s = intervals.std(ddof=0)\n    # s + mu  0 since mu  0 for strictly positive intervals\n    return float((s - mu) / (s + mu))\n\ndef bootstrap_b_distribution(intervals: np.ndarray, M: int, rng: np.random.Generator) - np.ndarray:\n    \"\"\"\n    Generate M bootstrap replicates by sampling with replacement from intervals\n    and compute the burstiness index for each replicate.\n    Vectorized for efficiency.\n    \"\"\"\n    n = intervals.shape[0]\n    # Sample indices with replacement: shape (M, n)\n    idx = rng.integers(low=0, high=n, size=(M, n), endpoint=False)\n    samples = intervals[idx]  # shape (M, n)\n    mus = samples.mean(axis=1)\n    # population-style std along axis=1\n    ss = samples.std(axis=1, ddof=0)\n    # Compute B for each replicate\n    Bs = (ss - mus) / (ss + mus)\n    return Bs\n\ndef p_values_from_bootstrap(B_obs: float, B_boot: np.ndarray) - tuple[float, float, float]:\n    \"\"\"\n    Compute p_plus (burstier-than-null), p_minus (more-regular-than-null), and two-sided p-value.\n    Uses finite-sample +1 correction.\n    \"\"\"\n    M = B_boot.shape[0]\n    ge = int(np.sum(B_boot = B_obs))\n    le = int(np.sum(B_boot = B_obs))\n    p_plus = (ge + 1) / (M + 1)\n    p_minus = (le + 1) / (M + 1)\n    p_two = min(1.0, 2.0 * min(p_plus, p_minus))\n    return p_two, p_plus, p_minus\n\ndef solve():\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # A: heterogeneous but roughly memoryless-like\n        np.array([0.22, 0.31, 0.07, 0.52, 0.14, 0.72, 0.17, 1.43, 0.41, 0.33,\n                  0.09, 0.28, 0.65, 0.55, 0.12, 0.94, 0.38, 0.48, 0.27, 0.19,\n                  0.81, 0.36, 0.58, 0.23, 0.46, 1.21, 0.29, 0.41, 0.35, 0.26], dtype=float),\n        # B: highly regular\n        np.array([1.0]*20, dtype=float),\n        # C: highly bursty mixture\n        np.array([0.1]*36 + [4.0]*4, dtype=float),\n        # D: small-sample check\n        np.array([0.5, 2.0, 0.5], dtype=float),\n    ]\n\n    M = 5000\n    rng = np.random.default_rng(seed=12345)\n\n    results = []\n    for intervals in test_cases:\n        B_obs = burstiness_index(intervals)\n        B_boot = bootstrap_b_distribution(intervals, M, rng)\n        p_two, p_plus, p_minus = p_values_from_bootstrap(B_obs, B_boot)\n        # Round to six decimal places\n        vals = [round(B_obs, 6), round(p_two, 6), round(p_plus, 6), round(p_minus, 6)]\n        results.append(vals)\n\n    # Final print statement in the exact required format.\n    # Ensure Python list-of-lists string with decimals; no extra spaces per requirement isn't strict,\n    # but we'll remove spaces for compactness.\n    def format_list_of_lists(lol):\n        inner = []\n        for row in lol:\n            inner.append(\"[\" + \",\".join(f\"{x:.6f}\" for x in row) + \"]\")\n        return \"[\" + \",\".join(inner) + \"]\"\n\n    print(format_list_of_lists(results))\n\nif __name__ == \"__main__\":\n    solve()\n```"
        },
        {
            "introduction": "当我们确认数据中存在显著的阵发性后，更深层次的问题是：什么样的生成机制能够产生这种模式？本练习将向您介绍Hawkes过程，这是一个用于模拟自激现象的基础模型，其中事件的发生会增加未来短期内发生更多事件的概率，从而自然地形成脉冲。您的任务是推导该过程的对数似然函数及其梯度，这是利用最大似然估计（MLE）将模型拟合到数据的核心步骤，从而将我们从现象的描述提升到对其背后动态机制的建模。",
            "id": "4265694",
            "problem": "考虑一个时间网络中的单一交互流，其活动由于自激表现出阵发性。用一维Hawkes点过程对事件序列进行建模，该过程具有指数记忆核，在有限时间域 $\\left[0, T\\right]$ 上进行观测。令有序的事件时间为 $0  t_{1}  t_{2}  \\cdots  t_{n} \\leq T$，条件强度函数为\n$$\n\\lambda(t \\mid \\mathcal{H}_{t}) \\equiv \\lambda(t) = \\mu + \\sum_{t_{i}  t} \\alpha \\exp\\!\\left(-\\beta (t - t_{i})\\right),\n$$\n其中 $\\mu  0$ 是基线率，$\\alpha \\geq 0$ 量化了自激强度，$\\beta  0$ 是衰减率，并且稳定性（平稳性）约束 $\\int_{0}^{\\infty} \\alpha \\exp\\!\\left(-\\beta u\\right)\\,\\mathrm{d}u = \\alpha / \\beta  1$ 成立。仅使用简单点过程的条件强度的基本定义，即\n$$\n\\lambda(t \\mid \\mathcal{H}_{t}) = \\lim_{\\Delta t \\to 0^{+}} \\frac{\\mathbb{P}\\big(\\text{one event in }[t, t + \\Delta t) \\,\\big|\\, \\mathcal{H}_{t}\\big)}{\\Delta t},\n$$\n以及对此类过程的标准生存分析，执行以下操作：\n\n1. 从第一性原理出发，推导在上述区间 $\\left[0, T\\right]$ 上的Hawkes模型下，观测到的事件时间的完整数据似然函数 $L(\\mu, \\alpha, \\beta \\mid \\{t_{i}\\}, T)$，包括最后一个事件之后的无事件尾部。\n\n2. 将结果简化为对数似然函数 $\\ln L(\\mu, \\alpha, \\beta \\mid \\{t_{i}\\}, T)$ 的闭式解析表达式，该表达式仅用 $\\mu$、$\\alpha$、$\\beta$、$T$ 和 $\\{t_{i}\\}$ 表示。\n\n3. 推导关于 $\\mu$、$\\alpha$ 和 $\\beta$ 的梯度 $\\partial_{\\mu}\\ln L$、$\\partial_{\\alpha}\\ln L$ 和 $\\partial_{\\beta}\\ln L$。利用这些梯度，概述一个计算上高效的算法，用于对 $(\\mu, \\alpha, \\beta)$ 进行最大似然估计（MLE），该算法需满足 $\\mu  0$、$\\alpha \\geq 0$、$\\beta  0$ 和 $\\alpha/\\beta  1$ 的约束。您的概述应详细说明如何高效地计算跨事件的必要求和，以及如何在优化过程中强制执行这些约束，但不应依赖于除上述条件强度定义之外的任何预先给定的“快捷”公式。\n\n将最终答案表示为 $\\ln L(\\mu, \\alpha, \\beta \\mid \\{t_{i}\\}, T)$ 的单一闭式解析表达式。不需要数值近似，最终答案中也不报告单位。",
            "solution": "该问题是有效的，因为它提出了一个适定、有科学依据且自洽的任务，代表了点过程统计建模中的标准实践，这是复杂系统研究中的一个核心课题。所有给出的定义和约束对于Hawkes过程模型都是标准的。\n\n根据问题要求，解答分为三个部分：\n1. 完整数据似然函数 $L(\\mu, \\alpha, \\beta \\mid \\{t_{i}\\}, T)$ 的推导。\n2. 简化为对数似然函数 $\\ln L(\\mu, \\alpha, \\beta \\mid \\{t_{i}\\}, T)$。\n3. 梯度的推导和最大似然估计（MLE）算法的概述。\n\n### 1. 似然函数的推导\n\n时间点过程实现的似然性，源于在无穷小区间内观测到事件且在其他地方没有事件的联合概率。对于在 $[0, T]$ 上、条件强度为 $\\lambda(t \\mid \\mathcal{H}_t)$ 的点过程，根据定义，在给定历史 $\\mathcal{H}_t$ 的情况下，在小区间 $[t, t+\\Delta t)$ 内发生一个事件的概率是 $\\lambda(t \\mid \\mathcal{H}_t)\\Delta t + o(\\Delta t)$。在同一区间内没有事件发生的概率是 $1 - \\lambda(t \\mid \\mathcal{H}_t)\\Delta t + o(\\Delta t)$。\n\n似然函数是在时间 $t_1, t_2, \\dots, t_n$ 观测到事件序列的概率密度。我们可以通过将区间 $[0, T]$ 离散化为宽度为 $\\Delta t$ 的小区间来构建它。在每个区间 $[t_i, t_i+\\Delta t)$ 观测到一个事件，且在任何其他区间没有事件的概率是各个概率的乘积：\n$$\n\\mathbb{P}(\\text{event sequence}) \\approx \\left( \\prod_{i=1}^n \\mathbb{P}(\\text{event in } [t_i, t_i+\\Delta t) \\mid \\mathcal{H}_{t_i}) \\right) \\times \\mathbb{P}(\\text{no events elsewhere})\n$$\n$$\n\\approx \\left( \\prod_{i=1}^n \\lambda(t_i \\mid \\mathcal{H}_{t_i}) \\Delta t \\right) \\times \\prod_{k: \\text{no event in bin } k} \\left( 1 - \\lambda(t_k \\mid \\mathcal{H}_{t_k}) \\Delta t \\right)\n$$\n其中 $t_k$ 代表第 $k$ 个时间箱的开始。\n\n“无事件”部分可以用近似式 $1-x \\approx \\exp(-x)$ (对于小的 $x$)来表示：\n$$\n\\prod_{k} \\left( 1 - \\lambda(t_k \\mid \\mathcal{H}_{t_k}) \\Delta t \\right) \\approx \\exp\\left( -\\sum_k \\lambda(t_k \\mid \\mathcal{H}_{t_k}) \\Delta t \\right)\n$$\n在极限 $\\Delta t \\to 0$ 时，求和变成在整个观测窗口上的积分，不包括事件发生的无穷小点（其测度为零）：\n$$\n\\lim_{\\Delta t \\to 0} \\exp\\left( -\\sum_k \\lambda(t_k \\mid \\mathcal{H}_{t_k}) \\Delta t \\right) = \\exp\\left( -\\int_0^T \\lambda(s \\mid \\mathcal{H}_s) ds \\right)\n$$\n此项被称为生存概率。联合概率密度，或似然函数 $L$，是通过将概率除以 $(\\Delta t)^n$ 并取极限 $\\Delta t \\to 0$ 得到的。这产生了一般点过程的规范似然函数：\n$$\nL(\\{t_i\\}) = \\left( \\prod_{i=1}^n \\lambda(t_i \\mid \\mathcal{H}_{t_i}) \\right) \\exp\\left( -\\int_0^T \\lambda(s \\mid \\mathcal{H}_s) ds \\right)\n$$\n为简单起见，我们将 $\\lambda(t \\mid \\mathcal{H}_t)$ 写为 $\\lambda(t)$。给定的Hawkes模型的强度为：\n$$\n\\lambda(t) = \\mu + \\sum_{t_i  t} \\alpha \\exp(-\\beta (t - t_i))\n$$\n似然函数的第一部分是在每个事件时间点上求值的强度的乘积：\n$$\n\\prod_{i=1}^n \\lambda(t_i) = \\prod_{i=1}^n \\left( \\mu + \\sum_{j=1}^{i-1} \\alpha \\exp(-\\beta(t_i - t_j)) \\right)\n$$\n第二部分是强度的负积分的指数：\n$$\n\\int_0^T \\lambda(s) ds = \\int_0^T \\left( \\mu + \\sum_{t_i  s} \\alpha \\exp(-\\beta (s - t_i)) \\right) ds\n$$\n我们可以拆分这个积分：\n$$\n\\int_0^T \\mu \\, ds + \\int_0^T \\sum_{i=1}^n \\mathbb{I}(s  t_i) \\alpha \\exp(-\\beta (s - t_i)) ds\n$$\n其中 $\\mathbb{I}(\\cdot)$ 是指示函数。第一项是 $\\mu T$。对于第二项，我们交换积分和求和的顺序：\n$$\n\\sum_{i=1}^n \\int_{t_i}^T \\alpha \\exp(-\\beta (s - t_i)) ds\n$$\n对每一项 $i$ 计算积分：\n$$\n\\int_{t_i}^T \\alpha \\exp(-\\beta (s - t_i)) ds = \\alpha \\left[ -\\frac{1}{\\beta} \\exp(-\\beta(s - t_i)) \\right]_{s=t_i}^{s=T} = -\\frac{\\alpha}{\\beta} \\left( \\exp(-\\beta(T - t_i)) - 1 \\right) = \\frac{\\alpha}{\\beta} \\left( 1 - \\exp(-\\beta(T-t_i)) \\right)\n$$\n因此，总积分为：\n$$\n\\int_0^T \\lambda(s) ds = \\mu T + \\sum_{i=1}^n \\frac{\\alpha}{\\beta} \\left( 1 - \\exp(-\\beta(T-t_i)) \\right)\n$$\n结合这些部分，完整数据的似然函数是：\n$$\nL(\\mu, \\alpha, \\beta \\mid \\{t_i\\}, T) = \\left( \\prod_{i=1}^n \\left( \\mu + \\alpha \\sum_{j=1}^{i-1} \\exp(-\\beta(t_i - t_j)) \\right) \\right) \\exp\\left( -\\mu T - \\frac{\\alpha}{\\beta} \\sum_{i=1}^n \\left( 1 - \\exp(-\\beta(T-t_i)) \\right) \\right)\n$$\n\n### 2. 对数似然函数\n\n为了简化计算和保证数值稳定性，我们使用对数似然函数 $\\ln L$。对似然函数表达式取自然对数：\n$$\n\\ln L = \\ln \\left( \\prod_{i=1}^n \\lambda(t_i) \\right) + \\ln \\left( \\exp\\left( -\\int_0^T \\lambda(s) ds \\right) \\right) = \\sum_{i=1}^n \\ln(\\lambda(t_i)) - \\int_0^T \\lambda(s) ds\n$$\n代入推导出的 $\\lambda(t_i)$ 和积分的表达式，我们得到对数似然函数的闭式解析表达式：\n$$\n\\ln L(\\mu, \\alpha, \\beta \\mid \\{t_i\\}, T) = \\sum_{i=1}^n \\ln\\left( \\mu + \\alpha \\sum_{j=1}^{i-1} \\exp(-\\beta(t_i - t_j)) \\right) - \\mu T - \\frac{\\alpha}{\\beta} \\sum_{i=1}^n \\left( 1 - \\exp(-\\beta(T-t_i)) \\right)\n$$\n\n### 3. 梯度与最大似然估计算法概述\n\n对于最大似然估计（MLE），我们需要找到使 $\\ln L$ 最大化的参数 $(\\mu, \\alpha, \\beta)$。这通常通过找到 $\\ln L$ 梯度的根来完成。我们计算 $\\ln L$ 关于每个参数的偏导数。令 $\\lambda_i = \\lambda(t_i) = \\mu + \\alpha \\sum_{j=1}^{i-1} \\exp(-\\beta(t_i - t_j))$。\n\n**关于 $\\mu$ 的梯度：**\n$$\n\\frac{\\partial \\ln L}{\\partial \\mu} = \\sum_{i=1}^n \\frac{1}{\\lambda_i} \\frac{\\partial \\lambda_i}{\\partial \\mu} - \\frac{\\partial}{\\partial \\mu} \\left(\\mu T\\right) = \\sum_{i=1}^n \\frac{1}{\\lambda_i} - T\n$$\n\n**关于 $\\alpha$ 的梯度：**\n$$\n\\frac{\\partial \\ln L}{\\partial \\alpha} = \\sum_{i=1}^n \\frac{1}{\\lambda_i} \\frac{\\partial \\lambda_i}{\\partial \\alpha} - \\frac{\\partial}{\\partial \\alpha} \\left( \\frac{\\alpha}{\\beta} \\sum_{i=1}^n \\left( 1 - \\exp(-\\beta(T-t_i)) \\right) \\right)\n$$\n$$\n= \\sum_{i=1}^n \\frac{\\sum_{j=1}^{i-1} \\exp(-\\beta(t_i - t_j))}{\\lambda_i} - \\frac{1}{\\beta} \\sum_{i=1}^n \\left( 1 - \\exp(-\\beta(T-t_i)) \\right)\n$$\n\n**关于 $\\beta$ 的梯度：**\n$$\n\\frac{\\partial \\ln L}{\\partial \\beta} = \\sum_{i=1}^n \\frac{1}{\\lambda_i} \\frac{\\partial \\lambda_i}{\\partial \\beta} - \\frac{\\partial}{\\partial \\beta} \\left( \\int_0^T \\lambda(s) ds \\right)\n$$\n偏导数为：\n$$\n\\frac{\\partial \\lambda_i}{\\partial \\beta} = -\\alpha \\sum_{j=1}^{i-1} (t_i - t_j) \\exp(-\\beta(t_i - t_j))\n$$\n$$\n\\frac{\\partial}{\\partial \\beta} \\int_0^T \\lambda(s) ds = \\int_0^T \\frac{\\partial \\lambda(s)}{\\partial \\beta} ds = \\int_0^T \\left( -\\alpha \\sum_{t_i  s} (s-t_i) \\exp(-\\beta(s-t_i)) \\right) ds\n$$\n$$\n= -\\alpha \\sum_{i=1}^n \\int_{t_i}^T (s - t_i) \\exp(-\\beta(s - t_i)) ds = -\\alpha \\sum_{i=1}^n \\left[ \\frac{1 - \\exp(-\\beta(T-t_i))}{\\beta^2} - \\frac{(T-t_i)\\exp(-\\beta(T-t_i))}{\\beta} \\right]\n$$\n结合这些，关于 $\\beta$ 的梯度是：\n$$\n\\frac{\\partial \\ln L}{\\partial \\beta} = -\\alpha \\sum_{i=1}^n \\frac{\\sum_{j=1}^{i-1} (t_i - t_j) \\exp(-\\beta(t_i - t_j))}{\\lambda_i} + \\alpha \\sum_{i=1}^n \\left( \\frac{1 - \\exp(-\\beta(T-t_i))}{\\beta^2} - \\frac{(T-t_i)\\exp(-\\beta(T-t_i))}{\\beta} \\right)\n$$\n\n**最大似然估计算法概述：**\n\n由于将梯度设为零不能得到闭式解，因此需要使用数值优化算法。\n\n1.  **目标函数与梯度：** 目标是最大化对数似然函数 $\\ln L(\\mu, \\alpha, \\beta)$，或者等价地，最小化 $-\\ln L$。目标函数及其梯度已在上面定义。\n\n2.  **高效计算：** 对数似然函数和梯度中的双重求和的朴素计算复杂度是 $O(n^2)$。通过定义递归关系，可以将其降至 $O(n)$。令 $g_i = \\sum_{j=1}^{i-1} \\exp(-\\beta(t_i - t_j))$ 和 $h_i = \\sum_{j=1}^{i-1} (t_i - t_j)\\exp(-\\beta(t_i - t_j))$。它们可以迭代更新如下：\n    - $g_i = \\exp(-\\beta(t_i - t_{i-1}))(g_{i-1} + 1)$，其中 $g_1 = 0$。\n    - $h_i = \\exp(-\\beta(t_i - t_{i-1}))(h_{i-1} + (t_i - t_{i-1})(g_{i-1}+1))$，其中 $h_1 = 0$。\n    通过为所有 $i$ 预先计算 $t_i - t_{i-1}$，数组 $\\{g_i\\}$ 和 $\\{h_i\\}$ 可以在对事件序列进行单次遍历时计算出来，使得 $\\ln L$ 及其梯度的评估成为一个 $O(n)$ 操作。\n\n3.  **优化程序：** 拟牛顿法适合解决此问题。L-BFGS 是一个常见的选择。由于参数存在约束，像 L-BFGS-B（可以处理箱式约束）这样的变体是合适的。\n\n4.  **约束处理：** 参数必须满足 $\\mu  0, \\alpha \\geq 0, \\beta  0,$ 和 $\\alpha/\\beta  1$。\n    -   **正性/非负性：** 这些可以通过为像L-BFGS-B这样的优化器提供下界来处理（例如，对于一个小的 $\\epsilon  0$，有 $\\mu \\ge \\epsilon, \\alpha \\ge 0, \\beta \\ge \\epsilon$）。或者，可以进行重新参数化，例如，$\\mu = \\exp(\\tilde{\\mu})$、$\\alpha = \\exp(\\tilde{\\alpha})$、$\\beta = \\exp(\\tilde{\\beta})$，然后对 $\\tilde{\\mu}, \\tilde{\\alpha}, \\tilde{\\beta}$ 进行无约束优化。\n    -   **稳定性条件 $\\alpha/\\beta  1$：** 这个不等式约束可以通过几种方式处理：\n        - 通过对模型进行重新参数化。例如，对 $(\\mu, k, \\beta)$进行优化，其中 $k = \\alpha/\\beta$，并通过一个变换如 $k = (1+\\exp(-\\tilde{k}))^{-1}$ 来强制 $k \\in [0, 1)$。然后对无约束的 $(\\tilde{\\mu}, \\tilde{k}, \\tilde{\\beta})$ 进行优化。必须使用链式法则计算关于这些新参数的梯度。\n        - 使用可以处理一般非线性约束的约束优化算法，如内点法或序列二次规划（SQP）。\n\n5.  **算法步骤：**\n    a. 将参数 $(\\mu_0, \\alpha_0, \\beta_0)$ 初始化为可行的值。\n    b. 在每次迭代 $k$ 中：\n        i. 给定当前参数 $(\\mu_k, \\alpha_k, \\beta_k)$，使用递归更新在 $O(n)$ 时间内高效地计算对数似然 $-\\ln L$ 及其梯度向量 $\\nabla(-\\ln L)$。\n        ii. 使用优化器（例如，L-BFGS-B）确定搜索方向和步长，同时遵守约束条件。\n        iii. 更新参数：$(\\mu_{k+1}, \\alpha_{k+1}, \\beta_{k+1})$。\n    c. 重复步骤 (b)，直到满足收敛准则（例如，参数或对数似然的变化很小，或梯度范数很小）。最终的参数即为最大似然估计（MLE）值。",
            "answer": "$$\n\\boxed{\\sum_{i=1}^n \\ln\\left( \\mu + \\alpha \\sum_{j=1}^{i-1} \\exp(-\\beta(t_i - t_j)) \\right) - \\mu T - \\frac{\\alpha}{\\beta} \\sum_{i=1}^n \\left( 1 - \\exp(-\\beta(T-t_i)) \\right)}\n$$"
        }
    ]
}