{
    "hands_on_practices": [
        {
            "introduction": "This exercise establishes a crucial theoretical benchmark for analyzing temporal event data. Before we can identify burstiness, we must first define what it means for a sequence to be \"random\" or memoryless. This practice guides you through calculating the expected value of the local variation ($LV$), a common metric for temporal regularity, for a Poisson process—the canonical model of random events—demonstrating that it yields a constant value regardless of the event rate . Mastering this derivation provides a fundamental reference point for interpreting burstiness measures in real-world data.",
            "id": "4265599",
            "problem": "In a temporal network, consider a single edge that generates an event sequence as a renewal process. Suppose the inter-event times $\\{\\tau_{i}\\}_{i=1}^{n}$ are independent and identically distributed with an exponential distribution of rate $\\lambda0$, so that each $\\tau_{i}$ has density $f_{\\tau}(t)=\\lambda \\exp(-\\lambda t)$ for $t0$. A widely used local stationarity-sensitive variability metric for event sequences is the local variation ($LV$), defined for $n \\geq 2$ successive inter-event times by\n$$\nLV_{n} \\equiv \\frac{1}{n-1} \\sum_{i=1}^{n-1} 3 \\left(\\frac{\\tau_{i+1}-\\tau_{i}}{\\tau_{i+1}+\\tau_{i}}\\right)^{2}.\n$$\nStarting only from the renewal property, the exponential inter-event time model, and basic probability calculus, derive the exact expected value of $LV_{n}$ in the limit $n \\to \\infty$, and demonstrate that it does not depend on the rate $\\lambda$. Express your final answer as a single exact real number. No approximation or rounding is required, and no units are needed.",
            "solution": "The problem asks for the exact expected value of the local variation metric $LV_n$ in the limit as the number of events $n$ approaches infinity. The inter-event times $\\{\\tau_i\\}$ are given as independent and identically distributed (i.i.d.) random variables following an exponential distribution with rate $\\lambda  0$.\n\nFirst, we state the definition of $LV_n$:\n$$\nLV_{n} \\equiv \\frac{1}{n-1} \\sum_{i=1}^{n-1} 3 \\left(\\frac{\\tau_{i+1}-\\tau_{i}}{\\tau_{i+1}+\\tau_{i}}\\right)^{2}\n$$\nWe seek to compute $\\lim_{n \\to \\infty} E[LV_n]$. By the linearity of the expectation operator, we have:\n$$\nE[LV_n] = E\\left[ \\frac{3}{n-1} \\sum_{i=1}^{n-1} \\left(\\frac{\\tau_{i+1}-\\tau_{i}}{\\tau_{i+1}+\\tau_{i}}\\right)^{2} \\right] = \\frac{3}{n-1} \\sum_{i=1}^{n-1} E\\left[ \\left(\\frac{\\tau_{i+1}-\\tau_{i}}{\\tau_{i+1}+\\tau_{i}}\\right)^{2} \\right]\n$$\nThe inter-event times $\\tau_i$ are i.i.d. by the renewal hypothesis. Therefore, the joint probability distribution of the pair $(\\tau_i, \\tau_{i+1})$ is identical for all $i = 1, 2, \\ldots, n-1$. Consequently, the expected value of any function of this pair is also identical for all $i$. Let us denote this constant expected value by $E_{term}$:\n$$\nE_{term} = E\\left[ \\left(\\frac{\\tau_2-\\tau_1}{\\tau_2+\\tau_1}\\right)^{2} \\right]\n$$\nSubstituting this into the expression for $E[LV_n]$ yields:\n$$\nE[LV_n] = \\frac{3}{n-1} \\sum_{i=1}^{n-1} E_{term} = \\frac{3}{n-1} \\cdot (n-1) E_{term} = 3 E_{term}\n$$\nThis result shows that $E[LV_n]$ is a constant for all $n \\geq 2$. Therefore, the limit as $n \\to \\infty$ is simply this constant value:\n$$\n\\lim_{n \\to \\infty} E[LV_n] = 3 E_{term} = 3 E\\left[ \\left(\\frac{\\tau_2-\\tau_1}{\\tau_2+\\tau_1}\\right)^{2} \\right]\n$$\nOur main task is to compute $E_{term}$. Let $\\tau_1$ and $\\tau_2$ be two independent random variables with the probability density function (PDF) $f_{\\tau}(t) = \\lambda \\exp(-\\lambda t)$ for $t  0$. The joint PDF is $f(\\tau_1, \\tau_2) = \\lambda^2 \\exp(-\\lambda(\\tau_1+\\tau_2))$ for $\\tau_1  0, \\tau_2  0$. The expectation is given by the double integral:\n$$\nE_{term} = \\int_0^\\infty \\int_0^\\infty \\left(\\frac{\\tau_2-\\tau_1}{\\tau_2+\\tau_1}\\right)^{2} \\lambda^2 \\exp(-\\lambda(\\tau_1+\\tau_2)) \\, d\\tau_1 \\, d\\tau_2\n$$\nWe can demonstrate that this quantity is independent of the rate parameter $\\lambda$. Let us perform a change of variables: $x = \\lambda \\tau_1$ and $y = \\lambda \\tau_2$. Then $d\\tau_1 = dx/\\lambda$ and $d\\tau_2 = dy/\\lambda$. The integral becomes:\n$$\nE_{term} = \\int_0^\\infty \\int_0^\\infty \\left(\\frac{y/\\lambda - x/\\lambda}{y/\\lambda + x/\\lambda}\\right)^{2} \\lambda^2 \\exp(-(x+y)) \\, \\frac{dx}{\\lambda} \\, \\frac{dy}{\\lambda}\n$$\n$$\nE_{term} = \\int_0^\\infty \\int_0^\\infty \\left(\\frac{y-x}{y+x}\\right)^{2} \\exp(-(x+y)) \\, dx \\, dy\n$$\nThe parameter $\\lambda$ has been eliminated, proving that the result is independent of the rate. We can proceed with the calculation by setting $\\lambda=1$ without loss of generality.\n\nTo solve this integral, we employ a more powerful probabilistic argument. Let $X = \\tau_1$ and $Y = \\tau_2$ be two i.i.d. exponential random variables. Consider the transformation to new random variables $S = X+Y$ and $R = X/(X+Y)$. The term inside the expectation can be rewritten in terms of $R$:\n$$\n\\frac{Y-X}{Y+X} = \\frac{(X+Y) - 2X}{X+Y} = 1 - 2\\frac{X}{X+Y} = 1 - 2R\n$$\nThus, we need to calculate $E[(1-2R)^2]$. This requires finding the probability distribution of the random variable $R$.\n\nIt is a standard result from probability theory that if $X \\sim \\text{Gamma}(\\alpha_1, \\beta)$ and $Y \\sim \\text{Gamma}(\\alpha_2, \\beta)$ are independent, then the ratio $R = X/(X+Y)$ follows a Beta distribution, $R \\sim \\text{Beta}(\\alpha_1, \\alpha_2)$. An exponential distribution with rate $\\lambda$ is a special case of the Gamma distribution, specifically $\\text{Exp}(\\lambda) \\equiv \\text{Gamma}(1, \\lambda)$. In our case (with $\\lambda=1$ for simplicity), $X \\sim \\text{Gamma}(1,1)$ and $Y \\sim \\text{Gamma}(1,1)$. Therefore, $\\alpha_1=1$ and $\\alpha_2=1$.\nThe random variable $R$ follows a Beta distribution with parameters $(1, 1)$: $R \\sim \\text{Beta}(1,1)$.\nThe PDF of a $\\text{Beta}(\\alpha, \\beta)$ distribution is $f_R(r) = \\frac{r^{\\alpha-1}(1-r)^{\\beta-1}}{B(\\alpha, \\beta)}$, where $B(\\alpha, \\beta)$ is the Beta function. For $\\alpha=1$ and $\\beta=1$, we have $B(1,1) = 1$, and the PDF becomes $f_R(r)=1$ for $r \\in [0, 1]$. This is the uniform distribution on the interval $[0, 1]$.\n\nNow we can calculate $E_{term} = E[(1-2R)^2]$. Since $R \\sim U(0,1)$, we have:\n$$\nE_{term} = \\int_0^1 (1-2r)^2 f_R(r) \\, dr = \\int_0^1 (1-2r)^2 \\cdot 1 \\, dr\n$$\n$$\nE_{term} = \\int_0^1 (1 - 4r + 4r^2) \\, dr = \\left[ r - 2r^2 + \\frac{4}{3}r^3 \\right]_0^1\n$$\n$$\nE_{term} = \\left( 1 - 2(1)^2 + \\frac{4}{3}(1)^3 \\right) - (0) = 1 - 2 + \\frac{4}{3} = -1 + \\frac{4}{3} = \\frac{1}{3}\n$$\nFinally, we substitute this result back into the expression for the limiting expected value of $LV_n$:\n$$\n\\lim_{n \\to \\infty} E[LV_n] = 3 E_{term} = 3 \\cdot \\frac{1}{3} = 1\n$$\nThe expected value of the local variation for a Poisson process (a renewal process with exponentially distributed inter-event times) is exactly $1$, regardless of the process rate $\\lambda$.",
            "answer": "$$\n\\boxed{1}\n$$"
        },
        {
            "introduction": "Moving from theoretical benchmarks to empirical data analysis, this practice provides a complete workflow for quantifying and testing for burstiness in an observed event sequence. You will first derive a widely-used, normalized burstiness index $B$ from fundamental principles, ensuring it has an interpretable scale from perfectly regular to highly bursty . Subsequently, you will implement a nonparametric bootstrap procedure to generate a null distribution, allowing you to compute a $p$-value and statistically assess whether the observed burstiness is significant or merely a product of random fluctuations.",
            "id": "4265613",
            "problem": "You observe temporal interaction sequences as strictly positive inter-event times and wish to assess whether the observed temporal dynamics are unusually bursty relative to an exchangeable renewal null model. Let the empirical inter-event sequence be denoted by $\\mathcal{T} = \\{ t_1, t_2, \\ldots, t_n \\}$ with $t_i \\in \\mathbb{R}_{0}$ and $n \\ge 2$. The burstiness index is to be constructed from first principles as a scale-invariant monotone function of dispersion with a bounded and interpretable range. \n\nUsing only fundamental definitions and facts, do the following:\n\n- Start from the sample mean $\\bar{t} = \\frac{1}{n}\\sum_{i=1}^n t_i$ and the population-style sample standard deviation $s = \\sqrt{\\frac{1}{n}\\sum_{i=1}^n (t_i - \\bar{t})^2}$. Use the principle of scale invariance to motivate the coefficient of variation $c = s/\\bar{t}$ as the basic dispersion measure for inter-event times. Impose the following normalization requirements on a burstiness index $B = f(c)$: \n  - $f$ is strictly increasing in $c$, \n  - $f(0) = -1$, \n  - $f(1) = 0$, and \n  - $\\lim_{c \\to \\infty} f(c) = 1$. \n  Derive the unique fractional-linear form consistent with these requirements and express $B$ explicitly in terms of $s$ and $\\bar{t}$.\n\n- Define the nonparametric exchangeable renewal null as follows: Under the null hypothesis, the inter-event times are independent and identically distributed (IID) draws from the empirical distribution of $\\mathcal{T}$, that is, from the empirical cumulative distribution function (ECDF) associated with $\\mathcal{T}$. To approximate the null distribution of $B$, generate $M$ bootstrap replicates by sampling with replacement $n$ inter-event times from $\\mathcal{T}$ for each replicate, computing $B$ for each bootstrap sample. Use a reproducible pseudo-random generator with a fixed seed.\n\n- Given an observed index $B_{\\mathrm{obs}}$ from $\\mathcal{T}$, define the one-sided $p$-values for “burstier-than-null” and “more-regular-than-null” as \n  $p_{+} = \\frac{ \\#\\{ B^{(m)} \\ge B_{\\mathrm{obs}} \\} + 1}{M + 1}$ and \n  $p_{-} = \\frac{ \\#\\{ B^{(m)} \\le B_{\\mathrm{obs}} \\} + 1}{M + 1}$, \n  where $B^{(m)}$ are the bootstrap indices and the $+1$ in numerator and denominator is the standard finite-sample correction to avoid zero $p$-values. Define the two-sided $p$-value as $p_{2} = \\min\\{ 1, 2 \\min(p_{+}, p_{-}) \\}$.\n\n- Implement an algorithm that, for each provided test case, computes $B_{\\mathrm{obs}}$, the bootstrap distribution under the null, and the three $p$-values $p_{2}$, $p_{+}$, and $p_{-}$.\n\nAll times are measured in seconds. Every output quantity is dimensionless and must be reported as a decimal. Use a fixed pseudo-random seed of $12345$ for reproducibility. Use $M = 5000$ bootstrap replicates for each test case.\n\nTest suite. Apply your program to the following inter-event sequences:\n- Test case A (heterogeneous but roughly memoryless-like): $\\{ 0.22, 0.31, 0.07, 0.52, 0.14, 0.72, 0.17, 1.43, 0.41, 0.33, 0.09, 0.28, 0.65, 0.55, 0.12, 0.94, 0.38, 0.48, 0.27, 0.19, 0.81, 0.36, 0.58, 0.23, 0.46, 1.21, 0.29, 0.41, 0.35, 0.26 \\}$.\n- Test case B (highly regular): $\\{ 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0 \\}$.\n- Test case C (highly bursty mixture): $\\{ 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 4.0, 4.0, 4.0, 4.0 \\}$.\n- Test case D (small-sample check): $\\{ 0.5, 2.0, 0.5 \\}$.\n\nFinal output format. Your program should produce a single line of output containing a list with one entry per test case, in the same order A, B, C, D. Each entry must itself be a list of four decimals: $[B_{\\mathrm{obs}}, p_{2}, p_{+}, p_{-}]$, each rounded to six decimal places. For example, the overall printed line must look like \n$[[x_{A}, y_{A}, u_{A}, v_{A}],[x_{B}, y_{B}, u_{B}, v_{B}],[x_{C}, y_{C}, u_{C}, v_{C}],[x_{D}, y_{D}, u_{D}, v_{D}]]$ \nwith each symbol replaced by its corresponding numeric value.",
            "solution": "We begin from the basic description of temporal point processes represented as inter-event intervals. Given an observed sequence $\\mathcal{T} = \\{ t_1, \\ldots, t_n \\}$, we consider dispersion properties of the empirical inter-event times to quantify burstiness. The foundational quantities are the sample mean and the population-style sample standard deviation,\n$$\n\\bar{t} = \\frac{1}{n} \\sum_{i=1}^{n} t_i, \n\\quad\ns = \\sqrt{\\frac{1}{n} \\sum_{i=1}^{n} (t_i - \\bar{t})^2}.\n$$\nScale invariance is a necessary property for an interval-based burstiness index: if all $t_i$ are multiplied by a positive constant $\\alpha$, the index should remain unchanged. The ratio $c = s/\\bar{t}$, known as the coefficient of variation, is the unique dimensionless measure of dispersion constructed from $\\bar{t}$ and $s$ that is invariant under scaling, since replacing $t_i$ by $\\alpha t_i$ yields $\\bar{t} \\mapsto \\alpha \\bar{t}$ and $s \\mapsto \\alpha s$, leaving $c$ unchanged.\n\nWe seek a monotone normalization $B = f(c)$ with an interpretable range. The requirements are: (i) $f$ is strictly increasing in $c$; (ii) $f(0) = -1$, corresponding to perfectly regular intervals; (iii) $f(1) = 0$, corresponding to memoryless-like dispersion, since a renewal process with exponential inter-event times has $c = 1$; and (iv) $\\lim_{c \\to \\infty} f(c) = 1$, representing extreme burstiness. A natural class of monotone maps from $[0,\\infty)$ onto $[-1,1)$ with these properties is the family of fractional-linear transforms,\n$$\nf(c) = \\frac{a c + b}{c + d},\n$$\nwith constants chosen to satisfy the boundary and anchoring conditions. Imposing $f(0) = -1$ gives $\\frac{b}{d} = -1$, hence $b = -d$. Imposing $f(1) = 0$ gives $a + b = 0$, hence $a = -b = d$. The limit $\\lim_{c \\to \\infty} f(c) = \\lim_{c \\to \\infty} \\frac{a c + b}{c + d} = a$ then requires $a = 1$. Thus, $a = 1$, $d = 1$, and $b = -1$, yielding the unique fractional-linear mapping\n$$\nf(c) = \\frac{c - 1}{c + 1}.\n$$\nSubstituting $c = s/\\bar{t}$ gives an equivalent and often convenient expression,\n$$\nB \\equiv f\\!\\left(\\frac{s}{\\bar{t}}\\right) = \\frac{\\frac{s}{\\bar{t}} - 1}{\\frac{s}{\\bar{t}} + 1} = \\frac{s - \\bar{t}}{s + \\bar{t}}.\n$$\nThis index $B$ is well-defined for strictly positive data because $\\bar{t}  0$ and $s \\ge 0$, and $s + \\bar{t}  0$, so no division by zero occurs. Moreover, $B \\in [-1,1)$ with $B = -1$ if and only if $s = 0$ (perfect regularity), and $B \\to 1$ as $s/\\bar{t} \\to \\infty$.\n\nWe now formalize the null model and the bootstrap. The nonparametric exchangeable renewal null posits that inter-event times are independent and identically distributed (IID) samples from the empirical distribution of $\\mathcal{T}$, that is, from the empirical cumulative distribution function (ECDF) defined by\n$$\n\\widehat{F}(x) = \\frac{1}{n} \\sum_{i=1}^{n} \\mathbf{1}\\{ t_i \\le x \\}.\n$$\nUnder this null, the distribution of $B$ for samples of size $n$ can be approximated by bootstrap resampling: for each replicate $m \\in \\{1,\\ldots,M\\}$, draw $\\{ t^{(m)}_1, \\ldots, t^{(m)}_n \\}$ by sampling with replacement from $\\mathcal{T}$, compute the replicate mean $\\bar{t}^{(m)}$, the replicate standard deviation $s^{(m)}$, and the replicate burstiness\n$$\nB^{(m)} = \\frac{s^{(m)} - \\bar{t}^{(m)}}{s^{(m)} + \\bar{t}^{(m)}}.\n$$\nThe empirical distribution of $\\{ B^{(m)} \\}_{m=1}^{M}$ estimates the null distribution of $B$. A fixed pseudo-random seed ensures reproducibility.\n\nFor a given observed $B_{\\mathrm{obs}}$ computed from $\\mathcal{T}$, we compute one-sided bootstrap $p$-values with finite-sample correction to avoid zero values:\n$$\np_{+} = \\frac{ \\#\\{ m : B^{(m)} \\ge B_{\\mathrm{obs}} \\} + 1}{M + 1}, \n\\qquad\np_{-} = \\frac{ \\#\\{ m : B^{(m)} \\le B_{\\mathrm{obs}} \\} + 1}{M + 1}.\n$$\nThe two-sided value is taken as\n$$\np_{2} = \\min\\{ 1, 2 \\min(p_{+}, p_{-}) \\}.\n$$\nThis mirrors standard bootstrap hypothesis testing practice by doubling the smaller tail probability and capping at $1$.\n\nAlgorithmic design for each test case proceeds as follows:\n- Input the sequence $\\mathcal{T}$ of length $n$ in seconds.\n- Compute $\\bar{t}$, $s$, and $B_{\\mathrm{obs}} = (s - \\bar{t})/(s + \\bar{t})$.\n- With a fixed seed (set to $12345$) and $M = 5000$, generate an array of size $M \\times n$ of bootstrap indices in $\\{1,\\ldots,n\\}$, sample the corresponding bootstrap arrays by indexing into $\\mathcal{T}$, compute the vectorized bootstrap means and standard deviations, and then compute the vectorized bootstrap $B^{(m)}$ values.\n- Compute $p_{+}$, $p_{-}$, and $p_{2}$ via the counts and the finite-sample correction.\n- Round $B_{\\mathrm{obs}}$, $p_{2}$, $p_{+}$, and $p_{-}$ to six decimal places.\n- Output for all test cases in the prescribed single-line format $[[B_{\\mathrm{obs}}, p_{2}, p_{+}, p_{-}], \\ldots]$ in the order A, B, C, D.\n\nEdge cases are naturally handled: if $\\mathcal{T}$ is perfectly regular (all $t_i$ equal), then $s = 0$ and $B_{\\mathrm{obs}} = -1$, and each bootstrap replicate is also perfectly regular with $B^{(m)} = -1$ for all $m$, yielding $p_{+} \\approx \\frac{1}{M+1}$, $p_{-} \\approx 1$, and $p_{2} \\approx \\frac{2}{M+1}$. Since all inter-event times are strictly positive, $\\bar{t}  0$ and $s + \\bar{t}  0$ always, hence no division-by-zero occurs. The use of population-style standard deviation with divisor $n$ matches the scale-invariant construction directly from the definitions of $\\bar{t}$ and $s$ without unbiasedness correction, aligning with the population-oriented interpretation of $B$.\n\nComputational considerations: vectorized generation of bootstrap samples and vectorized computation of means and standard deviations across replicates ensure that $M = 5000$ with modest $n$ remains efficient within the specified environment. Randomness is confined to bootstrap sampling with a fixed seed to ensure deterministic outputs.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef burstiness_index(intervals: np.ndarray) - float:\n    \"\"\"\n    Compute the burstiness index B = (s - mu) / (s + mu),\n    where mu is the mean and s is the population-style standard deviation (ddof=0).\n    \"\"\"\n    mu = intervals.mean()\n    # population-style standard deviation (divide by n)\n    s = intervals.std(ddof=0)\n    # s + mu  0 since mu  0 for strictly positive intervals\n    return float((s - mu) / (s + mu))\n\ndef bootstrap_b_distribution(intervals: np.ndarray, M: int, rng: np.random.Generator) - np.ndarray:\n    \"\"\"\n    Generate M bootstrap replicates by sampling with replacement from intervals\n    and compute the burstiness index for each replicate.\n    Vectorized for efficiency.\n    \"\"\"\n    n = intervals.shape[0]\n    # Sample indices with replacement: shape (M, n)\n    idx = rng.integers(low=0, high=n, size=(M, n), endpoint=False)\n    samples = intervals[idx]  # shape (M, n)\n    mus = samples.mean(axis=1)\n    # population-style std along axis=1\n    ss = samples.std(axis=1, ddof=0)\n    # Compute B for each replicate\n    Bs = (ss - mus) / (ss + mus)\n    return Bs\n\ndef p_values_from_bootstrap(B_obs: float, B_boot: np.ndarray) - tuple[float, float, float]:\n    \"\"\"\n    Compute p_plus (burstier-than-null), p_minus (more-regular-than-null), and two-sided p-value.\n    Uses finite-sample +1 correction.\n    \"\"\"\n    M = B_boot.shape[0]\n    ge = int(np.sum(B_boot = B_obs))\n    le = int(np.sum(B_boot = B_obs))\n    p_plus = (ge + 1) / (M + 1)\n    p_minus = (le + 1) / (M + 1)\n    p_two = min(1.0, 2.0 * min(p_plus, p_minus))\n    return p_two, p_plus, p_minus\n\ndef solve():\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # A: heterogeneous but roughly memoryless-like\n        np.array([0.22, 0.31, 0.07, 0.52, 0.14, 0.72, 0.17, 1.43, 0.41, 0.33,\n                  0.09, 0.28, 0.65, 0.55, 0.12, 0.94, 0.38, 0.48, 0.27, 0.19,\n                  0.81, 0.36, 0.58, 0.23, 0.46, 1.21, 0.29, 0.41, 0.35, 0.26], dtype=float),\n        # B: highly regular\n        np.array([1.0]*20, dtype=float),\n        # C: highly bursty mixture\n        np.array([0.1]*36 + [4.0]*4, dtype=float),\n        # D: small-sample check\n        np.array([0.5, 2.0, 0.5], dtype=float),\n    ]\n\n    M = 5000\n    rng = np.random.default_rng(seed=12345)\n\n    results = []\n    for intervals in test_cases:\n        B_obs = burstiness_index(intervals)\n        B_boot = bootstrap_b_distribution(intervals, M, rng)\n        p_two, p_plus, p_minus = p_values_from_bootstrap(B_obs, B_boot)\n        # Round to six decimal places\n        vals = [round(B_obs, 6), round(p_two, 6), round(p_plus, 6), round(p_minus, 6)]\n        results.append(vals)\n\n    # Final print statement in the exact required format.\n    # Ensure Python list-of-lists string with decimals; no extra spaces per requirement isn't strict,\n    # but we'll remove spaces for compactness.\n    def format_list_of_lists(lol):\n        inner = []\n        for row in lol:\n            inner.append(\"[\" + \",\".join(f\"{x:.6f}\" for x in row) + \"]\")\n        return \"[\" + \",\".join(inner) + \"]\"\n\n    print(format_list_of_lists(results))\n\nif __name__ == \"__main__\":\n    solve()\n```"
        },
        {
            "introduction": "This advanced practice transitions from describing burstiness with statistical metrics to modeling its underlying generative mechanism. Many real-world systems exhibit burstiness due to self-excitation, where past events increase the probability of future events. This exercise introduces the Hawkes process, a powerful point process model for such phenomena, and asks you to derive its log-likelihood function and the gradients necessary for parameter estimation from first principles . This forms the foundation for fitting mechanistic models to temporal data and uncovering the parameters that govern its dynamics.",
            "id": "4265694",
            "problem": "Consider a single interaction stream in a temporal network whose activity exhibits burstiness due to self-excitation. Model the event sequence by a one-dimensional Hawkes point process with exponential memory kernel observed over the finite horizon $\\left[0, T\\right]$. Let the ordered event times be $0  t_{1}  t_{2}  \\cdots  t_{n} \\leq T$, and let the conditional intensity function be\n$$\n\\lambda(t \\mid \\mathcal{H}_{t}) \\equiv \\lambda(t) = \\mu + \\sum_{t_{i}  t} \\alpha \\exp\\!\\left(-\\beta (t - t_{i})\\right),\n$$\nwhere $\\mu  0$ is the baseline rate, $\\alpha \\geq 0$ quantifies self-excitation strength, $\\beta  0$ is the decay rate, and the stability (stationarity) constraint $\\int_{0}^{\\infty} \\alpha \\exp\\!\\left(-\\beta u\\right)\\,\\mathrm{d}u = \\alpha / \\beta  1$ holds. Using only the foundational definition of the conditional intensity for a simple point process, namely\n$$\n\\lambda(t \\mid \\mathcal{H}_{t}) = \\lim_{\\Delta t \\to 0^{+}} \\frac{\\mathbb{P}\\big(\\text{one event in }[t, t + \\Delta t) \\,\\big|\\, \\mathcal{H}_{t}\\big)}{\\Delta t},\n$$\nand standard survival analysis for such processes, perform the following:\n\n1. Derive from first principles the complete-data likelihood $L(\\mu, \\alpha, \\beta \\mid \\{t_{i}\\}, T)$ of the observed event times under the above Hawkes model on $\\left[0, T\\right]$, including the no-event tail after the last event.\n\n2. Simplify the result to a closed-form analytic expression for the log-likelihood $\\ln L(\\mu, \\alpha, \\beta \\mid \\{t_{i}\\}, T)$ in terms of $\\mu$, $\\alpha$, $\\beta$, $T$, and $\\{t_{i}\\}$ only.\n\n3. Derive the gradients $\\partial_{\\mu}\\ln L$, $\\partial_{\\alpha}\\ln L$, and $\\partial_{\\beta}\\ln L$ with respect to $\\mu$, $\\alpha$, and $\\beta$. Using these, outline a computationally efficient algorithm for Maximum Likelihood Estimation (MLE) of $(\\mu, \\alpha, \\beta)$ that respects $\\mu  0$, $\\alpha \\geq 0$, $\\beta  0$, and $\\alpha/\\beta  1$. Your outline should specify how to compute the necessary summations efficiently across events and how to enforce the constraints during optimization, but it should not rely on any pre-given “shortcut” formulas beyond the above definition of the conditional intensity.\n\nExpress the final answer as the single closed-form analytic expression for $\\ln L(\\mu, \\alpha, \\beta \\mid \\{t_{i}\\}, T)$. No numerical approximation is required and no units are to be reported in the final answer.",
            "solution": "The problem is valid as it presents a well-posed, scientifically grounded, and self-contained task representative of standard practice in the statistical modeling of point processes, a core topic in the study of complex systems. All provided definitions and constraints are standard for the Hawkes process model.\n\nThe solution is divided into three parts as requested by the problem:\n1. Derivation of the complete-data likelihood $L(\\mu, \\alpha, \\beta \\mid \\{t_{i}\\}, T)$.\n2. Simplification to the log-likelihood $\\ln L(\\mu, \\alpha, \\beta \\mid \\{t_{i}\\}, T)$.\n3. Derivation of the gradients and outline of a Maximum Likelihood Estimation (MLE) algorithm.\n\n### 1. Derivation of the Likelihood Function\n\nThe likelihood of a realization of a temporal point process is derived from the joint probability of observing events in infinitesimally small intervals and no events elsewhere. For a point process on $[0, T]$ with conditional intensity $\\lambda(t \\mid \\mathcal{H}_t)$, the probability of an event in the small interval $[t, t+\\Delta t)$ given the history $\\mathcal{H}_t$ is, by definition, $\\lambda(t \\mid \\mathcal{H}_t)\\Delta t + o(\\Delta t)$. The probability of no event in the same interval is $1 - \\lambda(t \\mid \\mathcal{H}_t)\\Delta t + o(\\Delta t)$.\n\nThe likelihood is the probability density of observing the sequence of events at times $t_1, t_2, \\dots, t_n$. We can construct this by discretizing the interval $[0, T]$ into small bins of width $\\Delta t$. The probability of observing an event in each interval $[t_i, t_i+\\Delta t)$ and no events in any other interval is the product of the individual probabilities:\n$$\n\\mathbb{P}(\\text{event sequence}) \\approx \\left( \\prod_{i=1}^n \\mathbb{P}(\\text{event in } [t_i, t_i+\\Delta t) \\mid \\mathcal{H}_{t_i}) \\right) \\times \\mathbb{P}(\\text{no events elsewhere})\n$$\n$$\n\\approx \\left( \\prod_{i=1}^n \\lambda(t_i \\mid \\mathcal{H}_{t_i}) \\Delta t \\right) \\times \\prod_{k: \\text{no event in bin } k} \\left( 1 - \\lambda(t_k \\mid \\mathcal{H}_{t_k}) \\Delta t \\right)\n$$\nwhere $t_k$ represents the start of the $k$-th time bin.\n\nThe \"no event\" part can be expressed using the approximation $1-x \\approx \\exp(-x)$ for small $x$:\n$$\n\\prod_{k} \\left( 1 - \\lambda(t_k \\mid \\mathcal{H}_{t_k}) \\Delta t \\right) \\approx \\exp\\left( -\\sum_k \\lambda(t_k \\mid \\mathcal{H}_{t_k}) \\Delta t \\right)\n$$\nIn the limit $\\Delta t \\to 0$, the sum becomes an integral over the entire observation window, excluding the infinitesimal points where events occur (which have a measure of zero):\n$$\n\\lim_{\\Delta t \\to 0} \\exp\\left( -\\sum_k \\lambda(t_k \\mid \\mathcal{H}_{t_k}) \\Delta t \\right) = \\exp\\left( -\\int_0^T \\lambda(s \\mid \\mathcal{H}_s) ds \\right)\n$$\nThis term is known as the survival probability. The joint probability density, or likelihood $L$, is obtained by dividing the probability by $(\\Delta t)^n$ and taking the limit $\\Delta t \\to 0$. This yields the canonical likelihood for a general point process:\n$$\nL(\\{t_i\\}) = \\left( \\prod_{i=1}^n \\lambda(t_i \\mid \\mathcal{H}_{t_i}) \\right) \\exp\\left( -\\int_0^T \\lambda(s \\mid \\mathcal{H}_s) ds \\right)\n$$\nFor simplicity, we will write $\\lambda(t \\mid \\mathcal{H}_t)$ as $\\lambda(t)$. The given Hawkes model has the intensity:\n$$\n\\lambda(t) = \\mu + \\sum_{t_i  t} \\alpha \\exp(-\\beta (t - t_i))\n$$\nThe first part of the likelihood is the product of the intensities evaluated at each event time:\n$$\n\\prod_{i=1}^n \\lambda(t_i) = \\prod_{i=1}^n \\left( \\mu + \\sum_{j=1}^{i-1} \\alpha \\exp(-\\beta(t_i - t_j)) \\right)\n$$\nThe second part is the exponentiated negative integral of the intensity:\n$$\n\\int_0^T \\lambda(s) ds = \\int_0^T \\left( \\mu + \\sum_{t_i  s} \\alpha \\exp(-\\beta (s - t_i)) \\right) ds\n$$\nWe can split the integral:\n$$\n\\int_0^T \\mu \\, ds + \\int_0^T \\sum_{i=1}^n \\mathbb{I}(s  t_i) \\alpha \\exp(-\\beta (s - t_i)) ds\n$$\nwhere $\\mathbb{I}(\\cdot)$ is the indicator function. The first term is $\\mu T$. For the second term, we swap the integral and the sum:\n$$\n\\sum_{i=1}^n \\int_{t_i}^T \\alpha \\exp(-\\beta (s - t_i)) ds\n$$\nEvaluating the integral for each term $i$:\n$$\n\\int_{t_i}^T \\alpha \\exp(-\\beta (s - t_i)) ds = \\alpha \\left[ -\\frac{1}{\\beta} \\exp(-\\beta(s - t_i)) \\right]_{s=t_i}^{s=T} = -\\frac{\\alpha}{\\beta} \\left( \\exp(-\\beta(T - t_i)) - 1 \\right) = \\frac{\\alpha}{\\beta} \\left( 1 - \\exp(-\\beta(T-t_i)) \\right)\n$$\nThus, the total integral is:\n$$\n\\int_0^T \\lambda(s) ds = \\mu T + \\sum_{i=1}^n \\frac{\\alpha}{\\beta} \\left( 1 - \\exp(-\\beta(T-t_i)) \\right)\n$$\nCombining the parts, the complete-data likelihood is:\n$$\nL(\\mu, \\alpha, \\beta \\mid \\{t_i\\}, T) = \\left( \\prod_{i=1}^n \\left( \\mu + \\alpha \\sum_{j=1}^{i-1} \\exp(-\\beta(t_i - t_j)) \\right) \\right) \\exp\\left( -\\mu T - \\frac{\\alpha}{\\beta} \\sum_{i=1}^n \\left( 1 - \\exp(-\\beta(T-t_i)) \\right) \\right)\n$$\n\n### 2. The Log-Likelihood Function\n\nTo simplify calculations and for numerical stability, we work with the log-likelihood, $\\ln L$. Taking the natural logarithm of the likelihood expression:\n$$\n\\ln L = \\ln \\left( \\prod_{i=1}^n \\lambda(t_i) \\right) + \\ln \\left( \\exp\\left( -\\int_0^T \\lambda(s) ds \\right) \\right) = \\sum_{i=1}^n \\ln(\\lambda(t_i)) - \\int_0^T \\lambda(s) ds\n$$\nSubstituting the derived expressions for $\\lambda(t_i)$ and the integral, we obtain the closed-form analytic expression for the log-likelihood:\n$$\n\\ln L(\\mu, \\alpha, \\beta \\mid \\{t_i\\}, T) = \\sum_{i=1}^n \\ln\\left( \\mu + \\alpha \\sum_{j=1}^{i-1} \\exp(-\\beta(t_i - t_j)) \\right) - \\mu T - \\frac{\\alpha}{\\beta} \\sum_{i=1}^n \\left( 1 - \\exp(-\\beta(T-t_i)) \\right)\n$$\n\n### 3. Gradients and MLE Algorithm Outline\n\nFor Maximum Likelihood Estimation (MLE), we need to find the parameters $(\\mu, \\alpha, \\beta)$ that maximize $\\ln L$. This is typically done by finding the roots of the gradient of $\\ln L$. We compute the partial derivatives of $\\ln L$ with respect to each parameter. Let $\\lambda_i = \\lambda(t_i) = \\mu + \\alpha \\sum_{j=1}^{i-1} \\exp(-\\beta(t_i - t_j))$.\n\n**Gradient with respect to $\\mu$:**\n$$\n\\frac{\\partial \\ln L}{\\partial \\mu} = \\sum_{i=1}^n \\frac{1}{\\lambda_i} \\frac{\\partial \\lambda_i}{\\partial \\mu} - \\frac{\\partial}{\\partial \\mu} \\left(\\mu T\\right) = \\sum_{i=1}^n \\frac{1}{\\lambda_i} - T\n$$\n\n**Gradient with respect to $\\alpha$:**\n$$\n\\frac{\\partial \\ln L}{\\partial \\alpha} = \\sum_{i=1}^n \\frac{1}{\\lambda_i} \\frac{\\partial \\lambda_i}{\\partial \\alpha} - \\frac{\\partial}{\\partial \\alpha} \\left( \\frac{\\alpha}{\\beta} \\sum_{i=1}^n \\left( 1 - \\exp(-\\beta(T-t_i)) \\right) \\right)\n$$\n$$\n= \\sum_{i=1}^n \\frac{\\sum_{j=1}^{i-1} \\exp(-\\beta(t_i - t_j))}{\\lambda_i} - \\frac{1}{\\beta} \\sum_{i=1}^n \\left( 1 - \\exp(-\\beta(T-t_i)) \\right)\n$$\n\n**Gradient with respect to $\\beta$:**\n$$\n\\frac{\\partial \\ln L}{\\partial \\beta} = \\sum_{i=1}^n \\frac{1}{\\lambda_i} \\frac{\\partial \\lambda_i}{\\partial \\beta} - \\frac{\\partial}{\\partial \\beta} \\left( \\int_0^T \\lambda(s) ds \\right)\n$$\nThe derivatives are:\n$$\n\\frac{\\partial \\lambda_i}{\\partial \\beta} = -\\alpha \\sum_{j=1}^{i-1} (t_i - t_j) \\exp(-\\beta(t_i - t_j))\n$$\n$$\n\\frac{\\partial}{\\partial \\beta} \\int_0^T \\lambda(s) ds = \\int_0^T \\frac{\\partial \\lambda(s)}{\\partial \\beta} ds = \\int_0^T \\left( -\\alpha \\sum_{t_i  s} (s-t_i) \\exp(-\\beta(s-t_i)) \\right) ds\n$$\n$$\n= -\\alpha \\sum_{i=1}^n \\int_{t_i}^T (s - t_i) \\exp(-\\beta(s - t_i)) ds = -\\alpha \\sum_{i=1}^n \\left[ \\frac{1 - \\exp(-\\beta(T-t_i))}{\\beta^2} - \\frac{(T-t_i)\\exp(-\\beta(T-t_i))}{\\beta} \\right]\n$$\nCombining these, the gradient with respect to $\\beta$ is:\n$$\n\\frac{\\partial \\ln L}{\\partial \\beta} = -\\alpha \\sum_{i=1}^n \\frac{\\sum_{j=1}^{i-1} (t_i - t_j) \\exp(-\\beta(t_i - t_j))}{\\lambda_i} + \\alpha \\sum_{i=1}^n \\left( \\frac{1 - \\exp(-\\beta(T-t_i))}{\\beta^2} - \\frac{(T-t_i)\\exp(-\\beta(T-t_i))}{\\beta} \\right)\n$$\n\n**MLE Algorithm Outline:**\n\nSince setting the gradients to zero does not yield a closed-form solution, a numerical optimization algorithm is required.\n\n1.  **Objective Function  Gradients:** The goal is to maximize the log-likelihood $\\ln L(\\mu, \\alpha, \\beta)$ or, equivalently, minimize $-\\ln L$. The objective function and its gradients are defined above.\n\n2.  **Efficient Computation:** Naive computation of the double summations in the log-likelihood and gradients is $O(n^2)$. This can be reduced to $O(n)$ by defining a recursive relationship. Let $g_i = \\sum_{j=1}^{i-1} \\exp(-\\beta(t_i - t_j))$ and $h_i = \\sum_{j=1}^{i-1} (t_i - t_j)\\exp(-\\beta(t_i - t_j))$. These can be updated iteratively as:\n    - $g_i = \\exp(-\\beta(t_i - t_{i-1}))(g_{i-1} + 1)$, with $g_1 = 0$.\n    - $h_i = \\exp(-\\beta(t_i - t_{i-1}))(h_{i-1} + (t_i - t_{i-1})(g_{i-1}+1))$, with $h_1 = 0$.\n    By pre-calculating $t_i - t_{i-1}$ for all $i$, the arrays $\\{g_i\\}$ and $\\{h_i\\}$ can be computed in a single pass over the event sequence, making the evaluation of $\\ln L$ and its gradients an $O(n)$ operation.\n\n3.  **Optimization Routine:** A quasi-Newton method is suitable for this problem. L-BFGS is a common choice. Due to the constraints on the parameters, a variant such as L-BFGS-B (which handles box constraints) is appropriate.\n\n4.  **Constraint Handling:** The parameters must satisfy $\\mu  0, \\alpha \\geq 0, \\beta  0,$ and $\\alpha/\\beta  1$.\n    -   **Positivity/Non-negativity:** These can be handled by providing lower bounds to an optimizer like L-BFGS-B (e.g., $\\mu \\ge \\epsilon, \\alpha \\ge 0, \\beta \\ge \\epsilon$ for a small $\\epsilon  0$). Alternatively, one can reparameterize, e.g., $\\mu = \\exp(\\tilde{\\mu})$, $\\alpha = \\exp(\\tilde{\\alpha})$, $\\beta = \\exp(\\tilde{\\beta})$, and perform an unconstrained optimization over $\\tilde{\\mu}, \\tilde{\\alpha}, \\tilde{\\beta}$.\n    -   **Stability Condition $\\alpha/\\beta  1$:** This inequality constraint can be handled in several ways:\n        - By reparameterizing the model. For instance, optimize over $(\\mu, k, \\beta)$ where $k = \\alpha/\\beta$ and enforce $k \\in [0, 1)$ via a transformation like $k = (1+\\exp(-\\tilde{k}))^{-1}$. The optimization is then over unconstrained $(\\tilde{\\mu}, \\tilde{k}, \\tilde{\\beta})$. Gradients must be computed with respect to these new parameters using the chain rule.\n        - Using a constrained optimization algorithm like an interior-point method or Sequential Quadratic Programming (SQP) that can handle general non-linear constraints.\n\n5.  **Algorithm Steps:**\n    a. Initialize the parameters $(\\mu_0, \\alpha_0, \\beta_0)$ to feasible values.\n    b. At each iteration $k$:\n        i. Given the current parameters $(\\mu_k, \\alpha_k, \\beta_k)$, efficiently compute the log-likelihood $-\\ln L$ and its gradient vector $\\nabla(-\\ln L)$ in $O(n)$ time using the recursive updates.\n        ii. Use the optimizer (e.g., L-BFGS-B) to determine a search direction and step size, respecting the constraints.\n        iii. Update the parameters: $(\\mu_{k+1}, \\alpha_{k+1}, \\beta_{k+1})$.\n    c. Repeat step (b) until a convergence criterion (e.g., small change in parameters or log-likelihood, or small gradient norm) is met. The final parameters are the MLE estimates.",
            "answer": "$$\n\\boxed{\\sum_{i=1}^n \\ln\\left( \\mu + \\alpha \\sum_{j=1}^{i-1} \\exp(-\\beta(t_i - t_j)) \\right) - \\mu T - \\frac{\\alpha}{\\beta} \\sum_{i=1}^n \\left( 1 - \\exp(-\\beta(T-t_i)) \\right)}\n$$"
        }
    ]
}