{
    "hands_on_practices": [
        {
            "introduction": "This first exercise provides a foundational entry point into the mechanics of pinning control. The core principle is that adding a positive diagonal term, $K P$, to a graph Laplacian, $L$, can render the matrix $L+KP$ positive definite, which in turn makes the system matrix $A_c = -(L+KP)$ Hurwitz and guarantees stability. By working through the simple and instructive case of a path graph, you will gain hands-on experience constructing the key matrices and applying fundamental stability analysis techniques from first principles .",
            "id": "4297419",
            "problem": "Consider a simple path graph $P_{n}$ with $n \\geq 2$ nodes, labeled in order from node $1$ to node $n$, and unit edge weights. Let $L \\in \\mathbb{R}^{n \\times n}$ be the graph Laplacian, defined from first principles as follows: for each node $i$, $L_{ii}$ equals the degree of node $i$, $L_{ij} = -1$ if nodes $i$ and $j$ are adjacent, and $L_{ij} = 0$ otherwise. Let a single node be pinned at one end, specifically node $1$, using a scalar gain $K > 0$. Define the pinning matrix $P \\in \\mathbb{R}^{n \\times n}$ as the diagonal matrix with $P_{11} = 1$ and all other diagonal entries equal to $0$. The closed-loop network matrix is\n$$\nA_{c} = -\\big(L + K P\\big).\n$$\nTasks:\n- Using only the definitions above and elementary matrix and spectral theory, derive the explicit tridiagonal form of $A_{c}$ for general $n$ and $K > 0$.\n- Using the quadratic form characterization of the Laplacian and the pinning augmentation, determine whether all eigenvalues of $A_{c}$ are strictly negative for any $K > 0$.\n- Compute the determinant $\\det(A_{c})$ in closed form as a function of $n$ and $K$.\n\nYour final answer must be the single simplified analytic expression for $\\det(A_{c})$. Do not include units. No numerical rounding is required.",
            "solution": "The problem is analyzed in three parts as requested: deriving the form of the closed-loop matrix $A_{c}$, determining the sign of its eigenvalues, and computing its determinant.\n\nFirst, we derive the explicit form of the matrix $A_{c}$.\nThe path graph $P_{n}$ with nodes labeled $1, 2, \\dots, n$ has edges connecting node $i$ and node $i+1$ for $i=1, \\dots, n-1$.\nThe degree of node $i$, denoted $\\deg(i)$, is $1$ for the end nodes ($i=1$ and $i=n$) and $2$ for the internal nodes ($i=2, \\dots, n-1$).\nThe graph Laplacian $L \\in \\mathbb{R}^{n \\times n}$ is defined by its entries:\n- $L_{ii} = \\deg(i)$\n- $L_{ij} = -1$ if nodes $i$ and $j$ are adjacent.\n- $L_{ij} = 0$ otherwise.\n\nFor the path graph $P_n$, this results in the following symmetric tridiagonal matrix:\n$$\nL = \\begin{pmatrix}\n1 & -1 & 0 & \\cdots & 0 & 0 \\\\\n-1 & 2 & -1 & \\cdots & 0 & 0 \\\\\n0 & -1 & 2 & \\cdots & 0 & 0 \\\\\n\\vdots & \\vdots & \\vdots & \\ddots & \\vdots & \\vdots \\\\\n0 & 0 & 0 & \\cdots & 2 & -1 \\\\\n0 & 0 & 0 & \\cdots & -1 & 1\n\\end{pmatrix}\n$$\nThe pinning matrix $P$ is given as the diagonal matrix with $P_{11}=1$ and all other entries equal to $0$. We can write $P$ as $e_1 e_1^T$, where $e_1$ is the standard basis vector $(1, 0, \\dots, 0)^T$.\nThe pinning gain is $K > 0$.\nThe matrix $L + K P$ is obtained by adding $K$ to the $(1,1)$ entry of $L$:\n$$\nL + K P = \\begin{pmatrix}\n1+K & -1 & 0 & \\cdots & 0 & 0 \\\\\n-1 & 2 & -1 & \\cdots & 0 & 0 \\\\\n0 & -1 & 2 & \\cdots & 0 & 0 \\\\\n\\vdots & \\vdots & \\vdots & \\ddots & \\vdots & \\vdots \\\\\n0 & 0 & 0 & \\cdots & 2 & -1 \\\\\n0 & 0 & 0 & \\cdots & -1 & 1\n\\end{pmatrix}\n$$\nThe closed-loop network matrix $A_{c}$ is defined as $A_{c} = -(L + K P)$. Its explicit form is therefore:\n$$\nA_{c} = \\begin{pmatrix}\n-(1+K) & 1 & 0 & \\cdots & 0 & 0 \\\\\n1 & -2 & 1 & \\cdots & 0 & 0 \\\\\n0 & 1 & -2 & \\cdots & 0 & 0 \\\\\n\\vdots & \\vdots & \\vdots & \\ddots & \\vdots & \\vdots \\\\\n0 & 0 & 0 & \\cdots & -2 & 1 \\\\\n0 & 0 & 0 & \\cdots & 1 & -1\n\\end{pmatrix}\n$$\nThis is the required explicit tridiagonal form of $A_c$.\n\nSecond, we determine whether all eigenvalues of $A_c$ are strictly negative for any $K > 0$.\nLet $\\lambda$ be an eigenvalue of $A_c$ with corresponding eigenvector $v \\neq 0$. Then $A_c v = \\lambda v$.\nSubstituting the definition of $A_c$, we have $-(L+KP)v = \\lambda v$, which implies $(L+KP)v = (-\\lambda)v$.\nThis shows that $\\lambda$ is an eigenvalue of $A_c$ if and only if $-\\lambda$ is an eigenvalue of the matrix $M = L+KP$.\nThus, all eigenvalues of $A_c$ are strictly negative if and only if all eigenvalues of $M$ are strictly positive. A matrix has all its eigenvalues strictly positive if and only if it is positive definite. We check if $M$ is positive definite using the quadratic form characterization.\n\nFor any non-zero vector $x \\in \\mathbb{R}^n$, the quadratic form of $M$ is $x^T M x = x^T(L+KP)x = x^T L x + K x^T P x$.\nThe quadratic form of the graph Laplacian $L$ is known to be $x^T L x = \\sum_{(i,j) \\in E} w_{ij}(x_i - x_j)^2$, where $E$ is the set of edges and $w_{ij}$ are the edge weights. For the path graph with unit weights, this becomes:\n$$\nx^T L x = \\sum_{i=1}^{n-1} (x_i - x_{i+1})^2\n$$\nThis term is a sum of squares, so $x^T L x \\geq 0$.\nThe pinning term is $x^T P x$. Since $P = \\mathrm{diag}(1, 0, \\dots, 0)$, we have $x^T P x = x_1^2$.\nCombining these, the quadratic form for $M$ is:\n$$\nx^T M x = \\sum_{i=1}^{n-1} (x_i - x_{i+1})^2 + K x_1^2\n$$\nGiven that $K > 0$, both terms on the right-hand side are non-negative. Therefore, $x^T M x \\geq 0$ for any vector $x$, meaning $M$ is positive semi-definite.\nTo be positive definite, we must have $x^T M x > 0$ for all non-zero $x$. Let's find the conditions under which $x^T M x = 0$:\n$$\n\\sum_{i=1}^{n-1} (x_i - x_{i+1})^2 + K x_1^2 = 0\n$$\nSince both terms are non-negative, their sum is zero if and only if both terms are individually zero:\n1. $\\sum_{i=1}^{n-1} (x_i - x_{i+1})^2 = 0 \\implies x_i - x_{i+1} = 0 \\text{ for all } i=1, \\dots, n-1$. This implies $x_1 = x_2 = \\cdots = x_n$.\n2. $K x_1^2 = 0$. Since $K>0$, this implies $x_1^2 = 0$, so $x_1 = 0$.\n\nCombining these two conditions, we have $x_1=x_2=\\cdots=x_n=0$. This means that $x$ must be the zero vector.\nTherefore, for any non-zero vector $x \\in \\mathbb{R}^n$, we have $x^T M x > 0$. The matrix $M = L+KP$ is positive definite for any $K>0$.\nConsequently, all eigenvalues of $L+KP$ are strictly positive. Since the eigenvalues of $A_c$ are their negations, all eigenvalues of $A_c$ are strictly negative for any $K > 0$.\n\nThird, we compute the determinant $\\det(A_c)$.\nFrom the definition $A_c = -(L+KP)$, and using properties of determinants, we have:\n$$\n\\det(A_c) = \\det(-(L+KP)) = (-1)^n \\det(L+KP)\n$$\nWe need to compute $\\det(L+KP)$. Let $M_k$ be the top-left $k \\times k$ principal submatrix of $M = L+KP$, and let $D_k = \\det(M_k)$. The matrix $M$ is tridiagonal:\n$$\nM = \\begin{pmatrix}\n1+K & -1 & & & \\\\\n-1 & 2 & -1 & & \\\\\n& \\ddots & \\ddots & \\ddots & \\\\\n& & -1 & 2 & -1 \\\\\n& & & -1 & 1\n\\end{pmatrix}_{n \\times n}\n$$\nWe can find a recurrence relation for $D_k$.\n$D_1 = 1+K$.\n$D_2 = \\det \\begin{pmatrix} 1+K & -1 \\\\ -1 & 2 \\end{pmatrix} = 2(1+K) - 1 = 2K+1$.\nFor $k \\in \\{3, \\dots, n-1\\}$, cofactor expansion along the last row of $M_k$ gives the recurrence:\n$$\nD_k = 2 D_{k-1} - (-1)(-1)D_{k-2} = 2 D_{k-1} - D_{k-2}\n$$\nWe observe a pattern: $D_k = kK+1$. Let's verify this for the recurrence:\n$kK+1 = 2((k-1)K+1) - ((k-2)K+1) = (2k-2)K+2 - (k-2)K-1 = (2k-2-k+2)K + (2-1) = kK+1$.\nThe pattern holds for $k \\ge 3$, and also for $k=1$ and $k=2$. Thus, $D_k = kK+1$ for $k=1, \\dots, n-1$.\n\nTo find $D_n = \\det(M)$, we expand along the last row of the $n \\times n$ matrix $M$. The diagonal entry is $a_{nn}=1$.\n$$\nD_n = 1 \\cdot D_{n-1} - (-1)(-1) \\det(M_{n-2, \\text{mod}})\n$$\nwhere $M_{n-2, \\text{mod}}$ is the submatrix by removing row $n$ and column $n-1$. However, the standard three-term recurrence for a tridiagonal matrix is simpler to apply:\n$D_n = a_{nn} D_{n-1} - c_{n-1}b_{n-1} D_{n-2}$ where $a_{nn}=1$, $b_{n-1}=-1$, $c_{n-1}=-1$.\n$D_n = 1 \\cdot D_{n-1} - (-1)(-1)D_{n-2} = D_{n-1} - D_{n-2}$.\nUsing our formula $D_k = kK+1$:\n$D_{n-1} = (n-1)K+1$\n$D_{n-2} = (n-2)K+1$\nSubstituting these into the expression for $D_n$:\n$$\n\\det(L+KP) = D_n = ((n-1)K+1) - ((n-2)K+1) = (n-1-n+2)K = K\n$$\nThis can be confirmed using the matrix-tree theorem. The determinant of $L+K e_1 e_1^T$ is given by $K$ times the leading principal minor of the adjugate of $L$, which is the number of spanning trees, $\\tau(P_n)=1$. Thus $\\det(L+KP)=K \\cdot 1 = K$.\n\nFinally, we compute $\\det(A_c)$:\n$$\n\\det(A_c) = (-1)^n \\det(L+KP) = (-1)^n K\n$$\nThis expression is the required closed-form determinant as a function of $n$ and $K$.",
            "answer": "$$\n\\boxed{(-1)^{n} K}\n$$"
        },
        {
            "introduction": "Moving beyond a binary check for stability, this practice explores how to quantify the performance of pinning control. The effectiveness of control is often related to the magnitude of the eigenvalues of the pinned Laplacian, particularly the smallest eigenvalue, which corresponds to the algebraic connectivity of the pinned network. This exercise demonstrates how to exploit a graph's symmetry to make spectral analysis tractable, allowing you to see precisely how the pinning gain $K$ \"stiffens\" the network and improves its convergence properties on a star graph .",
            "id": "4297392",
            "problem": "Consider a star graph on $n \\geq 3$ nodes with one center node and $n-1$ leaf nodes. Let the node index $0$ denote the center and indices $1,2,\\dots,n-1$ denote the leaves. The graph Laplacian $L$ is defined as $L = D - A$, where $D$ is the diagonal degree matrix and $A$ is the adjacency matrix. In pinning control, a scalar pinning gain $K \\geq 0$ applied to the center node yields the grounded (pinned) Laplacian $L + K P$, where $P$ is the diagonal pinning matrix with $P_{00} = 1$ and $P_{ii} = 0$ for $i \\neq 0$. \n\nStarting from the definitions of the graph Laplacian and the pinning matrix, derive the exact spectrum (all eigenvalues with multiplicity) of $L + K P$ for this star topology by exploiting symmetry and a suitable basis decomposition. Then, define the algebraic connectivity of the pinned network to be the smallest eigenvalue of $L + K P$ and, using your spectral characterization, show how this quantity depends on $K$ and $n$, including its monotonicity in $K$ and its asymptotic behavior as $K \\to \\infty$.\n\nExpress your final answer as a single closed-form analytic expression for the algebraic connectivity $\\lambda_{2}(K)$ of $L + K P$ in terms of $n$ and $K$. No numerical approximation or rounding is required.",
            "solution": "The problem asks for the spectrum of the pinned Laplacian matrix of a star graph, and specifically for an expression for its smallest eigenvalue, which is defined as the algebraic connectivity of the pinned network.\n\nFirst, we construct the matrices for a star graph with $n \\geq 3$ nodes. The center node is indexed by $0$, and the $n-1$ leaf nodes are indexed by $1, 2, \\dots, n-1$.\n\nThe adjacency matrix $A$ has entries $A_{0i} = A_{i0} = 1$ for $i \\in \\{1, \\dots, n-1\\}$, and all other entries are $0$.\nThe degree matrix $D$ is a diagonal matrix where $D_{00} = \\deg(0) = n-1$ and $D_{ii} = \\deg(i) = 1$ for $i \\in \\{1, \\dots, n-1\\}$.\n\nThe graph Laplacian $L$ is given by $L = D - A$. Its matrix form is:\n$$\nL =\n\\begin{pmatrix}\nn-1 & -1 & -1 & \\cdots & -1 \\\\\n-1 & 1 & 0 & \\cdots & 0 \\\\\n-1 & 0 & 1 & \\cdots & 0 \\\\\n\\vdots & \\vdots & \\vdots & \\ddots & \\vdots \\\\\n-1 & 0 & 0 & \\cdots & 1\n\\end{pmatrix}\n$$\nThe pinning matrix $P$ is a diagonal matrix with $P_{00} = 1$ and $P_{ii} = 0$ for $i \\neq 0$. The pinned Laplacian matrix, which we denote by $M$, is $M = L + K P$, where $K \\geq 0$ is the pinning gain.\n$$\nM = L + K P =\n\\begin{pmatrix}\nn-1+K & -1 & -1 & \\cdots & -1 \\\\\n-1 & 1 & 0 & \\cdots & 0 \\\\\n-1 & 0 & 1 & \\cdots & 0 \\\\\n\\vdots & \\vdots & \\vdots & \\ddots & \\vdots \\\\\n-1 & 0 & 0 & \\cdots & 1\n\\end{pmatrix}\n$$\nTo find the spectrum of $M$, we solve the eigenvalue problem $M\\mathbf{v} = \\lambda\\mathbf{v}$, where $\\lambda$ is an eigenvalue and $\\mathbf{v} = (v_0, v_1, \\dots, v_{n-1})^T$ is the corresponding eigenvector. This matrix equation corresponds to the following system of linear equations:\n\\begin{align}\n(n-1+K)v_0 - \\sum_{i=1}^{n-1} v_i &= \\lambda v_0 \\quad &(1) \\\\\n-v_0 + v_i &= \\lambda v_i \\quad &(2_i) \\quad \\text{for } i = 1, \\dots, n-1\n\\end{align}\nDue to the permutation symmetry of the leaf nodes, the eigenspace of $M$ can be decomposed. We analyze the eigenvectors based on this symmetry.\n\nCase 1: Eigenvectors with $v_i = c$ for all $i \\in \\{1, \\dots, n-1\\}$.\nThis corresponds to eigenvectors lying in the two-dimensional subspace spanned by $(1, 0, \\dots, 0)^T$ and $(0, 1, \\dots, 1)^T$. The equations become:\n\\begin{align}\n(n-1+K)v_0 - (n-1)c &= \\lambda v_0 \\\\\n-v_0 + c &= \\lambda c\n\\end{align}\nFrom the second equation, we have $-v_0 = (\\lambda - 1)c$. Since $n \\ge 3$, for the known eigenvalues of the unpinned star graph Laplacian ($\\{0, n, 1, \\dots, 1\\}$), $\\lambda=1$ is a potential eigenvalue. If $\\lambda=1$, then $v_0=0$. Substituting $v_0=0$ into the first equation yields $-(n-1)c = 0$, so $c=0$, which gives the zero vector. Thus, $\\lambda=1$ is not an eigenvalue for this type of eigenvector. We can assume $\\lambda \\neq 1$ and write $c = \\frac{-v_0}{\\lambda-1} = \\frac{v_0}{1-\\lambda}$. For a non-trivial eigenvector, we must have $v_0 \\neq 0$.\nSubstituting $c$ into the first equation and dividing by $v_0$:\n$$ (n-1+K) - \\frac{n-1}{1-\\lambda} = \\lambda $$\nMultiplying by $1-\\lambda$ gives:\n$$ (n-1+K)(1-\\lambda) - (n-1) = \\lambda(1-\\lambda) $$\n$$ n-1 - (n-1)\\lambda + K - K\\lambda - (n-1) = \\lambda - \\lambda^2 $$\n$$ -\\lambda(n-1+K) + K = \\lambda - \\lambda^2 $$\n$$ \\lambda^2 - (n-1+K+1)\\lambda + K = 0 $$\n$$ \\lambda^2 - (n+K)\\lambda + K = 0 $$\nThis quadratic equation provides two eigenvalues, which we denote $\\lambda_+$ and $\\lambda_-$:\n$$ \\lambda_{\\pm} = \\frac{(n+K) \\pm \\sqrt{(n+K)^2 - 4K}}{2} $$\nThe discriminant is $(n+K)^2 - 4K = n^2 + 2nK + K^2 - 4K = n^2 + 2(n-2)K + K^2$. Since $n \\geq 3$ and $K \\geq 0$, the discriminant is non-negative, and the eigenvalues are real.\n\nCase 2: Eigenvectors orthogonal to the symmetric subspace of leaf nodes.\nThese eigenvectors have the form $\\mathbf{v} = (v_0, v_1, \\dots, v_{n-1})^T$ where $\\sum_{i=1}^{n-1} v_i = 0$.\nSubstituting this into equation (1):\n$$ (n-1+K)v_0 - 0 = \\lambda v_0 \\implies (n-1+K-\\lambda)v_0 = 0 $$\nFrom equations $(2_i)$:\n$$ -v_0 + v_i = \\lambda v_i \\implies v_i(1-\\lambda) = v_0 $$\nIf we assume $\\lambda \\neq 1$, then $v_i = v_0/(1-\\lambda)$ for all $i=1, \\dots, n-1$. The condition $\\sum v_i = 0$ implies $(n-1)v_0/(1-\\lambda) = 0$. Since $n \\ge 3$, this means $v_0 = 0$. If $v_0=0$, then $v_i=0$ for all $i$, yielding the trivial zero vector.\nTherefore, we must have $\\lambda=1$.\nIf $\\lambda=1$, equations $(2_i)$ become $-v_0 + v_i = v_i$, which implies $v_0=0$.\nEquation (1) becomes $(n-1+K) \\cdot 0 - \\sum v_i = 1 \\cdot 0$, which is $0 - 0 = 0$. This is satisfied as long as $\\sum v_i = 0$.\nSo, any vector of the form $(0, v_1, \\dots, v_{n-1})^T$ such that $\\sum_{i=1}^{n-1} v_i = 0$ is an eigenvector with eigenvalue $\\lambda=1$. The subspace of such vectors has dimension $(n-1)-1 = n-2$.\nThus, $\\lambda=1$ is an eigenvalue with multiplicity $n-2$.\n\nThe full spectrum of $M=L+KP$ is $\\{ \\lambda_-, \\lambda_+, 1, \\dots, 1 \\}$, where $1$ has multiplicity $n-2$.\n\nThe problem defines the algebraic connectivity of the pinned network, $\\lambda_2(K)$, as the smallest eigenvalue of $M$. We must find $\\min(\\lambda_-, \\lambda_+, 1)$. Since $\\sqrt{(n+K)^2 - 4K} \\ge 0$, we have $\\lambda_- \\le \\lambda_+$. So we need to compare $\\lambda_-$ with $1$.\nLet's check if $\\lambda_- < 1$:\n$$ \\frac{n+K - \\sqrt{(n+K)^2 - 4K}}{2} < 1 $$\n$$ n+K - 2 < \\sqrt{(n+K)^2 - 4K} $$\nSince $n \\ge 3$ and $K \\ge 0$, the left side $n+K-2 \\ge 1 > 0$. We can square both sides:\n$$ (n+K-2)^2 < (n+K)^2 - 4K $$\n$$ ((n+K)-2)^2 < (n+K)^2 - 4K $$\n$$ (n+K)^2 - 4(n+K) + 4 < (n+K)^2 - 4K $$\n$$ -4n - 4K + 4 < -4K $$\n$$ -4n + 4 < 0 \\implies 4 < 4n \\implies 1 < n $$\nThis is true for $n \\ge 3$. Therefore, $\\lambda_- < 1$ for all $K \\ge 0$.\nThe smallest eigenvalue is $\\lambda_-$. Thus, the algebraic connectivity is:\n$$ \\lambda_2(K) = \\lambda_- = \\frac{n+K - \\sqrt{(n+K)^2 - 4K}}{2} $$\n\nNow we analyze its properties. For $K=0$, $\\lambda_2(0) = \\frac{n-\\sqrt{n^2}}{2}=0$, which is correct since the unpinned Laplacian is positive semi-definite with smallest eigenvalue $0$.\n\nMonotonicity in $K$: We evaluate the derivative $\\frac{d\\lambda_2}{dK}$.\n$$ \\lambda_2(K) = \\frac{1}{2} \\left( n+K - \\sqrt{K^2+2(n-2)K+n^2} \\right) $$\n$$ \\frac{d\\lambda_2}{dK} = \\frac{1}{2} \\left( 1 - \\frac{2K+2(n-2)}{2\\sqrt{K^2+2(n-2)K+n^2}} \\right) = \\frac{1}{2} \\left( 1 - \\frac{K+n-2}{\\sqrt{(n+K)^2-4K}} \\right) $$\nTo show this derivative is positive, we need to show $1 > \\frac{K+n-2}{\\sqrt{(n+K)^2-4K}}$, or $\\sqrt{(n+K)^2-4K} > K+n-2$.\nSquaring both sides (which are positive): $(n+K)^2-4K > (K+n-2)^2$. This simplifies to $1 < n$, which is true. Thus, $\\frac{d\\lambda_2}{dK} > 0$, and $\\lambda_2(K)$ is a monotonically increasing function of $K$.\n\nAsymptotic behavior as $K \\to \\infty$:\nTo find the limit, we multiply by the conjugate:\n$$ \\lambda_2(K) = \\frac{(n+K - \\sqrt{(n+K)^2 - 4K})(n+K + \\sqrt{(n+K)^2 - 4K})}{2(n+K + \\sqrt{(n+K)^2 - 4K})} $$\n$$ \\lambda_2(K) = \\frac{(n+K)^2 - ((n+K)^2 - 4K)}{2(n+K + \\sqrt{(n+K)^2 - 4K})} = \\frac{4K}{2(n+K + \\sqrt{K^2+2(n-2)K+n^2})} $$\n$$ \\lambda_2(K) = \\frac{2K}{n+K + K\\sqrt{1+\\frac{2(n-2)}{K}+\\frac{n^2}{K^2}}} $$\nDividing the numerator and denominator by $K$:\n$$ \\lambda_2(K) = \\frac{2}{\\frac{n}{K}+1 + \\sqrt{1+\\frac{2(n-2)}{K}+\\frac{n^2}{K^2}}} $$\nTaking the limit as $K \\to \\infty$:\n$$ \\lim_{K\\to\\infty} \\lambda_2(K) = \\frac{2}{0+1 + \\sqrt{1+0+0}} = \\frac{2}{2} = 1 $$\nThe algebraic connectivity $\\lambda_2(K)$ increases monotonically from $0$ (at $K=0$) and asymptotically approaches $1$ as $K \\to \\infty$.\n\nThe final expression for the algebraic connectivity $\\lambda_2(K)$ is the expression for $\\lambda_-$.\n$$ \\lambda_2(K) = \\frac{n+K - \\sqrt{(n+K)^2 - 4K}}{2} $$",
            "answer": "$$\\boxed{\\frac{n+K - \\sqrt{(n+K)^{2} - 4K}}{2}}$$"
        },
        {
            "introduction": "This final practice elevates the analysis to the level of control design, where choices must be made with limited resources. It introduces the crucial idea that \"optimal\" pinning placement can be defined in multiple ways; for instance, maximizing the smallest eigenvalue $\\lambda_{\\min}$ optimizes the worst-case convergence rate, while minimizing an energy-based metric like the $\\mathcal{H}_2$ norm optimizes the system's average response to disturbances. By comparing these distinct criteria for a cycle graph, you will develop a deeper appreciation for how controller placement shapes the network's entire modal spectrum and the nuanced task of designing optimal networked systems .",
            "id": "4297382",
            "problem": "Consider an undirected, unweighted cycle graph on four nodes $G$ with vertex set $\\{1,2,3,4\\}$ and edges $\\{(1,2),(2,3),(3,4),(4,1)\\}$. The network state is $\\mathbf{x}(t) \\in \\mathbb{R}^{4}$ evolving under linear consensus dynamics with pinning feedback to a reference state $\\mathbf{x}_{r}=\\mathbf{0}$:\n$$\n\\frac{d\\mathbf{x}}{dt} \\;=\\; -\\big(L + \\kappa P\\big)\\,\\mathbf{x},\n$$\nwhere $L$ is the graph Laplacian of $G$, $\\kappa>0$ is the pinning gain, and $P$ is a diagonal selection matrix with entries $P_{ii}=1$ if node $i$ is pinned and $P_{ii}=0$ otherwise. Set $\\kappa=1$ and fix the number of pinned nodes at $m=2$. Due to graph symmetry, it suffices to compare two non-isomorphic pinning configurations:\n- Adjacent pinning: $S_{\\mathrm{adj}}=\\{1,2\\}$.\n- Opposite pinning: $S_{\\mathrm{opp}}=\\{1,3\\}$.\n\nDefine the spectral-optimal criterion as maximizing the smallest eigenvalue $\\lambda_{\\min}\\big(L+\\kappa P\\big)$, which determines the worst-case exponential convergence rate of the pinned consensus. Define the energy-optimal criterion as minimizing the steady-state disturbance-to-state energy metric\n$$\nJ(P) \\;=\\; \\operatorname{tr}\\!\\big((L+\\kappa P)^{-1}\\big),\n$$\nwhich quantifies the squared $\\mathcal{H}_{2}$ (where $\\mathcal{H}_{2}$ stands for Hardy space of square-integrable transfer functions) response from unit white noise disturbances acting additively on the state to the state output under the symmetric, positive definite drift matrix $L+\\kappa P$.\n\nTasks:\n1. Starting from the Laplacian definition and the linear time-invariant Lyapunov equation for the $\\mathcal{H}_{2}$ energy, derive the expression $J(P)=\\operatorname{tr}\\big((L+\\kappa P)^{-1}\\big)$ for the present symmetric and strictly stable case. Justify each step from first principles and well-tested facts in linear systems theory.\n2. For each pinning configuration $S_{\\mathrm{adj}}$ and $S_{\\mathrm{opp}}$ at $\\kappa=1$, compute the spectrum of $A(P)=L+\\kappa P$ using symmetry reductions that respect the cycle graphâ€™s automorphisms. From these spectra, compute both $\\lambda_{\\min}\\big(A(P)\\big)$ and $J(P)$ exactly.\n3. Identify the spectral-optimal and energy-optimal pinning configurations (they may or may not coincide) and explain any discrepancy (or lack thereof) by interpreting how pinning placement reshapes the modal spectrum beyond the worst mode.\n4. Finally, compute the ratio\n$$\nR \\;=\\; \\frac{J\\big(P_{\\mathrm{spectral\\text{-}opt}}\\big)}{J\\big(P_{\\mathrm{energy\\text{-}opt}}\\big)},\n$$\nand provide its value. If approximation is required, round your final numerical answer to four significant figures. No physical units are needed.\n\nYour final answer must be a single real-valued number.",
            "solution": "The problem is validated as scientifically grounded, well-posed, and objective. It presents a standard, solvable problem in the field of network control theory.\n\n### Part 1: Derivation of the Energy Metric $J(P)$\n\nWe begin with the linear time-invariant (LTI) system subjected to additive disturbances:\n$$\n\\frac{d\\mathbf{x}}{dt} \\;=\\; A\\mathbf{x} + B\\mathbf{w}\n$$\nwhere $\\mathbf{x} \\in \\mathbb{R}^n$ is the state vector, $A \\in \\mathbb{R}^{n \\times n}$ is the system matrix, $\\mathbf{w} \\in \\mathbb{R}^p$ is a vector of uncorrelated unit white noise processes (i.e., $\\mathbb{E}[\\mathbf{w}(t)\\mathbf{w}(\\tau)^T] = I_p \\delta(t-\\tau)$), and $B \\in \\mathbb{R}^{n \\times p}$ is the input matrix.\n\nIn our problem, the system dynamics are given by $\\frac{d\\mathbf{x}}{dt} = -(L + \\kappa P)\\mathbf{x}$. The disturbances are stated to be \"unit white noise disturbances acting additively on the state\". This implies that the input matrix $B$ is the identity matrix $I_n$ (where $n=4$) and the system matrix is $A = -(L + \\kappa P)$.\n\nThe squared $\\mathcal{H}_2$ norm from the disturbance input $\\mathbf{w}$ to the state output $\\mathbf{x}$ (i.e., output matrix $C=I_n$) is defined as the trace of the steady-state covariance matrix of the state, $X = \\lim_{t\\to\\infty} \\mathbb{E}[\\mathbf{x}(t)\\mathbf{x}(t)^T]$. For a stable LTI system, the matrix $X$ is the unique, symmetric, positive semidefinite solution to the algebraic Lyapunov equation:\n$$\nAX + XA^T + BB^T \\;=\\; 0\n$$\nFor our specific system, we substitute $A = -(L + \\kappa P)$ and $B = I_n$. The graph $G$ is undirected, so its Laplacian $L$ is a symmetric matrix. The pinning matrix $P$ is diagonal, hence also symmetric. Therefore, the system matrix $A = -(L + \\kappa P)$ is symmetric, i.e., $A=A^T$. The Lyapunov equation becomes:\n$$\n-(L + \\kappa P)X - X(L + \\kappa P) + I_n I_n^T \\;=\\; 0\n$$\n$$\n-2(L + \\kappa P)X + I_n \\;=\\; 0\n$$\nFor this equation to have a unique solution for $X$, the matrix $L + \\kappa P$ must be invertible. The Laplacian $L$ of a connected graph is positive semidefinite with a single zero eigenvalue corresponding to the eigenvector $\\mathbf{1}$ (the vector of all ones). Pinning at least one node (i.e., $P \\neq 0$) ensures that $(L+\\kappa P)\\mathbf{1} = L\\mathbf{1} + \\kappa P\\mathbf{1} = \\mathbf{0} + \\kappa P\\mathbf{1} \\neq \\mathbf{0}$. Since $L$ and $\\kappa P$ are both positive semidefinite, their sum $L+\\kappa P$ is also positive semidefinite. As it does not have $\\mathbf{1}$ as an eigenvector with eigenvalue $0$, it has no zero eigenvalues and is thus positive definite and invertible.\n\nSolving for $X$, we get:\n$$\nX \\;=\\; \\frac{1}{2}(L + \\kappa P)^{-1}\n$$\nThe squared $\\mathcal{H}_2$ norm is then:\n$$\n\\|\\cdot\\|_{\\mathcal{H}_2}^2 \\;=\\; \\operatorname{tr}(X) \\;=\\; \\operatorname{tr}\\left(\\frac{1}{2}(L + \\kappa P)^{-1}\\right) \\;=\\; \\frac{1}{2} \\operatorname{tr}\\big((L + \\kappa P)^{-1}\\big)\n$$\nThe problem defines the energy metric as $J(P) = \\operatorname{tr}((L + \\kappa P)^{-1})$. This metric is therefore twice the squared $\\mathcal{H}_2$ norm. This completes the derivation based on the stated principles.\n\n### Part 2: Spectral and Energy Analysis of Pinning Configurations\n\nThe graph is a cycle on $n=4$ nodes. Its Laplacian matrix $L = D-A_G$ is:\n$$\nL \\;=\\; \\begin{pmatrix} 2 & -1 & 0 & -1 \\\\ -1 & 2 & -1 & 0 \\\\ 0 & -1 & 2 & -1 \\\\ -1 & 0 & -1 & 2 \\end{pmatrix}\n$$\nWe are given $\\kappa=1$. The matrix for analysis is $A(P) = L+P$.\n\n#### Case 1: Adjacent Pinning ($S_{\\mathrm{adj}}=\\{1,2\\}$)\nThe pinning matrix is $P_{\\mathrm{adj}} = \\operatorname{diag}(1,1,0,0)$.\n$$\nA_{\\mathrm{adj}} = L+P_{\\mathrm{adj}} = \\begin{pmatrix} 3 & -1 & 0 & -1 \\\\ -1 & 3 & -1 & 0 \\\\ 0 & -1 & 2 & -1 \\\\ -1 & 0 & -1 & 2 \\end{pmatrix}\n$$\nThis matrix is symmetric with respect to the permutation $\\pi=(1,2)(3,4)$, which reflects the graph across the vertical axis. We can block-diagonalize $A_{\\mathrm{adj}}$ by decomposing $\\mathbb{R}^4$ into the symmetric and antisymmetric subspaces of this permutation.\nThe symmetric subspace (eigenvectors of $\\pi$ with eigenvalue $+1$) is spanned by $\\mathbf{v}_1=(1,1,0,0)^T$ and $\\mathbf{v}_2=(0,0,1,1)^T$. The action of $A_{\\mathrm{adj}}$ on this subspace is:\n$A_{\\mathrm{adj}}\\mathbf{v}_1 = (2,2,-1,-1)^T = 2\\mathbf{v}_1 - \\mathbf{v}_2$\n$A_{\\mathrm{adj}}\\mathbf{v}_2 = (-1,-1,1,1)^T = -\\mathbf{v}_1 + \\mathbf{v}_2$\nThe matrix representation is $M_{\\mathrm{sym}} = \\begin{pmatrix} 2 & -1 \\\\ -1 & 1 \\end{pmatrix}$. Its characteristic equation is $(2-\\lambda)(1-\\lambda)-1 = \\lambda^2-3\\lambda+1=0$, with eigenvalues $\\lambda = \\frac{3 \\pm \\sqrt{5}}{2}$.\n\nThe antisymmetric subspace (eigenvectors of $\\pi$ with eigenvalue $-1$) is spanned by $\\mathbf{v}_3=(1,-1,0,0)^T$ and $\\mathbf{v}_4=(0,0,1,-1)^T$. The action of $A_{\\mathrm{adj}}$ on this subspace is:\n$A_{\\mathrm{adj}}\\mathbf{v}_3 = (4,-4,1,-1)^T = 4\\mathbf{v}_3 + \\mathbf{v}_4$\n$A_{\\mathrm{adj}}\\mathbf{v}_4 = (1,-1,3,-3)^T = \\mathbf{v}_3 + 3\\mathbf{v}_4$\nThe matrix representation is $M_{\\mathrm{anti}} = \\begin{pmatrix} 4 & 1 \\\\ 1 & 3 \\end{pmatrix}$. Its characteristic equation is $(4-\\lambda)(3-\\lambda)-1 = \\lambda^2-7\\lambda+11=0$, with eigenvalues $\\lambda = \\frac{7 \\pm \\sqrt{5}}{2}$.\n\nThe spectrum of $A_{\\mathrm{adj}}$ is $\\left\\{ \\frac{3-\\sqrt{5}}{2}, \\frac{3+\\sqrt{5}}{2}, \\frac{7-\\sqrt{5}}{2}, \\frac{7+\\sqrt{5}}{2} \\right\\}$.\nThe smallest eigenvalue is $\\lambda_{\\min}(A_{\\mathrm{adj}}) = \\frac{3-\\sqrt{5}}{2}$.\nThe energy metric is $J(P_{\\mathrm{adj}}) = \\operatorname{tr}(A_{\\mathrm{adj}}^{-1}) = \\sum_i \\frac{1}{\\lambda_i}$:\n$$\nJ(P_{\\mathrm{adj}}) = \\left(\\frac{1}{\\frac{3-\\sqrt{5}}{2}} + \\frac{1}{\\frac{3+\\sqrt{5}}{2}}\\right) + \\left(\\frac{1}{\\frac{7-\\sqrt{5}}{2}} + \\frac{1}{\\frac{7+\\sqrt{5}}{2}}\\right)\n$$\n$$\nJ(P_{\\mathrm{adj}}) = \\left(\\frac{2(3+\\sqrt{5}) + 2(3-\\sqrt{5})}{9-5}\\right) + \\left(\\frac{2(7+\\sqrt{5}) + 2(7-\\sqrt{5})}{49-5}\\right) = \\frac{12}{4} + \\frac{28}{44} = 3 + \\frac{7}{11} = \\frac{40}{11}\n$$\n\n#### Case 2: Opposite Pinning ($S_{\\mathrm{opp}}=\\{1,3\\}$)\nThe pinning matrix is $P_{\\mathrm{opp}} = \\operatorname{diag}(1,0,1,0)$.\n$$\nA_{\\mathrm{opp}} = L+P_{\\mathrm{opp}} = \\begin{pmatrix} 3 & -1 & 0 & -1 \\\\ -1 & 2 & -1 & 0 \\\\ 0 & -1 & 3 & -1 \\\\ -1 & 0 & -1 & 2 \\end{pmatrix}\n$$\nThis matrix is symmetric with respect to the permutation $\\pi=(1,3)(2,4)$, a $180$-degree rotation. We proceed with a similar block-diagonalization.\nThe symmetric subspace (eigenvectors of $\\pi$ with eigenvalue $+1$) is spanned by $\\mathbf{v}_1=(1,0,1,0)^T$ and $\\mathbf{v}_2=(0,1,0,1)^T$. The action of $A_{\\mathrm{opp}}$ is:\n$A_{\\mathrm{opp}}\\mathbf{v}_1 = (3,-1,3,-1)^T = 3\\mathbf{v}_1 - \\mathbf{v}_2$\n$A_{\\mathrm{opp}}\\mathbf{v}_2 = (-2,2,-2,2)^T = -2\\mathbf{v}_1 + 2\\mathbf{v}_2$\nThe matrix representation is $M_{\\mathrm{sym}} = \\begin{pmatrix} 3 & -2 \\\\ -1 & 2 \\end{pmatrix}$. Its characteristic equation is $(3-\\lambda)(2-\\lambda)-2 = \\lambda^2-5\\lambda+4=0$, or $(\\lambda-1)(\\lambda-4)=0$, with eigenvalues $\\lambda=1, 4$.\n\nThe antisymmetric subspace (eigenvectors of $\\pi$ with eigenvalue $-1$) is spanned by $\\mathbf{v}_3=(1,0,-1,0)^T$ and $\\mathbf{v}_4=(0,1,0,-1)^T$. The action of $A_{\\mathrm{opp}}$ is:\n$A_{\\mathrm{opp}}\\mathbf{v}_3 = (3,-1,-3,1)^T = 3\\mathbf{v}_3 - \\mathbf{v}_4$\n$A_{\\mathrm{opp}}\\mathbf{v}_4 = (0,2,0,-2)^T = 0\\mathbf{v}_3 + 2\\mathbf{v}_4$\nThe matrix representation is $M_{\\mathrm{anti}} = \\begin{pmatrix} 3 & 0 \\\\ -1 & 2 \\end{pmatrix}$. As this is a triangular matrix, its eigenvalues are the diagonal entries: $\\lambda=2, 3$.\n\nThe spectrum of $A_{\\mathrm{opp}}$ is $\\{1, 2, 3, 4\\}$.\nThe smallest eigenvalue is $\\lambda_{\\min}(A_{\\mathrm{opp}}) = 1$.\nThe energy metric is $J(P_{\\mathrm{opp}}) = \\sum_i \\frac{1}{\\lambda_i}$:\n$$\nJ(P_{\\mathrm{opp}}) = \\frac{1}{1} + \\frac{1}{2} + \\frac{1}{3} + \\frac{1}{4} = \\frac{12+6+4+3}{12} = \\frac{25}{12}\n$$\n\n### Part 3: Optimal Configuration and Interpretation\n\n**Spectral-Optimal Configuration:** Maximize $\\lambda_{\\min}$.\n- $\\lambda_{\\min}(A_{\\mathrm{adj}}) = \\frac{3-\\sqrt{5}}{2} \\approx 0.382$\n- $\\lambda_{\\min}(A_{\\mathrm{opp}}) = 1$\nSince $1 > \\frac{3-\\sqrt{5}}{2}$, the **opposite pinning** configuration $S_{\\mathrm{opp}}$ is spectral-optimal.\n\n**Energy-Optimal Configuration:** Minimize $J(P)$.\n- $J(P_{\\mathrm{adj}}) = \\frac{40}{11} \\approx 3.636$\n- $J(P_{\\mathrm{opp}}) = \\frac{25}{12} \\approx 2.083$\nSince $\\frac{25}{12} < \\frac{40}{11}$, the **opposite pinning** configuration $S_{\\mathrm{opp}}$ is energy-optimal.\n\nIn this case, both optimality criteria agree. The opposite pinning configuration $S_{\\mathrm{opp}}$ is superior by both measures. There is no discrepancy to explain. The reason for this agreement lies in the full spectral distributions. The spectrum for opposite pinning, $\\{1, 2, 3, 4\\}$, dominates the spectrum for adjacent pinning, $\\left\\{\\frac{3-\\sqrt{5}}{2}, \\frac{7-\\sqrt{5}}{2}, \\frac{3+\\sqrt{5}}{2}, \\frac{7+\\sqrt{5}}{2}\\right\\} \\approx \\{0.38, 2.38, 2.62, 4.62\\}$, not just at the minimum eigenvalue but largely across the board.\n\nThe discrepancy between the two schemes can be interpreted physically. Adjacent pinning on nodes $\\{1,2\\}$ creates a contiguous block of pinned nodes and a contiguous block of unpinned nodes $\\{3,4\\}$. This unpinned \"tail\" is poorly controlled, giving rise to a very slow-decaying mode (a \"soft\" mode), represented by the small eigenvalue $\\lambda_{\\min}(A_{\\mathrm{adj}}) \\approx 0.382$. Conversely, opposite pinning on nodes $\\{1,3\\}$ distributes the control effort more evenly. Each unpinned node ($2$ and $4$) is directly connected to both a pinned and an unpinned node, breaking up any large, uncontrolled sub-structures. This leads to more effective \"stiffening\" of all network modes, reflected in a larger $\\lambda_{\\min}$ and a generally \"better\" spectrum, resulting in a smaller energy metric $J(P)$.\n\n### Part 4: Final Ratio Calculation\nThe ratio is defined as:\n$$\nR \\;=\\; \\frac{J\\big(P_{\\mathrm{spectral\\text{-}opt}}\\big)}{J\\big(P_{\\mathrm{energy\\text{-}opt}}\\big)}\n$$\nFrom Part 3, we identified the spectral-optimal configuration as $S_{\\mathrm{opp}}$, so $P_{\\mathrm{spectral\\text{-}opt}} = P_{\\mathrm{opp}}$.\nWe also identified the energy-optimal configuration as $S_{\\mathrm{opp}}$, so $P_{\\mathrm{energy\\text{-}opt}} = P_{\\mathrm{opp}}$.\nTherefore, the ratio becomes:\n$$\nR \\;=\\; \\frac{J(P_{\\mathrm{opp}})}{J(P_{\\mathrm{opp}})} = 1\n$$\nThe value is exactly $1$, and no approximation is needed.",
            "answer": "$$\\boxed{1}$$"
        }
    ]
}