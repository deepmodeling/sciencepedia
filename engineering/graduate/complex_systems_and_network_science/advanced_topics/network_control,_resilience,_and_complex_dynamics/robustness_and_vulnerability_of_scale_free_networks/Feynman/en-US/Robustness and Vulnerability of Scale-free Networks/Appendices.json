{
    "hands_on_practices": [
        {
            "introduction": "To truly grasp the implications of scale-free networks, we must move from abstract definitions to concrete structural properties. This first practice guides you through deriving two key characteristics directly from a power-law degree distribution with exponent $\\gamma$: the expected size of the largest hub and the fraction of nodes with very high degrees. Mastering this calculation sharpens your skills in applying probability theory and provides a quantitative intuition for the extreme heterogeneity that defines these networks .",
            "id": "4301052",
            "problem": "Consider a simple undirected scale-free network in which node degrees are modeled as independent and identically distributed (IID) samples from a continuous power-law distribution with exponent $\\gamma$ supported on $[k_{\\min}, \\infty)$, and probability density $p(k)$ such that the distribution is properly normalized. Assume $\\gamma2$ and that the network size $N$ is large enough for extreme-value estimates to be meaningful. Use only the following foundational elements:\n- The definition of a scale-free degree distribution: a tail that follows a power law $k^{-\\gamma}$.\n- The normalization requirement $\\int_{k_{\\min}}^{\\infty} p(k)\\,dk = 1$.\n- The survival (tail) function $S(k) = \\int_{k}^{\\infty} p(x)\\,dx$, which gives the fraction of nodes with degree at least $k$.\n- Basic order-statistics reasoning for IID samples: in a sample of size $N$, the typical maximum is asymptotically the quantile at survival probability of order $1/N$.\n\nStarting from these principles, derive:\n1. An asymptotic scaling expression for the maximum degree $k_{\\max}$ as a function of $N$, $\\gamma$, and $k_{\\min}$.\n2. An expression for the fraction of nodes with degree at least a threshold $K$ in terms of $\\gamma$ and $k_{\\min}$.\n\nThen evaluate both for $N = 10^{5}$, $\\gamma = 2.5$, $k_{\\min} = 1$, and $K = 100$. Round your numerical answers to four significant figures. Express both results as dimensionless quantities.",
            "solution": "The problem statement is validated as scientifically grounded, well-posed, objective, and complete. It describes a canonical problem in the study of complex networks, based on established principles of statistical mechanics and probability theory. The assumptions, such as modeling discrete node degrees with a continuous probability distribution, are standard theoretical approximations appropriate for the large network size ($N$) and the requested asymptotic analysis. We may therefore proceed with a complete solution.\n\nThe problem asks us to derive two quantities related to a scale-free network. The node degrees are stated to be modeled as independent and identically distributed (IID) random variables drawn from a continuous power-law probability density function (PDF), $p(k)$, with an exponent $\\gamma$ over the support $[k_{\\min}, \\infty)$.\n\nFirst, we must determine the explicit form of the normalized PDF, $p(k)$. The problem specifies a power-law form, which we can write as $p(k) = Ck^{-\\gamma}$ for $k \\ge k_{\\min}$, where $C$ is a normalization constant. The value of $C$ is found by enforcing the normalization condition $\\int_{k_{\\min}}^{\\infty} p(k) \\, dk = 1$.\n\n$$ \\int_{k_{\\min}}^{\\infty} C k^{-\\gamma} \\, dk = 1 $$\n$$ C \\left[ \\frac{k^{1-\\gamma}}{1-\\gamma} \\right]_{k_{\\min}}^{\\infty} = 1 $$\nGiven that the problem specifies $\\gamma  2$, the exponent $1-\\gamma$ is less than $-1$, which guarantees that the term $k^{1-\\gamma}$ converges to $0$ as $k \\to \\infty$. The evaluation of the integral therefore yields:\n$$ C \\left( 0 - \\frac{k_{\\min}^{1-\\gamma}}{1-\\gamma} \\right) = C \\frac{k_{\\min}^{1-\\gamma}}{\\gamma-1} = 1 $$\nSolving for the constant $C$, we find:\n$$ C = (\\gamma-1)k_{\\min}^{\\gamma-1} $$\nThus, the properly normalized PDF is:\n$$ p(k) = (\\gamma-1)k_{\\min}^{\\gamma-1} k^{-\\gamma} \\quad \\text{for } k \\ge k_{\\min} $$\n\nNext, we address the second task: deriving an expression for the fraction of nodes with a degree of at least a threshold $K$. This fraction is given by the survival function, $S(k)$, also known as the complementary cumulative distribution function (CCDF). The survival function is defined as $S(k) = \\int_{k}^{\\infty} p(x) \\, dx$. We evaluate this integral for an arbitrary threshold $k$, which we can later set to $K$.\n\n$$ S(k) = \\int_{k}^{\\infty} (\\gamma-1)k_{\\min}^{\\gamma-1} x^{-\\gamma} \\, dx $$\n$$ S(k) = (\\gamma-1)k_{\\min}^{\\gamma-1} \\left[ \\frac{x^{1-\\gamma}}{1-\\gamma} \\right]_{k}^{\\infty} $$\nAgain, utilizing the condition $\\gamma  2$, the term at the upper limit of integration vanishes.\n$$ S(k) = (\\gamma-1)k_{\\min}^{\\gamma-1} \\left( 0 - \\frac{k^{1-\\gamma}}{1-\\gamma} \\right) = (\\gamma-1)k_{\\min}^{\\gamma-1} \\left( \\frac{k^{1-\\gamma}}{\\gamma-1} \\right) $$\n$$ S(k) = k_{\\min}^{\\gamma-1} k^{1-\\gamma} = \\left(\\frac{k}{k_{\\min}}\\right)^{1-\\gamma} $$\nThis expression for $S(k)$ represents the fraction of nodes with degree at least $k$. For the specific threshold $K$, the fraction is $S(K) = \\left(\\frac{K}{k_{\\min}}\\right)^{1-\\gamma}$. This completes the symbolic derivation for the second part of the problem.\n\nNow we address the first task: deriving an asymptotic scaling expression for the maximum degree, $k_{\\max}$. The problem directs us to use order-statistics reasoning. For a large network of size $N$, the typical maximum degree $k_{\\max}$ is the value for which we expect to find approximately one node with a degree of $k_{\\max}$ or greater. The expected number of nodes with a degree of at least $k_{\\max}$ is the total number of nodes, $N$, multiplied by the probability of a single node having such a degree, $S(k_{\\max})$. Setting this expectation to $1$ provides the governing condition:\n\n$$ N \\cdot S(k_{\\max}) \\approx 1 \\implies S(k_{\\max}) \\approx \\frac{1}{N} $$\nSubstituting our derived expression for the survival function:\n$$ \\left(\\frac{k_{\\max}}{k_{\\min}}\\right)^{1-\\gamma} \\approx \\frac{1}{N} $$\nWe now solve this equation for $k_{\\max}$:\n$$ \\frac{k_{\\max}}{k_{\\min}} \\approx \\left(\\frac{1}{N}\\right)^{\\frac{1}{1-\\gamma}} = N^{-\\frac{1}{1-\\gamma}} = N^{\\frac{1}{\\gamma-1}} $$\n$$ k_{\\max} \\approx k_{\\min} N^{\\frac{1}{\\gamma-1}} $$\nThis is the required asymptotic scaling expression for the maximum degree $k_{\\max}$ as a function of $N$, $\\gamma$, and $k_{\\min}$. This completes the symbolic derivation for the first part of the problem.\n\nFinally, we perform the numerical evaluation using the given values: $N = 10^5$, $\\gamma = 2.5$, $k_{\\min} = 1$, and $K = 100$.\n\nFor the maximum degree $k_{\\max}$:\n$$ k_{\\max} \\approx k_{\\min} N^{\\frac{1}{\\gamma-1}} = (1) \\left(10^5\\right)^{\\frac{1}{2.5-1}} = \\left(10^5\\right)^{\\frac{1}{1.5}} = \\left(10^5\\right)^{2/3} = 10^{5 \\times \\frac{2}{3}} = 10^{10/3} $$\n$$ k_{\\max} \\approx 2154.43469\\dots $$\nRounding this result to four significant figures gives $k_{\\max} \\approx 2154$.\n\nFor the fraction of nodes with degree at least $K = 100$, we evaluate $S(100)$:\n$$ S(100) = \\left(\\frac{100}{k_{\\min}}\\right)^{1-\\gamma} = \\left(\\frac{100}{1}\\right)^{1-2.5} = 100^{-1.5} = (10^2)^{-1.5} = 10^{-3} $$\n$$ S(100) = 0.001 $$\nThis result is exact. To express it with four significant figures as requested, we write it in scientific notation as $1.000 \\times 10^{-3}$.\n\nBoth results are dimensionless quantities as required by the problem statement. The degree $k_{\\max}$ is a count, and $S(K)$ is a fraction.",
            "answer": "$$\n\\boxed{\\begin{pmatrix} 2154  1.000 \\times 10^{-3} \\end{pmatrix}}\n$$"
        },
        {
            "introduction": "Scale-free networks are famously robust to the random removal of nodes. This exercise explores the mathematical underpinnings of this robustness using the powerful framework of probability generating functions (PGFs) to model percolation. By comparing the impact of site (node) versus bond (edge) percolation under equivalent conditions, you will derive a surprisingly simple and elegant relationship between their effects on the giant component, deepening your understanding of network fragmentation processes .",
            "id": "4301081",
            "problem": "Consider a large, sparse configuration-model network with degree distribution $P(k) \\propto k^{-\\gamma}$ for integer $k \\in \\{k_{\\min}, k_{\\min}+1, \\dots, k_{\\max}\\}$, where $\\gamma = 2.7$, $k_{\\min} \\geq 1$, and $k_{\\max}$ obeys a structural cutoff scaling that ensures a finite second moment at finite network size. Assume the network is locally tree-like. Two independent percolation processes are applied:\n- Site percolation, in which each node is occupied independently with probability $p_{n}$.\n- Bond percolation, in which each edge is occupied independently with probability $p_{e}$.\n\nDefine the average-degree reduction factor as the ratio of the mean degree in the percolated network to the mean degree in the original network. Choose $p_{n}$ and $p_{e}$ so that the site and bond percolation produce exactly the same average-degree reduction factor. Using the Probability Generating Function (PGF) framework for the configuration model, derive a closed-form analytic expression for the ratio of the giant-component fractions $S_{\\mathrm{bond}} / S_{\\mathrm{site}}$ under this equality condition. Express your final answer as a function of the common occupation probability $p$ only. No numerical approximation is required.",
            "solution": "The problem has been validated and is determined to be a valid scientific problem. The solution proceeds by first establishing the Probability Generating Function (PGF) framework for the original network. Then, we analyze the effects of site and bond percolation on the mean degree to establish the relationship between their respective probabilities. Finally, we derive the expressions for the giant component fractions for both processes and compute their ratio.\n\nLet the degree distribution of the original network be $P(k)$. The PGF for this distribution is $G_0(x) = \\sum_k P(k) x^k$. The mean degree is $\\langle k \\rangle = G_0'(1)$. The PGF for the excess degree distribution is $G_1(x) = G_0'(x) / G_0'(1)$.\n\nFirst, we find the relationship between $p_n$ and $p_e$ by equating the average-degree reduction factors.\nFor site percolation with probability $p_n$, the mean degree of the percolated network is $\\langle k \\rangle_{\\mathrm{site}} = p_n \\langle k \\rangle$. The reduction factor is $p_n$.\nFor bond percolation with probability $p_e$, the new degree distribution has a PGF $G_{0, \\mathrm{bond}}(x) = G_0(1-p_e + p_e x)$. The mean degree is $\\langle k \\rangle_{\\mathrm{bond}} = G'_{0, \\mathrm{bond}}(1) = p_e G_0'(1) = p_e \\langle k \\rangle$. The reduction factor is $p_e$.\nThe problem states these factors are equal, so we have $p_n = p_e$. We define this common probability as $p$.\n\nNext, we derive the size of the giant component $S$ for each process.\n\n**Site Percolation:**\nLet $u_{\\mathrm{site}}$ be the probability that a randomly chosen edge in the original network leads to a finite cluster of occupied nodes. An edge leads to a neighbor node. This neighbor is unoccupied (with probability $1-p$), in which case the path terminates. Or, it is occupied (with probability $p$), and all of its other outgoing edges must also lead to finite clusters. The PGF for the excess degree is $G_1(x)$.\nThus, $u_{\\mathrm{site}}$ satisfies the self-consistency equation:\n$$ u_{\\mathrm{site}} = (1-p) + p G_1(u_{\\mathrm{site}}) $$\nA randomly chosen node belongs to a finite component if it is unoccupied (and thus isolated) or if it is occupied but all its outgoing edges lead to finite clusters. The probability that an occupied node is in a finite component is $\\sum_k P(k) (u_{\\mathrm{site}})^k = G_0(u_{\\mathrm{site}})$. Since only a fraction $p$ of nodes are occupied, the total fraction of all nodes in finite components is $(1-p) + p G_0(u_{\\mathrm{site}})$. The fraction in the giant component is the complement, but this is slightly wrong.\nA cleaner way: The giant component consists only of occupied nodes. The fraction of nodes in the giant component is the fraction of occupied nodes, $p$, times the probability that a randomly chosen occupied node is in the giant component. This probability is $1-G_0(u_{\\mathrm{site}})$.\nSo, the fraction of all nodes in the giant component is:\n$$ S_{\\mathrm{site}} = p (1 - G_0(u_{\\mathrm{site}})) $$\n\n**Bond Percolation:**\nLet $u_{\\mathrm{bond}}$ be the probability that an edge in the percolated network leads to a finite component. Its PGF for the excess degree distribution is $G_{1, \\mathrm{bond}}(x) = G_1(1-p+px)$. The self-consistency equation is:\n$$ u_{\\mathrm{bond}} = G_{1, \\mathrm{bond}}(u_{\\mathrm{bond}}) = G_1(1-p+p u_{\\mathrm{bond}}) $$\nThe fraction of nodes in the giant component is $S_{\\mathrm{bond}} = 1 - G_{0, \\mathrm{bond}}(u_{\\mathrm{bond}})$, where $G_{0, \\mathrm{bond}}(x)$ is the PGF of the degree distribution of the percolated graph.\n$$ S_{\\mathrm{bond}} = 1 - G_0(1-p+p u_{\\mathrm{bond}}) $$\n\n**Comparison:**\nLet's compare the two self-consistency equations:\n1. Site: $u_{\\mathrm{site}} = 1 - p + p G_1(u_{\\mathrm{site}})$\n2. Bond: $u_{\\mathrm{bond}} = G_1(1 - p + p u_{\\mathrm{bond}})$\n\nLet us define a new variable $v = 1 - p + p u_{\\mathrm{bond}}$. Substituting this into the second equation:\nThe argument of $G_1$ is $v$. So, $u_{\\mathrm{bond}} = G_1(v)$.\nNow substitute this back into the definition of $v$:\n$v = 1-p+pG_1(v)$.\nThis is the *exact same* self-consistency equation that $u_{\\mathrm{site}}$ must satisfy. Since we are interested in the giant component (which corresponds to the non-trivial solution where $u1$), the solutions must be the same.\nTherefore, we can conclude that $u_{\\mathrm{site}} = v = 1 - p + p u_{\\mathrm{bond}}$.\n\nNow we can write the giant component sizes in terms of the common solution $u_{\\mathrm{site}}$:\n$$ S_{\\mathrm{site}} = p (1 - G_0(u_{\\mathrm{site}})) $$\n$$ S_{\\mathrm{bond}} = 1 - G_0(1-p+p u_{\\mathrm{bond}}) = 1 - G_0(v) = 1 - G_0(u_{\\mathrm{site}}) $$\n\nFinally, we compute the ratio $S_{\\mathrm{bond}} / S_{\\mathrm{site}}$:\n$$ \\frac{S_{\\mathrm{bond}}}{S_{\\mathrm{site}}} = \\frac{1 - G_0(u_{\\mathrm{site}})}{p(1 - G_0(u_{\\mathrm{site}}))} $$\nAssuming we are above the percolation threshold, a giant component exists, meaning $S_{\\mathrm{site}} > 0$ and $1 - G_0(u_{\\mathrm{site}}) \\neq 0$. We can therefore cancel this term from the numerator and denominator.\n$$ \\frac{S_{\\mathrm{bond}}}{S_{\\mathrm{site}}} = \\frac{1}{p} $$\nThis remarkably simple result is independent of the specific form of the degree distribution $P(k)$, as long as the network is large, sparse, and locally tree-like.",
            "answer": "$$\n\\boxed{\\frac{1}{p}}\n$$"
        },
        {
            "introduction": "While robust against random error, the hubs that characterize scale-free networks are also their Achilles' heel when subjected to targeted attacks. This computational practice immerses you in this \"fragility\" by simulating a cascading failure initiated by removing the network's highest-degree nodes. By implementing a realistic load-capacity model where capacity is controlled by a tolerance parameter $\\alpha$, you will gain direct experience with network dynamics and quantify the critical vulnerability that complements their robustness .",
            "id": "4301020",
            "problem": "Consider a finite undirected simple graph representing a scale-free network with degree distribution following a power law $P(k) \\propto k^{-\\gamma}$ with exponent $\\gamma = 2.4$. A scale-free network is a network whose degree $k$ (the number of connections incident to a node) is distributed according to a power law over a range $[k_{\\min}, k_{\\max}]$. The robustness of such networks under targeted attacks can be studied by removing a small fraction of the highest-degree nodes (hubs) and observing the resulting overload cascades under a load-capacity model. The target is to determine how the cascade size depends on a tolerance parameter and to identify the critical tolerance that stabilizes the network.\n\nUse the following foundational base:\n- The degree distribution satisfies $P(k) \\propto k^{-\\gamma}$ with $\\gamma = 2.4$ and is truncated by $k_{\\min}$ and $k_{\\max}$.\n- The load $L_i$ on node $i$ is given by its betweenness centrality under shortest paths in the undirected, unweighted network, defined as $L_i = \\sum_{s \\neq i \\neq t} \\frac{\\sigma_{st}(i)}{\\sigma_{st}}$, where $\\sigma_{st}$ is the number of shortest paths between nodes $s$ and $t$, and $\\sigma_{st}(i)$ is the number of those shortest paths that pass through node $i$.\n- The capacity $C_i$ of node $i$ satisfies $C_i = (1 + \\alpha)L_i$, where $\\alpha \\geq 0$ is a global tolerance parameter.\n- An overload cascade is initiated by removing a fraction $f$ of nodes with the highest degrees (targeted attack). After the removal, loads are recomputed on the remaining network; any node $i$ whose new load $L_i^{\\text{new}}$ exceeds $C_i$ fails and is removed. The process repeats until no additional failures occur.\n- The cascade size is defined as the fraction of nodes (expressed as a decimal) that fail due to the cascade beyond the initially removed nodes.\n\nYour tasks:\n1. Generate a random scale-free network using the configuration model from a truncated power-law degree sequence with exponent $\\gamma = 2.4$, minimum degree $k_{\\min}$, maximum degree $k_{\\max}$, and number of nodes $N$. Use inverse transform sampling for the degree sequence on the continuous truncated distribution, then round to integers and construct the graph by pairing stubs uniformly at random. Remove self-loops and merge multi-edges so that the final graph is simple. All randomness must be controlled by a given seed.\n2. Compute the initial loads $L_i$ for all nodes using betweenness centrality under shortest paths in the undirected, unweighted graph. Use the Brandes algorithm based on Breadth-First Search (BFS) for efficiency.\n3. For a removal fraction $f = 0.01$ (i.e., top $1\\%$ hubs), remove the top $r = \\max(1, \\lfloor fN \\rfloor)$ nodes by degree. Simulate the overload cascade for a sequence of tolerance parameters $\\alpha \\in \\{0.0, 0.1, 0.2, \\dots, 1.0\\}$ as follows:\n   - Fix capacities $C_i = (1+\\alpha)L_i$ using the pre-removal loads $L_i$.\n   - After removing the hubs, recompute loads on the remaining network. Any node $i$ with $L_i^{\\text{new}}  C_i$ fails and is removed. Repeat until no new failures occur.\n   - Record the cascade size as the fraction of nodes (in decimal form) that fail beyond the initially removed nodes.\n4. Define the critical tolerance $\\alpha_c$ for stability as the smallest $\\alpha$ in the tested set such that the cascade size is less than or equal to a given decimal threshold $\\theta$ (e.g., $\\theta = 0.01$ means at most $1\\%$ additional failures). If no tested $\\alpha$ satisfies stability, return $-1.0$.\n\nTest suite:\nFor each test case, report only the computed $\\alpha_c$ as a float. Use the following parameter sets:\n- Test Case 1 (happy path): $N=200$, $k_{\\min}=2$, $k_{\\max}=25$, seed $=42$, threshold $\\theta=0.02$.\n- Test Case 2 (boundary condition: strict stability): $N=80$, $k_{\\min}=2$, $k_{\\max}=15$, seed $=123$, threshold $\\theta=0.00$.\n- Test Case 3 (edge case: higher heterogeneity): $N=150$, $k_{\\min}=3$, $k_{\\max}=30$, seed $=7$, threshold $\\theta=0.01$.\n\nFinal output specification:\nYour program should produce a single line of output containing the three results as a comma-separated list enclosed in square brackets, ordered as $[\\alpha_c^{(1)}, \\alpha_c^{(2)}, \\alpha_c^{(3)}]$, where each $\\alpha_c^{(j)}$ is a float rounded to three decimal places. No additional text should be printed.",
            "solution": "The foundation is the scale-free degree distribution and a load-capacity cascade model. A scale-free network has degree distribution $P(k) \\propto k^{-\\gamma}$ with $\\gamma = 2.4$, truncated to $k \\in [k_{\\min}, k_{\\max}]$. To generate the degree sequence, inverse transform sampling on the continuous truncated power law is used. For $\\gamma \\neq 1$, the cumulative distribution function for the truncated continuous power law over $[k_{\\min}, k_{\\max}]$ is\n$$\nF(k) = \\frac{k^{1-\\gamma} - k_{\\min}^{1-\\gamma}}{k_{\\max}^{1-\\gamma} - k_{\\min}^{1-\\gamma}}.\n$$\nIf $u \\sim \\text{Uniform}(0, 1)$, inverting $F$ yields\n$$\nk(u) = \\left(u \\left(k_{\\max}^{1-\\gamma} - k_{\\min}^{1-\\gamma}\\right) + k_{\\min}^{1-\\gamma} \\right)^{\\frac{1}{1-\\gamma}}.\n$$\nWe draw $N$ samples $k(u)$, round them to integers, enforce $k \\geq k_{\\min}$ and $k \\leq k_{\\max}$, and adjust the parity of the sum to ensure an even sum of degrees. The configuration model constructs a random multigraph by pairing degree “stubs” uniformly at random. To obtain a simple graph suitable for shortest-path computations, we remove self-loops and collapse parallel edges, resulting in an undirected simple graph with adjacency lists storing unique neighbors.\n\nLoads are defined by betweenness centrality in an undirected unweighted graph, which measures the fraction of all shortest paths that pass through a node. The Brandes algorithm computes betweenness efficiently. For each source node $s$, perform a Breadth-First Search (BFS) to obtain distances $d_s(v)$ and counts of shortest paths $\\sigma_s(v)$ from $s$ to all $v$. Maintain predecessor lists to know which nodes precede $w$ on shortest paths from $s$. Then accumulate dependencies $\\delta_s(v)$ backward using\n$$\n\\delta_s(v) = \\sum_{w: v \\in \\text{pred}_s(w)} \\frac{\\sigma_s(v)}{\\sigma_s(w)} \\left(1 + \\delta_s(w)\\right),\n$$\nand update betweenness\n$$\nL(v) \\mathrel{+}= \\delta_s(v)\n$$\nfor $v \\neq s$. For undirected graphs, divide the accumulated values by $2$ at the end to avoid double counting, yielding $L(v)$ as the load (betweenness centrality).\n\nThe capacity model is $C_i = (1+\\alpha)L_i$, where $L_i$ is computed for the pre-removal graph. This fixed capacity reflects a design tolerance proportional to initial load. To probe vulnerability under targeted attack, we remove the top fraction $f = 0.01$ of nodes by degree, i.e., $r = \\max(1, \\lfloor fN \\rfloor)$ hubs. After removal, recompute loads on the remaining graph. Any node $i$ whose current load $L_i^{\\text{new}}$ exceeds its capacity $C_i$ fails and is removed. This process iterates: after each removal step, recompute loads and apply the failure criterion until no new nodes fail.\n\nThe cascade size is the fraction (a decimal) of nodes that fail due to overload beyond those initially removed: if $F_{\\text{extra}}$ is the count of overload-induced failures, the cascade size is $F_{\\text{extra}}/N$. To map cascade size as a function of $\\alpha$, we evaluate $\\alpha$ on a predefined grid $\\{0.0, 0.1, \\dots, 1.0\\}$, simulate the cascade for each $\\alpha$, and record the cascade size. The critical tolerance $\\alpha_c$ is defined as the smallest $\\alpha$ on this grid such that the cascade size is less than or equal to a threshold $\\theta$ specified per test case. If no $\\alpha$ satisfies the criterion, $\\alpha_c$ is set to $-1.0$ to indicate that stability was not achieved within the tested range.\n\nAlgorithmic design:\n- Degree sequence: Sample using inverse transform to obtain a heavy-tailed distribution consistent with $\\gamma = 2.4$ and truncate to $[k_{\\min}, k_{\\max}]$. Adjust degree sum to be even. This yields stubs for the configuration model.\n- Graph construction: Randomly pair stubs. Discard self-loops and collapse multi-edges to enforce simplicity. Construct adjacency lists as sets to remove duplicates, then convert to lists for iteration.\n- Load computation: Implement the Brandes algorithm with Breadth-First Search (BFS) using a queue. For each active source node $s$, maintain arrays for distances $d$, shortest path counts $\\sigma$, predecessor lists, a stack to track traversal order, and dependencies $\\delta$. Update betweenness at the end of each source’s accumulation, and divide by $2$ for undirected graphs.\n- Cascade simulation: For each $\\alpha$ on the grid, compute capacities once from the initial loads. Remove the top $r$ hubs by degree. Iteratively recompute loads on the active subgraph and remove nodes whose load exceeds capacity until convergence. Record the cascade size $F_{\\text{extra}}/N$.\n- Critical tolerance: Scan the recorded cascade sizes and select the smallest $\\alpha$ whose cascade size is $\\leq \\theta$. If none are acceptable, output $-1.0$.\n- Test suite coverage: Three cases are chosen to probe typical behavior (moderate network size), strict stability requirement (boundary case where only zero cascade is acceptable), and higher heterogeneity (edge case with larger $k_{\\max}$). All results are reported as floats rounded to three decimal places in a single list.\n\nThis approach derives logically from core definitions of scale-free networks and betweenness centrality, combines the well-tested Brandes algorithm for shortest paths with a capacity-based overload rule, and produces quantifiable outputs for robustness analysis under targeted hub removal.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom collections import deque\n\ndef sample_truncated_power_law(N, gamma, k_min, k_max, rng):\n    \"\"\"\n    Sample N degrees from a truncated continuous power-law distribution\n    with exponent gamma over [k_min, k_max], then round to integers and clamp.\n    Ensure the sum of degrees is even.\n    \"\"\"\n    # Inverse CDF sampling for continuous truncated power law\n    # F(k) = (k^(1-gamma) - k_min^(1-gamma)) / (k_max^(1-gamma) - k_min^(1-gamma))\n    # Inversion: k = [u*(k_max^(1-gamma)-k_min^(1-gamma)) + k_min^(1-gamma)]^(1/(1-gamma))\n    a = k_min ** (1.0 - gamma)\n    b = k_max ** (1.0 - gamma)\n    u = rng.random(N)\n    ks = (u * (b - a) + a) ** (1.0 / (1.0 - gamma))\n    # Round and clamp\n    degs = np.clip(np.rint(ks).astype(int), k_min, k_max)\n    # Ensure sum of degrees is even\n    total = degs.sum()\n    if total % 2 != 0:\n        # Adjust one random element within bounds to fix parity\n        idxs = np.where((degs  k_min)  (degs  k_max))[0]\n        if idxs.size == 0:\n            # If all at bounds, flip one element between k_min and k_max\n            # to fix parity; choose a random index and toggle by +1 if possible, else -1\n            i = rng.integers(0, N)\n            if degs[i]  k_max:\n                degs[i] += 1\n            else:\n                degs[i] -= 1\n        else:\n            i = rng.choice(idxs)\n            # Toggle parity by adding 1 (stay within bounds)\n            degs[i] += 1\n    return degs.tolist()\n\ndef configuration_model_simple_graph(degrees, rng):\n    \"\"\"\n    Build a graph from the degree sequence via the configuration model,\n    then remove self-loops and collapse multi-edges to create a simple undirected graph.\n    Returns adjacency lists (list of lists).\n    \"\"\"\n    N = len(degrees)\n    stubs = []\n    for i, k in enumerate(degrees):\n        stubs.extend([i] * k)\n    rng.shuffle(stubs)\n\n    # Pair stubs\n    edges = []\n    # If odd number of stubs, drop the last one\n    pair_count = len(stubs) // 2\n    for p in range(pair_count):\n        u = stubs[2 * p]\n        v = stubs[2 * p + 1]\n        if u != v:\n            edges.append((u, v))\n        # self-loops are ignored here\n\n    # Build adjacency sets to collapse multi-edges\n    adj_sets = [set() for _ in range(N)]\n    for u, v in edges:\n        if u == v:\n            continue\n        adj_sets[u].add(v)\n        adj_sets[v].add(u)\n\n    # Convert to lists\n    adj = [list(neigh) for neigh in adj_sets]\n    return adj\n\ndef betweenness_centrality_undirected(adj, active_mask):\n    \"\"\"\n    Compute betweenness centrality for an undirected, unweighted graph\n    using Brandes algorithm. Nodes not active (active_mask[i] == False)\n    are considered removed; paths cannot go through them or start from them.\n    \"\"\"\n    N = len(adj)\n    BC = [0.0] * N\n    for s in range(N):\n        if not active_mask[s]:\n            continue\n        # Initialization\n        stack = []\n        pred = [[] for _ in range(N)]\n        sigma = [0] * N  # number of shortest paths from s\n        dist = [-1] * N  # distance from s\n        sigma[s] = 1\n        dist[s] = 0\n        Q = deque([s])\n        # BFS\n        while Q:\n            v = Q.popleft()\n            stack.append(v)\n            for w in adj[v]:\n                if not active_mask[w]:\n                    continue\n                if dist[w]  0:\n                    dist[w] = dist[v] + 1\n                    Q.append(w)\n                if dist[w] == dist[v] + 1:\n                    sigma[w] += sigma[v]\n                    pred[w].append(v)\n        # Accumulation\n        delta = [0.0] * N\n        while stack:\n            w = stack.pop()\n            # Avoid division by zero if sigma[w] == 0 (disconnected)\n            sw = sigma[w]\n            if sw  0:\n                coef = 1.0 + delta[w]\n                for v in pred[w]:\n                    delta[v] += (sigma[v] / sw) * coef\n            if w != s:\n                BC[w] += delta[w]\n    # For undirected graphs, divide by 2 to correct double-counting\n    for i in range(N):\n        BC[i] *= 0.5\n    return BC\n\ndef degrees_from_adj(adj):\n    return [len(neigh) for neigh in adj]\n\ndef simulate_cascade(adj, initial_loads, alpha, removal_fraction=0.01):\n    \"\"\"\n    Simulate the overload cascade after removing the top hubs by degree.\n    initial_loads: betweenness centrality on the full pre-removal graph.\n    alpha: tolerance parameter; capacity C_i = (1 + alpha) * initial_loads[i].\n    removal_fraction: fraction of top-degree nodes to remove initially.\n    Returns cascade size (fraction of extra failures beyond initial removal).\n    \"\"\"\n    N = len(adj)\n    capacities = [ (1.0 + alpha) * L for L in initial_loads ]\n    degs = degrees_from_adj(adj)\n    r = max(1, int(np.floor(removal_fraction * N)))\n    # Get indices sorted by degree descending\n    hub_order = sorted(range(N), key=lambda i: degs[i], reverse=True)\n    initial_fail = set(hub_order[:r])\n\n    active = [True] * N\n    for i in initial_fail:\n        active[i] = False\n\n    extra_failed_count = 0\n\n    while True:\n        # Compute loads on the current active subgraph\n        loads_new = betweenness_centrality_undirected(adj, active)\n        # Identify overloads\n        to_fail = []\n        for i in range(N):\n            if not active[i]:\n                continue\n            if loads_new[i]  capacities[i] + 1e-12:\n                to_fail.append(i)\n        if not to_fail:\n            break\n        for i in to_fail:\n            active[i] = False\n        extra_failed_count += len(to_fail)\n\n    cascade_fraction = extra_failed_count / N\n    return cascade_fraction\n\ndef compute_alpha_c(adj, alpha_values, threshold, removal_fraction=0.01):\n    \"\"\"\n    Compute initial loads and evaluate cascade across alpha_values.\n    Return the smallest alpha whose cascade size = threshold.\n    If none, return -1.0.\n    \"\"\"\n    N = len(adj)\n    active_full = [True] * N\n    initial_loads = betweenness_centrality_undirected(adj, active_full)\n\n    alpha_c = None\n    for alpha in alpha_values:\n        size = simulate_cascade(adj, initial_loads, alpha, removal_fraction=removal_fraction)\n        if size = threshold:\n            alpha_c = alpha\n            break\n    if alpha_c is None:\n        return -1.0\n    return alpha_c\n\ndef build_scale_free_graph(N, gamma, k_min, k_max, seed):\n    rng = np.random.default_rng(seed)\n    degrees = sample_truncated_power_law(N, gamma, k_min, k_max, rng)\n    adj = configuration_model_simple_graph(degrees, rng)\n    return adj\n\ndef solve():\n    # Define the test cases from the problem statement.\n    # Each case: (N, k_min, k_max, seed, threshold)\n    test_cases = [\n        (200, 2, 25, 42, 0.02),   # Test Case 1: happy path\n        (80,  2, 15, 123, 0.00),  # Test Case 2: boundary strict stability\n        (150, 3, 30, 7,  0.01),   # Test Case 3: edge case higher heterogeneity\n    ]\n\n    gamma = 2.4\n    alpha_values = [round(0.1 * i, 1) for i in range(11)]  # 0.0 to 1.0 inclusive\n\n    results = []\n    for N, k_min, k_max, seed, theta in test_cases:\n        adj = build_scale_free_graph(N, gamma, k_min, k_max, seed)\n        alpha_c = compute_alpha_c(adj, alpha_values, threshold=theta, removal_fraction=0.01)\n        # Round to three decimals\n        results.append(f\"{alpha_c:.3f}\")\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(results)}]\")\n\nsolve()\n```"
        }
    ]
}