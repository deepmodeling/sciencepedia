{
    "hands_on_practices": [
        {
            "introduction": "Understanding the catastrophic failures in interdependent networks begins with mastering the resilience of a single network. This foundational exercise guides you through the derivation of the giant component size under random node failures using the powerful generating function formalism . By applying this technique, first to a general network and then to the specific case of an Erdős–Rényi graph, you will build the core analytical skill needed to model percolation phenomena.",
            "id": "4266389",
            "problem": "Consider a single large, sparse random network generated by the configuration model with degree distribution $P(k)$ and mean degree $\\langle k \\rangle$. Define site percolation as the process in which each node is independently retained (occupied) with probability $p \\in [0,1]$, and removed with probability $1-p$, with all incident edges of removed nodes also removed. Let $S$ denote the fraction of all original nodes that belong to the giant connected component after site percolation. Using only foundational properties of the configuration model (local tree-likeness in the large-size limit and its characterization by degree distribution generating functions) and first-principles reasoning about independent branching, derive the self-consistent relations that determine $S$ for general $P(k)$, and then specialize to the Erdős–Rényi (ER) random graph with mean degree $c>0$ (equivalently, $P(k)$ is Poisson with mean $c$). In the ER specialization, eliminate any auxiliary variables to express the self-consistency relation for the order parameter $S$ in implicit form $S = f(S)$, where $f$ depends only on $p$, $c$, and $S$. For your final answer, provide the explicit analytic expression for $f(S)$ in the ER case. Do not include an equality sign in your final answer. No numerical approximation is required.",
            "solution": "The problem requires the derivation of a self-consistency relation for the size of the giant connected component ($S$) under site percolation on a random network. We begin with the general case of a configuration model network and then specialize to the Erdős–Rényi (ER) graph.\n\nFirst, we validate the problem statement.\nStep 1: Extract Givens\n- Network Model: Single large, sparse random network generated by the configuration model.\n- Degree Distribution: $P(k)$.\n- Mean Degree: $\\langle k \\rangle$.\n- Process: Site percolation, where each node is independently retained (occupied) with probability $p \\in [0,1]$ and removed with probability $1-p$.\n- Order Parameter: $S$, the fraction of all original nodes that belong to the giant connected component (GCC) after percolation.\n- Methodology: Use foundational properties of the configuration model (local tree-likeness) and generating functions.\n- Goal 1: Derive self-consistent relations for $S$ for general $P(k)$.\n- Goal 2: Specialize to an ER random graph with mean degree $c>0$, which has a Poisson degree distribution $P(k)$ with mean $c$.\n- Goal 3: For the ER case, express the self-consistency relation for $S$ in the implicit form $S = f(S)$, eliminating auxiliary variables.\n- Final Answer: Provide the explicit analytic expression for $f(S)$ in the ER case.\n\nStep 2: Validate Using Extracted Givens\nThe problem is scientifically grounded, well-posed, and objective. It is a standard, fundamental problem in the statistical physics of complex networks, specifically in percolation theory. The concepts (configuration model, ER graphs, site percolation, generating functions) are well-defined and central to the field. The premises are factually correct, and the problem is self-contained. There are no contradictions, ambiguities, or missing information. The requested derivation is non-trivial and requires substantive reasoning based on first principles. The problem is therefore valid.\n\nStep 3: Verdict and Action\nThe problem is valid. We proceed with the solution.\n\nThe solution strategy is based on the generating function formalism for branching processes, which accurately describes processes on large, sparse random networks due to their local tree-like structure.\n\nLet $P(k)$ be the degree distribution of the nodes in the original network. The generating function for this distribution is:\n$$G_0(x) = \\sum_{k=0}^{\\infty} P(k) x^k$$\nThe mean degree is $\\langle k \\rangle = G_0'(1)$.\n\nNext, we consider the excess degree distribution, which is the degree distribution of a node reached by traversing a randomly chosen edge, minus the edge we arrived along. The probability that a random edge leads to a node of degree $k$ is proportional to $kP(k)$. The corresponding generating function for the number of other edges (excess degree $k-1$) is:\n$$G_1(x) = \\sum_{k=1}^{\\infty} \\frac{k P(k)}{\\langle k \\rangle} x^{k-1} = \\frac{1}{\\langle k \\rangle} \\sum_{k=1}^{\\infty} k P(k) x^{k-1} = \\frac{G_0'(x)}{G_0'(1)} = \\frac{G_0'(x)}{\\langle k \\rangle}$$\n\nIn site percolation, each node is occupied with probability $p$. Let $u$ be the probability that a node reached by following a random edge does *not* belong to the giant connected component (GCC) of occupied nodes. This can happen in two mutually exclusive ways:\n1. The node at the end of the edge is removed (which occurs with probability $1-p$).\n2. The node is occupied (with probability $p$), but none of its other edges lead to the GCC. If the node has degree $k$, it has $k-1$ other edges. Since the network is locally tree-like, the paths emerging from these edges are independent. The probability that a single one of these paths does not lead to the GCC is $u$. Thus, the probability that all $k-1$ paths do not is $u^{k-1}$.\n\nTo find the total probability $u$, we must average over the excess degree distribution:\n$$u = \\sum_{k=1}^{\\infty} \\frac{k P(k)}{\\langle k \\rangle} \\left( (1-p) + p u^{k-1} \\right)$$\nSeparating the sums:\n$$u = (1-p) \\sum_{k=1}^{\\infty} \\frac{k P(k)}{\\langle k \\rangle} + p \\sum_{k=1}^{\\infty} \\frac{k P(k)}{\\langle k \\rangle} u^{k-1}$$\nThe first summation equals $1$, and the second is the definition of $G_1(u)$. This yields the first self-consistent relation:\n$$u = 1 - p + p G_1(u)$$\nA non-trivial GCC exists if this equation has a solution $u < 1$.\n\nNow we relate this to the size of the GCC, $S$. $S$ is the probability that a randomly chosen node from the original network is part of the GCC after percolation. A node is *not* in the GCC if:\n1. The node is removed (probability $1-p$).\n2. The node is occupied (probability $p$), but all of its neighbors are in finite clusters. If a node has degree $k$, the probability that none of its $k$ neighbors' branches reach the GCC is $u^k$.\n\nAveraging over the original degree distribution $P(k)$, the probability that a randomly chosen node is *not* in the GCC is:\n$$1 - S = \\sum_{k=0}^{\\infty} P(k) \\left( (1-p) + p u^k \\right)$$\nSeparating the sums:\n$$1 - S = (1-p) \\sum_{k=0}^{\\infty} P(k) + p \\sum_{k=0}^{\\infty} P(k) u^k$$\nThe first summation is $1$, and the second is the definition of $G_0(u)$.\n$$1 - S = 1 - p + p G_0(u)$$\nThis simplifies to the second self-consistent relation:\n$$S = p - p G_0(u) = p(1 - G_0(u))$$\n\nThese two relations, $u = 1 - p + p G_1(u)$ and $S = p(1 - G_0(u))$, hold for a general configuration model network.\n\nNext, we specialize to the Erdős–Rényi (ER) random graph with mean degree $c$. In the limit of a large number of nodes, the degree distribution of an ER graph is Poisson:\n$$P(k) = \\frac{c^k \\exp(-c)}{k!}$$\nThe generating function for this distribution is:\n$$G_0(x) = \\sum_{k=0}^{\\infty} \\frac{c^k \\exp(-c)}{k!} x^k = \\exp(-c) \\sum_{k=0}^{\\infty} \\frac{(cx)^k}{k!} = \\exp(-c) \\exp(cx) = \\exp(c(x-1))$$\nThe derivative is $G_0'(x) = c \\exp(c(x-1))$. The mean degree is $\\langle k \\rangle = G_0'(1) = c$.\nThe excess degree generating function is:\n$$G_1(x) = \\frac{G_0'(x)}{\\langle k \\rangle} = \\frac{c \\exp(c(x-1))}{c} = \\exp(c(x-1))$$\nFor a Poisson distribution, a notable property is that $G_0(x) = G_1(x)$.\n\nWe now substitute these specific generating functions into our general self-consistent relations:\n1. $u = 1 - p + p G_1(u) \\implies u = 1 - p + p \\exp(c(u-1))$\n2. $S = p(1 - G_0(u)) \\implies S = p(1 - \\exp(c(u-1)))$\n\nThe final step is to eliminate the auxiliary variable $u$ to find a single implicit equation for $S$ of the form $S = f(S)$. From the second equation, we can express the exponential term:\n$$\\frac{S}{p} = 1 - \\exp(c(u-1)) \\implies \\exp(c(u-1)) = 1 - \\frac{S}{p}$$\nSubstitute this expression into the first equation:\n$$u = 1 - p + p \\left(1 - \\frac{S}{p}\\right) = 1 - p + p - S$$\n$$u = 1 - S$$\nThis gives a direct relationship between the auxiliary variable $u$ and the order parameter $S$. Now, substitute $u=1-S$ back into the expression for $S$:\n$$S = p(1 - \\exp(c((1-S)-1)))$$\n$$S = p(1 - \\exp(c(-S)))$$\n$$S = p(1 - \\exp(-cS))$$\nThis is the desired self-consistency equation for $S$ in the form $S = f(S)$. The function $f(S)$ is the right-hand side of this equation.\n\nTherefore, the explicit analytic expression for $f(S)$ is $p(1 - \\exp(-cS))$.",
            "answer": "$$\n\\boxed{p(1 - \\exp(-cS))}\n$$"
        },
        {
            "introduction": "Theoretical models come to life when we can see their mechanics in action. This practice provides a hands-on opportunity to trace the step-by-step dynamics of a cascading failure on a small, concrete pair of interdependent networks . By manually calculating how failures propagate from one network to another and back, you will gain a tangible intuition for the feedback loops that can lead to abrupt and total system collapse, a hallmark of interdependent systems.",
            "id": "4266384",
            "problem": "Consider two undirected networks $A$ and $B$ that are interdependent via bidirectional one-to-one dependency pairs. Let the node sets be $A = \\{a_1,a_2,a_3,a_4,a_5,a_6\\}$ and $B = \\{b_1,b_2,b_3,b_4,b_5,b_6,b_7\\}$. The edge sets are\n$$\nE_A = \\{(a_1,a_2),(a_2,a_3),(a_3,a_4),(a_1,a_3),(a_5,a_6)\\}\n$$\nand\n$$\nE_B = \\{(b_1,b_2),(b_2,b_3),(b_1,b_3),(b_4,b_5),(b_5,b_6),(b_6,b_7)\\}.\n$$\nInterdependence is specified by the bidirectional dependency set\n$$\nD = \\{(a_1,b_2),(a_2,b_3),(a_3,b_1),(a_4,b_4),(a_5,b_5),(a_6,b_6)\\},\n$$\nso that for each $(a_i,b_j)\\in D$ there is a corresponding $(b_j,a_i)\\in D$. The node $b_7$ has no dependency partner and is autonomous.\n\nCascading failure dynamics are defined as follows, starting from an initial removal in network $A$. A node is functional at a given stage if and only if both of the following conditions hold: it belongs to the largest connected component (LCC) of its own network’s currently active subgraph, and, if it has a dependency partner in the other network, that partner is also functional. The process is monotone: once a node becomes nonfunctional, it remains nonfunctional. Define $S_A^{(t)}$ and $S_B^{(t)}$ as the sets of functional nodes in networks $A$ and $B$ after $t$ complete cascade rounds, with $t\\in\\mathbb{N}_0$. Initialization is $S_A^{(0)}=A\\setminus R$ and $S_B^{(0)}=B$, where the initial removal set is $R=\\{a_2\\}$. One complete cascade round consists of the following sequence:\n- Compute the LCC of the subgraph induced by $S_A^{(t)}$ in $A$; remove all nodes of $A$ not in this LCC, yielding an intermediate active set $S_{A,\\mathrm{LCC}}^{(t)}$.\n- Propagate dependencies to $B$: remove from $S_B^{(t)}$ any node in $B$ whose dependency partner in $A$ is not in $S_{A,\\mathrm{LCC}}^{(t)}$, yielding $S_{B,\\mathrm{dep}}^{(t)}$.\n- Compute the LCC of the subgraph induced by $S_{B,\\mathrm{dep}}^{(t)}$ in $B$; remove all nodes of $B$ not in this LCC, yielding $S_B^{(t+1)}$.\n- Propagate dependencies to $A$: remove from $S_{A,\\mathrm{LCC}}^{(t)}$ any node in $A$ whose dependency partner in $B$ is not in $S_B^{(t+1)}$, and then take the LCC of the remaining subgraph in $A$; the result is $S_A^{(t+1)}$.\n\nAssume ties in the size of the largest connected component are broken deterministically by selecting the component whose node labels have the smallest sum under the mappings $a_i\\mapsto i$ and $b_j\\mapsto j$. Perform exactly $2$ complete cascade rounds starting from $R=\\{a_2\\}$ as specified. Report the cardinalities $|S_A^{(2)}|$ and $|S_B^{(2)}|$ as your final answer, formatted as a row matrix. No rounding is required.",
            "solution": "The problem describes a cascading failure process on two interdependent networks, $A$ and $B$. We are asked to simulate this process for two complete rounds and determine the number of surviving nodes in each network.\n\n### Problem Validation\n**Step 1: Extract Givens**\n- Network $A$ node set: $A=\\{a_1, a_2, a_3, a_4, a_5, a_6\\}$\n- Network $A$ edge set: $E_A = \\{(a_1,a_2),(a_2,a_3),(a_3,a_4),(a_1,a_3),(a_5,a_6)\\}$\n- Network $B$ node set: $B=\\{b_1,b_2,b_3,b_4,b_5,b_6,b_7\\}$\n- Network $B$ edge set: $E_B = \\{(b_1,b_2),(b_2,b_3),(b_1,b_3),(b_4,b_5),(b_5,b_6),(b_6,b_7)\\}$\n- Bidirectional dependency set: $D = \\{(a_1,b_2),(a_2,b_3),(a_3,b_1),(a_4,b_4),(a_5,b_5),(a_6,b_6)\\}$\n- Autonomous node: $b_7$\n- Initial removal set: $R=\\{a_2\\}$\n- Initial functional sets: $S_A^{(0)}=A\\setminus R$ and $S_B^{(0)}=B$.\n- Cascade dynamics: A sequence of four operations defines one complete round from time $t$ to $t+1$:\n  1. Find the largest connected component (LCC) of the subgraph induced by $S_A^{(t)}$, yielding $S_{A,\\mathrm{LCC}}^{(t)}$.\n  2. Remove nodes from $S_B^{(t)}$ whose dependency partners are not in $S_{A,\\mathrm{LCC}}^{(t)}$, yielding $S_{B,\\mathrm{dep}}^{(t)}$.\n  3. Find the LCC of the subgraph induced by $S_{B,\\mathrm{dep}}^{(t)}$, yielding $S_B^{(t+1)}$.\n  4. Remove nodes from $S_{A,\\mathrm{LCC}}^{(t)}$ whose dependency partners are not in $S_B^{(t+1)}$, then find the LCC of the remaining subgraph, yielding $S_A^{(t+1)}$.\n- Tie-breaking rule for LCC: Select the component with the smallest sum of node indices.\n- Task: Report $|S_A^{(2)}|$ and $|S_B^{(2)}|$.\n\n**Step 2: Validate Using Extracted Givens**\nThe problem is scientifically grounded, describing a well-known model from network science. It is well-posed, with all components (networks, dependencies, initial conditions, dynamics, and tie-breaking rule) clearly and unambiguously defined, ensuring a unique, deterministic outcome. The problem is objective and formalizable. The setup is complete and consistent, without any contradictions or missing information. It requires a procedural simulation, making it non-trivial.\n\n**Step 3: Verdict and Action**\nThe problem is valid. A complete solution will be provided.\n\n### Solution\nWe will simulate the cascading failure process step-by-step for two rounds.\n\n**Initial State ($t=0$)**\nThe process starts with the removal of node $a_2$ from network $A$.\nThe initial set of functional nodes in network $A$ is $S_A^{(0)} = A \\setminus \\{a_2\\} = \\{a_1, a_3, a_4, a_5, a_6\\}$.\nThe initial set of functional nodes in network $B$ is $S_B^{(0)} = B = \\{b_1, b_2, b_3, b_4, b_5, b_6, b_7\\}$.\n\n**Cascade Round 1 ($t=0 \\to t=1$)**\n1.  **LCC in Network A:** We consider the subgraph of $A$ induced by $S_A^{(0)} = \\{a_1, a_3, a_4, a_5, a_6\\}$. The edges from $E_A$ within this subgraph are $(a_1, a_3)$, $(a_3, a_4)$, and $(a_5, a_6)$. This subgraph has two connected components: $C_{A,1} = \\{a_1, a_3, a_4\\}$ of size $3$ and $C_{A,2} = \\{a_5, a_6\\}$ of size $2$. The largest connected component (LCC) is $C_{A,1}$. Therefore, nodes outside this component fail. The intermediate set of functional nodes in $A$ is $S_{A,\\mathrm{LCC}}^{(0)} = \\{a_1, a_3, a_4\\}$.\n\n2.  **Dependency Propagation to Network B:** A node in $B$ fails if its dependency partner in $A$ is no longer functional. The set of all failed nodes in $A$ is now $\\{a_2\\}$ (initial removal) and $\\{a_5, a_6\\}$ (from LCC isolation). Their dependency partners in $B$ are $\\{b_3\\}$, $\\{b_5\\}$, and $\\{b_6\\}$, respectively. We remove these nodes from $S_B^{(0)}$.\n    The intermediate set of functional nodes in $B$ is $S_{B,\\mathrm{dep}}^{(0)} = S_B^{(0)} \\setminus \\{b_3, b_5, b_6\\} = \\{b_1, b_2, b_4, b_7\\}$.\n\n3.  **LCC in Network B:** We find the LCC of the subgraph of $B$ induced by $S_{B,\\mathrm{dep}}^{(0)} = \\{b_1, b_2, b_4, b_7\\}$. The only edge from $E_B$ within this subgraph is $(b_1, b_2)$. This forms three connected components: $C_{B,1}=\\{b_1, b_2\\}$ of size $2$, $C_{B,2}=\\{b_4\\}$ of size $1$, and $C_{B,3}=\\{b_7\\}$ of size $1$. The LCC is $C_{B,1}$. This defines the functional set for the next round: $S_B^{(1)} = \\{b_1, b_2\\}$.\n\n4.  **Dependency Propagation to Network A and Final LCC:** We start with the set $S_{A,\\mathrm{LCC}}^{(0)} = \\{a_1, a_3, a_4\\}$ and remove any node whose dependency partner is not in $S_B^{(1)} = \\{b_1, b_2\\}$.\n    - The partner of $a_1$ is $b_2$, and $b_2 \\in S_B^{(1)}$. So, $a_1$ is kept.\n    - The partner of $a_3$ is $b_1$, and $b_1 \\in S_B^{(1)}$. So, $a_3$ is kept.\n    - The partner of $a_4$ is $b_4$, and $b_4 \\notin S_B^{(1)}$. So, $a_4$ fails.\n    The remaining set of nodes is $\\{a_1, a_3\\}$. We must now find the LCC of the subgraph induced by these nodes. Since the edge $(a_1, a_3) \\in E_A$, this subgraph is connected. Thus, its LCC is the set itself.\n    This defines the functional set for the next round: $S_A^{(1)} = \\{a_1, a_3\\}$.\n\nAt the end of round $1$, the functional sets are $S_A^{(1)} = \\{a_1, a_3\\}$ and $S_B^{(1)} = \\{b_1, b_2\\}$.\n\n**Cascade Round 2 ($t=1 \\to t=2$)**\nWe begin with the functional sets $S_A^{(1)} = \\{a_1, a_3\\}$ and $S_B^{(1)} = \\{b_1, b_2\\}$.\n\n1.  **LCC in Network A:** The subgraph induced by $S_A^{(1)}$ is connected due to the edge $(a_1, a_3)$. The LCC is the set itself. So, $S_{A,\\mathrm{LCC}}^{(1)} = \\{a_1, a_3\\}$.\n\n2.  **Dependency Propagation to Network B:** We check the dependency partners of nodes in $S_B^{(1)} = \\{b_1, b_2}\\}$.\n    - The partner of $b_1$ is $a_3$, which is in $S_{A,\\mathrm{LCC}}^{(1)}$. So, $b_1$ is kept.\n    - The partner of $b_2$ is $a_1$, which is in $S_{A,\\mathrm{LCC}}^{(1)}$. So, $b_2$ is kept.\n    No nodes fail due to dependency. The intermediate set is $S_{B,\\mathrm{dep}}^{(1)} = \\{b_1, b_2\\}$.\n\n3.  **LCC in Network B:** The subgraph induced by $S_{B,\\mathrm{dep}}^{(1)} = \\{b_1, b_2\\}$ is connected due to the edge $(b_1, b_2)$. The LCC is the set itself. Thus, $S_B^{(2)} = \\{b_1, b_2\\}$.\n\n4.  **Dependency Propagation to Network A and Final LCC:** We start with $S_{A,\\mathrm{LCC}}^{(1)} = \\{a_1, a_3\\}$ and check dependencies against $S_B^{(2)} = \\{b_1, b_2\\}$.\n    - The partner of $a_1$ is $b_2 \\in S_B^{(2)}$. So, $a_1$ is kept.\n    - The partner of $a_3$ is $b_1 \\in S_B^{(2)}$. So, $a_3$ is kept.\n    No nodes fail due to dependency. The remaining set is $\\{a_1, a_3\\}$. The subgraph induced by this set is connected, so its LCC is the set itself.\n    Thus, $S_A^{(2)} = \\{a_1, a_3\\}$.\n\nAfter two rounds, the system has stabilized with $S_A^{(2)} = S_A^{(1)} = \\{a_1, a_3\\}$ and $S_B^{(2)} = S_B^{(1)} = \\{b_1, b_2\\}$.\nThe cardinalities are $|S_A^{(2)}| = 2$ and $|S_B^{(2)}| = 2$.",
            "answer": "$$\\boxed{\\begin{pmatrix} 2 & 2 \\end{pmatrix}}$$"
        },
        {
            "introduction": "The ultimate goal of theoretical modeling is to make quantifiable predictions and understand their limitations. This advanced computational practice challenges you to synthesize the generating function framework into a full-fledged numerical model to determine the critical failure threshold, $p_c$, for an interdependent system . Furthermore, by employing bootstrap resampling, you will investigate how finite-size effects and sample-to-sample variability in network structure create uncertainty in this critical point, a crucial consideration in the analysis of real-world data.",
            "id": "4266361",
            "problem": "Consider two fully interdependent networks, denoted as $A$ and $B$, each constructed as a configuration model defined entirely by an observed degree sequence. Interdependence is one-to-one and bidirectional: every node in $A$ depends on exactly one node in $B$, and vice versa, and a node fails if either it is not connected to the giant component of its own network or its dependent counterpart in the other network fails. An initial random failure removes a fraction $1 - p$ of nodes uniformly at random from both networks, where $p \\in [0,1]$ is the retained fraction.\n\nFundamental base and core definitions to use:\n- A configuration model network is specified by its degree distribution $P(k)$, which is the probability that a randomly chosen node has degree $k$. Its mean degree is $\\langle k \\rangle = \\sum_{k=0}^{\\infty} k P(k)$.\n- The generating functions of the degree distribution are the ordinary generating function $G_0(x) = \\sum_{k=0}^{\\infty} P(k) x^k$ and the excess-degree generating function $G_1(x) = \\sum_{k=1}^{\\infty} \\frac{k P(k)}{\\langle k \\rangle} x^{k-1}$, which arises from the fact that the distribution of the number of remaining edges when following a random edge is proportional to $k P(k)$.\n- In single-network site percolation on a configuration model with an occupancy fraction $x \\in [0,1]$, the giant component fraction is determined by a self-consistent fixed-point equation derived from the generating function framework and the branching process approximation. This fixed point relates the probability that an edge does not lead to the giant component to the retained fraction $x$, and the resulting giant component fraction is a function of $x$, $G_0(\\cdot)$, and $G_1(\\cdot)$.\n- In two fully interdependent networks, cascading failures proceed by alternating single-network percolation steps triggered by dependency removal, yielding a coupled fixed-point condition across $A$ and $B$.\n\nTask:\n1. Derive from the above fundamental base the fixed-point mapping for the occupancy-to-giant-component relation in a single configuration-model network as a function $S(x)$, where $x$ is the retained fraction. Then, derive the coupled fixed-point iteration for two interdependent networks, where the retained fraction pairs $(x_A, x_B)$ evolve by alternating application of the single-network mapping, starting from $(p,p)$, until convergence or collapse.\n2. Define the critical retained fraction $p_c$ as the infimum $p \\in [0,1]$ such that the cascade does not collapse to zero and the coupled fixed point yields a strictly positive mutual giant component in both networks. Justify that sample-to-sample variability in degree sequences leads to fluctuations in $p_c$ through the dependence of the generating functions $G_0(x)$ and $G_1(x)$ on the empirical degree distributions.\n3. Implement a program that, for each test case below, computes a point estimate $\\hat{p}_c$ by numerically solving the coupled fixed point via iterative cascading and bisection over $p$, and then computes a two-sided $95\\%$ confidence interval for $p_c$ by bootstrap resampling of the observed degree sequences (with replacement) and repeating the fixed-point solution for each bootstrap replicate to obtain the bootstrap distribution of $p_c$. The confidence interval must be returned as lower and upper quantiles at levels $0.025$ and $0.975$. All answers must be expressed as decimal floats. No physical units or angle units apply. Ensure algorithmic convergence by using appropriate numerical tolerances.\n\nTest suite:\nFor each test case, generate the observed degree sequences exactly as specified, using the indicated pseudo-random seeds to ensure reproducibility. Use the same network sizes for observed sequences and bootstrap resamples. For every test case, return a list of three floats $[\\hat{p}_c, \\text{CI}_{\\text{lower}}, \\text{CI}_{\\text{upper}}]$ computed as described.\n\n- Test Case $1$ (balanced, medium connectivity):\n  - Network $A$: sample $N_A = 800$ degrees independently from a Poisson distribution with mean $\\lambda_A = 3.0$ using seed $s_A = 1234$.\n  - Network $B$: sample $N_B = 800$ degrees independently from a Poisson distribution with mean $\\lambda_B = 3.0$ using seed $s_B = 5678$.\n  - Number of bootstrap replicates: $B = 200$.\n\n- Test Case $2$ (heterogeneous and mismatched connectivity):\n  - Network $A$: sample $N_A = 1000$ degrees from a truncated power-law over integers $k \\in \\{1,2,\\dots,50\\}$ with exponent $\\alpha = 2.5$, i.e., probability proportional to $k^{-\\alpha}$, using seed $s_A = 222$.\n  - Network $B$: sample $N_B = 1000$ degrees from a negative binomial distribution with parameters $(r = 3, p = 0.5)$ using seed $s_B = 333$.\n  - Number of bootstrap replicates: $B = 200$.\n\n- Test Case $3$ (near-critical sparse networks):\n  - Network $A$: sample $N_A = 600$ degrees from a Poisson distribution with mean $\\lambda_A = 1.2$ using seed $s_A = 444$.\n  - Network $B$: sample $N_B = 600$ degrees from a Poisson distribution with mean $\\lambda_B = 1.2$ using seed $s_B = 555$.\n  - Number of bootstrap replicates: $B = 150$.\n\n- Test Case $4$ (degenerate low-degree structure):\n  - Network $A$: $N_A = 400$ with exactly $380$ nodes of degree $1$, $18$ nodes of degree $2$, and $2$ nodes of degree $3$.\n  - Network $B$: identical to Network $A$.\n  - Number of bootstrap replicates: $B = 100$.\n\nAlgorithmic specifications:\n- For each network, construct the empirical degree distribution $P(k)$ from the observed degrees and compute its mean $\\langle k \\rangle$. Use the generating functions $G_0(x)$ and $G_1(x)$ induced by the empirical $P(k)$.\n- For a single network with occupancy $x$, compute its giant component fraction $S(x)$ via the appropriate fixed-point solution derived from generating functions; use a numerical fixed-point iteration with tolerance $\\varepsilon = 10^{-12}$ and a maximum of $10^4$ iterations for internal fixed-point calculations.\n- For two interdependent networks, perform synchronous cascading updates on $(x_A, x_B)$ starting at $(p,p)$ using the single-network mapping for each network until convergence within tolerance $\\varepsilon = 10^{-12}$ or a maximum of $5000$ cascade iterations. Declare survival if both limits are strictly larger than $10^{-8}$.\n- Determine $p_c$ via bisection on $p \\in [0,1]$ for up to $40$ bisection steps. If survival fails even at $p = 1$, set $p_c = 1.0$.\n- For bootstrap, resample degrees with replacement for each network independently, recompute the empirical $P(k)$, solve for $p_c$ as above, and collect the bootstrap distribution; report the empirical quantiles at $0.025$ and $0.975$ as the confidence interval.\n\nFinal output format:\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, where each element is the three-float list for the corresponding test case, in the same order as listed above. For example: \"[[result_case1_p_hat,result_case1_ci_lower,result_case1_ci_upper],[result_case2_p_hat,result_case2_ci_lower,result_case2_ci_upper],...]\".",
            "solution": "The problem requires the derivation and numerical implementation of a model for cascading failures in two interdependent networks, $A$ and $B$, followed by a statistical analysis of the critical point using bootstrap resampling.\n\n### Part 1: Derivation of the Fixed-Point Equations\n\nThe model is based on percolation theory on configuration-model networks, extended to a system of two interdependent networks. The core of the analysis lies in the use of generating functions for the degree distributions.\n\n#### 1.1 Single Network Percolation\n\nLet us first consider a single network with a degree distribution $P(k)$. The corresponding ordinary and excess-degree generating functions are $G_0(x) = \\sum_{k=0}^{\\infty} P(k) x^k$ and $G_1(x) = \\sum_{k=1}^{\\infty} \\frac{k P(k)}{\\langle k \\rangle} x^{k-1}$, respectively, where $\\langle k \\rangle = \\sum_k k P(k)$ is the mean degree.\n\nSuppose a fraction $x$ of nodes are randomly \"occupied\" (i.e., retained) and a fraction $1-x$ are removed. We want to find the fraction of nodes $S(x)$ that belong to the giant component (GC). This is determined via a self-consistency argument.\n\nLet $f$ be the probability that a node reached by following a random edge is *not* part of the GC. Such a node is not in the GC if it was either initially removed (which happens with probability $1-x$ for any node) or it was occupied (probability $x$) but all of its other edges do not lead to the GC.\n\nThe number of \"other\" edges from a node reached via a random edge is $k-1$, where the degree $k$ is drawn from the excess degree distribution $\\frac{kP(k)}{\\langle k \\rangle}$. The probability that all $k-1$ other edges do not lead to the GC is $f^{k-1}$. Summing over all possible degrees $k$, we obtain the fixed-point equation for $f$:\n$$ f = (1-x) + x \\sum_{k=1}^{\\infty} \\frac{k P(k)}{\\langle k \\rangle} f^{k-1} $$\nThe summation term is precisely the excess-degree generating function $G_1(f)$. Thus, the equation simplifies to:\n$$ f = 1 - x + x G_1(f) $$\nThe smallest non-negative solution, $f^*$, to this equation corresponds to the desired probability. This equation can be solved numerically via fixed-point iteration, e.g., $f_{n+1} = 1 - x + x G_1(f_n)$, starting from an initial guess like $f_0=0.5$.\n\nOnce $f^*$ is determined, we can find the fraction of nodes in the GC, $S(x)$. A randomly chosen node is in the GC if and only if it is occupied (probability $x$) AND it is connected to the GC. The probability that a random node is *not* in the GC is the sum of the probability that it is unoccupied ($1-x$) and the probability that it is occupied but all its edges lead to finite components. The latter probability is $x \\sum_{k=0}^{\\infty} P(k) (f^*)^k = x G_0(f^*)$.\nSo, the probability of not being in the GC is $(1-x) + xG_0(f^*)$. The fraction of nodes in the GC is therefore:\n$$ S(x) = 1 - \\left[ (1-x) + x G_0(f^*) \\right] = x - x G_0(f^*) = x(1 - G_0(f^*)) $$\nThis function $S(x)$ maps the retained fraction of nodes $x$ to the resulting fraction of nodes in the giant component.\n\n#### 1.2 Interdependent Networks\n\nNow, consider two interdependent networks, $A$ and $B$. An initial fraction $1-p$ of nodes is removed from both. A node survives the cascade if it is not initially removed, it is part of its own network's GC, AND its interdependent partner in the other network also survives.\n\nLet $P_A$ and $P_B$ be the probabilities that a randomly chosen node in network $A$ and $B$, respectively, belongs to the final mutual giant component. These are the quantities we wish to find.\n\nConsider a node in network $A$. For it to be part of the final functional component, three conditions must be met:\n1. It must not have been removed in the initial attack (probability $p$).\n2. Its interdependent partner in network $B$ must be part of the final functional component of $B$ (probability $P_B$).\n3. The node must belong to the giant component of network $A$, under the condition that only nodes satisfying (1) and (2) are considered \"occupied\".\n\nThe effective fraction of occupied nodes in network $A$ is the probability that a node satisfies (1) and (2), which, due to the random one-to-one dependency mapping, is $\\psi_A = p \\cdot P_B$.\nGiven this effective occupancy $\\psi_A$, the fraction of nodes in network $A$ that belong to its giant component is given by the single-network mapping $S_A(\\psi_A) = S_A(p \\cdot P_B)$. This fraction must be equal to the probability $P_A$ we are trying to find.\n\nBy symmetry, we arrive at the coupled fixed-point equations for the interdependent system:\n$$ P_A = S_A(p \\cdot P_B) $$\n$$ P_B = S_B(p \\cdot P_A) $$\nwhere $S_A$ and $S_B$ are the respective single-network GC mapping functions derived in the previous section.\n\nThese equations can be solved by synchronous iteration:\n1. Initialize $(P_A^{(0)}, P_B^{(0)}) = (p, p)$.\n2. Iterate for $n=0, 1, 2, \\dots$:\n   $$ P_A^{(n+1)} = S_A(p \\cdot P_B^{(n)}) $$\n   $$ P_B^{(n+1)} = S_B(p \\cdot P_A^{(n)}) $$\n3. The iteration continues until the pair $(P_A, P_B)$ converges to a fixed point $(P_A^*, P_B^*)$. If the fixed point is strictly positive, the network survives. Otherwise, it collapses.\n\n### Part 2: Critical Practions and Bootstrap Confidence Intervals\n\nThe critical retained fraction $p_c$ is the minimum value of $p$ for which a non-zero solution $(P_A^* > 0, P_B^* > 0)$ exists. Below $p_c$, the only stable solution is $(0,0)$. This value marks the percolation threshold for the interdependent system.\n\nThe value of $p_c$ depends on the functions $S_A$ and $S_B$, which in turn depend on the generating functions $G_{0,A}, G_{1,A}, G_{0,B}, G_{1,B}$. In this problem, these are derived from *empirical* degree sequences. Since these sequences are finite samples, they are subject to statistical fluctuations. If we were to draw different samples of degrees, we would obtain slightly different empirical distributions, leading to different $S$ functions and a different computed $p_c$. This justifies that $p_c$ itself is a random variable whose distribution is induced by the sampling process for the degrees.\n\nTo numerically estimate $p_c$ and its uncertainty, we perform two tasks:\n1.  **Point Estimate ($\\hat{p}_c$)**: For the single observed pair of degree sequences, we find $p_c$ using a bisection search. We define a function `survives(p)` which returns true if the iterative cascade for a given $p$ converges to a non-zero fixed point, and false otherwise. We then search for the boundary between survival and collapse in the interval $p \\in [0, 1]$.\n2.  **Confidence Interval (CI)**: We use bootstrap resampling to approximate the sampling distribution of $\\hat{p}_c$. We generate a large number, $B$, of new pairs of degree sequences by resampling with replacement from the original observed sequences. For each of these $B$ bootstrap replicates, we compute $\\hat{p}_c$. The collection of these $B$ values forms the bootstrap distribution. The $95\\%$ confidence interval is then estimated by taking the $2.5\\%$ and $97.5\\%$ quantiles of this distribution.\n\n### Part 3: Algorithmic Implementation\n\nThe overall algorithm proceeds as follows:\n1.  For each test case, generate the specified original degree sequences for networks $A$ and $B$.\n2.  Implement a function `make_s_of_x` that takes a degree sequence, computes the empirical generating functions $G_0$ and $G_1$, and returns the corresponding single-network mapping function $S(x)$. This involves the numerical fixed-point solution for $f$.\n3.  Implement a function `check_survival(p, S_A, S_B)` which solves the coupled cascade equations for a given $p$ and the two network mappings, returning true if the final mutual GCs are non-zero.\n4.  Implement `find_pc(S_A, S_B)` which uses bisection over $p \\in [0, 1]$ calling `check_survival` to find the critical threshold.\n5.  Compute the point estimate $\\hat{p}_c$ using the original degree sequences.\n6.  Perform a bootstrap loop for $B$ replicates:\n    a. Create bootstrap degree sequences by resampling with replacement from the original sequences.\n    b. Create the corresponding $S_A$ and $S_B$ functions for the bootstrap sample.\n    c. Compute and store the resulting $p_c$ for this replicate.\n7.  Calculate the $0.025$ and $0.975$ quantiles from the stored bootstrap $p_c$ values to form the CI.\n8.  Collect $[\\hat{p}_c, \\text{CI}_{\\text{lower}}, \\text{CI}_{\\text{upper}}]$ for each test case and format the final output.\n\nVectorized `numpy` operations are used for performance, especially in the calculation of generating functions, which are called repeatedly.",
            "answer": "```python\nimport numpy as np\nimport collections\n\n# Algorithmic constants from the problem statement\nFP_TOL = 1e-12\nFP_MAX_ITER = 10000\nCASCADE_TOL = 1e-12\nCASCADE_MAX_ITER = 5000\nBISECTION_STEPS = 40\nSURVIVAL_THRESH = 1e-8\n\ndef get_generating_functions(degrees):\n    \"\"\"\n    Computes the ordinary and excess-degree generating functions from an empirical degree sequence.\n    \"\"\"\n    if len(degrees) == 0:\n        return lambda x: 1.0, lambda x: 0.0\n\n    unique_k, counts = np.unique(degrees, return_counts=True)\n    probs = counts / len(degrees)\n    mean_k = np.mean(degrees)\n\n    def G0(x):\n        if x == 0:\n            return probs[unique_k == 0][0] if 0 in unique_k else 0.0\n        return np.sum(probs * np.power(x, unique_k))\n\n    def G1(x):\n        if mean_k == 0:\n            return 0.0\n        \n        valid_indices = unique_k > 0\n        if not np.any(valid_indices):\n            return 0.0\n            \n        k_vals = unique_k[valid_indices]\n        prob_vals = probs[valid_indices]\n        \n        if x == 0:\n            return (k_vals[0] * prob_vals[0] / mean_k) if k_vals[0] == 1 else 0.0\n\n        return np.sum(k_vals * prob_vals / mean_k * np.power(x, k_vals - 1))\n\n    return G0, G1\n\ndef make_s_of_x_func(degrees):\n    \"\"\"\n    Creates the single-network mapping S(x) for a given degree sequence.\n    \"\"\"\n    G0, G1 = get_generating_functions(degrees)\n\n    def s_of_x(x):\n        if x <= 0:\n            return 0.0\n        if x >= 1:\n            x = 1.0\n        \n        f = 0.5\n        for _ in range(FP_MAX_ITER):\n            f_next = 1.0 - x + x * G1(f)\n            if abs(f_next - f) < FP_TOL:\n                f = f_next\n                break\n            f = f_next\n        \n        return x * (1.0 - G0(f))\n\n    return s_of_x\n\ndef check_survival(p, S_A, S_B):\n    \"\"\"\n    Solves the coupled cascade equations for a given p and returns if the system survives.\n    \"\"\"\n    if p <= 0:\n        return False\n        \n    pa, pb = p, p\n    for _ in range(CASCADE_MAX_ITER):\n        pa_next = S_A(p * pb)\n        pb_next = S_B(p * pa)\n        \n        if max(abs(pa_next - pa), abs(pb_next - pb)) < CASCADE_TOL:\n            pa, pb = pa_next, pb_next\n            break\n        pa, pb = pa_next, pb_next\n\n    return pa > SURVIVAL_THRESH and pb > SURVIVAL_THRESH\n\ndef find_pc(S_A, S_B):\n    \"\"\"\n    Finds the critical retained fraction p_c using bisection search.\n    \"\"\"\n    if not check_survival(1.0, S_A, S_B):\n        return 1.0\n    \n    low, high = 0.0, 1.0\n    for _ in range(BISECTION_STEPS):\n        mid = (low + high) / 2.0\n        if mid == low or mid == high: # Precision limit reached\n            break\n        if check_survival(mid, S_A, S_B):\n            high = mid\n        else:\n            low = mid\n            \n    return high\n\ndef generate_degrees(spec):\n    \"\"\"\n    Generates degree sequences based on the test case specification.\n    \"\"\"\n    dist_type = spec['dist']\n    N = spec['N']\n    seed = spec.get('seed')\n    rng = np.random.default_rng(seed)\n\n    if dist_type == 'poisson':\n        return rng.poisson(spec['lambda'], size=N)\n    elif dist_type == 'truncated_power_law':\n        k_min, k_max = 1, spec['k_max']\n        alpha = spec['alpha']\n        k_range = np.arange(k_min, k_max + 1, dtype=np.float64)\n        weights = k_range**(-alpha)\n        probs = weights / np.sum(weights)\n        return rng.choice(k_range, size=N, p=probs).astype(int)\n    elif dist_type == 'negative_binomial':\n        r, p_param = spec['r'], spec['p']\n        return rng.negative_binomial(r, p_param, size=N)\n    elif dist_type == 'fixed':\n        return np.array(spec['sequence'], dtype=int)\n    else:\n        raise ValueError(f\"Unknown distribution type: {dist_type}\")\n\ndef solve():\n    \"\"\"\n    Main function to run all test cases and produce the final output.\n    \"\"\"\n    test_cases_spec = [\n        {\n            'A': {'dist': 'poisson', 'N': 800, 'lambda': 3.0, 'seed': 1234},\n            'B': {'dist': 'poisson', 'N': 800, 'lambda': 3.0, 'seed': 5678},\n            'B_reps': 200\n        },\n        {\n            'A': {'dist': 'truncated_power_law', 'N': 1000, 'alpha': 2.5, 'k_max': 50, 'seed': 222},\n            'B': {'dist': 'negative_binomial', 'N': 1000, 'r': 3, 'p': 0.5, 'seed': 333},\n            'B_reps': 200\n        },\n        {\n            'A': {'dist': 'poisson', 'N': 600, 'lambda': 1.2, 'seed': 444},\n            'B': {'dist': 'poisson', 'N': 600, 'lambda': 1.2, 'seed': 555},\n            'B_reps': 150\n        },\n        {\n            'A': {'dist': 'fixed', 'N': 400, 'sequence': [1]*380 + [2]*18 + [3]*2},\n            'B': {'dist': 'fixed', 'N': 400, 'sequence': [1]*380 + [2]*18 + [3]*2},\n            'B_reps': 100\n        }\n    ]\n\n    all_results = []\n    \n    for case in test_cases_spec:\n        # Generate original degree sequences\n        degrees_A_orig = generate_degrees(case['A'])\n        degrees_B_orig = generate_degrees(case['B'])\n        \n        # Create S(x) functions for original data\n        S_A_orig = make_s_of_x_func(degrees_A_orig)\n        S_B_orig = make_s_of_x_func(degrees_B_orig)\n\n        # Calculate point estimate for p_c\n        pc_hat = find_pc(S_A_orig, S_B_orig)\n\n        # Bootstrap\n        B_reps = case['B_reps']\n        bootstrap_pcs = np.zeros(B_reps)\n        \n        boot_rng = np.random.default_rng() \n        N_A, N_B = case['A']['N'], case['B']['N']\n\n        for i in range(B_reps):\n            degrees_A_boot = boot_rng.choice(degrees_A_orig, size=N_A, replace=True)\n            degrees_B_boot = boot_rng.choice(degrees_B_orig, size=N_B, replace=True)\n\n            S_A_boot = make_s_of_x_func(degrees_A_boot)\n            S_B_boot = make_s_of_x_func(degrees_B_boot)\n            \n            bootstrap_pcs[i] = find_pc(S_A_boot, S_B_boot)\n\n        # Calculate confidence interval\n        ci_lower, ci_upper = np.quantile(bootstrap_pcs, [0.025, 0.975])\n\n        all_results.append([pc_hat, ci_lower, ci_upper])\n\n    # Format the final output string\n    result_str = \",\".join([f\"[{r[0]},{r[1]},{r[2]}]\" for r in all_results])\n    print(f\"[{result_str}]\")\n\nsolve()\n```"
        }
    ]
}