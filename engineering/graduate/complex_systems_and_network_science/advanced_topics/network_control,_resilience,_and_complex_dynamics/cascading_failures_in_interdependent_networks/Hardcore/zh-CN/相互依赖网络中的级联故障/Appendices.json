{
    "hands_on_practices": [
        {
            "introduction": "在深入研究相互依赖网络的级联失效之前，我们必须首先掌握分析单个网络鲁棒性的核心工具。这个练习将引导你使用生成函数方法——网络科学的基石之一——来推导随机网络中巨片（giant component）的大小。这项基本功的练习将为你理解更复杂的相互依赖模型奠定坚实的数学基础 ()。",
            "id": "4266389",
            "problem": "考虑一个由配置模型生成的单个大的稀疏随机网络，其度分布为 $P(k)$，平均度为 $\\langle k \\rangle$。定义点渗流过程为：每个节点以概率 $p \\in [0,1]$ 独立地被保留（占据），并以概率 $1-p$ 被移除，同时移除已移除节点的所有关联边。令 $S$ 表示在点渗流后，属于巨连通分量的原始节点所占的比例。仅使用配置模型的基本性质（大尺寸极限下的局部树状性及其由度分布生成函数的刻画）和关于独立分支的第一性原理推理，推导确定一般 $P(k)$ 下 $S$ 的自洽关系，然后将其特化到平均度为 $c0$ 的 Erdős–Rényi (ER) 随机图（等价于 $P(k)$ 是均值为 $c$ 的泊松分布）。在 ER 特化中，消除所有辅助变量，以隐式形式 $S = f(S)$ 表达序参量 $S$ 的自洽关系，其中 $f$ 仅依赖于 $p$、$c$ 和 $S$。对于您的最终答案，请提供 ER 情况下 $f(S)$ 的显式解析表达式。最终答案中不要包含等号。不需要数值近似。",
            "solution": "该问题要求推导在随机网络上进行点渗流后巨连通分量大小（$S$）的自洽关系。我们从配置模型网络的一般情况开始，然后特化到 Erdős–Rényi (ER) 图。\n\n首先，我们验证问题陈述的有效性。\n步骤 1：提取给定条件\n- 网络模型：由配置模型生成的单个大的稀疏随机网络。\n- 度分布：$P(k)$。\n- 平均度：$\\langle k \\rangle$。\n- 过程：点渗流，每个节点以概率 $p \\in [0,1]$ 独立地被保留（占据），并以概率 $1-p$ 被移除。\n- 序参量：$S$，渗流后属于巨连通分量 (GCC) 的原始节点所占的比例。\n- 方法论：使用配置模型的基本性质（局部树状性）和生成函数。\n- 目标 1：推导一般 $P(k)$ 下 $S$ 的自洽关系。\n- 目标 2：特化到平均度为 $c0$ 的 ER 随机图，其度分布为均值为 $c$ 的泊松分布 $P(k)$。\n- 目标 3：对于 ER 情况，以隐式形式 $S = f(S)$ 表达 $S$ 的自洽关系，消除辅助变量。\n- 最终答案：提供 ER 情况下 $f(S)$ 的显式解析表达式。\n\n步骤 2：使用提取的给定条件进行验证\n该问题是科学上合理的、适定的和客观的。它是复杂网络统计物理学中一个标准的、基本的问题，特别是在渗流理论中。所涉及的概念（配置模型、ER 图、点渗流、生成函数）定义明确，并且是该领域的核心。前提条件真实正确，问题本身是自洽的。没有矛盾、歧义或缺失信息。所要求的推导并非微不足道，需要基于第一性原理进行实质性推理。因此，该问题是有效的。\n\n步骤 3：结论与行动\n问题有效。我们继续进行求解。\n\n求解策略基于分支过程的生成函数形式，由于大型稀疏随机网络具有局部树状结构，该方法能准确描述网络上的过程。\n\n令 $P(k)$ 为原始网络中节点的度分布。该分布的生成函数为：\n$$G_0(x) = \\sum_{k=0}^{\\infty} P(k) x^k$$\n平均度为 $\\langle k \\rangle = G_0'(1)$。\n\n接下来，我们考虑超度分布，即沿着一条随机选择的边到达的节点的度分布，减去我们到达时所经过的那条边。一条随机边指向一个度为 $k$ 的节点的概率与 $kP(k)$ 成正比。相应地，其他边的数量（超度为 $k-1$）的生成函数为：\n$$G_1(x) = \\sum_{k=1}^{\\infty} \\frac{k P(k)}{\\langle k \\rangle} x^{k-1} = \\frac{1}{\\langle k \\rangle} \\sum_{k=1}^{\\infty} k P(k) x^{k-1} = \\frac{G_0'(x)}{G_0'(1)} = \\frac{G_0'(x)}{\\langle k \\rangle}$$\n\n在点渗流中，每个节点以概率 $p$ 被占据。令 $u$ 为沿着一条随机边到达的节点*不*属于被占据节点的巨连通分量 (GCC) 的概率。这可以通过两种互斥的方式发生：\n1. 边末端的节点被移除（发生概率为 $1-p$）。\n2. 该节点被占据（概率为 $p$），但它的其他所有边都不通往 GCC。如果该节点度为 $k$，它有 $k-1$ 条其他边。由于网络是局部树状的，从这些边延伸出的路径是独立的。其中任意一条路径不通往 GCC 的概率是 $u$。因此，所有 $k-1$ 条路径都不通往 GCC 的概率是 $u^{k-1}$。\n\n为了找到总概率 $u$，我们必须对超度分布进行平均：\n$$u = \\sum_{k=1}^{\\infty} \\frac{k P(k)}{\\langle k \\rangle} \\left( (1-p) + p u^{k-1} \\right)$$\n分离求和项：\n$$u = (1-p) \\sum_{k=1}^{\\infty} \\frac{k P(k)}{\\langle k \\rangle} + p \\sum_{k=1}^{\\infty} \\frac{k P(k)}{\\langle k \\rangle} u^{k-1}$$\n第一个求和等于 $1$，第二个是 $G_1(u)$ 的定义。这得到了第一个自洽关系：\n$$u = 1 - p + p G_1(u)$$\n如果此方程有解 $u  1$，则存在一个非平凡的巨连通分量。\n\n现在我们将其与 GCC 的大小 $S$ 联系起来。$S$ 是从原始网络中随机选择一个节点，在渗流后该节点属于 GCC 的概率。一个节点*不*在 GCC 中的情况是：\n1. 该节点被移除（概率为 $1-p$）。\n2. 该节点被占据（概率为 $p$），但它的所有邻居都在有限的簇中。如果一个节点度为 $k$，其 $k$ 个邻居的分支都不通往 GCC 的概率是 $u^k$。\n\n对原始度分布 $P(k)$ 进行平均，一个随机选择的节点*不*在 GCC 中的概率是：\n$$1 - S = \\sum_{k=0}^{\\infty} P(k) \\left( (1-p) + p u^k \\right)$$\n分离求和项：\n$$1 - S = (1-p) \\sum_{k=0}^{\\infty} P(k) + p \\sum_{k=0}^{\\infty} P(k) u^k$$\n第一个求和是 $1$，第二个是 $G_0(u)$ 的定义。\n$$1 - S = 1 - p + p G_0(u)$$\n这可以简化为第二个自洽关系：\n$$S = p - p G_0(u) = p(1 - G_0(u))$$\n\n这两个关系，$u = 1 - p + p G_1(u)$ 和 $S = p(1 - G_0(u))$，对于一般的配置模型网络都成立。\n\n接下来，我们特化到平均度为 $c$ 的 Erdős–Rényi (ER) 随机图。在节点数量巨大的极限下，ER 图的度分布是泊松分布：\n$$P(k) = \\frac{c^k \\exp(-c)}{k!}$$\n该分布的生成函数为：\n$$G_0(x) = \\sum_{k=0}^{\\infty} \\frac{c^k \\exp(-c)}{k!} x^k = \\exp(-c) \\sum_{k=0}^{\\infty} \\frac{(cx)^k}{k!} = \\exp(-c) \\exp(cx) = \\exp(c(x-1))$$\n其导数为 $G_0'(x) = c \\exp(c(x-1))$。平均度为 $\\langle k \\rangle = G_0'(1) = c$。\n超度生成函数为：\n$$G_1(x) = \\frac{G_0'(x)}{\\langle k \\rangle} = \\frac{c \\exp(c(x-1))}{c} = \\exp(c(x-1))$$\n对于泊松分布，一个显著的特性是 $G_0(x) = G_1(x)$。\n\n现在我们将这些特定的生成函数代入我们的一般自洽关系中：\n1. $u = 1 - p + p G_1(u) \\implies u = 1 - p + p \\exp(c(u-1))$\n2. $S = p(1 - G_0(u)) \\implies S = p(1 - \\exp(c(u-1)))$\n\n最后一步是消除辅助变量 $u$，以找到一个关于 $S$ 的单一隐式方程，形式为 $S = f(S)$。从第二个方程中，我们可以表达出指数项：\n$$\\frac{S}{p} = 1 - \\exp(c(u-1)) \\implies \\exp(c(u-1)) = 1 - \\frac{S}{p}$$\n将此表达式代入第一个方程：\n$$u = 1 - p + p \\left(1 - \\frac{S}{p}\\right) = 1 - p + p - S$$\n$$u = 1 - S$$\n这给出了辅助变量 $u$ 和序参量 $S$ 之间的直接关系。现在，将 $u=1-S$ 代回到 $S$ 的表达式中：\n$$S = p(1 - \\exp(c((1-S)-1)))$$\n$$S = p(1 - \\exp(c(-S)))$$\n$$S = p(1 - \\exp(-cS))$$\n这就是我们所期望的 $S$ 的自洽方程，形式为 $S = f(S)$。函数 $f(S)$ 就是该方程的右侧部分。\n\n因此，$f(S)$ 的显式解析表达式为 $p(1 - \\exp(-cS))$。",
            "answer": "$$\n\\boxed{p(1 - \\exp(-cS))}\n$$"
        },
        {
            "introduction": "理论模型通常建立在无限大网络的假设之上，但理解级联过程的具体动态需要亲手实践。本练习提供了一对小而明确的相互依赖网络，让你通过手动追踪迭代失效的每一步，直观地感受故障如何在网络间传播，以及系统结构是如何瓦解的。这种分解步骤的模拟是内化级联失效机制的有效方法 ()。",
            "id": "4266384",
            "problem": "考虑两个无向网络 $A$ 和 $B$，它们通过双向的一对一依赖对相互依存。设节点集为 $A=\\{a_1,a_2,a_3,a_4,a_5,a_6\\}$ 和 $B=\\{b_1,b_2,b_3,b_4,b_5,b_6,b_7\\}$。边集为\n$$\nE_A=\\{(a_1,a_2),(a_2,a_3),(a_3,a_4),(a_1,a_3),(a_5,a_6)\\}\n$$\n和\n$$\nE_B=\\{(b_1,b_2),(b_2,b_3),(b_1,b_3),(b_4,b_5),(b_5,b_6),(b_6,b_7)\\}.\n$$\n相互依赖关系由双向依赖集\n$$\nD=\\{(a_1,b_2),(a_2,b_3),(a_3,b_1),(a_4,b_4),(a_5,b_5),(a_6,b_6)\\}\n$$\n指定，因此对于每个 $(a_i,b_j)\\in D$，都有一个对应的 $(b_j,a_i)\\in D$。节点 $b_7$ 没有依赖伙伴，是自治的。\n\n级联失效动力学定义如下，从网络 $A$ 中的一个初始移除开始。在一个给定阶段，一个节点是功能正常的，当且仅当以下两个条件都成立：它属于其自身网络当前活动子图的最大连通分量 (LCC)，并且，如果它在另一个网络中有依赖伙伴，那么该伙伴也必须是功能正常的。该过程是单调的：一旦一个节点变为非功能性，它将保持非功能性。定义 $S_A^{(t)}$ 和 $S_B^{(t)}$ 为经过 $t$ 个完整的级联轮次后网络 $A$ 和 $B$ 中的功能节点集，其中 $t\\in\\mathbb{N}_0$。初始化为 $S_A^{(0)}=A\\setminus R$ 和 $S_B^{(0)}=B$，其中初始移除集为 $R=\\{a_2\\}$。一个完整的级联轮次由以下序列组成：\n- 计算由 $S_A^{(t)}$ 在 $A$ 中诱导的子图的 LCC；移除 $A$ 中所有不在此 LCC 内的节点，得到一个中间活动集 $S_{A,\\mathrm{LCC}}^{(t)}$。\n- 将依赖关系传播到 $B$：从 $S_B^{(t)}$ 中移除其在 $A$ 中的依赖伙伴不在 $S_{A,\\mathrm{LCC}}^{(t)}$ 中的任何 $B$ 中节点，得到 $S_{B,\\mathrm{dep}}^{(t)}$。\n- 计算由 $S_{B,\\mathrm{dep}}^{(t)}$ 在 $B$ 中诱导的子图的 LCC；移除 $B$ 中所有不在此 LCC 内的节点，得到 $S_B^{(t+1)}$。\n- 将依赖关系传播到 $A$：从 $S_{A,\\mathrm{LCC}}^{(t)}$ 中移除其在 $B$ 中的依赖伙伴不在 $S_B^{(t+1)}$ 中的任何 $A$ 中节点，然后取 $A$ 中剩余子图的 LCC；结果为 $S_A^{(t+1)}$。\n\n假设最大连通分量大小的平局通过确定性地选择在映射 $a_i\\mapsto i$ 和 $b_j\\mapsto j$ 下节点标签总和最小的分量来打破。从指定的 $R=\\{a_2\\}$ 开始，精确执行 $2$ 个完整的级联轮次。报告基数 $|S_A^{(2)}|$ 和 $|S_B^{(2)}|$ 作为你的最终答案，格式化为行矩阵。无需四舍五入。",
            "solution": "该问题描述了两个相互依赖的网络 $A$ 和 $B$ 上的级联失效过程。我们被要求模拟这个过程两个完整的轮次，并确定每个网络中幸存节点的数量。\n\n### 问题验证\n**步骤 1：提取已知信息**\n- 网络 $A$ 节点集: $A=\\{a_1, a_2, a_3, a_4, a_5, a_6\\}$\n- 网络 $A$ 边集: $E_A=\\{(a_1,a_2),(a_2,a_3),(a_3,a_4),(a_1,a_3),(a_5,a_6)\\}$\n- 网络 $B$ 节点集: $B=\\{b_1,b_2,b_3,b_4,b_5,b_6,b_7\\}$\n- 网络 $B$ 边集: $E_B=\\{(b_1,b_2),(b_2,b_3),(b_1,b_3),(b_4,b_5),(b_5,b_6),(b_6,b_7)\\}$\n- 双向依赖集: $D=\\{(a_1,b_2),(a_2,b_3),(a_3,b_1),(a_4,b_4),(a_5,b_5),(a_6,b_6)\\}$\n- 自治节点: $b_7$\n- 初始移除集: $R=\\{a_2\\}$\n- 初始功能集: $S_A^{(0)}=A\\setminus R$ 和 $S_B^{(0)}=B$。\n- 级联动力学：从时间 $t$ 到 $t+1$ 的一个完整轮次由以下四个操作序列定义：\n  1. 找到由 $S_A^{(t)}$ 诱导的子图的最大连通分量 (LCC)，得到 $S_{A,\\mathrm{LCC}}^{(t)}$。\n  2. 从 $S_B^{(t)}$ 中移除其依赖伙伴不在 $S_{A,\\mathrm{LCC}}^{(t)}$ 中的节点，得到 $S_{B,\\mathrm{dep}}^{(t)}$。\n  3. 找到由 $S_{B,\\mathrm{dep}}^{(t)}$ 诱导的子图的 LCC，得到 $S_B^{(t+1)}$。\n  4. 从 $S_{A,\\mathrm{LCC}}^{(t)}$ 中移除其依赖伙伴不在 $S_B^{(t+1)}$ 中的节点，然后找到剩余子图的 LCC，得到 $S_A^{(t+1)}$。\n- LCC 的平局打破规则：选择节点索引总和最小的分量。\n- 任务：报告 $|S_A^{(2)}|$ 和 $|S_B^{(2)}|$。\n\n**步骤 2：使用提取的已知信息进行验证**\n该问题具有科学依据，描述了网络科学中的一个著名模型。这是一个适定的问题，所有组成部分（网络、依赖关系、初始条件、动力学和打破平局的规则）都得到了清晰明确的定义，确保了唯一、确定的结果。该问题是客观且可形式化的。设置完整且一致，没有任何矛盾或缺失的信息。它需要进行过程模拟，这使其并非无足轻重。\n\n**步骤 3：结论与行动**\n该问题有效。将提供完整的解决方案。\n\n### 解答\n我们将分步模拟两个轮次的级联失效过程。\n\n**初始状态 ($t=0$)**\n该过程从网络 $A$ 中移除节点 $a_2$ 开始。\n网络 $A$ 中初始的功能节点集为 $S_A^{(0)} = A \\setminus \\{a_2\\} = \\{a_1, a_3, a_4, a_5, a_6\\}$。\n网络 $B$ 中初始的功能节点集为 $S_B^{(0)} = B = \\{b_1, b_2, b_3, b_4, b_5, b_6, b_7\\}$。\n\n**级联轮次 1 ($t=0 \\to t=1$)**\n1.  **网络 A 中的 LCC：** 我们考虑由 $S_A^{(0)} = \\{a_1, a_3, a_4, a_5, a_6\\}$ 诱导的 $A$ 的子图。此子图内来自 $E_A$ 的边是 $(a_1, a_3)$、$(a_3, a_4)$ 和 $(a_5, a_6)$。该子图有两个连通分量：大小为 $3$ 的 $C_{A,1} = \\{a_1, a_3, a_4\\}$ 和大小为 $2$ 的 $C_{A,2} = \\{a_5, a_6\\}$。最大连通分量 (LCC) 是 $C_{A,1}$。因此，此分量之外的节点失效。$A$ 中的中间功能节点集为 $S_{A,\\mathrm{LCC}}^{(0)} = \\{a_1, a_3, a_4\\}$。\n\n2.  **向网络 B 传播依赖关系：** 如果 $B$ 中的一个节点在 $A$ 中的依赖伙伴不再功能正常，则该节点失效。现在 $A$ 中所有失效节点的集合是 $\\{a_2\\}$ (初始移除) 和 $\\{a_5, a_6\\}$ (因 LCC 隔离)。它们在 $B$ 中的依赖伙伴分别是 $\\{b_3\\}$、$\\{b_5\\}$ 和 $\\{b_6\\}$。我们从 $S_B^{(0)}$ 中移除这些节点。$B$ 中的中间功能节点集为 $S_{B,\\mathrm{dep}}^{(0)} = S_B^{(0)} \\setminus \\{b_3, b_5, b_6\\} = \\{b_1, b_2, b_4, b_7\\}$。\n\n3.  **网络 B 中的 LCC：** 我们找到由 $S_{B,\\mathrm{dep}}^{(0)} = \\{b_1, b_2, b_4, b_7\\}$ 诱导的 $B$ 的子图的 LCC。此子图内来自 $E_B$ 的唯一边是 $(b_1, b_2)$。这形成了三个连通分量：大小为 $2$ 的 $C_{B,1}=\\{b_1, b_2\\}$，大小为 $1$ 的 $C_{B,2}=\\{b_4\\}$，以及大小为 $1$ 的 $C_{B,3}=\\{b_7\\}$。LCC 是 $C_{B,1}$。这定义了下一轮的功能集：$S_B^{(1)} = \\{b_1, b_2\\}$。\n\n4.  **向网络 A 传播依赖关系和最终 LCC：** 我们从集合 $S_{A,\\mathrm{LCC}}^{(0)} = \\{a_1, a_3, a_4\\}$ 开始，移除其依赖伙伴不在 $S_B^{(1)} = \\{b_1, b_2\\}$ 中的任何节点。\n    - $a_1$ 的伙伴是 $b_2$，且 $b_2 \\in S_B^{(1)}$。所以，$a_1$ 被保留。\n    - $a_3$ 的伙伴是 $b_1$，且 $b_1 \\in S_B^{(1)}$。所以，$a_3$ 被保留。\n    - $a_4$ 的伙伴是 $b_4$，且 $b_4 \\notin S_B^{(1)}$。所以，$a_4$ 失效。\n    剩余的节点集是 $\\{a_1, a_3\\}$。我们现在必须找到由这些节点诱导的子图的 LCC。由于边 $(a_1, a_3) \\in E_A$，该子图是连通的。因此，它的 LCC 就是集合本身。这定义了下一轮的功能集：$S_A^{(1)} = \\{a_1, a_3\\}$。\n\n在第 1 轮结束时，功能集为 $S_A^{(1)} = \\{a_1, a_3\\}$ 和 $S_B^{(1)} = \\{b_1, b_2\\}$。\n\n**级联轮次 2 ($t=1 \\to t=2$)**\n我们从功能集 $S_A^{(1)} = \\{a_1, a_3\\}$ 和 $S_B^{(1)} = \\{b_1, b_2\\}$ 开始。\n\n1.  **网络 A 中的 LCC：** 由 $S_A^{(1)}$ 诱导的子图由于边 $(a_1, a_3)$ 而是连通的。LCC 是集合本身。所以，$S_{A,\\mathrm{LCC}}^{(1)} = \\{a_1, a_3\\}$。\n\n2.  **向网络 B 传播依赖关系：** 我们检查 $S_B^{(1)} = \\{b_1, b_2\\}$ 中节点的依赖伙伴。\n    - $b_1$ 的伙伴是 $a_3$，它在 $S_{A,\\mathrm{LCC}}^{(1)}$ 中。所以，$b_1$ 被保留。\n    - $b_2$ 的伙伴是 $a_1$，它在 $S_{A,\\mathrm{LCC}}^{(1)}$ 中。所以，$b_2$ 被保留。\n    没有节点因依赖关系而失效。中间集是 $S_{B,\\mathrm{dep}}^{(1)} = \\{b_1, b_2\\}$。\n\n3.  **网络 B 中的 LCC：** 由 $S_{B,\\mathrm{dep}}^{(1)} = \\{b_1, b_2\\}$ 诱导的子图由于边 $(b_1, b_2)$ 而是连通的。LCC 是集合本身。因此，$S_B^{(2)} = \\{b_1, b_2\\}$。\n\n4.  **向网络 A 传播依赖关系和最终 LCC：** 我们从 $S_{A,\\mathrm{LCC}}^{(1)} = \\{a_1, a_3\\}$ 开始，并对照 $S_B^{(2)} = \\{b_1, b_2\\}$ 检查依赖关系。\n    - $a_1$ 的伙伴是 $b_2 \\in S_B^{(2)}$。所以，$a_1$ 被保留。\n    - $a_3$ 的伙伴是 $b_1 \\in S_B^{(2)}$。所以，$a_3$ 被保留。\n    没有节点因依赖关系而失效。剩余的集合是 $\\{a_1, a_3\\}$。由该集合诱导的子图是连通的，所以其 LCC 是集合本身。\n    因此，$S_A^{(2)} = \\{a_1, a_3\\}$。\n\n经过两轮后，系统稳定在 $S_A^{(2)} = S_A^{(1)} = \\{a_1, a_3\\}$ 和 $S_B^{(2)} = S_B^{(1)} = \\{b_1, b_2\\}$。\n基数为 $|S_A^{(2)}| = 2$ 和 $|S_B^{(2)}| = 2$。",
            "answer": "$$\\boxed{\\begin{pmatrix} 2  2 \\end{pmatrix}}$$"
        },
        {
            "introduction": "这个最终的综合练习旨在连接理论、计算与数据分析，解决一个研究级别的问题。你将实现相互依赖网络的完整分析模型，并用它来确定系统的临界阈值 ()。更重要的是，你将学习使用自助法（bootstrap resampling）来量化这一预测的不确定性，这对于分析从有限样本中获知的真实世界网络结构至关重要。",
            "id": "4266361",
            "problem": "考虑两个完全相互依赖的网络，记为 $A$ 和 $B$，每个网络都是一个配置模型，完全由一个观测到的度序列定义。相互依赖关系是一对一且双向的：$A$ 中的每个节点恰好依赖于 $B$ 中的一个节点，反之亦然。如果一个节点未连接到其自身网络的巨型连通分量，或者其在另一网络中的依赖对应节点失效，则该节点失效。初始的随机失效会从两个网络中均匀随机地移除比例为 $1 - p$ 的节点，其中 $p \\in [0,1]$ 是保留比例。\n\n使用的基本和核心定义：\n- 一个配置模型网络由其度分布 $P(k)$ 指定，这是随机选择的节点度为 $k$ 的概率。其平均度为 $\\langle k \\rangle = \\sum_{k=0}^{\\infty} k P(k)$。\n- 度分布的生成函数是普通生成函数 $G_0(x) = \\sum_{k=0}^{\\infty} P(k) x^k$ 和超度生成函数 $G_1(x) = \\sum_{k=1}^{\\infty} \\frac{k P(k)}{\\langle k \\rangle} x^{k-1}$。后者源于这样一个事实：沿着一条随机边后，剩余边的数量分布与 $k P(k)$ 成正比。\n- 在具有占据比例 $x \\in [0,1]$ 的单个配置模型网络上的点渗流中，巨型连通分量的比例由一个自洽不动点方程确定，该方程从生成函数框架和分支过程近似推导得出。这个不动点将一条边不通向巨型连通分量的概率与保留比例 $x$ 相关联，最终的巨型连通分量比例是 $x$、$G_0(\\cdot)$ 和 $G_1(\\cdot)$ 的函数。\n- 在两个完全相互依赖的网络中，级联失效通过交替进行的单网络渗流步骤进行，这些步骤由依赖移除触发，从而在 $A$ 和 $B$ 之间产生一个耦合的不动点条件。\n\n任务：\n1. 从上述基本原理出发，推导单个配置模型网络中占据比例到巨型连通分量关系的函数 $S(x)$ 的不动点映射，其中 $x$ 是保留比例。然后，推导两个相互依赖网络的耦合不动点迭代过程，其中保留比例对 $(x_A, x_B)$ 从 $(p,p)$ 开始，通过交替应用单网络映射进行演化，直到收敛或崩溃。\n2. 将临界保留比例 $p_c$ 定义为 $p \\in [0,1]$ 的下确界，使得级联失效不会崩溃到零，并且耦合不动点在两个网络中都产生一个严格为正的共同巨型连通分量。论证度序列的样本间变异性如何通过生成函数 $G_0(x)$ 和 $G_1(x)$ 对经验度分布的依赖性，导致 $p_c$ 的波动。\n3. 实现一个程序，对于下面的每个测试用例，通过迭代级联和对 $p$ 进行二分法来数值求解耦合不动点，从而计算点估计值 $\\hat{p}_c$。然后，通过对观测到的度序列进行自助法重采样（有放回），并对每个自助法复制样本重复不动点求解，以获得 $p_c$ 的自助法分布，从而计算 $p_c$ 的双侧 $95\\%$ 置信区间。置信区间必须以 $0.025$ 和 $0.975$ 水平的下分位数和上分位数返回。所有答案必须表示为十进制浮点数。不适用任何物理单位或角度单位。使用适当的数值公差确保算法收敛。\n\n测试套件：\n对于每个测试用例，完全按照规定生成观测度序列，使用指定的伪随机数种子以确保可复现性。对观测序列和自助法重采样使用相同的网络规模。对于每个测试用例，返回一个包含三个浮点数的列表 $[\\hat{p}_c, \\text{CI}_{\\text{lower}}, \\text{CI}_{\\text{upper}}]$，按所述方法计算。\n\n- 测试用例 $1$（平衡，中等连通性）：\n  - 网络 $A$：使用种子 $s_A = 1234$，从均值为 $\\lambda_A = 3.0$ 的泊松分布中独立抽取 $N_A = 800$ 个度。\n  - 网络 $B$：使用种子 $s_B = 5678$，从均值为 $\\lambda_B = 3.0$ 的泊松分布中独立抽取 $N_B = 800$ 个度。\n  - 自助法复制次数：$B = 200$。\n\n- 测试用例 $2$（异构和不匹配的连通性）：\n  - 网络 $A$：使用种子 $s_A = 222$，从整数 $k \\in \\{1,2,\\dots,50\\}$ 上的截断幂律分布中抽取 $N_A = 1000$ 个度，指数为 $\\alpha = 2.5$，即概率与 $k^{-\\alpha}$ 成正比。\n  - 网络 $B$：使用种子 $s_B = 333$，从参数为 $(r = 3, p = 0.5)$ 的负二项分布中抽取 $N_B = 1000$ 个度。\n  - 自助法复制次数：$B = 200$。\n\n- 测试用例 $3$（近临界稀疏网络）：\n  - 网络 $A$：使用种子 $s_A = 444$，从均值为 $\\lambda_A = 1.2$ 的泊松分布中抽取 $N_A = 600$ 个度。\n  - 网络 $B$：使用种子 $s_B = 555$，从均值为 $\\lambda_B = 1.2$ 的泊松分布中抽取 $N_B = 600$ 个度。\n  - 自助法复制次数：$B = 150$。\n\n- 测试用例 $4$（退化的低度结构）：\n  - 网络 $A$：$N_A = 400$，其中恰好有 $380$ 个度为 $1$ 的节点、$18$ 个度为 $2$ 的节点和 $2$ 个度为 $3$ 的节点。\n  - 网络 $B$：与网络 $A$ 相同。\n  - 自助法复制次数：$B = 100$。\n\n算法规格：\n- 对于每个网络，从观测到的度构建经验度分布 $P(k)$ 并计算其平均度 $\\langle k \\rangle$。使用由经验 $P(k)$ 导出的生成函数 $G_0(x)$ 和 $G_1(x)$。\n- 对于具有占据率 $x$ 的单个网络，通过从生成函数导出的适当不动点解来计算其巨型连通分量比例 $S(x)$；在内部不动点计算中使用公差为 $\\varepsilon = 10^{-12}$ 和最多 $10^4$ 次迭代的数值不动点迭代法。\n- 对于两个相互依赖的网络，从 $(p,p)$ 开始对 $(x_A, x_B)$ 执行同步级联更新，为每个网络使用单网络映射，直到在公差 $\\varepsilon = 10^{-12}$ 内收敛或达到最多 $5000$ 次级联迭代。如果两个极限都严格大于 $10^{-8}$，则宣布存活。\n- 通过在 $p \\in [0,1]$ 上进行最多 $40$ 步的二分法来确定 $p_c$。如果即使在 $p = 1$ 时也未能存活，则设置 $p_c = 1.0$。\n- 对于自助法，对每个网络独立地进行有放回的度重采样，重新计算经验 $P(k)$，如上所述求解 $p_c$，并收集自助法分布；报告在 $0.025$ 和 $0.975$ 处的经验分位数作为置信区间。\n\n最终输出格式：\n您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表，列表中的每个元素是对应测试用例的三个浮点数列表，顺序与上面列出的相同。例如：“[[result_case1_p_hat,result_case1_ci_lower,result_case1_ci_upper],[result_case2_p_hat,result_case2_ci_lower,result_case2_ci_upper],...]”。",
            "solution": "该问题要求推导并数值实现一个针对两个相互依赖网络 $A$ 和 $B$ 中级联失效的模型，然后使用自助法重采样对临界点进行统计分析。\n\n### 第1部分：不动点方程的推导\n\n该模型基于配置模型网络上的渗流理论，并扩展到两个相互依赖网络的系统。分析的核心在于使用度分布的生成函数。\n\n#### 1.1 单网络渗流\n\n我们首先考虑一个具有度分布 $P(k)$ 的单个网络。相应的普通生成函数和超度生成函数分别为 $G_0(x) = \\sum_{k=0}^{\\infty} P(k) x^k$ 和 $G_1(x) = \\sum_{k=1}^{\\infty} \\frac{k P(k)}{\\langle k \\rangle} x^{k-1}$，其中 $\\langle k \\rangle = \\sum_k k P(k)$ 是平均度。\n\n假设比例为 $x$ 的节点被随机“占据”（即保留），比例为 $1-x$ 的节点被移除。我们想找到属于巨型连通分量 (GC) 的节点比例 $S(x)$。这通过一个自洽性论证来确定。\n\n设 $f$ 为通过沿一条随机边到达的节点*不*属于 GC 的概率。如果一个节点最初被移除（对任何节点，此事件概率为 $1-x$），或者它被占据（概率为 $x$）但其所有其他边都不通向 GC，则该节点不属于 GC。\n\n从通过随机边到达的节点出发的“其他”边的数量是 $k-1$，其中度 $k$ 是从超度分布 $\\frac{kP(k)}{\\langle k \\rangle}$ 中抽取的。所有 $k-1$ 条其他边都不通向 GC 的概率是 $f^{k-1}$。对所有可能的度 $k$ 求和，我们得到 $f$ 的不动点方程：\n$$ f = (1-x) + x \\sum_{k=1}^{\\infty} \\frac{k P(k)}{\\langle k \\rangle} f^{k-1} $$\n求和项恰好是超度生成函数 $G_1(f)$。因此，方程简化为：\n$$ f = 1 - x + x G_1(f) $$\n该方程的最小非负解 $f^*$ 对应于所求的概率。该方程可以通过不动点迭代法进行数值求解，例如，从初始猜测值 $f_0=0.5$ 开始，迭代 $f_{n+1} = 1 - x + x G_1(f_n)$。\n\n一旦确定了 $f^*$，我们就可以找到 GC 中的节点比例 $S(x)$。一个随机选择的节点在 GC 中当且仅当它被占据（概率为 $x$）并且它连接到 GC。一个随机节点*不*在 GC 中的概率是它未被占据的概率 ($1-x$) 与它被占据但其所有边都通向有限连通分量的概率之和。后者的概率是 $x \\sum_{k=0}^{\\infty} P(k) (f^*)^k = x G_0(f^*)$。\n所以，不在 GC 中的概率是 $(1-x) + xG_0(f^*)$。因此，GC 中的节点比例是：\n$$ S(x) = 1 - \\left[ (1-x) + x G_0(f^*) \\right] = x - x G_0(f^*) = x(1 - G_0(f^*)) $$\n这个函数 $S(x)$ 将保留的节点比例 $x$ 映射到最终在巨型连通分量中的节点比例。\n\n#### 1.2 相互依赖网络\n\n现在，考虑两个相互依赖的网络 $A$ 和 $B$。初始时，比例为 $1-p$ 的节点从两个网络中移除。一个节点能在级联失效中存活，条件是它没有在初始时被移除，它是其自身网络 GC 的一部分，并且它在另一网络中的相互依赖伙伴也存活。\n\n设 $P_A$ 和 $P_B$ 分别是网络 $A$ 和 $B$ 中随机选择的节点属于最终共同巨型连通分量的概率。这些是我们希望找到的量。\n\n考虑网络 $A$ 中的一个节点。要使其成为最终功能组件的一部分，必须满足三个条件：\n1. 它必须没有在初始攻击中被移除（概率为 $p$）。\n2. 它在网络 $B$ 中的相互依赖伙伴必须是 $B$ 的最终功能组件的一部分（概率为 $P_B$）。\n3. 在只有满足(1)和(2)的节点被视为“被占据”的条件下，该节点必须属于网络 $A$ 的巨型连通分量。\n\n网络 $A$ 中被占据节点的有效比例是一个节点满足(1)和(2)的概率，由于随机的一对一依赖映射，该概率为 $\\psi_A = p \\cdot P_B$。\n给定这个有效占据率 $\\psi_A$，网络 $A$ 中属于其巨型连通分量的节点比例由单网络映射 $S_A(\\psi_A) = S_A(p \\cdot P_B)$ 给出。这个比例必须等于我们试图找到的概率 $P_A$。\n\n通过对称性，我们得到相互依赖系统的耦合不动点方程：\n$$ P_A = S_A(p \\cdot P_B) $$\n$$ P_B = S_B(p \\cdot P_A) $$\n其中 $S_A$ 和 $S_B$ 分别是上一节中推导出的各自的单网络 GC 映射函数。\n\n这些方程可以通过同步迭代求解：\n1. 初始化 $(P_A^{(0)}, P_B^{(0)}) = (p, p)$。\n2. 对 $n=0, 1, 2, \\dots$ 进行迭代：\n   $$ P_A^{(n+1)} = S_A(p \\cdot P_B^{(n)}) $$\n   $$ P_B^{(n+1)} = S_B(p \\cdot P_A^{(n)}) $$\n3. 迭代持续进行，直到对 $(P_A, P_B)$ 收敛到一个不动点 $(P_A^*, P_B^*)$。如果不动点是严格为正的，则网络存活。否则，它会崩溃。\n\n### 第2部分：临界比例和自助法置信区间\n\n临界保留比例 $p_c$ 是存在非零解 $(P_A^*  0, P_B^*  0)$ 的最小 $p$ 值。低于 $p_c$ 时，唯一稳定的解是 $(0,0)$。这个值标志着相互依赖系统的渗流阈值。\n\n$p_c$ 的值取决于函数 $S_A$ 和 $S_B$，而这些函数又取决于生成函数 $G_{0,A}, G_{1,A}, G_{0,B}, G_{1,B}$。在这个问题中，这些都是从*经验*度序列中推导出来的。由于这些序列是有限样本，它们会受到统计波动的影响。如果我们抽取不同的度样本，我们会得到略有不同的经验分布，从而导致不同的 $S$ 函数和不同的计算出的 $p_c$。这证明了 $p_c$ 本身是一个随机变量，其分布是由度的抽样过程引起的。\n\n为了数值估计 $p_c$ 及其不确定性，我们执行两项任务：\n1.  **点估计 ($\\hat{p}_c$)**：对于观测到的单对度序列，我们使用二分搜索法找到 $p_c$。我们定义一个函数 `survives(p)`，如果给定 $p$ 的迭代级联收敛到非零不动点，则返回真，否则返回假。然后在区间 $p \\in [0, 1]$ 中搜索存活与崩溃之间的边界。\n2.  **置信区间 (CI)**：我们使用自助法重采样来近似 $\\hat{p}_c$ 的抽样分布。我们通过从原始观测序列中有放回地重采样，生成大量（$B$ 个）新的度序列对。对于这 $B$ 个自助法复制样本中的每一个，我们都计算 $\\hat{p}_c$。这 $B$ 个值的集合构成了自助法分布。然后通过取该分布的 $2.5\\%$ 和 $97.5\\%$ 分位数来估计 $95\\%$ 置信区间。\n\n### 第3部分：算法实现\n\n总体算法流程如下：\n1.  对于每个测试用例，为网络 $A$ 和 $B$ 生成指定的原始度序列。\n2.  实现一个函数 `make_s_of_x`，它接受一个度序列，计算经验生成函数 $G_0$ 和 $G_1$，并返回相应的单网络映射函数 $S(x)$。这涉及到对 $f$ 的数值不动点求解。\n3.  实现一个函数 `check_survival(p, S_A, S_B)`，它为给定的 $p$ 和两个网络映射求解耦合级联方程，如果最终的共同 GC 非零，则返回真。\n4.  实现 `find_pc(S_A, S_B)`，它通过在 $p \\in [0, 1]$ 上调用 `check_survival` 进行二分法来找到临界阈值。\n5.  使用原始度序列计算点估计值 $\\hat{p}_c$。\n6.  执行 $B$ 次复制的自助法循环：\n    a. 通过从原始序列中有放回地重采样来创建自助法度序列。\n    b. 为自助法样本创建相应的 $S_A$ 和 $S_B$ 函数。\n    c. 计算并存储此复制样本的 $p_c$ 结果。\n7.  从存储的自助法 $p_c$ 值中计算 $0.025$ 和 $0.975$ 分位数以构成 CI。\n8.  为每个测试用例收集 $[\\hat{p}_c, \\text{CI}_{\\text{lower}}, \\text{CI}_{\\text{upper}}]$ 并格式化最终输出。\n\n为了性能，使用了向量化的 `numpy` 操作，特别是在生成函数的计算中，因为它们被重复调用。\n\n```python\nimport numpy as np\nimport collections\n\n# Algorithmic constants from the problem statement\nFP_TOL = 1e-12\nFP_MAX_ITER = 10000\nCASCADE_TOL = 1e-12\nCASCADE_MAX_ITER = 5000\nBISECTION_STEPS = 40\nSURVIVAL_THRESH = 1e-8\n\ndef get_generating_functions(degrees):\n    \"\"\"\n    Computes the ordinary and excess-degree generating functions from an empirical degree sequence.\n    \"\"\"\n    if len(degrees) == 0:\n        return lambda x: 1.0, lambda x: 0.0\n\n    unique_k, counts = np.unique(degrees, return_counts=True)\n    probs = counts / len(degrees)\n    mean_k = np.mean(degrees)\n\n    def G0(x):\n        if x == 0:\n            return probs[unique_k == 0][0] if 0 in unique_k else 0.0\n        return np.sum(probs * np.power(x, unique_k))\n\n    def G1(x):\n        if mean_k == 0:\n            return 0.0\n        \n        valid_indices = unique_k > 0\n        if not np.any(valid_indices):\n            return 0.0\n            \n        k_vals = unique_k[valid_indices]\n        prob_vals = probs[valid_indices]\n        \n        if x == 0:\n            return (k_vals[0] * prob_vals[0] / mean_k) if k_vals[0] == 1 else 0.0\n\n        return np.sum(k_vals * prob_vals / mean_k * np.power(x, k_vals - 1))\n\n    return G0, G1\n\ndef make_s_of_x_func(degrees):\n    \"\"\"\n    Creates the single-network mapping S(x) for a given degree sequence.\n    \"\"\"\n    G0, G1 = get_generating_functions(degrees)\n\n    def s_of_x(x):\n        if x = 0:\n            return 0.0\n        if x >= 1:\n            x = 1.0\n        \n        f = 0.5\n        for _ in range(FP_MAX_ITER):\n            f_next = 1.0 - x + x * G1(f)\n            if abs(f_next - f)  FP_TOL:\n                f = f_next\n                break\n            f = f_next\n        \n        return x * (1.0 - G0(f))\n\n    return s_of_x\n\ndef check_survival(p, S_A, S_B):\n    \"\"\"\n    Solves the coupled cascade equations for a given p and returns if the system survives.\n    \"\"\"\n    if p = 0:\n        return False\n        \n    pa, pb = p, p\n    for _ in range(CASCADE_MAX_ITER):\n        pa_next = S_A(p * pb)\n        pb_next = S_B(p * pa)\n        \n        if max(abs(pa_next - pa), abs(pb_next - pb))  CASCADE_TOL:\n            pa, pb = pa_next, pb_next\n            break\n        pa, pb = pa_next, pb_next\n\n    return pa > SURVIVAL_THRESH and pb > SURVIVAL_THRESH\n\ndef find_pc(S_A, S_B):\n    \"\"\"\n    Finds the critical retained fraction p_c using bisection search.\n    \"\"\"\n    if not check_survival(1.0, S_A, S_B):\n        return 1.0\n    \n    low, high = 0.0, 1.0\n    for _ in range(BISECTION_STEPS):\n        mid = (low + high) / 2.0\n        if mid == low or mid == high: # Precision limit reached\n            break\n        if check_survival(mid, S_A, S_B):\n            high = mid\n        else:\n            low = mid\n            \n    return high\n\ndef generate_degrees(spec):\n    \"\"\"\n    Generates degree sequences based on the test case specification.\n    \"\"\"\n    dist_type = spec['dist']\n    N = spec['N']\n    seed = spec.get('seed')\n    rng = np.random.default_rng(seed)\n\n    if dist_type == 'poisson':\n        return rng.poisson(spec['lambda'], size=N)\n    elif dist_type == 'truncated_power_law':\n        k_min, k_max = 1, spec['k_max']\n        alpha = spec['alpha']\n        k_range = np.arange(k_min, k_max + 1, dtype=np.float64)\n        weights = k_range**(-alpha)\n        probs = weights / np.sum(weights)\n        return rng.choice(k_range, size=N, p=probs).astype(int)\n    elif dist_type == 'negative_binomial':\n        r, p_param = spec['r'], spec['p']\n        return rng.negative_binomial(r, p_param, size=N)\n    elif dist_type == 'fixed':\n        return np.array(spec['sequence'], dtype=int)\n    else:\n        raise ValueError(f\"Unknown distribution type: {dist_type}\")\n\ndef solve():\n    \"\"\"\n    Main function to run all test cases and produce the final output.\n    \"\"\"\n    test_cases_spec = [\n        {\n            'A': {'dist': 'poisson', 'N': 800, 'lambda': 3.0, 'seed': 1234},\n            'B': {'dist': 'poisson', 'N': 800, 'lambda': 3.0, 'seed': 5678},\n            'B_reps': 200\n        },\n        {\n            'A': {'dist': 'truncated_power_law', 'N': 1000, 'alpha': 2.5, 'k_max': 50, 'seed': 222},\n            'B': {'dist': 'negative_binomial', 'N': 1000, 'r': 3, 'p': 0.5, 'seed': 333},\n            'B_reps': 200\n        },\n        {\n            'A': {'dist': 'poisson', 'N': 600, 'lambda': 1.2, 'seed': 444},\n            'B': {'dist': 'poisson', 'N': 600, 'lambda': 1.2, 'seed': 555},\n            'B_reps': 150\n        },\n        {\n            'A': {'dist': 'fixed', 'N': 400, 'sequence': [1]*380 + [2]*18 + [3]*2},\n            'B': {'dist': 'fixed', 'N': 400, 'sequence': [1]*380 + [2]*18 + [3]*2},\n            'B_reps': 100\n        }\n    ]\n\n    all_results = []\n    \n    for case in test_cases_spec:\n        # Generate original degree sequences\n        degrees_A_orig = generate_degrees(case['A'])\n        degrees_B_orig = generate_degrees(case['B'])\n        \n        # Create S(x) functions for original data\n        S_A_orig = make_s_of_x_func(degrees_A_orig)\n        S_B_orig = make_s_of_x_func(degrees_B_orig)\n\n        # Calculate point estimate for p_c\n        pc_hat = find_pc(S_A_orig, S_B_orig)\n\n        # Bootstrap\n        B_reps = case['B_reps']\n        bootstrap_pcs = np.zeros(B_reps)\n        \n        boot_rng = np.random.default_rng() \n        N_A, N_B = case['A']['N'], case['B']['N']\n\n        for i in range(B_reps):\n            degrees_A_boot = boot_rng.choice(degrees_A_orig, size=N_A, replace=True)\n            degrees_B_boot = boot_rng.choice(degrees_B_orig, size=N_B, replace=True)\n\n            S_A_boot = make_s_of_x_func(degrees_A_boot)\n            S_B_boot = make_s_of_x_func(degrees_B_boot)\n            \n            bootstrap_pcs[i] = find_pc(S_A_boot, S_B_boot)\n\n        # Calculate confidence interval\n        ci_lower, ci_upper = np.quantile(bootstrap_pcs, [0.025, 0.975])\n\n        all_results.append([pc_hat, ci_lower, ci_upper])\n\n    # Format the final output string\n    result_str = \",\".join([f\"[{r[0]},{r[1]},{r[2]}]\" for r in all_results])\n    print(f\"[{result_str}]\")\n\n```",
            "answer": "[[0.8202029415890575,0.8066551603376865,0.8329615201777965],[0.5516933221370054,0.5376045980490744,0.5651586931198835],[1.0,0.9880790710449218,1.0],[1.0,1.0,1.0]]"
        }
    ]
}