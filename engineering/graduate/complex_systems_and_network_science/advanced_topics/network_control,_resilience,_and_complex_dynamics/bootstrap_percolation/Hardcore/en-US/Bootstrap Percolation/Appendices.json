{
    "hands_on_practices": [
        {
            "introduction": "Bootstrap percolation is not merely about connectivity, but about cooperative activation, a distinction that sets it apart from more conventional percolation models. This exercise provides a sharp contrast with standard site percolation on a specially designed graph, illustrating how a dense network of connections is not sufficient for a global cascade without the right local reinforcement . By analyzing a graph with a dense core and sparse leaves, you will analytically quantify how the threshold rule creates a fundamentally different outcome and appreciate the unique nature of bootstrap dynamics.",
            "id": "4265164",
            "problem": "Consider the following family of graphs that highlight a contrast between standard site percolation and $r$-bootstrap percolation. Let $G_{m,d}$ consist of a fully connected core of $m$ nodes (a clique), where each core node has exactly $d$ distinct pendant neighbors (degree-one leaves) attached to it. The total number of nodes is $n = m(1+d)$. Perform standard site percolation by independently occupying each node with probability $\\phi \\in (0,1)$ and consider the largest connected component among the occupied nodes. Independently, initialize $r$-bootstrap percolation with threshold $r=2$ by declaring as initially active exactly those nodes that are occupied in the site percolation step, and then iteratively activate any node that has at least $r$ active neighbors, repeating until no further activations are possible. \n\nStarting from the core definitions that site percolation is an independent node-occupation process and that $r$-bootstrap percolation is an iterative threshold activation dynamics on a graph, analyze $G_{m,d}$ in the limit $m \\to \\infty$ at fixed $d$. \n\nYour tasks are:\n- Deduce, from first principles, whether the standard site percolation process yields a giant component for any fixed $\\phi \\in (0,1)$, and whether the $r$-bootstrap percolation process with $r=2$ fully activates the graph for the same $\\phi$.\n- Define the discrepancy $\\Delta(\\phi,d)$ as the limiting expected fraction of nodes that are active at the end of the $r$-bootstrap process minus the limiting expected fraction of nodes that belong to the largest connected component under standard site percolation, and derive a closed-form analytic expression for $\\Delta(\\phi,d)$.\n\nExpress the final answer as a single closed-form expression in terms of $\\phi$ and $d$. No numerical approximation is required; do not round. No physical units are involved in this problem.",
            "solution": "The problem is assessed to be valid as it is scientifically grounded in network science, well-posed, objective, and internally consistent. It presents a solvable theoretical problem without any factual or logical flaws.\n\nThe problem requires an analysis of two processes, standard site percolation and $r$-bootstrap percolation, on a specific graph family $G_{m,d}$ in the limit where the core size $m \\to \\infty$ while the number of pendants per core node, $d$, remains fixed. The graph $G_{m,d}$ consists of a clique of $m$ core nodes, with each core node having $d$ distinct pendant neighbors (leaves). The total number of nodes in the graph is $n = m + md = m(1+d)$.\n\nLet's analyze each process separately to determine the expected fraction of nodes in the largest component or final active set.\n\n**1. Standard Site Percolation**\n\nIn standard site percolation, each node in $G_{m,d}$ is independently occupied with probability $\\phi \\in (0,1)$. We are interested in the size of the largest connected component (LCC) of occupied nodes.\n\nThe core of the graph is a clique of $m$ nodes. Any two occupied core nodes are, by definition, connected. Let $N_{core}^{occ}$ be the number of occupied core nodes. $N_{core}^{occ}$ follows a binomial distribution, $N_{core}^{occ} \\sim \\text{Bin}(m, \\phi)$. As $m \\to \\infty$, the probability of having $N_{core}^{occ}  2$ tends to zero. Specifically, $P(N_{core}^{occ}=0)=(1-\\phi)^m \\to 0$ and $P(N_{core}^{occ}=1)=m\\phi(1-\\phi)^{m-1} \\to 0$. Therefore, with probability approaching $1$, we have at least two occupied core nodes, which form a single connected component among themselves. This component forms the nucleus of the LCC.\n\nAn occupied pendant node is a leaf, having degree $1$. Its only neighbor is a core node. For an occupied pendant node to be part of a connected component of size greater than $1$, its unique core neighbor must also be part of that component. The LCC will thus consist of all occupied core nodes plus any occupied pendant nodes that are attached to an occupied core node.\n\nLet's calculate the expected size of the LCC, denoted by $\\langle S_{LCC} \\rangle$. By linearity of expectation, this is the sum of probabilities of each node being in the LCC.\nA core node is in the LCC if it is occupied. The expected number of occupied core nodes is $m\\phi$.\nA pendant node is in the LCC if it is occupied AND its core neighbor is occupied. Since these are independent events, the probability of a specific pendant node being in the LCC is $\\phi \\times \\phi = \\phi^2$. There are $md$ pendant nodes. So, the expected number of pendant nodes in the LCC is $md\\phi^2$.\n\nThe total expected size of the LCC is the sum of these two quantities:\n$$ \\langle S_{LCC} \\rangle = m\\phi + md\\phi^2 = m\\phi(1+d\\phi) $$\nThe expected fraction of nodes in the LCC is $\\langle S_{LCC} \\rangle/n$. In the limit $m \\to \\infty$:\n$$ \\lim_{m\\to\\infty} \\frac{\\langle S_{LCC} \\rangle}{n} = \\lim_{m\\to\\infty} \\frac{m\\phi(1+d\\phi)}{m(1+d)} = \\frac{\\phi(1+d\\phi)}{1+d} $$\nFor any fixed $\\phi \\in (0,1)$ and integer $d \\ge 1$, this fraction is strictly greater than $0$. A component containing a non-zero fraction of the total nodes in the infinite-system limit is a giant component. Thus, the standard site percolation process yields a giant component for any fixed $\\phi \\in (0,1)$.\n\n**2. $r$-Bootstrap Percolation with $r=2$**\n\nIn this process, the set of initially active nodes is the set of occupied nodes from the site percolation step. Subsequently, an inactive node becomes active if it has at least $r=2$ active neighbors. This rule is applied iteratively until no more nodes can be activated.\n\nLet's analyze the activation of different node types:\n-   **Pendant nodes**: A pendant node has degree $1$. It can never have $2$ or more active neighbors. Therefore, a pendant node can only be part of the final active set if it was initially active (i.e., occupied). It cannot be activated by the bootstrap dynamics.\n-   **Core nodes**: A core node is connected to all other $m-1$ core nodes. If at least two core nodes are initially active, say $C_i$ and $C_j$, then any other inactive core node $C_k$ will become active in the first step of the bootstrap process. This implies that if at least two core nodes are initially active, all $m$ core nodes will become active.\n\nThe number of initially active core nodes follows a binomial distribution $\\text{Bin}(m, \\phi)$. The probability of having fewer than two initially active core nodes is $P(\\text{fewer than 2}) = (1-\\phi)^m + m\\phi(1-\\phi)^{m-1}$. For any fixed $\\phi \\in (0,1)$, this probability tends to $0$ as $m \\to \\infty$. Thus, with probability approaching $1$, the entire core of $m$ nodes becomes active.\n\nLet's calculate the expected size of the final active set, $\\langle S_{BP} \\rangle$, in the limit $m \\to \\infty$.\nThe final active set consists of all core nodes (with probability approaching $1$) and all initially active pendant nodes.\nThe expected number of active core nodes, in the limit $m \\to \\infty$, is $m$.\nThe expected number of active pendant nodes is the expected number of initially occupied pendant nodes, which is $md\\phi$.\nThe total expected size of the final active set is:\n$$ \\langle S_{BP} \\rangle = m + md\\phi = m(1+d\\phi) $$\nThe limiting expected fraction of active nodes is then:\n$$ \\lim_{m\\to\\infty} \\frac{\\langle S_{BP} \\rangle}{n} = \\lim_{m\\to\\infty} \\frac{m(1+d\\phi)}{m(1+d)} = \\frac{1+d\\phi}{1+d} $$\nThe problem asks whether the process fully activates the graph. Full activation means the fraction of active nodes is $1$. The derived fraction is $1$ only if $1+d\\phi = 1+d$, which would require $\\phi=1$. Since the problem specifies $\\phi \\in (0,1)$, the fraction is always less than $1$. Therefore, the $r$-bootstrap percolation process does not fully activate the graph.\n\n**3. Discrepancy $\\Delta(\\phi, d)$**\n\nThe discrepancy $\\Delta(\\phi,d)$ is defined as the limiting expected fraction of active nodes in the bootstrap process minus the limiting expected fraction of nodes in the LCC under site percolation. Using the results derived above:\n$$ \\Delta(\\phi, d) = \\left( \\lim_{m\\to\\infty} \\frac{\\langle S_{BP} \\rangle}{n} \\right) - \\left( \\lim_{m\\to\\infty} \\frac{\\langle S_{LCC} \\rangle}{n} \\right) $$\n$$ \\Delta(\\phi, d) = \\frac{1+d\\phi}{1+d} - \\frac{\\phi(1+d\\phi)}{1+d} $$\nWe can simplify this expression by factoring out the common term $(1+d\\phi)$:\n$$ \\Delta(\\phi, d) = \\frac{(1+d\\phi) - \\phi(1+d\\phi)}{1+d} $$\n$$ \\Delta(\\phi, d) = \\frac{(1+d\\phi)(1-\\phi)}{1+d} $$\nThis can be expanded for an alternative form:\n$$ \\Delta(\\phi, d) = \\frac{1 - \\phi + d\\phi - d\\phi^2}{1+d} $$\nThis expression represents the limiting expected fraction of nodes that were initially unoccupied but became active during the bootstrap process. This occurs only for core nodes, which are recruited into the active set, and allows their respective occupied pendant neighbors (which would be isolated in site percolation) to be counted in the final active set.",
            "answer": "$$\\boxed{\\frac{(1-\\phi)(1+d\\phi)}{1+d}}$$"
        },
        {
            "introduction": "When simulating or analyzing dynamic processes, a critical question is whether the specific update protocol affects the final outcome. This practice explores the difference between synchronous (parallel) and asynchronous (sequential) updates for bootstrap percolation, a concept central to the model's definition. You will first prove from fundamental principles of monotonicity that the final active set is unique regardless of the update scheme, and then verify this powerful result computationally, demonstrating the robustness of the model's prediction .",
            "id": "4265169",
            "problem": "Let a finite tree graph be denoted by $G = (V,E)$ with $|V| = n$ and undirected edges. Consider $r$-bootstrap percolation defined as follows: an initial active set $A_0 \\subseteq V$ is given. The dynamics are progressive, meaning once a vertex becomes active it remains active. The update rule is: an inactive vertex $v$ becomes active if and only if it has at least $r$ active neighbors. Two update schemes are considered: synchronous and asynchronous. In synchronous updates, all vertices that satisfy the activation rule at a given round are activated simultaneously. In asynchronous updates, vertices are updated one at a time in a random sequential order, repeatedly selecting a single vertex according to a random schedule and applying the same rule, until no further activation is possible. An absorbing set is any $A \\subseteq V$ such that further updates under the rule leave $A$ unchanged.\n\nFundamental base and definitions: A progressive dynamics is one in which state transitions are monotone with respect to set inclusion and do not deactivate vertices. The update operator $F$ for synchronous $r$-bootstrap percolation is defined by $F(A) = A \\cup \\{ v \\in V : |\\{u \\in N(v) : u \\in A\\}| \\ge r \\}$, where $N(v)$ is the neighbor set of $v$. The operator $F$ is monotone with respect to the partial order on subsets of $V$ induced by inclusion and is inflationary, meaning $A \\subseteq F(A)$. On a finite set $V$, repeated application of $F$ must stabilize at a fixed point that is the absorbing set reached from $A_0$. Asynchronous updates apply the same rule to single vertices and thus implement single-site monotone, inflationary operators whose compositions are also monotone and inflationary.\n\nTask: Derive, from the above base, whether the final absorbing set reached by asynchronous random sequential updates is the same as that reached by synchronous updates for $r$-bootstrap percolation on finite trees. Then implement a program to empirically verify the equality of the distribution of final absorbing set sizes between synchronous updates and asynchronous random sequential updates when the initial active set $A_0$ is generated by independent Bernoulli trials with activation probability $p$ at each vertex. For each test case $i$ in the suite below, the program must:\n- Construct the specified tree $G_i$.\n- For $T$ independent trials, sample $A_0$ by including each vertex independently with probability $p$ (expressed as a decimal in $[0,1]$).\n- Compute the final absorbing set size under synchronous updates and under asynchronous random sequential updates starting from the same $A_0$ for each trial.\n- Aggregate the empirical distributions of final sizes for both schemes and compute the total variation distance between them, defined as $\\frac{1}{2} \\sum_{k=0}^{n} |P(k) - Q(k)|$, where $P(k)$ and $Q(k)$ are the empirical probabilities of final size $k$ under synchronous and asynchronous updates, respectively.\n\nYour program must output a single line containing a comma-separated list enclosed in square brackets of the total variation distances (each a float) for the following test suite, in the specified order:\n- Case $1$: Path tree with $n = 20$, threshold $r = 1$, initial activation probability $p = 0.1$, trials $T = 500$.\n- Case $2$: Star tree with $n = 21$ (one center, $20$ leaves), threshold $r = 2$, initial activation probability $p = 0.2$, trials $T = 500$.\n- Case $3$: Complete binary tree of height $h = 5$ (thus $n = 2^{h+1} - 1 = 63$), threshold $r = 2$, initial activation probability $p = 0.05$, trials $T = 500$.\n- Case $4$: Path tree with $n = 50$, threshold $r = 10$, initial activation probability $p = 0.3$, trials $T = 500$.\n- Case $5$: Complete binary tree of height $h = 4$ (thus $n = 2^{h+1} - 1 = 31$), threshold $r = 1$, initial activation probability $p = 0.0$, trials $T = 500$.\n\nFinal output format requirement: Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (e.g., $[x_1,x_2,x_3,x_4,x_5]$), where each $x_i$ is the computed total variation distance (a float) for case $i$.",
            "solution": "The problem asks for two tasks: first, a theoretical derivation concerning the final state of synchronous versus asynchronous bootstrap percolation on finite trees; and second, an empirical verification of the result via a computational experiment.\n\n### Theoretical Derivation\n\nThe core of the question is whether the choice of update scheme—synchronous versus asynchronous random sequential—affects the final absorbing set for $r$-bootstrap percolation. The process is defined on a finite graph $G = (V,E)$. The dynamics are progressive, meaning the set of active vertices, denoted by $A$, can only grow.\n\nLet's formalize the update operators. The initial set of active vertices is $A_0$.\n\nThe **synchronous update** operator, $F$, is defined as:\n$$F(A) = A \\cup \\{ v \\in V \\setminus A : |N(v) \\cap A| \\ge r \\}$$\nwhere $N(v)$ is the set of neighbors of vertex $v$. The final absorbing set under synchronous updates, $A_{sync}^*$, is the fixed point obtained by iterating $F$ starting from $A_0$, i.e., $A_{sync}^* = \\lim_{k \\to \\infty} F^k(A_0)$. This limit is guaranteed to exist because $V$ is finite and $F$ is inflationary ($A \\subseteq F(A)$).\n\nThe **asynchronous update** scheme involves applying single-site operators. For each vertex $i \\in V$, let $F_i$ be the operator that updates only vertex $i$:\n$$F_i(A) = \\begin{cases} A \\cup \\{i\\}  \\text{if } i \\notin A \\text{ and } |N(i) \\cap A| \\ge r \\\\ A  \\text{otherwise} \\end{cases}$$\nAn asynchronous process is a sequence of applications of these single-site operators, $A_{k+1} = F_{i_k}(A_k)$, for some schedule of vertices $\\{i_k\\}$. The final absorbing set, $A_{async}^*$, is the fixed point reached when no more single-vertex activations are possible.\n\nThe problem states, and it is a key property, that these operators are **monotone**. For any operator $\\mathcal{F}$ in our system (be it $F$ or any $F_i$), monotonicity means that if $A \\subseteq B \\subseteq V$, then $\\mathcal{F}(A) \\subseteq \\mathcal{F}(B)$. This property is crucial for proving the equivalence of the final states.\n\nWe will now prove that $A_{sync}^* = A_{async}^*$ for any finite graph (the result is not limited to trees). We do so by showing mutual set inclusion.\n\n**1. Proof of $A_{async}^* \\subseteq A_{sync}^*$**\n\nLet the sequence of active sets in an asynchronous update process be $A_0, A_1, A_2, \\ldots, A_{async}^*$, where $A_{k+1} = F_{v_k}(A_k)$ for some chosen vertex $v_k$. We prove by induction that $A_k \\subseteq A_{sync}^*$ for all $k \\ge 0$.\n\n*   **Base Case ($k=0$):** $A_0 \\subseteq A_{sync}^*$ by the definition of $A_{sync}^*$ as the closure of $A_0$ under the inflationary operator $F$.\n\n*   **Inductive Step:** Assume $A_k \\subseteq A_{sync}^*$ for some $k \\ge 0$. We need to show $A_{k+1} \\subseteq A_{sync}^*$.\n    The set $A_{k+1}$ is either $A_k$ or $A_k \\cup \\{v_k\\}$. If $A_{k+1} = A_k$, the claim holds trivially.\n    If $A_{k+1} = A_k \\cup \\{v_k\\}$, this means vertex $v_k$ was activated. By the rule, $v_k \\notin A_k$ and $|N(v_k) \\cap A_k| \\ge r$.\n    From the inductive hypothesis, $A_k \\subseteq A_{sync}^*$. By monotonicity of set intersection, $N(v_k) \\cap A_k \\subseteq N(v_k) \\cap A_{sync}^*$.\n    This implies $|N(v_k) \\cap A_{sync}^*| \\ge |N(v_k) \\cap A_k| \\ge r$.\n    So, vertex $v_k$ satisfies the activation condition with respect to the set $A_{sync}^*$.\n    Since $A_{sync}^*$ is a fixed point of the synchronous operator $F$, we have $F(A_{sync}^*) = A_{sync}^*$. This means there are no vertices outside $A_{sync}^*$ that can be activated from it. As $v_k$ can be activated from $A_{sync}^*$, it must be that $v_k \\in A_{sync}^*$.\n    Therefore, $A_{k+1} = A_k \\cup \\{v_k\\} \\subseteq A_{sync}^* \\cup \\{v_k\\} = A_{sync}^*$.\n\nBy induction, every set in the asynchronous sequence is a subset of $A_{sync}^*$. This includes the final absorbing set, so $A_{async}^* \\subseteq A_{sync}^*$.\n\n**2. Proof of $A_{sync}^* \\subseteq A_{async}^*$**\n\nLet the sequence of active sets in the synchronous update process be $A^{(0)}, A^{(1)}, A^{(2)}, \\ldots$, where $A^{(0)}=A_0$ and $A^{(k+1)} = F(A^{(k)})$. The union of these sets is $A_{sync}^*$. We prove by induction that $A^{(k)} \\subseteq A_{async}^*$ for all $k \\ge 0$.\n\n*   **Base Case ($k=0$):** $A^{(0)} = A_0$. Since the asynchronous process is progressive and starts from $A_0$, we have $A_0 \\subseteq A_{async}^*$.\n\n*   **Inductive Step:** Assume $A^{(k)} \\subseteq A_{async}^*$ for some $k \\ge 0$. We need to show $A^{(k+1)} \\subseteq A_{async}^*$.\n    By definition, $A^{(k+1)} = F(A^{(k)}) = A^{(k)} \\cup \\{v \\in V \\setminus A^{(k)} : |N(v) \\cap A^{(k)}| \\ge r\\}$.\n    Let $v$ be any vertex in $A^{(k+1)}$.\n    If $v \\in A^{(k)}$, then by the inductive hypothesis, $v \\in A_{async}^*$.\n    If $v \\notin A^{(k)}$, then its activation implies $|N(v) \\cap A^{(k)}| \\ge r$.\n    From the inductive hypothesis, $A^{(k)} \\subseteq A_{async}^*$. Thus, $|N(v) \\cap A_{async}^*| \\ge |N(v) \\cap A^{(k)}| \\ge r$.\n    This means vertex $v$ satisfies the activation condition with respect to the set $A_{async}^*$.\n    Since $A_{async}^*$ is an absorbing set for the asynchronous process, no vertex outside of it can be activated. Formally, for any $u \\notin A_{async}^*$, $|N(u) \\cap A_{async}^*|  r$.\n    As $v$ satisfies the condition $|N(v) \\cap A_{async}^*| \\ge r$, it must be that $v \\in A_{async}^*$.\n    Thus, any vertex $v \\in A^{(k+1)}$ is also in $A_{async}^*$, which means $A^{(k+1)} \\subseteq A_{async}^*$.\n\nBy induction, $A^{(k)} \\subseteq A_{async}^*$ for all $k$. Therefore, their union, $A_{sync}^* = \\bigcup_{k \\ge 0} A^{(k)}$, must also be a subset of $A_{async}^*$.\n\n**Conclusion**\n\nHaving shown both $A_{async}^* \\subseteq A_{sync}^*$ and $A_{sync}^* \\subseteq A_{async}^*$, we conclude that $A_{sync}^* = A_{async}^*$. The final absorbing set is independent of the update scheme (synchronous or asynchronous) for any $r$-bootstrap percolation process on any finite graph.\n\nThis theoretical result implies that for any given initial active set $A_0$, the final size of the absorbing set will be identical for both schemes. Consequently, when $A_0$ is sampled randomly, the resulting probability distributions of final sizes for the two schemes must be identical. The total variation distance between these two empirical distributions should therefore be $0.0$. Any non-zero result from the simulation would be attributable to subtle implementation differences rather than the underlying theory.\n\nThe provided implementation will compute this distance for several test cases. Based on this derivation, the expected output is a list of total variation distances that are all $0.0$.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef create_path_graph(n):\n    \"\"\"Creates an adjacency list for a path graph of n vertices.\"\"\"\n    if n = 0:\n        return {}\n    adj = {i: [] for i in range(n)}\n    for i in range(n - 1):\n        adj[i].append(i + 1)\n        adj[i + 1].append(i)\n    return adj\n\ndef create_star_graph(n):\n    \"\"\"Creates an adjacency list for a star graph of n vertices.\"\"\"\n    if n = 0:\n        return {}\n    adj = {i: [] for i in range(n)}\n    center = 0\n    for i in range(1, n):\n        adj[center].append(i)\n        adj[i].append(center)\n    return adj\n\ndef create_binary_tree(h):\n    \"\"\"Creates an adjacency list for a complete binary tree of height h.\"\"\"\n    n = 2**(h + 1) - 1\n    if n = 0:\n        return {}\n    adj = {i: [] for i in range(n)}\n    # Iterate through all possible parent nodes\n    for i in range((n - 1) // 2 + 1):\n        left_child = 2 * i + 1\n        right_child = 2 * i + 2\n        if left_child  n:\n            adj[i].append(left_child)\n            adj[left_child].append(i)\n        if right_child  n:\n            adj[i].append(right_child)\n            adj[right_child].append(i)\n    return adj\n\ndef simulate_sync(adj, r, initial_active):\n    \"\"\"Simulates r-bootstrap percolation with synchronous updates.\"\"\"\n    n = len(adj)\n    active = initial_active.copy()\n    \n    while True:\n        to_activate = []\n        for i in range(n):\n            if not active[i]:\n                active_neighbors = 0\n                for neighbor in adj[i]:\n                    if active[neighbor]:\n                        active_neighbors += 1\n                if active_neighbors = r:\n                    to_activate.append(i)\n        \n        if not to_activate:\n            break\n        \n        for i in to_activate:\n            active[i] = True\n            \n    return np.sum(active)\n\ndef simulate_async(adj, r, initial_active):\n    \"\"\"Simulates r-bootstrap percolation with asynchronous random sequential updates.\"\"\"\n    n = len(adj)\n    active = initial_active.copy()\n    \n    while True:\n        changed_in_pass = False\n        update_order = np.random.permutation(n)\n        for i in update_order:\n            if not active[i]:\n                active_neighbors = 0\n                for neighbor in adj[i]:\n                    if active[neighbor]:\n                        active_neighbors += 1\n                if active_neighbors = r:\n                    active[i] = True\n                    changed_in_pass = True\n        \n        if not changed_in_pass:\n            break\n            \n    return np.sum(active)\n\ndef solve():\n    \"\"\"\n    Runs the empirical verification for the test suite and prints the results.\n    \"\"\"\n    test_cases = [\n        {'type': 'path', 'params': {'n': 20}, 'r': 1, 'p': 0.1, 'T': 500},\n        {'type': 'star', 'params': {'n': 21}, 'r': 2, 'p': 0.2, 'T': 500},\n        {'type': 'binary_tree', 'params': {'h': 5}, 'r': 2, 'p': 0.05, 'T': 500},\n        {'type': 'path', 'params': {'n': 50}, 'r': 10, 'p': 0.3, 'T': 500},\n        {'type': 'binary_tree', 'params': {'h': 4}, 'r': 1, 'p': 0.0, 'T': 500},\n    ]\n\n    results = []\n    \n    for case in test_cases:\n        T = case['T']\n        p = case['p']\n        r = case['r']\n        \n        if case['type'] == 'path':\n            n = case['params']['n']\n            adj = create_path_graph(n)\n        elif case['type'] == 'star':\n            n = case['params']['n']\n            adj = create_star_graph(n)\n        elif case['type'] == 'binary_tree':\n            h = case['params']['h']\n            n = 2**(h + 1) - 1\n            adj = create_binary_tree(h)\n\n        sync_hist = np.zeros(n + 1, dtype=np.int32)\n        async_hist = np.zeros(n + 1, dtype=np.int32)\n        \n        for _ in range(T):\n            # Generate the same initial active set for both schemes in each trial\n            initial_active = np.random.rand(n)  p\n            \n            # Run synchronous simulation\n            sync_size = simulate_sync(adj, r, initial_active)\n            sync_hist[sync_size] += 1\n            \n            # Run asynchronous simulation\n            async_size = simulate_async(adj, r, initial_active)\n            async_hist[async_size] += 1\n\n        # Calculate empirical probability distributions\n        P_sync = sync_hist / T\n        P_async = async_hist / T\n        \n        # Calculate Total Variation Distance\n        tv_distance = 0.5 * np.sum(np.abs(P_sync - P_async))\n        results.append(tv_distance)\n\n    # Print the final result in the specified format\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "The fate of a system in bootstrap percolation is critically dependent on the initial placement of seeds, and the statistical properties of this initial set are paramount. This hands-on exercise moves beyond simple independent seeding to explore how correlations in the initial state can profoundly impact the probability of global activation. By implementing and comparing an independent seeding model with a negatively correlated one on small graphs, you will gain direct, quantitative insight into how suppressing local seed clusters can inhibit system-wide cascades .",
            "id": "4265123",
            "problem": "You are asked to design and analyze a dependent initial seeding scheme for bootstrap percolation on small graphs. The core reference process is the standard bootstrap percolation dynamics: a node is initially active (seed) or inactive, and then updates occur in discrete time with the rule that a node becomes active if at least a threshold number of its neighbors are active; once a node is active it remains active forever. The goal is to compute, exactly and by enumeration, the probability that the entire graph eventually becomes active under two different initial seeding models: an independent Bernoulli model and a negatively correlated dependent model.\n\nFundamental base definitions to be used:\n- Bootstrap percolation on a graph: for a simple, undirected graph $G=(V,E)$ with $|V|=n$, an initial seed configuration is a vector $\\mathbf{x} \\in \\{0,1\\}^n$. The dynamics proceeds in discrete steps $t = 0,1,2,\\ldots$, with state $\\mathbf{x}^{(t)} \\in \\{0,1\\}^n$. For a fixed threshold $r \\in \\mathbb{N}$, the update rule is: for each node $i \\in V$, if $x^{(t)}_i = 1$, then $x^{(t+1)}_i = 1$; if $x^{(t)}_i = 0$, then $x^{(t+1)}_i = 1$ if and only if the number of neighbors $j$ of $i$ with $x^{(t)}_j = 1$ is at least $r$. This monotone rule converges to a fixed point $\\mathbf{x}^{(\\infty)}$ which is increasing in the initial configuration $\\mathbf{x}^{(0)}$.\n- Independent Bernoulli seeding: each node $i \\in V$ is seeded independently with $\\mathbb{P}(X_i=1)=p$ and $\\mathbb{P}(X_i=0)=1-p$ where $p \\in [0,1]$. This is an independent and identically distributed (i.i.d.) model.\n- Negatively correlated dependent seeding via a matching: let $M$ be a set of disjoint unordered pairs of nodes (a matching) covering some subset of $V$. For each pair $(i,j) \\in M$, draw $(X_i,X_j)$ with joint distribution $\\mathbb{P}(X_i=1,X_j=1)=0$, $\\mathbb{P}(X_i=1,X_j=0)=p$, $\\mathbb{P}(X_i=0,X_j=1)=p$, and $\\mathbb{P}(X_i=0,X_j=0)=1-2p$, where $p \\in [0,\\frac{1}{2}]$. For nodes not in $M$, seed independently with $\\mathbb{P}(X_k=1)=p$. Different pairs in $M$ and unmatched nodes are sampled independently. This scheme exhibits negative correlation within each pair because $\\mathbb{P}(X_i=1,X_j=1)\\mathbb{P}(X_i=1)\\mathbb{P}(X_j=1)$.\n\nYour task is to implement an exact enumeration program that, for each test case specified below, computes two probabilities:\n- The probability that the entire graph becomes active under the negatively correlated dependent seeding scheme described above.\n- The probability that the entire graph becomes active under the independent Bernoulli seeding scheme with the same marginal $p$.\n\nFor each initial configuration $\\mathbf{x} \\in \\{0,1\\}^n$, compute its probability under both seeding schemes, then run the bootstrap percolation dynamics with threshold $r$ until convergence to obtain $\\mathbf{x}^{(\\infty)}$, and check whether $\\sum_{i=1}^n x^{(\\infty)}_i = n$. The required output per test case is the two probabilities (negatively correlated, independent), as decimal floats rounded to $6$ decimal places.\n\nTest suite:\n- Case $1$ (happy path): Graph is a path on $4$ nodes, with edges $\\{(0,1),(1,2),(2,3)\\}$, threshold $r=2$, marginal $p=0.2$, and matching $M=\\{(0,1),(2,3)\\}$.\n- Case $2$ (boundary low threshold): Graph is a cycle on $4$ nodes, with edges $\\{(0,1),(1,2),(2,3),(3,0)\\}$, threshold $r=1$, marginal $p=0.3$, and matching $M=\\{(0,1),(2,3)\\}$.\n- Case $3$ (boundary high threshold): Graph is a cycle on $4$ nodes, with edges $\\{(0,1),(1,2),(2,3),(3,0)\\}$, threshold $r=3$, marginal $p=0.4$, and matching $M=\\{(0,1),(2,3)\\}$. Note that for this case, since the maximum degree is $2$, only initially seeded nodes can be active in the final state.\n- Case $4$ (structural heterogeneity): Graph is a star on $4$ nodes with center $0$ and leaves $\\{1,2,3\\}$, edges $\\{(0,1),(0,2),(0,3)\\}$, threshold $r=2$, marginal $p=0.3$, and matching $M=\\{(1,2)\\}$ (nodes $0$ and $3$ are unmatched and seeded i.i.d. with parameter $p$).\n\nFinal output format:\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, where each element corresponds to a test case and is itself a two-element list of the two probabilities rounded to $6$ decimal places. For example, the output should look like $[[a_1,b_1],[a_2,b_2],[a_3,b_3],[a_4,b_4]]$ where $a_k$ is the negatively correlated probability and $b_k$ is the independent probability for case $k$.\n- No physical units or angles are involved. All numeric answers must be decimal floats.\n\nConstraints and requirements:\n- You must perform exact enumeration over all $2^n$ initial configurations for each test case, compute probability weights under both seeding schemes as specified, and accumulate the probability of complete activation.\n- Use only the specified runtime environment and libraries. Hard-code the test suite within the program; no external input is allowed.",
            "solution": "We start from the fundamental definition of bootstrap percolation. For a graph $G=(V,E)$, an initial seed configuration $\\mathbf{x}^{(0)} \\in \\{0,1\\}^n$ evolves via a monotone update rule with threshold $r$: a node remains active once active, and an inactive node becomes active if at least $r$ of its neighbors are active. The dynamics is monotone and converges to a fixed point $\\mathbf{x}^{(\\infty)}$ that is an increasing function of the initial configuration $\\mathbf{x}^{(0)}$. The event of complete activation is the increasing event $A=\\{\\sum_{i=1}^n x^{(\\infty)}_i = n\\}$.\n\nWe consider two initial seeding models:\n\n1. Independent Bernoulli seeding with parameter $p \\in [0,1]$, where $\\mathbb{P}(X_i=1)=p$ independently for all $i \\in V$. The probability weight of a specific configuration $\\mathbf{x} \\in \\{0,1\\}^n$ under this model is\n$$\nw_{\\text{ind}}(\\mathbf{x}) = \\prod_{i=1}^n p^{x_i} (1-p)^{1-x_i} = p^{\\sum_{i=1}^n x_i} (1-p)^{n-\\sum_{i=1}^n x_i}.\n$$\n\n2. A negatively correlated dependent seeding scheme constructed by a matching $M \\subseteq \\{\\{i,j\\} \\mid i,j \\in V, i \\neq j\\}$ that covers some subset of nodes. For each pair $(i,j) \\in M$, we draw $(X_i,X_j)$ with joint distribution\n$$\n\\mathbb{P}(X_i=1,X_j=1) = 0,\\quad \\mathbb{P}(X_i=1,X_j=0)=p,\\quad \\mathbb{P}(X_i=0,X_j=1)=p,\\quad \\mathbb{P}(X_i=0,X_j=0)=1-2p,\n$$\nwith $p \\in \\left[0,\\frac{1}{2}\\right]$. For nodes not in $M$, we seed independently with $\\mathbb{P}(X_k=1)=p$. Different pairs and unmatched nodes are sampled independently. The probability weight of a configuration $\\mathbf{x}$ under this scheme factorizes across pairs and unmatched nodes:\n$$\nw_{\\text{neg}}(\\mathbf{x}) = \\left( \\prod_{(i,j)\\in M} \\phi_p(x_i,x_j) \\right) \\left( \\prod_{k \\notin \\bigcup M} p^{x_k} (1-p)^{1-x_k} \\right),\n$$\nwhere\n$$\n\\phi_p(u,v) = \\begin{cases}\n0  \\text{if } u=1 \\text{ and } v=1,\\\\\np  \\text{if } (u,v) \\in \\{(1,0),(0,1)\\},\\\\\n1-2p  \\text{if } u=0 \\text{ and } v=0.\n\\end{cases}\n$$\nThe negative correlation property within each pair $(i,j) \\in M$ is immediate: $\\mathbb{P}(X_i=1,X_j=1)=0  p \\cdot p = \\mathbb{P}(X_i=1)\\mathbb{P}(X_j=1)$, and the covariance $\\mathrm{Cov}(X_i,X_j)$ is negative for $p \\in (0,\\frac{1}{2}]$.\n\nPrinciple-based reasoning about how negative correlation affects activation probability relies on monotonicity and the structure of activation pathways. The increasing event of complete activation is favored by the presence of clusters of initial seeds that satisfy local threshold constraints. Negative correlation suppresses simultaneous seeding within matched pairs, thereby reducing the likelihood of local clusters that can immediately activate nodes (for example, two neighbors of a node when $r=2$) and, more generally, reduces the initial availability of multi-seed neighborhoods. This tends to lower the probability of complete activation relative to the independent model with the same marginal $p$.\n\nWe illustrate this effect analytically in boundary cases:\n\n- For a graph of maximum degree at most $2$ and threshold $r=3$, no inactive node can ever become active because no node has $3$ neighbors. Therefore, the final active set equals the initial seed set. The probability of complete activation (all nodes active initially) under the independent Bernoulli model is $p^n$, while under the negatively correlated matching scheme that pairs all nodes, it is $0$ because pairs forbid both endpoints simultaneously active. This demonstrates a strict reduction in activation probability.\n\n- For a connected graph and threshold $r=1$, once there exists any seed in the graph, the entire connected component becomes active iteratively: neighbors of a seed become active at the next step, and the activation percolates through the component because each newly active node provides at least one active neighbor to its neighbors. Hence, the probability of complete activation equals the probability that at least one node is initially seeded. For independent seeding, this is $1-(1-p)^n$. For a matching that covers all nodes, Independence across pairs implies that the probability that no node is seeded is the product over pairs of the probability that the pair is $(0,0)$, equal to $(1-2p)^{n/2}$. Therefore, the probability of complete activation for the negative scheme is $1-(1-2p)^{n/2}$, which is strictly less than $1-(1-p)^n$ for $p \\in (0,\\frac{1}{2}]$ and $n \\ge 2$.\n\nFor intermediate scenarios such as threshold $r=2$ on small graphs, exact analytical expressions can be derived by casework on minimal contagious sets. However, a robust and universally applicable method is exact enumeration over all initial configurations to compute the activation probability. This approach exploits:\n- The monotone update property ensures that the final state can be obtained by iterating until no further activations occur.\n- The seeding distributions provide explicit probability weights for each configuration allowing exact aggregation.\n\nAlgorithmic design:\n1. Represent the graph by its adjacency list, and the threshold by an integer $r$.\n2. Enumerate all $\\mathbf{x} \\in \\{0,1\\}^n$ (there are $2^n$ configurations for $n=4$).\n3. For each $\\mathbf{x}$, compute $w_{\\text{ind}}(\\mathbf{x})$ and $w_{\\text{neg}}(\\mathbf{x})$ using the definitions above.\n4. Simulate the bootstrap dynamics from $\\mathbf{x}$:\n   - Initialize $\\mathbf{x}^{(0)}=\\mathbf{x}$.\n   - Repeat: for each node $i$ with $x^{(t)}_i=0$, set $x^{(t+1)}_i=1$ if $\\sum_{j \\in N(i)} x^{(t)}_j \\ge r$; otherwise keep $x^{(t+1)}_i=x^{(t)}_i$. Continue until $\\mathbf{x}^{(t+1)}=\\mathbf{x}^{(t)}$.\n5. Check whether $\\sum_{i=1}^n x^{(\\infty)}_i = n$ (complete activation). If yes, add the corresponding weight to the activation probability for each seeding model.\n6. Repeat for all configurations and report the probabilities for both models.\n\nWe apply this to four test cases:\n- Case $1$: path graph on $4$ nodes, threshold $r=2$, $p=0.2$, matching covers all nodes.\n- Case $2$: cycle on $4$ nodes, threshold $r=1$, $p=0.3$, matching covers all nodes.\n- Case $3$: cycle on $4$ nodes, threshold $r=3$, $p=0.4$, matching covers all nodes; only initial seeds survive.\n- Case $4$: star on $4$ nodes with center $0$, threshold $r=2$, $p=0.3$, matching on leaves $(1,2)$ only (nodes $0$ and $3$ seeded independently).\n\nThe program performs exact enumeration and outputs a single line with a list of four two-element lists, each containing the negatively correlated probability and the independent probability rounded to $6$ decimal places. This directly quantifies the impact of negative correlations relative to the independent Bernoulli model across different structural and threshold regimes.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef bootstrap_final_state(adj_list, seeds, r):\n    \"\"\"\n    Compute the final active set under bootstrap percolation with threshold r.\n    seeds: list/array of 0/1 initial states\n    \"\"\"\n    n = len(seeds)\n    x = np.array(seeds, dtype=int)\n    changed = True\n    while changed:\n        changed = False\n        x_next = x.copy()\n        for i in range(n):\n            if x[i] == 0:\n                # Count active neighbors\n                active_neighbors = sum(x[j] for j in adj_list[i])\n                if active_neighbors = r:\n                    x_next[i] = 1\n                    changed = True\n        x = x_next\n    return x\n\ndef weight_independent(config, p):\n    \"\"\"Probability weight under independent Bernoulli(p) seeding.\"\"\"\n    ones = sum(config)\n    n = len(config)\n    return (p ** ones) * ((1 - p) ** (n - ones))\n\ndef weight_negative(config, p, pairs, n):\n    \"\"\"\n    Probability weight under the negatively correlated matching scheme.\n    pairs: list of tuples (i,j) indicating paired nodes.\n    Unmatched nodes are seeded i.i.d. Bernoulli(p).\n    \"\"\"\n    paired_nodes = set()\n    for (i, j) in pairs:\n        paired_nodes.add(i)\n        paired_nodes.add(j)\n    w = 1.0\n    # Handle pairs\n    for (i, j) in pairs:\n        ci, cj = config[i], config[j]\n        if ci == 1 and cj == 1:\n            return 0.0  # forbidden\n        elif (ci == 1 and cj == 0) or (ci == 0 and cj == 1):\n            w *= p\n        elif ci == 0 and cj == 0:\n            w *= (1 - 2 * p)\n    # Handle unmatched nodes\n    for k in range(n):\n        if k not in paired_nodes:\n            w *= p if config[k] == 1 else (1 - p)\n    return w\n\ndef enumerate_activation_probability(adj_list, r, p, pairs):\n    \"\"\"\n    Enumerate all configurations and compute probabilities of full activation\n    under negative and independent seeding.\n    \"\"\"\n    n = len(adj_list)\n    total_neg = 0.0\n    total_ind = 0.0\n    # Enumerate all 2^n configurations\n    for mask in range(1  n):\n        config = [(mask  i)  1 for i in range(n)]\n        w_neg = weight_negative(config, p, pairs, n)\n        w_ind = weight_independent(config, p)\n        if w_neg == 0.0 and w_ind == 0.0:\n            continue\n        final_state = bootstrap_final_state(adj_list, config, r)\n        full_active = int(sum(final_state) == n)\n        if full_active:\n            total_neg += w_neg\n            total_ind += w_ind\n    return total_neg, total_ind\n\ndef solve():\n    # Define the test cases from the problem statement.\n    # Each test case: (adj_list, r, p, pairs)\n    # Node indices: 0-based\n    test_cases = [\n        # Case 1: Path on 4 nodes, r=2, p=0.2, pairs cover all nodes\n        (\n            {0: [1], 1: [0, 2], 2: [1, 3], 3: [2]},\n            2,\n            0.2,\n            [(0, 1), (2, 3)]\n        ),\n        # Case 2: Cycle on 4 nodes, r=1, p=0.3, pairs cover all nodes\n        (\n            {0: [1, 3], 1: [0, 2], 2: [1, 3], 3: [2, 0]},\n            1,\n            0.3,\n            [(0, 1), (2, 3)]\n        ),\n        # Case 3: Cycle on 4 nodes, r=3, p=0.4, pairs cover all nodes\n        (\n            {0: [1, 3], 1: [0, 2], 2: [1, 3], 3: [2, 0]},\n            3,\n            0.4,\n            [(0, 1), (2, 3)]\n        ),\n        # Case 4: Star on 4 nodes (center 0), r=2, p=0.3, pairs on leaves (1,2)\n        (\n            {0: [1, 2, 3], 1: [0], 2: [0], 3: [0]},\n            2,\n            0.3,\n            [(1, 2)]\n        ),\n    ]\n\n    results = []\n    for adj_dict, r, p, pairs in test_cases:\n        # Convert dict to adjacency list with stable ordering\n        n = len(adj_dict)\n        adj_list = [sorted(adj_dict[i]) for i in range(n)]\n        neg_prob, ind_prob = enumerate_activation_probability(adj_list, r, p, pairs)\n        # Round to 6 decimal places\n        neg_prob = round(neg_prob + 0.0, 6)\n        ind_prob = round(ind_prob + 0.0, 6)\n        results.append([neg_prob, ind_prob])\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(str(item) for item in results)}]\")\n\nsolve()\n```"
        }
    ]
}