{
    "hands_on_practices": [
        {
            "introduction": "从理想化模型转向更真实的网络，需要强大的启发式方法来识别关键节点。本练习将介绍“集体影响”（Collective Influence, CI）指标，这是一个有坚实理论基础的、用于识别影响力节点的度量。通过在一个样本网络中手动计算每个节点的CI分数，你将具体理解该指标如何捕捉节点在维持网络长程连接性中的作用。",
            "id": "4295214",
            "problem": "考虑一个无向简单图 $G$，其顶点集为 $V=\\{1,2,\\dots,10\\}$，边集为\n$$\nE=\\{(1,2),(1,3),(1,4),(2,5),(2,6),(3,7),(4,8),(4,9),(5,10),(9,10)\\}.\n$$\n令 $k_{i}$ 表示节点 $i$ 的度。在局部类树近似下的最优渗流框架中，最大连通分支消失的临界点可以通过非回溯矩阵 (NB) 的谱性质来分析，而节点移除问题可以转化为有限半径邻域上的影响力最大化目标。从这些基础——稀疏网络上的渗流、作为稳定性判据的非回溯矩阵的最大特征值、以及对有限半径邻域的限制——出发，推导一个半径 $\\ell=2$ 的节点级影响力测度，并为图 $G$ 的每个节点计算该值。\n\n然后，基于集体影响力拆除策略，即按推导出的半径为2的影响力降序移除节点，并通过优先选择标签最小的节点来打破平局，生成前十次选择的完整有序节点标签列表（即，根据所有节点的初始半径为2的影响力进行的排序）。将你最终的有序列表表示为一个行矩阵。无需四舍五入。",
            "solution": "本问题已经过验证。\n\n### 步骤 1：提取已知条件\n-   该图是一个无向简单图 $G$，其顶点集为 $V=\\{1,2,\\dots,10\\}$。\n-   边集为 $E=\\{(1,2),(1,3),(1,4),(2,5),(2,6),(3,7),(4,8),(4,9),(5,10),(9,10)\\}$。\n-   $k_i$ 表示节点 $i$ 的度。\n-   理论背景是稀疏网络上的最优渗流，使用局部类树近似。\n-   最大连通分支的稳定性判据是非回溯矩阵 (NB) 的最大特征值。\n-   分析被限制在有限半径邻域内。\n-   任务是推导一个半径 $\\ell=2$ 的节点级影响力测度。\n-   必须为图 $G$ 的每个节点计算该测度。\n-   需遵循一种集体影响力拆除策略，即按初始半径为2的影响力降序移除节点。\n-   平局打破规则是优先选择标签最小的节点。\n-   最终输出是所有10个节点标签的完整有序列表。\n\n### 步骤 2：使用提取的已知条件进行验证\n-   **科学依据**：该问题基于“集体影响力”(CI) 算法，这是网络科学中一种成熟的方法，用于识别有影响力的传播者或对网络完整性至关重要的节点。最优渗流、非回溯矩阵和类树近似等概念是现代网络理论的基础。该问题具有科学合理性。\n-   **适定性**：图被明确定义。任务是明确的：为所有节点计算一个特定指标 ($CI_2$)，然后根据清晰的规则对它们进行排序。平局打破规则确保了唯一解的存在。\n-   **客观性**：问题以精确、正式的语言陈述，不含主观或基于观点的内容。\n-   **完整性与一致性**：解决问题所需的所有信息（图结构、半径、排序规则、平局打破规则）均已提供。没有矛盾之处。\n-   **可行性**：图很小，使得手动计算度、距离和影响力分数是可行的。\n-   **结构性**：问题结构良好，并导向一个唯一的、可验证的答案。\n\n### 步骤 3：结论与行动\n该问题是有效的，因为它具有科学依据、适定、客观且完整。我现在将继续解答。\n\n该问题要求基于最优渗流的原理推导并应用一个节点级影响力测度。节点 $i$ 的集体影响力 (CI) 是从图的非回溯矩阵最大特征值 $\\lambda_B$ 的微扰分析中推导出来的。在局部类树近似下，巨分支的稳定性由 $\\lambda_B$ 决定，渗流阈值出现在 $\\lambda_B=1$ 处。一个节点的影响力是它对 $\\lambda_B$ 的贡献。移除节点 $i$ 会剪除所有通过它的非回溯路径。CI 分数通过考虑从 $i$ 出发的特定长度 $\\ell$ 的路径来近似这种影响。\n\n半径为 $\\ell$ 时节点 $i$ 的集体影响力 $CI_{\\ell}(i)$ 定义为节点 $i$ 的超额度与所有距离 $i$ 为 $\\ell$ 的节点 $j$ 的超额度之和的乘积。超额度 $k_i-1$ 代表了在类树结构中从节点 $i$ 出发的正向传播路径数。对半径为 $\\ell$ 的球体边界求和，捕捉了影响力前沿的聚合分支潜力。公式为：\n$$\nCI_{\\ell}(i) = (k_i - 1) \\sum_{j \\in \\partial B(i, \\ell)} (k_j - 1)\n$$\n其中 $\\partial B(i, \\ell)$ 是与顶点 $i$ 的最短路径距离恰好为 $\\ell$ 的顶点集合。对于此问题，我们需要使用 $\\ell=2$。\n\n首先，我们计算每个节点 $i \\in V = \\{1, 2, \\dots, 10\\}$ 的度 $k_i$。\n-   $k_1 = |\\{2,3,4\\}| = 3$\n-   $k_2 = |\\{1,5,6\\}| = 3$\n-   $k_3 = |\\{1,7\\}| = 2$\n-   $k_4 = |\\{1,8,9\\}| = 3$\n-   $k_5 = |\\{2,10\\}| = 2$\n-   $k_6 = |\\{2\\}| = 1$\n-   $k_7 = |\\{3\\}| = 1$\n-   $k_8 = |\\{4\\}| = 1$\n-   $k_9 = |\\{4,10\\}| = 2$\n-   $k_{10} = |\\{5,9\\}| = 2$\n\n接下来，我们计算每个节点的超额度 $k_i-1$。\n-   $k_1-1 = 2$\n-   $k_2-1 = 2$\n-   $k_3-1 = 1$\n-   $k_4-1 = 2$\n-   $k_5-1 = 1$\n-   $k_6-1 = 0$\n-   $k_7-1 = 0$\n-   $k_8-1 = 0$\n-   $k_9-1 = 1$\n-   $k_{10}-1 = 1$\n\n现在，对每个节点 $i$，我们找出距离为 2 的节点集 $\\partial B(i, 2)$ 并计算 $CI_2(i)$。\n\n-   **节点 1**：距离为 1 的邻居是 $\\{2, 3, 4\\}$。这些邻居的邻居（不包括已访问过的节点）给出了距离为 2 的节点：$\\partial B(1, 2) = \\{5, 6, 7, 8, 9\\}$。\n    $CI_2(1) = (k_1-1) \\left( (k_5-1)+(k_6-1)+(k_7-1)+(k_8-1)+(k_9-1) \\right) = 2(1+0+0+0+1) = 4$。\n\n-   **节点 2**：距离为 1 的邻居是 $\\{1, 5, 6\\}$。这些邻居的邻居给出了距离为 2 的节点：$\\partial B(2, 2) = \\{3, 4, 10\\}$。\n    $CI_2(2) = (k_2-1) \\left( (k_3-1)+(k_4-1)+(k_{10}-1) \\right) = 2(1+2+1) = 8$。\n\n-   **节点 3**：距离为 1 的邻居是 $\\{1, 7\\}$。这些邻居的邻居给出了距离为 2 的节点：$\\partial B(3, 2) = \\{2, 4\\}$。\n    $CI_2(3) = (k_3-1) \\left( (k_2-1)+(k_4-1) \\right) = 1(2+2) = 4$。\n\n-   **节点 4**：距离为 1 的邻居是 $\\{1, 8, 9\\}$。这些邻居的邻居给出了距离为 2 的节点：$\\partial B(4, 2) = \\{2, 3, 10\\}$。\n    $CI_2(4) = (k_4-1) \\left( (k_2-1)+(k_3-1)+(k_{10}-1) \\right) = 2(2+1+1) = 8$。\n\n-   **节点 5**：距离为 1 的邻居是 $\\{2, 10\\}$。这些邻居的邻居给出了距离为 2 的节点：$\\partial B(5, 2) = \\{1, 6, 9\\}$。\n    $CI_2(5) = (k_5-1) \\left( (k_1-1)+(k_6-1)+(k_9-1) \\right) = 1(2+0+1) = 3$。\n\n-   **节点 6**：$k_6-1=0$，所以 $CI_2(6) = 0$。\n\n-   **节点 7**：$k_7-1=0$，所以 $CI_2(7) = 0$。\n\n-   **节点 8**：$k_8-1=0$，所以 $CI_2(8) = 0$。\n\n-   **节点 9**：距离为 1 的邻居是 $\\{4, 10\\}$。这些邻居的邻居给出了距离为 2 的节点：$\\partial B(9, 2) = \\{1, 8, 5\\}$。\n    $CI_2(9) = (k_9-1) \\left( (k_1-1)+(k_8-1)+(k_5-1) \\right) = 1(2+0+1) = 3$。\n\n-   **节点 10**：距离为 1 的邻居是 $\\{5, 9\\}$。这些邻居的邻居给出了距离为 2 的节点：$\\partial B(10, 2) = \\{2, 4\\}$。\n    $CI_2(10) = (k_{10}-1) \\left( (k_2-1)+(k_4-1) \\right) = 1(2+2) = 4$。\n\n计算出的 $CI_2$ 值为：\n-   $CI_2(1) = 4$\n-   $CI_2(2) = 8$\n-   $CI_2(3) = 4$\n-   $CI_2(4) = 8$\n-   $CI_2(5) = 3$\n-   $CI_2(6) = 0$\n-   $CI_2(7) = 0$\n-   $CI_2(8) = 0$\n-   $CI_2(9) = 3$\n-   $CI_2(10) = 4$\n\n最后，我们生成要移除的节点的有序列表。规则是按其初始 $CI_2$ 值的降序移除节点，并通过优先选择标签最小的节点来打破平局。\n\n1.  最高分是 $CI_2 = 8$：节点 $\\{2, 4\\}$。按标签排序：$2, 4$。\n2.  次高分是 $CI_2 = 4$：节点 $\\{1, 3, 10\\}$。按标签排序：$1, 3, 10$。\n3.  再次是 $CI_2 = 3$：节点 $\\{5, 9\\}$。按标签排序：$5, 9$。\n4.  最低分是 $CI_2 = 0$：节点 $\\{6, 7, 8\\}$。按标签排序：$6, 7, 8$。\n\n合并这些组，完整的拆除顺序是：$2, 4, 1, 3, 10, 5, 9, 6, 7, 8$。",
            "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n2  4  1  3  10  5  9  6  7  8\n\\end{pmatrix}\n}\n$$"
        },
        {
            "introduction": "在掌握了CI指标的计算之后，我们现在可以探索其在完整的网络瓦解算法中的应用。这最后一个练习要求你实现并比较两种基本策略：静态方法和动态自适应方法。通过在不同类型的网络模型上测试这些策略，你将揭示计算效率和瓦解效果之间的权衡，这是在现实世界应用中至关重要的考量。",
            "id": "4295239",
            "problem": "给定一个无向简单图 $G = (V,E)$，其中 $|V| = N$，以及一个目标阈值 $\\theta \\in [0,1]$，该阈值限制了节点移除后残余最大连通分量的可接受大小。目标是比较两种拆解策略：一种是贪婪自适应策略，每次移除节点后重新计算节点得分；另一种是静态排序策略，一次性计算得分并按此固定顺序移除节点。您必须实现这两种策略，当最大连通分量的大小与原始节点数 $N$ 的比率降至最多为 $\\theta$ 时停止，并报告每种策略为达到此目标移除了多少个节点。\n\n从以下基础定义开始。网络上的渗流通过移除节点并检查残余图 $G \\setminus R$ 的连通性特性来建模，其中 $R \\subseteq V$ 是被移除节点的集合。定义在移除集合 $R$ 下的最大连通分量分数为\n$$\ng(R) = \\frac{|C_{\\max}(G \\setminus R)|}{N},\n$$\n其中 $C_{\\max}(\\cdot)$ 表示由 $V \\setminus R$ 诱导的残余图中的最大连通分量。拆解任务是找到一个移除集合 $R$，使得 $g(R) \\le \\theta$，同时最小化 $|R|$。\n\n节点评分函数使用半径为 $l$ 的集体影响（Collective Influence, CI），对于节点 $i \\in V \\setminus R$ 定义为\n$$\n\\mathrm{CI}_l(i) = \\big(k_i - 1\\big) \\sum_{j \\in \\partial \\mathcal{B}(i,l)} \\big(k_j - 1\\big),\n$$\n其中 $k_i$ 是节点 $i$ 在当前残余图中的度，$\\partial \\mathcal{B}(i,l)$ 是以 $i$ 为中心、半径为 $l$ 的球的边界，即在 $G \\setminus R$ 中与 $i$ 的图距离恰好为 $l$ 的节点集合。直观上，$\\mathrm{CI}_l(i)$ 估算了移除节点 $i$ 对削弱长程连通性的乘法效应，捕捉了维持最大连通分量的非回溯路径。\n\n实现并比较以下策略：\n- 贪婪自适应策略：从 $R = \\varnothing$ 开始，当 $g(R) > \\theta$ 时，计算所有 $i \\in V \\setminus R$ 的 $\\mathrm{CI}_l(i)$，选择一个使 $\\mathrm{CI}_l(i)$ 最大化的节点 $i^\\star$，应用平局打破规则，即优先选择较大的 $k_i$，然后是较小的索引 $i$，通过设置 $R \\leftarrow R \\cup \\{i^\\star\\}$ 来移除 $i^\\star$，然后重复。\n- 静态排序策略：在原始图（$R = \\varnothing$）上一次性计算所有节点的 $\\mathrm{CI}_l(i)$，按 $\\mathrm{CI}_l(i)$ 降序对节点排序，使用相同的平局打破规则，并按此固定顺序移除节点，每次移除后更新 $g(R)$，直到 $g(R) \\le \\theta$。\n\n您的程序必须实现这两种策略，并为每个测试用例返回一个整数三元组 $[r_{\\text{static}}, r_{\\text{adaptive}}, r_{\\text{static}} - r_{\\text{adaptive}}]$，其中 $r_{\\text{static}}$ 和 $r_{\\text{adaptive}}$ 分别是静态策略和自适应策略为满足 $g(R) \\le \\theta$ 所需移除的节点数。\n\n在所有情况下，集体影响半径均使用 $l=2$。测试套件中的图和目标是：\n\n- A例（Erdős–Rényi图）：$G$ 是一个 $G(N,p)$ 图，其中 $N=50$，$p=0.08$，随机种子为 $42$。目标 $\\theta = 0.2$。\n- B例（带桥的两个团）：$G$ 是两个大小各为 $20$ 的团的不相交并集，并附加一条边连接第一个团中的节点 $0$ 和第二个团中的节点 $20$。目标 $\\theta = 0.4$。\n- C例（Barabási–Albert优先连接图）：$G$ 有 $N=60$ 个节点，连接参数 $m=2$，随机种子为 $1337$。目标 $\\theta = 0.15$。\n- D例（路径图）：$G$ 是一个包含 $N=30$ 个节点的路径图。目标 $\\theta = 0.5$。\n\n科学真实性和算法约束：\n- 使用无向简单图模型。图中没有权重、自环或平行边。\n- 对于 Erdős–Rényi 和 Barabási–Albert 图，通过使用指定的种子以及在 Barabási–Albert 情况下使用标准的度成正比连接规则来确保可复现性。\n- 当多个节点的 $\\mathrm{CI}_l$ 相等时，为打破平局，选择当前度 $k_i$ 较大的节点；如果仍然相等，则选择索引 $i$ 较小的节点。\n\n最终输出格式：\n您的程序应生成单行输出，其中包含一个由方括号括起来的逗号分隔列表形式的结果，每个元素是对应测试用例的列表 $[r_{\\text{static}}, r_{\\text{adaptive}}, r_{\\text{static}} - r_{\\text{adaptive}}]$，顺序为 A、B、C、D。例如，打印的行应如下所示：\n$$\n\\big[\\,[r_{\\text{static}}^{(A)}, r_{\\text{adaptive}}^{(A)}, r_{\\text{static}}^{(A)} - r_{\\text{adaptive}}^{(A)}],\\,[r_{\\text{static}}^{(B)}, r_{\\text{adaptive}}^{(B)}, r_{\\text{static}}^{(B)} - r_{\\text{adaptive}}^{(B)}],\\,\\ldots\\,\\big].\n$$\n所有报告的量都必须是无物理单位的整数。\n\n测试套件覆盖 rationale：\n- A例探测了高于渗流阈值的典型随机图。\n- B例强调了具有最小社群间桥梁的模块化结构。\n- C例评估了无标度网络特有的异质性。\n- D例检验了一种边界情况，即在中心移除单个节点即可达到目标 $\\theta$。",
            "solution": "用户提供了一个来自网络科学领域的明确定义的计算问题，特别关注通过最优渗流进行网络拆解。该问题要求基于集体影响（CI）指标，比较两种节点移除策略——静态排序方法和贪婪自适应方法。问题陈述完整、科学上合理且算法上明确，包括所有必要的参数、图生成过程和打破平局的规则。因此，该问题是有效的，可以构建解决方案。\n\n解决方案将通过将问题分解为几个逻辑组件来实现：\n1.  图生成：构建四个指定网络拓扑结构的过程。\n2.  核心算法组件：用于计算拆解过程所必需的图属性的函数，例如连通分量和集体影响（CI）分数。\n3.  拆解策略：静态和自适应节点移除过程的实现。\n4.  主执行循环：一个主函数，用于遍历测试用例，运行两种策略并格式化结果。\n\n**1. 图生成**\n\n我们将根据问题规范创建四个不同的图。考虑到图的规模不大（$N \\le 60$），由NumPy数组表示的邻接矩阵是这些图的合适数据结构。\n\n-   **A例 (Erdős–Rényi图)**：生成一个 $G(N,p)$ 模型的实例，其中 $N=50$，$p=0.08$。使用带种子的随机数生成器（`seed=42`）确保可复现性。每对不同节点 $(i, j)$ 之间以概率 $p$ 创建一条边。\n-   **B例 (带桥的两个团)**：该图由两个大小为 $20$ 的完全图（团）组成。我们通过创建一个块对角邻接矩阵来构建它，其中每个块是团的邻接矩阵。然后，在第一个团的节点 $0$ 和第二个团的节点 $20$ 之间添加一条桥接边，总节点数为 $N=40$。\n-   **C例 (Barabási–Albert图)**：使用优先连接模型生成一个无标度网络，其中 $N=60$ 个节点，连接参数 $m=2$。从一个小的初始连通图（$m$ 个节点）开始，逐个添加新节点，每个新节点与现有节点形成 $m$ 条边。连接到现有节点 $i$ 的概率与其当前度 $k_i$ 成正比。使用带种子的随机数生成器（`seed=1337`）确保确定性结果。\n-   **D例 (路径图)**：创建一个包含 $N=30$ 个节点的简单线性链，其中每个节点 $i$ 连接到节点 $i-1$ 和 $i+1$（对于 $i \\in \\{1, \\ldots, N-2\\}$）。\n\n**2. 核心算法组件**\n\n为了实现拆解策略，我们需要几个算法辅助函数。\n\n-   **最大连通分量 (LCC) 大小**：两种策略的停止条件 $g(R) = |C_{\\max}(G \\setminus R)|/N \\le \\theta$ 需要计算残余图中最大连通分量的大小。这可以通过广度优先搜索 (BFS) 或深度优先搜索 (DFS) 高效完成。或者，我们可以使用 `scipy.sparse.csgraph.connected_components` 函数，该函数识别分量并为每个节点分配一个标签。然后可以通过计算每个标签的出现次数来找到分量的大小。这些计数中的最大值即为 $|C_{\\max}|$。\n\n-   **单源最短路径（距离）**：集体影响指标 $\\mathrm{CI}_l(i)$ 依赖于识别与给定节点 $i$ 的图距离恰好为 $l$ 的节点。对于无权图，从节点 $i$ 开始的广度优先搜索 (BFS)是计算到所有其他节点的最短路径距离的标准且最有效的算法。这将作为一个辅助函数来实现。\n\n-   **集体影响 (CI) 计算**：半径为 $l=2$ 的节点 $i$ 的CI分数由下式给出：\n    $$\n    \\mathrm{CI}_2(i) = \\big(k_i - 1\\big) \\sum_{j \\in \\partial \\mathcal{B}(i,2)} \\big(k_j - 1\\big)\n    $$\n    为了在给定（残余）图中为节点 $i$ 计算此值：\n    1.  通过对邻接矩阵的行求和，确定图中所有节点 $v$ 的当前度 $k_v$。\n    2.  从节点 $i$ 开始执行BFS，找到距离恰好为 $l=2$ 的节点集合 $\\partial \\mathcal{B}(i,2)$。\n    3.  计算项 $(k_i - 1)$。\n    4.  计算和 $\\sum_{j \\in \\partial \\mathcal{B}(i,2)} (k_j - 1)$。度为 $1$ 的节点对此和的贡献为 $0$，度为 $0$ 的节点贡献为 $-1$。\n    5.  这两个值的乘积即为 $\\mathrm{CI}_2(i)$。如果 $\\partial \\mathcal{B}(i,2)$ 为空，则和为 $0$，因此 $\\mathrm{CI}_2(i) = 0$。这正确处理了像团中节点的情况，其中没有节点在距离为 $2$ 的位置。\n\n**3. 拆解策略**\n\n有了核心组件后，我们可以实现这两种策略。两者都将在原始图邻接矩阵的副本上操作，并通过将相应的行和列置零来迭代地“移除”节点。\n\n-   **静态排序策略**：\n    1.  在原始完整图上，计算每个节点的初始 $\\mathrm{CI}_2$ 分数和度。\n    2.  创建一个所有节点的排序列表，基于元组 $(\\mathrm{CI}_2, k, -i)$ 进行降序排序。负索引正确处理了最终的平局打破规则（较小索引“更大”）。\n    3.  遍历此固定的排序列表。在每个步骤中，从图中移除下一个节点。\n    4.  每次移除后，计算残余图的LCC大小。\n    5.  当LCC分数降至或低于阈值 $\\theta$ 时停止。移除的节点数即为 $r_{\\text{static}}$。\n\n-   **贪婪自适应策略**：\n    1.  从原始图和空的已移除节点集合开始。\n    2.  开始一个循环，只要LCC分数大于 $\\theta$ 就继续。\n    3.  **循环内部（每一步）**：\n        a. 识别当前活动（尚未移除）的节点集合。\n        b. 对于每个活动节点，根据*当前*残余图的状态重新计算其 $\\mathrm{CI}_2$ 分数和度。\n        c. 选择使分数最大化的节点 $i^\\star$，使用相同的 $(\\mathrm{CI}_2, k, -i)$ 元组进行排序和打破平局。\n        d. 将 $i^\\star$ 添加到已移除节点集合中并更新图。\n    4.  当条件满足时循环终止。移除的节点总数即为 $r_{\\text{adaptive}}$。\n\n**4. 主执行与输出**\n\n主程序将为四个测试用例中的每一个定义参数。然后它将循环遍历它们，对每个用例执行以下操作：\n1.  生成指定的图。\n2.  运行静态策略以找到 $r_{\\text{static}}$。\n3.  运行自适应策略以找到 $r_{\\text{adaptive}}$。\n4.  计算差异 $r_{\\text{static}} - r_{\\text{adaptive}}$。\n5.  存储得到的三元组 $[r_{\\text{static}}, r_{\\text{adaptive}}, r_{\\text{static}} - r_{\\text{adaptive}}]$。\n\n最后，所有用例的结果列表将以指定的格式 `[[...],[...],...]` 打印到标准输出。这种结构化方法确保了正确性、可复现性以及对问题要求的遵守。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.sparse.csgraph import connected_components\nfrom collections import deque\n\ndef generate_graph(case_params):\n    \"\"\"Generates a graph based on the specified case parameters.\"\"\"\n    case, N, params, seed = case_params\n    adj = np.zeros((N, N), dtype=int)\n    rng = np.random.default_rng(seed)\n\n    if case == 'ER':\n        p = params['p']\n        for i in range(N):\n            for j in range(i + 1, N):\n                if rng.random()  p:\n                    adj[i, j] = adj[j, i] = 1\n    \n    elif case == 'two_cliques':\n        size = params['size']\n        # First clique\n        adj[0:size, 0:size] = 1\n        # Second clique\n        adj[size:2*size, size:2*size] = 1\n        np.fill_diagonal(adj, 0)\n        # Bridge\n        adj[0, size] = adj[size, 0] = 1\n\n    elif case == 'BA':\n        m = params['m']\n        # Start with a complete graph of m nodes\n        adj[:m, :m] = 1\n        np.fill_diagonal(adj[:m, :m], 0)\n        \n        degrees = np.sum(adj, axis=1)\n        \n        for i in range(m, N):\n            # Flatten degrees of existing nodes and their indices\n            existing_nodes = np.arange(i)\n            existing_degrees = degrees[:i]\n            \n            # Prevent division by zero if all degrees are zero (unlikely)\n            total_degree = np.sum(existing_degrees)\n            if total_degree == 0:\n                # Connect to m random nodes if no edges exist\n                targets = rng.choice(existing_nodes, size=m, replace=False)\n            else:\n                probs = existing_degrees / total_degree\n                targets = rng.choice(existing_nodes, size=m, replace=False, p=probs)\n            \n            for target in targets:\n                adj[i, target] = adj[target, i] = 1\n            degrees = np.sum(adj, axis=1) # Update degrees for next iteration\n\n    elif case == 'path':\n        for i in range(N - 1):\n            adj[i, i + 1] = adj[i + 1, i] = 1\n\n    return adj\n\ndef get_lcc_size(adj_matrix, active_nodes_mask):\n    \"\"\"Calculates the size of the Largest Connected Component.\"\"\"\n    num_nodes = adj_matrix.shape[0]\n    if not np.any(active_nodes_mask):\n        return 0\n    \n    # Create a subgraph view with only active nodes\n    active_indices = np.where(active_nodes_mask)[0]\n    subgraph_adj = adj_matrix[np.ix_(active_indices, active_indices)]\n    \n    if subgraph_adj.size == 0:\n        return 0\n\n    n_components, labels = connected_components(subgraph_adj, directed=False, return_labels=True)\n    \n    if n_components == 0:\n        return 0\n        \n    component_sizes = np.bincount(labels)\n    return np.max(component_sizes)\n\ndef get_distances(adj_matrix, start_node_idx):\n    \"\"\"Calculates shortest path distances from a start node using BFS.\"\"\"\n    num_nodes = adj_matrix.shape[0]\n    distances = -np.ones(num_nodes, dtype=int)\n    \n    if adj_matrix[start_node_idx].sum() == 0: # Node is isolated\n        distances[start_node_idx] = 0\n        return distances\n\n    q = deque([(start_node_idx, 0)])\n    distances[start_node_idx] = 0\n    \n    while q:\n        curr_node, dist = q.popleft()\n        \n        for neighbor in np.where(adj_matrix[curr_node] == 1)[0]:\n            if distances[neighbor] == -1:\n                distances[neighbor] = dist + 1\n                q.append((neighbor, dist + 1))\n                \n    return distances\n\ndef calculate_ci_l2(adj, degrees, node_idx):\n    \"\"\"Calculates Collective Influence for a single node with l=2.\"\"\"\n    k_i = degrees[node_idx]\n    if k_i = 1:\n        return 0.0\n\n    distances = get_distances(adj, node_idx)\n    ball_boundary = np.where(distances == 2)[0]\n    \n    if ball_boundary.size == 0:\n        return 0.0\n        \n    sum_term = np.sum(degrees[ball_boundary] - 1)\n    ci = (k_i - 1) * sum_term\n    return float(ci)\n\ndef solve_strategy(adj_orig, N, theta, l, is_adaptive):\n    \"\"\"Solves for the number of removals for a given strategy.\"\"\"\n    adj = adj_orig.copy()\n    removed_nodes = set()\n    active_nodes_mask = np.ones(N, dtype=bool)\n    num_removals = 0\n\n    # Initial LCC check\n    lcc_size = get_lcc_size(adj, active_nodes_mask)\n    if lcc_size / N = theta:\n        return 0\n    \n    # Static strategy: pre-compute ranking\n    removal_order = []\n    if not is_adaptive:\n        degrees = np.sum(adj, axis=1)\n        scores = []\n        for i in range(N):\n            ci = calculate_ci_l2(adj, degrees, i)\n            scores.append((ci, degrees[i], -i))\n        # Sort nodes by (CI, degree, -index)\n        sorted_nodes = sorted(range(N), key=lambda i: scores[i], reverse=True)\n        removal_order = deque(sorted_nodes)\n\n    while True:\n        node_to_remove = -1\n        \n        if is_adaptive:\n            # Re-calculate scores for all active nodes in each step\n            active_indices = np.where(active_nodes_mask)[0]\n            degrees = np.sum(adj, axis=1)\n            \n            best_score = (-1, -1, N)\n            \n            for i in active_indices:\n                ci = calculate_ci_l2(adj, degrees, i)\n                score = (ci, degrees[i], -i)\n                if score  best_score:\n                    best_score = score\n                    node_to_remove = i\n        else: # Static strategy\n            node_to_remove = removal_order.popleft()\n\n        # Remove the node\n        adj[node_to_remove, :] = 0\n        adj[:, node_to_remove] = 0\n        removed_nodes.add(node_to_remove)\n        active_nodes_mask[node_to_remove] = False\n        num_removals += 1\n        \n        # Check stopping condition\n        lcc_size = get_lcc_size(adj, active_nodes_mask)\n        if lcc_size == 0 or (lcc_size / N) = theta:\n            return num_removals\n\ndef solve():\n    test_cases = [\n        # (Case Name, N, params, seed), theta\n        (('ER', 50, {'p': 0.08}, 42), 0.2),\n        (('two_cliques', 40, {'size': 20}, None), 0.4),\n        (('BA', 60, {'m': 2}, 1337), 0.15),\n        (('path', 30, {}, None), 0.5),\n    ]\n\n    all_results = []\n    l = 2\n\n    for case_params, theta in test_cases:\n        N = case_params[1]\n        adj_orig = generate_graph(case_params)\n\n        r_static = solve_strategy(adj_orig, N, theta, l, is_adaptive=False)\n        r_adaptive = solve_strategy(adj_orig, N, theta, l, is_adaptive=True)\n        \n        diff = r_static - r_adaptive\n        all_results.append([r_static, r_adaptive, diff])\n\n    # Format the final output string\n    print(str(all_results).replace(\" \", \"\"))\n\nsolve()\n```"
        }
    ]
}