{
    "hands_on_practices": [
        {
            "introduction": "任何网络对齐任务的第一步都是定义一个有意义的目标函数。然而，在稀疏网络中，一个简单地计算匹配的边和非边的天真分数会产生偏差，因为非边匹配的数量远远超过了边匹配。本练习将指导你如何使用概率零模型推导出一种重加权分数，以平衡来自边和非边的贡献，从而实现更有意义的对齐。",
            "id": "4279336",
            "problem": "考虑两个无自环的简单无向图 $G_{1}$ 和 $G_{2}$，它们都定义在大小为 $n$ 的相同顶点集上，其邻接矩阵分别为 $A \\in \\{0,1\\}^{n \\times n}$ 和 $B \\in \\{0,1\\}^{n \\times n}$。假设 $G_{1}$ 是一个边概率为 $p_{1} \\in (0,1)$ 的 Erdős–Rényi (ER) 图的实现，而 $G_{2}$ 是一个独立的、边概率为 $p_{2} \\in (0,1)$ 的 Erdős–Rényi 图的实现。对于任意置换矩阵 $P \\in \\{0,1\\}^{n \\times n}$，定义朴素对齐一致性分数，该分数计算边的匹配和非边的匹配（即匹配的1和匹配的0）的总和，如下所示：\n$$\nS_{\\mathrm{naive}}(P) \\;=\\; \\sum_{1 \\le i  j \\le n} \\Big( \\mathbf{1}\\{A_{ij}=1,\\, B_{P(i)P(j)}=1\\} \\;+\\; \\mathbf{1}\\{A_{ij}=0,\\, B_{P(i)P(j)}=0\\} \\Big).\n$$\n因为在稀疏情况下，$(1-p_{1})(1-p_{2}) \\gg p_{1}p_{2}$，所以最大化 $S_{\\mathrm{naive}}(P)$ 可能会偏向于对齐非边，从而掩盖了由边所承载的结构信号。\n\n为了减轻这种偏差，我们考虑重加权一致性目标\n$$\nS_{w}(P) \\;=\\; \\sum_{1 \\le i  j \\le n} \\Big( w_{1}\\,\\mathbf{1}\\{A_{ij}=1,\\, B_{P(i)P(j)}=1\\} \\;+\\; w_{0}\\,\\mathbf{1}\\{A_{ij}=0,\\, B_{P(i)P(j)}=0\\} \\Big),\n$$\n其中权重 $w_{1}  0$ 且 $w_{0}  0$。在零模型下，其中 $P$ 独立于 $(A,B)$，且 $G_{1},G_{2}$ 是如上所述参数为 $p_{1}$ 和 $p_{2}$ 的独立ER图，请推导权重的精确比率，使得边的匹配和非边的匹配对 $S_{w}(P)$ 的期望总贡献相等，从而在期望层面上消除类别不平衡偏差。\n\n请用一个关于 $p_{1}$ 和 $p_{2}$ 的单一闭式表达式给出 $w_{0}^{\\star}/w_{1}^{\\star}$ 的最终答案。无需四舍五入。答案无需单位。",
            "solution": "该问题已经过验证，被确定为是合理的、适定的和有科学依据的。分析如下。\n\n目标是找到权重比率 $w_{0}/w_{1}$，使得边的匹配和非边的匹配对重加权分数 $S_{w}(P)$ 的期望贡献相等。设边的匹配的总贡献表示为 $C_{1}(P)$，非边的匹配的总贡献表示为 $C_{0}(P)$。它们的定义如下：\n$$\nC_{1}(P) = \\sum_{1 \\le i  j \\le n} w_{1}\\,\\mathbf{1}\\{A_{ij}=1,\\, B_{P(i)P(j)}=1\\}\n$$\n$$\nC_{0}(P) = \\sum_{1 \\le i  j \\le n} w_{0}\\,\\mathbf{1}\\{A_{ij}=0,\\, B_{P(i)P(j)}=0\\}\n$$\n问题要求我们找到特定的权重，记为 $w_{1}^{\\star}$ 和 $w_{0}^{\\star}$，使得在零模型下这两个量的期望相等。因此，条件是：\n$$\n\\mathbb{E}[C_{1}(P)] = \\mathbb{E}[C_{0}(P)]\n$$\n我们现在将分别计算每一项的期望。\n\n首先，我们计算来自边的匹配的期望总贡献 $\\mathbb{E}[C_{1}(P)]$。根据期望的线性性，我们可以将期望算子移到求和符号内：\n$$\n\\mathbb{E}[C_{1}(P)] = \\mathbb{E}\\left[ \\sum_{1 \\le i  j \\le n} w_{1}\\,\\mathbf{1}\\{A_{ij}=1,\\, B_{P(i)P(j)}=1\\} \\right] = w_{1} \\sum_{1 \\le i  j \\le n} \\mathbb{E}\\left[ \\mathbf{1}\\{A_{ij}=1,\\, B_{P(i)P(j)}=1\\} \\right]\n$$\n指示函数的期望是它所指示事件的概率。因此，我们有：\n$$\n\\mathbb{E}\\left[ \\mathbf{1}\\{A_{ij}=1,\\, B_{P(i)P(j)}=1\\} \\right] = \\mathbb{P}\\left(A_{ij}=1 \\text{ and } B_{P(i)P(j)}=1\\right)\n$$\n在指定的零模型下，图 $G_{1}$（邻接矩阵为 $A$）和图 $G_{2}$（邻接矩阵为 $B$）是 Erdős–Rényi 图的独立实现，并且置换 $P$ 独立于 $A$ 和 $B$。这种独立性允许我们将联合概率分解：\n$$\n\\mathbb{P}\\left(A_{ij}=1 \\text{ and } B_{P(i)P(j)}=1\\right) = \\mathbb{P}(A_{ij}=1) \\times \\mathbb{P}(B_{P(i)P(j)}=1)\n$$\n对于一个边概率为 $p_{1}$ 的 Erdős–Rényi 图，任意两个不同顶点 $i$ 和 $j$ 之间存在边的概率是 $\\mathbb{P}(A_{ij}=1) = p_{1}$。\n类似地，对于一个边概率为 $p_{2}$ 的 Erdős–Rényi 图，任意两个不同顶点 $u$ 和 $v$ 之间存在边的概率是 $\\mathbb{P}(B_{uv}=1) = p_{2}$。由于 $P$ 是一个置换矩阵且 $i \\neq j$，映射后的顶点 $P(i)$ 和 $P(j)$ 也是不同的。因此，$\\mathbb{P}(B_{P(i)P(j)}=1) = p_{2}$。\n将这些概率代回，我们得到：\n$$\n\\mathbb{P}\\left(A_{ij}=1 \\text{ and } B_{P(i)P(j)}=1\\right) = p_{1} p_{2}\n$$\n求和遍及所有满足 $1 \\le i  j \\le n$ 的不同顶点对 $(i, j)$。此类顶点对的总数为 $\\binom{n}{2}$。因此，来自边的匹配的期望总贡献是：\n$$\n\\mathbb{E}[C_{1}(P)] = w_{1} \\sum_{1 \\le i  j \\le n} p_{1}p_{2} = w_{1} \\binom{n}{2} p_{1}p_{2}\n$$\n\n接下来，我们以类似的方式计算来自非边的匹配的期望总贡献 $\\mathbb{E}[C_{0}(P)]$。\n$$\n\\mathbb{E}[C_{0}(P)] = \\mathbb{E}\\left[ \\sum_{1 \\le i  j \\le n} w_{0}\\,\\mathbf{1}\\{A_{ij}=0,\\, B_{P(i)P(j)}=0\\} \\right] = w_{0} \\sum_{1 \\le i  j \\le n} \\mathbb{E}\\left[ \\mathbf{1}\\{A_{ij}=0,\\, B_{P(i)P(j)}=0\\} \\right]\n$$\n这需要计算概率 $\\mathbb{P}\\left(A_{ij}=0 \\text{ and } B_{P(i)P(j)}=0\\right)$。同样，由于独立性：\n$$\n\\mathbb{P}\\left(A_{ij}=0 \\text{ and } B_{P(i)P(j)}=0\\right) = \\mathbb{P}(A_{ij}=0) \\times \\mathbb{P}(B_{P(i)P(j)}=0)\n$$\n在 ER 图中，一条非边的概率是 $\\mathbb{P}(A_{ij}=0) = 1 - \\mathbb{P}(A_{ij}=1) = 1 - p_{1}$。\n类似地，$\\mathbb{P}(B_{P(i)P(j)}=0) = 1 - \\mathbb{P}(B_{P(i)P(j)}=1) = 1 - p_{2}$。\n因此，一次非边匹配的概率是：\n$$\n\\mathbb{P}\\left(A_{ij}=0 \\text{ and } B_{P(i)P(j)}=0\\right) = (1 - p_{1})(1 - p_{2})\n$$\n来自非边的匹配的期望总贡献是所有 $\\binom{n}{2}$ 对的总和：\n$$\n\\mathbb{E}[C_{0}(P)] = w_{0} \\sum_{1 \\le i  j \\le n} (1 - p_{1})(1 - p_{2}) = w_{0} \\binom{n}{2} (1 - p_{1})(1 - p_{2})\n$$\n\n最后，我们使用权重 $w_{1}^{\\star}$ 和 $w_{0}^{\\star}$ 来强制执行期望贡献相等的条件：\n$$\nw_{1}^{\\star} \\binom{n}{2} p_{1}p_{2} = w_{0}^{\\star} \\binom{n}{2} (1 - p_{1})(1 - p_{2})\n$$\n假设顶点数 $n \\ge 2$，则项 $\\binom{n}{2} = \\frac{n(n-1)}{2}$ 非零，可以从等式两边消去：\n$$\nw_{1}^{\\star} p_{1}p_{2} = w_{0}^{\\star} (1 - p_{1})(1 - p_{2})\n$$\n问题要求的是比率 $w_{0}^{\\star}/w_{1}^{\\star}$。我们可以通过重新整理各项来求解这个比率。由于 $p_{1}, p_{2} \\in (0,1)$，量 $p_{1}p_{2}$ 和 $(1-p_{1})(1-p_{2})$ 均非零，并且已知 $w_{1}^{\\star}$ 为正，因此除法是良定义的。\n$$\n\\frac{w_{0}^{\\star}}{w_{1}^{\\star}} = \\frac{p_{1}p_{2}}{(1 - p_{1})(1 - p_{2})}\n$$\n此表达式给出了在零模型下平衡边的匹配和非边的匹配的期望贡献的精确权重比，从而消除了指定的偏差。",
            "answer": "$$\n\\boxed{\\frac{p_{1}p_{2}}{(1 - p_{1})(1 - p_{2})}}\n$$"
        },
        {
            "introduction": "在定义了目标函数之后，我们可以将网络对齐形式化为一个称为二次分配问题（$QAP$）的优化问题。本练习通过比较真实的最优解（在小规模实例上通过暴力搜索找到）与一个计算上更容易的连续松弛问题的解，来探索 $QAP$ 的根本困难。这个过程揭示了“整数性差距”，这是解释为什么精确图匹配如此困难的一个关键概念。",
            "id": "4279389",
            "problem": "设 $A \\in \\mathbb{R}^{3 \\times 3}$ 和 $B \\in \\mathbb{R}^{3 \\times 3}$ 由下式给出\n$$\nA \\;=\\; \\begin{pmatrix}\n0  1  0 \\\\\n1  0  1 \\\\\n0  1  0\n\\end{pmatrix}, \n\\qquad\nB \\;=\\; \\begin{pmatrix}\n2  0  0 \\\\\n0  -1  0 \\\\\n0  0  0\n\\end{pmatrix}.\n$$\n考虑二次分配问题 (QAP)，该问题对于给定的矩阵对 $A$ 和 $B$，旨在寻找一个置换矩阵 $P \\in \\mathbb{R}^{3 \\times 3}$ 来最大化目标函数\n$$\nf(P) \\;=\\; \\operatorname{trace}\\!\\big(A\\,P\\,B\\,P^{\\top}\\big).\n$$\n置换矩阵是其中的元素属于 $\\{0,1\\}$，每行每列恰好有一个 $1$，且满足 $P^{\\top} P = I$ 的矩阵。目标函数可以等价地写成弗罗贝尼乌斯内积 $f(P) = \\langle P^{\\top} A P,\\, B \\rangle_{\\!F} = \\sum_{i,j=1}^{3} (P^{\\top} A P)_{ij} B_{ij}$。\n\n任务：\n- 仅使用上述定义和基本的线性代数性质，计算所有 $6$ 个置换矩阵 $P$ 的 $f(P)$ 值，并确定一个最优的 $P$ 以及相应的最优整数（置换）值 $V_{\\mathrm{int}}$。\n- 考虑 QAP 的正交松弛，其中 $P$ 被一个满足 $X^{\\top} X = I$ 的正交矩阵 $X \\in \\mathbb{R}^{3 \\times 3}$ 替代，目标函数变为\n$$\nf(X) \\;=\\; \\operatorname{trace}\\!\\big(A\\,X\\,B\\,X^{\\top}\\big).\n$$\n- 从实对称矩阵的谱定理和成熟的迹不等式出发，以闭合形式推导出最优松弛值 $V_{\\mathrm{rel}} = \\max_{X^{\\top} X = I} \\operatorname{trace}(A X B X^{\\top})$。\n- 将整数性差距定义为 $\\Delta \\;=\\; V_{\\mathrm{rel}} - V_{\\mathrm{int}}$，并以简化的解析表达式给出其精确值。\n\n你的最终答案必须是 $\\Delta$ 的单个闭合形式表达式。不要四舍五入；不需要单位。请用简化的精确表达式作答。",
            "solution": "我们首先回顾核心定义和事实：\n- 置换矩阵 $P$ 满足 $P^{\\top} P = I$，并且每行每列有一个 $1$。\n- 二次分配问题 (QAP) 的目标函数可以写为 $f(P) = \\operatorname{trace}(A P B P^{\\top}) = \\langle P^{\\top} A P, B \\rangle_{\\!F}$，其中 $\\langle M, N \\rangle_{\\!F} = \\operatorname{trace}(M^{\\top} N)$ 是弗罗贝尼乌斯内积。\n- 对于正交松弛，我们考虑 $X \\in \\mathbb{R}^{3 \\times 3}$ 且满足 $X^{\\top} X = I$，并最大化 $f(X) = \\operatorname{trace}(A X B X^{\\top})$。\n- 对于对称实矩阵，根据谱定理，有 $A = U \\Lambda_A U^{\\top}$ 和 $B = V \\Lambda_B V^{\\top}$，其中 $U, V$ 是正交矩阵，$\\Lambda_A, \\Lambda_B$ 是由特征值组成的对角矩阵。一个成熟的结果（冯·诺依曼迹不等式在对称矩阵上的特例，结合重排原理）表明\n$$\n\\max_{X^{\\top} X = I} \\operatorname{trace}(A X B X^{\\top})\n\\;=\\;\n\\sum_{i=1}^{3} \\lambda_i^{\\downarrow}(A)\\,\\lambda_i^{\\downarrow}(B),\n$$\n其中 $\\lambda_i^{\\downarrow}(\\cdot)$ 表示按非递增顺序排序的特征值，最大值是通过对齐与相似排序的特征值相关联的特征向量来达到的。\n\n步骤 $1$：计算所有置换矩阵 $P$ 的 $f(P)$ 值，并求出 $V_{\\mathrm{int}}$。\n- 给定的矩阵 $B$ 是对角矩阵：$B = \\operatorname{diag}(2, -1, 0)$。对于任何置换矩阵 $P$，共轭矩阵 $P B P^{\\top}$ 也是对角矩阵，其对角线元素是 $(2, -1, 0)$ 的一个排列。\n- QAP 目标函数可以表示为内积：\n$$\nf(P) \\;=\\; \\langle P^{\\top} A P,\\, B \\rangle_{\\!F}.\n$$\n- 因为 $B$ 是对角矩阵，对于任何矩阵 $M$，有 $\\langle M, B \\rangle_{\\!F} = \\sum_{i=1}^{3} M_{ii} B_{ii}$。因此，\n$$\nf(P) \\;=\\; \\sum_{i=1}^{3} \\big(P^{\\top} A P\\big)_{ii} \\, \\big(P B P^{\\top}\\big)_{ii}.\n$$\n- 矩阵 $P^{\\top} A P$ 是 $A$ 的一个置换相似变换，因此其对角线元素的多重集与 $A$ 相同，只是索引被置换了。由于 $A$ 的对角线元素全为零，即 $A_{11} = A_{22} = A_{33} = 0$，因此对于所有 $i$ 也都有 $\\big(P^{\\top} A P\\big)_{ii} = 0$。因此，\n$$\nf(P) \\;=\\; \\sum_{i=1}^{3} 0 \\cdot \\big(P B P^{\\top}\\big)_{ii} \\;=\\; 0\n$$\n对于每个置换矩阵 $P$。\n- 因此，所有 $6$ 个置换都得到相同的目标值 $f(P) = 0$，任何置换矩阵都是最优的。最优整数（置换）值为\n$$\nV_{\\mathrm{int}} \\;=\\; 0.\n$$\n\n步骤 $2$：求解正交松弛问题并计算 $V_{\\mathrm{rel}}$。\n- 我们将松弛后的目标函数写为\n$$\nf(X) \\;=\\; \\operatorname{trace}\\!\\big(A X B X^{\\top}\\big),\n\\quad \\text{其中 } X^{\\top} X = I.\n$$\n- 由于 $A$ 和 $B$ 是对称矩阵，我们对它们进行对角化。$B$ 的特征值是其对角线元素，所以\n$$\n\\lambda(B) \\;=\\; \\big(2,\\, -1,\\, 0\\big).\n$$\n- 接下来，我们求 $A$ 的特征值。$A$ 的特征多项式由下式计算\n$$\n\\det(\\lambda I - A)\n\\;=\\;\n\\begin{vmatrix}\n\\lambda  -1  0 \\\\\n-1  \\lambda  -1 \\\\\n0  -1  \\lambda\n\\end{vmatrix}\n\\;=\\;\n\\lambda \\begin{vmatrix}\n\\lambda  -1 \\\\\n-1  \\lambda\n\\end{vmatrix}\n\\;-\\; (-1) \\begin{vmatrix}\n-1  0 \\\\\n-1  \\lambda\n\\end{vmatrix}\n\\;=\\;\n\\lambda(\\lambda^{2}-1) \\;-\\; \\big((1)\\cdot \\lambda - 0\\big)\n\\;=\\;\n\\lambda^{3} - \\lambda - \\lambda\n\\;=\\;\n\\lambda^{3} - 2\\lambda.\n$$\n- 方程的根满足 $\\lambda(\\lambda^{2} - 2) = 0$，因此\n$$\n\\lambda(A) \\;=\\; \\big(\\sqrt{2},\\, 0,\\, -\\sqrt{2}\\big).\n$$\n- 根据谱定理和适用于对称矩阵的冯·诺依曼迹不等式，最优松弛值是通过对齐特征向量，使得相似排序的特征值配对来获得的。将两个谱按非递增顺序排序，我们得到\n$$\n\\lambda^{\\downarrow}(A) \\;=\\; \\big(\\sqrt{2},\\, 0,\\, -\\sqrt{2}\\big), \n\\qquad\n\\lambda^{\\downarrow}(B) \\;=\\; \\big(2,\\, 0,\\, -1\\big).\n$$\n- 因此，\n$$\nV_{\\mathrm{rel}}\n\\;=\\;\n\\sum_{i=1}^{3} \\lambda_i^{\\downarrow}(A)\\,\\lambda_i^{\\downarrow}(B)\n\\;=\\;\n\\sqrt{2}\\cdot 2 \\;+\\; 0\\cdot 0 \\;+\\; (-\\sqrt{2})\\cdot (-1)\n\\;=\\;\n2\\sqrt{2} \\;+\\; \\sqrt{2}\n\\;=\\;\n3\\sqrt{2}.\n$$\n\n步骤 $3$：计算整数性差距 $\\Delta$。\n- 根据定义，\n$$\n\\Delta \\;=\\; V_{\\mathrm{rel}} - V_{\\mathrm{int}}\n\\;=\\;\n3\\sqrt{2} - 0\n\\;=\\;\n3\\sqrt{2}.\n$$\n\n因此，正交松弛值严格超过了最优置换值，这说明了在此实例上存在一个非零的整数性差距，其精确值为 $3\\sqrt{2}$。",
            "answer": "$$\\boxed{3\\sqrt{2}}$$"
        },
        {
            "introduction": "鉴于精确求解的难度，实际的网络对齐依赖于强大的启发式算法。本练习将引导你完成一个先进的谱匹配流程，演示如何使用图拉普拉斯算子将节点嵌入到几何空间中，然后使用正交普氏分析对齐生成的点云，最后利用匈牙利算法提取离散的节点到节点映射。这为你提供了一个关于广泛使用方法的完整、亲身实践的视角。",
            "id": "4279408",
            "problem": "考虑两个具有 $n=3$ 个顶点的简单无向图 $X$ 和 $Y$，其邻接矩阵为\n$$\nA_X=\\begin{pmatrix}\n0  1  0 \\\\\n1  0  1 \\\\\n0  1  0\n\\end{pmatrix},\\quad\nA_Y=\\begin{pmatrix}\n0  0  1 \\\\\n0  0  1 \\\\\n1  1  0\n\\end{pmatrix}.\n$$\n令 $D_X$ 和 $D_Y$ 为相应的度矩阵，并令 $L_X=D_X-A_X$ 和 $L_Y=D_Y-A_Y$ 为组合拉普拉斯算子。按如下方式定义维度为 $k=2$ 的拉普拉斯特征图嵌入：对每个图，计算其拉普拉斯算子与两个最小非零特征值相关的标准正交特征向量，将它们按列排成一个 $n\\times k$ 的矩阵，并将此矩阵用作节点嵌入 $U\\in\\mathbb{R}^{n\\times k}$，其中第 $i$ 行给出节点 $i$ 的 $k$ 维坐标。将图 $X$ 和图 $Y$ 的这些嵌入分别记为 $U_X$ 和 $U_Y$。\n\n使用这些嵌入，解决正交 Procrustes 问题：找到正交矩阵 $R^\\star\\in\\mathbb{R}^{k\\times k}$，在满足约束 $R^\\top R=I$ 的条件下，最小化 Frobenius 范数目标 $\\|U_X R-U_Y\\|_F$。然后，通过 $C_{ij}=\\|(U_X R^\\star)_{i,:}-(U_Y)_{j,:}\\|_2^2$ 定义指派成本矩阵 $C\\in\\mathbb{R}^{n\\times n}$，并使用匈牙利算法（也称为 Kuhn–Munkres 算法）计算在 $\\{1,2,3\\}$ 的所有排列 $\\pi$ 上的最小总指派成本，即 $\\min_{\\pi}\\sum_{i=1}^{n} C_{i,\\pi(i)}$。\n\n报告此最小总指派成本的精确值作为最终答案。无需四舍五入，不涉及单位。",
            "solution": "用户希望我解决一个图匹配问题。\n\n问题要求基于两个图 $X$ 和 $Y$ 的拉普拉斯特征图嵌入，计算它们之间的最小总指派成本。解决方案需要一个涉及线性代数和优化的多步骤过程。\n\n首先，我们验证问题陈述。该问题定义明确，在网络科学和数值线性代数方面有科学依据，并提供了所有必要信息。图、矩阵和分步过程都已明确指定。使用拉普拉斯特征图、正交 Procrustes 问题和匈牙利算法等标准方法使得该问题可解且可验证。特征向量符号的潜在模糊性通过 Procrustes 分析得以解决，该分析可以找到最优的旋转/反射，而不管点云的初始方向如何。该问题被认为是有效的。\n\n以下是分步解决方案：\n\n### 步骤 1：计算图拉普拉斯算子\n对于一个邻接矩阵为 $A$、度矩阵为 $D$ 的无向图，其组合拉普拉斯算子为 $L = D - A$。\n\n对于图 $X$：\n邻接矩阵为 $A_X = \\begin{pmatrix} 0  1  0 \\\\ 1  0  1 \\\\ 0  1  0 \\end{pmatrix}$。\n顶点的度分别为 $d_1 = 1$、$d_2 = 2$ 和 $d_3 = 1$。度矩阵为 $D_X = \\begin{pmatrix} 1  0  0 \\\\ 0  2  0 \\\\ 0  0  1 \\end{pmatrix}$。\n图 $X$ 的拉普拉斯算子为：\n$$L_X = D_X - A_X = \\begin{pmatrix} 1  0  0 \\\\ 0  2  0 \\\\ 0  0  1 \\end{pmatrix} - \\begin{pmatrix} 0  1  0 \\\\ 1  0  1 \\\\ 0  1  0 \\end{pmatrix} = \\begin{pmatrix} 1  -1  0 \\\\ -1  2  -1 \\\\ 0  -1  1 \\end{pmatrix}$$\n\n对于图 $Y$：\n邻接矩阵为 $A_Y = \\begin{pmatrix} 0  0  1 \\\\ 0  0  1 \\\\ 1  1  0 \\end{pmatrix}$。\n顶点的度分别为 $d_1 = 1$、$d_2 = 1$ 和 $d_3 = 2$。度矩阵为 $D_Y = \\begin{pmatrix} 1  0  0 \\\\ 0  1  0 \\\\ 0  0  2 \\end{pmatrix}$。\n图 $Y$ 的拉普拉斯算子为：\n$$L_Y = D_Y - A_Y = \\begin{pmatrix} 1  0  0 \\\\ 0  1  0 \\\\ 0  0  2 \\end{pmatrix} - \\begin{pmatrix} 0  0  1 \\\\ 0  0  1 \\\\ 1  1  0 \\end{pmatrix} = \\begin{pmatrix} 1  0  -1 \\\\ 0  1  -1 \\\\ -1  -1  2 \\end{pmatrix}$$\n\n### 步骤 2：求拉普拉斯算子的特征值和特征向量\n我们需要与两个最小非零特征值相关的特征向量。\n\n对于 $L_X$：\n特征方程为 $\\det(L_X - \\lambda I) = 0$，解得 $\\lambda(1-\\lambda)(\\lambda-3) = 0$。特征值为 $\\lambda_1 = 0$，$\\lambda_2 = 1$，$\\lambda_3 = 3$。两个最小的非零特征值是 1 和 3。\n\n- 对于 $\\lambda=1$：特征向量 $v$ 满足 $(L_X - I)v = 0$。这给出 $v_2=0$ 和 $v_1=-v_3$。一个标准正交特征向量是 $u_X^{(1)} = \\frac{1}{\\sqrt{2}}\\begin{pmatrix} 1 \\\\ 0 \\\\ -1 \\end{pmatrix}$。\n- 对于 $\\lambda=3$：特征向量 $v$ 满足 $(L_X - 3I)v = 0$。这给出 $v_2=-2v_1$ 和 $v_1=v_3$。一个标准正交特征向量是 $u_X^{(2)} = \\frac{1}{\\sqrt{6}}\\begin{pmatrix} 1 \\\\ -2 \\\\ 1 \\end{pmatrix}$。\n\n对于 $L_Y$：\n特征方程为 $\\det(L_Y - \\lambda I) = 0$，解得 $\\lambda(1-\\lambda)(\\lambda-3) = 0$。特征值相同：$\\lambda_1 = 0$，$\\lambda_2 = 1$，$\\lambda_3 = 3$。两个最小的非零特征值是 1 和 3。\n\n- 对于 $\\lambda=1$：特征向量 $v$ 满足 $(L_Y - I)v = 0$。这给出 $v_3=0$ 和 $v_1=-v_2$。一个标准正交特征向量是 $u_Y^{(1)} = \\frac{1}{\\sqrt{2}}\\begin{pmatrix} 1 \\\\ -1 \\\\ 0 \\end{pmatrix}$。\n- 对于 $\\lambda=3$：特征向量 $v$ 满足 $(L_Y - 3I)v = 0$。这给出 $v_3=-2v_1$ 和 $v_1=v_2$。一个标准正交特征向量是 $u_Y^{(2)} = \\frac{1}{\\sqrt{6}}\\begin{pmatrix} 1 \\\\ 1 \\\\ -2 \\end{pmatrix}$。\n\n### 步骤 3：构建嵌入矩阵\n嵌入矩阵 $U_X$ 和 $U_Y$ 是通过将标准正交特征向量按其对应特征值排序后作为列来构建的。维度为 $n=3, k=2$。\n\n$$ U_X = \\begin{pmatrix} u_X^{(1)}  u_X^{(2)} \\end{pmatrix} = \\begin{pmatrix} \\frac{1}{\\sqrt{2}}  \\frac{1}{\\sqrt{6}} \\\\ 0  -\\frac{2}{\\sqrt{6}} \\\\ -\\frac{1}{\\sqrt{2}}  \\frac{1}{\\sqrt{6}} \\end{pmatrix} $$\n$$ U_Y = \\begin{pmatrix} u_Y^{(1)}  u_Y^{(2)} \\end{pmatrix} = \\begin{pmatrix} \\frac{1}{\\sqrt{2}}  \\frac{1}{\\sqrt{6}} \\\\ -\\frac{1}{\\sqrt{2}}  \\frac{1}{\\sqrt{6}} \\\\ 0  -\\frac{2}{\\sqrt{6}} \\end{pmatrix} $$\n\n### 步骤 4：解决正交 Procrustes 问题\n我们需要找到一个正交矩阵 $R^\\star \\in \\mathbb{R}^{2\\times 2}$ 来最小化 $\\|U_X R - U_Y\\|_F$。解可以通过矩阵 $M = U_X^\\top U_Y$ 的奇异值分解 (SVD) 得到。如果 $M = U_S \\Sigma V_S^\\top$ 是 $M$ 的 SVD，那么 $R^\\star = U_S V_S^\\top$。\n\n$$ M = U_X^\\top U_Y = \\begin{pmatrix} \\frac{1}{\\sqrt{2}}  0  -\\frac{1}{\\sqrt{2}} \\\\ \\frac{1}{\\sqrt{6}}  -\\frac{2}{\\sqrt{6}}  \\frac{1}{\\sqrt{6}} \\end{pmatrix} \\begin{pmatrix} \\frac{1}{\\sqrt{2}}  \\frac{1}{\\sqrt{6}} \\\\ -\\frac{1}{\\sqrt{2}}  \\frac{1}{\\sqrt{6}} \\\\ 0  -\\frac{2}{\\sqrt{6}} \\end{pmatrix} $$\n$$ M = \\begin{pmatrix} \\frac{1}{2}  \\frac{1}{\\sqrt{12}} + \\frac{2}{\\sqrt{12}} \\\\ \\frac{1}{\\sqrt{12}} + \\frac{2}{\\sqrt{12}}  \\frac{1}{6} - \\frac{2}{6} - \\frac{2}{6} \\end{pmatrix} = \\begin{pmatrix} \\frac{1}{2}  \\frac{3}{\\sqrt{12}} \\\\ \\frac{3}{\\sqrt{12}}  -\\frac{3}{6} \\end{pmatrix} = \\begin{pmatrix} \\frac{1}{2}  \\frac{\\sqrt{3}}{2} \\\\ \\frac{\\sqrt{3}}{2}  -\\frac{1}{2} \\end{pmatrix} $$\n为了求 $M$ 的 SVD，我们注意到 $M$ 是对称的。并且，$M^\\top M = M^2 = I$，所以 $M$ 是正交的。\n对于一个正交矩阵 $M$，我们可以将其 SVD 写为 $M = M I I^\\top$。这给出了 SVD 的各部分 $U_S = M$，$\\Sigma = I$ 和 $V_S = I$。\n最优正交矩阵是 $R^\\star = U_S V_S^\\top = M I^\\top = M$。\n$$ R^\\star = \\begin{pmatrix} \\frac{1}{2}  \\frac{\\sqrt{3}}{2} \\\\ \\frac{\\sqrt{3}}{2}  -\\frac{1}{2} \\end{pmatrix} $$\n\n### 步骤 5：计算指派成本矩阵\n成本矩阵 $C \\in \\mathbb{R}^{3\\times 3}$ 由 $C_{ij} = \\|(U_X R^\\star)_{i,:} - (U_Y)_{j,:}\\|_2^2$ 给出。\n首先，我们计算对齐后的嵌入 $U_X' = U_X R^\\star$。\n$$ U_X' = \\begin{pmatrix} \\frac{1}{\\sqrt{2}}  \\frac{1}{\\sqrt{6}} \\\\ 0  -\\frac{2}{\\sqrt{6}} \\\\ -\\frac{1}{\\sqrt{2}}  \\frac{1}{\\sqrt{6}} \\end{pmatrix} \\begin{pmatrix} \\frac{1}{2}  \\frac{\\sqrt{3}}{2} \\\\ \\frac{\\sqrt{3}}{2}  -\\frac{1}{2} \\end{pmatrix} $$\n$U_X'$ 的第一行是：\n$(\\frac{1}{\\sqrt{2}}\\frac{1}{2} + \\frac{1}{\\sqrt{6}}\\frac{\\sqrt{3}}{2}, \\frac{1}{\\sqrt{2}}\\frac{\\sqrt{3}}{2} - \\frac{1}{\\sqrt{6}}\\frac{1}{2}) = (\\frac{1}{2\\sqrt{2}} + \\frac{1}{2\\sqrt{2}}, \\frac{\\sqrt{3}}{2\\sqrt{2}} - \\frac{1}{2\\sqrt{6}}) = (\\frac{1}{\\sqrt{2}}, \\frac{3-1}{2\\sqrt{6}}) = (\\frac{1}{\\sqrt{2}}, \\frac{1}{\\sqrt{6}})$。这是 $U_Y$ 的第一行。\n$U_X'$ 的第二行是：\n$(0 - \\frac{2}{\\sqrt{6}}\\frac{\\sqrt{3}}{2}, 0 + \\frac{2}{\\sqrt{6}}\\frac{1}{2}) = (-\\frac{\\sqrt{3}}{\\sqrt{6}}, \\frac{1}{\\sqrt{6}}) = (-\\frac{1}{\\sqrt{2}}, \\frac{1}{\\sqrt{6}})$。这是 $U_Y$ 的第二行。\n$U_X'$ 的第三行是：\n(-\\frac{1}{\\sqrt{2}}\\frac{1}{2} + \\frac{1}{\\sqrt{6}}\\frac{\\sqrt{3}}{2}, -\\frac{1}{\\sqrt{2}}\\frac{\\sqrt{3}}{2} - \\frac{1}{\\sqrt{6}}\\frac{1}{2}) = (0, -\\frac{\\sqrt{3}}{2\\sqrt{2}} - \\frac{1}{2\\sqrt{6}}) = (0, \\frac{-3-1}{2\\sqrt{6}}) = (0, -\\frac{2}{\\sqrt{6}})$。这是 $U_Y$ 的第三行。\n因此，我们发现 $U_X R^\\star = U_Y$。对齐是完美的，这意味着 $\\|U_X R - U_Y\\|_F$ 的最小值为 $0$。\n\n现在我们构建成本矩阵 $C$：\n$$ C_{ij} = \\|(U_Y)_{i,:} - (U_Y)_{j,:}\\|_2^2 $$\n这是图 $Y$ 的嵌入点之间的欧几里得距离平方矩阵。令 $p_j = (U_Y)_{j,:}$。\n$p_1 = (\\frac{1}{\\sqrt{2}}, \\frac{1}{\\sqrt{6}})$, $p_2 = (-\\frac{1}{\\sqrt{2}}, \\frac{1}{\\sqrt{6}})$, $p_3 = (0, -\\frac{2}{\\sqrt{6}})$。\n$C_{11}=C_{22}=C_{33}=0$。\n$C_{12} = \\|p_1-p_2\\|^2 = \\|(\\frac{2}{\\sqrt{2}}, 0)\\|^2 = (\\sqrt{2})^2 = 2$。\n$C_{13} = \\|p_1-p_3\\|^2 = \\|(\\frac{1}{\\sqrt{2}}, \\frac{3}{\\sqrt{6}})\\|^2 = (\\frac{1}{\\sqrt{2}})^2 + (\\frac{3}{\\sqrt{6}})^2 = \\frac{1}{2} + \\frac{9}{6} = \\frac{1}{2} + \\frac{3}{2} = 2$。\n$C_{23} = \\|p_2-p_3\\|^2 = \\|(-\\frac{1}{\\sqrt{2}}, \\frac{3}{\\sqrt{6}})\\|^2 = (-\\frac{1}{\\sqrt{2}})^2 + (\\frac{3}{\\sqrt{6}})^2 = \\frac{1}{2} + \\frac{9}{6} = 2$。\n由于 $C$ 是对称的，所以 $C_{ji}=C_{ij}$。\n$$ C = \\begin{pmatrix} 0  2  2 \\\\ 2  0  2 \\\\ 2  2  0 \\end{pmatrix} $$\n\n### 步骤 6：计算最小总指派成本\n我们必须找到 $\\min_{\\pi} \\sum_{i=1}^{3} C_{i,\\pi(i)}$，其中 $\\pi$ 是 $\\{1,2,3\\}$ 的一个排列。这是一个线性指派问题。对于一个 $3 \\times 3$ 矩阵，我们可以快速检查解。问题要求应用匈牙利算法。\n\n1.  **行和列归约**：从每行减去该行的最小元素，然后从每列减去该列的最小元素。由于每行和每列的最小值都是 $0$，矩阵 $C$ 保持不变。\n2.  **覆盖零元素**：我们需要找到覆盖矩阵中所有零元素的最少划线数（行或列）。零元素位于 $(1,1)$, $(2,2)$ 和 $(3,3)$。这些零元素无法用少于 3 条线覆盖。\n3.  **最优指派**：由于最少划线数为 3，等于 $n$，因此在当前的零元素中存在一个最优指派。唯一一个从每行和每列选择一个零元素的指派是 $(1,1), (2,2), (3,3)$。这对应于单位排列 $\\pi(i)=i$。\n\n最小总成本是来自原始成本矩阵 $C$ 的此指派的成本之和：\n$$ \\text{Cost} = C_{1,1} + C_{2,2} + C_{3,3} = 0 + 0 + 0 = 0 $$\n最小总指派成本为 $0$。",
            "answer": "$$\\boxed{0}$$"
        }
    ]
}