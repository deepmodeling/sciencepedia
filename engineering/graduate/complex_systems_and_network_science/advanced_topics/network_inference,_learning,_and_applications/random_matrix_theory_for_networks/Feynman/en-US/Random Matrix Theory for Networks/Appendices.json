{
    "hands_on_practices": [
        {
            "introduction": "To detect meaningful patterns in a network, we first need a baseline understanding of what a purely random network's spectrum looks like. This foundational exercise guides you through the moment method, a cornerstone technique in random matrix theory, to derive the spectral distribution of a large, dense random graph. By completing this practice , you will derive the celebrated Wigner semicircle law, which describes the universal \"bulk\" spectrum of random matrices and serves as the null model for network analysis.",
            "id": "4299557",
            "problem": "Consider the undirected Erdős–Rényi random graph $G(n,p)$ in the dense regime, where $p \\in (0,1)$ is a fixed constant independent of $n$, and edges are present independently. Let $A \\in \\mathbb{R}^{n \\times n}$ denote its adjacency matrix, with $A_{ij} = A_{ji} \\in \\{0,1\\}$ for $i \\neq j$ and $A_{ii} = 0$ for all $i$. Define the centered adjacency matrix $\\tilde{A} \\in \\mathbb{R}^{n \\times n}$ by $\\tilde{A}_{ij} = A_{ij} - p$ for $i \\neq j$ and $\\tilde{A}_{ii} = 0$, and consider the normalized matrix\n$$\nX_n = \\frac{\\tilde{A}}{\\sqrt{n p(1-p)}}.\n$$\nThe upper-triangular entries of $X_n$ are independent, have mean $0$, and have variance $1/n$. Let $\\mu_{X_n}$ denote the Empirical Spectral Distribution (ESD), defined by $\\mu_{X_n} = \\frac{1}{n} \\sum_{k=1}^{n} \\delta_{\\lambda_k(X_n)}$, where $\\lambda_k(X_n)$ are the eigenvalues of $X_n$. Starting from fundamental definitions and the trace-moment method, and using only general facts about independence, zero mean, finite variance, and boundedness of matrix entries, derive the limiting distribution of $\\mu_{X_n}$ as $n \\to \\infty$. In particular:\n- Show that for every fixed integer $k \\geq 1$, the sequence of moments $m_k^{(n)} = \\int x^k \\,\\mathrm{d}\\mu_{X_n}(x) = \\frac{1}{n} \\operatorname{Tr}(X_n^k)$ converges to a deterministic limit $m_k$.\n- Identify these limiting moments $\\{m_k\\}_{k \\geq 1}$ by enumerating the leading combinatorial contributions of closed walks in the trace expansion and explain why only pairwise edge-matchings (noncrossing pairings) contribute in the limit.\n- Conclude the limiting ESD and give its explicit probability density function $\\rho(x)$ as a single analytic expression in $x$.\n\nProvide your final answer as a single closed-form expression for the limiting density $\\rho(x)$, written in terms of $x$. No numerical approximation is required. Express the final density without units and do not include any extraneous text in the final answer.",
            "solution": "The problem asks for the limiting Empirical Spectral Distribution (ESD) of the normalized centered adjacency matrix $X_n$ of an Erdős–Rényi random graph $G(n,p)$. We will use the method of moments. The $k$-th moment of the ESD $\\mu_{X_n}$ is given by $m_k^{(n)} = \\frac{1}{n} \\operatorname{Tr}(X_n^k)$. We will demonstrate that for each fixed integer $k \\ge 1$, the sequence $m_k^{(n)}$ converges to a limit $m_k$ as $n \\to \\infty$, and then identify the distribution corresponding to this sequence of limiting moments.\n\nThe $k$-th moment can be written as an expansion of the trace:\n$$\nm_k^{(n)} = \\frac{1}{n} \\operatorname{Tr}(X_n^k) = \\frac{1}{n} \\sum_{i_1, i_2, \\dots, i_k=1}^n (X_n)_{i_1 i_2} (X_n)_{i_2 i_3} \\cdots (X_n)_{i_k i_1}\n$$\nSubstituting the definition $X_n = \\frac{\\tilde{A}}{\\sqrt{n p(1-p)}}$, where $\\tilde{A}_{ij} = A_{ij} - p$ for $i \\neq j$ and $\\tilde{A}_{ii}=0$:\n$$\nm_k^{(n)} = \\frac{1}{n (np(1-p))^{k/2}} \\sum_{i_1, \\dots, i_k=1}^n \\tilde{A}_{i_1 i_2} \\tilde{A}_{i_2 i_3} \\cdots \\tilde{A}_{i_k i_1}\n$$\nThe summation represents a sum over all closed walks of length $k$, $W = (i_1 \\to i_2 \\to \\dots \\to i_k \\to i_1)$, on the complete graph with $n$ vertices. To find the limiting value of $m_k^{(n)}$, we first compute its expectation, $\\mathbb{E}[m_k^{(n)}]$.\n$$\n\\mathbb{E}[m_k^{(n)}] = \\frac{1}{n^{1+k/2} (p(1-p))^{k/2}} \\sum_{i_1, \\dots, i_k=1}^n \\mathbb{E}[\\tilde{A}_{i_1 i_2} \\tilde{A}_{i_2 i_3} \\cdots \\tilde{A}_{i_k i_1}]\n$$\nThe entries $\\tilde{A}_{ij}$ for $ij$ are independent random variables with mean $\\mathbb{E}[\\tilde{A}_{ij}] = \\mathbb{E}[A_{ij}-p] = p-p=0$. The variance is $\\mathbb{E}[\\tilde{A}_{ij}^2] = \\text{Var}(A_{ij}) = p(1-p)$. The product of $\\tilde{A}$ values corresponds to the sequence of edges $\\{i_1, i_2\\}, \\{i_2, i_3\\}, \\dots, \\{i_k, i_1\\}$ in the walk $W$. Let $e_j = \\{i_j, i_{j+1}\\}$ (with $i_{k+1}=i_1$). Because of the independence of distinct entries and the zero-mean property, the expectation of the product is non-zero only if each distinct edge in the walk appears at least twice. If an edge appears exactly once, its corresponding variable $\\tilde{A}_{uv}$ is independent of the others in the product, causing the entire expectation to be zero.\n\nLet's analyze the leading-order contributions to the sum in the large $n$ limit. A walk $W$ is defined by its sequence of $k$ vertices. Let $v$ be the number of distinct vertices and $e$ be the number of distinct edges in the walk. The number of ways to choose $v$ distinct vertices from $n$ is $\\binom{n}{v} = O(n^v)$. For a fixed set of vertices and a fixed walk pattern, the contribution to the sum scales as $n^v$.\nThe total contribution from a class of walks with $v$ vertices scales as $n^v / (n^{1+k/2}) = n^{v-1-k/2}$. For a contribution to survive in the limit $n \\to \\infty$, we must have $v-1-k/2 \\ge 0$.\n\nFor a connected graph formed by the walk, the number of vertices $v$ and edges $e$ are related by $v \\le e+1$. As argued, for a non-zero expectation, each of the $e$ edges must be traversed at least twice. This implies the total length of the walk is $k \\ge 2e$. Combining these inequalities, we get:\n$$\nv \\le e+1 \\le \\frac{k}{2} + 1\n$$\nThis gives an upper bound on the scaling exponent:\n$$\nv-1-\\frac{k}{2} \\le \\left(\\frac{k}{2} + 1\\right) - 1 - \\frac{k}{2} = 0\n$$\nThe leading-order contributions, those that do not vanish as $n \\to \\infty$, must come from walk structures that saturate this bound, i.e., where $v = k/2+1$. This requires $e=k/2$, which implies that $k$ must be an even integer, say $k=2h$ for some integer $h \\ge 1$. For such walks, each of the $h$ distinct edges is traversed exactly twice. The graph structure of such a walk, having $v=h+1$ vertices and $e=h$ edges, must be a tree.\n\nIf $k$ is odd, it is impossible for every edge to be traversed an even number of times. So there must be at least one edge traversed an odd number of times (at least $3$ times) for the expectation to be possibly non-zero. Let $k=2h+1$. Then $e \\le h$. The number of vertices is bounded by $v \\le e+1 \\le h+1$. The scaling exponent is $v-1-k/2 \\le (h+1)-1-(h+1/2) = -1/2$. Thus, for any odd $k$, every term in the sum for $\\mathbb{E}[m_k^{(n)}]$ is of order $O(n^{-1/2})$ or smaller, and so $\\lim_{n \\to \\infty} \\mathbb{E}[m_k^{(n)}] = 0$. By also showing that $\\text{Var}(m_k^{(n)}) \\to 0$, one concludes that $m_k = 0$ for all odd $k$.\n\nNow, let's consider even $k=2h$. The leading contributions come from closed walks of length $2h$ that traverse $h$ distinct edges twice, on a graph of $h+1$ vertices (a tree). For such a walk, the expectation term is $\\mathbb{E}[\\prod_{j=1}^{h} \\tilde{A}_{e_j}^2] = \\prod_{j=1}^{h} \\mathbb{E}[\\tilde{A}_{e_j}^2] = (p(1-p))^h$.\nThe expectation of the moment is:\n$$\n\\mathbb{E}[m_{2h}^{(n)}] = \\frac{1}{n^{1+h} (p(1-p))^h} \\sum_{\\text{walks with } v=h+1, e=h} (p(1-p))^h = \\frac{1}{n^{1+h}} \\times (\\text{number of such walks})\n$$\nThe combinatorial task is to count these walks. Counting these walks is equivalent to counting non-crossing pairings of $2h$ points on a circle. A walk path $i_1 \\to i_2 \\to \\dots \\to i_{2h} \\to i_1$ corresponds to a pairing of the time steps $j$ and $l$ if the edge $\\{i_j, i_{j+1}\\}$ is the same as $\\{i_l, i_{l+1}\\}$. \"Non-crossing\" pairings correspond to walks that do not revisit a vertex until an entire branch of the underlying tree-like structure has been traversed and backtracked. These are precisely the walks that maximize the number of distinct vertices to $v=h+1$. \"Crossing\" pairings force additional vertex identifications, reducing $v$ and leading to contributions of order $O(n^{-1})$ or smaller.\nFor example, for $k=4$ ($h=2$), the walk $i_1 \\to i_2 \\to i_1 \\to i_3 \\to i_1$ corresponds to a non-crossing pairing, has $v=3=h+1$ vertices, and contributes to the leading order. The walk $i_1 \\to i_2 \\to i_1 \\to i_2 \\to i_1$ corresponds to a crossing pairing, has only $v=2  h+1$ vertices, and its contribution vanishes in the limit.\n\nThe number of non-crossing pairings of $2h$ elements is given by the $h$-th Catalan number, $C_h = \\frac{1}{h+1}\\binom{2h}{h}$. For each such pairing scheme, we need to count the number of ways to assign vertex indices from $\\{1, \\dots, n\\}$. A walk corresponding to a non-crossing pairing has $h+1$ free vertex choices. The number of such labeled walks is $C_h \\cdot n(n-1)\\dots(n-h) \\approx C_h n^{h+1}$.\nTherefore, the total count of dominating walks is asymptotically $C_h n^{h+1}$.\nPlugging this into the expression for the expected moment:\n$$\n\\lim_{n \\to \\infty} \\mathbb{E}[m_{2h}^{(n)}] = \\lim_{n \\to \\infty} \\frac{1}{n^{h+1}} (C_h n^{h+1}) = C_h\n$$\nA more detailed analysis shows that the variance of $m_k^{(n)}$ vanishes as $n \\to \\infty$, which implies that $m_k^{(n)}$ converges in probability to its expected value. Thus, the limiting moments are:\n$$\nm_k = \\lim_{n \\to \\infty} m_k^{(n)} = \\begin{cases} C_{k/2}  \\text{if } k \\text{ is even} \\\\ 0  \\text{if } k \\text{ is odd} \\end{cases}\n$$\nwhere $C_h = \\frac{1}{h+1}\\binom{2h}{h}$ are the Catalan numbers.\n\nThe final step is to identify the probability distribution from this moment sequence. A distribution that is symmetric about $0$ has all odd moments equal to zero. The sequence of even moments $m_{2h} = C_h$ is characteristic of the standard Wigner semicircle distribution. This distribution is supported on the interval $[-2, 2]$ and has the probability density function $\\rho(x)$:\n$$\n\\rho(x) = \\frac{1}{2\\pi} \\sqrt{4-x^2}, \\quad \\text{for } x \\in [-2, 2]\n$$\nand $\\rho(x)=0$ otherwise. Let's verify this. A distribution with density $\\frac{1}{2\\pi\\sigma^2}\\sqrt{4\\sigma^2-x^2}$ has even moments $m_{2h} = \\sigma^{2h} C_h$. Our limiting moments $m_{2h} = C_h$ correspond to the case where the variance parameter $\\sigma^2$ is $1$. The normalization of our matrix $X_n$ was indeed chosen to match this convention, as the entries of $\\sqrt{n} X_n$ have variance $p(1-p)/p(1-p)=1$. The radius of the semicircle is $R = 2\\sigma = 2$.\nThus, the limiting ESD is the Wigner semicircle law with radius $2$. The explicit probability density function is given by the expression for $\\rho(x)$ above.",
            "answer": "$$\n\\boxed{\\frac{\\sqrt{4-x^2}}{2\\pi}}\n$$"
        },
        {
            "introduction": "Once the spectral bulk of a random network is understood, the next question is how to detect signals corresponding to non-random structure, such as communities or core-periphery patterns. This practice introduces the concept of outlier eigenvalues, which are signatures of such structures, and tackles the fundamental question of detectability. Following the steps in this problem , you will derive the critical threshold for the famous Baik–Ben Arous–Péché (BBP) phase transition, revealing the precise signal strength needed for an outlier to emerge from the random bulk.",
            "id": "4299560",
            "problem": "Consider a sequence of undirected networks with $n$ nodes, modeled as sparse Erdős–Rényi graphs with independent edges. Let $A^{(n)}$ be the adjacency matrix with off-diagonal entries $A^{(n)}_{ij} \\in \\{0,1\\}$ for $i \\neq j$, where $\\mathbb{P}(A^{(n)}_{ij} = 1) = p_{n}$ and $p_{n} = c/n$ for a fixed $c  0$. Define the centered and standardized adjacency-like matrix $X^{(n)}$ by\n$$\nX^{(n)}_{ij} = \\begin{cases}\n\\dfrac{A^{(n)}_{ij} - p_{n}}{\\sqrt{n p_{n} (1 - p_{n})}}  \\text{if } i \\neq j, \\\\\n0  \\text{if } i = j,\n\\end{cases}\n$$\nand consider a rank-one heterogeneity (signal) added to this bulk,\n$$\nS^{(n)} = X^{(n)} + \\theta\\, v v^{\\top},\n$$\nwhere $v \\in \\mathbb{R}^{n}$ is a deterministic unit vector ($\\|v\\|_{2} = 1$) independent of $X^{(n)}$, and $\\theta \\in \\mathbb{R}$ is a signal strength parameter. In the large-$n$ limit, $X^{(n)}$ is a Wigner-type matrix with variance of off-diagonal entries equal to $1/n$, and its empirical spectral distribution converges to the semicircle law supported on $[-2,2]$.\n\nUsing first principles of random matrix theory for networks, derive the outlier-eigenvalue condition associated with the Baik–Ben Arous–Péché (BBP) phase transition for $S^{(n)}$, expressed in terms of the bulk Stieltjes transform $m(z)$ of the limiting spectral distribution of $X^{(n)}$. Then, for adjacency-like scaling as defined above (i.e., the centered and standardized matrix yielding the semicircle law of variance $1$), solve the resulting self-consistency equation for a putative outlier on the right of the bulk support and identify the critical value of $\\theta$ at which an outlier first emerges from the right edge of the bulk.\n\nYour derivation must begin from the definition of the Stieltjes transform, the resolvent of a matrix, and the Sherman–Morrison formula for rank-one updates, and proceed to the limiting isotropic approximation $\\langle v, (\\cdot) v \\rangle \\to m(z)$. Explicitly use the Stieltjes transform $m(z)$ of the semicircle law at real arguments $z  2$. Report the critical signal strength as a single exact number. No rounding is required. The final answer must be a single real number.",
            "solution": "The problem asks for the critical signal strength $\\theta$ for the emergence of an outlier eigenvalue in a specific random matrix model. The derivation proceeds in three main stages: first, establishing the general equation for outlier eigenvalues in a rank-one perturbed matrix model; second, specializing this equation to the given matrix ensemble whose limiting spectral distribution is the semicircle law; and third, solving for the critical parameter value.\n\nLet $S^{(n)} = X^{(n)} + \\theta v v^{\\top}$ be the matrix in question, where $X^{(n)}$ is the random \"bulk\" matrix and $\\theta v v^{\\top}$ is the rank-one \"signal\" or perturbation. We are interested in the eigenvalues of $S^{(n)}$ in the large-$n$ limit. Outlier eigenvalues are those that lie outside the support of the limiting spectral distribution of the bulk matrix $X^{(n)}$.\n\nThe location of eigenvalues can be determined from the poles of the Stieltjes transform of the empirical spectral distribution. The Stieltjes transform for a matrix $M$ of size $n \\times n$ is defined as\n$$\nm_{M}(z) = \\frac{1}{n} \\text{Tr}\\left((M - zI_n)^{-1}\\right)\n$$\nwhere $z \\in \\mathbb{C} \\setminus \\text{spectrum}(M)$ and $I_n$ is the $n \\times n$ identity matrix. The matrix $(M-zI_n)^{-1}$ is known as the resolvent of $M$ at $z$.\n\nLet $R_X(z) = (X^{(n)} - zI_n)^{-1}$ be the resolvent of the bulk matrix $X^{(n)}$. The resolvent of the perturbed matrix $S^{(n)}$ can be found using the Sherman–Morrison formula for the inverse of a rank-one update. For an invertible matrix $A$ and vectors $u, w$, the formula states $(A+uw^{\\top})^{-1} = A^{-1} - \\frac{A^{-1}uw^{\\top}A^{-1}}{1+w^{\\top}A^{-1}u}$.\nApplying this to $(S^{(n)} - zI_n)^{-1}$ with $A = X^{(n)} - zI_n$, $u = \\theta v$, and $w = v$:\n$$\n(S^{(n)} - zI_n)^{-1} = (X^{(n)} - zI_n + \\theta v v^{\\top})^{-1} = R_X(z) - \\frac{R_X(z) (\\theta v) v^{\\top} R_X(z)}{1 + v^{\\top} R_X(z) (\\theta v)} = R_X(z) - \\frac{\\theta R_X(z) v v^{\\top} R_X(z)}{1 + \\theta v^{\\top} R_X(z) v}\n$$\nThe Stieltjes transform of $S^{(n)}$, denoted $m_S(z)$, is obtained by taking the normalized trace:\n$$\nm_S(z) = \\frac{1}{n} \\text{Tr}\\left( (S^{(n)} - zI_n)^{-1} \\right) = \\frac{1}{n}\\text{Tr}(R_X(z)) - \\frac{1}{n} \\text{Tr}\\left( \\frac{\\theta R_X(z) v v^{\\top} R_X(z)}{1 + \\theta v^{\\top} R_X(z) v} \\right)\n$$\nThe first term is the Stieltjes transform of $X^{(n)}$, $m_X(z)$. For the second term, the denominator is a scalar and can be factored out of the trace. Using the cyclic property of the trace, $\\text{Tr}(AB) = \\text{Tr}(BA)$, we can simplify the trace in the numerator: $\\text{Tr}(R_X(z) v v^{\\top} R_X(z)) = \\text{Tr}(v^{\\top} R_X(z)^2 v) = v^{\\top} R_X(z)^2 v$, as the trace of a scalar is the scalar itself. So,\n$$\nm_S(z) = m_X(z) - \\frac{\\theta}{n} \\frac{v^{\\top} R_X(z)^2 v}{1 + \\theta v^{\\top} R_X(z) v}\n$$\nAn outlier eigenvalue $\\lambda$ of $S^{(n)}$ is an isolated real-valued pole of $m_S(z)$. Such a pole can only arise from the denominator of the second term vanishing. Thus, the location $\\lambda$ of a putative outlier must satisfy the equation:\n$$\n1 + \\theta \\, v^{\\top} R_X(\\lambda) v = 0 \\quad \\implies \\quad v^{\\top} (X^{(n)} - \\lambda I_n)^{-1} v = -\\frac{1}{\\theta}\n$$\nThis is the fundamental equation for the outlier eigenvalues. In the limit of large $n$, the quadratic form $v^{\\top} R_X(z) v$ concentrates around its expectation. For a deterministic, delocalized unit vector $v$, this quantity converges to the limiting Stieltjes transform of the bulk matrix. The problem statement provides this as the \"isotropic approximation\" $\\langle v, (\\cdot) v \\rangle \\to m(z)$, which means $v^{\\top} R_X(z) v \\to m(z)$ where $m(z) = \\lim_{n \\to \\infty} m_X(z)$.\nThus, the limiting equation for an outlier eigenvalue $\\lambda$ is:\n$$\n1 + \\theta m(\\lambda) = 0 \\quad \\text{or} \\quad m(\\lambda) = -\\frac{1}{\\theta}\n$$\nThis is the general outlier-eigenvalue condition for this class of models, expressed in terms of the bulk Stieltjes transform.\n\nNext, we apply this to the specific problem. The matrix $X^{(n)}$ is defined such that its empirical spectral distribution converges to the Wigner semicircle law. The variance of the off-diagonal entries is specified as $1/n$. For a Wigner matrix with entry variance $\\sigma^2/n$, the limiting spectrum is supported on $[-2\\sigma, 2\\sigma]$. Here, $\\sigma^2=1$, so the support is $[-2, 2]$, as stated in the problem. The Stieltjes transform of the Wigner semicircle law supported on $[-2, 2]$ is given by:\n$$\nm(z) = \\frac{-z + \\sqrt{z^2 - 4}}{2}\n$$\nfor $z \\in \\mathbb{C} \\setminus [-2, 2]$. We are looking for an outlier emerging from the right edge of the bulk, so we consider real $z > 2$.\nSubstituting this into the outlier equation $m(\\lambda) = -1/\\theta$:\n$$\n\\frac{-\\lambda + \\sqrt{\\lambda^2 - 4}}{2} = -\\frac{1}{\\theta}\n$$\nWe solve for the outlier location $\\lambda > 2$ in terms of the signal strength $\\theta$. We assume $\\theta0$, which is necessary for an outlier to appear on the right side of the spectrum (since for $\\lambda2$, $m(\\lambda)0$).\n$$\n-\\lambda + \\sqrt{\\lambda^2 - 4} = -\\frac{2}{\\theta}\n$$\n$$\n\\sqrt{\\lambda^2 - 4} = \\lambda - \\frac{2}{\\theta}\n$$\nFor a real solution to exist, the right-hand side must be non-negative, $\\lambda \\ge 2/\\theta$. Squaring both sides:\n$$\n\\lambda^2 - 4 = \\left(\\lambda - \\frac{2}{\\theta}\\right)^2 = \\lambda^2 - \\frac{4\\lambda}{\\theta} + \\frac{4}{\\theta^2}\n$$\n$$\n-4 = -\\frac{4\\lambda}{\\theta} + \\frac{4}{\\theta^2}\n$$\nMultiplying by $-\\theta/4$:\n$$\n\\theta = \\lambda - \\frac{1}{\\theta}\n$$\nSolving for $\\lambda$, we find the location of the outlier eigenvalue:\n$$\n\\lambda = \\theta + \\frac{1}{\\theta}\n$$\nThe BBP phase transition occurs at the critical value of $\\theta$ where an outlier eigenvalue first emerges from the continuous spectrum of the bulk. For an outlier to exist on the right, its location $\\lambda$ must be strictly greater than the right edge of the bulk spectrum, which is at $2$. So, we need to find the condition on $\\theta$ such that $\\lambda  2$.\n$$\n\\theta + \\frac{1}{\\theta}  2\n$$\nFor $\\theta  0$, we can multiply by $\\theta$ without changing the inequality direction:\n$$\n\\theta^2 + 1  2\\theta \\quad \\implies \\quad \\theta^2 - 2\\theta + 1  0 \\quad \\implies \\quad (\\theta - 1)^2  0\n$$\nThis inequality holds for all positive $\\theta$ except for $\\theta=1$. Therefore, an outlier exists on the right of the bulk if and only if $\\theta  1$. The critical value, $\\theta_c$, is the threshold at which this transition occurs. This corresponds to the case of equality, $(\\theta_c - 1)^2 = 0$, which yields $\\theta_c = 1$. At this critical value, the outlier is located at $\\lambda = 1 + 1/1 = 2$, precisely at the edge of the bulk spectrum. For any $\\theta  1$, the outlier $\\lambda = \\theta+1/\\theta$ is strictly greater than $2$.\n\nThe critical value of the signal strength $\\theta$ at which an outlier first emerges from the right edge of the bulk is $1$.",
            "answer": "$$\n\\boxed{1}\n$$"
        },
        {
            "introduction": "Moving from abstract principles to concrete network features, this exercise demonstrates how the theory of outlier eigenvalues can be used to identify and quantify a hub. By modeling a network as a random background plus a perturbation representing a single, highly connected node, you will apply the powerful resolvent formalism. This practice  provides a hands-on opportunity to calculate the exact location of the outlier eigenvalue induced by the hub and its separation from the bulk, making the theoretical framework tangible.",
            "id": "4299575",
            "problem": "Consider a synthetic undirected network on $n$ nodes represented by a symmetric weighted adjacency matrix $A_{n} \\in \\mathbb{R}^{n \\times n}$. Decompose $A_{n}$ as $A_{n} = W_{n} + S_{n}$, where $W_{n}$ models background connectivity fluctuations and $S_{n}$ models a single hub.\n\nThe background matrix $W_{n}$ is a real symmetric random matrix with $(W_{n})_{ij} = (W_{n})_{ji}$ for $i \\neq j$ independent and identically distributed with $\\mathbb{E}[(W_{n})_{ij}] = 0$ and $\\mathrm{Var}[(W_{n})_{ij}] = \\sigma^{2}/n$, and $(W_{n})_{ii} = 0$ for all $i$. The hub matrix $S_{n}$ encodes a star centered at node $1$ with uniform edge weight $s_{n}  0$ to all other nodes: $(S_{n})_{1j} = (S_{n})_{j1} = s_{n}$ for $j = 2, \\dots, n$, and $(S_{n})_{ij} = 0$ otherwise. Adopt the scaling $s_{n} = \\alpha/\\sqrt{n}$ with fixed $\\alpha  0$ and assume $\\alpha  \\sigma$ so that a hub-induced outlier eigenvalue exists.\n\nStarting from first principles of random matrix theory for networks—namely, the Wigner semicircle law for the spectral distribution of $W_{n}$ and resolvent-based self-consistency for additive finite-rank perturbations—derive, in the limit $n \\to \\infty$, the closed-form analytic expression for:\n1. The largest outlier eigenvalue of $A_{n}$ induced by the hub.\n2. Its separation from the right edge of the bulk spectrum of $W_{n}$.\n\nExpress your final answer as a single analytic expression or a single row matrix of analytic expressions in terms of $\\alpha$ and $\\sigma$. No numerical rounding is required. No physical units are involved.",
            "solution": "The problem asks for the largest outlier eigenvalue of the matrix $A_n = W_n + S_n$ and its separation from the bulk spectrum in the limit $n \\to \\infty$. We will solve this using resolvent techniques from random matrix theory.\n\nFirst, we characterize the spectral properties of the background matrix $W_n$. $W_n$ is a real symmetric random matrix with entries $(W_n)_{ij}$ for $i  j$ being independent and identically distributed with mean $0$ and variance $\\sigma^2/n$, and diagonal entries $(W_n)_{ii}=0$. This is a specific instance of a Wigner matrix. For this scaling of variance, the empirical spectral distribution of $W_n$ converges as $n \\to \\infty$ to the Wigner semicircle law. The probability density function $\\rho(x)$ is given by:\n$$ \\rho(x) = \\begin{cases} \\frac{1}{2\\pi\\sigma^2}\\sqrt{4\\sigma^2 - x^2}  \\text{if } |x| \\le 2\\sigma \\\\ 0  \\text{if } |x|  2\\sigma \\end{cases} $$\nThe spectrum of $W_n$ is thus asymptotically supported on the interval $[-2\\sigma, 2\\sigma]$. This continuous part of the spectrum is referred to as the \"bulk\". The right edge of the bulk spectrum is therefore at $\\lambda_{\\text{edge}} = 2\\sigma$.\n\nThe Stieltjes transform of this distribution, $g(z) = \\int \\frac{\\rho(x)}{x-z} dx$, is a crucial tool. For $z \\in \\mathbb{C} \\setminus [-2\\sigma, 2\\sigma]$, it satisfies the quadratic equation:\n$$ \\sigma^2 g(z)^2 + z g(z) + 1 = 0 $$\nThe appropriate solution, which satisfies $g(z) \\sim -1/z$ for large $|z|$, is:\n$$ g(z) = \\frac{-z + \\sqrt{z^2 - 4\\sigma^2}}{2\\sigma^2} $$\nFor a real-valued $\\lambda$ outside the bulk, i.e., $|\\lambda|  2\\sigma$, the quantities $(G_{W_n}(\\lambda))_{ii}$ converge to $g(\\lambda)$ and traces of the resolvent also relate to $g(\\lambda)$ via $\\frac{1}{n}\\mathrm{Tr}(G_{W_n}(\\lambda)) \\to g(\\lambda)$, where $G_{W_n}(\\lambda) = (W_n - \\lambda I)^{-1}$ is the resolvent of $W_n$.\n\nNext, we analyze the perturbation matrix $S_n$. It is defined by $(S_{n})_{1j} = (S_{n})_{j1} = s_{n} = \\alpha/\\sqrt{n}$ for $j=2, \\dots, n$, and all other entries are zero. This matrix represents a star graph and can be written as a rank-$2$ matrix. Let $e_1 = (1, 0, \\dots, 0)^T$ be the standard basis vector and $v = \\sum_{j=2}^n e_j = (0, 1, \\dots, 1)^T$. Then $S_n$ can be expressed as:\n$$ S_n = s_n (e_1 v^T + v e_1^T) $$\n\nAn outlier eigenvalue $\\lambda$ of $A_n = W_n + S_n$ that is separated from the bulk spectrum of $W_n$ is a pole of the resolvent $G_{A_n}(\\lambda) = (W_n + S_n - \\lambda I)^{-1}$. Such poles are determined by the condition $\\det(A_n - \\lambda I) = 0$, which can be rewritten using the resolvent of $W_n$ as:\n$$ \\det(I + G_{W_n}(\\lambda) S_n) = 0 $$\nUsing the property $\\det(I+BC) = \\det(I+CB)$, and the structure of $S_n = s_n(e_1 v^T + v e_1^T) = [e_1, v] \\begin{pmatrix} 0  s_n \\\\ s_n  0 \\end{pmatrix} [e_1, v]^T$, we can simplify the determinant.\nLet $U = [e_1, v]$ and $C = \\begin{pmatrix} 0  s_n \\\\ s_n  0 \\end{pmatrix}$. Then $S_n=UCU^T$.\nThe condition becomes $\\det(I_n + G_{W_n}(\\lambda) U C U^T) = 0$.\nThis is equivalent to $\\det(I_2 + U^T G_{W_n}(\\lambda) U C) = 0$.\nLet's compute the matrix $M(\\lambda) = U^T G_{W_n}(\\lambda) U$:\n$$ M(\\lambda) = \\begin{pmatrix} e_1^T G_{W_n}(\\lambda) e_1  e_1^T G_{W_n}(\\lambda) v \\\\ v^T G_{W_n}(\\lambda) e_1  v^T G_{W_n}(\\lambda) v \\end{pmatrix} $$\nThe condition becomes:\n$$ \\det\\left( \\begin{pmatrix} 1  0 \\\\ 0  1 \\end{pmatrix} + \\begin{pmatrix} e_1^T G_{W_n} e_1  e_1^T G_{W_n} v \\\\ v^T G_{W_n} e_1  v^T G_{W_n} v \\end{pmatrix} \\begin{pmatrix} 0  s_n \\\\ s_n  0 \\end{pmatrix} \\right) = 0 $$\n$$ \\det\\begin{pmatrix} 1+s_n(e_1^T G_{W_n} v)  s_n(e_1^T G_{W_n} e_1) \\\\ s_n(v^T G_{W_n} v)  1+s_n(v^T G_{W_n} e_1) \\end{pmatrix} = 0 $$\nSince $G_{W_n}$ is symmetric, $e_1^T G_{W_n} v = v^T G_{W_n} e_1$. The equation simplifies to:\n$$ (1+s_n e_1^T G_{W_n} v)^2 - s_n^2 (e_1^T G_{W_n} e_1)(v^T G_{W_n} v) = 0 $$\nIn the limit $n \\to \\infty$, for $\\lambda$ outside the bulk spectrum, quadratic forms of the resolvent converge: $u^T G_{W_n}(\\lambda) w \\to (u^T w) g(\\lambda)$.\nWe apply this to our terms:\n\\begin{itemize}\n    \\item $e_1^T G_{W_n}(\\lambda) e_1 \\to (e_1^T e_1) g(\\lambda) = 1 \\cdot g(\\lambda) = g(\\lambda)$.\n    \\item $v^T G_{W_n}(\\lambda) v \\to (v^T v) g(\\lambda) = (n-1) g(\\lambda)$.\n    \\item $e_1^T G_{W_n}(\\lambda) v \\to (e_1^T v) g(\\lambda) = 0 \\cdot g(\\lambda) = 0$.\n\\end{itemize}\nSubstituting these limits and $s_n = \\alpha/\\sqrt{n}$ into the equation:\n$$ (1 + \\frac{\\alpha}{\\sqrt{n}} \\cdot 0)^2 - \\left(\\frac{\\alpha}{\\sqrt{n}}\\right)^2 (g(\\lambda))((n-1) g(\\lambda)) \\approx 0 $$\n$$ 1 - \\frac{\\alpha^2}{n} g(\\lambda)^2 (n-1) = 0 $$\nTaking the limit $n \\to \\infty$, we get:\n$$ 1 - \\alpha^2 g(\\lambda)^2 = 0 \\implies g(\\lambda)^2 = \\frac{1}{\\alpha^2} $$\nWe are looking for the largest eigenvalue, so we assume $\\lambda  \\lambda_{\\text{edge}} = 2\\sigma$. For real $\\lambda  2\\sigma$, the Stieltjes transform $g(\\lambda) = \\int_{-2\\sigma}^{2\\sigma} \\frac{\\rho(x)}{x-\\lambda}dx$ is negative. Thus, we must take the negative root:\n$$ g(\\lambda) = -\\frac{1}{\\alpha} $$\nNow we substitute the expression for $g(\\lambda)$:\n$$ \\frac{-\\lambda + \\sqrt{\\lambda^2 - 4\\sigma^2}}{2\\sigma^2} = -\\frac{1}{\\alpha} $$\n$$ -\\lambda + \\sqrt{\\lambda^2 - 4\\sigma^2} = -\\frac{2\\sigma^2}{\\alpha} $$\n$$ \\sqrt{\\lambda^2 - 4\\sigma^2} = \\lambda - \\frac{2\\sigma^2}{\\alpha} $$\nThe condition $\\alpha  \\sigma$ ensures that the right-hand side is positive for the outlier $\\lambda$ we will find. Squaring both sides:\n$$ \\lambda^2 - 4\\sigma^2 = \\left(\\lambda - \\frac{2\\sigma^2}{\\alpha}\\right)^2 = \\lambda^2 - \\frac{4\\lambda\\sigma^2}{\\alpha} + \\frac{4\\sigma^4}{\\alpha^2} $$\n$$ -4\\sigma^2 = -\\frac{4\\lambda\\sigma^2}{\\alpha} + \\frac{4\\sigma^4}{\\alpha^2} $$\nAssuming $\\sigma \\neq 0$, we can divide by $-4\\sigma^2$:\n$$ 1 = \\frac{\\lambda}{\\alpha} - \\frac{\\sigma^2}{\\alpha^2} $$\nSolving for $\\lambda$ gives the largest outlier eigenvalue, $\\lambda_{\\text{outlier}}$:\n$$ \\lambda_{\\text{outlier}} = \\alpha \\left(1 + \\frac{\\sigma^2}{\\alpha^2}\\right) = \\alpha + \\frac{\\sigma^2}{\\alpha} $$\nThis result is valid for $\\alpha  \\sigma$, which ensures that $\\lambda_{\\text{outlier}}  2\\sigma$. Indeed, $\\alpha + \\frac{\\sigma^2}{\\alpha} - 2\\sigma = \\frac{\\alpha^2 - 2\\alpha\\sigma + \\sigma^2}{\\alpha} = \\frac{(\\alpha-\\sigma)^2}{\\alpha}  0$.\n\nThe first requested quantity is the outlier eigenvalue:\n$$ \\lambda_{\\text{outlier}} = \\alpha + \\frac{\\sigma^2}{\\alpha} $$\n\nThe second requested quantity is the separation of this eigenvalue from the right edge of the bulk spectrum. The right edge is at $\\lambda_{\\text{edge}} = 2\\sigma$. The separation, $\\Delta$, is:\n$$ \\Delta = \\lambda_{\\text{outlier}} - \\lambda_{\\text{edge}} = \\left(\\alpha + \\frac{\\sigma^2}{\\alpha}\\right) - 2\\sigma $$\n$$ \\Delta = \\frac{\\alpha^2 + \\sigma^2 - 2\\alpha\\sigma}{\\alpha} = \\frac{(\\alpha-\\sigma)^2}{\\alpha} $$\n\nThe two expressions are the complete answer to the problem. We present them as a row matrix.",
            "answer": "$$ \\boxed{\\begin{pmatrix} \\alpha + \\frac{\\sigma^2}{\\alpha}  \\frac{(\\alpha - \\sigma)^2}{\\alpha} \\end{pmatrix}} $$"
        }
    ]
}