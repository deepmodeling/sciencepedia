{
    "hands_on_practices": [
        {
            "introduction": "One of the most intuitive ways to characterize a graph's structure is through the distances between its nodes. This exercise demonstrates how to build a kernel based on this global property. By computing the distribution of all-pairs shortest-path lengths, we can create a feature vector that serves as a structural fingerprint for the graph, which can then be used in standard kernel machines .",
            "id": "4279073",
            "problem": "Consider two undirected, simple, connected weighted graphs $G$ and $H$ on $5$ labeled nodes $\\{1,2,3,4,5\\}$ with edge-weight function $w: E \\to \\mathbb{R}_{0}$ specified as follows. In $G$, the only edges are $(1,2)$, $(2,3)$, $(3,4)$, $(4,5)$, each with weight $w(e)=1$. In $H$, the only edges are $(3,1)$, $(3,2)$, $(3,4)$, $(3,5)$, each with weight $w(e)=1$. There are no other edges in either graph.\n\nYou will construct a shortest-path length distribution for each graph as a feature representation and then evaluate a Gaussian Radial Basis Function (RBF) kernel between these feature distributions to obtain $k(G,H)$. Use the following foundational definitions and steps:\n\n- The shortest-path length between nodes $u$ and $v$, denoted $d(u,v)$, is the minimum over all paths $\\pi$ connecting $u$ and $v$ of the sum of edge weights along $\\pi$.\n- Over the set of unordered node pairs, i.e., the $10$ pairs in $\\{ \\{u,v\\} : u,v \\in \\{1,\\dots,5\\}, uv\\}$, compute the multiset of shortest-path lengths for $G$ and for $H$.\n- Form a histogram over integer path lengths $\\ell \\in \\{1,2,3,4\\}$ for each graph by counting how many unordered pairs have shortest-path length equal to $\\ell$. If a length does not occur in a graph, its count is $0$.\n- Normalize each histogram by dividing by the total number of unordered pairs, $\\binom{5}{2}=10$, to obtain a probability distribution vector $p(G)$ and $p(H)$ in $\\mathbb{R}^{4}$ whose components correspond to lengths $\\ell=1,2,3,4$.\n- Define the Gaussian Radial Basis Function (RBF) kernel between these distributions by\n$$\nk(G,H) \\;=\\; \\exp\\!\\Big(-\\frac{\\|\\,p(G)-p(H)\\,\\|_{2}^{2}}{2 s^{2}}\\Big),\n$$\nwhere $s0$ is the bandwidth parameter. For this problem, use $s=\\frac{1}{2}$.\n\nStarting from the above definitions, compute $p(G)$ and $p(H)$ explicitly, then evaluate $k(G,H)$ exactly. Express the final answer as a closed-form analytic expression with no rounding.",
            "solution": "The user wants me to validate the problem statement and, if it is valid, provide a complete written solution.\n\n### Step 1: Extract Givens\n- **Graphs**: Two undirected, simple, connected weighted graphs, $G$ and $H$.\n- **Node Set**: $V = \\{1, 2, 3, 4, 5\\}$.\n- **Graph G Structure**: Edges $E_G = \\{(1,2), (2,3), (3,4), (4,5)\\}$, with edge weights $w(e)=1$ for all $e \\in E_G$.\n- **Graph H Structure**: Edges $E_H = \\{(3,1), (3,2), (3,4), (3,5)\\}$, with edge weights $w(e)=1$ for all $e \\in E_H$.\n- **Shortest-Path Length**: $d(u,v)$ is the minimum sum of edge weights over all paths between nodes $u$ and $v$.\n- **Feature Extraction**:\n    1. Compute the multiset of shortest-path lengths for all $\\binom{5}{2}=10$ unordered node pairs $\\{u,v\\}$ where $uv$.\n    2. Form a histogram for integer path lengths $\\ell \\in \\{1,2,3,4\\}$ by counting occurrences.\n    3. Normalize the histogram by dividing by $10$ to obtain probability distribution vectors $p(G), p(H) \\in \\mathbb{R}^4$.\n- **Kernel Definition**: The Gaussian Radial Basis Function (RBF) kernel is $k(G,H) = \\exp(-\\frac{\\|\\,p(G)-p(H)\\,\\|_{2}^{2}}{2 s^{2}})$.\n- **Parameter**: The bandwidth is $s=\\frac{1}{2}$.\n\n### Step 2: Validate Using Extracted Givens\nThe problem is assessed against the validation criteria.\n- **Scientifically Grounded**: The problem is based on standard, well-established concepts from graph theory (shortest paths, graph structures) and machine learning (kernel methods, feature extraction). The Gaussian RBF kernel is a fundamental tool. All definitions are correct and standard.\n- **Well-Posed**: The problem is unambiguously defined. The graphs are explicitly described, the feature extraction procedure is specified step-by-step, and the kernel function and its parameters are given. This structure guarantees that a unique, stable, and meaningful solution exists.\n- **Objective**: The problem is stated using precise and objective mathematical language, free from any subjectivity or bias.\n\nThe problem does not exhibit any of the listed invalidity flaws. It is a well-defined computational exercise within the domain of network science and machine learning.\n\n### Step 3: Verdict and Action\nThe problem is **valid**. A solution will be provided.\n\n### Solution Derivation\nThe solution proceeds by first constructing the feature vectors $p(G)$ and $p(H)$ and then computing the kernel value $k(G,H)$.\n\n**1. Feature Vector for Graph G**\nGraph $G$ is a path graph on $5$ nodes: $1-2-3-4-5$. All edge weights are $w(e)=1$. The shortest-path distance $d_G(u,v)$ is the number of edges between nodes $u$ and $v$. We compute these distances for all $\\binom{5}{2}=10$ unordered pairs of nodes.\n- Shortest-path length $\\ell=1$: The adjacent pairs in the path. These are $\\{1,2\\}, \\{2,3\\}, \\{3,4\\}, \\{4,5\\}$. The count is $4$.\n- Shortest-path length $\\ell=2$: Pairs separated by one node. These are $\\{1,3\\}, \\{2,4\\}, \\{3,5\\}$. The count is $3$.\n- Shortest-path length $\\ell=3$: Pairs separated by two nodes. These are $\\{1,4\\}, \\{2,5\\}$. The count is $2$.\n- Shortest-path length $\\ell=4$: The pair of endpoints. This is $\\{1,5\\}$. The count is $1$.\n\nThe histogram of shortest-path lengths for $G$, corresponding to lengths $\\ell=1, 2, 3, 4$, is the vector of counts $h(G) = (4, 3, 2, 1)$. To obtain the probability distribution $p(G)$, we normalize by the total number of pairs, $10$:\n$$p(G) = \\frac{1}{10} h(G) = \\left( \\frac{4}{10}, \\frac{3}{10}, \\frac{2}{10}, \\frac{1}{10} \\right)$$\n\n**2. Feature Vector for Graph H**\nGraph $H$ is a star graph with node $3$ as the center and nodes $\\{1,2,4,5\\}$ as its neighbors (leaves). All edge weights are $w(e)=1$. We compute the shortest-path distances for all $10$ pairs.\n- Shortest-path length $\\ell=1$: These are the pairs consisting of the central node and a leaf node. The pairs are $\\{1,3\\}, \\{2,3\\}, \\{3,4\\}, \\{3,5\\}$. The count is $4$.\n- Shortest-path length $\\ell=2$: These are the pairs of two distinct leaf nodes. The path between any two leaves must pass through the center, so the distance is $1+1=2$. The number of such pairs is the number of ways to choose $2$ leaves from $4$, which is $\\binom{4}{2} = \\frac{4 \\times 3}{2} = 6$. The count is $6$.\n- Shortest-path length $\\ell=3$: There are no pairs with a shortest-path length of $3$. The count is $0$.\n- Shortest-path length $\\ell=4$: There are no pairs with a shortest-path length of $4$. The count is $0$.\n\nThe histogram of shortest-path lengths for $H$ is $h(H) = (4, 6, 0, 0)$. Normalizing by $10$ gives the probability distribution $p(H)$:\n$$p(H) = \\frac{1}{10} h(H) = \\left( \\frac{4}{10}, \\frac{6}{10}, 0, 0 \\right)$$\n\n**3. Compute the Kernel Value**\nThe Gaussian RBF kernel requires the squared Euclidean distance between the feature vectors, $\\|\\,p(G)-p(H)\\,\\|_{2}^{2}$.\nFirst, we find the difference vector:\n$$p(G) - p(H) = \\left( \\frac{4}{10} - \\frac{4}{10}, \\frac{3}{10} - \\frac{6}{10}, \\frac{2}{10} - 0, \\frac{1}{10} - 0 \\right) = \\left( 0, -\\frac{3}{10}, \\frac{2}{10}, \\frac{1}{10} \\right)$$\nNext, we compute the squared $L_2$-norm of this vector:\n$$ \\|\\,p(G)-p(H)\\,\\|_{2}^{2} = (0)^2 + \\left(-\\frac{3}{10}\\right)^2 + \\left(\\frac{2}{10}\\right)^2 + \\left(\\frac{1}{10}\\right)^2 $$\n$$ \\|\\,p(G)-p(H)\\,\\|_{2}^{2} = 0 + \\frac{9}{100} + \\frac{4}{100} + \\frac{1}{100} = \\frac{14}{100} = \\frac{7}{50} $$\nThe kernel is given by $k(G,H) = \\exp(-\\frac{\\|\\,p(G)-p(H)\\,\\|_{2}^{2}}{2 s^{2}})$. The bandwidth parameter is $s=\\frac{1}{2}$, so $s^2 = \\frac{1}{4}$ and $2s^2 = 2(\\frac{1}{4}) = \\frac{1}{2}$.\nSubstituting the computed distance and the parameter into the kernel formula:\n$$ k(G,H) = \\exp\\left( -\\frac{7/50}{1/2} \\right) = \\exp\\left( -\\frac{7}{50} \\times 2 \\right) = \\exp\\left( -\\frac{14}{50} \\right) $$\nSimplifying the exponent gives the final answer:\n$$ k(G,H) = \\exp\\left( -\\frac{7}{25} \\right) $$\nThis is the exact, closed-form analytic expression for the kernel value.",
            "answer": "$$\\boxed{\\exp\\left(-\\frac{7}{25}\\right)}$$"
        },
        {
            "introduction": "Shifting our focus from global properties to local topology, this exercise introduces the graphlet kernel, which compares graphs based on the frequency of small, induced subgraphs. This approach is rooted in the idea that local structural patterns, or network motifs, are fundamental to a graph's function and identity. You will practice enumerating specific graphlets and see how their frequency vectors can be used to compute a similarity matrix, revealing which structures the kernel can and cannot distinguish .",
            "id": "4279105",
            "problem": "Consider three simple graphs defined as follows. Graph $G_{\\triangle}$ is the complete graph on $3$ vertices, denoted $K_{3}$. Graph $G_{\\mathrm{path}}$ is the path on $3$ vertices, denoted $P_{3}$. Graph $G_{\\mathrm{star}}$ is the star with $3$ leaves (thus $4$ vertices in total), denoted $K_{1,3}$, whose vertex set is $\\{c,a,b,d\\}$ and whose edge set is $\\{(c,a),(c,b),(c,d)\\}$. Using the connected size-$k$ graphlet kernel with $k=3$ as commonly used in complex systems and network science, define the feature map $\\phi(G)$ as the vector of normalized frequencies of isomorphism classes of connected induced subgraphs on $3$ vertices. For $k=3$, the connected isomorphism classes are precisely the triangle $K_{3}$ and the path $P_{3}$. Thus, for any graph $G$, let $f_{K_{3}}(G)$ be the number of $3$-vertex subsets whose induced subgraph is isomorphic to $K_{3}$, let $f_{P_{3}}(G)$ be the number of $3$-vertex subsets whose induced subgraph is isomorphic to $P_{3}$, and let $m(G)$ be the total number of connected induced subgraphs on $3$ vertices in $G$. The normalized feature map is $\\phi(G)=\\left(\\frac{f_{K_{3}}(G)}{m(G)},\\frac{f_{P_{3}}(G)}{m(G)}\\right)$. The Graphlet Kernel (GK) between two graphs $G$ and $H$ is the standard Euclidean inner product $K(G,H)=\\langle \\phi(G),\\phi(H)\\rangle$.\n\nCompute the $3\\times 3$ kernel matrix $K$ with entries $K_{ij}=K(G_{i},G_{j})$ for $G_{1}=G_{\\triangle}$, $G_{2}=G_{\\mathrm{path}}$, and $G_{3}=G_{\\mathrm{star}}$ by explicitly enumerating all induced subgraphs on $3$ vertices, determining connectedness and isomorphism type, forming the normalized feature vectors, and taking inner products. Express your final answer as an exact matrix with real entries. No rounding is required.",
            "solution": "The problem requires the computation of a $3 \\times 3$ kernel matrix $K$ for three given simple graphs: $G_1 = G_{\\triangle} = K_3$, the complete graph on $3$ vertices; $G_2 = G_{\\mathrm{path}} = P_3$, the path graph on $3$ vertices; and $G_3 = G_{\\mathrm{star}} = K_{1,3}$, the star graph with $3$ leaves and $1$ center (total of $4$ vertices). The kernel to be used is the connected size-$k$ graphlet kernel with $k=3$.\n\nThe feature map $\\phi(G)$ for a graph $G$ is defined as the vector of normalized frequencies of its connected induced subgraphs of size $k=3$. The isomorphism classes for connected graphs on $3$ vertices are the triangle ($K_3$) and the path of length $2$ ($P_3$). Let $f_{K_3}(G)$ be the number of $3$-vertex induced subgraphs of $G$ isomorphic to $K_3$, and let $f_{P_3}(G)$ be the number of $3$-vertex induced subgraphs of $G$ isomorphic to $P_3$. The total number of connected induced subgraphs on $3$ vertices is $m(G) = f_{K_3}(G) + f_{P_3}(G)$. The problem defines a specific normalization where the feature vector is:\n$$ \\phi(G) = \\left( \\frac{f_{K_3}(G)}{m(G)}, \\frac{f_{P_3}(G)}{m(G)} \\right) $$\nThis vector is defined provided $m(G)  0$. The graphlet kernel $K(G,H)$ between two graphs $G$ and $H$ is the standard Euclidean inner product of their feature vectors: $K(G,H) = \\langle \\phi(G), \\phi(H) \\rangle$.\n\nOur objective is to compute the matrix $K$ with entries $K_{ij} = K(G_i, G_j)$ for $i,j \\in \\{1, 2, 3\\}$. We proceed by first computing the feature vector for each of the three graphs.\n\n**1. Analysis of $G_1 = G_{\\triangle} = K_3$**\nThe graph $G_1$ is the complete graph on $3$ vertices, let them be $\\{v_1, v_2, v_3\\}$.\nThe number of vertices is $|V_1| = 3$. The number of subsets of $3$ vertices is $\\binom{3}{3} = 1$. The only such subset is the entire vertex set $\\{v_1, v_2, v_3\\}$.\nThe induced subgraph on this vertex set is $G_1$ itself, which is a $K_3$.\nTherefore, the counts of connected graphlets of size $3$ are:\n$f_{K_3}(G_1) = 1$\n$f_{P_3}(G_1) = 0$\nThe total number of connected induced subgraphs of size $3$ is $m(G_1) = 1 + 0 = 1$.\nThe normalized feature vector for $G_1$ is:\n$$ \\phi(G_1) = \\left( \\frac{1}{1}, \\frac{0}{1} \\right) = (1, 0) $$\n\n**2. Analysis of $G_2 = G_{\\mathrm{path}} = P_3$**\nThe graph $G_2$ is the path graph on $3$ vertices, let them be $\\{v_1, v_2, v_3\\}$ with edges $\\{(v_1, v_2), (v_2, v_3)\\}$.\nThe number of vertices is $|V_2| = 3$. The number of subsets of $3$ vertices is $\\binom{3}{3} = 1$. The only such subset is $\\{v_1, v_2, v_3\\}$.\nThe induced subgraph on this vertex set is $G_2$ itself, which is a $P_3$.\nTherefore, the counts of connected graphlets of size $3$ are:\n$f_{K_3}(G_2) = 0$\n$f_{P_3}(G_2) = 1$\nThe total number of connected induced subgraphs of size $3$ is $m(G_2) = 0 + 1 = 1$.\nThe normalized feature vector for $G_2$ is:\n$$ \\phi(G_2) = \\left( \\frac{0}{1}, \\frac{1}{1} \\right) = (0, 1) $$\n\n**3. Analysis of $G_3 = G_{\\mathrm{star}} = K_{1,3}$**\nThe graph $G_3$ is the star graph with one central vertex $c$ and $3$ leaf vertices $\\{a, b, d\\}$. The vertex set is $V_3 = \\{c, a, b, d\\}$ and the edge set is $E_3 = \\{(c,a), (c,b), (c,d)\\}$.\nThe number of vertices is $|V_3| = 4$. The number of subsets of $3$ vertices is $\\binom{4}{3} = \\frac{4 \\cdot 3 \\cdot 2}{3 \\cdot 2 \\cdot 1} = 4$. We must examine the induced subgraph for each subset.\n\\begin{enumerate}\n    \\item Subset $\\{c, a, b\\}$: The edges in $G_3$ connecting vertices in this subset are $(c,a)$ and $(c,b)$. The induced subgraph is a path of length $2$ with $c$ as the central vertex. This is isomorphic to $P_3$. It is connected.\n    \\item Subset $\\{c, a, d\\}$: The edges in $G_3$ connecting vertices in this subset are $(c,a)$ and $(c,d)$. The induced subgraph is also a $P_3$. It is connected.\n    \\item Subset $\\{c, b, d\\}$: The edges in $G_3$ connecting vertices in this subset are $(c,b)$ and $(c,d)$. The induced subgraph is also a $P_3$. It is connected.\n    \\item Subset $\\{a, b, d\\}$: There are no edges in $G_3$ connecting any pair of these three leaf vertices. The induced subgraph consists of $3$ isolated vertices. This subgraph is disconnected.\n\\end{enumerate}\nFrom this enumeration, we count the number of connected induced subgraphs of size $3$. All $3$ of them are isomorphic to $P_3$, and none are isomorphic to $K_3$.\nTherefore, the counts are:\n$f_{K_3}(G_3) = 0$\n$f_{P_3}(G_3) = 3$\nThe total number of connected induced subgraphs of size $3$ is $m(G_3) = 0 + 3 = 3$.\nThe normalized feature vector for $G_3$ is:\n$$ \\phi(G_3) = \\left( \\frac{0}{3}, \\frac{3}{3} \\right) = (0, 1) $$\n\n**4. Computation of the Kernel Matrix $K$**\nWe have the three feature vectors:\n$\\phi_1 = \\phi(G_1) = (1, 0)$\n$\\phi_2 = \\phi(G_2) = (0, 1)$\n$\\phi_3 = \\phi(G_3) = (0, 1)$\n\nThe kernel matrix $K$ has entries $K_{ij} = \\langle \\phi_i, \\phi_j \\rangle$. Since the kernel matrix is a Gram matrix, it is symmetric, so $K_{ij} = K_{ji}$. We compute the entries of the upper triangle.\n\n$K_{11} = \\langle \\phi_1, \\phi_1 \\rangle = \\langle (1, 0), (1, 0) \\rangle = (1)(1) + (0)(0) = 1$\n$K_{12} = \\langle \\phi_1, \\phi_2 \\rangle = \\langle (1, 0), (0, 1) \\rangle = (1)(0) + (0)(1) = 0$\n$K_{13} = \\langle \\phi_1, \\phi_3 \\rangle = \\langle (1, 0), (0, 1) \\rangle = (1)(0) + (0)(1) = 0$\n\n$K_{22} = \\langle \\phi_2, \\phi_2 \\rangle = \\langle (0, 1), (0, 1) \\rangle = (0)(0) + (1)(1) = 1$\n$K_{23} = \\langle \\phi_2, \\phi_3 \\rangle = \\langle (0, 1), (0, 1) \\rangle = (0)(0) + (1)(1) = 1$\n\n$K_{33} = \\langle \\phi_3, \\phi_3 \\rangle = \\langle (0, 1), (0, 1) \\rangle = (0)(0) + (1)(1) = 1$\n\nBy symmetry, $K_{21}=K_{12}=0$, $K_{31}=K_{13}=0$, and $K_{32}=K_{23}=1$.\nAssembling these values into a matrix gives:\n$$ K = \\begin{pmatrix} 1  0  0 \\\\ 0  1  1 \\\\ 0  1  1 \\end{pmatrix} $$\nThis is the final kernel matrix. The fact that $\\phi(G_2) = \\phi(G_3)$ implies that this particular graphlet kernel cannot distinguish between the path graph $P_3$ and the star graph $K_{1,3}$.",
            "answer": "$$ \\boxed{\\begin{pmatrix} 1  0  0 \\\\ 0  1  1 \\\\ 0  1  1 \\end{pmatrix}} $$"
        },
        {
            "introduction": "The Weisfeiler-Leman (WL) algorithm offers a powerful and efficient framework for measuring graph similarity, forming the basis for many state-of-the-art graph neural networks. This exercise guides you through one iteration of the WL refinement process, where node labels are updated based on the labels of their neighbors. This practice will demystify the label propagation mechanism and show how it generates rich, multi-scale structural features for highly effective graph comparison .",
            "id": "4279075",
            "problem": "Consider two finite, simple, undirected, node-labeled graphs with labels drawn from the alphabet $\\Sigma = \\{\\alpha,\\beta\\}$. Let $G = (V_G,E_G)$ have vertex set $V_G = \\{1,2,3,4\\}$ and edge set $E_G = \\{\\{1,2\\},\\{2,3\\},\\{3,1\\},\\{2,4\\}\\}$. Let $H = (V_H,E_H)$ have vertex set $V_H = \\{5,6,7,8\\}$ and edge set $E_H = \\{\\{5,6\\},\\{6,7\\},\\{7,5\\},\\{7,8\\}\\}$. The initial node-labeling functions are $\\ell_G^{(0)} : V_G \\to \\Sigma$ given by $\\ell_G^{(0)}(1) = \\alpha$, $\\ell_G^{(0)}(2) = \\beta$, $\\ell_G^{(0)}(3) = \\alpha$, $\\ell_G^{(0)}(4) = \\beta$, and $\\ell_H^{(0)} : V_H \\to \\Sigma$ given by $\\ell_H^{(0)}(5) = \\alpha$, $\\ell_H^{(0)}(6) = \\alpha$, $\\ell_H^{(0)}(7) = \\beta$, $\\ell_H^{(0)}(8) = \\beta$. Let $N_G(v)$ and $N_H(v)$ denote the neighbor sets of node $v$ in graphs $G$ and $H$, respectively.\n\nOne iteration of the one-dimensional Weisfeiler–Leman (WL) refinement constructs, for each node $v$, the signature at height $t=1$ as the pair\n$$\n\\sigma^{(1)}(v) := \\Big(\\ell^{(0)}(v),\\, \\mathrm{sort}\\big(\\{\\!\\{\\ell^{(0)}(u) : u \\in N(v)\\}\\!\\}\\big)\\Big),\n$$\nwhere $\\mathrm{sort}$ returns the sequence of labels in nondecreasing order with respect to the fixed ordering $\\alpha  \\beta$, and $\\{\\!\\{\\cdot\\}\\!\\}$ denotes a multiset. A global, injective compression map $\\kappa_1$ is then constructed by collecting all distinct $\\sigma^{(1)}(v)$ over $v \\in V_G \\cup V_H$, sorting these pairs lexicographically using the rule: first compare the first component by $\\alpha  \\beta$, then compare the neighbor-sequence by increasing length, and finally by lexicographic order under $\\alpha  \\beta$; assign consecutive integers starting at $1$ in this sorted order. The compressed refined label at height $1$ is $\\ell^{(1)}(v) := \\kappa_1(\\sigma^{(1)}(v))$. Similarly, define a global compression map for the initial labels $\\kappa_0$ by sorting $\\{\\alpha,\\beta\\}$ under $\\alpha  \\beta$ and assigning $\\kappa_0(\\alpha) = 1$, $\\kappa_0(\\beta) = 2$; the compressed initial label is $\\tilde{\\ell}^{(0)}(v) := \\kappa_0(\\ell^{(0)}(v))$.\n\nFor each height $t \\in \\{0,1\\}$, define the feature-count vector $\\phi_t(G)$ whose components count, for graph $G$, the number of nodes having each compressed label at height $t$ under the global maps. Define $\\phi_t(H)$ analogously for $H$. The Weisfeiler–Leman (WL) kernel at height $h=1$ between $G$ and $H$ is the inner product of the aggregated count vectors across heights $t=0$ and $t=1$:\n$$\nK_{\\mathrm{WL}}^{(1)}(G,H) := \\langle \\phi_0(G), \\phi_0(H) \\rangle + \\langle \\phi_1(G), \\phi_1(H) \\rangle.\n$$\n\nStarting from the above core definitions, perform one WL refinement iteration ($t=1$) on both $G$ and $H$, construct the global compression maps, compute the refined label counts, and evaluate $K_{\\mathrm{WL}}^{(1)}(G,H)$. Express the final answer as a single real-valued number. No rounding is required.",
            "solution": "The problem requires the computation of the Weisfeiler–Leman (WL) kernel at height $h=1$ between two graphs, $G$ and $H$. The kernel is defined as the sum of inner products of feature-count vectors at heights $t=0$ and $t=1$:\n$$\nK_{\\mathrm{WL}}^{(1)}(G,H) = \\langle \\phi_0(G), \\phi_0(H) \\rangle + \\langle \\phi_1(G), \\phi_1(H) \\rangle.\n$$\nWe will compute each term separately.\n\n**Part 1: Height $t=0$ Analysis**\n\nFirst, we determine the feature-count vectors for the initial node labels at height $t=0$. The label alphabet is $\\Sigma = \\{\\alpha, \\beta\\}$ with the ordering $\\alpha  \\beta$.\n\nThe initial node labels for graph $G$ are:\n- $\\ell_G^{(0)}(1) = \\alpha$\n- $\\ell_G^{(0)}(2) = \\beta$\n- $\\ell_G^{(0)}(3) = \\alpha$\n- $\\ell_G^{(0)}(4) = \\beta$\nThe counts of labels in $G$ are $2$ for $\\alpha$ and $2$ for $\\beta$.\n\nThe initial node labels for graph $H$ are:\n- $\\ell_H^{(0)}(5) = \\alpha$\n- $\\ell_H^{(0)}(6) = \\alpha$\n- $\\ell_H^{(0)}(7) = \\beta$\n- $\\ell_H^{(0)}(8) = \\beta$\nThe counts of labels in $H$ are $2$ for $\\alpha$ and $2$ for $\\beta$.\n\nThe global compression map for initial labels, $\\kappa_0$, is defined by sorting $\\{\\alpha, \\beta\\}$ to get the sequence $(\\alpha, \\beta)$ and assigning integer labels starting from $1$:\n- $\\kappa_0(\\alpha) = 1$\n- $\\kappa_0(\\beta) = 2$\nThe compressed initial label for a node $v$ is $\\tilde{\\ell}^{(0)}(v) = \\kappa_0(\\ell^{(0)}(v))$.\n\nThe feature-count vector $\\phi_0(G)$ has components corresponding to the counts of the compressed labels $\\{1, 2\\}$.\nFor graph $G$, the count of label $1$ (from $\\alpha$) is $2$, and the count of label $2$ (from $\\beta$) is $2$.\nTherefore, $\\phi_0(G) = \\begin{pmatrix} 2  2 \\end{pmatrix}$.\n\nSimilarly, for graph $H$, the count of label $1$ is $2$, and the count of label $2$ is $2$.\nTherefore, $\\phi_0(H) = \\begin{pmatrix} 2  2 \\end{pmatrix}$.\n\nThe inner product at height $t=0$ is:\n$$\n\\langle \\phi_0(G), \\phi_0(H) \\rangle = \\langle \\begin{pmatrix} 2  2 \\end{pmatrix}, \\begin{pmatrix} 2  2 \\end{pmatrix} \\rangle = (2 \\times 2) + (2 \\times 2) = 4 + 4 = 8.\n$$\n\n**Part 2: Height $t=1$ Analysis**\n\nNext, we perform one iteration of the WL refinement to compute the feature-count vectors at height $t=1$. This involves computing the signature $\\sigma^{(1)}(v)$ for each node $v \\in V_G \\cup V_H$. The signature is defined as $\\sigma^{(1)}(v) = (\\ell^{(0)}(v),\\, \\mathrm{sort}(\\{\\!\\{\\ell^{(0)}(u) : u \\in N(v)\\}\\!\\}\\big))$.\n\n**For Graph G:**\n- Node $1$: $\\ell_G^{(0)}(1)=\\alpha$. Neighbors $N_G(1)=\\{2,3\\}$. Neighbor labels: $\\{\\ell_G^{(0)}(2), \\ell_G^{(0)}(3)\\} = \\{\\beta, \\alpha\\}$. Sorted multiset: $\\{\\alpha, \\beta\\}$.\n  $\\sigma^{(1)}(1) = (\\alpha, \\{\\alpha, \\beta\\})$.\n- Node $2$: $\\ell_G^{(0)}(2)=\\beta$. Neighbors $N_G(2)=\\{1,3,4\\}$. Neighbor labels: $\\{\\ell_G^{(0)}(1), \\ell_G^{(0)}(3), \\ell_G^{(0)}(4)\\} = \\{\\alpha, \\alpha, \\beta\\}$. Sorted multiset: $\\{\\alpha, \\alpha, \\beta\\}$.\n  $\\sigma^{(1)}(2) = (\\beta, \\{\\alpha, \\alpha, \\beta\\})$.\n- Node $3$: $\\ell_G^{(0)}(3)=\\alpha$. Neighbors $N_G(3)=\\{1,2\\}$. Neighbor labels: $\\{\\ell_G^{(0)}(1), \\ell_G^{(0)}(2)\\} = \\{\\alpha, \\beta\\}$. Sorted multiset: $\\{\\alpha, \\beta\\}$.\n  $\\sigma^{(1)}(3) = (\\alpha, \\{\\alpha, \\beta\\})$.\n- Node $4$: $\\ell_G^{(0)}(4)=\\beta$. Neighbor $N_G(4)=\\{2\\}$. Neighbor label: $\\{\\ell_G^{(0)}(2)\\} = \\{\\beta\\}$. Sorted multiset: $\\{\\beta\\}$.\n  $\\sigma^{(1)}(4) = (\\beta, \\{\\beta\\})$.\n\n**For Graph H:**\n- Node $5$: $\\ell_H^{(0)}(5)=\\alpha$. Neighbors $N_H(5)=\\{6,7\\}$. Neighbor labels: $\\{\\ell_H^{(0)}(6), \\ell_H^{(0)}(7)\\} = \\{\\alpha, \\beta\\}$. Sorted multiset: $\\{\\alpha, \\beta\\}$.\n  $\\sigma^{(1)}(5) = (\\alpha, \\{\\alpha, \\beta\\})$.\n- Node $6$: $\\ell_H^{(0)}(6)=\\alpha$. Neighbors $N_H(6)=\\{5,7\\}$. Neighbor labels: $\\{\\ell_H^{(0)}(5), \\ell_H^{(0)}(7)\\} = \\{\\alpha, \\beta\\}$. Sorted multiset: $\\{\\alpha, \\beta\\}$.\n  $\\sigma^{(1)}(6) = (\\alpha, \\{\\alpha, \\beta\\})$.\n- Node $7$: $\\ell_H^{(0)}(7)=\\beta$. Neighbors $N_H(7)=\\{5,6,8\\}$. Neighbor labels: $\\{\\ell_H^{(0)}(5), \\ell_H^{(0)}(6), \\ell_H^{(0)}(8)\\} = \\{\\alpha, \\alpha, \\beta\\}$. Sorted multiset: $\\{\\alpha, \\alpha, \\beta\\}$.\n  $\\sigma^{(1)}(7) = (\\beta, \\{\\alpha, \\alpha, \\beta\\})$.\n- Node $8$: $\\ell_H^{(0)}(8)=\\beta$. Neighbor $N_H(8)=\\{7\\}$. Neighbor label: $\\{\\ell_H^{(0)}(7)\\} = \\{\\beta\\}$. Sorted multiset: $\\{\\beta\\}$.\n  $\\sigma^{(1)}(8) = (\\beta, \\{\\beta\\})$.\n\nNow, we collect all distinct signatures from $V_G \\cup V_H$ and sort them to create the global compression map $\\kappa_1$. The set of distinct signatures is:\n- $s_A = (\\alpha, \\{\\alpha, \\beta\\})$\n- $s_B = (\\beta, \\{\\alpha, \\alpha, \\beta\\})$\n- $s_C = (\\beta, \\{\\beta\\})$\n\nWe sort these lexicographically.\n1. Compare first components using $\\alpha  \\beta$. This places $s_A$ first.\n2. Compare $s_B$ and $s_C$. Their first components are both $\\beta$. We compare their second components (neighbor multisets) first by length. The length for $s_C$ is $1$, and for $s_B$ is $3$. Thus, $s_C$ comes before $s_B$.\n\nThe sorted list of unique signatures is:\n1. $(\\alpha, \\{\\alpha, \\beta\\})$\n2. $(\\beta, \\{\\beta\\})$\n3. $(\\beta, \\{\\alpha, \\alpha, \\beta\\})$\n\nThe compression map $\\kappa_1$ assigns integers to these sorted signatures:\n- $\\kappa_1((\\alpha, \\{\\alpha, \\beta\\})) = 1$\n- $\\kappa_1((\\beta, \\{\\beta\\})) = 2$\n- $\\kappa_1((\\beta, \\{\\alpha, \\alpha, \\beta\\})) = 3$\n\nUsing $\\kappa_1$, we find the compressed refined labels $\\ell^{(1)}(v) = \\kappa_1(\\sigma^{(1)}(v))$.\nFor graph $G$:\n- $\\ell^{(1)}(1) = \\kappa_1((\\alpha, \\{\\alpha, \\beta\\})) = 1$\n- $\\ell^{(1)}(2) = \\kappa_1((\\beta, \\{\\alpha, \\alpha, \\beta\\})) = 3$\n- $\\ell^{(1)}(3) = \\kappa_1((\\alpha, \\{\\alpha, \\beta\\})) = 1$\n- $\\ell^{(1)}(4) = \\kappa_1((\\beta, \\{\\beta\\})) = 2$\nThe counts of refined labels in $G$ are: two nodes with label $1$, one node with label $2$, and one node with label $3$.\nThus, the feature-count vector is $\\phi_1(G) = \\begin{pmatrix} 2  1  1 \\end{pmatrix}$.\n\nFor graph $H$:\n- $\\ell^{(1)}(5) = \\kappa_1((\\alpha, \\{\\alpha, \\beta\\})) = 1$\n- $\\ell^{(1)}(6) = \\kappa_1((\\alpha, \\{\\alpha, \\beta\\})) = 1$\n- $\\ell^{(1)}(7) = \\kappa_1((\\beta, \\{\\alpha, \\alpha, \\beta\\})) = 3$\n- $\\ell^{(1)}(8) = \\kappa_1((\\beta, \\{\\beta\\})) = 2$\nThe counts of refined labels in $H$ are: two nodes with label $1$, one node with label $2$, and one node with label $3$.\nThus, the feature-count vector is $\\phi_1(H) = \\begin{pmatrix} 2  1  1 \\end{pmatrix}$.\n\nThe inner product at height $t=1$ is:\n$$\n\\langle \\phi_1(G), \\phi_1(H) \\rangle = \\langle \\begin{pmatrix} 2  1  1 \\end{pmatrix}, \\begin{pmatrix} 2  1  1 \\end{pmatrix} \\rangle = (2 \\times 2) + (1 \\times 1) + (1 \\times 1) = 4 + 1 + 1 = 6.\n$$\n\n**Part 3: Final Kernel Calculation**\n\nFinally, we sum the inner products from both heights to obtain the WL kernel value.\n$$\nK_{\\mathrm{WL}}^{(1)}(G,H) = \\langle \\phi_0(G), \\phi_0(H) \\rangle + \\langle \\phi_1(G), \\phi_1(H) \\rangle = 8 + 6 = 14.\n$$",
            "answer": "$$\n\\boxed{14}\n$$"
        }
    ]
}