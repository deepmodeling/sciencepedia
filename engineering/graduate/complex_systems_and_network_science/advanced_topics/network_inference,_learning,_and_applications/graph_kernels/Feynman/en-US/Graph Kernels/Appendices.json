{
    "hands_on_practices": [
        {
            "introduction": "To begin our practical exploration, we will dissect the mechanics of the celebrated Weisfeiler–Leman (WL) kernel. This exercise provides a step-by-step walkthrough of the WL algorithm, which forms the basis of many state-of-the-art graph neural networks. By iteratively refining node labels based on the sorted labels of their neighbors, the WL test produces a canonical representation of a node's local structure, and this practice will make that abstract process concrete .",
            "id": "4279075",
            "problem": "Consider two finite, simple, undirected, node-labeled graphs with labels drawn from the alphabet $\\Sigma = \\{\\alpha,\\beta\\}$. Let $G = (V_G,E_G)$ have vertex set $V_G = \\{1,2,3,4\\}$ and edge set $E_G = \\{\\{1,2\\},\\{2,3\\},\\{3,1\\},\\{2,4\\}\\}$. Let $H = (V_H,E_H)$ have vertex set $V_H = \\{5,6,7,8\\}$ and edge set $E_H = \\{\\{5,6\\},\\{6,7\\},\\{7,5\\},\\{7,8\\}\\}$. The initial node-labeling functions are $\\ell_G^{(0)} : V_G \\to \\Sigma$ given by $\\ell_G^{(0)}(1) = \\alpha$, $\\ell_G^{(0)}(2) = \\beta$, $\\ell_G^{(0)}(3) = \\alpha$, $\\ell_G^{(0)}(4) = \\beta$, and $\\ell_H^{(0)} : V_H \\to \\Sigma$ given by $\\ell_H^{(0)}(5) = \\alpha$, $\\ell_H^{(0)}(6) = \\alpha$, $\\ell_H^{(0)}(7) = \\beta$, $\\ell_H^{(0)}(8) = \\beta$. Let $N_G(v)$ and $N_H(v)$ denote the neighbor sets of node $v$ in graphs $G$ and $H$, respectively.\n\nOne iteration of the one-dimensional Weisfeiler–Leman (WL) refinement constructs, for each node $v$, the signature at height $t=1$ as the pair\n$$\n\\sigma^{(1)}(v) := \\Big(\\ell^{(0)}(v),\\, \\mathrm{sort}\\big(\\{\\!\\{\\ell^{(0)}(u) : u \\in N(v)\\}\\!\\}\\big)\\Big),\n$$\nwhere $\\mathrm{sort}$ returns the sequence of labels in nondecreasing order with respect to the fixed ordering $\\alpha  \\beta$, and $\\{\\!\\{\\cdot\\}\\!\\}$ denotes a multiset. A global, injective compression map $\\kappa_1$ is then constructed by collecting all distinct $\\sigma^{(1)}(v)$ over $v \\in V_G \\cup V_H$, sorting these pairs lexicographically using the rule: first compare the first component by the relation $\\alpha  \\beta$, then compare the neighbor-sequence by increasing length, and finally by lexicographic order under $\\alpha  \\beta$; assign consecutive integers starting at $1$ in this sorted order. The compressed refined label at height $1$ is $\\ell^{(1)}(v) := \\kappa_1(\\sigma^{(1)}(v))$. Similarly, define a global compression map for the initial labels $\\kappa_0$ by sorting $\\{\\alpha,\\beta\\}$ under $\\alpha  \\beta$ and assigning $\\kappa_0(\\alpha) = 1$, $\\kappa_0(\\beta) = 2$; the compressed initial label is $\\tilde{\\ell}^{(0)}(v) := \\kappa_0(\\ell^{(0)}(v))$.\n\nFor each height $t \\in \\{0,1\\}$, define the feature-count vector $\\phi_t(G)$ whose components count, for graph $G$, the number of nodes having each compressed label at height $t$ under the global maps. Define $\\phi_t(H)$ analogously for $H$. The Weisfeiler–Leman (WL) kernel at height $h=1$ between $G$ and $H$ is the inner product of the aggregated count vectors across heights $t=0$ and $t=1$:\n$$\nK_{\\mathrm{WL}}^{(1)}(G,H) := \\langle \\phi_0(G), \\phi_0(H) \\rangle + \\langle \\phi_1(G), \\phi_1(H) \\rangle.\n$$\n\nStarting from the above core definitions, perform one WL refinement iteration ($t=1$) on both $G$ and $H$, construct the global compression maps, compute the refined label counts, and evaluate $K_{\\mathrm{WL}}^{(1)}(G,H)$. Express the final answer as a single real-valued number. No rounding is required.",
            "solution": "The problem requires the computation of the Weisfeiler–Leman (WL) kernel at height $h=1$ between two graphs, $G$ and $H$. The kernel is defined as the sum of inner products of feature-count vectors at heights $t=0$ and $t=1$:\n$$\nK_{\\mathrm{WL}}^{(1)}(G,H) = \\langle \\phi_0(G), \\phi_0(H) \\rangle + \\langle \\phi_1(G), \\phi_1(H) \\rangle.\n$$\nWe will compute each term separately.\n\n**Part 1: Height $t=0$ Analysis**\n\nFirst, we determine the feature-count vectors for the initial node labels at height $t=0$. The label alphabet is $\\Sigma = \\{\\alpha, \\beta\\}$ with the ordering $\\alpha  \\beta$.\n\nThe initial node labels for graph $G$ are:\n- $\\ell_G^{(0)}(1) = \\alpha$\n- $\\ell_G^{(0)}(2) = \\beta$\n- $\\ell_G^{(0)}(3) = \\alpha$\n- $\\ell_G^{(0)}(4) = \\beta$\nThe counts of labels in $G$ are $2$ for $\\alpha$ and $2$ for $\\beta$.\n\nThe initial node labels for graph $H$ are:\n- $\\ell_H^{(0)}(5) = \\alpha$\n- $\\ell_H^{(0)}(6) = \\alpha$\n- $\\ell_H^{(0)}(7) = \\beta$\n- $\\ell_H^{(0)}(8) = \\beta$\nThe counts of labels in $H$ are $2$ for $\\alpha$ and $2$ for $\\beta$.\n\nThe global compression map for initial labels, $\\kappa_0$, is defined by sorting $\\{\\alpha, \\beta\\}$ to get the sequence $(\\alpha, \\beta)$ and assigning integer labels starting from $1$:\n- $\\kappa_0(\\alpha) = 1$\n- $\\kappa_0(\\beta) = 2$\nThe compressed initial label for a node $v$ is $\\tilde{\\ell}^{(0)}(v) = \\kappa_0(\\ell^{(0)}(v))$.\n\nThe feature-count vector $\\phi_0(G)$ has components corresponding to the counts of the compressed labels $\\{1, 2\\}$.\nFor graph $G$, the count of label $1$ (from $\\alpha$) is $2$, and the count of label $2$ (from $\\beta$) is $2$.\nTherefore, $\\phi_0(G) = (2, 2)$.\n\nSimilarly, for graph $H$, the count of label $1$ is $2$, and the count of label $2$ is $2$.\nTherefore, $\\phi_0(H) = (2, 2)$.\n\nThe inner product at height $t=0$ is:\n$$\n\\langle \\phi_0(G), \\phi_0(H) \\rangle = \\langle (2, 2), (2, 2) \\rangle = (2 \\times 2) + (2 \\times 2) = 4 + 4 = 8.\n$$\n\n**Part 2: Height $t=1$ Analysis**\n\nNext, we perform one iteration of the WL refinement to compute the feature-count vectors at height $t=1$. This involves computing the signature $\\sigma^{(1)}(v)$ for each node $v \\in V_G \\cup V_H$. The signature is defined as $\\sigma^{(1)}(v) = (\\ell^{(0)}(v),\\, \\mathrm{sort}(\\{\\!\\{\\ell^{(0)}(u) : u \\in N(v)\\}\\!\\}\\big))$.\n\n**For Graph G:**\n- Node $1$: $\\ell_G^{(0)}(1)=\\alpha$. Neighbors $N_G(1)=\\{2,3\\}$. Neighbor labels: $\\{\\ell_G^{(0)}(2), \\ell_G^{(0)}(3)\\} = \\{\\beta, \\alpha\\}$. Sorted multiset: $\\{\\alpha, \\beta\\}$.\n  $\\sigma^{(1)}(1) = (\\alpha, \\{\\alpha, \\beta\\})$.\n- Node $2$: $\\ell_G^{(0)}(2)=\\beta$. Neighbors $N_G(2)=\\{1,3,4\\}$. Neighbor labels: $\\{\\ell_G^{(0)}(1), \\ell_G^{(0)}(3), \\ell_G^{(0)}(4)\\} = \\{\\alpha, \\alpha, \\beta\\}$. Sorted multiset: $\\{\\alpha, \\alpha, \\beta\\}$.\n  $\\sigma^{(1)}(2) = (\\beta, \\{\\alpha, \\alpha, \\beta\\})$.\n- Node $3$: $\\ell_G^{(0)}(3)=\\alpha$. Neighbors $N_G(3)=\\{1,2\\}$. Neighbor labels: $\\{\\ell_G^{(0)}(1), \\ell_G^{(0)}(2)\\} = \\{\\alpha, \\beta\\}$. Sorted multiset: $\\{\\alpha, \\beta\\}$.\n  $\\sigma^{(1)}(3) = (\\alpha, \\{\\alpha, \\beta\\})$.\n- Node $4$: $\\ell_G^{(0)}(4)=\\beta$. Neighbor $N_G(4)=\\{2\\}$. Neighbor label: $\\{\\ell_G^{(0)}(2)\\} = \\{\\beta\\}$. Sorted multiset: $\\{\\beta\\}$.\n  $\\sigma^{(1)}(4) = (\\beta, \\{\\beta\\})$.\n\n**For Graph H:**\n- Node $5$: $\\ell_H^{(0)}(5)=\\alpha$. Neighbors $N_H(5)=\\{6,7\\}$. Neighbor labels: $\\{\\ell_H^{(0)}(6), \\ell_H^{(0)}(7)\\} = \\{\\alpha, \\beta\\}$. Sorted multiset: $\\{\\alpha, \\beta\\}$.\n  $\\sigma^{(1)}(5) = (\\alpha, \\{\\alpha, \\beta\\})$.\n- Node $6$: $\\ell_H^{(0)}(6)=\\alpha$. Neighbors $N_H(6)=\\{5,7\\}$. Neighbor labels: $\\{\\ell_H^{(0)}(5), \\ell_H^{(0)}(7)\\} = \\{\\alpha, \\beta\\}$. Sorted multiset: $\\{\\alpha, \\beta\\}$.\n  $\\sigma^{(1)}(6) = (\\alpha, \\{\\alpha, \\beta\\})$.\n- Node $7$: $\\ell_H^{(0)}(7)=\\beta$. Neighbors $N_H(7)=\\{5,6,8\\}$. Neighbor labels: $\\{\\ell_H^{(0)}(5), \\ell_H^{(0)}(6), \\ell_H^{(0)}(8)\\} = \\{\\alpha, \\alpha, \\beta\\}$. Sorted multiset: $\\{\\alpha, \\alpha, \\beta\\}$.\n  $\\sigma^{(1)}(7) = (\\beta, \\{\\alpha, \\alpha, \\beta\\})$.\n- Node $8$: $\\ell_H^{(0)}(8)=\\beta$. Neighbor $N_H(8)=\\{7\\}$. Neighbor label: $\\{\\ell_H^{(0)}(7)\\} = \\{\\beta\\}$. Sorted multiset: $\\{\\beta\\}$.\n  $\\sigma^{(1)}(8) = (\\beta, \\{\\beta\\})$.\n\nNow, we collect all distinct signatures from $V_G \\cup V_H$ and sort them to create the global compression map $\\kappa_1$. The set of distinct signatures is:\n- $s_A = (\\alpha, \\{\\alpha, \\beta\\})$\n- $s_B = (\\beta, \\{\\alpha, \\alpha, \\beta\\})$\n- $s_C = (\\beta, \\{\\beta\\})$\n\nWe sort these lexicographically.\n1. Compare first components using $\\alpha  \\beta$. This places $s_A$ first.\n2. Compare $s_B$ and $s_C$. Their first components are both $\\beta$. We compare their second components (neighbor multisets) first by length. The length for $s_C$ is $1$, and for $s_B$ is $3$. Thus, $s_C$ comes before $s_B$.\n\nThe sorted list of unique signatures is:\n1. $(\\alpha, \\{\\alpha, \\beta\\})$\n2. $(\\beta, \\{\\beta\\})$\n3. $(\\beta, \\{\\alpha, \\alpha, \\beta\\})$\n\nThe compression map $\\kappa_1$ assigns integers to these sorted signatures:\n- $\\kappa_1((\\alpha, \\{\\alpha, \\beta\\})) = 1$\n- $\\kappa_1((\\beta, \\{\\beta\\})) = 2$\n- $\\kappa_1((\\beta, \\{\\alpha, \\alpha, \\beta\\})) = 3$\n\nUsing $\\kappa_1$, we find the compressed refined labels $\\ell^{(1)}(v) = \\kappa_1(\\sigma^{(1)}(v))$.\nFor graph $G$:\n- $\\ell^{(1)}(1) = \\kappa_1((\\alpha, \\{\\alpha, \\beta\\})) = 1$\n- $\\ell^{(1)}(2) = \\kappa_1((\\beta, \\{\\alpha, \\alpha, \\beta\\})) = 3$\n- $\\ell^{(1)}(3) = \\kappa_1((\\alpha, \\{\\alpha, \\beta\\})) = 1$\n- $\\ell^{(1)}(4) = \\kappa_1((\\beta, \\{\\beta\\})) = 2$\nThe counts of refined labels in $G$ are: two nodes with label $1$, one node with label $2$, and one node with label $3$.\nThus, the feature-count vector is $\\phi_1(G) = (2, 1, 1)$.\n\nFor graph $H$:\n- $\\ell^{(1)}(5) = \\kappa_1((\\alpha, \\{\\alpha, \\beta\\})) = 1$\n- $\\ell^{(1)}(6) = \\kappa_1((\\alpha, \\{\\alpha, \\beta\\})) = 1$\n- $\\ell^{(1)}(7) = \\kappa_1((\\beta, \\{\\alpha, \\alpha, \\beta\\})) = 3$\n- $\\ell^{(1)}(8) = \\kappa_1((\\beta, \\{\\beta\\})) = 2$\nThe counts of refined labels in $H$ are: two nodes with label $1$, one node with label $2$, and one node with label $3$.\nThus, the feature-count vector is $\\phi_1(H) = (2, 1, 1)$.\n\nThe inner product at height $t=1$ is:\n$$\n\\langle \\phi_1(G), \\phi_1(H) \\rangle = \\langle (2, 1, 1), (2, 1, 1) \\rangle = (2 \\times 2) + (1 \\times 1) + (1 \\times 1) = 4 + 1 + 1 = 6.\n$$\n\n**Part 3: Final Kernel Calculation**\n\nFinally, we sum the inner products from both heights to obtain the WL kernel value.\n$$\nK_{\\mathrm{WL}}^{(1)}(G,H) = \\langle \\phi_0(G), \\phi_0(H) \\rangle + \\langle \\phi_1(G), \\phi_1(H) \\rangle = 8 + 6 = 14.\n$$",
            "answer": "$$\n\\boxed{14}\n$$"
        },
        {
            "introduction": "Moving from iterative refinement to explicit substructure counting, our next practice focuses on the graphlet kernel. This approach characterizes graphs by creating a feature vector based on the frequency of small, induced subgraphs, or 'graphlets'. This exercise will guide you in manually enumerating connected 3-node graphlets to compute a kernel matrix, offering direct insight into how local structural patterns can be used for graph comparison and revealing the kernel's inherent limitations .",
            "id": "4279105",
            "problem": "Consider three simple graphs defined as follows. Graph $G_{\\triangle}$ is the complete graph on $3$ vertices, denoted $K_{3}$. Graph $G_{\\mathrm{path}}$ is the path on $3$ vertices, denoted $P_{3}$. Graph $G_{\\mathrm{star}}$ is the star with $3$ leaves (thus $4$ vertices in total), denoted $K_{1,3}$, whose vertex set is $\\{c,a,b,d\\}$ and whose edge set is $\\{(c,a),(c,b),(c,d)\\}$. Using the connected size-$k$ graphlet kernel with $k=3$ as commonly used in complex systems and network science, define the feature map $\\phi(G)$ as the vector of normalized frequencies of isomorphism classes of connected induced subgraphs on $3$ vertices. For $k=3$, the connected isomorphism classes are precisely the triangle $K_{3}$ and the path $P_{3}$. Thus, for any graph $G$, let $f_{K_{3}}(G)$ be the number of $3$-vertex subsets whose induced subgraph is isomorphic to $K_{3}$, let $f_{P_{3}}(G)$ be the number of $3$-vertex subsets whose induced subgraph is isomorphic to $P_{3}$, and let $m(G)$ be the total number of connected induced subgraphs on $3$ vertices in $G$. The normalized feature map is $\\phi(G)=\\left(\\frac{f_{K_{3}}(G)}{m(G)},\\frac{f_{P_{3}}(G)}{m(G)}\\right)$. The Graphlet Kernel (GK) between two graphs $G$ and $H$ is the standard Euclidean inner product $K(G,H)=\\langle \\phi(G),\\phi(H)\\rangle$.\n\nCompute the $3\\times 3$ kernel matrix $K$ with entries $K_{ij}=K(G_{i},G_{j})$ for $G_{1}=G_{\\triangle}$, $G_{2}=G_{\\mathrm{path}}$, and $G_{3}=G_{\\mathrm{star}}$ by explicitly enumerating all induced subgraphs on $3$ vertices, determining connectedness and isomorphism type, forming the normalized feature vectors, and taking inner products. Express your final answer as an exact matrix with real entries. No rounding is required.",
            "solution": "The problem requires the computation of a $3 \\times 3$ kernel matrix $K$ for three given simple graphs: $G_1 = G_{\\triangle} = K_3$, the complete graph on $3$ vertices; $G_2 = G_{\\mathrm{path}} = P_3$, the path graph on $3$ vertices; and $G_3 = G_{\\mathrm{star}} = K_{1,3}$, the star graph with $3$ leaves and $1$ center (total of $4$ vertices). The kernel to be used is the connected size-$k$ graphlet kernel with $k=3$.\n\nThe feature map $\\phi(G)$ for a graph $G$ is defined as the vector of normalized frequencies of its connected induced subgraphs of size $k=3$. The isomorphism classes for connected graphs on $3$ vertices are the triangle ($K_3$) and the path of length $2$ ($P_3$). Let $f_{K_3}(G)$ be the number of $3$-vertex induced subgraphs of $G$ isomorphic to $K_3$, and let $f_{P_3}(G)$ be the number of $3$-vertex induced subgraphs of $G$ isomorphic to $P_3$. The total number of connected induced subgraphs on $3$ vertices is $m(G) = f_{K_3}(G) + f_{P_3}(G)$. The problem defines a specific normalization where the feature vector is:\n$$ \\phi(G) = \\left( \\frac{f_{K_3}(G)}{m(G)}, \\frac{f_{P_3}(G)}{m(G)} \\right) $$\nThis vector is defined provided $m(G) > 0$. The graphlet kernel $K(G,H)$ between two graphs $G$ and $H$ is the standard Euclidean inner product of their feature vectors: $K(G,H) = \\langle \\phi(G), \\phi(H) \\rangle$.\n\nOur objective is to compute the matrix $K$ with entries $K_{ij} = K(G_i, G_j)$ for $i,j \\in \\{1, 2, 3\\}$. We proceed by first computing the feature vector for each of the three graphs.\n\n**1. Analysis of $G_1 = G_{\\triangle} = K_3$**\nThe graph $G_1$ is the complete graph on $3$ vertices, let them be $\\{v_1, v_2, v_3\\}$.\nThe number of vertices is $|V_1| = 3$. The number of subsets of $3$ vertices is $\\binom{3}{3} = 1$. The only such subset is the entire vertex set $\\{v_1, v_2, v_3\\}$.\nThe induced subgraph on this vertex set is $G_1$ itself, which is a $K_3$.\nTherefore, the counts of connected graphlets of size $3$ are:\n$f_{K_3}(G_1) = 1$\n$f_{P_3}(G_1) = 0$\nThe total number of connected induced subgraphs of size $3$ is $m(G_1) = 1 + 0 = 1$.\nThe normalized feature vector for $G_1$ is:\n$$ \\phi(G_1) = \\left( \\frac{1}{1}, \\frac{0}{1} \\right) = (1, 0) $$\n\n**2. Analysis of $G_2 = G_{\\mathrm{path}} = P_3$**\nThe graph $G_2$ is the path graph on $3$ vertices, let them be $\\{v_1, v_2, v_3\\}$ with edges $\\{(v_1, v_2), (v_2, v_3)\\}$.\nThe number of vertices is $|V_2| = 3$. The number of subsets of $3$ vertices is $\\binom{3}{3} = 1$. The only such subset is $\\{v_1, v_2, v_3\\}$.\nThe induced subgraph on this vertex set is $G_2$ itself, which is a $P_3$.\nTherefore, the counts of connected graphlets of size $3$ are:\n$f_{K_3}(G_2) = 0$\n$f_{P_3}(G_2) = 1$\nThe total number of connected induced subgraphs of size $3$ is $m(G_2) = 0 + 1 = 1$.\nThe normalized feature vector for $G_2$ is:\n$$ \\phi(G_2) = \\left( \\frac{0}{1}, \\frac{1}{1} \\right) = (0, 1) $$\n\n**3. Analysis of $G_3 = G_{\\mathrm{star}} = K_{1,3}$**\nThe graph $G_3$ is the star graph with one central vertex $c$ and $3$ leaf vertices $\\{a, b, d\\}$. The vertex set is $V_3 = \\{c, a, b, d\\}$ and the edge set is $E_3 = \\{(c,a), (c,b), (c,d)\\}$.\nThe number of vertices is $|V_3| = 4$. The number of subsets of $3$ vertices is $\\binom{4}{3} = \\frac{4 \\cdot 3 \\cdot 2}{3 \\cdot 2 \\cdot 1} = 4$. We must examine the induced subgraph for each subset.\n\\begin{enumerate}\n    \\item Subset $\\{c, a, b\\}$: The edges in $G_3$ connecting vertices in this subset are $(c,a)$ and $(c,b)$. The induced subgraph is a path of length $2$ with $c$ as the central vertex. This is isomorphic to $P_3$. It is connected.\n    \\item Subset $\\{c, a, d\\}$: The edges in $G_3$ connecting vertices in this subset are $(c,a)$ and $(c,d)$. The induced subgraph is also a $P_3$. It is connected.\n    \\item Subset $\\{c, b, d\\}$: The edges in $G_3$ connecting vertices in this subset are $(c,b)$ and $(c,d)$. The induced subgraph is also a $P_3$. It is connected.\n    \\item Subset $\\{a, b, d\\}$: There are no edges in $G_3$ connecting any pair of these three leaf vertices. The induced subgraph consists of $3$ isolated vertices. This subgraph is disconnected.\n\\end{enumerate}\nFrom this enumeration, we count the number of connected induced subgraphs of size $3$. All $3$ of them are isomorphic to $P_3$, and none are isomorphic to $K_3$.\nTherefore, the counts are:\n$f_{K_3}(G_3) = 0$\n$f_{P_3}(G_3) = 3$\nThe total number of connected induced subgraphs of size $3$ is $m(G_3) = 0 + 3 = 3$.\nThe normalized feature vector for $G_3$ is:\n$$ \\phi(G_3) = \\left( \\frac{0}{3}, \\frac{3}{3} \\right) = (0, 1) $$\n\n**4. Computation of the Kernel Matrix $K$**\nWe have the three feature vectors:\n$\\phi_1 = \\phi(G_1) = (1, 0)$\n$\\phi_2 = \\phi(G_2) = (0, 1)$\n$\\phi_3 = \\phi(G_3) = (0, 1)$\n\nThe kernel matrix $K$ has entries $K_{ij} = \\langle \\phi_i, \\phi_j \\rangle$. Since the kernel matrix is a Gram matrix, it is symmetric, so $K_{ij} = K_{ji}$. We compute the entries of the upper triangle.\n\n$K_{11} = \\langle \\phi_1, \\phi_1 \\rangle = \\langle (1, 0), (1, 0) \\rangle = (1)(1) + (0)(0) = 1$\n$K_{12} = \\langle \\phi_1, \\phi_2 \\rangle = \\langle (1, 0), (0, 1) \\rangle = (1)(0) + (0)(1) = 0$\n$K_{13} = \\langle \\phi_1, \\phi_3 \\rangle = \\langle (1, 0), (0, 1) \\rangle = (1)(0) + (0)(1) = 0$\n\n$K_{22} = \\langle \\phi_2, \\phi_2 \\rangle = \\langle (0, 1), (0, 1) \\rangle = (0)(0) + (1)(1) = 1$\n$K_{23} = \\langle \\phi_2, \\phi_3 \\rangle = \\langle (0, 1), (0, 1) \\rangle = (0)(0) + (1)(1) = 1$\n\n$K_{33} = \\langle \\phi_3, \\phi_3 \\rangle = \\langle (0, 1), (0, 1) \\rangle = (0)(0) + (1)(1) = 1$\n\nBy symmetry, $K_{21}=K_{12}=0$, $K_{31}=K_{13}=0$, and $K_{32}=K_{23}=1$.\nAssembling these values into a matrix gives:\n$$ K = \\begin{pmatrix} 1  0  0 \\\\ 0  1  1 \\\\ 0  1  1 \\end{pmatrix} $$\nThis is the final kernel matrix. The fact that $\\phi(G_2) = \\phi(G_3)$ implies that this particular graphlet kernel cannot distinguish between the path graph $P_3$ and the star graph $K_{1,3}$.",
            "answer": "$$ \\boxed{\\begin{pmatrix} 1  0  0 \\\\ 0  1  1 \\\\ 0  1  1 \\end{pmatrix}} $$"
        },
        {
            "introduction": "Our final practice ventures into the spectral domain to construct a diffusion signature kernel, which leverages the eigenvalues of the graph Laplacian. This powerful technique interprets graph similarity through the lens of a simulated heat diffusion process, where the rate of heat dissipation is a signature of the graph's topology. In this computational exercise, you will calculate the graph's heat trace from its Laplacian spectrum and use it to approximate the kernel value, bridging the gap between abstract spectral theory and practical application .",
            "id": "4279068",
            "problem": "You are given the task of constructing and evaluating a diffusion signature kernel between small undirected graphs using the graph heat trace. Work from first principles of spectral graph theory as follows: for a simple undirected graph with adjacency matrix $A \\in \\{0,1\\}^{n \\times n}$ and degree matrix $D \\in \\mathbb{R}^{n \\times n}$ defined by $D_{ii} = \\sum_{j=1}^{n} A_{ij}$, define the combinatorial Laplacian $L = D - A$. For any diffusion scale parameter $\\beta \\geq 0$, define the heat kernel $H(\\beta) = \\exp(-\\beta L)$ via the matrix exponential, and the heat trace $h(\\beta) = \\operatorname{tr}(H(\\beta))$. The diffusion signature kernel between two graphs $G$ and $H$ over an interval $\\beta \\in [\\beta_{\\min}, \\beta_{\\max}]$ is defined by the integral\n$$\nK(G,H) = \\int_{\\beta_{\\min}}^{\\beta_{\\max}} h_G(\\beta)\\, h_H(\\beta)\\, d\\beta,\n$$\nwhere $h_G(\\beta)$ and $h_H(\\beta)$ are the heat traces of the respective graphs. You must approximate this integral numerically using the trapezoidal rule on a specified grid $\\{\\beta_0, \\beta_1, \\ldots, \\beta_m\\}$ with $\\beta_0 = \\beta_{\\min}$ and $\\beta_m = \\beta_{\\max}$:\n$$\n\\widehat{K}(G,H) = \\sum_{i=0}^{m-1} \\frac{\\Delta \\beta_i}{2}\\,\\Big(h_G(\\beta_i)\\,h_H(\\beta_i) + h_G(\\beta_{i+1})\\,h_H(\\beta_{i+1})\\Big),\n$$\nwhere $\\Delta \\beta_i = \\beta_{i+1} - \\beta_i$. Use the spectral theorem to compute $h(\\beta)$ through the eigenvalues $\\{\\lambda_k\\}_{k=1}^{n}$ of $L$ by\n$$\nh(\\beta) = \\sum_{k=1}^{n} e^{-\\beta \\lambda_k}.\n$$\nAll quantities are unitless.\n\nImplement a single program that performs the following tasks for the provided test suite. For each graph pair, compute the list of heat traces at the given $\\beta$ values, then compute the trapezoidal approximation of the diffusion signature kernel $\\widehat{K}$ over the full $\\beta$ range.\n\nGraphs are specified by their edge sets on labeled vertices $\\{0,1,\\ldots,n-1\\}$, are undirected, unweighted, and simple (no self-loops, no multiedges). For each pair, the $\\beta$ grid is explicitly given and defines the integration bounds.\n\nTest Suite:\n- Pair $1$:\n  - Graph $G_A$: path on $4$ nodes with edges $\\{(0,1),(1,2),(2,3)\\}$.\n  - Graph $G_B$: star on $4$ nodes with center at node $0$ and edges $\\{(0,1),(0,2),(0,3)\\}$.\n  - Grid $\\mathcal{B}_1 = [\\,0.0,\\,0.25,\\,0.5,\\,1.0,\\,2.0\\,]$, so $\\beta_{\\min} = 0.0$, $\\beta_{\\max} = 2.0$.\n  - Tasks: compute $[h_{G_A}(\\beta): \\beta \\in \\mathcal{B}_1]$, $[h_{G_B}(\\beta): \\beta \\in \\mathcal{B}_1]$, and $\\widehat{K}(G_A,G_B)$ over $[0.0,2.0]$.\n- Pair $2$:\n  - Graph $G_C$: triangle (cycle on $3$ nodes) with edges $\\{(0,1),(1,2),(2,0)\\}$.\n  - Graph $G_D$: path on $3$ nodes with edges $\\{(0,1),(1,2)\\}$.\n  - Grid $\\mathcal{B}_2 = [\\,0.0,\\,0.1,\\,0.2,\\,0.5,\\,1.0\\,]$, so $\\beta_{\\min} = 0.0$, $\\beta_{\\max} = 1.0$.\n  - Tasks: compute $[h_{G_C}(\\beta): \\beta \\in \\mathcal{B}_2]$, $[h_{G_D}(\\beta): \\beta \\in \\mathcal{B}_2]$, and $\\widehat{K}(G_C,G_D)$ over $[0.0,1.0]$.\n- Pair $3$:\n  - Graph $G_E$: $2$ isolated nodes with no edges.\n  - Graph $G_F$: single edge on $2$ nodes with edges $\\{(0,1)\\}$.\n  - Grid $\\mathcal{B}_3 = [\\,0.0,\\,5.0\\,]$, so $\\beta_{\\min} = 0.0$, $\\beta_{\\max} = 5.0$.\n  - Tasks: compute $[h_{G_E}(\\beta): \\beta \\in \\mathcal{B}_3]$, $[h_{G_F}(\\beta): \\beta \\in \\mathcal{B}_3]$, and $\\widehat{K}(G_E,G_F)$ over $[0.0,5.0]$.\n\nYour program must:\n- Construct each Laplacian $L$ from the given edges.\n- Compute all heat traces using the eigenvalue formula above.\n- Approximate each diffusion signature kernel using the trapezoidal rule on the provided grid.\n\nFinal Output Format:\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets. The nine items, in order, must be:\n  - The list of heat traces for $G_A$ on $\\mathcal{B}_1$,\n  - The list of heat traces for $G_B$ on $\\mathcal{B}_1$,\n  - The scalar $\\widehat{K}(G_A,G_B)$,\n  - The list of heat traces for $G_C$ on $\\mathcal{B}_2$,\n  - The list of heat traces for $G_D$ on $\\mathcal{B}_2$,\n  - The scalar $\\widehat{K}(G_C,G_D)$,\n  - The list of heat traces for $G_E$ on $\\mathcal{B}_3$,\n  - The list of heat traces for $G_F$ on $\\mathcal{B}_3$,\n  - The scalar $\\widehat{K}(G_E,G_F)$.\n- Represent each floating-point number with at least $10$ decimal places.\n- The output must contain no spaces, for example: \"[[...],[...],0.1234567890,[...],[...],0.2345678901,[...],[...],0.3456789012]\".",
            "solution": "The problem statement is assessed to be **valid**. It is scientifically grounded, well-posed, and objective. All definitions, data, and constraints are provided, are free of contradictions, and are based on established principles of spectral graph theory and numerical analysis. The problem is a well-defined computational task that is both theoretically sound and practically feasible.\n\nThe solution proceeds by implementing the specified mathematical formalism. The core of the problem is to compute a similarity measure between pairs of graphs, known as the diffusion signature kernel. This requires three main steps for each pair of graphs $G$ and $H$.\n\n1.  **Graph Laplacian Construction**: A graph is fundamentally represented by its connectivity. For a simple, undirected graph $G$ with $n$ vertices, we first construct its adjacency matrix $A$, an $n \\times n$ matrix where $A_{ij} = 1$ if an edge exists between vertex $i$ and vertex $j$, and $A_{ij} = 0$ otherwise. From $A$, we form the diagonal degree matrix $D$, where each diagonal element $D_{ii}$ is the degree of vertex $i$, calculated as $D_{ii} = \\sum_{j=1}^{n} A_{ij}$. The combinatorial Laplacian matrix $L$ is then defined as $L = D - A$. This matrix is a cornerstone of spectral graph theory, and its properties encode significant structural information about the graph.\n\n2.  **Heat Trace Calculation via Eigenvalue Decomposition**: The diffusion of heat on a graph is modeled by the graph heat equation, whose solution involves the matrix exponential of the Laplacian, $H(\\beta) = \\exp(-\\beta L)$, where $\\beta$ is a time-like diffusion scale parameter. The heat trace, $h(\\beta) = \\operatorname{tr}(H(\\beta))$, is a graph invariant that captures information about the graph's structure at various diffusion scales. A direct computation of the matrix exponential is computationally expensive. The problem specifies a more efficient method using the spectral theorem. Since the Laplacian matrix $L$ is real and symmetric, it is diagonalizable and has a full set of real eigenvalues, $\\{\\lambda_k\\}_{k=1}^{n}$. The trace of a matrix is the sum of its eigenvalues. Consequently, the trace of a function of a matrix, such as the matrix exponential, is the sum of the function applied to each eigenvalue. Therefore, the heat trace can be computed as:\n    $$\n    h(\\beta) = \\operatorname{tr}(\\exp(-\\beta L)) = \\sum_{k=1}^{n} \\lambda_k(\\exp(-\\beta L)) = \\sum_{k=1}^{n} \\exp(-\\beta \\lambda_k)\n    $$\n    For each graph, we compute the eigenvalues of its Laplacian matrix $L$. Then, for each value of $\\beta$ in the specified grid $\\mathcal{B}$, we calculate $h(\\beta)$ using this summation. A key property is that for any graph with $n$ vertices, $h(0) = \\sum_{k=1}^{n} \\exp(0) = n$, which serves as a useful sanity check.\n\n3.  **Numerical Integration of the Kernel**: The diffusion signature kernel $K(G,H)$ is defined by the integral of the product of the two graphs' heat traces over a range of $\\beta$ values:\n    $$\n    K(G,H) = \\int_{\\beta_{\\min}}^{\\beta_{\\max}} h_G(\\beta)\\, h_H(\\beta)\\, d\\beta\n    $$\n    This integral measures the similarity of the graphs' diffusion profiles across scales. The problem requires a numerical approximation of this integral, $\\widehat{K}(G,H)$, using the trapezoidal rule on the given grid of $\\beta$ values: $\\mathcal{B} = \\{\\beta_0, \\beta_1, \\ldots, \\beta_m\\}$. The formula is given by:\n    $$\n    \\widehat{K}(G,H) = \\sum_{i=0}^{m-1} \\frac{\\Delta \\beta_i}{2}\\,\\Big(f(\\beta_i) + f(\\beta_{i+1})\\Big),\n    $$\n    where $f(\\beta) = h_G(\\beta)h_H(\\beta)$ is the integrand and $\\Delta \\beta_i = \\beta_{i+1} - \\beta_i$ is the step size, which may not be uniform. This summation is performed for each pair of graphs using their computed heat trace values at the grid points.\n\nThis three-step procedure is implemented for each of the three test pairs specified in the problem. The results—lists of heat traces and the scalar kernel value for each pair—are then collected and formatted into a single string as per the strict output requirements. The entire process relies on standard, numerically stable algorithms, namely eigenvalue computation for symmetric matrices and the trapezoidal rule for numerical integration, which are readily available in the `numpy` library.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to solve the graph kernel problem for all test cases.\n    \"\"\"\n\n    test_cases = [\n        {\n            \"graphs\": {\n                \"G_A\": {\"n\": 4, \"edges\": [(0, 1), (1, 2), (2, 3)]},\n                \"G_B\": {\"n\": 4, \"edges\": [(0, 1), (0, 2), (0, 3)]},\n            },\n            \"beta_grid\": [0.0, 0.25, 0.5, 1.0, 2.0],\n        },\n        {\n            \"graphs\": {\n                \"G_C\": {\"n\": 3, \"edges\": [(0, 1), (1, 2), (2, 0)]},\n                \"G_D\": {\"n\": 3, \"edges\": [(0, 1), (1, 2)]},\n            },\n            \"beta_grid\": [0.0, 0.1, 0.2, 0.5, 1.0],\n        },\n        {\n            \"graphs\": {\n                \"G_E\": {\"n\": 2, \"edges\": []},\n                \"G_F\": {\"n\": 2, \"edges\": [(0, 1)]},\n            },\n            \"beta_grid\": [0.0, 5.0],\n        },\n    ]\n\n    all_results_str = []\n    \n    def get_heat_traces(n, edges, beta_grid):\n        \"\"\"\n        Computes the heat traces for a single graph.\n        \n        Args:\n            n (int): Number of nodes in the graph.\n            edges (list of tuples): Edge list of the graph.\n            beta_grid (list of float): Grid of beta values.\n            \n        Returns:\n            list of float: List of heat trace values h(beta).\n        \"\"\"\n        adj_matrix = np.zeros((n, n), dtype=float)\n        for u, v in edges:\n            adj_matrix[u, v] = 1\n            adj_matrix[v, u] = 1\n        \n        degree_matrix = np.diag(np.sum(adj_matrix, axis=1))\n        laplacian = degree_matrix - adj_matrix\n        \n        # For a real symmetric matrix, eigvalsh is preferred for numerical stability\n        eigenvalues = np.linalg.eigvalsh(laplacian)\n        \n        heat_traces = []\n        for beta in beta_grid:\n            h_beta = np.sum(np.exp(-beta * eigenvalues))\n            heat_traces.append(h_beta)\n            \n        return heat_traces\n\n    for case in test_cases:\n        graph_defs = case[\"graphs\"]\n        beta_grid = np.array(case[\"beta_grid\"])\n        \n        graph_A_def = list(graph_defs.values())[0]\n        graph_B_def = list(graph_defs.values())[1]\n\n        h_A = get_heat_traces(graph_A_def[\"n\"], graph_A_def[\"edges\"], beta_grid)\n        h_B = get_heat_traces(graph_B_def[\"n\"], graph_B_def[\"edges\"], beta_grid)\n        \n        # Compute the integrand for the trapezoidal rule\n        integrand = np.array(h_A) * np.array(h_B)\n        \n        # Compute the kernel value using the trapezoidal rule\n        kernel_val = np.trapz(integrand, beta_grid)\n        \n        # Format results as specified\n        h_A_str = f\"[{','.join([f'{v:.15f}' for v in h_A])}]\"\n        h_B_str = f\"[{','.join([f'{v:.15f}' for v in h_B])}]\"\n        kernel_str = f\"{kernel_val:.15f}\"\n        \n        all_results_str.append(h_A_str)\n        all_results_str.append(h_B_str)\n        all_results_str.append(kernel_str)\n\n    # Final print statement in the exact required format\n    print(f\"[{','.join(all_results_str)}]\")\n\nsolve()\n```"
        }
    ]
}