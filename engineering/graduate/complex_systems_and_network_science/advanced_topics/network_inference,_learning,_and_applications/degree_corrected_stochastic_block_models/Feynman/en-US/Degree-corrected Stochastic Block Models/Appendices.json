{
    "hands_on_practices": [
        {
            "introduction": "Before fitting complex models, it's crucial to understand what the parameters represent. This first exercise provides a foundational insight into the Degree-Corrected Stochastic Block Model (DCSBM) by connecting its abstract block-affinity parameters directly to a tangible network property: the expected number of edges between communities. By working through this derivation , you will see how the model's normalization constraints lead to this elegant and interpretable relationship.",
            "id": "4272166",
            "problem": "Consider a directed multigraph on $N$ vertices generated by the Degree-Corrected Stochastic Block Model (DCSBM). Each vertex $i \\in \\{1,\\dots,N\\}$ is assigned a block label $g_i \\in \\{1,\\dots,B\\}$ and a positive degree parameter $\\theta_i > 0$. Let $\\Omega$ be the $B \\times B$ nonnegative block-affinity matrix with entries $\\omega_{rs}$ for $r,s \\in \\{1,\\dots,B\\}$. The adjacency matrix $A$ has entries $A_{ij}$ that are independent Poisson random variables with rate parameter $\\lambda_{ij} = \\theta_i \\theta_j \\,\\omega_{g_i g_j}$ for all ordered pairs $(i,j)$, including $i=j$. Define the total number of edges from block $r$ to block $s$ as\n$$\nm_{rs} = \\sum_{i: g_i = r} \\sum_{j: g_j = s} A_{ij}.\n$$\nAssume the block-wise normalization constraint\n$$\n\\sum_{i: g_i = r} \\theta_i = 1 \\quad \\text{for every} \\quad r \\in \\{1,\\dots,B\\}.\n$$\nStarting from the fundamental definitions of expectation for Poisson random variables and the linearity of expectation, derive a closed-form expression for $\\mathbb{E}[m_{rs}]$ in terms of the block-affinity matrix entries. Your final answer must be a single closed-form analytic expression.",
            "solution": "The objective is to derive a closed-form expression for $\\mathbb{E}[m_{rs}]$, the expected total number of edges from block $r$ to block $s$. We begin with the definition of $m_{rs}$ provided in the problem statement:\n$$\nm_{rs} = \\sum_{i: g_i = r} \\sum_{j: g_j = s} A_{ij}\n$$\nHere, $g_i$ is the block label of vertex $i$, and the summation runs over all vertices $i$ in block $r$ and all vertices $j$ in block $s$.\n\nTo find the expectation of $m_{rs}$, we apply the linearity of expectation. The expectation of a sum of random variables is the sum of their individual expectations.\n$$\n\\mathbb{E}[m_{rs}] = \\mathbb{E}\\left[ \\sum_{i: g_i = r} \\sum_{j: g_j = s} A_{ij} \\right] = \\sum_{i: g_i = r} \\sum_{j: g_j = s} \\mathbb{E}[A_{ij}]\n$$\nThe problem states that each entry $A_{ij}$ of the adjacency matrix is an independent Poisson random variable with a rate parameter $\\lambda_{ij}$. A fundamental property of the Poisson distribution is that its expectation is equal to its rate parameter. Thus, for a random variable $X \\sim \\text{Poisson}(\\lambda)$, we have $\\mathbb{E}[X] = \\lambda$. Applying this property to $A_{ij}$, we get:\n$$\n\\mathbb{E}[A_{ij}] = \\lambda_{ij}\n$$\nSubstituting this into the expression for $\\mathbb{E}[m_{rs}]$ yields:\n$$\n\\mathbb{E}[m_{rs}] = \\sum_{i: g_i = r} \\sum_{j: g_j = s} \\lambda_{ij}\n$$\nNext, we use the definition of the rate parameter $\\lambda_{ij}$ for the Degree-Corrected Stochastic Block Model (DCSBM), which is given as:\n$$\n\\lambda_{ij} = \\theta_i \\theta_j \\,\\omega_{g_i g_j}\n$$\nwhere $\\theta_i$ and $\\theta_j$ are the degree parameters for vertices $i$ and $j$, respectively, and $\\omega_{g_i g_j}$ is the entry of the block-affinity matrix $\\Omega$ corresponding to the blocks of vertices $i$ and $j$.\n\nSubstituting this expression for $\\lambda_{ij}$ into our equation for $\\mathbb{E}[m_{rs}]$:\n$$\n\\mathbb{E}[m_{rs}] = \\sum_{i: g_i = r} \\sum_{j: g_j = s} \\theta_i \\theta_j \\,\\omega_{g_i g_j}\n$$\nWithin the scope of the double summation, the index $i$ runs over all vertices belonging to block $r$ (so $g_i = r$), and the index $j$ runs over all vertices belonging to block $s$ (so $g_j = s$). Therefore, for every term in this sum, the block-affinity term $\\omega_{g_i g_j}$ is constant and equal to $\\omega_{rs}$. We can factor this constant term out of the summation:\n$$\n\\mathbb{E}[m_{rs}] = \\omega_{rs} \\sum_{i: g_i = r} \\sum_{j: g_j = s} \\theta_i \\theta_j\n$$\nThe remaining double summation can be separated into a product of two independent sums, as the term $\\theta_i$ does not depend on the inner summation index $j$, and the term $\\theta_j$ does not depend on the outer summation index $i$:\n$$\n\\sum_{i: g_i = r} \\sum_{j: g_j = s} \\theta_i \\theta_j = \\left( \\sum_{i: g_i = r} \\theta_i \\right) \\left( \\sum_{j: g_j = s} \\theta_j \\right)\n$$\nAt this point, we employ the block-wise normalization constraint provided in the problem statement:\n$$\n\\sum_{k: g_k = q} \\theta_k = 1 \\quad \\text{for every block} \\quad q \\in \\{1,\\dots,B\\}\n$$\nApplying this constraint to each of the sums in our product:\nThe first sum is over all vertices $i$ in block $r$, so:\n$$\n\\sum_{i: g_i = r} \\theta_i = 1\n$$\nThe second sum is over all vertices $j$ in block $s$, so:\n$$\n\\sum_{j: g_j = s} \\theta_j = 1\n$$\nTherefore, the product of the two sums is equal to $1 \\times 1 = 1$.\n\nSubstituting this result back into our expression for $\\mathbb{E}[m_{rs}]$, we obtain the final expression:\n$$\n\\mathbb{E}[m_{rs}] = \\omega_{rs} \\times 1 = \\omega_{rs}\n$$\nThis result shows that under the given normalization, the entries of the block-affinity matrix $\\Omega$ directly correspond to the expected total number of edges between the respective blocks.",
            "answer": "$$\\boxed{\\omega_{rs}}$$"
        },
        {
            "introduction": "Once we understand the model's parameters, the next step is to estimate them from observed network data. This practice guides you through the core of this process by setting up the constrained Maximum Likelihood Estimation (MLE) for the DCSBM parameters. By using the method of Lagrange multipliers , you will derive the fundamental stationarity conditions that are the basis for many practical algorithms used to fit the DCSBM to real-world networks.",
            "id": "4272149",
            "problem": "Consider an undirected network with $n$ nodes, represented by a symmetric adjacency matrix $A$ with entries $A_{ij} \\in \\{0,1,2,\\dots\\}$ for $i \\neq j$ and $A_{ii} = 0$. Each node $i$ is assigned to one of $B$ blocks, with block labels $g_i \\in \\{1,2,\\dots,B\\}$. Assume the Degree-Corrected Stochastic Block Model (DCSBM), where for each unordered pair $\\{i,j\\}$ with $i<j$, the random variable $A_{ij}$ is independent and distributed according to a Poisson law with mean $\\theta_i \\theta_j \\Omega_{g_i g_j}$, where $\\theta_i > 0$ are node-specific degree-correction parameters and $\\Omega \\in \\mathbb{R}_{+}^{B \\times B}$ is a symmetric block affinity matrix with entries $\\Omega_{rs} > 0$. Let $k_i := \\sum_{j \\neq i} A_{ij}$ denote the observed degree of node $i$, and define the block edge counts\n$$\nm_{rs} := \\sum_{\\substack{i<j:\\\\ (g_i,g_j) \\in \\{(r,s),(s,r)\\}}} A_{ij},\n$$\nwhich is the total number of edges between blocks $r$ and $s$ for $r \\neq s$, and for $r=s$ equals the number of edges strictly within block $r$.\n\nYou are to perform constrained maximum likelihood estimation for $(\\theta,\\Omega)$ under the normalization constraints\n$$\n\\sum_{i: g_i=r} \\theta_i = 1 \\quad \\text{for each } r \\in \\{1,\\dots,B\\}.\n$$\nIntroduce Lagrange multipliers $\\lambda_r \\in \\mathbb{R}$ to enforce these constraints. Starting from the product Poisson model for independent edges and the corresponding log-likelihood (up to additive constants that do not depend on parameters), set up the Lagrangian function and derive the stationarity conditions by taking partial derivatives with respect to $\\theta_i$, $\\Omega_{rs}$, and $\\lambda_r$ and setting them to zero. Express the conditions compactly in terms of the observed degrees $k_i$ and the block edge counts $m_{rs}$, and use the constraints to simplify the expressions wherever possible. Your final boxed answer should be the explicit analytic expression of the Lagrangian function with the constraint terms included. No numerical computation or rounding is required, and no physical units are involved.",
            "solution": "The problem asks for the constrained maximum likelihood estimation of the parameters of a Degree-Corrected Stochastic Block Model (DCSBM). We are to formulate the Lagrangian and derive the first-order stationarity conditions.\n\nThe probability mass function of a Poisson random variable $X$ with mean $\\mu$ is $P(X=k) = \\frac{\\mu^k e^{-\\mu}}{k!}$. According to the DCSBM, for each pair of nodes $(i,j)$ with $i<j$, the edge count $A_{ij}$ is drawn independently from a Poisson distribution with mean $\\theta_i \\theta_j \\Omega_{g_i g_j}$. The likelihood of observing the entire network $A$ is the product of these probabilities over all such pairs:\n$$\nL(\\theta, \\Omega | A) = \\prod_{i<j} \\frac{(\\theta_i \\theta_j \\Omega_{g_i g_j})^{A_{ij}} \\exp(-\\theta_i \\theta_j \\Omega_{g_i g_j})}{A_{ij}!}\n$$\nThe log-likelihood, up to additive constants that are independent of the parameters $(\\theta, \\Omega)$, is given by:\n$$\n\\mathcal{L}(\\theta, \\Omega) = \\sum_{i<j} \\left[ A_{ij} \\ln(\\theta_i \\theta_j \\Omega_{g_i g_j}) - \\theta_i \\theta_j \\Omega_{g_i g_j} \\right]\n$$\nWe can expand the logarithm term:\n$$\n\\mathcal{L}(\\theta, \\Omega) = \\sum_{i<j} \\left[ A_{ij}(\\ln \\theta_i + \\ln \\theta_j + \\ln \\Omega_{g_i g_j}) - \\theta_i \\theta_j \\Omega_{g_i g_j} \\right]\n$$\nThe problem requires imposing the normalization constraints $C_r(\\theta) = \\sum_{i: g_i=r} \\theta_i - 1 = 0$ for each block $r \\in \\{1, \\dots, B\\}$. We introduce Lagrange multipliers $\\lambda_r$ and form the Lagrangian function $\\mathcal{L}_C$:\n$$\n\\mathcal{L}_C(\\theta, \\Omega, \\lambda) = \\mathcal{L}(\\theta, \\Omega) - \\sum_{r=1}^B \\lambda_r C_r(\\theta) = \\sum_{i<j} \\left[ A_{ij}(\\ln \\theta_i + \\ln \\theta_j + \\ln \\Omega_{g_i g_j}) - \\theta_i \\theta_j \\Omega_{g_i g_j} \\right] - \\sum_{r=1}^B \\lambda_r \\left( \\sum_{i:g_i=r} \\theta_i - 1 \\right)\n$$\nTo find the maximum likelihood estimates, we derive the stationarity conditions by setting the partial derivatives of $\\mathcal{L}_C$ with respect to each parameter ($\\theta_i$, $\\Omega_{rs}$) and each Lagrange multiplier ($\\lambda_r$) to zero.\n\n1.  **Partial derivative with respect to $\\theta_i$**:\n    For a specific node $i$, terms involving $\\theta_i$ appear in the sum for all $j \\neq i$.\n    $$\n    \\frac{\\partial \\mathcal{L}_C}{\\partial \\theta_i} = \\sum_{j \\neq i} \\left( \\frac{A_{ij}}{\\theta_i} - \\theta_j \\Omega_{g_i g_j} \\right) - \\lambda_{g_i} = 0\n    $$\n    Using the definition of the observed degree $k_i = \\sum_{j \\neq i} A_{ij}$, this simplifies to:\n    $$\n    \\frac{k_i}{\\theta_i} - \\sum_{j \\neq i} \\theta_j \\Omega_{g_i g_j} - \\lambda_{g_i} = 0\n    $$\n    This gives the first stationarity condition:\n    $$\n    k_i = \\theta_i \\left( \\sum_{j \\neq i} \\theta_j \\Omega_{g_i g_j} + \\lambda_{g_i} \\right)\n    $$\n\n2.  **Partial derivative with respect to $\\Omega_{rs}$**:\n    Since $\\Omega$ is symmetric ($\\Omega_{rs} = \\Omega_{sr}$), we differentiate with respect to each unique element, corresponding to an unordered pair of blocks $\\{r, s\\}$.\n    $$\n    \\frac{\\partial \\mathcal{L}_C}{\\partial \\Omega_{rs}} = \\sum_{\\substack{i<j \\\\ \\{g_i,g_j\\}=\\{r,s\\}}} \\left( \\frac{A_{ij}}{\\Omega_{rs}} - \\theta_i \\theta_j \\right) = 0\n    $$\n    Using the definition of block edge counts $m_{rs}$, we get:\n    $$\n    \\frac{m_{rs}}{\\Omega_{rs}} - \\sum_{\\substack{i<j \\\\ \\{g_i,g_j\\}=\\{r,s\\}}} \\theta_i \\theta_j = 0\n    $$\n    This gives the second stationarity condition:\n    $$\n    m_{rs} = \\Omega_{rs} \\sum_{\\substack{i<j \\\\ \\{g_i,g_j\\}=\\{r,s\\}}} \\theta_i \\theta_j\n    $$\n    We can simplify the summation term using the constraints.\n    - If $r \\neq s$: The sum is over all pairs with one node in block $r$ and the other in $s$. This can be factored: $\\sum_{\\substack{i:g_i=r \\\\ j:g_j=s}} \\theta_i \\theta_j = (\\sum_{i:g_i=r} \\theta_i)(\\sum_{j:g_j=s} \\theta_j) = 1 \\cdot 1 = 1$.\n    The condition simplifies to $\\Omega_{rs} = m_{rs}$ for $r \\neq s$.\n    - If $r = s$: The sum is over pairs of distinct nodes both in block $r$. We use the identity $(\\sum_{i:g_i=r} \\theta_i)^2 = \\sum_{i:g_i=r} \\theta_i^2 + 2 \\sum_{i<j, g_i=g_j=r} \\theta_i \\theta_j$. With the constraint, this gives $1 = \\sum_{i:g_i=r} \\theta_i^2 + 2 \\sum_{i<j, g_i=g_j=r} \\theta_i \\theta_j$, so $\\sum_{i<j, g_i=g_j=r} \\theta_i \\theta_j = \\frac{1}{2}(1 - \\sum_{i:g_i=r} \\theta_i^2)$.\n    The condition becomes $m_{rr} = \\frac{1}{2} \\Omega_{rr} (1 - \\sum_{i:g_i=r} \\theta_i^2)$.\n\n3.  **Partial derivative with respect to $\\lambda_r$**:\n    $$\n    \\frac{\\partial \\mathcal{L}_C}{\\partial \\lambda_r} = - \\left( \\sum_{i:g_i=r} \\theta_i - 1 \\right) = 0\n    $$\n    This simply recovers the constraint equation: $\\sum_{i:g_i=r} \\theta_i = 1$.\n\nFinally, we can determine the value of the Lagrange multipliers $\\lambda_r$. Sum the first stationarity condition over all nodes $i$ in a block $r$:\n$$\n\\sum_{i:g_i=r} k_i = \\sum_{i:g_i=r} \\theta_i \\left( \\sum_{j \\neq i} \\theta_j \\Omega_{g_i g_j} + \\lambda_{g_i} \\right) = \\sum_{i:g_i=r} \\theta_i \\sum_{j \\neq i} \\theta_j \\Omega_{r,g_j} + \\lambda_r \\sum_{i:g_i=r} \\theta_i\n$$\nUsing the constraint, this is $\\sum_{i:g_i=r} k_i = \\sum_{i:g_i=r} \\sum_{j \\neq i} \\theta_i \\theta_j \\Omega_{r,g_j} + \\lambda_r$.\nThe a sum of observed degrees on the left is $\\sum_{i:g_i=r} k_i = 2m_{rr} + \\sum_{s \\neq r} m_{rs}$.\nThe summation on the right can be evaluated as:\n$\\sum_{s=1}^B \\Omega_{rs} \\sum_{i:g_i=r} \\sum_{j:g_j=s, j \\neq i} \\theta_i \\theta_j = \\Omega_{rr} (1-\\sum_{i:g_i=r} \\theta_i^2) + \\sum_{s \\neq r} \\Omega_{rs}(1)$.\nSubstituting the expressions for $\\Omega_{rs}$ from the second stationarity conditions, this becomes $\\frac{2m_{rr}}{1 - \\sum_{i:g_i=r}\\theta_i^2}(1-\\sum_{i:g_i=r} \\theta_i^2) + \\sum_{s \\neq r} m_{rs} = 2m_{rr} + \\sum_{s \\neq r} m_{rs}$.\nThus, the equation becomes $\\sum_{i:g_i=r} k_i = \\sum_{i:g_i=r} k_i + \\lambda_r$, which implies $\\lambda_r = 0$ for all $r$.\n\nThe simplified stationarity conditions are therefore:\n1. $k_i = \\theta_i \\sum_{j \\neq i} \\theta_j \\Omega_{g_i g_j}$ for all $i \\in \\{1,\\dots,n\\}$.\n2. For $r \\neq s$, $\\Omega_{rs} = m_{rs}$.\n3. For $r=s$, $\\Omega_{rr} = \\frac{2 m_{rr}}{1 - \\sum_{i:g_i=r} \\theta_i^2}$.\n4. $\\sum_{i:g_i=r} \\theta_i = 1$ for all $r \\in \\{1,\\dots,B\\}$.\n\nThe problem asks for the explicit analytic expression of the Lagrangian function as the final answer.",
            "answer": "$$\n\\boxed{\\mathcal{L}_{C}(\\theta, \\Omega, \\lambda) = \\sum_{i<j} \\left( A_{ij} (\\ln \\theta_i + \\ln \\theta_j + \\ln \\Omega_{g_i g_j}) - \\theta_i \\theta_j \\Omega_{g_i g_j} \\right) - \\sum_{r=1}^B \\lambda_r \\left( \\sum_{i:g_i=r} \\theta_i - 1 \\right)}\n$$"
        },
        {
            "introduction": "Fitting a model does not guarantee that it provides a meaningful description of the data; we must test its validity. A critical step in network analysis is to ask whether the community structure found by the DCSBM is a genuine feature or simply an artifact of node degree variations. This exercise  walks you through constructing a likelihood ratio test to formally compare the DCSBM against the simpler configuration model, providing a powerful statistical tool to validate the significance of detected communities.",
            "id": "4272165",
            "problem": "Consider an undirected multigraph with $n$ vertices and $m$ edges, possibly including multi-edges and self-edges, generated from a degree-corrected model. Each vertex $i$ has a known community assignment $g_i \\in \\{1,\\dots,B\\}$. Let $m_{rs}$ denote the number of edges with endpoints in communities $r$ and $s$ for $r \\neq s$, and let $m_{rr}$ denote the number of edges with both endpoints in community $r$. Define the total number of stubs in community $r$ by $\\kappa_r = \\sum_{i: g_i = r} k_i$, where $k_i$ is the degree of vertex $i$; equivalently, $\\kappa_r = 2 m_{rr} + \\sum_{s \\neq r} m_{rs}$ by double-counting stubs contributed by within- and between-community edges. The observed block-edge counts satisfy $m = \\sum_{r \\leq s} m_{rs}$.\n\nYou will compare the configuration model (null hypothesis) to a Degree-Corrected Stochastic Block Model (DCSBM) alternative with a specified symmetric, strictly positive $B \\times B$ block interaction matrix $\\Omega = (\\Omega_{rs})$. Work in the canonical sparse regime in which block-pair edge placements are independent and the block-level edge counts $m_{rs}$ can be approximated as Poisson random variables with means proportional to the product of the community stub totals. Specifically, for unordered block pairs $(r,s)$ with $r \\neq s$, use baseline weights $B_{rs} = \\kappa_r \\kappa_s$, and for $(r,r)$ use $B_{rr} = \\frac{1}{2}\\kappa_r (\\kappa_r - 1)$. Under the configuration model null, the probability that a uniformly random edge falls into block pair $(r,s)$ is proportional to $B_{rs}$; under the DCSBM alternative, it is proportional to $\\Omega_{rs} B_{rs}$. With $m$ edges, approximate the block counts $m_{rs}$ as independent Poisson variables with means $\\mu_{rs}^{(0)} = m \\frac{B_{rs}}{\\sum_{a \\leq b} B_{ab}}$ under the null and $\\mu_{rs}^{(1)} = m \\frac{\\Omega_{rs} B_{rs}}{\\sum_{a \\leq b} \\Omega_{ab} B_{ab}}$ under the alternative. This approximation is a well-tested consequence of the sparse edge-placement limit and the additivity of independent Poisson processes.\n\nConstruct the likelihood ratio test (LRT) comparing the configuration model (null) to the specified DCSBM (alternative), and derive an explicit closed-form expression for the LRT statistic $D = 2 \\ln \\Lambda$ solely in terms of the observed block counts $m_{rs}$ and the specified $\\Omega$. Your final expression must eliminate $\\kappa_r$ in favor of $m_{rs}$ via $\\kappa_r = 2 m_{rr} + \\sum_{s \\neq r} m_{rs}$ and must be written as a single analytic expression. No numerical evaluation is required.",
            "solution": "The likelihood ratio test is constructed to compare the two nested hypotheses: the configuration model ($H_0$) and the Degree-Corrected Stochastic Block Model ($H_1$). The test statistic is based on the ratio of likelihoods of observing the data $\\{m_{rs}\\}_{1 \\le r \\le s \\le B}$ under each model.\n\nThe problem states that the block-level edge counts $m_{rs}$ are approximated as independent Poisson random variables. The probability mass function for a Poisson random variable with mean $\\mu$ is $P(k; \\mu) = \\frac{\\mu^k \\exp(-\\mu)}{k!}$. The likelihood function under a given hypothesis is the product of these probabilities over all unordered block pairs $(r,s)$.\n\nUnder the null hypothesis $H_0$, the likelihood is:\n$$ L_0 = P(\\{m_{rs}\\} | H_0) = \\prod_{1 \\le r \\le s \\le B} \\frac{(\\mu_{rs}^{(0)})^{m_{rs}} \\exp(-\\mu_{rs}^{(0)})}{m_{rs}!} $$\n\nUnder the alternative hypothesis $H_1$, the likelihood is:\n$$ L_1 = P(\\{m_{rs}\\} | H_1) = \\prod_{1 \\le r \\le s \\le B} \\frac{(\\mu_{rs}^{(1)})^{m_{rs}} \\exp(-\\mu_{rs}^{(1)})}{m_{rs}!} $$\n\nThe likelihood ratio $\\Lambda$ is the ratio of the alternative likelihood to the null likelihood:\n$$ \\Lambda = \\frac{L_1}{L_0} = \\frac{\\prod_{r \\le s} (\\mu_{rs}^{(1)})^{m_{rs}} \\exp(-\\mu_{rs}^{(1)}) / m_{rs}!}{\\prod_{r \\le s} (\\mu_{rs}^{(0)})^{m_{rs}} \\exp(-\\mu_{rs}^{(0)}) / m_{rs}!} = \\prod_{r \\le s} \\left( \\frac{\\mu_{rs}^{(1)}}{\\mu_{rs}^{(0)}} \\right)^{m_{rs}} \\exp\\left( -(\\mu_{rs}^{(1)} - \\mu_{rs}^{(0)}) \\right) $$\n\nThe log-likelihood ratio is:\n$$ \\ln \\Lambda = \\sum_{r \\le s} \\left[ m_{rs} \\ln\\left(\\frac{\\mu_{rs}^{(1)}}{\\mu_{rs}^{(0)}}\\right) - (\\mu_{rs}^{(1)} - \\mu_{rs}^{(0)}) \\right] $$\n\nLet us define the normalization constants $C_0 = \\sum_{a \\le b} B_{ab}$ and $C_1 = \\sum_{a \\le b} \\Omega_{ab} B_{ab}$. The means are $\\mu_{rs}^{(0)} = m \\frac{B_{rs}}{C_0}$ and $\\mu_{rs}^{(1)} = m \\frac{\\Omega_{rs} B_{rs}}{C_1}$. The ratio of the means is:\n$$ \\frac{\\mu_{rs}^{(1)}}{\\mu_{rs}^{(0)}} = \\frac{m \\frac{\\Omega_{rs} B_{rs}}{C_1}}{m \\frac{B_{rs}}{C_0}} = \\frac{\\Omega_{rs} C_0}{C_1} $$\n\nThe term involving the difference of means is:\n$$ \\sum_{r \\le s} (\\mu_{rs}^{(1)} - \\mu_{rs}^{(0)}) = \\sum_{r \\le s} \\left( m \\frac{\\Omega_{rs} B_{rs}}{C_1} - m \\frac{B_{rs}}{C_0} \\right) = \\frac{m}{C_1} \\sum_{r \\le s} \\Omega_{rs} B_{rs} - \\frac{m}{C_0} \\sum_{r \\le s} B_{rs} $$\nBy definition of $C_1$ and $C_0$, this simplifies to:\n$$ \\frac{m}{C_1} (C_1) - \\frac{m}{C_0} (C_0) = m - m = 0 $$\n\nSubstituting these results back into the expression for $\\ln \\Lambda$:\n$$ \\ln \\Lambda = \\sum_{r \\le s} m_{rs} \\ln\\left(\\frac{\\Omega_{rs} C_0}{C_1}\\right) = \\sum_{r \\le s} m_{rs} \\ln(\\Omega_{rs}) + \\sum_{r \\le s} m_{rs} (\\ln(C_0) - \\ln(C_1)) $$\nSince $\\sum_{r \\le s} m_{rs} = m$, we get:\n$$ \\ln \\Lambda = \\sum_{r \\le s} m_{rs} \\ln(\\Omega_{rs}) + m \\ln(C_0) - m \\ln(C_1) = \\sum_{r \\le s} m_{rs} \\ln(\\Omega_{rs}) - m \\ln\\left(\\frac{C_1}{C_0}\\right) $$\n\nThe required statistic is $D = 2 \\ln \\Lambda$:\n$$ D = 2 \\sum_{r \\le s} m_{rs} \\ln(\\Omega_{rs}) - 2m \\ln\\left(\\frac{\\sum_{a \\le b} \\Omega_{ab} B_{ab}}{\\sum_{a \\le b} B_{ab}}\\right) $$\n\nTo obtain the final expression, we must express all terms as functions of $m_{rs}$ and $\\Omega$.\nThe total number of edges is $m = \\sum_{a \\le b} m_{ab}$.\nThe community stub counts are given by $\\kappa_r = 2 m_{rr} + \\sum_{s \\neq r} m_{rs}$. Since the graph is undirected, $m_{rs} = m_{sr}$, and the provided data $\\{m_{rs}\\}$ are for $r \\le s$, we can write this sum as $\\kappa_r = 2 m_{rr} + \\sum_{s < r} m_{sr} + \\sum_{s > r} m_{rs}$.\nThe baseline weights $B_{rs}$ are defined in terms of $\\kappa_r$.\n\nThe denominator sum, $C_0 = \\sum_{a \\le b} B_{ab}$, can be simplified. It represents the total number of pairs of stubs in the configuration model framework:\n$$ \\sum_{a \\le b} B_{ab} = \\sum_{a < b} \\kappa_a \\kappa_b + \\sum_{a=1}^B \\frac{1}{2}\\kappa_a(\\kappa_a-1) = \\frac{1}{2} \\left[ \\left(\\sum_a \\kappa_a\\right)^2 - \\sum_a \\kappa_a^2 \\right] + \\frac{1}{2} \\left[ \\sum_a \\kappa_a^2 - \\sum_a \\kappa_a \\right] = \\frac{1}{2} \\left[ \\left(\\sum_a \\kappa_a\\right)^2 - \\sum_a \\kappa_a \\right] $$\nThe total number of stubs is $\\sum_a \\kappa_a = \\sum_a \\sum_{i:g_i=a} k_i = \\sum_i k_i = 2m$.\nThus, $C_0 = \\frac{1}{2}((2m)^2 - 2m) = 2m^2 - m$.\n\nThe numerator sum, $C_1 = \\sum_{a \\le b} \\Omega_{ab} B_{ab}$, does not simplify as neatly due to the $\\Omega_{ab}$ weights. We must write it out by substituting the definitions of $B_{ab}$ and $\\kappa_a$.\n\nSubstituting all components yields the final expression for $D$ solely in terms of $\\{m_{rs}\\}_{r \\le s}$ and $\\{\\Omega_{rs}\\}$.",
            "answer": "$$\n\\boxed{\n2 \\sum_{1 \\le r \\le s \\le B} m_{rs} \\ln(\\Omega_{rs}) - 2 \\left( \\sum_{1 \\le i \\le j \\le B} m_{ij} \\right) \\ln\\left( \\frac{\\sum_{1 \\le a < b \\le B} \\Omega_{ab} \\left(2 m_{aa} + \\sum_{t<a} m_{ta} + \\sum_{t>a} m_{at}\\right)\\left(2 m_{bb} + \\sum_{u<b} m_{ub} + \\sum_{u>b} m_{bu}\\right) + \\sum_{a=1}^B \\frac{\\Omega_{aa}}{2} \\left(2 m_{aa} + \\sum_{t<a} m_{ta} + \\sum_{t>a} m_{at}\\right)\\left(2 m_{aa} + \\sum_{t<a} m_{ta} + \\sum_{t>a} m_{at} - 1\\right)}{2\\left(\\sum_{1 \\le c \\le d \\le B} m_{cd}\\right)^2 - \\left(\\sum_{1 \\le c \\le d \\le B} m_{cd}\\right)} \\right)\n}\n$$"
        }
    ]
}