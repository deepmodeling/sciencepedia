{
    "hands_on_practices": [
        {
            "introduction": "我们从一个基础但至关重要的练习开始，它旨在阐明度校正随机块模型（DCSBM）中核心参数的物理意义。通过推导模型参数与网络可观测宏观统计量之间的关系，我们可以更直观地理解模型的内在机制。这项实践将揭示，在特定的归一化条件下，块间亲和力矩阵 $\\Omega$ 中的元素 $\\omega_{rs}$ 直接对应于连接社区 $r$ 和 $s$ 的期望边数，为抽象的数学参数赋予了清晰的物理诠释。",
            "id": "4272166",
            "problem": "考虑一个由度校正随机块模型（DCSBM）生成的包含 $N$ 个顶点的有向多重图。每个顶点 $i \\in \\{1,\\dots,N\\}$ 被分配一个块标签 $g_i \\in \\{1,\\dots,B\\}$ 和一个正的度参数 $\\theta_i > 0$。设 $\\Omega$ 是一个 $B \\times B$ 的非负块亲和矩阵，其元素为 $\\omega_{rs}$，$r,s \\in \\{1,\\dots,B\\}$。邻接矩阵 $A$ 的元素 $A_{ij}$ 是独立的泊松随机变量，其速率参数为 $\\lambda_{ij} = \\theta_i \\theta_j \\,\\omega_{g_i g_j}$，适用于所有有序对 $(i,j)$，包括 $i=j$ 的情况。定义从块 $r$ 到块 $s$ 的总边数为\n$$\nm_{rs} = \\sum_{i: g_i = r} \\sum_{j: g_j = s} A_{ij}.\n$$\n假设存在块级归一化约束\n$$\n\\sum_{i: g_i = r} \\theta_i = 1 \\quad \\text{for every} \\quad r \\in \\{1,\\dots,B\\}.\n$$\n从泊松随机变量期望的基本定义和期望的线性性质出发，推导 $\\mathbb{E}[m_{rs}]$ 关于块亲和矩阵元素的闭式表达式。你的最终答案必须是一个单一的闭式解析表达式。",
            "solution": "目标是推导 $\\mathbb{E}[m_{rs}]$ 的闭式表达式，即从块 $r$ 到块 $s$ 的预期总边数。我们从问题陈述中给出的 $m_{rs}$ 的定义开始：\n$$\nm_{rs} = \\sum_{i: g_i = r} \\sum_{j: g_j = s} A_{ij}\n$$\n在这里，$g_i$ 是顶点 $i$ 的块标签，求和遍历块 $r$ 中的所有顶点 $i$ 和块 $s$ 中的所有顶点 $j$。\n\n为了求 $m_{rs}$ 的期望，我们应用期望的线性性质。随机变量之和的期望等于它们各自期望之和。\n$$\n\\mathbb{E}[m_{rs}] = \\mathbb{E}\\left[ \\sum_{i: g_i = r} \\sum_{j: g_j = s} A_{ij} \\right] = \\sum_{i: g_i = r} \\sum_{j: g_j = s} \\mathbb{E}[A_{ij}]\n$$\n问题陈述指出，邻接矩阵的每个元素 $A_{ij}$ 是一个独立的泊松随机变量，其速率参数为 $\\lambda_{ij}$。泊松分布的一个基本性质是其期望等于其速率参数。因此，对于随机变量 $X \\sim \\text{Poisson}(\\lambda)$，我们有 $\\mathbb{E}[X] = \\lambda$。将此性质应用于 $A_{ij}$，我们得到：\n$$\n\\mathbb{E}[A_{ij}] = \\lambda_{ij}\n$$\n将此代入 $\\mathbb{E}[m_{rs}]$ 的表达式中，得到：\n$$\n\\mathbb{E}[m_{rs}] = \\sum_{i: g_i = r} \\sum_{j: g_j = s} \\lambda_{ij}\n$$\n接下来，我们使用度校正随机块模型（DCSBM）的速率参数 $\\lambda_{ij}$ 的定义，其形式如下：\n$$\n\\lambda_{ij} = \\theta_i \\theta_j \\,\\omega_{g_i g_j}\n$$\n其中 $\\theta_i$ 和 $\\theta_j$ 分别是顶点 $i$ 和 $j$ 的度参数，而 $\\omega_{g_i g_j}$ 是块亲和矩阵 $\\Omega$ 中对应于顶点 $i$ 和 $j$ 所在块的元素。\n\n将 $\\lambda_{ij}$ 的这个表达式代入我们关于 $\\mathbb{E}[m_{rs}]$ 的方程中：\n$$\n\\mathbb{E}[m_{rs}] = \\sum_{i: g_i = r} \\sum_{j: g_j = s} \\theta_i \\theta_j \\,\\omega_{g_i g_j}\n$$\n在这个双重求和的范围内，索引 $i$ 遍历所有属于块 $r$ 的顶点（因此 $g_i = r$），索引 $j$ 遍历所有属于块 $s$ 的顶点（因此 $g_j = s$）。因此，对于此和中的每一项，块亲和项 $\\omega_{g_i g_j}$ 都是常数，等于 $\\omega_{rs}$。我们可以将这个常数项从求和中提取出来：\n$$\n\\mathbb{E}[m_{rs}] = \\omega_{rs} \\sum_{i: g_i = r} \\sum_{j: g_j = s} \\theta_i \\theta_j\n$$\n剩下的双重求和可以分解为两个独立求和的乘积，因为项 $\\theta_i$ 不依赖于内部求和索引 $j$，而项 $\\theta_j$ 不依赖于外部求和索引 $i$：\n$$\n\\sum_{i: g_i = r} \\sum_{j: g_j = s} \\theta_i \\theta_j = \\left( \\sum_{i: g_i = r} \\theta_i \\right) \\left( \\sum_{j: g_j = s} \\theta_j \\right)\n$$\n此时，我们使用问题陈述中给出的块级归一化约束：\n$$\n\\sum_{k: g_k = q} \\theta_k = 1 \\quad \\text{for every block} \\quad q \\in \\{1,\\dots,B\\}\n$$\n将此约束应用于我们乘积中的每个求和：\n第一个求和是针对块 $r$ 中的所有顶点 $i$，所以：\n$$\n\\sum_{i: g_i = r} \\theta_i = 1\n$$\n第二个求和是针对块 $s$ 中的所有顶点 $j$，所以：\n$$\n\\sum_{j: g_j = s} \\theta_j = 1\n$$\n因此，这两个求和的乘积等于 $1 \\times 1 = 1$。\n\n将此结果代回我们关于 $\\mathbb{E}[m_{rs}]$ 的表达式中，我们得到最终的表达式：\n$$\n\\mathbb{E}[m_{rs}] = \\omega_{rs} \\times 1 = \\omega_{rs}\n$$\n这个结果表明，在给定的归一化条件下，块亲和矩阵 $\\Omega$ 的元素直接对应于相应块之间的预期总边数。",
            "answer": "$$\\boxed{\\omega_{rs}}$$"
        },
        {
            "introduction": "理解了模型参数的含义之后，下一个关键问题是：为什么“度校正”这一项至关重要？此练习  通过一个精心设计的思想实验，帮助我们深入理解度异质性对社区发现的潜在干扰。它揭示了普通的随机块模型（SBM）可能错误地将网络中的高 度节点（“枢纽”）识别为一个独立的社区，从而推断出并不存在的“伪社团结构”。通过这个练习，你将能深刻体会到 DCSBM 在解耦节点度异质性与真实社区结构方面的核心优势。",
            "id": "4118157",
            "problem": "一个邻接矩阵为 $A \\in \\{0,1\\}^{n \\times n}$ 的无向稀疏网络是由一个潜在分组过程生成的。复杂自适应系统中社群结构的两个标准生成模型是随机块模型 (SBM) 和度校正随机块模型 (DC-SBM)。随机块模型 (SBM) 假设两个节点之间存在边的概率仅通过一个块亲和矩阵取决于它们的潜在组标签，而度校正随机块模型 (DC-SBM) 则通过引入节点特定的度参数来扩展这一点，这些参数调节每个块内的期望度。从这些核心定义出发，确定在何种情况下，DC-SBM 在满足通常可识别性约束的重参数化下等价于 SBM，并找出一个具体的合成数据生成过程，以证明度校正如何能够防止因度异质性而非真实的社群偏好差异而产生的伪同配性的推断。\n\n选择一个选项，该选项同时给出了 DC-SBM 简化为 SBM 的一个充分必要条件（在经过适当的重参数化后产生相同图分布族的精确意义上），并描述了一个科学上现实的合成设置，在该设置中，度校正移除了一个普通 SBM 否则会推断出的伪同配结构。\n\nA. 条件：存在块特定的常数 $\\{c_{r} : r \\in \\{1,\\dots, K\\}\\}$，使得对每个节点 $i$ 都有 $\\theta_{i} = c_{g_{i}}$，并且在标准的可识别性归一化 $\\frac{1}{n_{r}}\\sum_{i: g_{i}=r} \\theta_{i} = 1$ 下，对所有 $r$ 都有 $c_{r} = 1$，因此 DC-SBM 精确地简化为一个具有重参数化块亲和矩阵的 SBM。示例：取 $n=400$，$K=2$，潜在标签 $g_{i}$ 在 $\\{1,2\\}$ 上独立且均匀分布，以及一个在所有节点对上同质的对称块亲和矩阵，基准率为 $B_{11} = B_{12} = B_{22} = \\lambda / n$，其中 $\\lambda = 8$（稀疏区域）。从一个重尾分布中抽取独立的节点特定乘子 $\\theta_{i}$，例如 $\\theta_{i} \\propto X_{i}$ 且 $X_{i} \\sim \\text{Pareto}(\\alpha=3)$，并重新缩放以使 $\\frac{1}{n}\\sum_{i=1}^{n} \\theta_{i} = 1$。在此设置中，真实的图没有按组划分的同配性，只有度异质性。一个普通的 SBM，由于缺少节点特定的度参数，会倾向于将高度节点分组在一起，并估计出 $B_{11} > B_{12} \\approx B_{22}$，从而为解释中心节点而推断出伪同配性，而 DC-SBM 会将度变异吸收到 $\\theta_{i}$ 中，并正确地估计出没有同配性。\n\nB. 条件：块大小相等，即对所有 $r$ 都有 $n_{r} = n/K$，因此 DC-SBM 简化为 SBM。示例：取 $n=300$，$K=3$，大小相等的块，令 $B_{11} = 0.08$，$B_{22} = 0.02$，$B_{33} = 0.02$，且对于 $r \\neq s$ 有 $B_{rs} = 0.01$，$\\theta_{i}$ 独立同分布于 $[0.9,1.1]$ 上的均匀分布。这表明一个普通的 SBM 可能会过度拟合同配性，但 DC-SBM 会避免它。\n\nC. 条件：块亲和矩阵是对角矩阵，即对于 $r \\neq s$ 有 $B_{rs} = 0$，因此 DC-SBM 简化为 SBM。示例：取 $n=200$，$K=2$，$B_{11} = 0.06$，$B_{22} = 0.06$，$B_{12} = 0$，并从一个对数正态分布中抽取 $\\theta_{i}$，并进行归一化，使得对每个 $r$ 都有 $\\frac{1}{n_{r}} \\sum_{i: g_{i}=r} \\theta_{i} = 1$。这证明了度校正消除了伪同配性。\n\nD. 条件：度参数的总和在各块之间是平衡的，即 $\\sum_{i: g_{i}=1} \\theta_{i} = \\cdots = \\sum_{i: g_{i}=K} \\theta_{i}$，因此 DC-SBM 简化为 SBM。示例：取 $n=500$，$K=2$，有 $50$ 个大小为 $\\theta_{i} = 4$ 的中心节点均匀分布在各个块中，其余 $450$ 个节点的大小为 $\\theta_{i} = 2/3$，使得 $\\sum_{i: g_{i}=1} \\theta_{i} = \\sum_{i: g_{i}=2} \\theta_{i}$，并令 $B_{11} = B_{12} = B_{22} = 10/n$。在这种情况下，一个普通的 SBM 不会推断出同配性，而 DC-SBM 会，因为它过度拟合了度。",
            "solution": "该问题要求我们首先确定度校正随机块模型 (DC-SBM) 在何种充分必要条件下等价于标准随机块模型 (SBM)，其次，描述一个合成数据生成过程，该过程能正确说明 SBM 中伪同配性推断的问题，而 DC-SBM 正是为防止此问题而设计的。\n\n让我们首先将模型和等价性概念形式化。\n设 $A \\in \\{0, 1\\}^{n \\times n}$ 是一个 $n$ 个节点的无向网络的邻接矩阵。设 $g_i \\in \\{1, \\dots, K\\}$ 是节点 $i$ 的潜在组分配。\n\n随机块模型 (SBM) 假定节点 $i$ 和 $j$ 之间存在边的概率完全由它们的组成员身份决定：\n$$P(A_{ij} = 1) = B_{g_i, g_j}$$\n其中 $B \\in [0, 1]^{K \\times K}$ 是对称的块亲和矩阵。\n\n度校正随机块模型 (DC-SBM) 通过引入节点特定的度参数 $\\theta_i > 0$ 来扩展此模型：\n$$P(A_{ij} = 1) = \\theta_i \\theta_j B_{g_i, g_j}$$\n参数 $\\theta_i$ 旨在捕捉无法由社群结构 $g$ 和亲和矩阵 $B$ 解释的度异质性。项 $\\theta_i \\theta_j$ 调节了基准连接概率 $B_{g_i, g_j}$。为了使概率有良好定义，必须满足 $\\max_{i,j} \\theta_i \\theta_j B_{g_i, g_j} \\le 1$。\n\n如果对于一组给定的 DC-SBM 参数 $(\\{\\theta_i\\}, \\{g_i\\}, B)$，存在一个 SBM 亲和矩阵 $B'$，使得生成的图上的概率分布完全相同，则称 DC-SBM 等价于 SBM。这要求所有节点对 $(i, j)$ 的边概率都匹配：\n$$\\theta_i \\theta_j B_{g_i, g_j} = B'_{g_i, g_j}$$\n根据 SBM 的定义，右侧仅取决于组索引 $g_i$ 和 $g_j$。因此，左侧也必须仅是 $g_i$ 和 $g_j$ 的函数。让我们假设一个非退化情况，其中对于所有组对 $(r, s)$ 都有 $B_{rs} > 0$。这意味着乘积 $\\theta_i \\theta_j$ 必须仅是 $(g_i, g_j)$ 的函数。我们将其写作 $\\theta_i \\theta_j = f(g_i, g_j)$，其中 $f$ 是某个函数。\n\n现在，考虑属于同一组（例如组 $r$）的任意两个节点 $i$ 和 $k$，因此 $g_i = g_k = r$。设 $j$ 是组 $s$ 中的任何其他节点（其中 $s$ 可以等于 $r$）。根据我们的条件，我们必须有：\n$$\\theta_i \\theta_j = f(r, s)$$\n$$\\theta_k \\theta_j = f(r, s)$$\n如果我们假设 $\\theta_j > 0$ （因为 $\\theta_j=0$ 的节点是孤立的，可以忽略），我们可以得出 $\\theta_i \\theta_j = \\theta_k \\theta_j$，这意味着 $\\theta_i = \\theta_k$。由于这对于同一组 $r$ 内的任何两个节点 $i, k$ 都必须成立，并且对于任何组 $r$ 也都成立，因此度参数 $\\theta_i$ 在每个组内必须是常数。\n这意味着必须存在一组常数 $\\{c_1, c_2, \\dots, c_K\\}$，使得对于每个节点 $i$，$\\theta_i = c_{g_i}$。这是一个必要条件。\n\n为了证明其充分性，假设 $\\theta_i = c_{g_i}$。DC-SBM 的边概率变为：\n$$P(A_{ij} = 1) = c_{g_i} c_{g_j} B_{g_i, g_j}$$\n我们可以定义一个新的块亲和矩阵 $B'$，其元素为 $B'_{rs} = c_r c_s B_{rs}$。使用这个新矩阵，边概率为 $P(A_{ij} = 1) = B'_{g_i, g_j}$，这正是 SBM 的公式。因此，该条件也是充分的。\n\n问题陈述中包含了“与通常的可识别性约束一致”这一短语。在 DC-SBM 中，存在一个缩放模糊性：我们可以对组 $r$ 中的所有 $i$ 将 $\\theta_i$ 缩放为 $\\lambda_r \\theta_i$，同时对所有 $s$ 将亲和矩阵 $B_{rs}$ 缩放为 $(\\lambda_r \\lambda_s)^{-1} B_{rs}$，而不会改变边概率。为了解决这个问题，一个常见的约束是在每个块内对度参数进行归一化。一个典型的归一化是要求每个块中 $\\theta_i$ 的平均值为 $1$：\n$$\\frac{1}{n_r} \\sum_{i: g_i=r} \\theta_i = 1 \\quad \\text{对于每个 } r \\in \\{1, \\dots, K\\}$$\n其中 $n_r$ 是组 $r$ 中的节点数。如果我们将此约束应用于我们导出的条件 $\\theta_i = c_{g_i}$，我们得到：\n$$\\frac{1}{n_r} \\sum_{i: g_i=r} c_r = 1 \\implies \\frac{1}{n_r} (n_r c_r) = 1 \\implies c_r = 1$$\n这必须对所有块 $r$ 都成立。因此，在这种标准的可识别性约束下，DC-SBM 当且仅当对所有节点 $i$ 都有 $\\theta_i = 1$ 时才简化为 SBM。在这种情况下，DC-SBM 公式 $P(A_{ij} = 1) = \\theta_i \\theta_j B_{g_i, g_j}$ 变得与 SBM 公式 $P(A_{ij} = 1) = B_{g_i, g_j}$ 完全相同，无需对 $B$ 进行重参数化。\n\n对于问题的第二部分，我们需要一个例子，其中普通的 SBM 从一个没有同配性的网络中推断出伪同配性。同配性意味着节点优先连接到相同类型的节点，在 SBM 的背景下，这转化为 $B_{rr}$ 显著大于非对角项 $B_{rs}$（对于 $r \\ne s$）。伪同配性意味着在真实生成过程中不存在这种结构时，却被推断出来。\n当存在与真实社群结构不相关的显著度异质性时，会发生这种现象。考虑一个真实的 DC-SBM，其中块亲和矩阵 $B$ 是常数，例如，对所有 $r, s$ 都有 $B_{rs} = b$。这代表了一个没有内在社群偏好（没有同配性）的模型。真实的边概率是 $P(A_{ij} = 1) = \\theta_i \\theta_j b$。现在，让度参数 $\\{\\theta_i\\}$ 从一个高方差的分布（例如像帕累托或对数正态这样的重尾分布）中抽取，且与组分配 $\\{g_i\\}$ 无关。这会产生具有高 $\\theta_i$ 的“中心”节点和许多低度节点。\n当将标准 SBM 拟合到从此过程生成的网络时，它缺少 $\\theta_i$ 参数来解释观察到的度变异。它观察到中心节点之间连接紧密（因为对于两个中心节点 $i,j$，$\\theta_i \\theta_j$ 很大），而与低度节点连接稀疏。为了解释这种观察到的连接模式，SBM 的推断算法会倾向于将高度中心节点放入一个社群（比如，组1），将低度节点放入另一个社群（组2）。通过这样做，它可以将推断的亲和力 $B'_{11}$ 设置得很高，以解释中心节点之间的密集连接，并将 $B'_{12}$ 和 $B'_{22}$ 设置得较低。结果是推断出 $B'_{11} > B'_{12} \\approx B'_{22}$ 的结构，这是同配混合的标志。这种同配性是伪的，因为它是模型无法处理度异质性的产物，而不是生成过程的真实特征。\n相比之下，DC-SBM 将使用其 $\\theta_i$ 参数来捕捉度异质性，正确地为中心节点分配大的 $\\theta_i$ 值。这将使亲和矩阵 $B$ 来解释残余模式，在这种情况下，该模式是平坦的，从而正确地推断出没有同配性。\n\n现在我们基于此分析评估给出的选项。\n\nA. 条件：该条件指出对于块特定的常数 $c_r$，有 $\\theta_i = c_{g_i}$。这正是我们推导出的充分必要条件。它还正确地指出，在使用标准归一化 $\\frac{1}{n_r}\\sum_{i:g_i=r}\\theta_i=1$ 时，这意味着对所有 $r$ 都有 $c_r=1$。这部分是正确的。\n示例：该示例设置了一个非同配的真实情况（$B_{11} = B_{12} = B_{22} = \\lambda/n$），并通过一个用于 $\\theta_i$ 参数的重尾帕累托分布引入了显著的度异质性，并明确指出这种异质性与组标签无关。然后它正确地得出结论，SBM 会通过将高度节点分组来错误解释这一点，导致估计出 $B_{11} > B_{12} \\approx B_{22}$（伪同配性），而 DC-SBM 会将度方差吸收到 $\\theta_i$ 参数中，并正确地识别出不存在同配性。这个例子完美地说明了所要求的现象。\n结论：**正确**。\n\nB. 条件：条件是块大小相等，即 $n_r = n/K$。这对单个 $\\theta_i$ 参数的值没有影响。即使块大小相等，$\\theta_i$ 的值也可以是高度异质的。因此，这个条件不会导致 DC-SBM 简化为 SBM。这个条件是错误的。\n示例：该示例使用的 $\\theta_i$ 是从一个非常窄的分布 $[0.9, 1.1]$ 中抽取的，这对应于度异质性很小的情况。这恰恰是 SBM 和 DC-SBM 预期表现相似的情况。它未能设置 DC-SBM 的校正最需要的情境。\n结论：**错误**。\n\nC. 条件：条件是块亲和矩阵是对角矩阵，即对于 $r \\ne s$ 有 $B_{rs} = 0$。这意味着社群之间是相互断开的。然而，在每个社群内部，仍然可能存在显著的度异质性（即非恒定的 $\\theta_i$）。在这种情况下，一个普通的 SBM 可能仍然会错误地将一个真实的社群划分为一个“中心”子社群和一个“外围”子社群来解释度方差。在这种条件下，DC-SBM 不会简化为 SBM。这个条件是错误的。\n示例：该示例使用一个对角 $B$ 矩阵。它正确地指出了使用对数正态分布为 $\\theta_i$ 创建异质性。然而，它声称这个设置展示了伪同配性的消除。这里的真实情况是*最大程度*同配的（$B_{12}=0$）。SBM 不会推断*伪*同配性；它会试图拟合一个本身就包含度异质性的强同配结构。这个例子选择得很差，未能说明在没有同配性的地方创造同配性的具体现象。\n结论：**错误**。\n\nD. 条件：条件是度参数的总和在各块之间是平衡的，即 $\\sum_{i:g_i=r} \\theta_i = \\text{const}$。这不是等价的正确条件。等价性取决于单个 $\\theta_i$ 值在块内是常数，而不是块级总和相等。\n示例：该示例表明一个普通的 SBM *不会*推断出同配性，而 DC-SBM *会*。这与这些模型的已知行为完全相反。SBM 是倾向于从度异质性中推断出伪同配性的模型。DC-SBM 是为纠正此问题而设计的，而不是引入它。示例中的解释在事实上是错误的。\n结论：**错误**。\n\n基于对充分必要条件和说明性示例的透彻分析，选项 A 是唯一一个在两方面都正确的选项。",
            "answer": "$$\\boxed{A}$$"
        },
        {
            "introduction": "掌握了模型的基本诠释和其理论优势后，我们进入一个更具实践性的环节：如何根据观测到的网络数据来估计模型的参数。此练习  将引导你使用最大似然估计（MLE）这一经典统计方法，在满足模型可识别性约束的条件下，推导出 DCSBM 参数的估计方程。通过构建拉格朗日函数并求解其平稳点条件，你将亲手揭示连接网络观测数据（如节点度、块间边数）与模型未知参数（$\\theta$ 和 $\\Omega$）之间的数学桥梁，这是任何模型应用者都需具备的核心技能。",
            "id": "4272149",
            "problem": "考虑一个由度校正随机块模型（DCSBM）生成的包含 $N$ 个顶点的有向多重图，与练习1的设定相同。对于所有有序对 $(i,j)$，边数 $A_{ij}$ 是独立的泊松随机变量，其速率为 $\\lambda_{ij} = \\theta_i \\theta_j \\Omega_{g_i g_j}$（这里我们假设出度和入度参数相同，即 $\\theta_i = \\phi_i$）。给定观测到的邻接矩阵 $A$ 和已知的块分配 $\\{g_i\\}$，我们需要估计参数 $\\theta_i$ 和 $\\Omega_{rs}$。为了确保模型的可识别性，我们施加约束 $\\sum_{i: g_i=r} \\theta_i = 1$ 对所有块 $r$ 成立。请构建此约束最大化问题的拉格朗日函数，并推导出参数 $\\{\\theta_i\\}$ 和 $\\{\\Omega_{rs}\\}$ 的最大似然估计（MLE）所满足的方程组。",
            "solution": "我们的目标是使用最大似然估计（MLE）来估计DCSBM参数 $\\theta$ 和 $\\Omega$。我们遵循问题设定，即一个有向多重图，其中边数 $A_{ij} \\sim \\text{Poisson}(\\theta_i \\theta_j \\Omega_{g_i g_j})$ 对所有有序对 $(i,j)$ 成立。\n\n**1. 对数似然函数**\n似然函数是所有独立泊松事件概率的乘积。对数似然函数 $\\ell$（忽略与参数无关的常数项）是：\n$$\n\\ell(\\theta, \\Omega | A) = \\sum_{i,j} \\left( A_{ij} \\log(\\lambda_{ij}) - \\lambda_{ij} \\right)\n$$\n代入 $\\lambda_{ij} = \\theta_i \\theta_j \\Omega_{g_i g_j}$，我们得到：\n$$\n\\ell = \\sum_{i,j} \\left( A_{ij} (\\log\\theta_i + \\log\\theta_j + \\log\\Omega_{g_i g_j}) - \\theta_i \\theta_j \\Omega_{g_i g_j} \\right)\n$$\n\n**2. 拉格朗日函数**\n为了处理可识别性约束 $\\sum_{i: g_i=r} \\theta_i = 1$（对于所有块 $r=1, \\dots, B$），我们引入拉格朗日乘子 $\\alpha_1, \\dots, \\alpha_B$。拉格朗日函数 $\\mathcal{L}$ 定义为：\n$$\n\\mathcal{L}(\\theta, \\Omega, \\alpha) = \\ell - \\sum_{r=1}^{B} \\alpha_r \\left( \\sum_{i: g_i=r} \\theta_i - 1 \\right)\n$$\n\n**3. 推导平稳性条件 (MLE 方程)**\n我们通过将 $\\mathcal{L}$ 对每个参数的偏导数设为零来找到平稳点。\n\n*   **对 $\\Omega_{rs}$ 求导:**\n    $\\Omega_{rs}$ 只出现在 $g_i=r, g_j=s$ 的项中。\n    $$\n    \\frac{\\partial \\mathcal{L}}{\\partial \\Omega_{rs}} = \\sum_{i:g_i=r} \\sum_{j:g_j=s} \\left( \\frac{A_{ij}}{\\Omega_{rs}} - \\theta_i \\theta_j \\right) = 0\n    $$\n    令 $m_{rs} = \\sum_{i:g_i=r, j:g_j=s} A_{ij}$ 为从块 $r$ 到块 $s$ 的总边数。方程变为：\n    $$\n    \\frac{m_{rs}}{\\Omega_{rs}} - \\left(\\sum_{i:g_i=r} \\theta_i\\right) \\left(\\sum_{j:g_j=s} \\theta_j\\right) = 0\n    $$\n    应用约束 $\\sum_{i:g_i=r} \\theta_i = 1$，我们得到关于 $\\Omega_{rs}$ 的第一个方程：\n    $$\n    \\hat{\\Omega}_{rs} = m_{rs}\n    $$\n    这表明，在满足此约束的条件下，块间亲和力的最大似然估计就是观测到的块间总边数。\n\n*   **对 $\\theta_k$求导:**\n    $\\theta_k$ 出现在 $i=k$ 或 $j=k$ 的项中。\n    $$\n    \\frac{\\partial \\mathcal{L}}{\\partial \\theta_k} = \\sum_{j} \\left( \\frac{A_{kj}}{\\theta_k} - \\theta_j \\Omega_{g_k g_j} \\right) + \\sum_{i} \\left( \\frac{A_{ik}}{\\theta_k} - \\theta_i \\Omega_{g_i g_k} \\right) - \\alpha_{g_k} = 0\n    $$\n    令 $k_k^{\\text{out}} = \\sum_j A_{kj}$ 为节点 $k$ 的出度， $k_k^{\\text{in}} = \\sum_i A_{ik}$ 为节点 $k$ 的入度。\n    $$\n    \\frac{k_k^{\\text{out}}}{\\theta_k} + \\frac{k_k^{\\text{in}}}{\\theta_k} - \\sum_j \\theta_j \\Omega_{g_k g_j} - \\sum_i \\theta_i \\Omega_{g_i g_k} - \\alpha_{g_k} = 0\n    $$\n    由于 $\\Omega$ 是对称的，且模型假设 $\\theta_i=\\phi_i$，两个求和项是相等的。因此，我们得到关于 $\\theta_k$ 的第二个方程：\n    $$\n    \\frac{k_k^{\\text{out}} + k_k^{\\text{in}}}{\\theta_k} - 2 \\sum_j \\theta_j \\Omega_{g_k g_j} = \\alpha_{g_k}\n    $$\n    \n    这组方程（连同约束本身）共同定义了参数的最大似然估计。它们通常需要通过迭代算法求解。",
            "answer": "$$\\boxed{\\mathcal{L}(\\theta, \\Omega, \\alpha) = \\sum_{i,j} \\left[ A_{ij}(\\log\\theta_i + \\log\\theta_j + \\log\\Omega_{g_ig_j}) - \\theta_i\\theta_j\\Omega_{g_ig_j} \\right] - \\sum_{r=1}^{B} \\alpha_r\\left(\\sum_{i:g_i=r}\\theta_i - 1\\right)}$$"
        }
    ]
}