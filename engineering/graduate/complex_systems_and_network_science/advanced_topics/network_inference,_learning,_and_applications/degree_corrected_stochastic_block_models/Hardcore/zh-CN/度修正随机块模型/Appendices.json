{
    "hands_on_practices": [
        {
            "introduction": "理论知识需要通过实践来巩固。为了真正掌握度校正随机块模型 (DCSBM)，理解其参数与网络宏观属性之间的关系至关重要。此练习将引导您推导一个基本但至关重要的关系，揭示在特定的参数归一化条件下，模型中的亲和力矩阵 $\\Omega$ 如何直接对应于块间连接的期望数量。通过这个推导 ，您将对模型参数的实际意义建立起一个清晰直观的认识。",
            "id": "4272166",
            "problem": "考虑一个由度校正随机块模型 (DCSBM) 生成的、包含 $N$ 个顶点的有向多重图。每个顶点 $i \\in \\{1,\\dots,N\\}$ 都被分配一个块标签 $g_i \\in \\{1,\\dots,B\\}$ 和一个正度参数 $\\theta_i > 0$。设 $\\Omega$ 是一个 $B \\times B$ 的非负块亲和矩阵，其元素为 $\\omega_{rs}$，$r,s \\in \\{1,\\dots,B\\}$。邻接矩阵 $A$ 的元素 $A_{ij}$ 是独立的泊松随机变量，其率参数为 $\\lambda_{ij} = \\theta_i \\theta_j \\,\\omega_{g_i g_j}$，这适用于所有有序对 $(i,j)$，包括 $i=j$ 的情况。将从块 $r$ 到块 $s$ 的边总数定义为\n$$\nm_{rs} = \\sum_{i: g_i = r} \\sum_{j: g_j = s} A_{ij}.\n$$\n假设存在逐块归一化约束\n$$\n\\sum_{i: g_i = r} \\theta_i = 1 \\quad \\text{for every} \\quad r \\in \\{1,\\dots,B\\}.\n$$\n从泊松随机变量期望的基本定义和期望的线性性质出发，推导出 $\\mathbb{E}[m_{rs}]$ 关于块亲和矩阵元素的闭式表达式。你的最终答案必须是单个闭式解析表达式。",
            "solution": "目标是推导 $\\mathbb{E}[m_{rs}]$ 的闭式表达式，即从块 $r$ 到块 $s$ 的期望边总数。我们从问题陈述中给出的 $m_{rs}$ 的定义开始：\n$$\nm_{rs} = \\sum_{i: g_i = r} \\sum_{j: g_j = s} A_{ij}\n$$\n此处，$g_i$ 是顶点 $i$ 的块标签，求和遍历块 $r$ 中的所有顶点 $i$ 和块 $s$ 中的所有顶点 $j$。\n\n为了求 $m_{rs}$ 的期望，我们应用期望的线性性质。随机变量之和的期望等于它们各自期望的和。\n$$\n\\mathbb{E}[m_{rs}] = \\mathbb{E}\\left[ \\sum_{i: g_i = r} \\sum_{j: g_j = s} A_{ij} \\right] = \\sum_{i: g_i = r} \\sum_{j: g_j = s} \\mathbb{E}[A_{ij}]\n$$\n问题陈述指出，邻接矩阵的每个元素 $A_{ij}$ 都是一个独立的泊松随机变量，其率参数为 $\\lambda_{ij}$。泊松分布的一个基本性质是其期望等于其率参数。因此，对于一个随机变量 $X \\sim \\text{Poisson}(\\lambda)$，我们有 $\\mathbb{E}[X] = \\lambda$。将此性质应用于 $A_{ij}$，我们得到：\n$$\n\\mathbb{E}[A_{ij}] = \\lambda_{ij}\n$$\n将此代入 $\\mathbb{E}[m_{rs}]$ 的表达式中，得到：\n$$\n\\mathbb{E}[m_{rs}] = \\sum_{i: g_i = r} \\sum_{j: g_j = s} \\lambda_{ij}\n$$\n接下来，我们使用度校正随机块模型 (DCSBM) 的率参数 $\\lambda_{ij}$ 的定义，其给出为：\n$$\n\\lambda_{ij} = \\theta_i \\theta_j \\,\\omega_{g_i g_j}\n$$\n其中 $\\theta_i$ 和 $\\theta_j$ 分别是顶点 $i$ 和 $j$ 的度参数，而 $\\omega_{g_i g_j}$ 是块亲和矩阵 $\\Omega$ 中对应于顶点 $i$ 和 $j$ 所在块的元素。\n\n将 $\\lambda_{ij}$ 的这个表达式代入我们关于 $\\mathbb{E}[m_{rs}]$ 的方程中：\n$$\n\\mathbb{E}[m_{rs}] = \\sum_{i: g_i = r} \\sum_{j: g_j = s} \\theta_i \\theta_j \\,\\omega_{g_i g_j}\n$$\n在该双重求和的范围内，指数 $i$ 遍历所有属于块 $r$ 的顶点（因此 $g_i = r$），指数 $j$ 遍历所有属于块 $s$ 的顶点（因此 $g_j = s$）。因此，对于此和中的每一项，块亲和项 $\\omega_{g_i g_j}$ 都是常数，等于 $\\omega_{rs}$。我们可以将这个常数项从求和中提出来：\n$$\n\\mathbb{E}[m_{rs}] = \\omega_{rs} \\sum_{i: g_i = r} \\sum_{j: g_j = s} \\theta_i \\theta_j\n$$\n剩下的双重求和可以分解为两个独立和的乘积，因为项 $\\theta_i$ 不依赖于内层求和指数 $j$，而项 $\\theta_j$ 不依赖于外层求和指数 $i$：\n$$\n\\sum_{i: g_i = r} \\sum_{j: g_j = s} \\theta_i \\theta_j = \\left( \\sum_{i: g_i = r} \\theta_i \\right) \\left( \\sum_{j: g_j = s} \\theta_j \\right)\n$$\n此时，我们使用问题陈述中给出的逐块归一化约束：\n$$\n\\sum_{k: g_k = q} \\theta_k = 1 \\quad \\text{for every block} \\quad q \\in \\{1,\\dots,B\\}\n$$\n将此约束应用于我们乘积中的每一个和：\n第一个和是关于块 $r$ 中所有顶点 $i$ 的求和，所以：\n$$\n\\sum_{i: g_i = r} \\theta_i = 1\n$$\n第二个和是关于块 $s$ 中所有顶点 $j$ 的求和，所以：\n$$\n\\sum_{j: g_j = s} \\theta_j = 1\n$$\n因此，这两个和的乘积等于 $1 \\times 1 = 1$。\n\n将此结果代回我们关于 $\\mathbb{E}[m_{rs}]$ 的表达式中，我们得到最终表达式：\n$$\n\\mathbb{E}[m_{rs}] = \\omega_{rs} \\times 1 = \\omega_{rs}\n$$\n这个结果表明，在给定的归一化条件下，块亲和矩阵 $\\Omega$ 的元素直接对应于相应块之间的期望边总数。",
            "answer": "$$\\boxed{\\omega_{rs}}$$"
        },
        {
            "introduction": "理解模型参数的意义后，下一步便是如何从观测到的网络数据中估计这些参数。最大似然估计 (Maximum Likelihood Estimation, MLE) 是解决此类问题的基石性统计方法。在此练习  中，您将为DCSBM构建带约束的最大似然估计问题，并使用拉格朗日乘子法来处理参数的识别性约束。推导出这些平稳性条件是开发DCSBM拟合算法的第一步，它揭示了连接观测数据（如节点度 $k_i$ 和块间边数 $m_{rs}$）与模型参数（如 $\\theta_i$ 和 $\\Omega_{rs}$）之间的一组自洽方程。",
            "id": "4272149",
            "problem": "考虑一个具有 $n$ 个节点的无向网络，由一个对称邻接矩阵 $A$ 表示，其中当 $i \\neq j$ 时，条目为 $A_{ij} \\in \\{0,1,2,\\dots\\}$，且 $A_{ii} = 0$。每个节点 $i$ 被分配到 $B$ 个块中的一个，其块标签为 $g_i \\in \\{1,2,\\dots,B\\}$。假设采用度数校正随机块模型 (Degree-Corrected Stochastic Block Model, DCSBM)，其中对于每个 $i",
            "solution": "问题要求对度数校正随机块模型 (DCSBM) 的参数进行约束最大似然估计。我们需要构建拉格朗日函数并推导一阶平稳性条件。\n\n首先，我们验证问题陈述。\n提取并列出所有给定条件：\n- 一个具有 $n$ 个节点的无向网络。\n- 一个对称邻接矩阵 $A$，其中当 $i \\neq j$ 时，条目为 $A_{ij} \\in \\{0, 1, 2, \\dots\\}$，且 $A_{ii} = 0$。\n- 将节点划分为 $B$ 个块，块分配为 $g_i \\in \\{1, 2, \\dots, B\\}$。\n- DCSBM 生成模型：对于每个无序节点对 $\\{i, j\\}$ 且 $i  j$，边数 $A_{ij}$ 是从泊松分布 $A_{ij} \\sim \\text{Poisson}(\\theta_i \\theta_j \\Omega_{g_i g_j})$ 中独立抽取的随机变量。\n- 参数包括节点特定的度数校正 $\\theta_i > 0$ 和一个对称的块亲和矩阵 $\\Omega \\in \\mathbb{R}_{+}^{B \\times B}$，其条目 $\\Omega_{rs} > 0$。\n- 节点 $i$ 的观测度数为 $k_i := \\sum_{j \\neq i} A_{ij}$。\n- 块边数为 $m_{rs} := \\sum_{\\substack{i",
            "answer": "$$\n\\boxed{\\mathcal{L}_{C}(\\theta, \\Omega, \\lambda) = \\sum_{i"
        },
        {
            "introduction": "在复杂的网络模型中，一个核心的科学问题是：模型的复杂性是否真的由数据支持？我们如何确定DCSBM发现的社区结构是真实存在的，而不仅仅是过拟合的产物？此练习  将您带入统计推断的前沿，通过构建似然比检验 (Likelihood Ratio Test, LRT) 来形式化地比较DCSBM与更简单的配置模型。配置模型保留了节点的度序列但假设不存在社区结构，因此该检验能够判断引入社区结构是否在统计上是显著的。完成这个练习将展示如何运用DCSBM进行严谨的科学假设检验，从而从描述性建模迈向推断性分析。",
            "id": "4272165",
            "problem": "考虑一个由度矫正模型生成的具有 $n$ 个顶点和 $m$ 条边的无向多重图，该图可能包含多重边和自环。每个顶点 $i$ 都有一个已知的社群分配 $g_i \\in \\{1,\\dots,B\\}$。令 $m_{rs}$ 表示端点分别在社群 $r$ 和 $s$ ($r \\neq s$) 中的边的数量，令 $m_{rr}$ 表示两个端点都在社群 $r$ 中的边的数量。定义社群 $r$ 中的总“桩”(stub)数为 $\\kappa_r = \\sum_{i: g_i = r} k_i$，其中 $k_i$ 是顶点 $i$ 的度；等价地，通过对社群内部和社群之间边所贡献的“桩”进行重复计数，可得 $\\kappa_r = 2 m_{rr} + \\sum_{s \\neq r} m_{rs}$。观测到的块间边数满足 $m = \\sum_{r \\leq s} m_{rs}$。\n\n你需要将配置模型（原假设）与一个度矫正随机块模型（DCSBM）备择假设进行比较，该备择假设具有一个指定的对称、严格为正的 $B \\times B$ 块交互矩阵 $\\Omega = (\\Omega_{rs})$。在典则稀疏机制下进行分析，在该机制中，块对间的边放置是独立的，并且块级别的边数 $m_{rs}$ 可以近似为泊松随机变量，其均值与社群总桩数的乘积成正比。具体来说，对于无序块对 $(r,s)$ 且 $r \\neq s$，使用基线权重 $B_{rs} = \\kappa_r \\kappa_s$；对于 $(r,r)$，使用 $B_{rr} = \\frac{1}{2}\\kappa_r (\\kappa_r - 1)$。在配置模型原假设下，一条均匀随机选择的边落入块对 $(r,s)$ 的概率与 $B_{rs}$ 成正比；在DCSBM备择假设下，该概率与 $\\Omega_{rs} B_{rs}$ 成正比。对于 $m$ 条边，将块数 $m_{rs}$ 近似为独立的泊松变量，其均值在原假设下为 $\\mu_{rs}^{(0)} = m \\frac{B_{rs}}{\\sum_{a \\leq b} B_{ab}}$，在备择假设下为 $\\mu_{rs}^{(1)} = m \\frac{\\Omega_{rs} B_{rs}}{\\sum_{a \\leq b} \\Omega_{ab} B_{ab}}$。这种近似是稀疏边放置极限以及独立泊松过程可加性的一个经过充分检验的推论。\n\n构建似然比检验（LRT）来比较配置模型（原假设）与指定的DCSBM（备择假设），并推导LRT统计量 $D = 2 \\ln \\Lambda$ 的一个显式闭式表达式，该表达式仅用观测到的块数 $m_{rs}$ 和指定的 $\\Omega$ 表示。你的最终表达式必须通过 $\\kappa_r = 2 m_{rr} + \\sum_{s \\neq r} m_{rs}$ 消去 $\\kappa_r$ 而用 $m_{rs}$ 表示，并且必须写成单个解析表达式。不需要进行数值计算。",
            "solution": "在进行求解之前，对问题陈述进行严格验证。\n\n### 第一步：提取已知条件\n- **图与模型**：一个由度矫正模型生成的具有 $n$ 个顶点和 $m$ 条边的无向多重图。允许存在多重边和自环。\n- **社群结构**：每个顶点 $i$ 都有一个已知的社群分配 $g_i \\in \\{1, \\dots, B\\}$。\n- **观测数据**：块级别的边数 $m_{rs}$，其中 $r \\neq s$（社群 $r$ 和 $s$ 之间的边）和 $m_{rr}$（社群 $r$ 内部的边）。\n- **总边数**：$m = \\sum_{1 \\le r \\le s \\le B} m_{rs}$。\n- **社群桩数 ($\\kappa_r$)**：社群 $r$ 中的总桩数为 $\\kappa_r = \\sum_{i: g_i = r} k_i$，其中 $k_i$ 是顶点 $i$ 的度。这与观测到的边数相关联，即 $\\kappa_r = 2 m_{rr} + \\sum_{s \\neq r} m_{rs}$。\n- **待比较的假设**：\n  - **原假设 ($H_0$)**：配置模型 (CM)。\n  - **备择假设 ($H_1$)**：度矫正随机块模型 (DCSBM)，具有一个指定的对称、严格为正的 $B \\times B$ 块交互矩阵 $\\Omega = (\\Omega_{rs})$。\n- **统计近似**：在稀疏机制下，无序对 $(r,s)$ 的块数 $m_{rs}$ 近似为独立的泊松随机变量。\n- **泊松均值**：\n  - 原假设 ($H_0$)：$\\mu_{rs}^{(0)} = m \\frac{B_{rs}}{\\sum_{a \\leq b} B_{ab}}$。\n  - 备择假设 ($H_1$)：$\\mu_{rs}^{(1)} = m \\frac{\\Omega_{rs} B_{rs}}{\\sum_{a \\leq b} \\Omega_{ab} B_{ab}}$。\n- **基线权重 ($B_{rs}$)**：对于无序块对：\n  - $B_{rs} = \\kappa_r \\kappa_s$ 对于 $r \\neq s$。\n  - $B_{rr} = \\frac{1}{2}\\kappa_r (\\kappa_r - 1)$ 对于 $r=s$。\n- **任务**：推导似然比检验统计量 $D = 2 \\ln \\Lambda$ 的一个单一、显式、闭式的表达式，该表达式仅用观测到的块数 $m_{rs}$ 和指定的矩阵 $\\Omega$ 表示。表达式中不得含有 $\\kappa_r$。\n\n### 第二步：使用提取的已知条件进行验证\n根据既定的验证标准对问题进行评估。\n- **科学基础**：该问题植根于已有的网络模型统计理论，特别是比较配置模型与DCSBM。使用似然比检验是模型比较的标准方法。在稀疏图中对边数使用泊松近似是网络科学文献中一种有充分依据的技术。$\\kappa_r$ 和基线权重 $B_{rs}$ 的定义与这些模型的微正则系综表述一致。\n- **定义明确**：该问题是定义明确的。它提供了所有必要的定义、数据 ($m_{rs}$)、一个指定的参数 ($\\Omega$) 以及一个明确的目标：推导统计量 $D = 2 \\ln \\Lambda$。指令精确，可以导出一个唯一的解析解。\n- **客观性**：该问题以精确、正式且无偏见的数学语言陈述，不含任何主观性或意见。\n\n### 第三步：结论与行动\n该问题具有科学合理性、定义明确且客观。它不包含任何可辨别的缺陷。因此，该问题被判定为**有效**，有必要给出完整解答。\n\n### LRT统计量的推导\n\n构建似然比检验是为了比较两个嵌套的假设：配置模型（$H_0$）和度矫正随机块模型（$H_1$）。该检验统计量基于在每个模型下观测到数据 $\\{m_{rs}\\}_{1 \\le r \\le s \\le B}$ 的似然比。\n\n问题陈述指出，块级别的边数 $m_{rs}$ 近似为独立的泊松随机变量。均值为 $\\mu$ 的泊松随机变量的概率质量函数为 $P(k; \\mu) = \\frac{\\mu^k \\exp(-\\mu)}{k!}$。在给定假设下的似然函数是这些概率在所有无序块对 $(r,s)$ 上的乘积。\n\n在原假设 $H_0$ 下，似然函数为：\n$$ L_0 = P(\\{m_{rs}\\} | H_0) = \\prod_{1 \\le r \\le s \\le B} \\frac{(\\mu_{rs}^{(0)})^{m_{rs}} \\exp(-\\mu_{rs}^{(0)})}{m_{rs}!} $$\n\n在备择假设 $H_1$ 下，似然函数为：\n$$ L_1 = P(\\{m_{rs}\\} | H_1) = \\prod_{1 \\le r \\le s \\le B} \\frac{(\\mu_{rs}^{(1)})^{m_{rs}} \\exp(-\\mu_{rs}^{(1)})}{m_{rs}!} $$\n\n似然比 $\\Lambda$ 是备择似然与原似然之比：\n$$ \\Lambda = \\frac{L_1}{L_0} = \\frac{\\prod_{r \\le s} (\\mu_{rs}^{(1)})^{m_{rs}} \\exp(-\\mu_{rs}^{(1)}) / m_{rs}!}{\\prod_{r \\le s} (\\mu_{rs}^{(0)})^{m_{rs}} \\exp(-\\mu_{rs}^{(0)}) / m_{rs}!} = \\prod_{r \\le s} \\left( \\frac{\\mu_{rs}^{(1)}}{\\mu_{rs}^{(0)}} \\right)^{m_{rs}} \\exp\\left( -(\\mu_{rs}^{(1)} - \\mu_{rs}^{(0)}) \\right) $$\n\n对数似然比为：\n$$ \\ln \\Lambda = \\sum_{r \\le s} \\left[ m_{rs} \\ln\\left(\\frac{\\mu_{rs}^{(1)}}{\\mu_{rs}^{(0)}}\\right) - (\\mu_{rs}^{(1)} - \\mu_{rs}^{(0)}) \\right] $$\n\n我们定义归一化常数 $C_0 = \\sum_{a \\le b} B_{ab}$ 和 $C_1 = \\sum_{a \\le b} \\Omega_{ab} B_{ab}$。均值为 $\\mu_{rs}^{(0)} = m \\frac{B_{rs}}{C_0}$ 和 $\\mu_{rs}^{(1)} = m \\frac{\\Omega_{rs} B_{rs}}{C_1}$。均值之比为：\n$$ \\frac{\\mu_{rs}^{(1)}}{\\mu_{rs}^{(0)}} = \\frac{m \\frac{\\Omega_{rs} B_{rs}}{C_1}}{m \\frac{B_{rs}}{C_0}} = \\frac{\\Omega_{rs} C_0}{C_1} $$\n\n涉及均值差的项为：\n$$ \\sum_{r \\le s} (\\mu_{rs}^{(1)} - \\mu_{rs}^{(0)}) = \\sum_{r \\le s} \\left( m \\frac{\\Omega_{rs} B_{rs}}{C_1} - m \\frac{B_{rs}}{C_0} \\right) = \\frac{m}{C_1} \\sum_{r \\le s} \\Omega_{rs} B_{rs} - \\frac{m}{C_0} \\sum_{r \\le s} B_{rs} $$\n根据 $C_1$ 和 $C_0$ 的定义，此式简化为：\n$$ \\frac{m}{C_1} (C_1) - \\frac{m}{C_0} (C_0) = m - m = 0 $$\n\n将这些结果代回到 $\\ln \\Lambda$ 的表达式中：\n$$ \\ln \\Lambda = \\sum_{r \\le s} m_{rs} \\ln\\left(\\frac{\\Omega_{rs} C_0}{C_1}\\right) = \\sum_{r \\le s} m_{rs} \\ln(\\Omega_{rs}) + \\sum_{r \\le s} m_{rs} (\\ln(C_0) - \\ln(C_1)) $$\n由于 $\\sum_{r \\le s} m_{rs} = m$，我们得到：\n$$ \\ln \\Lambda = \\sum_{r \\le s} m_{rs} \\ln(\\Omega_{rs}) + m \\ln(C_0) - m \\ln(C_1) = \\sum_{r \\le s} m_{rs} \\ln(\\Omega_{rs}) - m \\ln\\left(\\frac{C_1}{C_0}\\right) $$\n\n所求的统计量是 $D = 2 \\ln \\Lambda$：\n$$ D = 2 \\sum_{r \\le s} m_{rs} \\ln(\\Omega_{rs}) - 2m \\ln\\left(\\frac{\\sum_{a \\le b} \\Omega_{ab} B_{ab}}{\\sum_{a \\le b} B_{ab}}\\right) $$\n\n为了得到最终表达式，我们必须将所有项表示为 $m_{rs}$ 和 $\\Omega$ 的函数。\n总边数为 $m = \\sum_{a \\le b} m_{ab}$。\n社群桩数由 $\\kappa_r = 2 m_{rr} + \\sum_{s \\neq r} m_{rs}$ 给出。由于图是无向的，$m_{rs} = m_{sr}$，且提供的数据 $\\{m_{rs}\\}$ 是针对 $r \\le s$ 的，我们可以将此和写为 $\\kappa_r = 2 m_{rr} + \\sum_{s  r} m_{sr} + \\sum_{s > r} m_{rs}$。\n基线权重 $B_{rs}$ 是用 $\\kappa_r$ 定义的。\n\n分母的和，$C_0 = \\sum_{a \\le b} B_{ab}$，可以被简化。它代表了配置模型框架中桩对的总数：\n$$ \\sum_{a \\le b} B_{ab} = \\sum_{a  b} \\kappa_a \\kappa_b + \\sum_{a=1}^B \\frac{1}{2}\\kappa_a(\\kappa_a-1) = \\frac{1}{2} \\left[ \\left(\\sum_a \\kappa_a\\right)^2 - \\sum_a \\kappa_a^2 \\right] + \\frac{1}{2} \\left[ \\sum_a \\kappa_a^2 - \\sum_a \\kappa_a \\right] = \\frac{1}{2} \\left[ \\left(\\sum_a \\kappa_a\\right)^2 - \\sum_a \\kappa_a \\right] $$\n总桩数为 $\\sum_a \\kappa_a = \\sum_a \\sum_{i:g_i=a} k_i = \\sum_i k_i = 2m$。\n因此，$C_0 = \\frac{1}{2}((2m)^2 - 2m) = 2m^2 - m$。\n\n分子的和，$C_1 = \\sum_{a \\le b} \\Omega_{ab} B_{ab}$，由于 $\\Omega_{ab}$ 权重的影响，不能如此简洁地化简。我们必须通过代入 $B_{ab}$ 和 $\\kappa_a$ 的定义来将其写出。\n\n代入所有分量，得到仅用 $\\{m_{rs}\\}_{r \\le s}$ 和 $\\{\\Omega_{rs}\\}$ 表示的 $D$ 的最终表达式。",
            "answer": "$$\n\\boxed{\n2 \\sum_{1 \\le r \\le s \\le B} m_{rs} \\ln(\\Omega_{rs}) - 2 \\left( \\sum_{1 \\le i \\le j \\le B} m_{ij} \\right) \\ln\\left( \\frac{\\sum_{1 \\le a  b \\le B} \\Omega_{ab} \\left(2 m_{aa} + \\sum_{t"
        }
    ]
}