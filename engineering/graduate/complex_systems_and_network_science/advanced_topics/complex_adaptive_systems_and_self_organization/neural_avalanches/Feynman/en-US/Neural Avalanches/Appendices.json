{
    "hands_on_practices": [
        {
            "introduction": "To analyze neural avalanches, we must first learn how to measure them from raw or processed neural data. This exercise provides a hands-on opportunity to apply the standard definitions of avalanche size and duration to a simple, idealized spike raster. By working through this foundational calculation, you will solidify your understanding of the key observables that form the basis of all subsequent statistical analysis in the study of critical brain dynamics.",
            "id": "4292846",
            "problem": "A spike raster from a recurrent neural network is observed over a window of $200\\,\\mathrm{ms}$ and discretized into time bins of width $2\\,\\mathrm{ms}$. In the standard neural avalanche framework, an avalanche is defined as a maximal sequence of consecutive time bins with nonzero activity (no silent bin), bounded before and after by silent bins (bins with zero activity). Avalanche size is the total number of active neuron events accumulated over all bins in the avalanche. Avalanche duration is the time spanned by the avalanche’s consecutive active bins. The average avalanche rate is the total number of active neuron events per unit time over the avalanche duration.\n\nSuppose that during one contiguous sequence of $8$ active bins there are exactly $50$ neurons active in each bin, with no silent bin between the first and last active bin in the sequence, and assume that there are silent bins immediately before and after this sequence so that it constitutes a single avalanche. Using these definitions, compute the avalanche size, the avalanche duration, and the average avalanche rate. Express the avalanche size as a dimensionless count, the avalanche duration in milliseconds, and the average rate in hertz (Hz). No rounding is required; report exact values.",
            "solution": "The user wants me to solve the problem by following these steps.\n1.  **Extract Givens**:\n    *   Time bin width: $\\Delta t = 2\\,\\mathrm{ms}$.\n    *   An avalanche consists of a sequence of $8$ active bins.\n    *   Number of active neurons in each bin: $50$.\n    *   The sequence is bounded by silent bins, thus forming a single avalanche.\n    *   Definition of avalanche size ($S$): total number of active neuron events accumulated over all bins in the avalanche.\n    *   Definition of avalanche duration ($D$): time spanned by the avalanche’s consecutive active bins.\n    *   Definition of average avalanche rate ($R$): total number of active neuron events per unit time over the avalanche duration.\n    *   Required outputs: avalanche size (dimensionless count), avalanche duration (milliseconds), and average avalanche rate (hertz).\n\n2.  **Validate Using Extracted Givens**:\n    *   **Scientifically Grounded**: The problem statement uses standard definitions and concepts from the study of neural avalanches in computational neuroscience and complex systems. The framework of binning spike data and defining avalanches based on contiguous non-empty bins is canonical, originating from the work of Beggs and Plenz. The problem is scientifically sound.\n    *   **Well-Posed**: The problem is clearly stated, with all necessary data and definitions provided to compute the required quantities. The definitions for size, duration, and rate are unambiguous.\n    *   **Objective**: The language is quantitative and precise, free from subjective or opinion-based statements.\n    *   The problem does not exhibit any of the listed flaws (Scientific Unsoundness, Non-Formalizable, Incomplete Setup, Unrealistic, Ill-Posed, Pseudo-Profound, or Outside Scientific Verifiability). The data are consistent and plausible within the context of a neural system or model. The information regarding the $200\\,\\mathrm{ms}$ observation window is contextual and does not conflict with the data for the specific avalanche in question.\n\n3.  **Verdict and Action**:\n    *   The problem is **valid**. A solution will be provided.\n\nThe problem asks for the calculation of three quantities related to a single neural avalanche: its size, duration, and average rate. We are given the necessary parameters to compute these values based on their definitions.\n\nLet $N_{bins}$ be the number of consecutive active time bins in the avalanche, and let $N_{events\\_per\\_bin}$ be the number of active neuron events in each bin. Let $\\Delta t$ be the width of a single time bin.\n\nFrom the problem statement, we have:\n-   Number of active bins, $N_{bins} = 8$.\n-   Number of events per bin, $N_{events\\_per\\_bin} = 50$.\n-   Time bin width, $\\Delta t = 2\\,\\mathrm{ms}$.\n\nFirst, we compute the **avalanche size**, denoted by $S$. The size is defined as the total number of active neuron events accumulated over all bins in the avalanche. Since each of the $N_{bins}$ bins has $N_{events\\_per\\_bin}$ events, the total size is their product.\n$$S = N_{bins} \\times N_{events\\_per\\_bin}$$\nSubstituting the given values:\n$$S = 8 \\times 50 = 400$$\nThe avalanche size is a dimensionless count of events. So, $S = 400$.\n\nSecond, we compute the **avalanche duration**, denoted by $D$. The duration is defined as the total time spanned by the avalanche's consecutive active bins. This is the product of the number of active bins and the width of each time bin.\n$$D = N_{bins} \\times \\Delta t$$\nSubstituting the given values:\n$$D = 8 \\times 2\\,\\mathrm{ms} = 16\\,\\mathrm{ms}$$\nThe problem asks for the duration in milliseconds, so $D = 16\\,\\mathrm{ms}$.\n\nThird, we compute the **average avalanche rate**, denoted by $R$. This is defined as the total number of active neuron events per unit time over the avalanche duration. This is the ratio of the avalanche size $S$ to the avalanche duration $D$.\n$$R = \\frac{S}{D}$$\nThe problem requires the rate to be expressed in hertz ($\\mathrm{Hz}$), which is equivalent to events per second ($\\mathrm{s}^{-1}$). We must first convert the duration $D$ from milliseconds to seconds.\n$$D = 16\\,\\mathrm{ms} = 16 \\times 10^{-3}\\,\\mathrm{s}$$\nNow we can calculate the rate:\n$$R = \\frac{400 \\text{ events}}{16 \\times 10^{-3}\\,\\mathrm{s}} = \\frac{400}{16} \\times 10^3\\,\\mathrm{Hz}$$\n$$R = 25 \\times 10^3\\,\\mathrm{Hz} = 25000\\,\\mathrm{Hz}$$\nExpressing this in standard scientific notation:\n$$R = 2.5 \\times 10^4\\,\\mathrm{Hz}$$\n\nThe three computed quantities are:\n-   Avalanche size: $400$\n-   Avalanche duration: $16\\,\\mathrm{ms}$\n-   Average avalanche rate: $25000\\,\\mathrm{Hz}$ or $2.5 \\times 10^4\\,\\mathrm{Hz}$\n\nThe final answer should present these three numerical values in the specified order.",
            "answer": "$$\\boxed{\\begin{pmatrix} 400  16  2.5 \\times 10^4 \\end{pmatrix}}$$"
        },
        {
            "introduction": "The statistical patterns of neural avalanches are elegantly explained by the mathematics of branching processes. This practice challenges you to use the Galton-Watson branching process model, the theoretical cornerstone of avalanche research, to interpret an experimental observation . By determining the system's dynamical regime from the average offspring count, $\\hat{\\sigma}$, you will learn to predict the qualitative shape of the avalanche size distribution, a critical skill for linking theory to data.",
            "id": "4292860",
            "problem": "In experiments on neuronal cultures, spontaneous cascades of spiking activity can be coarse-grained into trees where each active neuron can activate a random number of downstream neurons in the next time bin. Treat the cascade as a Galton–Watson (GW) branching process with offspring distribution characterized by an empirical average offspring count $\\hat{\\sigma}$ and a finite variance $\\mathrm{Var}[K]$. You observe an ensemble of cascades whose reconstructed activation trees yield $\\hat{\\sigma}=0.95$ and an offspring variance satisfying $\\mathrm{Var}[K]  1$. Using first principles of branching processes as a model for neural avalanches, decide whether the system is subcritical, and predict the qualitative form of the avalanche total-size distribution $P(S)$, where $S$ is the total number of activations in a cascade. In particular, determine whether a power-law regime is expected, whether there is a cutoff, and how the cutoff scale should qualitatively depend on the distance to criticality.\n\nChoose the most appropriate statement.\n\nA. The system is subcritical because $\\hat{\\sigma}1$. For finite $\\mathrm{Var}[K]$, $P(S)$ shows a critical-like power-law regime $P(S)\\sim S^{-3/2}$ up to an exponential cutoff, $P(S)\\sim S^{-3/2}\\exp\\!\\left(-S/S_{c}\\right)$, with cutoff scale $S_{c}$ diverging as $S_{c}\\propto (1-\\hat{\\sigma})^{-2}$, with a proportionality constant depending on $\\mathrm{Var}[K]$.\n\nB. The system is effectively critical because $\\mathrm{Var}[K]1$, hence $P(S)$ is a pure power law $P(S)\\sim S^{-3/2}$ without any cutoff.\n\nC. The system is subcritical, but $P(S)$ is purely exponential, $P(S)\\sim \\exp(-S/S_{c})$, with no power-law prefactor, and $S_{c}$ is independent of $\\hat{\\sigma}$.\n\nD. The system is supercritical because the variance exceeds $1$, implying a nonzero probability of infinite avalanches and a size distribution $P(S)\\sim S^{-2}$ for finite $S$.",
            "solution": "We model a neural avalanche as a Galton–Watson (GW) branching process. Let the offspring distribution have probability generating function (PGF) $f(u)=\\sum_{k\\ge 0} p_{k}u^{k}$ with mean $m=\\sum_{k}k p_{k}$ and variance $\\sigma_{K}^{2}=\\sum_{k}(k-m)^{2}p_{k}$. The branching ratio is $m$. The total progeny (avalanche size) $S$ starting from a single ancestor has a PGF $T(z)$ that satisfies the fundamental GW recursion\n$$\nT(z) \\;=\\; z\\, f\\!\\big(T(z)\\big),\n$$\nwhich follows from the decomposition of the tree into the root and its independent subtrees.\n\nClassification by first principles:\n- If $m1$ (subcritical), extinction occurs with probability $1$ and all avalanches are finite almost surely.\n- If $m=1$ (critical) with finite $\\sigma_{K}^{2}$, extinction still occurs almost surely, and the total-progeny distribution has a heavy tail with universal exponent.\n- If $m1$ (supercritical), there is a nonzero probability of nonextinction (infinite avalanche).\n\nGiven $\\hat{\\sigma}=0.95$, we have $m\\approx 0.951$, hence the system is subcritical.\n\nTo derive the qualitative form of $P(S)$ near criticality with finite variance, we analyze the singular behavior of $T(z)$ near $z=1$, because the tail of $P(S)$ is governed by the nature of this singularity. Expand the offspring PGF for $u$ near $1$ using its first two moments:\n$$\nf(1-\\epsilon) \\;=\\; 1 - m\\,\\epsilon + \\tfrac{1}{2}\\sigma_{K}^{2}\\,\\epsilon^{2} + o(\\epsilon^{2}) \\quad \\text{as } \\epsilon\\to 0^{+}.\n$$\nSet $T(z)=1-\\epsilon$ with small $\\epsilon$, and write $z=1-\\delta$ with small $\\delta$. The GW equation becomes\n$$\n1-\\epsilon \\;=\\; (1-\\delta)\\Big(1 - m\\,\\epsilon + \\tfrac{1}{2}\\sigma_{K}^{2}\\,\\epsilon^{2} + o(\\epsilon^{2})\\Big).\n$$\nExpanding the right-hand side to leading orders,\n$$\n1-\\epsilon \\;=\\; \\Big(1-\\delta\\Big)\\Big(1 - m\\,\\epsilon\\Big) + \\tfrac{1}{2}\\sigma_{K}^{2}(1-\\delta)\\epsilon^{2} + \\cdots\n\\\\\n= 1 - \\delta - m\\,\\epsilon + m\\,\\delta\\,\\epsilon + \\tfrac{1}{2}\\sigma_{K}^{2}\\epsilon^{2} + o(\\delta\\,\\epsilon,\\epsilon^{2},\\delta^{2}).\n$$\nEquating both sides and rearranging terms yields, to leading order in small $\\delta$ and $\\epsilon$,\n$$\n(1-m)\\,\\epsilon \\;+\\; \\tfrac{1}{2}\\sigma_{K}^{2}\\,\\epsilon^{2} \\;\\approx\\; \\delta.\n$$\nThis quadratic relation determines the local inversion $T(z)$ near $z=1$. Two regimes result:\n\n- Critical case $m=1$: then $\\tfrac{1}{2}\\sigma_{K}^{2}\\epsilon^{2}\\approx \\delta$, giving $\\epsilon \\sim \\sqrt{\\tfrac{2}{\\sigma_{K}^{2}}}\\,\\delta^{1/2}$. A square-root singularity at $z=1$ leads, by standard transfer theorems for generating functions, to the universal tail\n$$\nP(S)\\;\\sim\\; C\\, S^{-3/2}, \\quad \\text{as } S\\to\\infty.\n$$\n\n- Subcritical case $m1$: the linear term $(1-m)\\epsilon$ dominates initially, so for $z$ sufficiently close to $1$ one has $\\epsilon\\approx \\delta/(1-m)$ and the function $T(z)$ is analytic at $z=1$. However, the true dominant singularity $z_{c}1$ emerges where the quadratic and linear balance breaks down. Solving for the branch-point defined by the vanishing discriminant,\n$$\n(1-m)\\,\\epsilon + \\tfrac{1}{2}\\sigma_{K}^{2}\\,\\epsilon^{2} \\;=\\; \\delta, \\quad \\frac{d\\delta}{d\\epsilon}=0\n$$\ngives a square-root branch point at\n$$\n\\epsilon_{c} \\;=\\; \\frac{1-m}{\\sigma_{K}^{2}}, \n\\qquad \n\\delta_{c} \\;=\\; \\frac{(1-m)^{2}}{2\\sigma_{K}^{2}},\n\\qquad \nz_{c} \\;=\\; 1-\\delta_{c} \\;\\; 1.\n$$\nHence $T(z)$ has a square-root singularity at $z=z_{c}$, not at $z=1$. By transfer theorems, the coefficients obey\n$$\nP(S)\\;\\sim\\; C'\\, S^{-3/2}\\, z_{c}^{-S} \\;=\\; C'\\, S^{-3/2}\\, \\exp\\!\\Big(-S/S_{c}\\Big),\n$$\nwith an exponential cutoff governed by\n$$\nS_{c} \\;=\\; \\big(-\\ln z_{c}\\big)^{-1} \\;\\asymp\\; \\frac{1}{\\delta_{c}} \\;=\\; \\frac{2\\sigma_{K}^{2}}{(1-m)^{2}},\n$$\nwhere the last relation uses $\\delta_{c}\\ll 1$ near criticality so that $-\\ln z_{c}\\approx \\delta_{c}$. Thus, for finite variance, the subcritical avalanche-size distribution exhibits a critical-like prefactor $S^{-3/2}$ multiplied by an exponential cutoff whose scale diverges as $S_{c}\\propto (1-m)^{-2}$ as $m\\uparrow 1$.\n\nApplying these results to the observation $\\hat{\\sigma}=0.95$ and $\\mathrm{Var}[K]1$:\n- Since $\\hat{\\sigma}1$, the system is subcritical, with no infinite avalanches.\n- Finite $\\mathrm{Var}[K]$ ensures the universal square-root singularity structure and hence the $S^{-3/2}$ prefactor; the variance enters the proportionality constant in $S_{c}\\propto (1-\\hat{\\sigma})^{-2}$.\n- Therefore $P(S)$ is expected to have a power-law regime with exponent $3/2$ up to an exponential cutoff, and the cutoff scale diverges as the square of the inverse distance to criticality.\n\nOption-by-option analysis:\n\nA. States subcriticality because $\\hat{\\sigma}1$, predicts $P(S)\\sim S^{-3/2}\\exp(-S/S_{c})$ with $S_{c}\\propto (1-\\hat{\\sigma})^{-2}$ and a prefactor depending on $\\mathrm{Var}[K]$. This matches the GW analysis with finite variance. Verdict: Correct.\n\nB. Claims effective criticality and a pure power law because $\\mathrm{Var}[K]1$. Variance being $1$ does not imply criticality; criticality is set by the mean $m$. With $m1$, a cutoff is present. Verdict: Incorrect.\n\nC. Claims purely exponential decay without a power-law prefactor and independence of $S_{c}$ from $\\hat{\\sigma}$. For finite variance near criticality, the $S^{-3/2}$ prefactor is universal, and $S_{c}$ depends sensitively on $1-\\hat{\\sigma}$. Verdict: Incorrect.\n\nD. Claims supercriticality because the variance exceeds $1$, suggesting a nonzero probability of infinite avalanches and a $S^{-2}$ law. Supercriticality is governed by $m1$, not by the variance magnitude; here $m1$. Verdict: Incorrect.",
            "answer": "$$\\boxed{A}$$"
        },
        {
            "introduction": "A major challenge in neuroscience is that our measurements are typically an incomplete, or subsampled, view of the full network activity. This problem tackles the critical question of how such subsampling affects the statistics of observed neural avalanches . By deriving the mathematical relationship between the true and observed size distributions, you will develop a deeper appreciation for the subtleties of experimental data analysis and learn how to account for measurement limitations when testing for signatures of criticality.",
            "id": "4292899",
            "problem": "Consider a theoretical model of neural avalanches based on a critical Galton–Watson branching process, where an avalanche is defined as the total number of activated neurons before extinction. Let the avalanche size be denoted by $S \\in \\mathbb{N}$ and suppose that, in the critical regime with finite offspring variance, the size distribution has the well-tested asymptotic form $P(S) \\sim C S^{-3/2}$ for large $S$, up to a finite-size cutoff $S_{c}$ imposed by either network size or observation window constraints. Assume that due to random spatial subsampling, each activated neuron is independently observed with probability $p \\in (0,1)$, so that the observed avalanche size $s$ is the number of observed activated neurons within the avalanche.\n\nStarting from fundamental probabilistic definitions and widely accepted asymptotics, derive the leading-order asymptotic form of the observed size distribution tail $P_{\\mathrm{obs}}(s)$ for large $s$ under subsampling at fraction $p$, and determine how the effective cutoff in the observed distribution scales with $p$. Your derivation must explicitly begin with the representation of $P_{\\mathrm{obs}}(s)$ as a mixture over $S$ with the binomial sampling model, and proceed using first-principles approximations justified for large avalanches (e.g., Stirling approximations and the Central Limit Theorem (CLT) for the binomial). Express the final tail in terms of $s$, $p$, and $C$, and express the cutoff scale in terms of $p$ and $S_{c}$.\n\nYour final answer must be a single analytical object. If you report both the tail expression and the cutoff scaling, arrange them as a two-entry row matrix in the order “tail, cutoff.” No units are required. Do not provide any inequalities in the final answer.",
            "solution": "The problem asks for the derivation of the asymptotic form of the observed size distribution of neural avalanches under subsampling, and the scaling of the effective cutoff. We begin by formalizing the problem statement.\n\nThe true avalanche size, $S$, is a random variable whose distribution for large $S$ has the asymptotic form $P(S) \\sim C S^{-3/2}$, where $C$ is a constant. This distribution is subject to a finite-size cutoff $S_c$. Each of the $S$ activated neurons in a true avalanche is observed independently with a probability $p \\in (0,1)$. The observed avalanche size, $s$, is the number of neurons detected.\n\nThe conditional probability of observing an avalanche of size $s$ given a true avalanche of size $S$ follows a binomial distribution, since each of the $S$ neurons represents an independent Bernoulli trial with success probability $p$. This is given by:\n$$\nP(s|S) = \\binom{S}{s} p^s (1-p)^{S-s}\n$$\nThis is defined for $0 \\le s \\le S$. If $s  S$, then $P(s|S) = 0$.\n\nThe total probability of observing an avalanche of size $s$, denoted $P_{\\mathrm{obs}}(s)$, is obtained by marginalizing over all possible true avalanche sizes $S$. This is a sum over the product of the conditional probability and the prior probability of the true size $S$:\n$$\nP_{\\mathrm{obs}}(s) = \\sum_{S=s}^{S_c} P(s|S) P(S)\n$$\nThe sum starts at $S=s$ because it is impossible to observe more neurons than were actually activated. The sum ends at the system cutoff $S_c$.\n\nSubstituting the given asymptotic form for $P(S)$, we get:\n$$\nP_{\\mathrm{obs}}(s) \\approx \\sum_{S=s}^{S_c} \\left[ \\binom{S}{s} p^s (1-p)^{S-s} \\right] \\left( C S^{-3/2} \\right)\n$$\nWe are interested in the behavior of $P_{\\mathrm{obs}}(s)$ for large $s$. When $s$ is large, any $S \\ge s$ in the sum is also large. This justifies two key approximations:\n1. The sum can be approximated by an integral, as the summand varies relatively slowly with $S$ for large $S$.\n2. The binomial distribution $P(s|S)$ can be approximated by a Gaussian distribution. This is a consequence of the De Moivre-Laplace theorem, a special case of the Central Limit Theorem. The binomial distribution $\\mathrm{Bin}(S,p)$ has a mean $\\mu = Sp$ and variance $\\sigma^2 = Sp(1-p)$. The Gaussian approximation is:\n$$\nP(s|S) \\approx \\frac{1}{\\sqrt{2\\pi S p(1-p)}} \\exp\\left( -\\frac{(s - Sp)^2}{2Sp(1-p)} \\right)\n$$\nThis approximation is valid when $Sp(1-p) \\gg 1$. Since $s$ is large and $p$ is fixed, the dominant contributions to the sum will come from $S$ near $s/p$, for which $S$ is also large, validating the condition.\n\nReplacing the sum with an integral and substituting the approximations, we have:\n$$\nP_{\\mathrm{obs}}(s) \\approx C \\int_{s}^{S_c} \\frac{1}{\\sqrt{2\\pi S p(1-p)}} \\exp\\left( -\\frac{(s - Sp)^2}{2Sp(1-p)} \\right) S^{-3/2} dS\n$$\nCombining the terms involving $S$:\n$$\nP_{\\mathrm{obs}}(s) \\approx \\frac{C}{\\sqrt{2\\pi p(1-p)}} \\int_{s}^{S_c} S^{-1/2} S^{-3/2} \\exp\\left( -\\frac{(s - Sp)^2}{2Sp(1-p)} \\right) dS\n$$\n$$\nP_{\\mathrm{obs}}(s) \\approx \\frac{C}{\\sqrt{2\\pi p(1-p)}} \\int_{s}^{S_c} S^{-2} \\exp\\left( -\\frac{(s - Sp)^2}{2Sp(1-p)} \\right) dS\n$$\nThis integral can be evaluated using Laplace's method (or the saddle-point approximation), as the exponential term is sharply peaked for large $s$. The argument of the exponential is maximized (i.e., its magnitude is minimized) when $s - Sp = 0$, which occurs at $S_0 = s/p$. For $p \\in (0,1)$, this peak $S_0$ is greater than the lower integration limit $s$. As long as $S_0  S_c$, the peak is within the integration domain.\n\nLet the integrand be $g(S) \\exp(h(S))$, with $g(S) = S^{-2}$ and $h(S) = -\\frac{(s - Sp)^2}{2Sp(1-p)}$. According to Laplace's method, the integral is approximated by the value of the slowly varying part $g(S)$ at the peak $S_0$, multiplied by the integral of the Gaussian function that approximates $\\exp(h(S))$ around $S_0$.\nThe integral is approximately:\n$$\nI \\approx g(S_0) \\exp(h(S_0)) \\sqrt{\\frac{2\\pi}{-h''(S_0)}}\n$$\nFirst, we evaluate the terms at the saddle point $S_0 = s/p$:\n- $g(S_0) = (s/p)^{-2} = p^2s^{-2}$.\n- $h(S_0) = -\\frac{(s - (s/p)p)^2}{2(s/p)p(1-p)} = 0$, so $\\exp(h(S_0)) = 1$.\n\nNext, we compute the second derivative of $h(S)$. It is easier to expand the argument of the exponential around $S=S_0$. Let $S = S_0 + \\delta S = s/p + \\delta S$.\nThe numerator of the exponent is $(s - Sp)^2 = (s - (s/p + \\delta S)p)^2 = (s - s - p\\delta S)^2 = p^2(\\delta S)^2$.\nThe denominator is $2Sp(1-p) = 2(s/p + \\delta S)p(1-p) \\approx 2(s/p)p(1-p) = 2s(1-p)$ for small $\\delta S$.\nSo, near the peak, $h(S) \\approx -\\frac{p^2(\\delta S)^2}{2s(1-p)}$. This corresponds to a Gaussian with variance $\\sigma_S^2 = \\frac{s(1-p)}{p^2}$. The term $-h''(S_0)$ is $1/\\sigma_S^2 = \\frac{p^2}{s(1-p)}$.\n\nThe value of the Gaussian integral over its whole domain is $\\sqrt{2\\pi \\sigma_S^2} = \\sqrt{\\frac{2\\pi s(1-p)}{p^2}} = \\frac{\\sqrt{2\\pi s(1-p)}}{p}$.\nSo, the approximation for the integral is:\n$$\n\\int_{s}^{S_c} \\dots dS \\approx g(S_0) \\cdot \\frac{\\sqrt{2\\pi s(1-p)}}{p} = (p^2s^{-2}) \\frac{\\sqrt{2\\pi s(1-p)}}{p} = p s^{-3/2} \\sqrt{2\\pi(1-p)}\n$$\nNow, we substitute this result back into the expression for $P_{\\mathrm{obs}}(s)$:\n$$\nP_{\\mathrm{obs}}(s) \\approx \\frac{C}{\\sqrt{2\\pi p(1-p)}} \\left( p s^{-3/2} \\sqrt{2\\pi(1-p)} \\right)\n$$\nThe terms involving $\\sqrt{2\\pi(1-p)}$ cancel out.\n$$\nP_{\\mathrm{obs}}(s) \\approx C \\frac{p}{\\sqrt{p}} s^{-3/2} = C \\sqrt{p} s^{-3/2}\n$$\nThis is the leading-order asymptotic form for the observed size distribution. The power-law exponent of $-3/2$ is preserved under subsampling, but the normalization constant is scaled by $\\sqrt{p}$.\n\nNext, we determine the scaling of the effective cutoff in the observed distribution. The derivation above is based on the saddle-point approximation, which is valid as long as the saddle point $S_0 = s/p$ is located well within the support of the true distribution, i.e., $S_0 \\ll S_c$. As the observed size $s$ increases, so does the corresponding most likely true size $S_0$. The power-law behavior of $P_{\\mathrm{obs}}(s)$ will break down when $S_0$ approaches the true cutoff $S_c$. The effective cutoff in the observed distribution, let's call it $s_c$, can thus be estimated by the condition $S_0 \\approx S_c$.\n$$\n\\frac{s_c}{p} \\approx S_c \\implies s_c \\approx p S_c\n$$\nTherefore, the effective cutoff of the observed distribution scales linearly with the subsampling probability $p$ and the original cutoff $S_c$. The new cutoff scale is $p S_c$.\n\nThe two results required are:\n1. The asymptotic tail of the observed distribution: $P_{\\mathrm{obs}}(s) \\sim C \\sqrt{p} s^{-3/2}$.\n2. The scaling of the observed cutoff: proportional to $p S_c$.",
            "answer": "$$\n\\boxed{\\begin{pmatrix} C \\sqrt{p} s^{-3/2}  p S_c \\end{pmatrix}}\n$$"
        }
    ]
}