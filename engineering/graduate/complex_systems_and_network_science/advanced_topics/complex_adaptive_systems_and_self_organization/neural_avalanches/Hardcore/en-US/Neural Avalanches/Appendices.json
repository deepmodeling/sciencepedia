{
    "hands_on_practices": [
        {
            "introduction": "The analysis of neural avalanches begins with clear, operational definitions. From a stream of neural activity, we must first discretize time and then identify individual cascade events. This fundamental exercise  provides practice in applying the canonical definitions of avalanche size and duration to a hypothetical segment of binned neural data, translating a raw activity pattern into the quantitative metrics that form the basis of all subsequent statistical analysis.",
            "id": "4292846",
            "problem": "A spike raster from a recurrent neural network is observed over a window of $200\\,\\mathrm{ms}$ and discretized into time bins of width $2\\,\\mathrm{ms}$. In the standard neural avalanche framework, an avalanche is defined as a maximal sequence of consecutive time bins with nonzero activity (no silent bin), bounded before and after by silent bins (bins with zero activity). Avalanche size is the total number of active neuron events accumulated over all bins in the avalanche. Avalanche duration is the time spanned by the avalanche’s consecutive active bins. The average avalanche rate is the total number of active neuron events per unit time over the avalanche duration.\n\nSuppose that during one contiguous sequence of $8$ active bins there are exactly $50$ neurons active in each bin, with no silent bin between the first and last active bin in the sequence, and assume that there are silent bins immediately before and after this sequence so that it constitutes a single avalanche. Using these definitions, compute the avalanche size, the avalanche duration, and the average avalanche rate. Express the avalanche size as a dimensionless count, the avalanche duration in milliseconds, and the average rate in hertz (Hz). No rounding is required; report exact values.",
            "solution": "The user wants me to solve the problem by following these steps.\n1.  **Extract Givens**:\n    *   Time bin width: $\\Delta t = 2\\,\\mathrm{ms}$.\n    *   An avalanche consists of a sequence of $8$ active bins.\n    *   Number of active neurons in each bin: $50$.\n    *   The sequence is bounded by silent bins, thus forming a single avalanche.\n    *   Definition of avalanche size ($S$): total number of active neuron events accumulated over all bins in the avalanche.\n    *   Definition of avalanche duration ($D$): time spanned by the avalanche’s consecutive active bins.\n    *   Definition of average avalanche rate ($R$): total number of active neuron events per unit time over the avalanche duration.\n    *   Required outputs: avalanche size (dimensionless count), avalanche duration (milliseconds), and average avalanche rate (hertz).\n\n2.  **Validate Using Extracted Givens**:\n    *   **Scientifically Grounded**: The problem statement uses standard definitions and concepts from the study of neural avalanches in computational neuroscience and complex systems. The framework of binning spike data and defining avalanches based on contiguous non-empty bins is canonical, originating from the work of Beggs and Plenz. The problem is scientifically sound.\n    *   **Well-Posed**: The problem is clearly stated, with all necessary data and definitions provided to compute the required quantities. The definitions for size, duration, and rate are unambiguous.\n    *   **Objective**: The language is quantitative and precise, free from subjective or opinion-based statements.\n    *   The problem does not exhibit any of the listed flaws (Scientific Unsoundness, Non-Formalizable, Incomplete Setup, Unrealistic, Ill-Posed, Pseudo-Profound, or Outside Scientific Verifiability). The data are consistent and plausible within the context of a neural system or model. The information regarding the $200\\,\\mathrm{ms}$ observation window is contextual and does not conflict with the data for the specific avalanche in question.\n\n3.  **Verdict and Action**:\n    *   The problem is **valid**. A solution will be provided.\n\nThe problem asks for the calculation of three quantities related to a single neural avalanche: its size, duration, and average rate. We are given the necessary parameters to compute these values based on their definitions.\n\nLet $N_{bins}$ be the number of consecutive active time bins in the avalanche, and let $N_{events\\_per\\_bin}$ be the number of active neuron events in each bin. Let $\\Delta t$ be the width of a single time bin.\n\nFrom the problem statement, we have:\n-   Number of active bins, $N_{bins} = 8$.\n-   Number of events per bin, $N_{events\\_per\\_bin} = 50$.\n-   Time bin width, $\\Delta t = 2\\,\\mathrm{ms}$.\n\nFirst, we compute the **avalanche size**, denoted by $S$. The size is defined as the total number of active neuron events accumulated over all bins in the avalanche. Since each of the $N_{bins}$ bins has $N_{events\\_per\\_bin}$ events, the total size is their product.\n$$S = N_{bins} \\times N_{events\\_per\\_bin}$$\nSubstituting the given values:\n$$S = 8 \\times 50 = 400$$\nThe avalanche size is a dimensionless count of events. So, $S = 400$.\n\nSecond, we compute the **avalanche duration**, denoted by $D$. The duration is defined as the total time spanned by the avalanche's consecutive active bins. This is the product of the number of active bins and the width of each time bin.\n$$D = N_{bins} \\times \\Delta t$$\nSubstituting the given values:\n$$D = 8 \\times 2\\,\\mathrm{ms} = 16\\,\\mathrm{ms}$$\nThe problem asks for the duration in milliseconds, so $D = 16\\,\\mathrm{ms}$.\n\nThird, we compute the **average avalanche rate**, denoted by $R$. This is defined as the total number of active neuron events per unit time over the avalanche duration. This is the ratio of the avalanche size $S$ to the avalanche duration $D$.\n$$R = \\frac{S}{D}$$\nThe problem requires the rate to be expressed in hertz ($\\mathrm{Hz}$), which is equivalent to events per second ($\\mathrm{s}^{-1}$). We must first convert the duration $D$ from milliseconds to seconds.\n$$D = 16\\,\\mathrm{ms} = 16 \\times 10^{-3}\\,\\mathrm{s}$$\nNow we can calculate the rate:\n$$R = \\frac{400 \\text{ events}}{16 \\times 10^{-3}\\,\\mathrm{s}} = \\frac{400}{16} \\times 10^3\\,\\mathrm{Hz}$$\n$$R = 25 \\times 10^3\\,\\mathrm{Hz} = 25000\\,\\mathrm{Hz}$$\nExpressing this in standard scientific notation:\n$$R = 2.5 \\times 10^4\\,\\mathrm{Hz}$$\n\nThe three computed quantities are:\n-   Avalanche size: $400$\n-   Avalanche duration: $16\\,\\mathrm{ms}$\n-   Average avalanche rate: $25000\\,\\mathrm{Hz}$ or $2.5 \\times 10^4\\,\\mathrm{Hz}$\n\nThe final answer should present these three numerical values in the specified order.",
            "answer": "$$\\boxed{\\begin{pmatrix} 400  16  2.5 \\times 10^4 \\end{pmatrix}}$$"
        },
        {
            "introduction": "A key finding that launched the study of neural avalanches is that their size and duration distributions often follow power laws, a signature of systems operating near a critical point. This exercise  takes you to the theoretical heart of this phenomenon. By modeling an avalanche as a critical branching process, you will use the powerful framework of probability generating functions to derive the universal $S^{-3/2}$ power-law for avalanche sizes, providing a first-principles understanding of why scale-free dynamics emerge in critical neural systems.",
            "id": "4002313",
            "problem": "In a simplified model of neural avalanches, consider a discrete-time Galton–Watson branching process in which each active neuron at generation $t$ produces a random number $K$ of active descendants at generation $t+1$. Assume the process is initiated by a single active neuron at generation $t=0$, that offspring numbers are independent and identically distributed across neurons and generations, and that the process is critical with mean offspring $\\mathbb{E}[K]=m=1$ and finite, nonzero variance $\\mathrm{Var}(K)=\\sigma^{2}\\in(0,\\infty)$. Define the avalanche size $S$ as the total number of active neurons across all generations until extinction, including the initial neuron.\n\nLet $f(u)=\\sum_{k=0}^{\\infty} p_{k} u^{k}$ denote the probability generating function (PGF) of $K$, and let $T(z)=\\sum_{s=1}^{\\infty} \\mathbb{P}(S=s) z^{s}$ denote the PGF of the avalanche size $S$. Starting from first principles for branching processes and properties of probability generating functions (PGFs), do the following:\n\n- Construct the functional relation between $T(z)$ and $f(u)$ implied by the branching property and the definition of $S$.\n- Analyze the behavior of $T(z)$ in the neighborhood of $z=1$ under the criticality condition $\\mathbb{E}[K]=1$ and finite variance $\\sigma^{2}$.\n- Use a standard transfer theorem for coefficient asymptotics of generating functions with square-root singularities to deduce the asymptotic form of the avalanche size distribution $\\mathbb{P}(S=s)$ for large $s$.\n\nReport the coefficient $C$ (as a closed-form analytic expression in terms of $\\sigma$ only) in the asymptotic law\n$$\n\\mathbb{P}(S=s)\\sim C\\, s^{-3/2}\\quad \\text{as } s\\to\\infty.\n$$\nYour final answer must be the expression for $C$ only. No numerical approximation is required, and no units are involved.",
            "solution": "The problem asks for the derivation of the coefficient $C$ in the asymptotic law for the size distribution of avalanches in a critical Galton-Watson branching process, given by $\\mathbb{P}(S=s)\\sim C\\, s^{-3/2}$. The process starts with a single individual, has a mean offspring of $\\mathbb{E}[K]=m=1$ (criticality), and a finite, non-zero offspring variance $\\mathrm{Var}(K)=\\sigma^2$.\n\nFirst, we establish the functional relationship between the probability generating function (PGF) of the avalanche size, $T(z) = \\sum_{s=1}^{\\infty} \\mathbb{P}(S=s) z^{s}$, and the PGF of the offspring distribution, $f(u) = \\sum_{k=0}^{\\infty} \\mathbb{P}(K=k) u^{k}$. The total avalanche size $S$ is the sum of the initial ancestor (size $1$) and the sizes of the sub-avalanches initiated by its $K$ offspring. Let the number of offspring of the initial ancestor be $K$. Each of these $K$ offspring starts a new, independent branching process, and the size of each sub-avalanche, denoted $S_i$ for $i=1, \\ldots, K$, has the same distribution as $S$. Thus, the total size is $S=1+\\sum_{i=1}^{K} S_i$.\n\nWe can write the PGF for $S$ using the law of total expectation:\n$$T(z) = \\mathbb{E}[z^S] = \\mathbb{E}\\left[z^{1+\\sum_{i=1}^{K} S_i}\\right] = z \\cdot \\mathbb{E}\\left[\\mathbb{E}\\left[z^{\\sum_{i=1}^{K} S_i} \\Big| K\\right]\\right]$$\nSince the $S_i$ are independent and identically distributed, given $K=k$, the PGF of their sum is the product of their individual PGFs: $\\mathbb{E}\\left[z^{\\sum_{i=1}^{k} S_i}\\right] = \\left(\\mathbb{E}[z^S]\\right)^k = (T(z))^k$.\nTaking the expectation over $K$, we get $\\mathbb{E}[(T(z))^K] = \\sum_{k=0}^{\\infty} \\mathbb{P}(K=k) (T(z))^k$, which is by definition the PGF of $K$ evaluated at $u=T(z)$. Therefore, we have:\n$$T(z) = z \\cdot f(T(z))$$\nThis is the fundamental functional equation for the PGF of the total progeny.\n\nNext, we analyze this equation in the neighborhood of $z=1$. For a critical process, the probability of eventual extinction is $1$, meaning $\\mathbb{P}(S  \\infty)=1$. Thus, as $z \\to 1^{-}$, $T(z) = \\sum \\mathbb{P}(S=s)z^s \\to \\sum \\mathbb{P}(S=s) = 1$. Let $u=T(z)$. We perform a Taylor expansion of $f(u)$ around $u=1$. The derivatives of $f(u)$ at $u=1$ relate to the moments of $K$:\n$f(1) = \\sum \\mathbb{P}(K=k) = 1$.\n$f'(1) = \\sum k \\mathbb{P}(K=k) = \\mathbb{E}[K] = m = 1$ (by the criticality condition).\n$f''(1) = \\sum k(k-1) \\mathbb{P}(K=k) = \\mathbb{E}[K(K-1)] = \\mathbb{E}[K^2] - \\mathbb{E}[K]$.\nWe know $\\mathrm{Var}(K) = \\sigma^2 = \\mathbb{E}[K^2] - (\\mathbb{E}[K])^2$. Since $\\mathbb{E}[K]=1$, we have $\\mathbb{E}[K^2] = \\sigma^2 + 1$.\nSo, $f''(1) = (\\sigma^2+1) - 1 = \\sigma^2$.\n\nThe Taylor series for $f(u)$ around $u=1$ is:\n$$f(u) = f(1) + f'(1)(u-1) + \\frac{f''(1)}{2!}(u-1)^2 + O((u-1)^3)$$\n$$f(u) = 1 + 1 \\cdot (u-1) + \\frac{\\sigma^2}{2}(u-1)^2 + O((u-1)^3) = u + \\frac{\\sigma^2}{2}(u-1)^2 + O((u-1)^3)$$\nSubstituting this back into the functional equation $T(z) = z f(T(z))$, with $u=T(z)$:\n$$u = z \\left( u + \\frac{\\sigma^2}{2}(u-1)^2 + O((u-1)^3) \\right)$$\nRearranging the terms:\n$$u(1-z) = z \\frac{\\sigma^2}{2}(u-1)^2 + z O((u-1)^3)$$\nAs $z \\to 1^-$, we have $u=T(z) \\to 1^-$. We can analyze the leading order behavior by setting $z \\approx 1$ and $u \\approx 1$ in the less sensitive parts of the equation:\n$$1 \\cdot (1-z) \\approx 1 \\cdot \\frac{\\sigma^2}{2}(u-1)^2$$\n$$(u-1)^2 \\approx \\frac{2(1-z)}{\\sigma^2}$$\nSince $u=T(z)1$ for $z1$, we have $u-10$, so we must take the negative square root:\n$$u-1 \\approx -\\sqrt{\\frac{2(1-z)}{\\sigma^2}} = -\\frac{\\sqrt{2}}{\\sigma}\\sqrt{1-z}$$\nThus, the asymptotic behavior of $T(z)$ near its singularity at $z=1$ is:\n$$T(z) \\approx 1 - \\frac{\\sqrt{2}}{\\sigma}\\sqrt{1-z} = 1 - \\frac{\\sqrt{2}}{\\sigma}(1-z)^{1/2}$$\nThis square-root singularity governs the asymptotic behavior of the coefficients $\\mathbb{P}(S=s)$.\n\nTo find the asymptotic form of $\\mathbb{P}(S=s)$, we use a transfer theorem from analytic combinatorics. It is often more convenient to apply the theorem to a function with a singularity of the form $(1-z)^{-\\alpha}$ where $\\alpha  0$. We can achieve this by differentiating $T(z)$:\n$$T'(z) = \\sum_{s=1}^{\\infty} s \\, \\mathbb{P}(S=s) z^{s-1}$$\nDifferentiating the asymptotic expression for $T(z)$:\n$$T'(z) \\approx \\frac{d}{dz}\\left(1 - \\frac{\\sqrt{2}}{\\sigma}(1-z)^{1/2}\\right) = - \\frac{\\sqrt{2}}{\\sigma} \\cdot \\frac{1}{2}(1-z)^{-1/2} \\cdot (-1) = \\frac{\\sqrt{2}}{2\\sigma}(1-z)^{-1/2} = \\frac{1}{\\sigma\\sqrt{2}}(1-z)^{-1/2}$$\nThe standard transfer theorem states that if a generating function $A(z) = \\sum a_n z^n$ behaves as $A(z) \\sim K(1-z)^{-\\alpha}$ for $z \\to 1$ (with $\\alpha \\notin \\{0, -1, -2, \\ldots\\}$), then its coefficients have the asymptotic form $a_n \\sim K \\frac{n^{\\alpha-1}}{\\Gamma(\\alpha)}$.\n\nLet's apply this to $T'(z)$. Here we have $K = \\frac{1}{\\sigma\\sqrt{2}}$ and $\\alpha = 1/2$. The coefficients of $T'(z)$ are given by $[z^s]T'(z) = (s+1)\\mathbb{P}(S=s+1)$. Applying the theorem:\n$$[z^s]T'(z) \\sim \\frac{1}{\\sigma\\sqrt{2}} \\frac{s^{(1/2)-1}}{\\Gamma(1/2)} = \\frac{1}{\\sigma\\sqrt{2}} \\frac{s^{-1/2}}{\\sqrt{\\pi}} = \\frac{1}{\\sigma\\sqrt{2\\pi}} s^{-1/2}$$\nwhere we used the known value $\\Gamma(1/2)=\\sqrt{\\pi}$.\nEquating the two expressions for the coefficients of $T'(z)$:\n$$(s+1)\\mathbb{P}(S=s+1) \\sim \\frac{1}{\\sigma\\sqrt{2\\pi}} s^{-1/2}$$\nFor large $s$, we can replace $s+1$ with $s$ on the left-hand side, and $s$ with $s-1$ on the right-hand side. Let $n=s+1$. For large $n$:\n$$n \\mathbb{P}(S=n) \\sim \\frac{1}{\\sigma\\sqrt{2\\pi}} (n-1)^{-1/2} \\approx \\frac{1}{\\sigma\\sqrt{2\\pi}} n^{-1/2}$$\nDividing by $n$, we obtain the asymptotic distribution for the avalanche size $S$:\n$$\\mathbb{P}(S=n) \\sim \\frac{1}{\\sigma\\sqrt{2\\pi}} n^{-3/2}$$\nComparing this to the requested form $\\mathbb{P}(S=s)\\sim C\\, s^{-3/2}$, we can identify the coefficient $C$.\n\nThe coefficient $C$ is therefore:\n$$C = \\frac{1}{\\sigma\\sqrt{2\\pi}}$$\nThis is the celebrated result for the size distribution of critical branching processes.",
            "answer": "$$\\boxed{\\frac{1}{\\sigma\\sqrt{2\\pi}}}$$"
        },
        {
            "introduction": "A significant challenge in neuroscience is that our recording technologies only capture a small fraction of the total neural activity in a circuit. This inevitable subsampling can distort our measurements and potentially obscure the underlying dynamics. This advanced practice  tackles this issue head-on by asking you to derive how random, spatial subsampling affects the observed avalanche size distribution, revealing how the true power-law signature is altered and offering crucial insights for the interpretation of experimental data.",
            "id": "4292899",
            "problem": "Consider a theoretical model of neural avalanches based on a critical Galton–Watson branching process, where an avalanche is defined as the total number of activated neurons before extinction. Let the avalanche size be denoted by $S \\in \\mathbb{N}$ and suppose that, in the critical regime with finite offspring variance, the size distribution has the well-tested asymptotic form $P(S) \\sim C S^{-3/2}$ for large $S$, up to a finite-size cutoff $S_{c}$ imposed by either network size or observation window constraints. Assume that due to random spatial subsampling, each activated neuron is independently observed with probability $p \\in (0,1)$, so that the observed avalanche size $s$ is the number of observed activated neurons within the avalanche.\n\nStarting from fundamental probabilistic definitions and widely accepted asymptotics, derive the leading-order asymptotic form of the observed size distribution tail $P_{\\mathrm{obs}}(s)$ for large $s$ under subsampling at fraction $p$, and determine how the effective cutoff in the observed distribution scales with $p$. Your derivation must explicitly begin with the representation of $P_{\\mathrm{obs}}(s)$ as a mixture over $S$ with the binomial sampling model, and proceed using first-principles approximations justified for large avalanches (e.g., Stirling approximations and the Central Limit Theorem (CLT) for the binomial). Express the final tail in terms of $s$, $p$, and $C$, and express the cutoff scale in terms of $p$ and $S_{c}$.\n\nYour final answer must be a single analytical object. If you report both the tail expression and the cutoff scaling, arrange them as a two-entry row matrix in the order “tail, cutoff.” No units are required. Do not provide any inequalities in the final answer.",
            "solution": "The problem asks for the derivation of the asymptotic form of the observed size distribution of neural avalanches under subsampling, and the scaling of the effective cutoff. We begin by formalizing the problem statement.\n\nThe true avalanche size, $S$, is a random variable whose distribution for large $S$ has the asymptotic form $P(S) \\sim C S^{-3/2}$, where $C$ is a constant. This distribution is subject to a finite-size cutoff $S_c$. Each of the $S$ activated neurons in a true avalanche is observed independently with a probability $p \\in (0,1)$. The observed avalanche size, $s$, is the number of neurons detected.\n\nThe conditional probability of observing an avalanche of size $s$ given a true avalanche of size $S$ follows a binomial distribution, since each of the $S$ neurons represents an independent Bernoulli trial with success probability $p$. This is given by:\n$$\nP(s|S) = \\binom{S}{s} p^s (1-p)^{S-s}\n$$\nThis is defined for $0 \\le s \\le S$. If $s  S$, then $P(s|S) = 0$.\n\nThe total probability of observing an avalanche of size $s$, denoted $P_{\\mathrm{obs}}(s)$, is obtained by marginalizing over all possible true avalanche sizes $S$. This is a sum over the product of the conditional probability and the prior probability of the true size $S$:\n$$\nP_{\\mathrm{obs}}(s) = \\sum_{S=s}^{S_c} P(s|S) P(S)\n$$\nThe sum starts at $S=s$ because it is impossible to observe more neurons than were actually activated. The sum ends at the system cutoff $S_c$.\n\nSubstituting the given asymptotic form for $P(S)$, we get:\n$$\nP_{\\mathrm{obs}}(s) \\approx \\sum_{S=s}^{S_c} \\left[ \\binom{S}{s} p^s (1-p)^{S-s} \\right] \\left( C S^{-3/2} \\right)\n$$\nWe are interested in the behavior of $P_{\\mathrm{obs}}(s)$ for large $s$. When $s$ is large, any $S \\ge s$ in the sum is also large. This justifies two key approximations:\n1. The sum can be approximated by an integral, as the summand varies relatively slowly with $S$ for large $S$.\n2. The binomial distribution $P(s|S)$ can be approximated by a Gaussian distribution. This is a consequence of the De Moivre-Laplace theorem, a special case of the Central Limit Theorem. The binomial distribution $\\mathrm{Bin}(S,p)$ has a mean $\\mu = Sp$ and variance $\\sigma^2 = Sp(1-p)$. The Gaussian approximation is:\n$$\nP(s|S) \\approx \\frac{1}{\\sqrt{2\\pi S p(1-p)}} \\exp\\left( -\\frac{(s - Sp)^2}{2Sp(1-p)} \\right)\n$$\nThis approximation is valid when $Sp(1-p) \\gg 1$. Since $s$ is large and $p$ is fixed, the dominant contributions to the sum will come from $S$ near $s/p$, for which $S$ is also large, validating the condition.\n\nReplacing the sum with an integral and substituting the approximations, we have:\n$$\nP_{\\mathrm{obs}}(s) \\approx C \\int_{s}^{S_c} \\frac{1}{\\sqrt{2\\pi S p(1-p)}} \\exp\\left( -\\frac{(s - Sp)^2}{2Sp(1-p)} \\right) S^{-3/2} dS\n$$\nCombining the terms involving $S$:\n$$\nP_{\\mathrm{obs}}(s) \\approx \\frac{C}{\\sqrt{2\\pi p(1-p)}} \\int_{s}^{S_c} S^{-1/2} S^{-3/2} \\exp\\left( -\\frac{(s - Sp)^2}{2Sp(1-p)} \\right) dS\n$$\n$$\nP_{\\mathrm{obs}}(s) \\approx \\frac{C}{\\sqrt{2\\pi p(1-p)}} \\int_{s}^{S_c} S^{-2} \\exp\\left( -\\frac{(s - Sp)^2}{2Sp(1-p)} \\right) dS\n$$\nThis integral can be evaluated using Laplace's method (or the saddle-point approximation), as the exponential term is sharply peaked for large $s$. The argument of the exponential is maximized (i.e., its magnitude is minimized) when $s - Sp = 0$, which occurs at $S_0 = s/p$. For $p \\in (0,1)$, this peak $S_0$ is greater than the lower integration limit $s$. As long as $S_0  S_c$, the peak is within the integration domain.\n\nLet the integrand be $g(S) \\exp(h(S))$, with $g(S) = S^{-2}$ and $h(S) = -\\frac{(s - Sp)^2}{2Sp(1-p)}$. According to Laplace's method, the integral is approximated by the value of the slowly varying part $g(S)$ at the peak $S_0$, multiplied by the integral of the Gaussian function that approximates $\\exp(h(S))$ around $S_0$.\nThe integral is approximately:\n$$\nI \\approx g(S_0) \\exp(h(S_0)) \\sqrt{\\frac{2\\pi}{-h''(S_0)}}\n$$\nFirst, we evaluate the terms at the saddle point $S_0 = s/p$:\n- $g(S_0) = (s/p)^{-2} = p^2s^{-2}$.\n- $h(S_0) = -\\frac{(s - (s/p)p)^2}{2(s/p)p(1-p)} = 0$, so $\\exp(h(S_0)) = 1$.\n\nNext, we compute the second derivative of $h(S)$. It is easier to expand the argument of the exponential around $S=S_0$. Let $S = S_0 + \\delta S = s/p + \\delta S$.\nThe numerator of the exponent is $(s - Sp)^2 = (s - (s/p + \\delta S)p)^2 = (s - s - p\\delta S)^2 = p^2(\\delta S)^2$.\nThe denominator is $2Sp(1-p) = 2(s/p + \\delta S)p(1-p) \\approx 2(s/p)p(1-p) = 2s(1-p)$ for small $\\delta S$.\nSo, near the peak, $h(S) \\approx -\\frac{p^2(\\delta S)^2}{2s(1-p)}$. This corresponds to a Gaussian with variance $\\sigma_S^2 = \\frac{s(1-p)}{p^2}$. The term $-h''(S_0)$ is $1/\\sigma_S^2 = \\frac{p^2}{s(1-p)}$.\n\nThe value of the Gaussian integral over its whole domain is $\\sqrt{2\\pi \\sigma_S^2} = \\sqrt{\\frac{2\\pi s(1-p)}{p^2}} = \\frac{\\sqrt{2\\pi s(1-p)}}{p}$.\nSo, the approximation for the integral is:\n$$\n\\int_{s}^{S_c} \\dots dS \\approx g(S_0) \\cdot \\frac{\\sqrt{2\\pi s(1-p)}}{p} = (p^2s^{-2}) \\frac{\\sqrt{2\\pi s(1-p)}}{p} = p s^{-3/2} \\sqrt{2\\pi(1-p)}\n$$\nNow, we substitute this result back into the expression for $P_{\\mathrm{obs}}(s)$:\n$$\nP_{\\mathrm{obs}}(s) \\approx \\frac{C}{\\sqrt{2\\pi p(1-p)}} \\left( p s^{-3/2} \\sqrt{2\\pi(1-p)} \\right)\n$$\nThe terms involving $\\sqrt{2\\pi(1-p)}$ cancel out.\n$$\nP_{\\mathrm{obs}}(s) \\approx C \\frac{p}{\\sqrt{p}} s^{-3/2} = C \\sqrt{p} s^{-3/2}\n$$\nThis is the leading-order asymptotic form for the observed size distribution. The power-law exponent of $-3/2$ is preserved under subsampling, but the normalization constant is scaled by $\\sqrt{p}$.\n\nNext, we determine the scaling of the effective cutoff in the observed distribution. The derivation above is based on the saddle-point approximation, which is valid as long as the saddle point $S_0 = s/p$ is located well within the support of the true distribution, i.e., $S_0 \\ll S_c$. As the observed size $s$ increases, so does the corresponding most likely true size $S_0$. The power-law behavior of $P_{\\mathrm{obs}}(s)$ will break down when $S_0$ approaches the true cutoff $S_c$. The effective cutoff in the observed distribution, let's call it $s_c$, can thus be estimated by the condition $S_0 \\approx S_c$.\n$$\n\\frac{s_c}{p} \\approx S_c \\implies s_c \\approx p S_c\n$$\nTherefore, the effective cutoff of the observed distribution scales linearly with the subsampling probability $p$ and the original cutoff $S_c$. The new cutoff scale is $p S_c$.\n\nThe two results required are:\n1. The asymptotic tail of the observed distribution: $P_{\\mathrm{obs}}(s) \\sim C \\sqrt{p} s^{-3/2}$.\n2. The scaling of the observed cutoff: proportional to $p S_c$.",
            "answer": "$$\n\\boxed{\\begin{pmatrix} C \\sqrt{p} s^{-3/2}  p S_c \\end{pmatrix}}\n$$"
        }
    ]
}