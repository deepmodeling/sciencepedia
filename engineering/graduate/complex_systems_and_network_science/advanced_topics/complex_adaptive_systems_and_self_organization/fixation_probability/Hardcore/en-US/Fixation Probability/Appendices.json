{
    "hands_on_practices": [
        {
            "introduction": "To truly understand fixation probability, we must begin with its fundamental definition within the framework of Markov chains. This first exercise  strips the problem down to its essential components: a simple birth-death process on a small population. By applying first-step analysis, you will derive and solve the system of linear equations that governs the probability of absorption into the fixation state, reinforcing the core mathematical principles from the ground up.",
            "id": "4277530",
            "problem": "Consider a well-mixed population of size $N=5$ with two types: a resident type and a mutant type. The population evolves as a time-homogeneous birth–death Markov chain on the state space $\\{0,1,2,3,4,5\\}$, where state $i$ denotes that there are $i$ mutants in the population. States $0$ and $5$ are absorbing, corresponding to extinction and fixation of the mutant type, respectively. For transient states $i \\in \\{1,2,3,4\\}$, the one-step transition probabilities are given by\n$$\n\\Pr(i \\to i+1)=p_i,\\quad \\Pr(i \\to i-1)=q_i,\\quad \\Pr(i \\to i)=r_i,\n$$\nwith $p_i+q_i+r_i=1$ for each $i$. The explicit values are:\n- For $i=1$: $p_1=\\frac{3}{10}$, $q_1=\\frac{1}{2}$, $r_1=\\frac{1}{5}$.\n- For $i=2$: $p_2=\\frac{2}{5}$, $q_2=\\frac{2}{5}$, $r_2=\\frac{1}{5}$.\n- For $i=3$: $p_3=\\frac{1}{2}$, $q_3=\\frac{3}{10}$, $r_3=\\frac{1}{5}$.\n- For $i=4$: $p_4=\\frac{3}{5}$, $q_4=\\frac{1}{5}$, $r_4=\\frac{1}{5}$.\n\nUsing only the foundational definition of absorption (fixation) probability for a time-homogeneous Markov chain and first-step (backward) conditioning, derive and solve the linear system that governs the absorption probabilities into state $5$. Let $u_i$ denote the probability that the chain is eventually absorbed at state $5$ starting from state $i$. Compute the fixation probability starting from a single mutant, i.e., $u_1$. Express your final answer as an exact value. Do not round.",
            "solution": "The problem asks for the fixation probability of a mutant type in a population of size $N=5$. The system is modeled as a time-homogeneous birth–death Markov chain on the state space $\\{0, 1, 2, 3, 4, 5\\}$, where the state $i$ represents the number of mutants. The states $0$ and $5$ are absorbing, corresponding to the extinction and fixation of the mutant, respectively.\n\nLet $u_i$ be the probability of eventual absorption into state $5$ (fixation), given that the process starts in state $i$. By definition, the boundary conditions for the absorbing states are:\n$$\nu_0 = 0 \\quad (\\text{extinction})\n$$\n$$\nu_5 = 1 \\quad (\\text{fixation})\n$$\n\nFor the transient states $i \\in \\{1, 2, 3, 4\\}$, we can establish a system of linear equations for the probabilities $u_i$ by using first-step (or backward) conditioning. This method relies on the law of total probability, conditioning on the outcome of the first step of the process. For any transient state $i$, the probability of eventual fixation $u_i$ is the sum of the probabilities of fixation from each possible next state, weighted by the transition probabilities from state $i$.\n\nThe general equation is:\n$$\nu_i = \\sum_{j=0}^{N} \\Pr(\\text{next state is } j | \\text{current state is } i) \\times u_j\n$$\nFor the given birth-death process, the possible transitions from a state $i \\in \\{1, 2, 3, 4\\}$ are to states $i+1$, $i-1$, or $i$. The equation thus becomes:\n$$\nu_i = p_i u_{i+1} + q_i u_{i-1} + r_i u_i\n$$\nwhere $p_i = \\Pr(i \\to i+1)$, $q_i = \\Pr(i \\to i-1)$, and $r_i = \\Pr(i \\to i)$.\n\nWe can simplify this equation by collecting the terms involving $u_i$:\n$$\n(1 - r_i)u_i = p_i u_{i+1} + q_i u_{i-1}\n$$\nSince $p_i + q_i + r_i = 1$, we have $1 - r_i = p_i + q_i$. Substituting this into the equation gives:\n$$\n(p_i + q_i)u_i = p_i u_{i+1} + q_i u_{i-1}\n$$\nThis equation relates the fixation probability at state $i$ to the probabilities at its neighboring states. We now apply this to each transient state using the provided transition probabilities.\n\nFor $i=1$:\nThe equation is $(p_1+q_1)u_1 = p_1 u_2 + q_1 u_0$.\nGiven $p_1 = \\frac{3}{10}$, $q_1 = \\frac{1}{2}$, and the boundary condition $u_0=0$:\n$$\n\\left(\\frac{3}{10} + \\frac{5}{10}\\right)u_1 = \\frac{3}{10} u_2 + \\frac{5}{10}(0) \\implies \\frac{8}{10}u_1 = \\frac{3}{10}u_2 \\implies 8u_1 = 3u_2\n$$\nThis gives our first equation: $8u_1 - 3u_2 = 0$.\n\nFor $i=2$:\nThe equation is $(p_2+q_2)u_2 = p_2 u_3 + q_2 u_1$.\nGiven $p_2 = \\frac{2}{5}$ and $q_2 = \\frac{2}{5}$:\n$$\n\\left(\\frac{2}{5} + \\frac{2}{5}\\right)u_2 = \\frac{2}{5} u_3 + \\frac{2}{5} u_1 \\implies \\frac{4}{5}u_2 = \\frac{2}{5}u_3 + \\frac{2}{5}u_1 \\implies 2u_2 = u_3 + u_1\n$$\nThis gives our second equation: $u_1 - 2u_2 + u_3 = 0$.\n\nFor $i=3$:\nThe equation is $(p_3+q_3)u_3 = p_3 u_4 + q_3 u_2$.\nGiven $p_3 = \\frac{1}{2}$ and $q_3 = \\frac{3}{10}$:\n$$\n\\left(\\frac{5}{10} + \\frac{3}{10}\\right)u_3 = \\frac{5}{10} u_4 + \\frac{3}{10} u_2 \\implies \\frac{8}{10}u_3 = \\frac{5}{10}u_4 + \\frac{3}{10}u_2 \\implies 8u_3 = 5u_4 + 3u_2\n$$\nThis gives our third equation: $3u_2 - 8u_3 + 5u_4 = 0$.\n\nFor $i=4$:\nThe equation is $(p_4+q_4)u_4 = p_4 u_5 + q_4 u_3$.\nGiven $p_4 = \\frac{3}{5}$, $q_4 = \\frac{1}{5}$, and the boundary condition $u_5=1$:\n$$\n\\left(\\frac{3}{5} + \\frac{1}{5}\\right)u_4 = \\frac{3}{5}(1) + \\frac{1}{5}u_3 \\implies \\frac{4}{5}u_4 = \\frac{3}{5} + \\frac{1}{5}u_3 \\implies 4u_4 = 3 + u_3\n$$\nThis gives our fourth equation: $u_3 - 4u_4 = -3$.\n\nWe have now derived the following system of four linear equations for the four unknown probabilities $u_1, u_2, u_3, u_4$:\n1.  $8u_1 - 3u_2 = 0$\n2.  $u_1 - 2u_2 + u_3 = 0$\n3.  $3u_2 - 8u_3 + 5u_4 = 0$\n4.  $u_3 - 4u_4 = -3$\n\nWe solve this system to find $u_1$. We use substitution.\nFrom equation (1), we express $u_2$ in terms of $u_1$:\n$$\nu_2 = \\frac{8}{3}u_1\n$$\nSubstitute this into equation (2) to find $u_3$ in terms of $u_1$:\n$$\nu_1 - 2\\left(\\frac{8}{3}u_1\\right) + u_3 = 0 \\implies u_1 - \\frac{16}{3}u_1 + u_3 = 0 \\implies -\\frac{13}{3}u_1 + u_3 = 0 \\implies u_3 = \\frac{13}{3}u_1\n$$\nFrom equation (4), we express $u_4$ in terms of $u_3$, and then in terms of $u_1$:\n$$\n4u_4 = u_3 + 3 \\implies u_4 = \\frac{1}{4}(u_3 + 3) = \\frac{1}{4}\\left(\\frac{13}{3}u_1 + 3\\right) = \\frac{13}{12}u_1 + \\frac{3}{4}\n$$\nNow, substitute the expressions for $u_2, u_3, u_4$ all in terms of $u_1$ into the final remaining equation (3):\n$$\n3\\left(\\frac{8}{3}u_1\\right) - 8\\left(\\frac{13}{3}u_1\\right) + 5\\left(\\frac{13}{12}u_1 + \\frac{3}{4}\\right) = 0\n$$\nSimplify the equation:\n$$\n8u_1 - \\frac{104}{3}u_1 + \\frac{65}{12}u_1 + \\frac{15}{4} = 0\n$$\nTo eliminate the denominators, we multiply the entire equation by the least common multiple of $3$, $12$, and $4$, which is $12$:\n$$\n12(8u_1) - 4(104u_1) + 1(65u_1) + 3(15) = 0\n$$\n$$\n96u_1 - 416u_1 + 65u_1 + 45 = 0\n$$\nCombine the terms with $u_1$:\n$$\n(96 - 416 + 65)u_1 + 45 = 0\n$$\n$$\n(161 - 416)u_1 + 45 = 0\n$$\n$$\n-255u_1 + 45 = 0\n$$\nFinally, we solve for $u_1$:\n$$\n255u_1 = 45 \\implies u_1 = \\frac{45}{255}\n$$\nTo simplify the fraction, we can divide the numerator and denominator by their greatest common divisor. Both are divisible by $5$:\n$$\nu_1 = \\frac{45 \\div 5}{255 \\div 5} = \\frac{9}{51}\n$$\nBoth are now divisible by $3$:\n$$\nu_1 = \\frac{9 \\div 3}{51 \\div 3} = \\frac{3}{17}\n$$\nThe fixation probability starting from a single mutant is $u_1 = \\frac{3}{17}$.",
            "answer": "$$\n\\boxed{\\frac{3}{17}}\n$$"
        },
        {
            "introduction": "While well-mixed populations provide a crucial baseline, real-world evolution often unfolds on structured networks. This practice  explores how population structure and microscopic dynamics jointly determine outcomes, using a star graph as a model for heterogeneous systems. You will calculate fixation probabilities for different initial mutant placements under both Birth-Death (BD) and Death-Birth (DB) update rules, revealing how these subtle changes can dramatically alter the effects of selection.",
            "id": "4277558",
            "problem": "Consider a star graph with $N=3$ nodes, consisting of a single hub connected to $L=2$ leaves. An evolutionary process proceeds according to the Moran process on graphs with two types: a mutant type of fitness $r0$ and a resident type of fitness $1$. Two stochastic update mechanisms are considered:\n\n- Birth–Death (BD) rule: at each step, one node is selected to reproduce with probability proportional to its fitness, and one of its neighbors is selected uniformly at random to be replaced by the offspring.\n\n- Death–Birth (DB) rule: at each step, one node is selected uniformly at random to die, and one of its neighbors is selected to reproduce with probability proportional to its fitness to fill the vacancy.\n\nLet the state of the system be denoted by $(h,k)$, where $h\\in\\{0,1\\}$ indicates whether the hub is mutant ($h=1$) or resident ($h=0$), and $k\\in\\{0,1,2\\}$ is the number of mutant leaves. The absorbing states are $(1,2)$ (fixation of mutants) and $(0,0)$ (extinction of mutants).\n\nAssume the initial population has exactly two mutants in one of the following configurations:\n\n- Configuration A: one mutant at the hub and one mutant at a leaf, i.e., state $(1,1)$.\n\n- Configuration B: two mutant leaves and a resident hub, i.e., state $(0,2)$.\n\nStarting from first principles (the definitions above), derive the exact fixation probabilities under both the Birth–Death (BD) rule and the Death–Birth (DB) rule for Configuration A and Configuration B. Express your final answers as closed-form functions of $r$. Provide the four fixation probabilities in the following order: BD with Configuration A, BD with Configuration B, DB with Configuration A, DB with Configuration B. The final answer must be a single analytical expression. No rounding is required.",
            "solution": "The problem asks for the fixation probabilities of a mutant type on a star graph with $N=3$ nodes under two different evolutionary update rules. The graph consists of one central hub and $L=2$ leaves. Let the hub be node $0$, and the leaves be nodes $1$ and $2$. The fitness of the mutant type is $r  0$, and the fitness of the resident type is $1$.\n\nThe state of the system is given by $(h, k)$, where $h \\in \\{0, 1\\}$ is the type of the hub ($1$ for mutant, $0$ for resident) and $k \\in \\{0, 1, 2\\}$ is the number of mutant leaves. The absorbing states are $(0,0)$ (extinction) and $(1,2)$ (fixation). The transient states are $(0,1)$, $(0,2)$, $(1,0)$, and $(1,1)$.\n\nLet $\\rho_{h,k}$ be the probability of eventual fixation starting from state $(h,k)$. By definition, $\\rho_{0,0} = 0$ and $\\rho_{1,2} = 1$. For any transient state $i$, the fixation probability $\\rho_i$ satisfies the relation $\\rho_i = \\sum_j P_{ij} \\rho_j$, where $P_{ij}$ is the one-step transition probability from state $i$ to state $j$, and the sum is over all possible next states. This leads to a system of linear equations for the fixation probabilities of the transient states.\n\nWe need to find the fixation probabilities for two initial configurations:\nConfiguration A: state $(1,1)$, giving $\\rho_A = \\rho_{1,1}$.\nConfiguration B: state $(0,2)$, giving $\\rho_B = \\rho_{0,2}$.\n\nWe will analyze the two update rules separately.\n\n### Birth–Death (BD) Rule\nUnder the BD rule, a node is chosen to reproduce with probability proportional to its fitness. The total fitness of the population in a given state is $W$. An individual at node $i$ with fitness $f_i$ is chosen with probability $f_i / W$. Its offspring replaces a uniformly chosen random neighbor.\n\nThe transient states are $(0,1)$, $(0,2)$, $(1,0)$, and $(1,1)$.\nThe total fitness $W$ for each state is:\n- State $(0,1)$: One mutant leaf ($r$), one resident leaf ($1$), one resident hub ($1$). $W = r+1+1 = r+2$.\n- State $(0,2)$: Two mutant leaves ($r$ each), one resident hub ($1$). $W = 2r+1$.\n- State $(1,0)$: One mutant hub ($r$), two resident leaves ($1$ each). $W = r+1+1 = r+2$.\n- State $(1,1)$: One mutant hub ($r$), one mutant leaf ($r$), one resident leaf ($1$). $W = 2r+1$.\n\nLet's derive the transition probabilities and the corresponding equations for the fixation probabilities $\\rho_{h,k}$.\n\nFrom state $(0,1)$: $W = r+2$.\n- The mutant leaf reproduces (prob $r/W$). Its neighbor is the hub, which is replaced. State $\\to (1,1)$. $P_{(0,1)\\to(1,1)} = \\frac{r}{r+2}$.\n- The resident hub reproduces (prob $1/W$). It replaces one of its two neighbors (the leaves) with probability $1/2$. If it replaces the mutant leaf, the system goes to extinction. State $\\to (0,0)$. $P_{(0,1)\\to(0,0)} = \\frac{1}{W} \\cdot \\frac{1}{2} = \\frac{1}{2(r+2)}$.\nThe equation for $\\rho_{0,1}$ is $\\rho_{0,1} = P_{(0,1)\\to(1,1)}\\rho_{1,1} + P_{(0,1)\\to(0,0)}\\rho_{0,0} + \\dots$.\nConsidering only transitions that change the state and lead to non-zero fixation probability term:\n$(1 - P_{(0,1)\\to(0,1)})\\rho_{0,1} = P_{(0,1)\\to(1,1)}\\rho_{1,1} + P_{(0,1)\\to(0,0)}\\rho_{0,0}$.\n$(\\frac{r}{r+2} + \\frac{1}{2(r+2)}) \\rho_{0,1} = \\frac{r}{r+2}\\rho_{1,1}$.\n$\\frac{2r+1}{2(r+2)} \\rho_{0,1} = \\frac{2r}{2(r+2)}\\rho_{1,1} \\implies (2r+1)\\rho_{0,1} = 2r\\rho_{1,1}$.\n(1) $\\rho_{0,1} = \\frac{2r}{2r+1}\\rho_{1,1}$.\n\nFrom state $(1,1)$: $W = 2r+1$.\n- The mutant hub reproduces (prob $r/W$). It replaces a neighbor (prob $1/2$ for each). If it replaces the resident leaf, the system fixates. State $\\to (1,2)$. $P_{(1,1)\\to(1,2)} = \\frac{r}{W} \\cdot \\frac{1}{2} = \\frac{r}{2(2r+1)}$.\n- The resident leaf reproduces (prob $1/W$). It replaces its neighbor, the hub. State $\\to (0,1)$. $P_{(1,1)\\to(0,1)} = \\frac{1}{W} = \\frac{1}{2r+1}$.\nThe equation is $(1-P_{(1,1)\\to(1,1)})\\rho_{1,1} = P_{(1,1)\\to(1,2)}\\rho_{1,2} + P_{(1,1)\\to(0,1)}\\rho_{0,1}$.\n$(\\frac{r}{2(2r+1)} + \\frac{1}{2r+1}) \\rho_{1,1} = \\frac{r}{2(2r+1)}(1) + \\frac{1}{2r+1}\\rho_{0,1}$.\n$\\frac{r+2}{2(2r+1)}\\rho_{1,1} = \\frac{r}{2(2r+1)} + \\frac{2}{2(2r+1)}\\rho_{0,1}$.\n(2) $(r+2)\\rho_{1,1} = r + 2\\rho_{0,1}$.\n\nNow we solve for $\\rho_{1,1}$ (Configuration A) by substituting (1) into (2):\n$(r+2)\\rho_{1,1} = r + 2\\left(\\frac{2r}{2r+1}\\rho_{1,1}\\right) = r + \\frac{4r}{2r+1}\\rho_{1,1}$.\n$\\rho_{1,1} \\left(r+2 - \\frac{4r}{2r+1}\\right) = r$.\n$\\rho_{1,1} \\left(\\frac{(r+2)(2r+1)-4r}{2r+1}\\right) = r$.\n$\\rho_{1,1} \\left(\\frac{2r^2+r+4r+2-4r}{2r+1}\\right) = r$.\n$\\rho_{1,1} \\left(\\frac{2r^2+r+2}{2r+1}\\right) = r$.\n$\\rho_{A, BD} = \\rho_{1,1} = \\frac{r(2r+1)}{2r^2+r+2}$.\n\nTo find $\\rho_{0,2}$ (Configuration B), we need its transition probabilities.\nFrom state $(0,2)$: $W = 2r+1$.\n- A mutant leaf reproduces (prob $2r/W$). Replaces the hub. State $\\to (1,2)$ (fixation). $P_{(0,2)\\to(1,2)} = \\frac{2r}{2r+1}$.\n- The resident hub reproduces (prob $1/W$). Replaces a mutant leaf. State $\\to (0,1)$. $P_{(0,2)\\to(0,1)} = \\frac{1}{2r+1}$.\nThe equation for $\\rho_{0,2}$ is $\\rho_{0,2} = P_{(0,2)\\to(1,2)}\\rho_{1,2} + P_{(0,2)\\to(0,1)}\\rho_{0,1}$.\n(3) $\\rho_{0,2} = \\frac{2r}{2r+1}(1) + \\frac{1}{2r+1}\\rho_{0,1}$.\nUsing (1) and the expression for $\\rho_{1,1}$:\n$\\rho_{0,1} = \\frac{2r}{2r+1} \\left(\\frac{r(2r+1)}{2r^2+r+2}\\right) = \\frac{2r^2}{2r^2+r+2}$.\nSubstitute this into (3):\n$\\rho_{B, BD} = \\rho_{0,2} = \\frac{2r}{2r+1} + \\frac{1}{2r+1}\\left(\\frac{2r^2}{2r^2+r+2}\\right) = \\frac{2r(2r^2+r+2) + 2r^2}{(2r+1)(2r^2+r+2)}$.\n$\\rho_{B, BD} = \\frac{4r^3+2r^2+4r+2r^2}{(2r+1)(2r^2+r+2)} = \\frac{4r^3+4r^2+4r}{(2r+1)(2r^2+r+2)} = \\frac{4r(r^2+r+1)}{(2r+1)(2r^2+r+2)}$.\n\n### Death–Birth (DB) Rule\nUnder the DB rule, a node is chosen uniformly at random to die (prob $1/N = 1/3$). Its neighbors then compete to reproduce, with probability proportional to their fitness, to fill the vacancy.\n\nFrom state $(0,1)$: one mutant leaf, one resident leaf, one resident hub.\n- Hub dies (prob $1/3$). Neighbors (mutant leaf, resident leaf) compete. Fitness sum is $r+1$. Mutant reproduces with prob $r/(r+1)$. State $\\to (1,1)$. $P_{(0,1)\\to(1,1)} = \\frac{1}{3}\\frac{r}{r+1}$.\n- Mutant leaf dies (prob $1/3$). Its neighbor (resident hub) reproduces. State $\\to (0,0)$. $P_{(0,1)\\to(0,0)} = \\frac{1}{3}$.\nThe equation from these transitions is $(1-P_{(0,1)\\to(0,1)})\\rho_{0,1} = P_{(0,1)\\to(1,1)}\\rho_{1,1} + P_{(0,1)\\to(0,0)}\\rho_{0,0}$.\n$(\\frac{1}{3}\\frac{r}{r+1} + \\frac{1}{3})\\rho_{0,1} = \\frac{1}{3}\\frac{r}{r+1}\\rho_{1,1}$.\n$\\frac{r+r+1}{3(r+1)}\\rho_{0,1} = \\frac{r}{3(r+1)}\\rho_{1,1} \\implies (2r+1)\\rho_{0,1} = r\\rho_{1,1}$.\n(4) $\\rho_{0,1} = \\frac{r}{2r+1}\\rho_{1,1}$.\n\nFrom state $(1,1)$: mutant hub, one mutant leaf, one resident leaf.\n- Hub dies (prob $1/3$). Neighbors (mutant leaf, resident leaf) compete. Fitness sum $r+1$. Resident reproduces with prob $1/(r+1)$. State $\\to (0,1)$. $P_{(1,1)\\to(0,1)} = \\frac{1}{3}\\frac{1}{r+1}$.\n- Resident leaf dies (prob $1/3$). Its neighbor (mutant hub) reproduces. State $\\to (1,2)$. $P_{(1,1)\\to(1,2)} = \\frac{1}{3}$.\nThe equation is $(1-P_{(1,1)\\to(1,1)})\\rho_{1,1} = P_{(1,1)\\to(1,2)}\\rho_{1,2} + P_{(1,1)\\to(0,1)}\\rho_{0,1}$.\n$(\\frac{1}{3}\\frac{1}{r+1} + \\frac{1}{3}) \\rho_{1,1} = \\frac{1}{3}(1) + \\frac{1}{3(r+1)}\\rho_{0,1}$.\n$\\frac{1+r+1}{3(r+1)}\\rho_{1,1} = \\frac{r+1}{3(r+1)} + \\frac{1}{3(r+1)}\\rho_{0,1}$.\n(5) $(r+2)\\rho_{1,1} = r+1 + \\rho_{0,1}$.\n\nSolve for $\\rho_{1,1}$ (Configuration A) by substituting (4) into (5):\n$(r+2)\\rho_{1,1} = r+1 + \\frac{r}{2r+1}\\rho_{1,1}$.\n$\\rho_{1,1}\\left(r+2 - \\frac{r}{2r+1}\\right) = r+1$.\n$\\rho_{1,1}\\left(\\frac{(r+2)(2r+1)-r}{2r+1}\\right) = r+1$.\n$\\rho_{1,1}\\left(\\frac{2r^2+5r+2-r}{2r+1}\\right) = r+1$.\n$\\rho_{1,1}\\left(\\frac{2r^2+4r+2}{2r+1}\\right) = r+1$.\n$\\rho_{1,1}\\left(\\frac{2(r+1)^2}{2r+1}\\right) = r+1$.\n$\\rho_{A, DB} = \\rho_{1,1} = \\frac{(r+1)(2r+1)}{2(r+1)^2} = \\frac{2r+1}{2(r+1)}$.\n\nTo find $\\rho_{0,2}$ (Configuration B), we analyze its transitions.\nFrom state $(0,2)$: two mutant leaves, one resident hub.\n- Hub dies (prob $1/3$). Neighbors are two mutant leaves. A mutant reproduces. State $\\to (1,2)$ (fixation). $P_{(0,2)\\to(1,2)} = \\frac{1}{3}$.\n- A mutant leaf dies (prob $2/3$). Neighbor is resident hub, which reproduces. State $\\to (0,1)$. $P_{(0,2)\\to(0,1)} = \\frac{2}{3}$.\nThe equation is $\\rho_{0,2} = P_{(0,2)\\to(1,2)}\\rho_{1,2} + P_{(0,2)\\to(0,1)}\\rho_{0,1}$.\n(6) $\\rho_{0,2} = \\frac{1}{3}(1) + \\frac{2}{3}\\rho_{0,1}$.\nUsing (4) and the expression for $\\rho_{1,1}$:\n$\\rho_{0,1} = \\frac{r}{2r+1}\\left(\\frac{2r+1}{2(r+1)}\\right) = \\frac{r}{2(r+1)}$.\nSubstitute this into (6):\n$\\rho_{B, DB} = \\rho_{0,2} = \\frac{1}{3} + \\frac{2}{3}\\left(\\frac{r}{2(r+1)}\\right) = \\frac{1}{3} + \\frac{r}{3(r+1)} = \\frac{r+1+r}{3(r+1)} = \\frac{2r+1}{3(r+1)}$.\n\nThe four fixation probabilities are:\n1. BD, Config A ($\\rho_{1,1}$): $\\frac{r(2r+1)}{2r^2+r+2}$\n2. BD, Config B ($\\rho_{0,2}$): $\\frac{4r(r^2+r+1)}{(2r+1)(2r^2+r+2)}$\n3. DB, Config A ($\\rho_{1,1}$): $\\frac{2r+1}{2(r+1)}$\n4. DB, Config B ($\\rho_{0,2}$): $\\frac{2r+1}{3(r+1)}$",
            "answer": "$$ \\boxed{ \\begin{pmatrix} \\frac{r(2r+1)}{2r^2+r+2}  \\frac{4r(r^2+r+1)}{(2r+1)(2r^2+r+2)}  \\frac{2r+1}{2(r+1)}  \\frac{2r+1}{3(r+1)} \\end{pmatrix} } $$"
        },
        {
            "introduction": "As systems grow in size and complexity, analytical solutions become intractable, and we must turn to computational methods. This final exercise  challenges you to compute fixation probabilities on a multiplex network, where evolution can proceed on different topological layers. Instead of seeking a closed-form solution, you will implement a first-principles numerical approach: constructing the complete state-transition matrix for the finite Markov chain and solving for the absorption probabilities directly, a powerful technique applicable to a wide range of complex evolutionary scenarios.",
            "id": "4277546",
            "problem": "Consider a multiplex network with a single population of $N$ individuals that are co-located across two layers sharing the same node set. Layer $\\mathcal{R}$ is a regular cycle graph (each node $i$ is connected to nodes $(i-1) \\bmod N$ and $(i+1) \\bmod N$), and layer $\\mathcal{S}$ is a star graph with a single hub at node $0$ connected to all other nodes $1,\\dots,N-1$; leaves are only connected to the hub in $\\mathcal{S}$. The population undergoes Birth-Death (BD) updating, defined as follows: at each time step, one reproducing individual is chosen, with probability proportional to its fitness. The offspring replaces a neighbor, chosen uniformly at random from the neighbor set of the chosen layer. Mutant fitness is $r1$ and resident fitness is $1$. The coupling between layers is specified by a probability $p \\in [0,1]$: with probability $p$, reproduction and replacement occur along edges of layer $\\mathcal{R}$; with probability $1-p$, they occur along edges of layer $\\mathcal{S}$. The state of the system is a vector of length $N$ indicating which nodes are mutants ($1$) and which are residents ($0$). The process is a finite Markov chain with two absorbing states: extinction (all zeros) and fixation (all ones). Starting from a single mutant at a specified initial node, the fixation probability is the probability that the Markov chain is absorbed in the fixation state.\n\nYour task is to derive from first principles an exact, finite-state computation of the fixation probability under the BD rule with layer coupling and to implement it in a program that constructs the absorbing Markov chain on the state space $\\{0,1\\}^N$, computes the transition probabilities induced by the BD rule and layer choice, and solves for the fixation probability using linear algebra on the transient-state subspace. The computational basis must be strictly derived from the following core definitions:\n\n- BD updating: the reproducing node $i$ is selected with probability $f_i / \\sum_{j=1}^N f_j$, where $f_i=r$ if node $i$ is mutant and $f_i=1$ if node $i$ is resident. A neighbor in the chosen layer is selected uniformly at random from the neighbors of node $i$ in that layer and is replaced by the reproducer’s type.\n- Multiplex layer coupling: with probability $p$ the replacement is along layer $\\mathcal{R}$, and with probability $1-p$ along layer $\\mathcal{S}$.\n\nYou must not use or assume any closed-form fixation formulas. You must construct the full finite Markov chain on the $2^N$ states, identify the transient set, and compute absorption probabilities to the fixation absorbing state by solving the appropriate linear system derived from the absorbing chain equations. The network, updating rule, and coupling must be used exactly as specified. There are no physical units involved in this problem. All reported fixation probabilities must be expressed as decimal floats, rounded to $6$ decimal places.\n\nImplement a program that, for each test case below, computes the exact fixation probability under the specified parameters and initial condition. For initial placement \"uniform,\" average the fixation probability over all $N$ possible single-mutant starting nodes. For initial placement \"hub,\" the mutant starts at node $0$. For initial placement \"leaf at index $i$,\" the mutant starts at node $i$ (where $i \\in \\{1,\\dots,N-1\\}$). The regular layer $\\mathcal{R}$ is the cycle with degree $2$; the star layer $\\mathcal{S}$ has hub $0$ and leaves $1,\\dots,N-1$.\n\nTest suite:\n\n- Case $1$: $N=6$, $r=1.5$, $p=0.7$, initial placement \"hub\" (node $0$).\n- Case $2$: $N=6$, $r=1.5$, $p=0.0$, initial placement \"leaf at index $3$\".\n- Case $3$: $N=6$, $r=1.5$, $p=1.0$, initial placement \"leaf at index $3$\".\n- Case $4$: $N=6$, $r=1.0$, $p=0.4$, initial placement \"uniform\" (average over all single-mutant starts).\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (e.g., $[\\text{result}_1,\\text{result}_2,\\text{result}_3,\\text{result}_4]$), where each $\\text{result}_k$ is the fixation probability for the corresponding test case, rounded to $6$ decimal places.",
            "solution": "The problem is to compute the fixation probability of a single mutant in a population of size $N$ on a two-layer multiplex network. The process is governed by a Birth-Death (BD) updating rule with layer coupling. This problem is scientifically well-posed and all parameters and dynamics are clearly defined. It requires a first-principles calculation, constructing the full finite-state Markov chain and solving for the absorption probabilities. This is a standard and valid approach in evolutionary dynamics.\n\nThe solution proceeds in three main stages: first, formalizing the state space and the dynamics as a finite absorbing Markov chain; second, deriving the transition probabilities between states from the given BD rule and network structure; and third, solving for the fixation probabilities using the standard theory of absorbing Markov chains.\n\n**1. State Space and Markov Chain Formulation**\nThe state of the system is a binary vector of length $N$, $S \\in \\{0,1\\}^N$, where $s_i=1$ indicates a mutant at node $i$ and $s_i=0$ indicates a resident. The total number of states is $2^N$. Each state can be uniquely represented by an integer from $0$ to $2^N-1$ via the binary representation $S = (s_0, s_1, \\dots, s_{N-1}) \\mapsto \\sum_{i=0}^{N-1} s_i 2^{N-1-i}$.\n\nThe process is a Markov chain on this state space. There are two absorbing states:\n- **Extinction**: The state where all individuals are residents, corresponding to the vector $(0,0,\\dots,0)$ and integer $0$.\n- **Fixation**: The state where all individuals are mutants, corresponding to the vector $(1,1,\\dots,1)$ and integer $2^N-1$.\n\nAll other $2^N-2$ states are transient. The transition matrix $P$ of an absorbing Markov chain can be written in the canonical form:\n$$\nP = \\begin{pmatrix} Q  R \\\\ 0  I \\end{pmatrix}\n$$\nHere, $Q$ is a $(2^N-2) \\times (2^N-2)$ submatrix describing transitions between transient states. $R$ is a $(2^N-2) \\times 2$ submatrix describing transitions from transient states to the two absorbing states (extinction and fixation). $I$ is the $2 \\times 2$ identity matrix for absorbing states, and $0$ is a zero matrix.\n\n**2. Derivation of Transition Probabilities**\nThe entries of $Q$ and $R$ are derived from the specified BD updating rule. Let $S$ be the current state.\nThe number of mutants is $k = \\sum_{i=0}^{N-1} s_i$. The fitness of a mutant is $r  1$ and of a resident is $1$. The total fitness of the population is $F = k \\cdot r + (N-k) \\cdot 1$.\n\nAn individual at node $i$ is selected for reproduction with probability proportional to its fitness:\n$$\nP_{\\text{select}}(i) = \\frac{f_i}{F} = \\begin{cases} r/F  \\text{if } s_i=1 \\\\ 1/F  \\text{if } s_i=0 \\end{cases}\n$$\nFollowing selection of node $i$, a layer is chosen. With probability $p$, layer $\\mathcal{R}$ (cycle graph) is chosen. With probability $1-p$, layer $\\mathcal{S}$ (star graph) is chosen. An offspring of type $s_i$ then replaces a neighbor of $i$ in the chosen layer, selected uniformly at random.\n\nLet us find the total probability of transitioning from state $S$ to a new state $S'$. A transition $S \\to S'$ occurs if an individual at node $i$ of type $s_i$ produces an offspring that replaces an individual at a neighboring node $j$ of type $s_j$, where $s_j \\neq s_i$. The new state $S'$ is identical to $S$ except at position $j$, where $s'_j = s_i$. The probability of such a specific event $(i \\to j)$ is the product of the probabilities of selection, layer choice, and neighbor replacement.\n\nThe total transition probability $T_{S,S'}$ is the sum of probabilities of all elementary events that result in the transition from $S$ to $S'$. Since a single event flips at most one bit, we only need to consider transitions where $S$ and $S'$ differ by one bit, or self-loops where $S'=S$.\n\nFor a given transient state $S$, we compute the transition probabilities to all other states $S'$:\n- For each node $i \\in \\{0, \\dots, N-1\\}$ (the potential reproducer):\n  - Calculate selection probability $P_{\\text{select}}(i)$.\n  - **Layer $\\mathcal{R}$ (Cycle):** The degree is $k_{\\mathcal{R}}(i)=2$ for all $i$.\n    - For each neighbor $j$ of $i$ in $\\mathcal{R}$:\n      - The event probability is $ P_{\\text{event}} = p \\cdot P_{\\text{select}}(i) \\cdot (1/2)$.\n      - If $s_i \\neq s_j$, a new state $S'$ is reached. We add $P_{\\text{event}}$ to the transition probability $T_{S,S'}$.\n      - If $s_i = s_j$, the state does not change. We add $P_{\\text{event}}$ to the self-loop probability $T_{S,S}$.\n  - **Layer $\\mathcal{S}$ (Star):** The degree of the hub (node $0$) is $k_{\\mathcal{S}}(0) = N-1$. The degree of a leaf (node $i0$) is $k_{\\mathcal{S}}(i) = 1$.\n    - For each neighbor $j$ of $i$ in $\\mathcal{S}$:\n      - The event probability is $P_{\\text{event}} = (1-p) \\cdot P_{\\text{select}}(i) \\cdot (1/k_{\\mathcal{S}}(i))$.\n      - If $s_i \\neq s_j$, a new state $S'$ is reached. Add $P_{\\text{event}}$ to $T_{S,S'}$.\n      - If $s_i = s_j$, the state does not change. Add $P_{\\text{event}}$ to $T_{S,S}$.\n\nBy iterating over all nodes $i$, we fill one row of the full transition matrix, which allows us to populate the matrices $Q$ and $R$.\n\n**3. Solving for Fixation Probability**\nLet $\\mathbf{x}$ be a column vector where $x_i$ is the probability of eventual absorption into the fixation state, given the process starts in transient state $i$. This vector satisfies the linear system:\n$$\n\\mathbf{x} = Q\\mathbf{x} + \\mathbf{r}_{\\text{fix}}\n$$\nwhere $\\mathbf{r}_{\\text{fix}}$ is the column of $R$ corresponding to transitions into the fixation state. Rearranging gives:\n$$\n(I - Q)\\mathbf{x} = \\mathbf{r}_{\\text{fix}}\n$$\nThe solution is obtained by matrix inversion:\n$$\n\\mathbf{x} = (I - Q)^{-1} \\mathbf{r}_{\\text{fix}}\n$$\nThe matrix $N_{mat} = (I-Q)^{-1}$ is known as the fundamental matrix of the absorbing Markov chain.\n\n**4. Computational Implementation**\nThe program implements this exact procedure.\n1.  A mapping from integer state representations $\\{1, \\dots, 2^N-2\\}$ to transient matrix indices $\\{0, \\dots, 2^N-3\\}$ is established.\n2.  The matrices $Q$ and $R$ are constructed by iterating through each transient state and calculating the transition probabilities to all other states (transient or absorbing) based on the BD dynamics derived above.\n3.  The NumPy and SciPy libraries are used to perform the linear algebra. Specifically, `scipy.linalg.inv` is used to compute the fundamental matrix $N_{mat} = (I-Q)^{-1}$.\n4.  The vector of fixation probabilities $\\mathbf{x}$ is computed via the matrix-vector product $N_{mat} \\mathbf{r}_{\\text{fix}}$.\n5.  For each test case, the initial state is determined (e.g., a single mutant at the hub corresponds to state $2^{N-1}$). The corresponding fixation probability is retrieved from the computed vector $\\mathbf{x}$.\n6.  For the \"uniform\" initial placement, the fixation probabilities for all $N$ single-mutant starting states are calculated and then averaged. For the special case $r=1$, this average is analytically known to be $1/N$, providing a valuable sanity check for the implementation.\n7.  The final results are rounded to $6$ decimal places as required.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.linalg import inv\n\ndef compute_fixation_probabilities(N, r, p):\n    \"\"\"\n    Computes fixation probabilities for all possible transient initial states.\n\n    The function constructs the transition matrix for the absorbing Markov chain\n    defined by the problem, partitions it into transient and absorbing components\n    (Q and R), and solves the linear system (I - Q)x = r_fix to find the\n    fixation probabilities.\n\n    Args:\n        N (int): The number of individuals in the population.\n        r (float): The fitness of a mutant.\n        p (float): The probability of using the regular cycle graph layer.\n\n    Returns:\n        dict: A dictionary mapping an initial state (as an integer) to its\n              fixation probability.\n    \"\"\"\n    num_states = 1  N\n    all_residents_state = 0\n    all_mutants_state = num_states - 1\n    \n    transient_states_map = {}\n    transient_idx = 0\n    for i in range(num_states):\n        if i != all_residents_state and i != all_mutants_state:\n            transient_states_map[i] = transient_idx\n            transient_idx += 1\n    \n    num_transient = len(transient_states_map)\n    \n    Q = np.zeros((num_transient, num_transient), dtype=np.float64)\n    R = np.zeros((num_transient, 2), dtype=np.float64)  # Col 0: extinction, Col 1: fixation\n\n    # Adjacency lists for the two layers\n    adj_R = {i: [(i - 1) % N, (i + 1) % N] for i in range(N)}\n    adj_S = {0: list(range(1, N))}\n    for i in range(1, N):\n        adj_S[i] = [0]\n    \n    # Iterate through all transient states to build Q and R\n    for state_int, trans_idx in transient_states_map.items():\n        state_bin_str = bin(state_int)[2:].zfill(N)\n        state_bin = np.array([int(b) for b in state_bin_str])\n        \n        num_mutants = np.sum(state_bin)\n        total_fitness = num_mutants * r + (N - num_mutants)\n        \n        if total_fitness == 0: continue\n\n        # Iterate over all possible reproducers\n        for i in range(N):\n            fitness = r if state_bin[i] == 1 else 1.0\n            prob_selection = fitness / total_fitness\n            \n            # Layer R (Cycle)\n            if p  0:\n                degree_R = len(adj_R[i])\n                for neighbor in adj_R[i]:\n                    prob_event = p * prob_selection / degree_R\n                    if state_bin[i] != state_bin[neighbor]:\n                        next_state_bin = state_bin.copy()\n                        next_state_bin[neighbor] = state_bin[i]\n                        next_state_int = int(\"\".join(map(str, next_state_bin)), 2)\n                        \n                        if next_state_int in transient_states_map:\n                            next_trans_idx = transient_states_map[next_state_int]\n                            Q[trans_idx, next_trans_idx] += prob_event\n                        elif next_state_int == all_residents_state:\n                            R[trans_idx, 0] += prob_event\n                        else:  # all_mutants_state\n                            R[trans_idx, 1] += prob_event\n                    else: # No state change\n                        Q[trans_idx, trans_idx] += prob_event\n\n            # Layer S (Star)\n            if (1.0 - p)  0:\n                degree_S = len(adj_S[i])\n                if degree_S  0:\n                    for neighbor in adj_S[i]:\n                        prob_event = (1.0 - p) * prob_selection / degree_S\n                        if state_bin[i] != state_bin[neighbor]:\n                            next_state_bin = state_bin.copy()\n                            next_state_bin[neighbor] = state_bin[i]\n                            next_state_int = int(\"\".join(map(str, next_state_bin)), 2)\n\n                            if next_state_int in transient_states_map:\n                                next_trans_idx = transient_states_map[next_state_int]\n                                Q[trans_idx, next_trans_idx] += prob_event\n                            elif next_state_int == all_residents_state:\n                                R[trans_idx, 0] += prob_event\n                            else: # all_mutants_state\n                                R[trans_idx, 1] += prob_event\n                        else: # No state change\n                            Q[trans_idx, trans_idx] += prob_event\n\n    # Solve for absorption probabilities\n    I = np.identity(num_transient, dtype=np.float64)\n    # Using scipy.linalg.inv for better numerical stability\n    N_mat = inv(I - Q)\n    B = np.dot(N_mat, R)\n    \n    fixation_probs = {}\n    for state_int, trans_idx in transient_states_map.items():\n        fixation_probs[state_int] = B[trans_idx, 1]\n    \n    return fixation_probs\n\ndef solve():\n    # Define the test cases from the problem statement.\n    # Format: (N, r, p, placement_type, placement_data)\n    # placement_type \"node\": single mutant at node `placement_data`.\n    # placement_type \"uniform\": average over all single-mutant starting nodes.\n    test_cases = [\n        # Case 1: N=6, r=1.5, p=0.7, initial placement \"hub\" (node 0)\n        (6, 1.5, 0.7, 'node', 0),\n        # Case 2: N=6, r=1.5, p=0.0, initial placement \"leaf at index 3\"\n        (6, 1.5, 0.0, 'node', 3),\n        # Case 3: N=6, r=1.5, p=1.0, initial placement \"leaf at index 3\"\n        (6, 1.5, 1.0, 'node', 3),\n        # Case 4: N=6, r=1.0, p=0.4, initial placement \"uniform\"\n        (6, 1.0, 0.4, 'uniform', None)\n    ]\n\n    results = []\n    cached_probs = {}\n\n    for case in test_cases:\n        N, r, p, placement_type, placement_data = case\n        \n        params = (N, r, p)\n        if params not in cached_probs:\n            cached_probs[params] = compute_fixation_probabilities(N, r, p)\n        \n        fix_probs_dict = cached_probs[params]\n        \n        prob = 0.0\n        if placement_type == 'node':\n            # State with a single mutant at node `placement_data`.\n            # Node 0 is MSB, so node i is at bit (N-1-i).\n            node_idx = placement_data\n            state_int = 1  (N - 1 - node_idx)\n            prob = fix_probs_dict.get(state_int, 0.0)\n        elif placement_type == 'uniform':\n            total_prob = 0.0\n            if N > 0 and r == 1.0: # Optimization/sanity check for neutral case\n                prob = 1.0 / N\n            else:\n                for i in range(N):\n                    state_int = 1  (N - 1 - i)\n                    total_prob += fix_probs_dict.get(state_int, 0.0)\n                if N  0:\n                    prob = total_prob / N\n        \n        results.append(round(prob, 6))\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        }
    ]
}