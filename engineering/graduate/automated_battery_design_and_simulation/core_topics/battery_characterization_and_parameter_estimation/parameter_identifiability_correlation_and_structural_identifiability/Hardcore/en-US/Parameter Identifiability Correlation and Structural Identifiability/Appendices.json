{
    "hands_on_practices": [
        {
            "introduction": "Before investing in complex experiments, it is crucial to determine if a model's parameters are theoretically identifiable from the proposed measurements. This analytical exercise explores the concept of structural identifiability by examining a common two-branch equivalent circuit model used in impedance spectroscopy . By deriving the model's impedance function, you will discover how distinct sets of parameters can produce identical outputs, revealing the fundamental limitations of the model structure itself.",
            "id": "3936955",
            "problem": "A lithium-ion cell is modeled for electrochemical impedance spectroscopy using a linear equivalent circuit composed of a series ohmic resistance and two parallel resistor-capacitor branches in series. The series element has resistance $R_0$. The two branches are $(R_1 \\parallel C_1)$ and $(R_2 \\parallel C_2)$, where $\\parallel$ denotes a parallel connection. Let the complex frequency be $s$ with $s = \\mathrm{j} \\omega$ and $\\mathrm{j}^2 = -1$, and define the branch time constants $\\tau_1 = R_1 C_1$ and $\\tau_2 = R_2 C_2$. The impedance of an ideal resistor is $Z_R(s) = R$, and the impedance of an ideal capacitor is $Z_C(s) = 1/(s C)$. Using Kirchhoff’s laws and linear time-invariant network composition rules, the overall impedance $Z(s)$ is determined by $(R_0, R_1, C_1, R_2, C_2)$ for all real $\\omega$.\n\nYou are given that the impedance is measured perfectly over all real angular frequencies, so that $Z(s)$ is known exactly as a complex analytic function on the imaginary axis. Starting only from the above fundamental laws and definitions, do the following:\n\n1. Derive $Z(s)$ in rational form with real coefficients in $s$ expressed in terms of $(R_0, R_1, \\tau_1, R_2, \\tau_2)$.\n2. Prove that there exist distinct parameter tuples $(R_0, R_1, \\tau_1, R_2, \\tau_2)$ and $(R_0, \\tilde{R}_1, \\tilde{\\tau}_1, \\tilde{R}_2, \\tilde{\\tau}_2)$ that produce identical $Z(s)$ for all real $\\omega$ by identifying algebraic invariants of the mapping from parameters to $Z(s)$.\n3. Show that when $\\tau_1 \\neq \\tau_2$, the only nontrivial indistinguishability is permutation of the two branches, whereas when $\\tau_1 = \\tau_2$ there is a nontrivial continuum of indistinguishable parameterizations with the same spectrum. Explicitly characterize, in terms of algebraic equalities, the set of all parameter tuples that produce a given $Z(s)$.\n\nAnswer specification: Provide, as your final answer, a single row vector giving a complete set of algebraic invariants of the parameter-to-impedance map that classify the equivalence classes under the relation “produce identical $Z(s)$ for all real $\\omega$.” Express your answer symbolically in terms of $(R_0, R_1, \\tau_1, R_2, \\tau_2)$. Do not include units. If you choose an equivalent but different invariant generating set, it must be algebraically complete and minimal with respect to recovering $Z(s)$ as a rational function up to identical spectra, and it must be expressed as a single closed-form expression.",
            "solution": "The problem statement is evaluated as scientifically grounded, well-posed, and objective. It presents a standard problem in system identification applied to a common electrochemical model. All necessary information is provided, and the questions are specific and mathematically rigorous. Therefore, the problem is deemed valid and a full solution is provided below.\n\n### 1. Derivation of the Impedance Function $Z(s)$\nThe electrochemical impedance model consists of a series resistor with resistance $R_0$ and two series-connected parallel resistor-capacitor (RC) branches, $(R_1 \\parallel C_1)$ and $(R_2 \\parallel C_2)$.\n\nThe impedance of a resistor $R$ is $Z_R(s) = R$.\nThe impedance of a capacitor $C$ is $Z_C(s) = \\frac{1}{sC}$.\nThe complex frequency is $s = \\mathrm{j} \\omega$.\n\nThe impedance of the first parallel RC branch, $Z_1(s)$, is given by:\n$$Z_1(s) = \\frac{1}{\\frac{1}{Z_{R_1}(s)} + \\frac{1}{Z_{C_1}(s)}} = \\frac{1}{\\frac{1}{R_1} + sC_1} = \\frac{R_1}{1 + sR_1C_1}$$\nUsing the definition of the time constant $\\tau_1 = R_1 C_1$, this becomes:\n$$Z_1(s) = \\frac{R_1}{1 + s\\tau_1}$$\nSimilarly, the impedance of the second parallel RC branch, $Z_2(s)$, is:\n$$Z_2(s) = \\frac{R_2}{1 + s\\tau_2}$$\nwhere $\\tau_2 = R_2 C_2$.\n\nThe total impedance $Z(s)$ is the sum of the impedances of the components in series:\n$$Z(s) = Z_{R_0}(s) + Z_1(s) + Z_2(s) = R_0 + \\frac{R_1}{1 + s\\tau_1} + \\frac{R_2}{1 + s\\tau_2}$$\nTo express $Z(s)$ as a rational function, we combine the terms over a common denominator:\n$$Z(s) = R_0 \\frac{(1 + s\\tau_1)(1 + s\\tau_2)}{(1 + s\\tau_1)(1 + s\\tau_2)} + \\frac{R_1(1 + s\\tau_2)}{(1 + s\\tau_1)(1 + s\\tau_2)} + \\frac{R_2(1 + s\\tau_1)}{(1 + s\\tau_1)(1 + s\\tau_2)}$$\n$$Z(s) = \\frac{R_0(1 + s\\tau_1)(1 + s\\tau_2) + R_1(1 + s\\tau_2) + R_2(1 + s\\tau_1)}{(1 + s\\tau_1)(1 + s\\tau_2)}$$\nExpanding the numerator and the denominator polynomials in powers of $s$:\nThe denominator is:\n$$Q(s) = (1 + s\\tau_1)(1 + s\\tau_2) = 1 + s(\\tau_1 + \\tau_2) + s^2(\\tau_1\\tau_2)$$\nThe numerator is:\n$$P(s) = R_0(1 + s(\\tau_1 + \\tau_2) + s^2\\tau_1\\tau_2) + R_1 + sR_1\\tau_2 + R_2 + sR_2\\tau_1$$\n$$P(s) = (R_0 + R_1 + R_2) + s(R_0(\\tau_1 + \\tau_2) + R_1\\tau_2 + R_2\\tau_1) + s^2(R_0\\tau_1\\tau_2)$$\nThus, the rational form of $Z(s)$ is:\n$$Z(s) = \\frac{(R_0\\tau_1\\tau_2)s^2 + (R_0(\\tau_1 + \\tau_2) + R_1\\tau_2 + R_2\\tau_1)s + (R_0 + R_1 + R_2)}{(\\tau_1\\tau_2)s^2 + (\\tau_1 + \\tau_2)s + 1}$$\nThe coefficients of the polynomials are real and expressed in terms of the parameter set $(R_0, R_1, \\tau_1, R_2, \\tau_2)$.\n\n### 2. Parameter Indistinguishability and Algebraic Invariants\nWe assume that $Z(s)$ is known exactly, which means the coefficients of the rational function are known. Let us write $Z(s) = \\frac{a_2 s^2 + a_1 s + a_0}{b_2 s^2 + b_1 s + 1}$. By comparing with the derived expression, we identify the following relationships between the five model parameters $(R_0, R_1, R_2, \\tau_1, \\tau_2)$ and the five observable coefficients $(a_0, a_1, a_2, b_1, b_2)$:\n\\begin{align*}\nb_1 &= \\tau_1 + \\tau_2 \\\\\nb_2 &= \\tau_1\\tau_2 \\\\\na_0 &= R_0 + R_1 + R_2 \\\\\na_1 &= R_0(\\tau_1 + \\tau_2) + R_1\\tau_2 + R_2\\tau_1 \\\\\na_2 &= R_0\\tau_1\\tau_2\n\\end{align*}\nFrom these equations, we can attempt to solve for the model parameters.\nFrom the coefficients of the denominator, $b_1$ and $b_2$ are the elementary symmetric polynomials in $\\tau_1$ and $\\tau_2$. This means $\\tau_1$ and $\\tau_2$ are the two roots of the quadratic equation $x^2 - b_1 x + b_2 = 0$. The set of time constants $\\{\\tau_1, \\tau_2\\}$ is uniquely determined, but we cannot distinguish $\\tau_1$ from $\\tau_2$.\nFrom the coefficients $a_2$ and $b_2$, we can uniquely determine $R_0$:\n$$R_0 = \\frac{a_2}{b_2} = \\frac{R_0\\tau_1\\tau_2}{\\tau_1\\tau_2}$$\nThis identification is unique, assuming $\\tau_1, \\tau_2 \\neq 0$, which is physically required for the model to be second-order.\n\nNow, consider the remaining equations for $R_1$ and $R_2$:\n$$R_1 + R_2 = a_0 - R_0$$\n$$R_1\\tau_2 + R_2\\tau_1 = a_1 - R_0(\\tau_1+\\tau_2) = a_1 - R_0 b_1$$\nThis is a linear system for $(R_1, R_2)$. The determinant of the coefficient matrix is $\\tau_1 - \\tau_2$.\n\nThe indistinguishability arises from the permutation symmetry of the two RC branches. The expression $Z(s) = R_0 + \\frac{R_1}{1 + s\\tau_1} + \\frac{R_2}{1 + s\\tau_2}$ is invariant under the simultaneous exchange of the pair $(R_1, \\tau_1)$ with $(R_2, \\tau_2)$.\nThis means the parameter tuple $(R_0, R_1, \\tau_1, R_2, \\tau_2)$ is empirically indistinguishable from the tuple $(R_0, R_2, \\tau_2, R_1, \\tau_1)$. If $(R_1, \\tau_1) \\neq (R_2, \\tau_2)$, these two tuples are distinct, proving that there exist distinct parameter sets that produce an identical impedance function $Z(s)$.\n\n### 3. Characterization of Equivalence Classes\n\n**Case 1: $\\tau_1 \\neq \\tau_2$ (Distinct Time Constants)**\nWhen $\\tau_1 \\neq \\tau_2$, the poles of the impedance function at $s = -1/\\tau_1$ and $s = -1/\\tau_2$ are distinct. The determinant of the linear system for $(R_1, R_2)$ is non-zero, yielding a unique solution for $(R_1, R_2)$ for a given choice of which time constant is $\\tau_1$ and which is $\\tau_2$.\nLet's choose an assignment, say $(\\tau_a, \\tau_b)$, for the two roots of $x^2 - b_1 x + b_2 = 0$.\nThe system becomes:\n$$R_1 + R_2 = S_R \\equiv a_0 - R_0$$\n$$R_1\\tau_b + R_2\\tau_a = P_R \\equiv a_1 - R_0 b_1$$\nSolving this gives a unique pair $(R_1, R_2)$.\nIf we then swap our assignment to $(\\tau_b, \\tau_a)$, the second equation becomes $R_1\\tau_a + R_2\\tau_b = P_R$. This new system yields a solution where the values of $R_1$ and $R_2$ are swapped.\nTherefore, if $\\tau_1 \\neq \\tau_2$, there are exactly two parameter tuples that produce the same $Z(s)$:\n$$(R_0, R_1, \\tau_1, R_2, \\tau_2) \\quad \\text{and} \\quad (R_0, R_2, \\tau_2, R_1, \\tau_1)$$\nThe only nontrivial indistinguishability is the permutation of the two distinct branches.\n\n**Case 2: $\\tau_1 = \\tau_2 = \\tau$ (Identical Time Constants)**\nIf $\\tau_1 = \\tau_2 = \\tau$, the model degenerates. The impedance function becomes:\n$$Z(s) = R_0 + \\frac{R_1}{1 + s\\tau} + \\frac{R_2}{1 + s\\tau} = R_0 + \\frac{R_1 + R_2}{1 + s\\tau}$$\nIn this form, the observable parameters from the impedance spectrum are $R_0$, the time constant $\\tau$, and the sum of the branch resistances $R_{sum} = R_1 + R_2$. The individual values of $R_1$ and $R_2$ are not identifiable.\nAny pair of parameters $(R_1, R_2)$ such that $R_1 + R_2 = R_{sum}$ (and $R_1 > 0, R_2 > 0$) will produce the same impedance function, assuming they share the same time constant $\\tau$. This defines a continuous one-parameter family of equivalent models, forming a continuum of indistinguishable parameterizations. For a given total resistance $R_{sum}$, we can choose any $R_1 \\in (0, R_{sum})$, and set $R_2 = R_{sum} - R_1$. This gives a valid parameter set $(R_0, R_1, \\tau, R_{sum}-R_1, \\tau)$ that is indistinguishable from any other such choice.\n\n### Complete Set of Algebraic Invariants\nTwo parameter tuples are equivalent if and only if they generate the same impedance function $Z(s)$. This is equivalent to them generating the same set of coefficients $(a_0, a_1, a_2, b_1, b_2)$. We seek a minimal and complete set of functions of the original parameters $(R_0, R_1, \\tau_1, R_2, \\tau_2)$ that uniquely determine these coefficients. These functions form a basis for the invariants of the parameter-to-impedance map.\nAs shown in section 2, the coefficients themselves can be expressed as functions of five key combinations of the original parameters. These combinations are invariant under the permutation of the branches, and they are sufficient to reconstruct $Z(s)$.\nA complete and minimal set of such algebraic invariants is:\n1.  $I_1 = R_0$: Identifies the high-frequency resistance.\n2.  $I_2 = \\tau_1 + \\tau_2$: The sum of the time constants.\n3.  $I_3 = \\tau_1\\tau_2$: The product of the time constants.\n4.  $I_4 = R_1 + R_2$: The sum of the branch resistances.\n5.  $I_5 = R_1\\tau_2 + R_2\\tau_1$: A weighted sum coupling resistances and time constants.\n\nThese five quantities are uniquely determined from the impedance spectrum. Any two parameter sets $(R_0, R_1, \\tau_1, R_2, \\tau_2)$ and $(R'_0, R'_1, \\tau'_1, R'_2, \\tau'_2)$ produce the same impedance function if and only if these five invariants have the same value for both sets. This set of five functions of the parameters, therefore, completely classifies the equivalence classes. The final answer is the row vector composed of these five expressions.",
            "answer": "$$\n\\boxed{\n\\begin{pmatrix}\nR_0 & \\tau_1 + \\tau_2 & \\tau_1 \\tau_2 & R_1 + R_2 & R_1 \\tau_2 + R_2 \\tau_1\n\\end{pmatrix}\n}\n$$"
        },
        {
            "introduction": "While structural identifiability is a property of the model, practical identifiability is determined by the experiment itself. This practice moves from pure theory to simulation, demonstrating how to quantify the information content of an experiment using the Fisher Information Matrix (FIM) . You will investigate how experimental design choices, such as the input current profile and measurement noise, directly influence parameter uncertainty and correlation in a simple battery model.",
            "id": "3936961",
            "problem": "You are designing an automated identifiability assessment tool for a simplified lithium-ion battery equivalent circuit model used in simulation-based design. Practical identifiability must be quantified as a function of sensor noise level and sampling rate. Assume a resistive-capacitive Thevenin model with one polarization branch, governed by a linear time-invariant state and a linear output with additive Gaussian noise. The objective is to compute the Fisher Information Matrix (FIM) and a Laplace-approximated posterior concentration, then extract identifiability and correlation metrics for several test cases.\n\nFundamental base:\n- The state variable is the polarization voltage $x(t)$ evolving as \n$$\n\\frac{dx}{dt} = -\\frac{1}{R_1 C_1} x(t) + \\frac{1}{C_1} I(t),\n$$ \nwhere $R_1$ is the polarization resistance in ohms, $C_1$ is the polarization capacitance in farads, and $I(t)$ is the applied current in amperes.\n- The output voltage is \n$$\ny(t) = V_{\\mathrm{OC}} + R_0 I(t) + x(t) + \\varepsilon(t),\n$$ \nwhere $R_0$ is the ohmic resistance in ohms, $V_{\\mathrm{OC}}$ is a known constant open-circuit voltage in volts, and $\\varepsilon(t)$ is zero-mean independent Gaussian sensor noise with variance $\\sigma^2$ in squared volts.\n- The parameter vector is $\\theta = [R_0, R_1, C_1]^\\top$.\n- The Fisher Information Matrix for independent Gaussian noise is \n$$\nF(\\theta) = \\frac{1}{\\sigma^2} \\sum_{k=0}^{N-1} J_k^\\top J_k,\n$$\nwhere $J_k = \\frac{\\partial y(t_k)}{\\partial \\theta}$ is the output Jacobian evaluated at sampling times $t_k$.\n\nSensitivity base:\n- Let $S_i(t) = \\frac{\\partial x(t)}{\\partial \\theta_i}$ be the sensitivities of the state with respect to parameters. For a smooth right-hand side $f(x,\\theta,t)$, the forward sensitivity equations are\n$$\n\\frac{dS_i}{dt} = \\frac{\\partial f}{\\partial x} S_i + \\frac{\\partial f}{\\partial \\theta_i}.\n$$\nFor $f(x,\\theta,t) = -\\frac{1}{R_1 C_1} x + \\frac{1}{C_1} I(t)$, it follows that\n$$\n\\frac{\\partial f}{\\partial x} = -\\frac{1}{R_1 C_1}, \\quad \\frac{\\partial f}{\\partial R_1} = \\frac{x}{R_1^2 C_1}, \\quad \\frac{\\partial f}{\\partial C_1} = \\frac{x}{R_1 C_1^2} - \\frac{I(t)}{C_1^2}, \\quad \\frac{\\partial f}{\\partial R_0} = 0.\n$$\n- Therefore, the output Jacobian components are \n$$\n\\frac{\\partial y}{\\partial R_0} = I(t), \\quad \\frac{\\partial y}{\\partial R_1} = S_{R_1}(t), \\quad \\frac{\\partial y}{\\partial C_1} = S_{C_1}(t),\n$$\nwhere $S_{R_1}(t)$ and $S_{C_1}(t)$ are the solutions of the sensitivity differential equations with initial conditions $S_{R_1}(0) = 0$ and $S_{C_1}(0) = 0$.\n\nPosterior base:\n- Under the Laplace approximation and local linearization, the posterior covariance of $\\theta$ given data is \n$$\n\\Sigma \\approx F(\\theta)^{-1},\n$$ \nassuming $F(\\theta)$ is nonsingular; otherwise use the Moore–Penrose pseudoinverse to handle rank-deficiency.\n- The correlation matrix $C$ is obtained by normalizing $\\Sigma$:\n$$\nC_{ij} = \\frac{\\Sigma_{ij}}{\\sqrt{\\Sigma_{ii} \\Sigma_{jj}}}.\n$$\n\nAlgorithmic task:\n- For each test case, simulate the dynamics over a fixed horizon using a discrete forward Euler integrator aligned with the sampling interval. Use the current input to compute the state $x(t_k)$ and sensitivities $S_{R_1}(t_k)$ and $S_{C_1}(t_k)$, form $J_k$, and accumulate the FIM. Compute the posterior covariance and correlation metrics, then extract identifiability measures.\n\nModel parameters and units:\n- Use $R_0 = 0.05$ ohms, $R_1 = 0.02$ ohms, $C_1 = 2400$ farads, and $V_{\\mathrm{OC}} = 3.7$ volts. These are fixed and known for the simulation.\n- The input current $I(t)$ is expressed in amperes. Sensor noise standard deviation $\\sigma$ is expressed in volts. Sampling rate $f_s$ is expressed in hertz (samples per second). The sampling interval is $\\Delta t = 1/f_s$ in seconds.\n- Express any angular frequency implicitly in radians per second when needed; angles do not appear explicitly.\n\nMetrics to compute per test case:\n- Log-determinant of the Fisher Information Matrix: $\\log \\det F$. If $F$ is singular or numerically indefinite, define this as $-\\infty$.\n- Maximum normalized posterior standard deviation: $\\max_i \\frac{\\sqrt{\\Sigma_{ii}}}{|\\theta_i|}$ (dimensionless).\n- Maximum absolute posterior correlation: $\\max_{i \\neq j} |C_{ij}|$ (dimensionless).\n- Identifiability score: a float equal to $1.0$ if all the following hold and $0.0$ otherwise:\n  1. $\\min(\\lambda(F)) / \\max(\\lambda(F)) > 10^{-8}$, where $\\lambda(F)$ denotes the eigenvalues of $F$.\n  2. $\\max_{i \\neq j} |C_{ij}| < 0.95$.\n  3. $\\max_i \\frac{\\sqrt{\\Sigma_{ii}}}{|\\theta_i|} < 0.5$.\n\nInput current definition:\n- For test cases $0$ through $3$, use a deterministic pseudo-random binary sequence-like piecewise constant current with $1$ second segments cycling through levels $\\{2.0, -1.5, 2.5, -2.0, 1.0, -3.0, 3.0, -1.0\\}$ in amperes, repeating.\n- For test case $4$, use a constant current $I(t) = 0.5$ amperes to illustrate structural unidentifiability under non-persistently excited input.\n\nSimulation horizon:\n- Use a total time $T = 200$ seconds for all cases.\n\nNumerical implementation details:\n- Use forward Euler discretization for both the state and sensitivity differential equations with step size $\\Delta t$.\n- Initialize $x(0) = 0$ volts and $S_{R_1}(0) = S_{C_1}(0) = 0$.\n- At each sampling time $t_k$, compute the output Jacobian \n$$\nJ_k = \\begin{bmatrix} I(t_k) & S_{R_1}(t_k) & S_{C_1}(t_k) \\end{bmatrix}.\n$$\n\nFinal output specification:\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets. For each test case in order $0$ through $4$, append the four metrics in the following order: $[\\log \\det F, \\max_i \\frac{\\sqrt{\\Sigma_{ii}}}{|\\theta_i|}, \\max_{i \\neq j} |C_{ij}|, \\text{identifiability score}]$. The final output is the concatenation of these metrics for all five cases, resulting in a flat list of $20$ numbers printed as one line, for example, $[m_{0,1},m_{0,2},m_{0,3},m_{0,4},m_{1,1},\\dots,m_{4,4}]$.",
            "solution": "The problem is assessed to be **valid**. It is scientifically grounded in the principles of system identification and state-space modeling, employing standard techniques such as the Fisher Information Matrix (FIM) and sensitivity analysis. The problem is well-posed, providing all necessary parameters, initial conditions, and a clear, unambiguous algorithmic-numeric task. All terms are precisely defined, and the test cases are constructed to probe different aspects of parameter identifiability, including a case designed to demonstrate structural unidentifiability under non-persistently exciting input. The setup is self-contained, consistent, and computationally feasible.\n\nThe solution proceeds by implementing the specified algorithm. For each test case, we simulate a simplified Thevenin equivalent circuit model of a lithium-ion battery. The model is described by a linear time-invariant state-space representation. The core of the analysis lies in computing the Fisher Information Matrix, which quantifies the amount of information the experimental data carries about the unknown parameters $\\theta = [R_0, R_1, C_1]^\\top$.\n\nThe simulation is performed using a forward Euler discretization scheme with a step size $\\Delta t = 1/f_s$, where $f_s$ is the sampling frequency. The state equation for the polarization voltage $x(t)$ and the associated sensitivity equations for $S_{R_1}(t) = \\frac{\\partial x(t)}{\\partial R_1}$ and $S_{C_1}(t) = \\frac{\\partial x(t)}{\\partial C_1}$ are integrated simultaneously.\n\nThe state and sensitivity Ordinary Differential Equations (ODEs) are:\n$$\n\\frac{dx}{dt} = -\\frac{1}{R_1 C_1} x(t) + \\frac{1}{C_1} I(t)\n$$\n$$\n\\frac{dS_{R_1}}{dt} = -\\frac{1}{R_1 C_1} S_{R_1}(t) + \\frac{x(t)}{R_1^2 C_1}\n$$\n$$\n\\frac{dS_{C_1}}{dt} = -\\frac{1}{R_1 C_1} S_{C_1}(t) + \\frac{x(t)}{R_1 C_1^2} - \\frac{I(t)}{C_1^2}\n$$\nAll are initialized to zero at $t=0$. The discrete-time update rules for the forward Euler method with step size $\\Delta t$ are:\n$$\nx_{k+1} = x_k + \\Delta t \\left( -\\frac{x_k}{R_1 C_1} + \\frac{I_k}{C_1} \\right)\n$$\n$$\nS_{R_1, k+1} = S_{R_1, k} + \\Delta t \\left( -\\frac{S_{R_1, k}}{R_1 C_1} + \\frac{x_k}{R_1^2 C_1} \\right)\n$$\n$$\nS_{C_1, k+1} = S_{C_1, k} + \\Delta t \\left( -\\frac{S_{C_1, k}}{R_1 C_1} + \\frac{x_k}{R_1 C_1^2} - \\frac{I_k}{C_1^2} \\right)\n$$\nwhere $I_k = I(t_k)$ is the current at time $t_k = k \\Delta t$.\n\nAt each time step $t_k$, the output sensitivity Jacobian, $J_k = \\frac{\\partial y(t_k)}{\\partial \\theta}$, is computed. The components of the Jacobian are:\n$$\nJ_k = \\begin{bmatrix} \\frac{\\partial y_k}{\\partial R_0} & \\frac{\\partial y_k}{\\partial R_1} & \\frac{\\partial y_k}{\\partial C_1} \\end{bmatrix} = \\begin{bmatrix} I(t_k) & S_{R_1}(t_k) & S_{C_1}(t_k) \\end{bmatrix}\n$$\nThe FIM is accumulated over the simulation horizon $T = 200$ seconds, which consists of $N = \\lfloor T \\cdot f_s \\rfloor$ samples:\n$$\nF(\\theta) = \\frac{1}{\\sigma^2} \\sum_{k=0}^{N-1} J_k^\\top J_k\n$$\nwhere $\\sigma^2$ is the noise variance.\n\nAfter the simulation, four metrics are computed from the resulting FIM:\n\n1.  **Log-determinant of FIM, $\\log \\det F$**: This metric quantifies the overall volume of the information ellipsoid. A larger value indicates more information. If the FIM is singular or numerically indefinite (which can happen with insufficient excitation), its determinant is non-positive. In this case, the value is set to $-\\infty$. This is calculated using `numpy.linalg.slogdet`.\n\n2.  **Posterior Covariance and Normalized Standard Deviation**: Under a Laplace approximation, the posterior covariance matrix of the parameters is approximated by the inverse of the FIM, $\\Sigma \\approx F^{-1}$. To handle potential singularity (unidentifiability), the Moore-Penrose pseudoinverse, $\\Sigma = F^+$, is used. The diagonal elements $\\Sigma_{ii}$ represent the posterior variances of the parameters $\\theta_i$. The maximum normalized standard deviation, $\\max_i \\frac{\\sqrt{\\Sigma_{ii}}}{|\\theta_i|}$, provides a-scale-independent measure of parameter uncertainty.\n\n3.  **Maximum Absolute Posterior Correlation**: The off-diagonal elements of the normalized covariance matrix, $C_{ij} = \\frac{\\Sigma_{ij}}{\\sqrt{\\Sigma_{ii} \\Sigma_{jj}}}$, give the posterior correlations between parameter estimates. The metric $\\max_{i \\neq j} |C_{ij}|$ quantifies the strongest linear dependency between any two parameter estimates. High correlation (close to $1$) is a hallmark of poor identifiability.\n\n4.  **Identifiability Score**: A binary score ($1.0$ for identifiable, $0.0$ for not) is assigned based on three quantitative criteria:\n    a. The FIM must be well-conditioned: $\\min(\\lambda(F)) / \\max(\\lambda(F)) > 10^{-8}$, where $\\lambda(F)$ are the eigenvalues. This ratio is the reciprocal of the condition number. A small value indicates near-singularity.\n    b. Parameter estimates must not be excessively correlated: $\\max_{i \\neq j} |C_{ij}| < 0.95$.\n    c. Relative uncertainty for each parameter must be acceptable: $\\max_i \\frac{\\sqrt{\\Sigma_{ii}}}{|\\theta_i|} < 0.5$.\n\nThis entire procedure is applied to five test cases, varying the sensor noise $\\sigma$, sampling rate $f_s$, and the input current profile $I(t)$. The final output is a flattened list of the four computed metrics for each of the five cases.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy import linalg\n\ndef solve():\n    \"\"\"\n    Main function to run the identifiability analysis for all test cases.\n    \"\"\"\n\n    # --- Model and Simulation Parameters ---\n    R0_true = 0.05   # Ohms\n    R1_true = 0.02   # Ohms\n    C1_true = 2400.0 # Farads\n    T_horizon = 200.0 # seconds\n\n    theta_true = np.array([R0_true, R1_true, C1_true])\n\n    I_sequence = np.array([2.0, -1.5, 2.5, -2.0, 1.0, -3.0, 3.0, -1.0])\n\n    # --- Test Cases ---\n    test_cases = [\n        # Case 0: Baseline\n        {'sigma': 0.01, 'fs': 10.0, 'input_type': 'piecewise'},\n        # Case 1: Increased noise\n        {'sigma': 0.05, 'fs': 10.0, 'input_type': 'piecewise'},\n        # Case 2: Lower sampling rate\n        {'sigma': 0.01, 'fs': 0.5, 'input_type': 'piecewise'},\n        # Case 3: High resolution (low noise, high fs)\n        {'sigma': 0.005, 'fs': 100.0, 'input_type': 'piecewise'},\n        # Case 4: Non-persistent excitation (constant current)\n        {'sigma': 0.01, 'fs': 10.0, 'input_type': 'constant'},\n    ]\n\n    all_results = []\n    for case_params in test_cases:\n        FIM = run_simulation(case_params, R0_true, R1_true, C1_true, T_horizon, I_sequence)\n        metrics = compute_metrics(FIM, theta_true, case_params['sigma'])\n        all_results.extend(metrics)\n    \n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, all_results))}]\")\n\n\ndef run_simulation(params, R0, R1, C1, T, I_seq):\n    \"\"\"\n    Simulates the battery model dynamics and accumulates the Fisher Information Matrix.\n    \"\"\"\n    fs = params['fs']\n    input_type = params['input_type']\n\n    dt = 1.0 / fs\n    num_steps = int(T / dt)\n\n    # Initialize state and sensitivities\n    x, S_R1, S_C1 = 0.0, 0.0, 0.0\n\n    # Initialize FIM accumulator\n    # The FIM is sum(J' * J). We accumulate this sum.\n    FIM_accumulator = np.zeros((3, 3))\n\n    # Pre-calculate expensive constants\n    tau_inv = 1.0 / (R1 * C1)\n    C1_inv = 1.0 / C1\n    R1_sq_C1_inv = 1.0 / (R1**2 * C1)\n    R1_C1_sq_inv = 1.0 / (R1 * C1**2)\n    C1_sq_inv = 1.0 / (C1**2)\n\n    for k in range(num_steps):\n        t_k = k * dt\n        \n        # Determine current I(t_k)\n        if input_type == 'piecewise':\n            I_k = I_seq[int(t_k) % len(I_seq)]\n        else: # 'constant'\n            I_k = 0.5\n\n        # --- Step 1: Form Jacobian at current state ---\n        Jk = np.array([I_k, S_R1, S_C1])\n\n        # --- Step 2: Update FIM accumulator ---\n        FIM_accumulator += np.outer(Jk, Jk)\n        \n        # --- Step 3: Update state and sensitivities using Forward Euler ---\n        # Derivatives\n        dx_dt = -tau_inv * x + C1_inv * I_k\n        dS_R1_dt = -tau_inv * S_R1 + R1_sq_C1_inv * x\n        dS_C1_dt = -tau_inv * S_C1 + R1_C1_sq_inv * x - C1_sq_inv * I_k\n\n        # Update\n        x += dt * dx_dt\n        S_R1 += dt * dS_R1_dt\n        S_C1 += dt * dS_C1_dt\n        \n    return FIM_accumulator\n\ndef compute_metrics(FIM_accumulator, theta, sigma):\n    \"\"\"\n    Computes the four required metrics from the final FIM.\n    \"\"\"\n    # Finalize FIM by scaling with noise variance\n    FIM = FIM_accumulator / (sigma**2)\n\n    # --- Metric 1: Log-determinant of FIM ---\n    sign, logdet = np.linalg.slogdet(FIM)\n    if sign > 0:\n        log_det_F = logdet\n    else:\n        log_det_F = float('-inf')\n\n    # --- Compute Posterior Covariance using Moore-Penrose Pseudoinverse ---\n    # This is numerically stable even for singular/ill-conditioned matrices\n    Sigma = linalg.pinv(FIM)\n\n    # --- Metric 2: Maximum normalized posterior standard deviation ---\n    # We must handle the case where a diagonal element of Sigma is negative\n    # due to numerical inaccuracies with pinv.\n    diag_Sigma = np.diag(Sigma)\n    stdevs = np.sqrt(np.maximum(0, diag_Sigma)) # Avoid sqrt of negative numbers\n    # Also handle theta_i = 0, though not the case here.\n    norm_stdevs = stdevs / np.abs(theta)\n    max_norm_std_dev = np.max(norm_stdevs)\n\n    # --- Metric 3: Maximum absolute posterior correlation ---\n    # C_ij = Sigma_ij / sqrt(Sigma_ii * Sigma_jj)\n    # To avoid division by zero if a variance is zero\n    epsilon = 1e-12\n    inv_stdevs = 1.0 / (stdevs + epsilon)\n    Corr_matrix = Sigma * np.outer(inv_stdevs, inv_stdevs)\n    np.fill_diagonal(Corr_matrix, 0) # We only want off-diagonal elements\n    max_abs_corr = np.max(np.abs(Corr_matrix))\n\n    # --- Metric 4: Identifiability Score ---\n    # Condition 1: FIM is well-conditioned\n    try:\n        eigvals = linalg.eigvalsh(FIM)\n        # eigvalsh guarantees real eigenvalues for a symmetric matrix\n        if eigvals.min() <= 0 or eigvals.max() == 0:\n             cond1 = False\n        else:\n             cond1 = (eigvals.min() / eigvals.max()) > 1e-8\n    except linalg.LinAlgError:\n        cond1 = False\n\n    # Condition 2: Correlations are not too high\n    cond2 = max_abs_corr < 0.95\n    \n    # Condition 3: Uncertainties are not too high\n    cond3 = max_norm_std_dev < 0.5\n    \n    identifiability_score = 1.0 if cond1 and cond2 and cond3 else 0.0\n\n    return [log_det_F, max_norm_std_dev, max_abs_corr, identifiability_score]\n\nif __name__ == \"__main__\":\n    solve()\n\n```"
        },
        {
            "introduction": "The Fisher Information Matrix provides a powerful but local assessment of identifiability based on a quadratic approximation of the likelihood surface. To gain a more global and robust understanding, especially in the face of non-linearities, we turn to profile likelihoods . This computational exercise demonstrates how to use this advanced technique to distinguish between true structural non-identifiability (an unbounded likelihood profile) and practical non-identifiability (a flat but bounded profile), providing a more definitive diagnosis of parameter estimation challenges.",
            "id": "3937072",
            "problem": "You are given a small-signal, linearized voltage model appropriate for calibration of the Single Particle Model (SPM) of lithium-ion batteries. The terminal voltage response to an applied current is modeled as the sum of an instantaneous ohmic drop and a diffusion overpotential that is approximated by a causal exponential kernel. The model assumes additive, independent Gaussian measurement noise. The goal is to use profile likelihoods to distinguish between true structural non-identifiability and flat but bounded likelihood regions for the diffusion time constant parameter.\n\nFundamental base:\n- Let $I(t)$ denote the applied current in amperes (A).\n- Let $R_s$ denote the series resistance in ohms ($\\Omega$).\n- Let $a$ denote the diffusion amplitude in volts per ampere-second ($\\mathrm{V}\\cdot\\mathrm{A}^{-1}\\cdot\\mathrm{s}^{-1}$).\n- Let $\\tau$ denote the diffusion time constant in seconds (s).\n- Let $V(t)$ denote the modeled voltage in volts (V).\n- For small signals, we approximate the diffusion overpotential as the convolution of $I(t)$ with the exponential kernel $k_\\tau(t) = \\exp(-t/\\tau)$.\n- Continuous-time convolution is approximated by a discrete-time convolution with uniform sampling interval $\\Delta t$ seconds:\n$$\ns_\\tau[n] = \\Delta t \\sum_{m=0}^{n} I[m] \\exp\\left(-\\frac{(t_n - t_m)}{\\tau}\\right),\n$$\nwhere $t_n = n \\Delta t$.\n- The model voltage is $V[n] = -R_s I[n] - a\\, s_\\tau[n]$.\n- Measurements are $Y[n] = V[n] + \\varepsilon[n]$ with $\\varepsilon[n] \\sim \\mathcal{N}(0,\\sigma^2)$ independent and identically distributed.\n\nParameter identifiability and profile likelihood:\n- For a parameter of interest $\\tau$, the profile likelihood fixes $\\tau$ and optimizes all other parameters $(R_s, a)$ to maximize the likelihood (equivalently, minimize the residual sum of squares).\n- Under Gaussian noise, $-2\\log L(\\tau) = \\frac{\\mathrm{RSS}(\\tau)}{\\sigma^2} + C$, where $L(\\tau)$ is the likelihood profiled over $(R_s, a)$ and $C$ is a constant independent of $\\tau$.\n- The $95\\%$ confidence cutoff for a single profiled parameter corresponds to an increase $\\Delta(-2\\log L)$ of $\\chi^2_{0.95,1} = 3.841458820694124$ above the minimum.\n\nTask:\n- Implement a program that, for each test case described below, constructs $Y[n]$ from the specified true parameters and current input, computes the profile likelihood over $\\tau$ by minimizing $\\mathrm{RSS}(\\tau)$ with respect to $(R_s, a)$ at each $\\tau$, and classifies whether $\\tau$ is truly non-identifiable (unbounded profile) versus flat but bounded.\n- Classification rule: Let $\\Delta(\\tau) = \\frac{\\mathrm{RSS}(\\tau) - \\min_{\\tilde{\\tau}} \\mathrm{RSS}(\\tilde{\\tau})}{\\sigma^2}$. If $\\Delta(\\tau)$ exceeds $3.841458820694124$ at both ends of the tested $\\tau$ grid, then the flat region is bounded (return the boolean value `False` for \"true non-identifiability\"). If $\\Delta(\\tau)$ does not exceed the threshold at one or both ends, then the profile is unbounded in the tested range, indicating true structural non-identifiability (return the boolean value `True`).\n\nUnits:\n- Time $\\tau$ must be treated in seconds (s).\n- Current $I$ in amperes (A).\n- Voltage $V$ and $Y$ in volts (V).\n- Series resistance $R_s$ in ohms ($\\Omega$).\n- Diffusion amplitude $a$ in $\\mathrm{V}\\cdot\\mathrm{A}^{-1}\\cdot\\mathrm{s}^{-1}$.\n- Express the final decision as booleans per test case; no physical unit is required for the final outputs.\n\nTest suite:\n- The program must evaluate the following three cases. In all cases, use a uniform sampling grid and discrete-time convolution as defined above. Use a fixed random seed for reproducible Gaussian noise.\n\n1. Case $1$ (structural non-identifiability due to steady-state-only sampling):\n    - Sampling: $\\Delta t = 1.0$ s, times $t_n$ from $0$ s to $100$ s inclusive.\n    - Current: $I[n] = 1.0$ A for all $n$.\n    - True parameters: $R_s^\\star = 0.05$ $\\Omega$, $a^\\star = 2\\times 10^{-2}$ $\\mathrm{V}\\cdot\\mathrm{A}^{-1}\\cdot\\mathrm{s}^{-1}$, $\\tau^\\star = 5.0$ s.\n    - Noise standard deviation: $\\sigma = 1\\times 10^{-4}$ V.\n    - Measurement window: Use only indices with $t_n \\ge 60$ s to emulate steady-state-only observations.\n    - $\\tau$ grid: $N_\\tau = 60$ points logarithmically spaced from $10^{-1}$ s to $10^{3}$ s inclusive.\n\n2. Case $2$ (flat but bounded likelihood region under limited excitation and moderate noise):\n    - Sampling: $\\Delta t = 0.5$ s, times $t_n$ from $0$ s to $200$ s inclusive.\n    - Current: piecewise constant,\n        - $I[n] = 1.0$ A for $0 \\le t_n < 50$ s,\n        - $I[n] = 0.0$ A for $50 \\le t_n < 100$ s,\n        - $I[n] = -0.5$ A for $100 \\le t_n < 150$ s,\n        - $I[n] = 0.0$ A for $150 \\le t_n \\le 200$ s.\n    - True parameters: $R_s^\\star = 0.03$ $\\Omega$, $a^\\star = 1\\times 10^{-3}$ $\\mathrm{V}\\cdot\\mathrm{A}^{-1}\\cdot\\mathrm{s}^{-1}$, $\\tau^\\star = 20.0$ s.\n    - Noise standard deviation: $\\sigma = 2\\times 10^{-3}$ V.\n    - Measurement window: use all indices.\n    - $\\tau$ grid: $N_\\tau = 60$ points logarithmically spaced from $10^{-1}$ s to $10^{3}$ s inclusive.\n\n3. Case $3$ (well-identified under rich excitation and low noise):\n    - Sampling: $\\Delta t = 0.2$ s, times $t_n$ from $0$ s to $200$ s inclusive.\n    - Current: pseudo-random binary sequence (PRBS)-like piecewise constant with segment length $5.0$ s and amplitudes $\\pm 1.0$ A, zero mean over the horizon.\n    - True parameters: $R_s^\\star = 0.05$ $\\Omega$, $a^\\star = 5\\times 10^{-3}$ $\\mathrm{V}\\cdot\\mathrm{A}^{-1}\\cdot\\mathrm{s}^{-1}$, $\\tau^\\star = 10.0$ s.\n    - Noise standard deviation: $\\sigma = 5\\times 10^{-4}$ V.\n    - Measurement window: use all indices.\n    - $\\tau$ grid: $N_\\tau = 60$ points logarithmically spaced from $10^{-1}$ s to $10^{3}$ s inclusive.\n\nAlgorithmic requirements:\n- For each fixed $\\tau$ in the grid, minimize \n$$\n\\mathrm{RSS}(\\tau) = \\sum_{n \\in \\mathcal{W}} \\left(Y[n] - \\left(-R_s I[n] - a\\, s_\\tau[n]\\right)\\right)^2\n$$ \nover $(R_s, a)$ with $\\mathcal{W}$ the measurement window. This is a linear least squares problem in $(R_s, a)$.\n- Compute the profile $\\Delta(\\tau)$, find whether it exceeds the cutoff at both ends of the grid, and classify each case accordingly.\n\nFinal output format:\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (e.g., `[True,False,False]`). Each entry must be a boolean indicating \"true non-identifiability\" for the corresponding test case, in the order Case $1$, Case $2$, Case $3$.",
            "solution": "The problem requires an analysis of parameter identifiability for a simplified electrochemical model of a lithium-ion battery. This analysis will distinguish between structural non-identifiability, where the model's mathematical form prevents unique parameter determination regardless of data quality, and practical non-identifiability, where the parameter is theoretically identifiable but the experimental data is not sufficiently informative, leading to a very flat likelihood function. The tool for this analysis is the profile likelihood.\n\nThe system is described by a discrete-time model for the battery's terminal voltage $Y[n]$ at time $t_n = n \\Delta t$:\n$$\nY[n] = -R_s I[n] - a s_\\tau[n] + \\varepsilon[n]\n$$\nwhere $I[n]$ is the applied current, $R_s$ is the series resistance, $a$ is the diffusion amplitude, and $\\varepsilon[n]$ is additive white Gaussian noise with mean $0$ and variance $\\sigma^2$. The term $s_\\tau[n]$ represents the history-dependent diffusion overpotential, calculated as a discrete-time convolution:\n$$\ns_\\tau[n] = \\Delta t \\sum_{m=0}^{n} I[m] \\exp\\left(-\\frac{(t_n - t_m)}{\\tau}\\right)\n$$\nHere, $\\tau$ is the diffusion time constant, which is the parameter of interest for our identifiability analysis. This convolution can be computed efficiently using the recursive formula:\n$$\ns_\\tau[n] = \\exp(-\\Delta t/\\tau) s_\\tau[n-1] + \\Delta t I[n], \\quad s_\\tau[-1] = 0\n$$\nThis is equivalent to applying a first-order infinite impulse response (IIR) filter to the input current signal $I[n]$.\n\nThe core of the task is to compute the profile likelihood for the parameter $\\tau$. For a fixed value of $\\tau$, the model is linear with respect to the parameters $R_s$ and $a$. The measurements $Y[n]$ can be expressed as:\n$$\nY[n] = R_s (-I[n]) + a (-s_\\tau[n]) + \\varepsilon[n]\n$$\nGiven that the noise $\\varepsilon[n]$ is Gaussian, maximizing the likelihood of observing the data $Y[n]$ is equivalent to minimizing the Residual Sum of Squares (RSS):\n$$\n\\mathrm{RSS}(R_s, a | \\tau) = \\sum_{n \\in \\mathcal{W}} \\left( Y[n] - (-R_s I[n] - a s_\\tau[n]) \\right)^2\n$$\nwhere $\\mathcal{W}$ is the set of indices corresponding to the measurement window. For each fixed $\\tau$, this is a standard linear least squares problem. We can define a design matrix $\\mathbf{X}(\\tau)$ and a parameter vector $\\boldsymbol{\\theta}$:\n$$\n\\mathbf{X}(\\tau) = \\begin{pmatrix} -I[n_1] & -s_\\tau[n_1] \\\\ -I[n_2] & -s_\\tau[n_2] \\\\ \\vdots & \\vdots \\\\ -I[n_N] & -s_\\tau[n_N] \\end{pmatrix}, \\quad \\boldsymbol{\\theta} = \\begin{pmatrix} R_s \\\\ a \\end{pmatrix}\n$$\nThe RSS is minimized by the least squares solution $\\hat{\\boldsymbol{\\theta}}(\\tau) = (\\mathbf{X}(\\tau)^T \\mathbf{X}(\\tau))^{-1} \\mathbf{X}(\\tau)^T \\mathbf{Y}$. The resulting minimum RSS for a given $\\tau$ is the profiled RSS, denoted $\\mathrm{RSS}(\\tau) = \\min_{R_s, a} \\mathrm{RSS}(R_s, a | \\tau)$.\n\nThe identifiability of $\\tau$ is assessed by examining the shape of the function $\\mathrm{RSS}(\\tau)$. A sharp, well-defined minimum indicates that the data strongly supports a specific value of $\\tau$. A flat minimum suggests practical non-identifiability. Structural non-identifiability manifests as a profile that remains flat indefinitely in one or both directions ($\\tau \\to 0$ or $\\tau \\to \\infty$), implying that multiple, disparate values of $\\tau$ explain the data equally well.\n\nTo formalize this, we analyze the normalized log-likelihood profile change, $\\Delta(\\tau)$:\n$$\n\\Delta(\\tau) = \\frac{\\mathrm{RSS}(\\tau) - \\min_{\\tilde{\\tau}} \\mathrm{RSS}(\\tilde{\\tau})}{\\sigma^2}\n$$\nAccording to Wilks' theorem, under the null hypothesis, this statistic follows a $\\chi^2$ distribution with one degree of freedom (since we are profiling one parameter, $\\tau$). A $95\\%$ confidence interval for $\\tau$ is the set of all $\\tau$ values for which $\\Delta(\\tau) \\le \\chi^2_{0.95, 1} \\approx 3.841$.\n\nThe problem defines a practical criterion for distinguishing bounded from unbounded profiles based on a specific grid of $\\tau$ values. If $\\Delta(\\tau)$ exceeds this threshold at both the minimum and maximum values of $\\tau$ in the grid, we conclude the profile is bounded within this range, and thus $\\tau$ is structurally identifiable (returning `False` for \"true non-identifiability\"). If the profile remains below the threshold at either end of the grid, we classify it as unbounded, indicating structural non-identifiability (returning `True`).\n\nThe three test cases are designed to illustrate this principle:\n1.  **Case 1:** A constant current input, observed only in steady-state. Here, the diffusion term $s_\\tau[n]$ becomes approximately proportional to $\\tau$ (for $\\tau$ much smaller than the observation start time), and the regressors for $R_s$ and $a$ (which are $-I[n]$ and $-s_\\tau[n]$) become linearly dependent. This leads to a structural non-identifiability where only the sum $R_s + a\\tau$ can be identified. The profile likelihood for $\\tau$ is expected to be flat.\n2.  **Case 2:** A piecewise-constant current input. The steps in the current provide excitation that, in principle, allows for the unique determination of all parameters. However, with limited excitation and relatively high noise, the likelihood profile may be very flat near its minimum, a case of practical non-identifiability. The profile should, however, be bounded at the extremes of the $\\tau$ grid.\n3.  **Case 3:** A pseudo-random binary sequence (PRBS) input. This signal is rich in frequencies and provides persistent excitation, which is ideal for system identification. Combined with low noise, this should result in a sharply defined, bounded likelihood profile, and $\\tau$ should be well-identified.",
            "answer": "```python\nimport numpy as np\nfrom scipy import signal\n\ndef solve():\n    \"\"\"\n    Main solver function that orchestrates the analysis for each test case.\n    \"\"\"\n    \n    # Define the confidence cutoff threshold based on chi-squared distribution\n    CHI2_THRESHOLD = 3.841458820694124\n\n    def run_case(case_params: dict) -> bool:\n        \"\"\"\n        Executes a single test case for identifiability analysis.\n        \n        Args:\n            case_params: A dictionary containing all parameters for the test case.\n            \n        Returns:\n            A boolean, True if the parameter is structurally non-identifiable, False otherwise.\n        \"\"\"\n        \n        # Unpack case parameters\n        delta_t = case_params[\"delta_t\"]\n        t_end = case_params[\"t_end\"]\n        current_profile = case_params[\"current_profile\"]\n        true_params = case_params[\"true_params\"]\n        sigma = case_params[\"sigma\"]\n        window_start_t = case_params[\"window_start_t\"]\n        tau_grid_spec = case_params[\"tau_grid\"]\n        prbs_seed = case_params.get(\"prbs_seed\", None)\n\n        # 1. Setup time and current vectors\n        t = np.arange(0, t_end + delta_t / 2, delta_t)\n        num_points = len(t)\n        I = np.zeros(num_points)\n\n        if current_profile == \"constant\":\n            I.fill(1.0)\n        elif current_profile == \"piecewise\":\n            I[(t >= 0) & (t < 50)] = 1.0\n            I[(t >= 50) & (t < 100)] = 0.0\n            I[(t >= 100) & (t < 150)] = -0.5\n            I[(t >= 150) & (t <= t_end)] = 0.0\n        elif current_profile == \"prbs\":\n            seg_len_s = 5.0\n            num_segments = int(t_end / seg_len_s)\n            samples_per_seg = int(seg_len_s / delta_t)\n            \n            # Create a zero-mean sequence of +1 and -1\n            base_seq = np.array([1.0] * (num_segments // 2) + [-1.0] * (num_segments // 2))\n            rng = np.random.default_rng(prbs_seed)\n            rng.shuffle(base_seq)\n            \n            # Construct the full current signal\n            I_segments = np.repeat(base_seq, samples_per_seg)\n            I[:len(I_segments)] = I_segments\n            if len(I) > len(I_segments):\n                I[len(I_segments):] = I_segments[-1] # Pad last value if needed\n\n        # 2. Generate true measurement data with noise\n        R_s_star, a_star, tau_star = true_params[\"R_s\"], true_params[\"a\"], true_params[\"tau\"]\n        \n        # Calculate convolution using a recursive IIR filter implementation\n        b = [delta_t]\n        a_filt = [1, -np.exp(-delta_t / tau_star)]\n        s_tau_star = signal.lfilter(b, a_filt, I)\n\n        V_true = -R_s_star * I - a_star * s_tau_star\n        \n        # Add reproducible Gaussian noise\n        rng_noise = np.random.default_rng(seed=0)\n        noise = rng_noise.normal(0, sigma, num_points)\n        Y_data = V_true + noise\n\n        # 3. Perform Profile Likelihood Analysis\n        tau_grid = np.logspace(np.log10(tau_grid_spec[\"min\"]), np.log10(tau_grid_spec[\"max\"]), tau_grid_spec[\"N\"])\n        rss_profile = np.zeros_like(tau_grid)\n        \n        window_indices = np.where(t >= window_start_t)[0]\n        \n        Y_win = Y_data[window_indices]\n        I_win = I[window_indices]\n\n        for i, tau_val in enumerate(tau_grid):\n            # For each tau, calculate the corresponding diffusion signal\n            a_filt_i = [1, -np.exp(-delta_t / tau_val)]\n            s_tau_i = signal.lfilter(b, a_filt_i, I)\n            s_tau_win = s_tau_i[window_indices]\n            \n            # Set up and solve the linear least squares problem\n            # Y_win = Rs*(-I_win) + a*(-s_tau_win)\n            X = np.c_[-I_win, -s_tau_win]\n            \n            # lstsq returns: params, residuals, rank, singular_values\n            # residuals is the RSS if the problem is overdetermined.\n            _, rss, _, _ = np.linalg.lstsq(X, Y_win, rcond=None)\n            \n            # If system is underdetermined, residuals array is empty.\n            # This happens with rank deficient X. In this case, RSS is 0.\n            if rss.size == 0:\n                # In a perfectly rank-deficient case, the fit is perfect.\n                # This indicates non-identifiability. We can use a small value\n                # for RSS to reflect the flat profile. Here, we calculate RSS manually.\n                # A robust lstsq would indicate this. Let's recalculate RSS.\n                p, _, _, _ = np.linalg.lstsq(X, Y_win, rcond=None)\n                Y_fit = X @ p\n                rss_profile[i] = np.sum((Y_win - Y_fit)**2)\n            else:\n                rss_profile[i] = rss[0]\n\n        # 4. Classify the result based on the profile shape\n        min_rss = np.min(rss_profile)\n        delta_profile = (rss_profile - min_rss) / (sigma ** 2)\n\n        # Check if profile is unbounded at either end of the grid\n        is_unbounded_at_low_tau = delta_profile[0] <= CHI2_THRESHOLD\n        is_unbounded_at_high_tau = delta_profile[-1] <= CHI2_THRESHOLD\n\n        # \"True non-identifiability\" is True if profile is unbounded\n        is_non_identifiable = is_unbounded_at_low_tau or is_unbounded_at_high_tau\n        \n        return is_non_identifiable\n\n    # --- Define Test Cases ---\n\n    test_cases = [\n        # Case 1: Structural non-identifiability\n        {\n            \"delta_t\": 1.0, \"t_end\": 100.0, \"current_profile\": \"constant\",\n            \"true_params\": {\"R_s\": 0.05, \"a\": 2e-2, \"tau\": 5.0},\n            \"sigma\": 1e-4, \"window_start_t\": 60.0,\n            \"tau_grid\": {\"min\": 1e-1, \"max\": 1e3, \"N\": 60}\n        },\n        # Case 2: Flat but bounded likelihood\n        {\n            \"delta_t\": 0.5, \"t_end\": 200.0, \"current_profile\": \"piecewise\",\n            \"true_params\": {\"R_s\": 0.03, \"a\": 1e-3, \"tau\": 20.0},\n            \"sigma\": 2e-3, \"window_start_t\": 0.0,\n            \"tau_grid\": {\"min\": 1e-1, \"max\": 1e3, \"N\": 60}\n        },\n        # Case 3: Well-identified\n        {\n            \"delta_t\": 0.2, \"t_end\": 200.0, \"current_profile\": \"prbs\",\n            \"true_params\": {\"R_s\": 0.05, \"a\": 5e-3, \"tau\": 10.0},\n            \"sigma\": 5e-4, \"window_start_t\": 0.0,\n            \"tau_grid\": {\"min\": 1e-1, \"max\": 1e3, \"N\": 60},\n            \"prbs_seed\": 42\n        }\n    ]\n\n    results = []\n    for case in test_cases:\n        result = run_case(case)\n        results.append(result)\n\n    # Format and print the final output\n    print(f\"[{','.join(str(r).lower() for r in results)}]\")\n\nsolve()\n```"
        }
    ]
}