{
    "hands_on_practices": [
        {
            "introduction": "Before an optimization algorithm can search for the best battery design, we must first mathematically define the set of all possible and manufacturable designs. This exercise guides you through translating tangible manufacturing limits, such as electrode thickness and porosity bounds, into a formal system of linear inequalities. By solving this, you will see how these rules shape the feasible design space into a convex polytope, a foundational geometric structure that enables efficient optimization. ",
            "id": "3950144",
            "problem": "Consider an automated battery electrode design problem in which the design vector is $x \\in \\mathbb{R}^4$ with $x = (L_c, L_a, \\epsilon_c, \\epsilon_a)$ representing cathode coating thickness $L_c$, anode coating thickness $L_a$, calendered cathode porosity $\\epsilon_c$, and calendered anode porosity $\\epsilon_a$. Manufacturing and physical feasibility impose affine constraints of the following types:\n- Total coating thickness budget: $L_c + L_a \\leq L_{\\text{tot}}^{\\max}$ with $L_{\\text{tot}}^{\\max}  0$.\n- Nonnegativity of thicknesses: $L_c \\geq 0$ and $L_a \\geq 0$.\n- Calendered porosity lower bounds due to manufacturability: $\\epsilon_i \\geq \\epsilon_i^{\\min}$ for $i \\in \\{c,a\\}$, where $0  \\epsilon_i^{\\min}  1$.\n- Calendered porosity upper bounds due to precursor porosity and material compressibility: $\\epsilon_i \\leq \\epsilon_i^{\\max}$ for $i \\in \\{c,a\\}$, where $\\epsilon_i^{\\min} \\leq \\epsilon_i^{\\max}  1$.\n\nThese constraints define a feasible set $\\mathcal{F} \\subset \\mathbb{R}^4$ for both single-objective and multi-objective automated battery design and simulation workflows. Starting only from the definitions of a closed half-space, a convex set, a polyhedron, and a polytope, and the physical feasibility of $0 \\leq \\epsilon_i \\leq 1$, do the following:\n- Express $\\mathcal{F}$ as the intersection of finitely many closed half-spaces of the form $A x \\leq b$ for a suitable matrix $A \\in \\mathbb{R}^{m \\times 4}$ and vector $b \\in \\mathbb{R}^m$, making explicit how each manufacturing constraint maps to an affine inequality.\n- Prove that $\\mathcal{F}$ is a polyhedron and determine whether it is bounded. If it is bounded, conclude that it is a polytope.\n- Using only the foundational definitions listed above, rigorously determine whether $\\mathcal{F}$ is convex or not.\n\nFor the final answer, encode your convexity classification as a scalar indicator $I_{\\text{convex}} \\in \\{0,1\\}$, where $I_{\\text{convex}} = 1$ if $\\mathcal{F}$ is convex and $I_{\\text{convex}} = 0$ otherwise. Report only $I_{\\text{convex}}$ as your final answer. No rounding is required, and no units are to be reported in the final answer.",
            "solution": "The problem as stated is formally and scientifically valid. It is self-contained, with all variables, constants, and constraints clearly defined. The premises are grounded in the standard physical and manufacturing realities of battery electrode design. The objectives are clear, well-posed, and based on fundamental mathematical definitions. There are no contradictions, ambiguities, or factual unsoundness. We may therefore proceed with a solution.\n\nThe problem asks for several characterizations of the feasible set $\\mathcal{F}$, which is a subset of $\\mathbb{R}^4$. The design vector is $x = (L_c, L_a, \\epsilon_c, \\epsilon_a)$, where the components represent cathode thickness, anode thickness, cathode porosity, and anode porosity, respectively. For notational convenience, let us denote the components of $x$ as $x_1 = L_c$, $x_2 = L_a$, $x_3 = \\epsilon_c$, and $x_4 = \\epsilon_a$.\n\nFirst, we express the feasible set $\\mathcal{F}$ as the solution to a system of linear inequalities of the form $A x \\leq b$. The constraints given in the problem statement are translated into affine inequalities as follows:\n\n- Total coating thickness budget: $L_c + L_a \\leq L_{\\text{tot}}^{\\max}$ becomes $x_1 + x_2 \\leq L_{\\text{tot}}^{\\max}$.\n- Nonnegativity of cathode thickness: $L_c \\geq 0$ is equivalent to $-x_1 \\leq 0$.\n- Nonnegativity of anode thickness: $L_a \\geq 0$ is equivalent to $-x_2 \\leq 0$.\n- Cathode porosity lower bound: $\\epsilon_c \\geq \\epsilon_c^{\\min}$ is equivalent to $-x_3 \\leq -\\epsilon_c^{\\min}$.\n- Anode porosity lower bound: $\\epsilon_a \\geq \\epsilon_a^{\\min}$ is equivalent to $-x_4 \\leq -\\epsilon_a^{\\min}$.\n- Cathode porosity upper bound: $\\epsilon_c \\leq \\epsilon_c^{\\max}$ is written as $x_3 \\leq \\epsilon_c^{\\max}$.\n- Anode porosity upper bound: $\\epsilon_a \\leq \\epsilon_a^{\\max}$ is written as $x_4 \\leq \\epsilon_a^{\\max}$.\n\nWe have a total of $m=7$ linear inequalities. The feasible set $\\mathcal{F}$ is the set of all $x \\in \\mathbb{R}^4$ that simultaneously satisfy these $7$ inequalities. We can represent this system in matrix form $A x \\leq b$, where $A \\in \\mathbb{R}^{7 \\times 4}$ and $b \\in \\mathbb{R}^7$. The matrix $A$ and vector $b$ are explicitly:\n$$\nA = \\begin{pmatrix}\n1  1  0  0 \\\\\n-1  0  0  0 \\\\\n0  -1  0  0 \\\\\n0  0  1  0 \\\\\n0  0  -1  0 \\\\\n0  0  0  1 \\\\\n0  0  0  -1\n\\end{pmatrix}, \\quad \nb = \\begin{pmatrix}\nL_{\\text{tot}}^{\\max} \\\\\n0 \\\\\n0 \\\\\n\\epsilon_c^{\\max} \\\\\n-\\epsilon_c^{\\min} \\\\\n\\epsilon_a^{\\max} \\\\\n-\\epsilon_a^{\\min}\n\\end{pmatrix}\n$$\nThus, $\\mathcal{F} = \\{x \\in \\mathbb{R}^4 \\mid A x \\leq b\\}$.\n\nNext, we prove that $\\mathcal{F}$ is a polyhedron and determine if it is a polytope.\nA **polyhedron** is defined as the intersection of a finite number of closed half-spaces. A **closed half-space** is a set of the form $\\{x \\in \\mathbb{R}^n \\mid a^T x \\leq \\beta\\}$.\nEach of the $7$ inequalities defining $\\mathcal{F}$ describes a closed half-space in $\\mathbb{R}^4$. For example, the first inequality, $x_1 + x_2 \\leq L_{\\text{tot}}^{\\max}$, corresponds to the half-space defined by $a^T = (1, 1, 0, 0)$ and $\\beta = L_{\\text{tot}}^{\\max}$.\nSince $\\mathcal{F}$ is the set of points satisfying all $7$ of these inequalities, it is by definition the intersection of $7$ closed half-spaces. Therefore, $\\mathcal{F}$ is a polyhedron.\n\nA **polytope** is defined as a bounded polyhedron. To determine if $\\mathcal{F}$ is a polytope, we must check if it is bounded. A set is bounded if there exists a real number $R  0$ such that for all $x \\in \\mathcal{F}$, $\\|x\\| \\leq R$. This is equivalent to showing that each component of $x$ is bounded.\nFor any $x = (L_c, L_a, \\epsilon_c, \\epsilon_a) \\in \\mathcal{F}$:\n- For $L_c$: The constraints are $L_c \\geq 0$ and $L_c + L_a \\leq L_{\\text{tot}}^{\\max}$. Since $L_a \\geq 0$, we have $L_c \\leq L_c + L_a \\leq L_{\\text{tot}}^{\\max}$. Thus, $0 \\leq L_c \\leq L_{\\text{tot}}^{\\max}$.\n- For $L_a$: Similarly, $L_a \\geq 0$ and $L_a \\leq L_c + L_a \\leq L_{\\text{tot}}^{\\max}$ (since $L_c \\geq 0$). Thus, $0 \\leq L_a \\leq L_{\\text{tot}}^{\\max}$.\n- For $\\epsilon_c$: The constraints are $\\epsilon_c^{\\min} \\leq \\epsilon_c \\leq \\epsilon_c^{\\max}$.\n- For $\\epsilon_a$: The constraints are $\\epsilon_a^{\\min} \\leq \\epsilon_a \\leq \\epsilon_a^{\\max}$.\nAll constants $L_{\\text{tot}}^{\\max}$, $\\epsilon_i^{\\min}$, and $\\epsilon_i^{\\max}$ are finite. Therefore, each component of any vector $x \\in \\mathcal{F}$ is confined to a closed interval on the real line. This implies that the set $\\mathcal{F}$ is bounded. Since $\\mathcal{F}$ is a bounded polyhedron, it is a polytope.\n\nFinally, we rigorously determine if $\\mathcal{F}$ is a convex set using foundational definitions.\nA set $S \\subseteq \\mathbb{R}^n$ is **convex** if for any two points $x_1, x_2 \\in S$, the line segment connecting them is also entirely contained in $S$. That is, for any scalar $\\theta \\in [0, 1]$, the point $\\theta x_1 + (1-\\theta)x_2$ must be in $S$.\n\nOur proof proceeds in two steps:\n1.  Prove that any closed half-space is a convex set.\n2.  Prove that the intersection of convex sets is a convex set.\n\nStep 1: Consider an arbitrary closed half-space $H = \\{x \\in \\mathbb{R}^n \\mid a^T x \\leq \\beta\\}$. Let $x_1, x_2 \\in H$. By definition of $H$, this means $a^T x_1 \\leq \\beta$ and $a^T x_2 \\leq \\beta$. Now consider an arbitrary point $z = \\theta x_1 + (1-\\theta)x_2$ on the line segment between $x_1$ and $x_2$, where $\\theta \\in [0, 1]$. We check if $z \\in H$:\n$$a^T z = a^T (\\theta x_1 + (1-\\theta)x_2) = \\theta (a^T x_1) + (1-\\theta)(a^T x_2)$$\nSince $\\theta \\geq 0$ and $1-\\theta \\geq 0$, we can use the inequalities for $x_1$ and $x_2$:\n$$\\theta (a^T x_1) \\leq \\theta \\beta$$\n$$(1-\\theta)(a^T x_2) \\leq (1-\\theta)\\beta$$\nSumming these two results gives:\n$$a^T z \\leq \\theta \\beta + (1-\\theta)\\beta = (\\theta + 1 - \\theta)\\beta = \\beta$$\nSo, $a^T z \\leq \\beta$, which implies $z \\in H$. Thus, any closed half-space is a convex set.\n\nStep 2: Let $\\{S_i\\}_{i \\in I}$ be an arbitrary collection of convex sets, and let $S = \\bigcap_{i \\in I} S_i$. Let $x_1, x_2 \\in S$. By definition of intersection, $x_1 \\in S_i$ and $x_2 \\in S_i$ for all $i \\in I$. Let $\\theta \\in [0, 1]$ and consider the point $z = \\theta x_1 + (1-\\theta)x_2$. For any given index $j \\in I$, since $S_j$ is a convex set and $x_1, x_2 \\in S_j$, it follows from the definition of convexity that $z \\in S_j$. Since this holds true for all $j \\in I$, the point $z$ must belong to every set in the collection. Therefore, $z \\in \\bigcap_{i \\in I} S_i = S$. This proves that the intersection of any collection of convex sets is itself a convex set.\n\nConclusion: The feasible set $\\mathcal{F}$ is defined as the intersection of $7$ closed half-spaces. From Step 1, each of these half-spaces is a convex set. From Step 2, their intersection, $\\mathcal{F}$, must also be a convex set.\n\nThe problem asks for an indicator variable $I_{\\text{convex}}$ such that $I_{\\text{convex}} = 1$ if $\\mathcal{F}$ is convex and $I_{\\text{convex}} = 0$ otherwise. Based on the rigorous proof above, $\\mathcal{F}$ is convex. Therefore, $I_{\\text{convex}} = 1$.",
            "answer": "$$\n\\boxed{1}\n$$"
        },
        {
            "introduction": "Multi-objective optimization is all about managing trade-offs, but not all \"optimal\" solutions are equally desirable. This practice explores the crucial difference between strong and weak Pareto optimality, revealing why relying on the latter can lead to accepting inferior designs. Furthermore, it addresses the practical challenge of comparing objectives with disparate units and scales—like cost in dollars versus charge time in seconds—by demonstrating the importance of normalization in scalarization-based decision-making. ",
            "id": "3950155",
            "problem": "Consider an automated battery design problem where the goal is to minimize multiple performance objectives simultaneously. Let the vector of objectives be $\\mathbf{f}(x) = (f_1(x), f_2(x), \\dots, f_m(x))$ for a design $x$ in a feasible set $\\mathcal{X}$, and suppose we focus on three objectives for concreteness: $f_1$ is cost per kilowatt-hour in dollars per kilowatt-hour, $f_2$ is fast-charge time from $20\\%$ to $80\\%$ state-of-charge in seconds, and $f_3$ is peak temperature rise during a $3\\mathrm{C}$ pulse in kelvins. Assume minimization for all objectives.\n\nFundamental base definitions: for two feasible designs $x,y \\in \\mathcal{X}$, define componentwise orderings in minimization as follows. Say $y$ strongly dominates $x$ if $f_k(y) \\le f_k(x)$ for all $k \\in \\{1,\\dots,m\\}$ and $f_j(y)  f_j(x)$ for at least one $j$. Say $y$ strictly dominates $x$ if $f_k(y)  f_k(x)$ for all $k$. A design $x^\\star$ is Pareto optimal (also called strongly Pareto optimal) if there is no $y \\in \\mathcal{X}$ that strongly dominates $x^\\star$. A design $x^\\star$ is weakly Pareto optimal if there is no $y \\in \\mathcal{X}$ that strictly dominates $x^\\star$.\n\nTo illustrate numerical scales, consider that typical feasible ranges may be $f_1 \\in [100,300]$ dollars per kilowatt-hour, $f_2 \\in [600,1200]$ seconds, and $f_3 \\in [5,20]$ kelvins. Algorithms for multi-objective search in this domain often embed decision-making through scalarization, such as a weighted sum $\\sum_{k=1}^m w_k f_k(x)$ with weights $w_k  0$ reflecting stakeholder preferences, or through distance-based measures to a reference “utopia” point $\\mathbf{z}^\\star$ where $z_k^\\star = \\min_{x \\in \\mathcal{X}} f_k(x)$.\n\nSelect all statements that are correct about the sufficiency of weak Pareto optimality for decision-making when objectives have differing numerical scales and about appropriate normalization strategies for scalarization in automated battery design:\n\nA. Weak Pareto optimality is insufficient for rational decision-making because it can retain designs that are strongly dominated; in minimization, the existence of a feasible $y$ with $f_k(y) \\le f_k(x^\\star)$ for all $k$ and $f_j(y)  f_j(x^\\star)$ for some $j$ implies $x^\\star$ is not Pareto optimal, yet $x^\\star$ may still be weakly Pareto optimal.\n\nB. When objectives have different numerical scales (for example, seconds versus kelvins), affine rescaling of each objective by positive factors can change which designs are weakly or strongly Pareto optimal, so normalization is necessary to preserve dominance relationships.\n\nC. To mitigate scale-induced bias in weighted-sum decision-making, each objective should be normalized to a common range using feasible bounds, for example mapping the minimum and maximum feasible values to $0$ and $1$ via $f_k^{\\mathrm{norm}}(x) = \\big(f_k(x) - f_k^{\\min}\\big)\\big/\\big(f_k^{\\max} - f_k^{\\min}\\big)$, before applying weights.\n\nD. Z-score normalization defined by $f_k^{\\mathrm{norm}}(x) = \\big(f_k(x) - \\mu_k\\big)\\big/\\sigma_k$, where $\\mu_k$ and $\\sigma_k$ are the sample mean and standard deviation of $f_k$ over a set of feasible designs, is guaranteed to encode the decision-maker’s value trade-offs directly and is therefore the preferred approach for preserving dominance and guiding choices regardless of the distribution of feasible designs.",
            "solution": "We begin from the core definitions of dominance and Pareto optimality in minimization. A design $y$ strongly dominates $x$ if $f_k(y) \\le f_k(x)$ for all $k$ and $f_j(y)  f_j(x)$ for at least one $j$. A design $y$ strictly dominates $x$ if $f_k(y)  f_k(x)$ for all $k$. A design $x^\\star$ is Pareto optimal if there is no $y$ that strongly dominates it; it is weakly Pareto optimal if there is no $y$ that strictly dominates it.\n\nFrom these definitions, the set of Pareto optimal (strong) points is a subset of the weakly Pareto optimal set, because any design that is strictly dominated is also strongly dominated, but the converse is not true. More precisely, there exist designs $x^\\star$ that are weakly Pareto optimal but not Pareto optimal: these are designs for which no feasible $y$ improves all objectives strictly, but there exists a $y$ that improves at least one objective without worsening any other (i.e., $f_k(y) \\le f_k(x^\\star)$ for all $k$ and $f_j(y)  f_j(x^\\star)$ for some $j$). Such $x^\\star$ are strongly dominated and hence not Pareto optimal, yet they may remain weakly Pareto optimal because the violation of weak optimality requires a strictly better $y$ in all components.\n\nWe also recall a foundational fact: Pareto dominance relationships are invariant under any strictly increasing transformation applied independently to each objective. In particular, multiplying each $f_k$ by a positive constant and adding a constant (affine rescaling with positive slope) preserves pairwise order within each objective and hence preserves both strong and weak dominance relations. Therefore, differing numerical scales of objectives do not alter whether one design dominates another; instead, scale differences affect scalarization procedures (such as weighted sums or distance to a utopia point) because these procedures aggregate magnitudes across objectives. Without normalization, a large-scale objective (for example, $f_2$ in seconds ranging from $600$ to $1200$) can numerically overwhelm a smaller-scale objective (for example, $f_3$ in kelvins ranging from $5$ to $20$), even when the decision-maker’s intended trade-offs do not prioritize the large-scale objective so disproportionately.\n\nFor weighted-sum scalarization, a principled normalization maps each objective to a dimensionless and commensurate scale so that weights $w_k$ represent genuine trade-off rates. A common and effective choice is min-max normalization based on feasible or estimated bounds, sending the best attainable value $f_k^{\\min}$ to $0$ and the worst $f_k^{\\max}$ to $1$:\n$$\nf_k^{\\mathrm{norm}}(x) = \\frac{f_k(x) - f_k^{\\min}}{f_k^{\\max} - f_k^{\\min}}.\n$$\nThis transformation is strictly increasing in $f_k$ when $f_k^{\\max}  f_k^{\\min}$, so it preserves dominance and places all normalized objectives on the same interval $[0,1]$, allowing weights to be chosen according to preference rather than numerical scale. An alternative rooted in multi-objective theory uses the utopia and nadir points $z_k^\\star$ and $z_k^{\\mathrm{nad}}$ (with $z_k^\\star = f_k^{\\min}$ and $z_k^{\\mathrm{nad}} = f_k^{\\max}$ when those extrema are known or well estimated), which yields the same min-max normalization and supports achievement scalarizing and Chebyshev distance measures that are meaningful across scales.\n\nWe now evaluate each option:\n\nOption A: This statement asserts that weak Pareto optimality can include strongly dominated designs and explains why that undermines decision-making. From the definitions above, a design $x^\\star$ can be such that no feasible $y$ strictly improves all components, yet some feasible $y$ improves one or more components without worsening any others. In that case, $x^\\star$ is weakly Pareto optimal (no strictly better $y$ in all components) but not Pareto optimal (it is strongly dominated). Such designs are clearly inferior from a rational decision-making standpoint because there exists a design that is at least as good in all objectives and strictly better in at least one. Therefore, weak Pareto optimality is insufficient. Verdict: Correct.\n\nOption B: This statement claims that affine rescaling by positive factors changes the identity of weakly or strongly Pareto optimal designs. As noted, Pareto dominance is invariant under strictly increasing transformations applied componentwise, including positive affine rescalings of each objective. Therefore, rescaling units or magnitudes by positive constants does not change dominance relationships or the sets of weak/strong Pareto optimal points. Normalization is pursued for scalarization and preference representation, not to preserve dominance. Verdict: Incorrect.\n\nOption C: This statement proposes min-max normalization using feasible bounds to mitigate scale-induced bias in weighted sums: $f_k^{\\mathrm{norm}}(x) = \\big(f_k(x) - f_k^{\\min}\\big)\\big/\\big(f_k^{\\max} - f_k^{\\min}\\big)$. As argued, this normalization is strictly increasing in $f_k$, preserves dominance, maps each objective to $[0,1]$, and ensures that weights $w_k$ reflect preference trade-offs rather than numerical scales. This is appropriate for automated battery design where objectives are in heterogeneous units and ranges. Verdict: Correct.\n\nOption D: This statement claims that z-score normalization guarantees encoding of decision-maker value trade-offs and is preferred regardless of the distribution of feasible designs. While z-score normalization $f_k^{\\mathrm{norm}}(x) = \\big(f_k(x) - \\mu_k\\big)\\big/\\sigma_k$ is a strictly increasing affine transformation when $\\sigma_k  0$ (thus it preserves dominance), it does not inherently encode decision-maker preferences; it encodes statistical dispersion relative to the sample mean and standard deviation, which depend on the distribution of feasible designs and can be sensitive to outliers. Moreover, z-scores do not map objectives to a common bounded interval and can distort weighting if $\\sigma_k$ varies widely across objectives, making weights $w_k$ difficult to interpret consistently. Therefore, the claim that z-scores “guarantee” encoding of preferences and are preferred regardless of distribution is unfounded. Verdict: Incorrect.\n\nIn summary, weak Pareto optimality is insufficient because it can include designs that are strictly inferior in at least one objective without any compensating improvement, and normalization such as min-max mapping to $[0,1]$ is appropriate to counteract scale-induced bias in scalarized decision-making while preserving dominance.",
            "answer": "$$\\boxed{AC}$$"
        },
        {
            "introduction": "A multi-objective optimization process typically yields a set of optimal trade-off solutions, the Pareto front, rather than a single answer. The final challenge is to select one \"best compromise\" design from this set. This hands-on problem introduces a powerful method for this task: identifying the \"knee\" of the Pareto front, the point of maximum curvature that represents the most balanced trade-off. You will derive and apply a computational technique to estimate curvature from discrete data, turning an abstract concept into a practical decision-making tool. ",
            "id": "3950102",
            "problem": "An automated battery pack design and simulation pipeline, driven by a Multi-Objective Evolutionary Algorithm (MOEA), produces a nondominated set of designs trading off two minimized objectives after normalization to the unit interval: normalized mass increase relative to a baseline, denoted by $f_{1}$, and normalized lifetime loss (higher means worse durability), denoted by $f_{2}$. Assume the nondominated set represents a discretized, noise-free sample from an underlying smooth Pareto front in the $(f_{1}, f_{2})$-plane, already normalized so that each axis is dimensionless and scaled to $[0,1]$. The sampled points, sorted by ascending $f_{1}$, are\n$$\n\\mathcal{S} = \\big\\{(0.05,\\,0.95),\\,(0.12,\\,0.78),\\,(0.20,\\,0.62),\\,(0.30,\\,0.50),\\,(0.45,\\,0.43),\\,(0.65,\\,0.39),\\,(0.90,\\,0.36)\\big\\}.\n$$\nDefine a knee point as the point on the normalized Pareto front that maximizes a curvature proxy $\\kappa(x)$, where the curvature proxy must be derived from first principles of curvature for smooth planar curves and then adapted to discrete data sampled from the curve. Starting from the definition of curvature as the inverse of the radius of the osculating circle for a smooth planar curve and using only fundamental geometric relations, derive a computational method that, for a discrete set $\\mathcal{S}$ sorted by $f_{1}$, assigns to each internal point an estimate of curvature $\\kappa_{j}$ using only that point and its two neighbors, and then selects the knee as the index $j^{\\star}$ that maximizes $\\kappa_{j}$. Apply your method to the set $\\mathcal{S}$ above and report the index $j^{\\star}$ of the knee point in the given ordering. Express your final answer as an integer with no units. No rounding instruction is needed for an integer.",
            "solution": "The problem requires the identification of a \"knee point\" from a discrete set of points $\\mathcal{S}$ representing a Pareto front. The knee point is defined as the point that maximizes a curvature proxy, which must be derived from first principles.\n\nLet the given set of points be denoted as $\\mathcal{S} = \\{P_j = (f_{1,j}, f_{2,j})\\}_{j=1}^{7}$, where $f_1$ and $f_2$ are the two objectives. The points are sorted by ascending $f_1$:\n$P_1 = (0.05, 0.95)$\n$P_2 = (0.12, 0.78)$\n$P_3 = (0.20, 0.62)$\n$P_4 = (0.30, 0.50)$\n$P_5 = (0.45, 0.43)$\n$P_6 = (0.65, 0.39)$\n$P_7 = (0.90, 0.36)$\n\n**1. Derivation of the Curvature Proxy**\n\nFor a smooth planar curve, the curvature $\\kappa$ at a point is the inverse of the radius $R$ of the osculating circle at that point, i.e., $\\kappa = 1/R$. The osculating circle is the circle that best approximates the curve at that point, and can be thought of as the limit of a circle passing through three infinitesimally close points on the curve.\n\nTo adapt this concept to a discrete set of points, we can approximate the osculating circle at an internal point $P_j$ using the unique circle that passes through $P_j$ and its two immediate neighbors, $P_{j-1}$ and $P_{j+1}$. This is the circumcircle of the triangle formed by these three points, $\\triangle P_{j-1}P_jP_{j+1}$. The curvature proxy $\\kappa_j$ at $P_j$ is then the reciprocal of the radius of this circumcircle, $R_j$.\n\nThe radius of the circumcircle of a triangle can be calculated from its side lengths. Let the side lengths of $\\triangle P_{j-1}P_jP_{j+1}$ be:\n$c_j = \\|P_{j-1} - P_j\\|$\n$a_j = \\|P_j - P_{j+1}\\|$\n$b_j = \\|P_{j-1} - P_{j+1}\\|$\n\nThe radius $R_j$ of the circumcircle is given by the formula:\n$$\nR_j = \\frac{a_j b_j c_j}{4\\mathcal{A}_j}\n$$\nwhere $\\mathcal{A}_j$ is the area of the triangle $\\triangle P_{j-1}P_jP_{j+1}$.\n\nThe curvature proxy $\\kappa_j$ is therefore:\n$$\n\\kappa_j = \\frac{1}{R_j} = \\frac{4\\mathcal{A}_j}{a_j b_j c_j}\n$$\nThe area $\\mathcal{A}_j$ can be computed using the coordinates of the points $P_{j-1}=(f_{1,j-1}, f_{2,j-1})$, $P_j=(f_{1,j}, f_{2,j})$, and $P_{j+1}=(f_{1,j+1}, f_{2,j+1})$ via the Shoelace formula:\n$$\n\\mathcal{A}_j = \\frac{1}{2} |f_{1,j-1}(f_{2,j} - f_{2,j+1}) + f_{1,j}(f_{2,j+1} - f_{2,j-1}) + f_{1,j+1}(f_{2,j-1} - f_{2,j})|\n$$\nThis method, known as Menger curvature, provides a robust, geometrically-derived proxy for curvature at each internal point of the discrete set.\n\n**2. Application to the Data Set**\n\nWe calculate the curvature proxy $\\kappa_j$ for each internal point of $\\mathcal{S}$, which corresponds to indices $j = 2, 3, 4, 5, 6$.\n\nFor $j=2$: Points are $P_1(0.05, 0.95)$, $P_2(0.12, 0.78)$, $P_3(0.20, 0.62)$.\n$c_2^2 = (0.12-0.05)^2 + (0.78-0.95)^2 = 0.07^2 + (-0.17)^2 = 0.0338$\n$a_2^2 = (0.20-0.12)^2 + (0.62-0.78)^2 = 0.08^2 + (-0.16)^2 = 0.0320$\n$b_2^2 = (0.20-0.05)^2 + (0.62-0.95)^2 = 0.15^2 + (-0.33)^2 = 0.1314$\n$\\mathcal{A}_2 = \\frac{1}{2}|0.05(0.78-0.62) + 0.12(0.62-0.95) + 0.20(0.95-0.78)| = \\frac{1}{2}|0.0024| = 0.0012$\n$\\kappa_2 = \\frac{4(0.0012)}{\\sqrt{0.0338 \\cdot 0.0320 \\cdot 0.1314}} \\approx 0.4031$\n\nFor $j=3$: Points are $P_2(0.12, 0.78)$, $P_3(0.20, 0.62)$, $P_4(0.30, 0.50)$.\n$c_3^2 = a_2^2 = 0.0320$\n$a_3^2 = (0.30-0.20)^2 + (0.50-0.62)^2 = 0.10^2 + (-0.12)^2 = 0.0244$\n$b_3^2 = (0.30-0.12)^2 + (0.50-0.78)^2 = 0.18^2 + (-0.28)^2 = 0.1108$\n$\\mathcal{A}_3 = \\frac{1}{2}|0.12(0.62-0.50) + 0.20(0.50-0.78) + 0.30(0.78-0.62)| = \\frac{1}{2}|0.0064| = 0.0032$\n$\\kappa_3 = \\frac{4(0.0032)}{\\sqrt{0.0320 \\cdot 0.0244 \\cdot 0.1108}} \\approx 1.3754$\n\nFor $j=4$: Points are $P_3(0.20, 0.62)$, $P_4(0.30, 0.50)$, $P_5(0.45, 0.43)$.\n$c_4^2 = a_3^2 = 0.0244$\n$a_4^2 = (0.45-0.30)^2 + (0.43-0.50)^2 = 0.15^2 + (-0.07)^2 = 0.0274$\n$b_4^2 = (0.45-0.20)^2 + (0.43-0.62)^2 = 0.25^2 + (-0.19)^2 = 0.0986$\n$\\mathcal{A}_4 = \\frac{1}{2}|0.20(0.50-0.43) + 0.30(0.43-0.62) + 0.45(0.62-0.50)| = \\frac{1}{2}|0.011| = 0.0055$\n$\\kappa_4 = \\frac{4(0.0055)}{\\sqrt{0.0244 \\cdot 0.0274 \\cdot 0.0986}} \\approx 2.7093$\n\nFor $j=5$: Points are $P_4(0.30, 0.50)$, $P_5(0.45, 0.43)$, $P_6(0.65, 0.39)$.\n$c_5^2 = a_4^2 = 0.0274$\n$a_5^2 = (0.65-0.45)^2 + (0.39-0.43)^2 = 0.20^2 + (-0.04)^2 = 0.0416$\n$b_5^2 = (0.65-0.30)^2 + (0.39-0.50)^2 = 0.35^2 + (-0.11)^2 = 0.1346$\n$\\mathcal{A}_5 = \\frac{1}{2}|0.30(0.43-0.39) + 0.45(0.39-0.50) + 0.65(0.50-0.43)| = \\frac{1}{2}|0.008| = 0.004$\n$\\kappa_5 = \\frac{4(0.004)}{\\sqrt{0.0274 \\cdot 0.0416 \\cdot 0.1346}} \\approx 1.2915$\n\nFor $j=6$: Points are $P_5(0.45, 0.43)$, $P_6(0.65, 0.39)$, $P_7(0.90, 0.36)$.\n$c_6^2 = a_5^2 = 0.0416$\n$a_6^2 = (0.90-0.65)^2 + (0.36-0.39)^2 = 0.25^2 + (-0.03)^2 = 0.0634$\n$b_6^2 = (0.90-0.45)^2 + (0.36-0.43)^2 = 0.45^2 + (-0.07)^2 = 0.2074$\n$\\mathcal{A}_6 = \\frac{1}{2}|0.45(0.39-0.36) + 0.65(0.36-0.43) + 0.90(0.43-0.39)| = \\frac{1}{2}|0.004| = 0.002$\n$\\kappa_6 = \\frac{4(0.002)}{\\sqrt{0.0416 \\cdot 0.0634 \\cdot 0.2074}} \\approx 0.3423$\n\n**3. Identification of the Knee Point**\n\nThe calculated curvature-proxy values for the internal points are:\n$\\kappa_2 \\approx 0.4031$\n$\\kappa_3 \\approx 1.3754$\n$\\kappa_4 \\approx 2.7093$\n$\\kappa_5 \\approx 1.2915$\n$\\kappa_6 \\approx 0.3423$\n\nThe knee point is the point that maximizes the curvature proxy. Comparing the values, the maximum is $\\kappa_4$. Therefore, the index of the knee point is $j^{\\star} = 4$. This corresponds to the point $P_4=(0.30, 0.50)$, which represents the best trade-off or \"knee\" of the Pareto front according to this geometric criterion.\nThe problem asks for the index $j^{\\star}$.",
            "answer": "$$\\boxed{4}$$"
        }
    ]
}