{
    "hands_on_practices": [
        {
            "introduction": "The reliability of any automated workflow hinges on the quality of the data it processes. This first practice establishes a crucial checkpoint by implementing a safety monitor to validate simulation data in real-time. By ensuring that Key Performance Indicators (KPIs) like energy throughput are calculated only from data within a safe operating envelope, we build resilience against corrupted or physically unrealistic results, a cornerstone of trustworthy automation. ",
            "id": "3893774",
            "problem": "You are to formalize and implement an automation step in a battery simulation workflow that enforces safety invariants on the electrochemical cell voltage and guarantees that downstream Key Performance Indicator (KPI) extraction does not include unsafe data. The workflow step must halt a simulation when the voltage deviates beyond specified safe bounds, and the KPI extractor must use only the safe portion of the simulation data to compute energy throughput. The task includes a mathematical proof of correctness and a programmatic demonstration using a fixed test suite. All physical quantities must be expressed in explicit units as specified, and all numerical answers must be rounded according to the instructions.\n\nFundamental base and core definitions:\n- Let the instantaneous voltage be $v(t)$ in $\\mathrm{V}$ and the instantaneous current be $i(t)$ in $\\mathrm{A}$, where $t$ is time in $\\mathrm{s}$.\n- The instantaneous electrical power is defined as $p(t) = v(t) \\cdot i(t)$ in $\\mathrm{W}$.\n- The energy over a time interval $\\left[t_0, t_1\\right]$ is defined as $E = \\int_{t_0}^{t_1} p(t) \\, dt$ in $\\mathrm{J}$.\n- In discrete-time simulation, the integral is approximated numerically. Use the trapezoidal rule with uniform or nonuniform sampling to approximate the integral of $p(t)$.\n- A safety invariant on voltage is the predicate $\\mathcal{S}(t)$ defined by $\\mathcal{S}(t) :\\Leftrightarrow \\left(v(t) \\ge V_{\\min}\\right) \\land \\left(v(t) \\le V_{\\max}\\right)$, where $V_{\\min}$ and $V_{\\max}$ are constants in $\\mathrm{V}$.\n\nWorkflow step specification:\n- The monitor evaluates $\\mathcal{S}(t)$ at each sampled time $t_k$ in a simulated sequence $\\{t_k\\}_{k=0}^{N-1}$ with corresponding measurements $\\{v_k\\}_{k=0}^{N-1}$ and $\\{i_k\\}_{k=0}^{N-1}$.\n- Define the halting index $h$ as the greatest index such that $\\mathcal{S}(t_k)$ holds for all $k \\le h$, and either $h = N - 1$ if no violation occurs or $h + 1$ is the first index where $\\neg \\mathcal{S}(t_{h+1})$.\n- The KPI extractor must compute energy $E_{\\mathrm{mon}}$ using only the prefix $\\{t_k, v_k, i_k\\}_{k=0}^{h}$.\n- For comparison, define the naive energy $E_{\\mathrm{full}}$ computed over the entire sequence $\\{t_k, v_k, i_k\\}_{k=0}^{N-1}$ without monitoring.\n\nContamination metric:\n- Define the contamination ratio $r$ as $r = \\begin{cases}\\dfrac{E_{\\mathrm{full}} - E_{\\mathrm{mon}}}{E_{\\mathrm{full}}} & \\text{if } E_{\\mathrm{full}} > 0, \\\\ 0 & \\text{if } E_{\\mathrm{full}} = 0.\\end{cases}$ This quantity is dimensionless and must be expressed as a decimal (no percentage sign), rounded to $6$ decimal places.\n\nUnits and rounding requirements:\n- Energies $E_{\\mathrm{mon}}$ and $E_{\\mathrm{full}}$ must be expressed in $\\mathrm{J}$, each rounded to $6$ decimal places.\n- Angles appearing in trigonometric functions must be in radians.\n- Time is in $\\mathrm{s}$, voltage in $\\mathrm{V}$, current in $\\mathrm{A}$, power in $\\mathrm{W}$, energy in $\\mathrm{J}$.\n\nTest suite (four cases):\n- Case $1$ (happy path, always-safe operation):\n  - Sampling times $t_k$ from $t_0 = 0 \\, \\mathrm{s}$ to $t_{N-1} = 100 \\, \\mathrm{s}$ with step $\\Delta t = 0.5 \\, \\mathrm{s}$.\n  - Voltage $v(t) = 3.7 + 0.2 \\sin\\!\\left(\\dfrac{2\\pi t}{50}\\right)$ in $\\mathrm{V}$.\n  - Current $i(t) = 1.5 + 0.3 \\cos\\!\\left(\\dfrac{2\\pi t}{40}\\right)$ in $\\mathrm{A}$.\n  - Safe bounds $V_{\\min} = 3.0 \\, \\mathrm{V}$ and $V_{\\max} = 4.2 \\, \\mathrm{V}$.\n- Case $2$ (overvoltage violation mid-run, boundary condition where equality at $V_{\\max}$ is allowed):\n  - Sampling times $t_k$ from $t_0 = 0 \\, \\mathrm{s}$ to $t_{N-1} = 100 \\, \\mathrm{s}$ with step $\\Delta t = 0.5 \\, \\mathrm{s}$.\n  - Voltage $v(t) = 3.6 + 0.01 t$ in $\\mathrm{V}$.\n  - Current $i(t) = 2.0$ in $\\mathrm{A}$.\n  - Safe bounds $V_{\\min} = 3.0 \\, \\mathrm{V}$ and $V_{\\max} = 4.2 \\, \\mathrm{V}$.\n- Case $3$ (undervoltage violation after boundary-hovering noise):\n  - Sampling times $t_k$ from $t_0 = 0 \\, \\mathrm{s}$ to $t_{N-1} = 50 \\, \\mathrm{s}$ with step $\\Delta t = 0.5 \\, \\mathrm{s}$.\n  - Voltage $v(t) = 3.0 - 0.02 t + 0.05 \\sin\\!\\left(\\dfrac{2\\pi t}{5}\\right)$ in $\\mathrm{V}$.\n  - Current $i(t) = 1.0 + 0.5 \\sin\\!\\left(\\dfrac{2\\pi t}{10}\\right)$ in $\\mathrm{A}$.\n  - Safe bounds $V_{\\min} = 2.5 \\, \\mathrm{V}$ and $V_{\\max} = 4.2 \\, \\mathrm{V}$.\n- Case $4$ (edge case: immediate violation with zero current):\n  - Sampling times $t_k$ from $t_0 = 0 \\, \\mathrm{s}$ to $t_{N-1} = 10 \\, \\mathrm{s}$ with step $\\Delta t = 0.5 \\, \\mathrm{s}$.\n  - Voltage $v(t) = 4.5 - 0.1 t$ in $\\mathrm{V}$.\n  - Current $i(t) = 0.0$ in $\\mathrm{A}$.\n  - Safe bounds $V_{\\min} = 3.0 \\, \\mathrm{V}$ and $V_{\\max} = 4.2 \\, \\mathrm{V}$.\n\nRequired tasks:\n- Implement the monitor to compute $h$.\n- Compute $E_{\\mathrm{mon}}$ using the trapezoidal rule over $\\{t_k, p_k\\}_{k=0}^{h}$ where $p_k = v_k i_k$.\n- Compute $E_{\\mathrm{full}}$ using the trapezoidal rule over $\\{t_k, p_k\\}_{k=0}^{N-1}$.\n- Compute $r$ according to its definition.\n\nFinal output format:\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, where each element is itself a comma-separated list in square brackets of the form $\\left[E_{\\mathrm{mon}},E_{\\mathrm{full}},r\\right]$ for the four test cases, with all numeric values rounded as specified. For example, the output format must look like $\\left[\\left[E_{\\mathrm{mon,1}},E_{\\mathrm{full,1}},r_1\\right],\\left[E_{\\mathrm{mon,2}},E_{\\mathrm{full,2}},r_2\\right],\\left[E_{\\mathrm{mon,3}},E_{\\mathrm{full,3}},r_3\\right],\\left[E_{\\mathrm{mon,4}},E_{\\mathrm{full,4}},r_4\\right]\\right]$.",
            "solution": "The problem statement has been meticulously validated and is determined to be scientifically grounded, well-posed, and internally consistent. It presents a formal and solvable task in the domain of automated battery simulation workflows. We may therefore proceed with a complete, reasoned solution.\n\nThe core task is to implement a safety monitoring workflow for a simulated electrochemical cell. This involves two primary components: a monitor that halts the simulation data stream upon a safety violation, and a Key Performance Indicator (KPI) extractor that computes energy throughput using only the validated, safe portion of the data.\n\nThe solution is designed based on the following principles:\n\n1.  **Discretization of Continuous Signals**: The continuous-time voltage $v(t)$ and current $i(t)$ signals are sampled at discrete time points $\\{t_k\\}_{k=0}^{N-1}$ to produce a time series of measurements $\\{v_k, i_k\\}_{k=0}^{N-1}$. For a uniform time step $\\Delta t$, the time points are given by $t_k = t_0 + k \\Delta t$. The instantaneous power at each point is then $p_k = v_k \\cdot i_k$.\n\n2.  **Safety Invariant Enforcement**: A safety invariant, $\\mathcal{S}(t_k) :\\Leftrightarrow (v_k \\ge V_{\\min}) \\land (v_k \\le V_{\\max})$, is checked at each time step $t_k$. The workflow must process data only up to the point of the first violation. We define the halting index $h$ as the greatest index such that the safety predicate $\\mathcal{S}(t_i)$ is true for all indices $i \\le h$.\n    -   If no violation occurs in the entire sequence, all data points are safe. The set of safe indices is $\\{0, 1, \\dots, N-1\\}$. The greatest index is $h = N-1$.\n    -   If a violation first occurs at index $j = \\min\\{k \\mid \\neg \\mathcal{S}(t_k)\\}$, then the data is safe for all indices $i < j$. The set of safe indices is $\\{0, 1, \\dots, j-1\\}$. The greatest index in this set is $h = j-1$. For the edge case $j=0$, the set of safe indices is empty, and we define $h = -1$.\n\n3.  **KPI Extraction via Numerical Integration**: The energy $E$ is the time integral of power, $E = \\int p(t) \\, dt$. For a discrete power sequence $\\{p_k\\}_{k=0}^{M-1}$ at times $\\{t_k\\}_{k=0}^{M-1}$, this integral is approximated using the trapezoidal rule:\n    $$ E \\approx \\sum_{k=0}^{M-2} \\frac{p_k + p_{k+1}}{2} (t_{k+1} - t_k) $$\n    For a constant time step $\\Delta t$, this simplifies to:\n    $$ E \\approx \\frac{\\Delta t}{2} \\left[ p_0 + 2\\sum_{k=1}^{M-2} p_k + p_{M-1} \\right] $$\n    Two energy KPIs are calculated:\n    -   The naive energy, $E_{\\mathrm{full}}$, is calculated over the entire data sequence, from $k=0$ to $k=N-1$.\n    -   The monitored energy, $E_{\\mathrm{mon}}$, is calculated only over the safe prefix of the data, which is the sequence of points from $k=0$ to $k=h$. This corresponds to a sequence of $h+1$ data points. The integration is performed on the data $\\{ (t_k, p_k) \\}_{k=0}^{h}$. If $h < 1$, the number of points is insufficient to form an interval, so the energy is correctly taken as $0$.\n\n4.  **Contamination Analysis**: The contamination ratio $r$ quantifies the relative error introduced by including unsafe data in the KPI calculation. It is defined as:\n    $$ r = \\begin{cases}\\dfrac{E_{\\mathrm{full}} - E_{\\mathrm{mon}}}{E_{\\mathrm{full}}} & \\text{if } E_{\\mathrm{full}} > 0 \\\\ 0 & \\text{if } E_{\\mathrm{full}} = 0\\end{cases} $$\n    A value of $r=0$ indicates no contamination, either because no violation occurred ($E_{\\mathrm{mon}} = E_{\\mathrm{full}}$) or because the total energy was zero. A non-zero $r$ indicates that $E_{\\mathrm{full}}$ was corrupted by data from outside the safe operating envelope.\n\n**Proof of Correctness**:\nThe algorithmic implementation directly follows from these principles.\n- The generation of time series data from the provided continuous functions is a standard sampling procedure.\n- The determination of the halting index $h$ is achieved by finding the first index $j$ of a voltage violation. If no such $j$ exists, $h$ is set to $N-1$; otherwise, $h$ is set to $j-1$. This correctly implements the definition of $h$ as the \"greatest index such that $\\mathcal{S}(t_k)$ holds for all $k \\le h$\".\n- The calculation of $E_{\\mathrm{mon}}$ uses a data slice from index $0$ to $h$, which is the slice `[0:h+1]`. This ensures that only data points satisfying the safety invariant are included in the KPI, as required. The `numpy.trapz` function correctly handles the numerical integration, including the edge cases where the number of safe points is less than $2$ (yielding an energy of $0$).\n- The calculation of $E_{\\mathrm{full}}$ uses the complete dataset.\n- The contamination ratio $r$ is computed according to its definition, including the special case for $E_{\\mathrm{full}}=0$.\nThe logic is sound and covers all specified cases, ensuring a correct and robust solution. The final program will implement this design for the provided test suite.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef calculate_kpis(t_data, v_data, i_data, v_min, v_max):\n    \"\"\"\n    Monitors simulation data, computes safe and full energy, and the contamination ratio.\n\n    Args:\n        t_data (np.ndarray): Array of time points in seconds.\n        v_data (np.ndarray): Array of voltage measurements in volts.\n        i_data (np.ndarray): Array of current measurements in amperes.\n        v_min (float): Minimum safe voltage.\n        v_max (float): Maximum safe voltage.\n\n    Returns:\n        tuple[float, float, float]: A tuple containing E_mon, E_full, and r, rounded.\n    \"\"\"\n    if t_data.size == 0:\n        return 0.0, 0.0, 0.0\n\n    # Calculate instantaneous power\n    p_data = v_data * i_data\n\n    # Calculate naive energy E_full over the entire dataset\n    e_full = np.trapz(p_data, t_data)\n\n    # Find the halting index h\n    # The safety invariant is S(t_k) <=> (v_k >= V_min) and (v_k <= V_max)\n    violation_mask = (v_data < v_min) | (v_data > v_max)\n    violation_indices = np.where(violation_mask)[0]\n\n    if violation_indices.size == 0:\n        # No violation occurred, the entire run is safe\n        h = t_data.size - 1\n    else:\n        # First violation occurs at the first index in violation_indices\n        first_violation_idx = violation_indices[0]\n        # h is the greatest index such that S(t_k) holds for all k <= h\n        h = first_violation_idx - 1\n\n    # The monitored energy E_mon is computed over the safe prefix {t_k, ...}_k=0 to h\n    # This corresponds to a slice of length h + 1\n    cutoff_idx = h + 1\n\n    t_safe = t_data[:cutoff_idx]\n    p_safe = p_data[:cutoff_idx]\n\n    # np.trapz returns 0.0 for arrays with length < 2, correctly handling edge cases\n    e_mon = np.trapz(p_safe, t_safe)\n\n    # Calculate contamination ratio r\n    if e_full != 0:\n        r = (e_full - e_mon) / e_full\n    else:\n        r = 0.0\n\n    return round(e_mon, 6), round(e_full, 6), round(r, 6)\n\ndef solve():\n    \"\"\"\n    Main function to run the test suite and print results.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases_params = [\n        {\n            # Case 1 (happy path, always-safe operation)\n            \"t_range\": (0, 100), \"dt\": 0.5,\n            \"v_func\": lambda t: 3.7 + 0.2 * np.sin(2 * np.pi * t / 50),\n            \"i_func\": lambda t: 1.5 + 0.3 * np.cos(2 * np.pi * t / 40),\n            \"bounds\": (3.0, 4.2)\n        },\n        {\n            # Case 2 (overvoltage violation mid-run)\n            \"t_range\": (0, 100), \"dt\": 0.5,\n            \"v_func\": lambda t: 3.6 + 0.01 * t,\n            \"i_func\": lambda t: 2.0,\n            \"bounds\": (3.0, 4.2)\n        },\n        {\n            # Case 3 (undervoltage violation)\n            \"t_range\": (0, 50), \"dt\": 0.5,\n            \"v_func\": lambda t: 3.0 - 0.02 * t + 0.05 * np.sin(2 * np.pi * t / 5),\n            \"i_func\": lambda t: 1.0 + 0.5 * np.sin(2 * np.pi * t / 10),\n            \"bounds\": (2.5, 4.2)\n        },\n        {\n            # Case 4 (edge case: immediate violation)\n            \"t_range\": (0, 10), \"dt\": 0.5,\n            \"v_func\": lambda t: 4.5 - 0.1 * t,\n            \"i_func\": lambda t: 0.0,\n            \"bounds\": (3.0, 4.2)\n        }\n    ]\n\n    results = []\n    for params in test_cases_params:\n        # Generate data for the current test case\n        t_start, t_end = params[\"t_range\"]\n        dt = params[\"dt\"]\n        num_points = int(round((t_end - t_start) / dt)) + 1\n        t_data = np.linspace(t_start, t_end, num_points)\n        \n        v_data = params[\"v_func\"](t_data)\n        i_data = params[\"i_func\"](t_data)\n        v_min, v_max = params[\"bounds\"]\n\n        # Calculate KPIs\n        e_mon, e_full, r = calculate_kpis(t_data, v_data, i_data, v_min, v_max)\n        results.append((e_mon, e_full, r))\n\n    # Format the final output string as specified\n    formatted_results = [f\"[{e_mon:.6f},{e_full:.6f},{r:.6f}]\" for e_mon, e_full, r in results]\n    final_output = f\"[{','.join(formatted_results)}]\"\n    print(final_output)\n\nsolve()\n```"
        },
        {
            "introduction": "Effective automation extends beyond processing results to proactively configuring simulations for desired accuracy. This exercise demonstrates how to automate a critical setup parameter—the mesh density—by linking a physical model of diffusion to the numerical error of the simulation. By deriving the required spatial resolution to meet a given accuracy tolerance, you will learn to create workflows that are not just fast, but verifiably precise. ",
            "id": "3893789",
            "problem": "An automated simulation workflow for lithium-ion battery design must allocate spatial resolution in the separator to accurately capture electrolyte concentration boundary layers that form under a step to high current. The workflow uses a uniform one-dimensional mesh of the separator of thickness $\\delta_{s}$ and advances the electrolyte salt concentration $c_{e}(x,t)$ using a second-order centered Finite Difference (FD) scheme. The design Key Performance Indicator (KPI) for mesh sufficiency is the relative pointwise error in the gradient $\\nabla c_{e}$, constrained by a tolerance $\\varepsilon$.\n\nAssume early-time boundary layer formation is diffusion-dominated and can be approximated by Fick’s second law, $\\partial c_{e}/\\partial t = D_{e} \\, \\partial^{2} c_{e}/\\partial x^{2}$, on a semi-infinite domain $x \\geq 0$ subjected at $t > 0$ to a step change in interfacial concentration at $x=0$ from $c_{0}$ to $c_{s}$, with $c_{e}(x,0)=c_{0}$ and $c_{e}(\\infty,t)=c_{0}$. This canonical diffusion problem yields a boundary layer near $x=0$ whose gradient sets the most stringent resolution requirement. The mesh spacing is $h = \\delta_{s}/(N-1)$ for $N$ uniform nodes including both separator boundaries.\n\nStarting from these principles and without invoking any shortcut formulas, derive the mesh-spacing constraint needed to enforce that the relative error in $\\nabla c_{e}$ at the location of its maximum is bounded by $\\varepsilon$ when using the second-order centered FD gradient. Then compute the smallest integer number of nodes $N$ that satisfies this constraint for:\n- $\\delta_{s} = 25 \\times 10^{-6} \\ \\mathrm{m}$,\n- $D_{e} = 1.2 \\times 10^{-10} \\ \\mathrm{m}^{2}\\,\\mathrm{s}^{-1}$,\n- $t = 1 \\ \\mathrm{s}$,\n- $\\varepsilon = 0.01$.\n\nState any mathematical assumptions you make explicitly and keep constants symbolic until the final numerical evaluation. Report the final result as an exact integer number of nodes $N$ (unitless). No rounding rule is needed beyond the integer requirement.",
            "solution": "The problem requires the derivation of a mesh-spacing constraint for an automated battery simulation workflow. The constraint is based on the relative error of a numerical gradient calculation for the electrolyte concentration, $c_e(x,t)$, during early-time boundary layer formation. The final objective is to calculate the minimum number of mesh nodes, $N$, needed to satisfy this constraint under specified conditions.\n\nThe validation of the problem statement is performed first.\n\n### Step 1: Extract Givens\n-   Governing Equation: Fick's second law, $\\frac{\\partial c_{e}}{\\partial t} = D_{e} \\frac{\\partial^{2} c_{e}}{\\partial x^{2}}$.\n-   Domain: Semi-infinite, $x \\geq 0$.\n-   Initial Condition: $c_{e}(x,0) = c_{0}$.\n-   Boundary Conditions: $c_{e}(0,t) = c_{s}$ for $t > 0$, and $c_{e}(\\infty,t) = c_{0}$.\n-   Numerical Method: Second-order centered Finite Difference (FD) for the gradient $\\nabla c_{e}$.\n-   Performance Constraint (KPI): Relative pointwise error in $\\nabla c_{e}$ at its maximum is bounded by $\\varepsilon$.\n-   Mesh Definition: Uniform mesh with $N$ nodes on a separator of thickness $\\delta_s$. Mesh spacing is $h = \\frac{\\delta_{s}}{N-1}$.\n-   Numerical values:\n    -   $\\delta_{s} = 25 \\times 10^{-6} \\ \\mathrm{m}$\n    -   $D_{e} = 1.2 \\times 10^{-10} \\ \\mathrm{m}^{2}\\,\\mathrm{s}^{-1}$\n    -   $t = 1 \\ \\mathrm{s}$\n    -   $\\varepsilon = 0.01$\n\n### Step 2: Validate Using Extracted Givens\nThe problem is scientifically grounded in the principles of diffusion (Fick's law) and numerical analysis (finite differences). The setup, involving the use of a semi-infinite domain solution to ascertain resolution requirements for a finite domain problem at early times, is a standard and physically sound engineering approximation. The characteristic diffusion length $\\sqrt{D_e t} = \\sqrt{1.2 \\times 10^{-10} \\times 1} \\approx 3.46 \\times 10^{-6} \\ \\mathrm{m}$ is substantially smaller than the separator thickness $\\delta_s = 25 \\times 10^{-6} \\ \\mathrm{m}$, justifying the semi-infinite assumption at the given time $t=1 \\ \\mathrm{s}$. The problem is well-posed, objective, and contains sufficient information for a unique solution.\n\n### Step 3: Verdict and Action\nThe problem is deemed **valid**. A full derivation and solution will be provided.\n\n### Derivation of the Mesh-Spacing Constraint\n\n**1. Analytical Solution of the Governing Equation**\n\nThe diffusion process is described by the partial differential equation (PDE):\n$$\n\\frac{\\partial c_{e}}{\\partial t} = D_{e} \\frac{\\partial^{2} c_{e}}{\\partial x^{2}}\n$$\nwith initial and boundary conditions:\n$$\nc_{e}(x,0) = c_{0} \\quad \\text{for } x \\geq 0\n$$\n$$\nc_{e}(0,t) = c_{s} \\quad \\text{for } t > 0\n$$\n$$\n\\lim_{x\\to\\infty} c_{e}(x,t) = c_{0} \\quad \\text{for } t > 0\n$$\nThis is a standard one-dimensional diffusion problem on a semi-infinite domain. We solve it using a similarity transformation. Let us define a dimensionless similarity variable $\\eta$:\n$$\n\\eta = \\frac{x}{2\\sqrt{D_e t}}\n$$\nAssuming a solution of the form $c_e(x,t) = f(\\eta)$, the PDE transforms into an ordinary differential equation (ODE). After normalizing the concentration as $u(\\eta) = \\frac{c_e - c_0}{c_s - c_0}$, the PDE becomes:\n$$\nu''(\\eta) + 2\\eta u'(\\eta) = 0\n$$\nThe boundary conditions transform to $u(0) = 1$ and $u(\\infty) = 0$. The solution to this ODE is given in terms of the complementary error function, $\\mathrm{erfc}(z)$:\n$$\nu(\\eta) = \\mathrm{erfc}(\\eta)\n$$\nReverting to the original variables, the analytical solution for the concentration profile is:\n$$\nc_e(x,t) = c_0 + (c_s - c_0) \\mathrm{erfc}\\left(\\frac{x}{2\\sqrt{D_e t}}\\right)\n$$\n\n**2. Analytical Gradient and Location of its Maximum**\n\nThe concentration gradient, $G(x,t) = \\nabla c_e = \\frac{\\partial c_e}{\\partial x}$, is found by differentiating the solution with respect to $x$. Using the property $\\frac{d}{dz}\\mathrm{erfc}(z) = -\\frac{2}{\\sqrt{\\pi}}\\exp(-z^2)$ and the chain rule:\n$$\n\\frac{\\partial c_e}{\\partial x} = (c_s - c_0) \\left( -\\frac{2}{\\sqrt{\\pi}} \\exp\\left(-\\frac{x^2}{4 D_e t}\\right) \\right) \\left( \\frac{1}{2\\sqrt{D_e t}} \\right)\n$$\n$$\nG(x,t) = \\frac{\\partial c_e}{\\partial x} = -\\frac{c_s - c_0}{\\sqrt{\\pi D_e t}} \\exp\\left(-\\frac{x^2}{4 D_e t}\\right)\n$$\nThe problem requires analysis at the location of the gradient's maximum. The magnitude of the gradient is:\n$$\n|G(x,t)| = \\frac{|c_s - c_0|}{\\sqrt{\\pi D_e t}} \\exp\\left(-\\frac{x^2}{4 D_e t}\\right)\n$$\nThis function is a Gaussian centered at $x=0$, and thus its maximum value occurs at $x=0$. The location of the maximum gradient magnitude is therefore $x_{max} = 0$.\n\n**3. Finite Difference Error Analysis**\n\nThe workflow uses a second-order centered finite difference scheme to approximate the gradient. For a function $f(x)$, the approximation at a point $x_i$ is given by:\n$$\nf'_{FD}(x_i) = \\frac{f(x_i+h) - f(x_i-h)}{2h}\n$$\nThe leading term of the truncation error for this approximation is given by Taylor's theorem:\n$$\nE_{abs}(x) = |f'_{FD}(x) - f'(x)| \\approx \\left| \\frac{h^2}{6} f'''(x) \\right|\n$$\nThe problem specifies the use of this scheme. However, at the boundary point $x=0$, a centered difference stencil is ill-defined as it requires a point at $x=-h$ which is outside the domain. The scheme is applicable to all interior nodes $x_i$ for $i=2, \\dots, N-1$. The point of maximum gradient is $x=0$, and the error is expected to be largest in this region. Therefore, we must enforce the error constraint at the first interior node where the centered scheme can be applied, which is $x_1=h$.\n\n**Assumption:** The error constraint is enforced at the first interior grid point, $x=h$, as this is the closest computable point to the location of maximum gradient magnitude ($x=0$).\n\nThe relative error at $x=h$ is defined as:\n$$\nE_{rel}(h) = \\frac{|G_{FD}(h) - G(h)|}{|G(h)|} \\approx \\frac{h^2}{6} \\frac{|c_e'''(h)|}{|c_e'(h)|}\n$$\nWe need to compute the first and third derivatives of $c_e(x,t)$. Let $C = -\\frac{c_s-c_0}{\\sqrt{\\pi D_e t}}$ and $a = \\frac{1}{4D_e t}$. Then $G(x,t) = c_e'(x) = C \\exp(-ax^2)$.\n$$\nc_e''(x) = C(-2ax)\\exp(-ax^2)\n$$\n$$\nc_e'''(x) = C(-2a)\\exp(-ax^2) + C(-2ax)^2\\exp(-ax^2) = -2aC(1 - 2ax^2)\\exp(-ax^2)\n$$\nThe relative error at an arbitrary point $x$ is:\n$$\nE_{rel}(x) \\approx \\frac{h^2}{6} \\frac{|-2aC(1 - 2ax^2)\\exp(-ax^2)|}{|C\\exp(-ax^2)|} = \\frac{ah^2}{3} |1 - 2ax^2|\n$$\nSubstituting $a = \\frac{1}{4D_e t}$:\n$$\nE_{rel}(x) \\approx \\frac{h^2}{12 D_e t} \\left| 1 - \\frac{x^2}{2 D_e t} \\right|\n$$\nEvaluating this at $x=h$, we get the constraint:\n$$\nE_{rel}(h) \\approx \\frac{h^2}{12 D_e t} \\left| 1 - \\frac{h^2}{2 D_e t} \\right| \\le \\varepsilon\n$$\nFor a sufficiently fine mesh, $h$ must be small, implying that the characteristic length of the discretization $h$ is much smaller than the characteristic diffusion length $\\sqrt{D_e t}$. This means that the term $\\frac{h^2}{2 D_e t}$ is much smaller than $1$. We can therefore approximate $|1 - \\frac{h^2}{2 D_e t}| \\approx 1$. The constraint simplifies to:\n$$\n\\frac{h^2}{12 D_e t} \\le \\varepsilon\n$$\nThis leads to the mesh-spacing constraint:\n$$\nh \\le \\sqrt{12 D_e t \\varepsilon}\n$$\n(Note: A similar analysis using a second-order accurate forward difference stencil at $x=0$ yields the same constraint, $\\frac{h^2}{12 D_e t} \\le \\varepsilon$, reinforcing the validity of this result.)\n\n**4. Calculation of the Number of Nodes N**\n\nThe mesh spacing $h$ is related to the number of nodes $N$ and the separator thickness $\\delta_s$ by $h = \\frac{\\delta_s}{N-1}$. Substituting this into the constraint:\n$$\n\\frac{\\delta_s}{N-1} \\le \\sqrt{12 D_e t \\varepsilon}\n$$\nWe rearrange to solve for $N$:\n$$\nN - 1 \\ge \\frac{\\delta_s}{\\sqrt{12 D_e t \\varepsilon}}\n$$\n$$\nN \\ge 1 + \\frac{\\delta_s}{\\sqrt{12 D_e t \\varepsilon}}\n$$\nNow, we substitute the given numerical values:\n-   $\\delta_{s} = 25 \\times 10^{-6} \\ \\mathrm{m}$\n-   $D_{e} = 1.2 \\times 10^{-10} \\ \\mathrm{m}^{2}\\,\\mathrm{s}^{-1}$\n-   $t = 1 \\ \\mathrm{s}$\n-   $\\varepsilon = 0.01$\n\nThe term in the denominator is:\n$$\n\\sqrt{12 D_e t \\varepsilon} = \\sqrt{12 \\times (1.2 \\times 10^{-10}) \\times 1 \\times 0.01} = \\sqrt{14.4 \\times 10^{-12}} = \\sqrt{14.4} \\times 10^{-6} \\ \\mathrm{m}\n$$\nSubstituting this into the inequality for $N$:\n$$\nN \\ge 1 + \\frac{25 \\times 10^{-6}}{\\sqrt{14.4} \\times 10^{-6}} = 1 + \\frac{25}{\\sqrt{14.4}}\n$$\nWe can write $\\sqrt{14.4} = \\sqrt{\\frac{144}{10}} = \\frac{12}{\\sqrt{10}}$.\n$$\nN \\ge 1 + \\frac{25}{12/\\sqrt{10}} = 1 + \\frac{25\\sqrt{10}}{12}\n$$\nNumerically, $\\sqrt{10} \\approx 3.16227766$.\n$$\nN \\ge 1 + \\frac{25 \\times 3.16227766}{12} \\approx 1 + \\frac{79.05694}{12} \\approx 1 + 6.588078\n$$\n$$\nN \\ge 7.588078\n$$\nSince $N$ must be an integer, the smallest integer value for $N$ that satisfies this condition is $8$.\n\nTo verify the approximation made earlier, we calculate $h=\\frac{25 \\times 10^{-6}}{8-1} \\approx 3.57 \\times 10^{-6} \\ \\mathrm{m}$. The term $\\frac{h^2}{2 D_e t} = \\frac{(3.57 \\times 10^{-6})^2}{2 \\times 1.2 \\times 10^{-10} \\times 1} \\approx \\frac{12.76 \\times 10^{-12}}{2.4 \\times 10^{-10}} \\approx 0.053$, which is indeed small compared to $1$, confirming the validity of the simplified constraint.\n\nThe smallest integer number of nodes required is $8$.",
            "answer": "$$\n\\boxed{8}\n$$"
        },
        {
            "introduction": "The pinnacle of workflow automation is creating systems that not only execute tasks but also learn and make decisions. This practice introduces this advanced concept through active learning, where the workflow intelligently guides the search for optimal battery designs. You will implement the Expected Improvement acquisition function to balance exploring new designs with exploiting known good ones, closing the loop on the design-of-experiments process and accelerating discovery. ",
            "id": "3893813",
            "problem": "You are automating a design-of-experiments loop for lithium-ion battery cells in which simulated cycle life is the key performance indicator (KPI). In each iteration, an Active Learning (AL) policy must rank candidate designs using an acquisition score derived from Expected Improvement and select a subset to simulate next. The pipeline assumes a Gaussian Process (GP) surrogate model that provides, for each candidate design, a posterior predictive mean and variance of cycle life. The simulated cycle life is a physical quantity measured in cycles, which must be treated as a count. The acquisition scores must be expressed in cycles. The selection indices are unitless.\n\nStarting from the following fundamentals:\n- The GP predictive distribution at a candidate design is Gaussian with predictive mean $\\,\\mu\\,$ and predictive variance $\\,\\sigma^2\\,$ for the KPI cycle life $\\,Y\\,$.\n- The improvement random variable is defined as $\\,I = \\max(0, Y - y^\\star)\\,$, where $\\,y^\\star\\,$ is the current best observed cycle life (in cycles).\n- The standard normal probability density function is $\\,\\phi(z)\\,$ and the standard normal cumulative distribution function is $\\,\\Phi(z)\\,$.\n\nYour tasks are:\n1. Derive, from first principles and the above definitions, the Expected Improvement acquisition for cycle life and express it in cycles. Handle the boundary case $\\,\\sigma = 0\\,$ rigorously.\n2. Define a sampling policy that balances exploitation and exploration by a convex combination of the Expected Improvement and the predictive standard deviation. Let the policy be parameterized by $\\,\\lambda \\in [0,1]\\,$ and a nonnegative scale factor $\\,\\kappa\\,$, and select the top $\\,B\\,$ candidates by the resulting acquisition score. Break ties by selecting the smallest indices.\n3. Implement a self-contained program that:\n   - Computes the Expected Improvement for each candidate and the balanced acquisition score in cycles.\n   - Selects the indices of the top $\\,B\\,$ candidates under the policy.\n   - Produces the final output in the exact format specified below.\n\nUse the following test suite. For each test case, the inputs are:\n- A list of predictive means $\\,\\mu\\,$ in cycles.\n- A list of predictive standard deviations $\\,\\sigma\\,$ in cycles.\n- The current best observed cycle life $\\,y^\\star\\,$ in cycles.\n- The exploration weight $\\,\\lambda\\,$ (dimensionless).\n- The scale factor $\\,\\kappa\\,$ (dimensionless).\n- The simulation budget $\\,B\\,$ (integer).\n\nCompute and report acquisition scores in cycles, rounded to six decimal places. The angle unit is not applicable. Do not use percentages.\n\nTest Suite:\n- Case $\\,1\\,$ (happy path):\n  - $\\,\\mu = [800, 600, 900, 700]\\,$ cycles\n  - $\\,\\sigma = [50, 120, 30, 80]\\,$ cycles\n  - $\\,y^\\star = 750\\,$ cycles\n  - $\\,\\lambda = 0.3\\,$\n  - $\\,\\kappa = 1.0\\,$\n  - $\\,B = 2\\,$\n- Case $\\,2\\,$ (boundary with zero variance):\n  - $\\,\\mu = [760, 740, 755]\\,$ cycles\n  - $\\,\\sigma = [0, 0, 0]\\,$ cycles\n  - $\\,y^\\star = 755\\,$ cycles\n  - $\\,\\lambda = 0.5\\,$\n  - $\\,\\kappa = 1.0\\,$\n  - $\\,B = 1\\,$\n- Case $\\,3\\,$ (exploration-dominant edge case):\n  - $\\,\\mu = [700, 730, 720]\\,$ cycles\n  - $\\,\\sigma = [150, 200, 10]\\,$ cycles\n  - $\\,y^\\star = 750\\,$ cycles\n  - $\\,\\lambda = 0.7\\,$\n  - $\\,\\kappa = 1.0\\,$\n  - $\\,B = 2\\,$\n- Case $\\,4\\,$ (exploitation-dominant case):\n  - $\\,\\mu = [1000, 760, 755]\\,$ cycles\n  - $\\,\\sigma = [5, 100, 100]\\,$ cycles\n  - $\\,y^\\star = 800\\,$ cycles\n  - $\\,\\lambda = 0.1\\,$\n  - $\\,\\kappa = 1.0\\,$\n  - $\\,B = 1\\,$\n\nOutput specification:\n- For each test case, output a pair consisting of:\n  - The list of balanced acquisition scores in cycles for all candidates, rounded to six decimal places.\n  - The list of selected indices (top $\\,B\\,$ under tie-breaking by smallest index).\n- Aggregate the per-case results into a single outer list. Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, with no spaces. For example, for two cases the format is $\\,[[\\text{scores}_1,\\text{indices}_1],[\\text{scores}_2,\\text{indices}_2]]\\,$.",
            "solution": "The problem is valid as it is scientifically grounded in the principles of Bayesian optimization for engineering design, is mathematically well-posed, and all necessary data and constraints are provided. We proceed with a step-by-step derivation and algorithmic design.\n\nThe first task is to derive the analytical expression for the Expected Improvement (EI) acquisition function from first principles. The improvement, $I$, over the current best observed cycle life, $y^\\star$, is defined for a candidate design whose cycle life $Y$ is a random variable. The improvement is given by $I = \\max(0, Y - y^\\star)$. The cycle life $Y$ is modeled by a Gaussian Process, resulting in a predictive distribution for $Y$ that is a normal distribution, $Y \\sim \\mathcal{N}(\\mu, \\sigma^2)$, where $\\mu$ is the predictive mean and $\\sigma^2$ is the predictive variance.\n\nThe Expected Improvement, $E[I]$, is the expectation of the improvement random variable $I$ with respect to the predictive distribution of $Y$. Let $f_Y(y)$ be the probability density function (PDF) of $Y$. The expectation is calculated by the integral:\n$$E[I] = E[\\max(0, Y - y^\\star)] = \\int_{-\\infty}^{\\infty} \\max(0, y - y^\\star) f_Y(y) \\, dy$$\nThe term $\\max(0, y - y^\\star)$ is non-zero only for $y > y^\\star$. Therefore, the integral is non-zero only over the domain $[y^\\star, \\infty)$:\n$$E[I] = \\int_{y^\\star}^{\\infty} (y - y^\\star) f_Y(y) \\, dy$$\nwhere $f_Y(y) = \\frac{1}{\\sigma\\sqrt{2\\pi}} \\exp\\left(-\\frac{(y-\\mu)^2}{2\\sigma^2}\\right)$. We can split the integral into two parts:\n$$E[I] = \\int_{y^\\star}^{\\infty} y f_Y(y) \\, dy - y^\\star \\int_{y^\\star}^{\\infty} f_Y(y) \\, dy$$\nThe second term is $y^\\star$ multiplied by the probability that $Y$ exceeds $y^\\star$, i.e., $y^\\star P(Y > y^\\star)$. To evaluate these terms, we perform a change of variables to the standard normal distribution. Let $z = \\frac{y - \\mu}{\\sigma}$, which implies $y = \\mu + \\sigma z$ and $dy = \\sigma dz$. The random variable $Z = \\frac{Y - \\mu}{\\sigma}$ follows the standard normal distribution, $Z \\sim \\mathcal{N}(0, 1)$, with PDF $\\phi(z) = \\frac{1}{\\sqrt{2\\pi}} e^{-z^2/2}$ and CDF $\\Phi(z) = \\int_{-\\infty}^{z} \\phi(u) du$.\n\nThe integration limit $y = y^\\star$ becomes $z = \\frac{y^\\star - \\mu}{\\sigma}$. The integral becomes:\n$$E[I] = \\int_{\\frac{y^\\star - \\mu}{\\sigma}}^{\\infty} (\\mu + \\sigma z - y^\\star) \\phi(z) \\, dz$$\n$$E[I] = \\int_{\\frac{y^\\star - \\mu}{\\sigma}}^{\\infty} (\\mu - y^\\star) \\phi(z) \\, dz + \\int_{\\frac{y^\\star - \\mu}{\\sigma}}^{\\infty} \\sigma z \\phi(z) \\, dz$$\n$$E[I] = (\\mu - y^\\star) \\int_{\\frac{y^\\star - \\mu}{\\sigma}}^{\\infty} \\phi(z) \\, dz + \\sigma \\int_{\\frac{y^\\star - \\mu}{\\sigma}}^{\\infty} z \\phi(z) \\, dz$$\nThe first integral is the probability $P(Z > \\frac{y^\\star - \\mu}{\\sigma}) = 1 - \\Phi(\\frac{y^\\star - \\mu}{\\sigma}) = \\Phi(\\frac{\\mu - y^\\star}{\\sigma})$.\nThe second integral can be solved directly: $\\int_{a}^{\\infty} z \\phi(z) dz = \\int_{a}^{\\infty} z \\frac{1}{\\sqrt{2\\pi}} e^{-z^2/2} dz$. Using the substitution $u = -z^2/2$, we find this integral is equal to $\\phi(a)$.\nThus, with $a = \\frac{y^\\star - \\mu}{\\sigma}$, the second integral evaluates to $\\sigma \\phi(\\frac{y^\\star - \\mu}{\\sigma})$. Since the standard normal PDF $\\phi(z)$ is an even function, $\\phi(\\frac{y^\\star - \\mu}{\\sigma}) = \\phi(\\frac{\\mu - y^\\star}{\\sigma})$.\n\nCombining the terms, the Expected Improvement is:\n$$E[I] = (\\mu - y^\\star) \\Phi\\left(\\frac{\\mu - y^\\star}{\\sigma}\\right) + \\sigma \\phi\\left(\\frac{\\mu - y^\\star}{\\sigma}\\right)$$\nThis formula is valid for $\\sigma > 0$. Both $Y$ and $y^\\star$ have units of cycles, making the term $(\\mu - y^\\star)$ have units of cycles. The CDF $\\Phi(\\cdot)$ is dimensionless. The standard deviation $\\sigma$ is in cycles, and the PDF $\\phi(\\cdot)$ has units inverse to its argument's standard deviation, so the product $\\sigma \\phi(\\cdot)$ is dimensionless. Wait, my unit analysis is incorrect. The argument to $\\phi$ and $\\Phi$ is dimensionless. $\\phi(z)$ has dimension $1$, so $\\sigma \\phi(z)$ has units of $\\sigma$, which is cycles. This makes both terms in the sum have units of cycles, ensuring $E[I]$ is in cycles.\n\nNext, we must rigorously handle the boundary case where the predictive variance is zero, i.e., $\\sigma = 0$. In this scenario, the Gaussian distribution collapses to a Dirac delta function centered at $\\mu$, meaning $Y = \\mu$ with probability $1$. The improvement is no longer a random variable but a deterministic quantity: $I = \\max(0, \\mu - y^\\star)$. Consequently, the expectation is simply $E[I] = \\max(0, \\mu - y^\\star)$. This can also be derived by taking the limit of the EI formula as $\\sigma \\to 0^+$.\nLet $z = \\frac{\\mu - y^\\star}{\\sigma}$.\n- If $\\mu > y^\\star$, then $z \\to \\infty$. As $z \\to \\infty$, $\\Phi(z) \\to 1$ and $\\phi(z) \\to 0$. $E[I] \\to (\\mu - y^\\star) \\cdot 1 + \\sigma \\cdot 0 = \\mu - y^\\star$.\n- If $\\mu < y^\\star$, then $z \\to -\\infty$. As $z \\to -\\infty$, $\\Phi(z) \\to 0$ and $\\phi(z) \\to 0$. $E[I] \\to (\\mu - y^\\star) \\cdot 0 + \\sigma \\cdot 0 = 0$.\n- If $\\mu = y^\\star$, then $z=0$ for $\\sigma>0$, giving $E[I] = 0 \\cdot \\Phi(0) + \\sigma \\phi(0) = \\sigma/\\sqrt{2\\pi}$, which goes to $0$ as $\\sigma \\to 0$.\nIn all cases, the limit is $\\max(0, \\mu - y^\\star)$. Thus, the complete definition for EI is:\n$$EI(\\mu, \\sigma, y^\\star) = \\begin{cases} (\\mu - y^\\star)\\Phi\\left(\\frac{\\mu - y^\\star}{\\sigma}\\right) + \\sigma\\phi\\left(\\frac{\\mu - y^\\star}{\\sigma}\\right) & \\text{if } \\sigma > 0 \\\\ \\max(0, \\mu - y^\\star) & \\text{if } \\sigma = 0 \\end{cases}$$\n\nThe second task is to define the sampling policy. The policy constructs a balanced acquisition score, $A$, by taking a convex combination of the Expected Improvement (exploitation) and the predictive standard deviation $\\sigma$ (exploration). The score is parameterized by a weight $\\lambda \\in [0, 1]$ and a non-negative scale factor $\\kappa$. The formula for the acquisition score for a candidate $i$ with predictive mean $\\mu_i$ and standard deviation $\\sigma_i$ is:\n$$A_i = (1 - \\lambda) \\cdot EI(\\mu_i, \\sigma_i, y^\\star) + \\lambda \\kappa \\sigma_i$$\nThis score is in cycles, as both $EI$ and $\\sigma_i$ are in cycles, while $\\lambda$ and $\\kappa$ are dimensionless.\n\nThe third task is implementation. The algorithm first computes the acquisition score $A_i$ for each candidate design. Then, it selects the top $B$ candidates with the highest scores. To ensure a unique selection, ties in scores are broken by choosing the candidate with the smallest original index. This is achieved by sorting the candidates based on a primary key of the acquisition score (in descending order) and a secondary key of the original index (in ascending order). The program must process the provided test suite and produce output in the specified format. The implementation will use `numpy` for efficient vectorized calculations and `scipy.stats.norm` for the CDF ($\\Phi$) and PDF ($\\phi$) of the standard normal distribution.",
            "answer": "```python\nimport numpy as np\nfrom scipy.stats import norm\nimport json\n\ndef solve():\n    \"\"\"\n    Computes acquisition scores and selects candidate designs for a battery\n    simulation workflow based on Expected Improvement and a balanced policy.\n    \"\"\"\n\n    test_cases = [\n        # Case 1 (happy path)\n        {'mu': [800, 600, 900, 700], 'sigma': [50, 120, 30, 80], 'y_star': 750, 'lambda_': 0.3, 'kappa': 1.0, 'B': 2},\n        # Case 2 (boundary with zero variance)\n        {'mu': [760, 740, 755], 'sigma': [0, 0, 0], 'y_star': 755, 'lambda_': 0.5, 'kappa': 1.0, 'B': 1},\n        # Case 3 (exploration-dominant edge case)\n        {'mu': [700, 730, 720], 'sigma': [150, 200, 10], 'y_star': 750, 'lambda_': 0.7, 'kappa': 1.0, 'B': 2},\n        # Case 4 (exploitation-dominant case)\n        {'mu': [1000, 760, 755], 'sigma': [5, 100, 100], 'y_star': 800, 'lambda_': 0.1, 'kappa': 1.0, 'B': 1},\n    ]\n\n    all_results = []\n\n    for case in test_cases:\n        mu = np.array(case['mu'], dtype=float)\n        sigma = np.array(case['sigma'], dtype=float)\n        y_star = float(case['y_star'])\n        lambda_ = float(case['lambda_'])\n        kappa = float(case['kappa'])\n        B = int(case['B'])\n\n        # Initialize Expected Improvement array\n        ei = np.zeros_like(mu)\n\n        # Handle sigma > 0 case\n        mask_pos_sigma = sigma > 1e-9 # Use a small epsilon for floating point stability\n        if np.any(mask_pos_sigma):\n            mu_pos = mu[mask_pos_sigma]\n            sigma_pos = sigma[mask_pos_sigma]\n            \n            improvement = mu_pos - y_star\n            z = improvement / sigma_pos\n            \n            ei_pos = improvement * norm.cdf(z) + sigma_pos * norm.pdf(z)\n            ei[mask_pos_sigma] = ei_pos\n            \n        # Handle sigma = 0 case\n        mask_zero_sigma = ~mask_pos_sigma\n        if np.any(mask_zero_sigma):\n            mu_zero = mu[mask_zero_sigma]\n            \n            ei_zero = np.maximum(0.0, mu_zero - y_star)\n            ei[mask_zero_sigma] = ei_zero\n\n        # Calculate the balanced acquisition score\n        acquisition_scores = (1 - lambda_) * ei + lambda_ * kappa * sigma\n        \n        # Round scores to six decimal places for the output\n        rounded_scores = np.round(acquisition_scores, 6).tolist()\n        \n        # Select top B candidates with tie-breaking\n        # Create a list of (score, original_index) tuples\n        indexed_scores = list(enumerate(acquisition_scores))\n        \n        # Sort by score (descending) and then by index (ascending) to break ties\n        sorted_candidates = sorted(indexed_scores, key=lambda x: (-x[1], x[0]))\n        \n        # Extract the indices of the top B candidates\n        top_indices = [idx for idx, score in sorted_candidates[:B]]\n        \n        all_results.append([rounded_scores, top_indices])\n\n    # Convert the list of lists to the specified string format with no spaces\n    # json.dumps provides a compact representation.\n    output_str = json.dumps(all_results, separators=(',', ':'))\n    print(output_str)\n\nsolve()\n```"
        }
    ]
}