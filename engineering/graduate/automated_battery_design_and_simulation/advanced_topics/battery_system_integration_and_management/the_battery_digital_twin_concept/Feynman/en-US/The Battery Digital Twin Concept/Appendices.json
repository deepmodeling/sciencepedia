{
    "hands_on_practices": [
        {
            "introduction": "A crucial first step in designing an efficient battery digital twin is to understand the relative speeds of the underlying physical processes. This exercise guides you through a time-scale analysis, a fundamental technique for model simplification. By deriving and comparing the characteristic times for diffusion and charge relaxation, you can determine which phenomena are rate-limiting and which can be approximated as quasi-steady, allowing for the construction of computationally faster yet physically accurate models .",
            "id": "3955465",
            "problem": "A Battery Digital Twin (BDT) for automated battery design and simulation must decide, based on first principles, which coupled physics can be reduced by quasi-steady approximations at a specified operating intensity. Consider a single-particle porous electrode model of a lithium-ion cell in which the solid-state lithium concentration in active particles, the electrolyte concentration across the porous electrode, and electric charge in the electronic and ionic phases evolve in time. For a characteristic particle radius $R_s$, electrode electrolyte path length $L$, solid diffusion coefficient $D_s$, electrolyte diffusion coefficient $D_e$, electronic conductivity $\\sigma_{e}$, ionic conductivity $\\sigma_{\\mathrm{ion}}$, vacuum permittivity $\\epsilon_0$, electrolyte relative permittivity $\\epsilon_{r,\\mathrm{ion}}$, and electronic-phase relative permittivity $\\epsilon_{r,e}$, perform a time-scale analysis rooted in governing conservation laws to compare the characteristic solid diffusion time $t_{D,s}$, electrolyte diffusion time $t_{D,e}$, and charge relaxation times in the electronic and ionic phases.\n\nUse the following scientifically consistent parameters:\n- $R_s = 5.0 \\times 10^{-6}\\,\\mathrm{m}$,\n- $L = 1.0 \\times 10^{-4}\\,\\mathrm{m}$,\n- $D_s = 1.0 \\times 10^{-14}\\,\\mathrm{m}^2\\,\\mathrm{s}^{-1}$,\n- $D_e = 2.0 \\times 10^{-10}\\,\\mathrm{m}^2\\,\\mathrm{s}^{-1}$,\n- $\\sigma_{e} = 1.0 \\times 10^{4}\\,\\mathrm{S}\\,\\mathrm{m}^{-1}$,\n- $\\sigma_{\\mathrm{ion}} = 1.0\\,\\mathrm{S}\\,\\mathrm{m}^{-1}$,\n- $\\epsilon_0 = 8.8541878128 \\times 10^{-12}\\,\\mathrm{F}\\,\\mathrm{m}^{-1}$,\n- $\\epsilon_{r,\\mathrm{ion}} = 40$,\n- $\\epsilon_{r,e} = 5$.\n\nAdopt the definition of $C$-rate $C$ such that a full charge or discharge at $1C$ lasts $3600\\,\\mathrm{s}$, so the operating period at $C$ is $T_C = 3600/C$. A process is deemed quasi-steady within the BDT if its characteristic time $t_i$ satisfies $t_i \\leq 0.1\\,T_C$.\n\nStarting from conservation laws for mass and charge and constitutive relations, derive appropriate characteristic times and evaluate them numerically for a representative operating intensity $C^{\\star} = 3.0$ to decide which dynamics can be treated as quasi-steady under that $C$-rate. Then, using the same quasi-steady criterion, compute the maximum $C$-rate $C_{\\max,e}$ for which electrolyte concentration dynamics can be modeled as quasi-steady.\n\nExpress the final answer as a dimensionless number for $C_{\\max,e}$ and round to three significant figures. Do not include any units in the final answer.",
            "solution": "The problem requires a time-scale analysis for a lithium-ion battery model to determine which physical processes can be approximated as quasi-steady. This involves deriving the characteristic times for solid-state diffusion, electrolyte diffusion, and charge relaxation from fundamental conservation laws, evaluating them numerically, and comparing them to a threshold time defined by the battery's operating C-rate.\n\nFirst, we establish the theoretical basis for each characteristic time.\n\n1.  **Characteristic Time for Solid-State Diffusion ($t_{D,s}$)**\n    The transport of lithium within the solid active material particles is governed by Fick's second law of diffusion. In spherical coordinates, assuming diffusion is purely radial, the conservation of mass is expressed as:\n    $$\n    \\frac{\\partial c_s}{\\partial t} = \\frac{1}{r^2} \\frac{\\partial}{\\partial r} \\left( D_s r^2 \\frac{\\partial c_s}{\\partial r} \\right)\n    $$\n    where $c_s$ is the lithium concentration in the solid, $t$ is time, $r$ is the radial coordinate, and $D_s$ is the solid-state diffusion coefficient. A dimensional analysis of this equation reveals the scaling relationship between time and length. The left side scales as $[c_s]/[t]$, and the right side scales as $D_s [c_s]/[L]^2$. The characteristic length scale for this process is the particle radius, $R_s$. Equating the time scales gives the characteristic diffusion time:\n    $$\n    t_{D,s} \\sim \\frac{R_s^2}{D_s}\n    $$\n\n2.  **Characteristic Time for Electrolyte Diffusion ($t_{D,e}$)**\n    Similarly, the transport of salt ions in the electrolyte across the porous electrode is governed by Fick's second law. In one dimension, this is:\n    $$\n    \\frac{\\partial c_e}{\\partial t} = \\frac{\\partial}{\\partial x} \\left( D_e \\frac{\\partial c_e}{\\partial x} \\right)\n    $$\n    where $c_e$ is the electrolyte concentration, $x$ is the spatial coordinate across the electrode, and $D_e$ is the electrolyte diffusion coefficient. The characteristic length for this process is the electrode's electrolyte path length, $L$. The dimensional analysis is analogous to the solid-state case, yielding the characteristic diffusion time for the electrolyte:\n    $$\n    t_{D,e} \\sim \\frac{L^2}{D_e}\n    $$\n    Note that in a porous medium, an effective diffusivity $D_{e, \\text{eff}}$ is often used. Since only $D_e$ is provided, we use it directly as the relevant transport parameter for this analysis.\n\n3.  **Characteristic Times for Charge Relaxation ($t_{R,e}$ and $t_{R,\\mathrm{ion}}$)**\n    Charge relaxation describes how quickly a non-neutral charge distribution returns to equilibrium in a conductive medium. The governing principles are the charge continuity equation and Gauss's law. The continuity equation is $\\frac{\\partial \\rho_q}{\\partial t} + \\nabla \\cdot \\vec{J} = 0$, where $\\rho_q$ is the free charge density and $\\vec{J}$ is the current density. The current density is given by Ohm's law, $\\vec{J} = \\sigma \\vec{E}$, where $\\sigma$ is the conductivity and $\\vec{E}$ is the electric field. Gauss's law for a dielectric material states $\\nabla \\cdot \\vec{E} = \\rho_q/\\epsilon$, where $\\epsilon$ is the material's permittivity ($\\epsilon = \\epsilon_0 \\epsilon_r$). Combining these equations (assuming uniform $\\sigma$) gives:\n    $$\n    \\frac{\\partial \\rho_q}{\\partial t} + \\sigma (\\nabla \\cdot \\vec{E}) = 0 \\implies \\frac{\\partial \\rho_q}{\\partial t} + \\frac{\\sigma}{\\epsilon} \\rho_q = 0\n    $$\n    This is a first-order ordinary differential equation for $\\rho_q$, which describes exponential decay with a characteristic time constant, known as the charge relaxation time, $t_R = \\epsilon/\\sigma$.\n    For the electronic phase (solid matrix), the permittivity is $\\epsilon_e = \\epsilon_0 \\epsilon_{r,e}$ and the conductivity is $\\sigma_e$:\n    $$\n    t_{R,e} = \\frac{\\epsilon_0 \\epsilon_{r,e}}{\\sigma_e}\n    $$\n    For the ionic phase (electrolyte), the permittivity is $\\epsilon_{\\mathrm{ion}} = \\epsilon_0 \\epsilon_{r,\\mathrm{ion}}$ and the conductivity is $\\sigma_{\\mathrm{ion}}$:\n    $$\n    t_{R,\\mathrm{ion}} = \\frac{\\epsilon_0 \\epsilon_{r,\\mathrm{ion}}}{\\sigma_{\\mathrm{ion}}}\n    $$\n\nNow, we evaluate these characteristic times using the provided numerical values:\n$R_s = 5.0 \\times 10^{-6}\\,\\mathrm{m}$, $L = 1.0 \\times 10^{-4}\\,\\mathrm{m}$, $D_s = 1.0 \\times 10^{-14}\\,\\mathrm{m}^2\\,\\mathrm{s}^{-1}$, $D_e = 2.0 \\times 10^{-10}\\,\\mathrm{m}^2\\,\\mathrm{s}^{-1}$, $\\sigma_{e} = 1.0 \\times 10^{4}\\,\\mathrm{S}\\,\\mathrm{m}^{-1}$, $\\sigma_{\\mathrm{ion}} = 1.0\\,\\mathrm{S}\\,\\mathrm{m}^{-1}$, $\\epsilon_0 = 8.8541878128 \\times 10^{-12}\\,\\mathrm{F}\\,\\mathrm{m}^{-1}$, $\\epsilon_{r,\\mathrm{ion}} = 40$, and $\\epsilon_{r,e} = 5$.\n\n$$\nt_{D,s} = \\frac{(5.0 \\times 10^{-6})^2}{1.0 \\times 10^{-14}} = \\frac{25.0 \\times 10^{-12}}{1.0 \\times 10^{-14}} = 2500\\,\\mathrm{s}\n$$\n$$\nt_{D,e} = \\frac{(1.0 \\times 10^{-4})^2}{2.0 \\times 10^{-10}} = \\frac{1.0 \\times 10^{-8}}{2.0 \\times 10^{-10}} = 50\\,\\mathrm{s}\n$$\n$$\nt_{R,e} = \\frac{(8.8541878128 \\times 10^{-12})(5)}{1.0 \\times 10^{4}} \\approx 4.427 \\times 10^{-15}\\,\\mathrm{s}\n$$\n$$\nt_{R,\\mathrm{ion}} = \\frac{(8.8541878128 \\times 10^{-12})(40)}{1.0} \\approx 3.542 \\times 10^{-10}\\,\\mathrm{s}\n$$\n\nNext, we determine which processes are quasi-steady at the operating intensity $C^{\\star} = 3.0$. The operating period is $T_{C^{\\star}} = 3600/C^{\\star} = 3600/3.0 = 1200\\,\\mathrm{s}$. The quasi-steady criterion is $t_i \\leq 0.1\\,T_{C^{\\star}}$.\nThe threshold time is $0.1 \\times 1200\\,\\mathrm{s} = 120\\,\\mathrm{s}$.\nWe compare our calculated times to this threshold:\n-   Solid diffusion: $t_{D,s} = 2500\\,\\mathrm{s}$. Since $2500\\,\\mathrm{s} > 120\\,\\mathrm{s}$, this process is **not** quasi-steady. It is the slowest dynamic process.\n-   Electrolyte diffusion: $t_{D,e} = 50\\,\\mathrm{s}$. Since $50\\,\\mathrm{s} \\leq 120\\,\\mathrm{s}$, this process **is** quasi-steady.\n-   Electronic charge relaxation: $t_{R,e} \\approx 4.4 \\times 10^{-15}\\,\\mathrm{s}$. Since $4.4 \\times 10^{-15}\\,\\mathrm{s} \\ll 120\\,\\mathrm{s}$, this process **is** quasi-steady.\n-   Ionic charge relaxation: $t_{R,\\mathrm{ion}} \\approx 3.5 \\times 10^{-10}\\,\\mathrm{s}$. Since $3.5 \\times 10^{-10}\\,\\mathrm{s} \\ll 120\\,\\mathrm{s}$, this process **is** quasi-steady.\n\nThe extremely short charge relaxation times indicate that charge distribution in both phases happens almost instantaneously compared to the operating time scale. Thus, the governing equations for electric charge can be simplified to algebraic equations (electroneutrality), a common simplification in battery models.\n\nFinally, we compute the maximum C-rate, $C_{\\max,e}$, for which electrolyte concentration dynamics can be modeled as quasi-steady. The condition is $t_{D,e} \\leq 0.1\\,T_C$.\n$$\nt_{D,e} \\leq 0.1 \\left( \\frac{3600}{C} \\right)\n$$\nTo find the maximum C-rate, we solve for $C$ at the boundary of this inequality:\n$$\nC_{\\max,e} = \\frac{0.1 \\times 3600}{t_{D,e}} = \\frac{360}{t_{D,e}}\n$$\nSubstituting the value $t_{D,e} = 50\\,\\mathrm{s}$:\n$$\nC_{\\max,e} = \\frac{360}{50} = 7.2\n$$\nThe problem requires this result rounded to three significant figures, which is $7.20$. This means that for any C-rate up to $7.20$, the electrolyte diffusion process can be considered quasi-steady according to the specified criterion. Beyond this rate, its dynamics must be resolved explicitly.",
            "answer": "$$\\boxed{7.20}$$"
        },
        {
            "introduction": "A physics-based digital twin is only as reliable as its numerical solver. This practice delves into the critical concept of numerical stability, a cornerstone of computational modeling. You will use von Neumann stability analysis to derive the time-step constraint for a common explicit scheme, revealing why such methods are often impractical for the \"stiff\" systems typical of battery models and justifying the need for more robust implicit methods .",
            "id": "3955419",
            "problem": "A battery digital twin integrates multi-physics models to replicate the behavior of a real battery. Consider the solid-state lithium concentration field in one dimension within a single active material particle of a lithium-ion electrode, modeled by Fick's second law as the partial differential equation (PDE) $\\frac{\\partial c(x,t)}{\\partial t} = D \\frac{\\partial^{2} c(x,t)}{\\partial x^{2}}$, where $c(x,t)$ is the lithium concentration, $D$ is the constant solid-state diffusion coefficient, $x$ is the spatial coordinate, and $t$ is time. On a uniform spatial grid with spacing $\\Delta x$, an automated battery design workflow applies a forward Euler time discretization and a second-order central difference spatial discretization to this diffusion subproblem.\n\nStarting from the PDE and the stated discretization choices (but not any specific update formula), perform a Fourier-mode amplification (also known as Von Neumann) stability analysis to derive the largest admissible time step $\\Delta t_{\\max}$ for the explicit scheme in terms of $D$ and $\\Delta x$. Then, compute the numerical value of $\\Delta t_{\\max}$ for $\\Delta x = 50\\,\\mathrm{nm}$ and $D = 1.0 \\times 10^{-14}\\,\\mathrm{m}^{2}\\,\\mathrm{s}^{-1}$. Express the final time-step in seconds and round your answer to four significant figures.\n\nFinally, within the battery digital twin context, justify from first principles why implicit time-stepping schemes are preferred for stiff coupled reaction–diffusion–electrostatics systems that include fast interfacial kinetics and charge conservation constraints, even though implicit schemes require solving algebraic systems at each time step. Your justification should be based on the eigenvalue structure of the linearized operators and the stability properties of the time integrators, rather than on heuristic statements.",
            "solution": "The problem is divided into three parts: first, the derivation of the stability criterion for an explicit numerical scheme for the diffusion equation; second, the calculation of a numerical value for the maximum time step; and third, a justification for the use of implicit schemes in complex battery models. We shall address each part in sequence.\n\nThe governing partial differential equation (PDE) for one-dimensional diffusion is Fick's second law:\n$$\n\\frac{\\partial c(x,t)}{\\partial t} = D \\frac{\\partial^{2} c(x,t)}{\\partial x^{2}}\n$$\nwhere $c$ is the concentration, $D$ is the diffusion coefficient, $x$ is the spatial coordinate, and $t$ is time.\n\nTo analyze the stability of the numerical scheme, we first discretize this PDE. Let the grid points be denoted by $x_j = j \\Delta x$ and time steps by $t_n = n \\Delta t$. The concentration at a grid point $(x_j, t_n)$ is denoted by $c_j^n$.\n\nThe problem specifies a forward Euler scheme for the time derivative and a second-order central difference for the spatial derivative.\nThe forward Euler approximation for the time derivative at $(x_j, t_n)$ is:\n$$\n\\frac{\\partial c}{\\partial t} \\bigg|_{j,n} \\approx \\frac{c_j^{n+1} - c_j^n}{\\Delta t}\n$$\nThe second-order central difference approximation for the second spatial derivative at $(x_j, t_n)$ is:\n$$\n\\frac{\\partial^{2} c}{\\partial x^{2}} \\bigg|_{j,n} \\approx \\frac{c_{j+1}^n - 2c_j^n + c_{j-1}^n}{(\\Delta x)^2}\n$$\nSubstituting these approximations into the PDE yields the fully discretized update equation:\n$$\n\\frac{c_j^{n+1} - c_j^n}{\\Delta t} = D \\left( \\frac{c_{j+1}^n - 2c_j^n + c_{j-1}^n}{(\\Delta x)^2} \\right)\n$$\nRearranging for the concentration at the next time step, $c_j^{n+1}$, we get:\n$$\nc_j^{n+1} = c_j^n + \\frac{D \\Delta t}{(\\Delta x)^2} (c_{j+1}^n - 2c_j^n + c_{j-1}^n)\n$$\n\nWe now perform a Fourier-mode amplification (von Neumann) stability analysis. We consider a single Fourier mode component of the numerical error, represented as:\n$$\nc_j^n = G(k)^n e^{i k x_j} = G^n e^{i k j \\Delta x}\n$$\nwhere $k$ is the wave number and $G(k)$ is the amplification factor for that mode. For the scheme to be stable, the magnitude of the amplification factor must not exceed unity for all possible wave numbers, i.e., $|G(k)| \\le 1$.\n\nSubstituting the Fourier mode into the discretized equation:\n$$\nG^{n+1} e^{i k j \\Delta x} = G^n e^{i k j \\Delta x} + \\frac{D \\Delta t}{(\\Delta x)^2} \\left[ G^n e^{i k (j+1) \\Delta x} - 2G^n e^{i k j \\Delta x} + G^n e^{i k (j-1) \\Delta x} \\right]\n$$\nDividing by the common factor $G^n e^{i k j \\Delta x}$:\n$$\nG = 1 + \\frac{D \\Delta t}{(\\Delta x)^2} \\left[ e^{i k \\Delta x} - 2 + e^{-i k \\Delta x} \\right]\n$$\nUsing the Euler's formula identity $e^{i\\theta} + e^{-i\\theta} = 2\\cos(\\theta)$, we can simplify the expression in the brackets:\n$$\nG = 1 + \\frac{D \\Delta t}{(\\Delta x)^2} [2\\cos(k \\Delta x) - 2] = 1 - \\frac{2 D \\Delta t}{(\\Delta x)^2} [1 - \\cos(k \\Delta x)]\n$$\nNext, we use the trigonometric half-angle identity $1 - \\cos(\\theta) = 2\\sin^2(\\theta/2)$:\n$$\nG = 1 - \\frac{4 D \\Delta t}{(\\Delta x)^2} \\sin^2\\left(\\frac{k \\Delta x}{2}\\right)\n$$\nThe stability condition is $|G| \\le 1$, which for this real-valued amplification factor is $-1 \\le G \\le 1$.\nThe upper bound, $G \\le 1$, is always satisfied, since $D$, $\\Delta t$, and $(\\Delta x)^2$ are positive, and $\\sin^2(\\cdot) \\geq 0$.\nThe lower bound, $G \\ge -1$, imposes the critical constraint:\n$$\n-1 \\le 1 - \\frac{4 D \\Delta t}{(\\Delta x)^2} \\sin^2\\left(\\frac{k \\Delta x}{2}\\right)\n$$\n$$\n\\frac{4 D \\Delta t}{(\\Delta x)^2} \\sin^2\\left(\\frac{k \\Delta x}{2}\\right) \\le 2\n$$\n$$\n\\frac{2 D \\Delta t}{(\\Delta x)^2} \\sin^2\\left(\\frac{k \\Delta x}{2}\\right) \\le 1\n$$\nThis condition must hold for all wave numbers $k$. The most restrictive case (the \"worst case\" for stability) occurs when the term $\\sin^2\\left(\\frac{k \\Delta x}{2}\\right)$ is maximized. The maximum value of $\\sin^2(\\cdot)$ is $1$. This corresponds to the highest frequency mode resolvable on the grid, where $k \\Delta x = \\pi$.\nSetting $\\sin^2\\left(\\frac{k \\Delta x}{2}\\right) = 1$, the stability condition becomes:\n$$\n\\frac{2 D \\Delta t}{(\\Delta x)^2} \\le 1\n$$\nSolving for $\\Delta t$, we find the stability limit:\n$$\n\\Delta t \\le \\frac{(\\Delta x)^2}{2 D}\n$$\nThus, the largest admissible time step, $\\Delta t_{\\max}$, is:\n$$\n\\Delta t_{\\max} = \\frac{(\\Delta x)^2}{2 D}\n$$\n\nNext, we compute the numerical value for $\\Delta t_{\\max}$ using the provided data: $\\Delta x = 50\\,\\mathrm{nm} = 50 \\times 10^{-9}\\,\\mathrm{m}$ and $D = 1.0 \\times 10^{-14}\\,\\mathrm{m}^{2}\\,\\mathrm{s}^{-1}$.\n$$\n\\Delta t_{\\max} = \\frac{(50 \\times 10^{-9}\\,\\mathrm{m})^2}{2 \\times (1.0 \\times 10^{-14}\\,\\mathrm{m}^{2}\\,\\mathrm{s}^{-1})} = \\frac{2500 \\times 10^{-18}\\,\\mathrm{m}^2}{2.0 \\times 10^{-14}\\,\\mathrm{m}^{2}\\,\\mathrm{s}^{-1}}\n$$\n$$\n\\Delta t_{\\max} = \\frac{2.5 \\times 10^{-15}\\,\\mathrm{m}^2}{2.0 \\times 10^{-14}\\,\\mathrm{m}^{2}\\,\\mathrm{s}^{-1}} = 0.125\\,\\mathrm{s}\n$$\nRounding this result to four significant figures as requested gives $0.1250\\,\\mathrm{s}$.\n\nFinally, we address why implicit time-stepping schemes are preferred for stiff coupled systems in battery digital twins.\nA system of differential equations is termed \"stiff\" when it involves physical processes occurring on vastly different time scales. In a battery model, this includes:\n$1.$ Fast processes: rapid interfacial charge-transfer reactions (Butler-Volmer kinetics).\n$2.$ Intermediate processes: ion diffusion in the electrolyte and solid particles.\n$3.$ Slow processes: degradation mechanisms or full charge/discharge cycles.\n\nSpatially discretizing the coupled PDEs (for concentration, potential, etc.) transforms the problem into a large system of ordinary differential equations (ODEs) of the form $\\frac{d\\mathbf{u}}{dt} = \\mathbf{f}(\\mathbf{u}, t)$, where $\\mathbf{u}$ is the vector of state variables at all grid points. The stiffness of this system is characterized by the eigenvalue spectrum of its Jacobian matrix, $\\mathbf{J} = \\frac{\\partial \\mathbf{f}}{\\partial \\mathbf{u}}$. A stiff system has eigenvalues $\\lambda_i$ where the ratio $\\max_i |\\text{Re}(\\lambda_i)| / \\min_i |\\text{Re}(\\lambda_i)|$ is very large.\n\nFor the diffusion operator, as shown by the stability analysis, the effective eigenvalues are proportional to $-D/(\\Delta x)^2$. For fine spatial grids required for accuracy, $|\\lambda_{\\max}|$ becomes very large. Fast reaction kinetics contribute further large-magnitude negative eigenvalues.\n\nThe stability of a time integrator is analyzed by applying it to the model problem $\\frac{dy}{dt} = \\lambda y$, where $\\lambda$ is a complex number representative of an eigenvalue of the system Jacobian.\nFor an explicit scheme like Forward Euler, the update is $y_{n+1} = y_n + \\Delta t (\\lambda y_n) = (1 + \\Delta t \\lambda) y_n$. The amplification factor is $G = 1 + \\Delta t \\lambda$. For stability, we require $|G| \\le 1$. This condition defines a stability region in the complex plane for $\\Delta t \\lambda$. For eigenvalues with negative real parts (typical of dissipative physical systems like diffusion), this region is a circle of radius $1$ centered at $(-1,0)$. This imposes a constraint on the time step: $\\Delta t \\le \\frac{C}{|\\lambda_{\\max}|}$, where $C$ is a constant of order unity (e.g., $C=2$ for diffusion). The time step is thus severely restricted by the fastest time scale (largest eigenvalue) in the system, even if the solution components associated with that time scale decay rapidly and are not of primary interest.\n\nIn contrast, implicit schemes are designed to have much larger stability regions. For an implicit scheme like Backward Euler, the update is $y_{n+1} = y_n + \\Delta t (\\lambda y_{n+1})$, leading to $y_{n+1} = \\frac{1}{1 - \\Delta t \\lambda} y_n$. The amplification factor is $G = (1 - \\Delta t \\lambda)^{-1}$. For any $\\lambda$ with a negative real part, $|G| < 1$ for any $\\Delta t > 0$. Such a scheme is called \"A-stable\". Its stability region includes the entire left half of the complex plane.\n\nThis property of unconditional stability for stiff components is the critical advantage of implicit methods. The time step $\\Delta t$ is no longer constrained by the stability of the fastest, often uninteresting, dynamics. Instead, it can be chosen based on the accuracy requirements for resolving the slower, physically significant dynamics of the overall system. While implicit schemes require solving a system of (often nonlinear) algebraic equations at each time step, which is computationally more expensive per step than an explicit method, the ability to take vastly larger time steps makes them far more efficient and robust for simulating stiff battery systems over practical time scales.",
            "answer": "$$\\boxed{0.1250}$$"
        },
        {
            "introduction": "Bridging the gap between physical models and real-world data is the essence of a digital twin. This hands-on problem introduces Physics-Informed Neural Networks (PINNs), a powerful machine learning framework for this purpose. You will construct the composite loss function for a PINN that encodes diffusion physics, electrochemical boundary conditions, and data assimilation terms, providing a blueprint for creating next-generation, data-adaptive battery models .",
            "id": "3955483",
            "problem": "You are tasked with designing a Physics-Informed Neural Network (PINN) for a one-dimensional solid-state diffusion subsystem of a battery Digital Twin (DT). The PINN must encode the diffusion Partial Differential Equation (PDE), boundary conditions, and a data assimilation term to compare against sparse sensor-like measurements. Your final output must be a complete, runnable program that computes the composite loss for three scientifically plausible test cases, each representing distinct electrochemical regimes. The program must produce a single line containing a comma-separated list enclosed in square brackets with one floating-point loss value per test case.\n\nThe physical subsystem is one-dimensional solid diffusion in a thin active-material slab with spatial coordinate $x \\in [0,L]$ and time $t \\in [0,T_{\\mathrm{end}}]$. The governing law is Fick’s second law, and the boundary flux at the external surface $x=L$ is constrained by Butler–Volmer (BV) kinetics with a Nernst equilibrium potential. The PINN approximates the lithium concentration field $\\hat{c}(x,t;\\theta)$.\n\nFundamental base and core definitions:\n- Fick’s second law: $\\dfrac{\\partial c}{\\partial t} = D \\dfrac{\\partial^2 c}{\\partial x^2}$, where $D$ is the solid diffusion coefficient.\n- Symmetry (no-flux) boundary at $x=0$: $\\left.\\dfrac{\\partial c}{\\partial x}\\right|_{x=0} = 0$.\n- Flux boundary at $x=L$: $-D \\left.\\dfrac{\\partial c}{\\partial x}\\right|_{x=L} = \\dfrac{j_{\\mathrm{BV}}}{n F}$, where $n$ is the number of electrons per reaction (here $n=1$), $F$ is Faraday’s constant, and $j_{\\mathrm{BV}}$ is the Butler–Volmer current density.\n- Butler–Volmer current density: $j_{\\mathrm{BV}}(c_s) = i_0(c_s)\\left[\\exp\\!\\left(\\dfrac{\\alpha_a F \\eta}{R T}\\right) - \\exp\\!\\left(-\\dfrac{\\alpha_c F \\eta}{R T}\\right)\\right]$, where $\\eta = E_{\\mathrm{app}} - U(c_s)$ is the overpotential, $E_{\\mathrm{app}}$ is applied potential, $\\alpha_a$ and $\\alpha_c$ are anodic and cathodic charge-transfer coefficients, $R$ is the gas constant, $T$ is temperature, and $i_0(c_s)$ is the exchange current density.\n- Nernst equilibrium potential: $U(c) = U_{\\mathrm{ref}} + \\dfrac{R T}{F}\\ln\\!\\left(\\dfrac{c}{c_{\\max}-c}\\right)$, where $c_{\\max}$ is the maximum concentration.\n- Exchange current density model: $i_0(c) = k_0 \\sqrt{c(c_{\\max}-c)}$, with kinetic prefactor $k_0$.\n- Initial condition: $c(x,0) = c_0$ for all $x$.\n\nTo ensure numerical robustness in the Butler–Volmer evaluation, use a regularized concentration at the boundary, $\\tilde{c}_s = \\max\\!\\left(\\epsilon,\\min\\!\\left(c_s,c_{\\max}-\\epsilon\\right)\\right)$, with small $\\epsilon>0$.\n\nPINN architecture and analytical derivatives:\n- Use a single-hidden-layer feedforward network with $m$ neurons and hyperbolic tangent activation. Let the input be $(x,t)$, with weight matrix $W_1 \\in \\mathbb{R}^{m\\times 2}$, bias $b_1 \\in \\mathbb{R}^m$, output weights $W_2 \\in \\mathbb{R}^m$, and output bias $b_2 \\in \\mathbb{R}$.\n- The network output is\n$$\n\\hat{c}(x,t;\\theta) = b_2 + \\sum_{k=1}^{m} W_{2,k}\\,\\tanh\\!\\big(z_k(x,t)\\big), \\quad z_k(x,t) = b_{1,k} + W_{1,k,1} x + W_{1,k,2} t.\n$$\n- Let $\\operatorname{sech}(z) = 1/\\cosh(z)$ and note $\\dfrac{d}{dz}\\tanh(z) = \\operatorname{sech}^2(z)$ and $\\dfrac{d^2}{dz^2}\\tanh(z) = -2\\,\\tanh(z)\\,\\operatorname{sech}^2(z)$.\n- The required derivatives are\n$$\n\\frac{\\partial \\hat{c}}{\\partial x} = \\sum_{k=1}^m W_{2,k}\\,\\operatorname{sech}^2(z_k)\\,W_{1,k,1}, \\quad\n\\frac{\\partial \\hat{c}}{\\partial t} = \\sum_{k=1}^m W_{2,k}\\,\\operatorname{sech}^2(z_k)\\,W_{1,k,2},\n$$\n$$\n\\frac{\\partial^2 \\hat{c}}{\\partial x^2} = \\sum_{k=1}^m W_{2,k}\\,\\big(-2\\,\\tanh(z_k)\\,\\operatorname{sech}^2(z_k)\\big)\\,W_{1,k,1}^2.\n$$\n\nComposite loss design:\n- Define residuals at interior collocation points $(x_i,t_i)$: $r_{\\mathrm{pde}}(x_i,t_i) = \\dfrac{\\partial \\hat{c}}{\\partial t}(x_i,t_i) - D\\,\\dfrac{\\partial^2 \\hat{c}}{\\partial x^2}(x_i,t_i)$.\n- Define symmetry boundary residuals at times $t_j$: $r_{0}(t_j) = \\dfrac{\\partial \\hat{c}}{\\partial x}(0,t_j)$.\n- Define flux boundary residuals at times $t_j$ using BV: $r_{L}(t_j) = -D\\,\\dfrac{\\partial \\hat{c}}{\\partial x}(L,t_j) - \\dfrac{j_{\\mathrm{BV}}(\\tilde{c}_s(L,t_j))}{n F}$.\n- Define initial condition residuals at positions $x_\\ell$: $r_{\\mathrm{ic}}(x_\\ell) = \\hat{c}(x_\\ell,0) - c_0$.\n- Define data mismatch residuals at given data points $(x_d,t_d)$ with target $c_{\\mathrm{data}}$: $r_{\\mathrm{data}}(x_d,t_d) = \\hat{c}(x_d,t_d) - c_{\\mathrm{data}}$.\n\n- The composite loss is\n$$\n\\mathcal{L}(\\theta) = \\lambda_{\\mathrm{pde}}\\,\\frac{1}{N_{\\mathrm{pde}}}\\sum_i r_{\\mathrm{pde}}(x_i,t_i)^2\n+ \\lambda_{0}\\,\\frac{1}{N_{0}}\\sum_j r_{0}(t_j)^2\n+ \\lambda_{L}\\,\\frac{1}{N_{L}}\\sum_j r_{L}(t_j)^2\n+ \\lambda_{\\mathrm{ic}}\\,\\frac{1}{N_{\\mathrm{ic}}}\\sum_\\ell r_{\\mathrm{ic}}(x_\\ell)^2\n+ \\lambda_{\\mathrm{data}}\\,\\frac{1}{N_{\\mathrm{data}}}\\sum_{d} r_{\\mathrm{data}}(x_d,t_d)^2,\n$$\nwith nonnegative weights $\\lambda_{\\cdot}$.\n\nScientific realism:\n- Use physically plausible ranges: $D$ on the order of $10^{-14}\\,\\mathrm{m^2/s}$, $L$ on the order of $10^{-6}\\,\\mathrm{m}$, $T$ near room temperature, exchange kinetics that yield reasonable $j_{\\mathrm{BV}}$ magnitudes, and concentration ranges strictly within $(0,c_{\\max})$. Use $n=1$.\n\nProgram requirements:\n- Implement the PINN and compute the composite loss for each test case using only analytical derivatives as defined above.\n- Do not train the network; simply evaluate the loss for the predefined parameter sets.\n- The final output must be a single line of the form $[\\ell_1,\\ell_2,\\ell_3]$, where $\\ell_k$ are floating-point losses for each test case. The loss values are dimensionless.\n\nUnits and angle specification:\n- Express all physical quantities internally in SI units: $x$ in $\\mathrm{m}$, $t$ in $\\mathrm{s}$, $c$ in $\\mathrm{mol/m^3}$, potentials in $\\mathrm{V}$, temperature in $\\mathrm{K}$, and current density in $\\mathrm{A/m^2}$. No angles are involved. The output loss values are unitless floats.\n\nTest suite:\n- Use three test cases with the following parameters and evaluation grids.\n\nCase $\\mathbf{1}$ (baseline, moderate flux):\n- $m = 3$,\n- $L = 1.0\\times 10^{-6}\\,\\mathrm{m}$,\n- $D = 1.0\\times 10^{-14}\\,\\mathrm{m^2/s}$,\n- $T = 298.0\\,\\mathrm{K}$,\n- $R = 8.314\\,\\mathrm{J/(mol\\cdot K)}$,\n- $F = 96485.0\\,\\mathrm{C/mol}$,\n- $\\alpha_a = 0.5$, $\\alpha_c = 0.5$,\n- $U_{\\mathrm{ref}} = 4.0\\,\\mathrm{V}$,\n- $c_{\\max} = 25000.0\\,\\mathrm{mol/m^3}$,\n- $c_0 = 15000.0\\,\\mathrm{mol/m^3}$,\n- $k_0 = 5.0\\,\\mathrm{A/m^2}$,\n- $E_{\\mathrm{app}} = 4.2\\,\\mathrm{V}$,\n- $\\epsilon = 1.0\\,\\mathrm{mol/m^3}$,\n- Weights: $W_1 = \\begin{bmatrix} 1.0\\times 10^{6} & -1.0 \\\\ -1.0\\times 10^{6} & 2.0 \\\\ 5.0\\times 10^{5} & -0.5 \\end{bmatrix}$, $b_1 = \\begin{bmatrix} 0.0 \\\\ 0.1 \\\\ -0.1 \\end{bmatrix}$, $W_2 = \\begin{bmatrix} 100.0 \\\\ -50.0 \\\\ 25.0 \\end{bmatrix}$, $b_2 = 15000.0$,\n- Interior collocation: $x \\in \\{L/4,\\,L/2,\\,3L/4\\} = \\{2.5\\times 10^{-7},\\,5.0\\times 10^{-7},\\,7.5\\times 10^{-7}\\}\\,\\mathrm{m}$, $t \\in \\{2.0,\\,5.0,\\,8.0\\}\\,\\mathrm{s}$,\n- Boundary times: $t \\in \\{1.0,\\,4.0,\\,7.0\\}\\,\\mathrm{s}$,\n- Initial positions: $x \\in \\{0.0,\\,L/3,\\,2L/3,\\,L\\} = \\{0.0,\\,3.\\overline{3}\\times 10^{-7},\\,6.\\overline{6}\\times 10^{-7},\\,1.0\\times 10^{-6}\\}\\,\\mathrm{m}$,\n- Data points: $(x,t,c_{\\mathrm{data}}) \\in \\{(0.75L,\\,5.0,\\,15050.0),\\,(0.25L,\\,5.0,\\,14980.0)\\}$,\n- Loss weights: $\\lambda_{\\mathrm{pde}} = 1.0$, $\\lambda_{0} = 10.0$, $\\lambda_{L} = 10.0$, $\\lambda_{\\mathrm{ic}} = 5.0$, $\\lambda_{\\mathrm{data}} = 2.0$.\n\nCase $\\mathbf{2}$ (strong kinetics and higher overpotential):\n- $m = 3$,\n- $L = 1.0\\times 10^{-6}\\,\\mathrm{m}$,\n- $D = 5.0\\times 10^{-15}\\,\\mathrm{m^2/s}$,\n- $T = 298.0\\,\\mathrm{K}$,\n- $R = 8.314\\,\\mathrm{J/(mol\\cdot K)}$,\n- $F = 96485.0\\,\\mathrm{C/mol}$,\n- $\\alpha_a = 0.5$, $\\alpha_c = 0.5$,\n- $U_{\\mathrm{ref}} = 4.0\\,\\mathrm{V}$,\n- $c_{\\max} = 25000.0\\,\\mathrm{mol/m^3}$,\n- $c_0 = 15000.0\\,\\mathrm{mol/m^3}$,\n- $k_0 = 8.0\\,\\mathrm{A/m^2}$,\n- $E_{\\mathrm{app}} = 4.5\\,\\mathrm{V}$,\n- $\\epsilon = 1.0\\,\\mathrm{mol/m^3}$,\n- Weights: $W_1 = \\begin{bmatrix} 0.8\\times 10^{6} & -0.8 \\\\ -0.8\\times 10^{6} & 1.5 \\\\ 0.4\\times 10^{6} & -0.3 \\end{bmatrix}$, $b_1 = \\begin{bmatrix} 0.05 \\\\ -0.05 \\\\ 0.1 \\end{bmatrix}$, $W_2 = \\begin{bmatrix} 120.0 \\\\ -60.0 \\\\ 30.0 \\end{bmatrix}$, $b_2 = 15000.0$,\n- Interior collocation: $x \\in \\{2.5\\times 10^{-7},\\,5.0\\times 10^{-7},\\,7.5\\times 10^{-7}\\}\\,\\mathrm{m}$, $t \\in \\{2.0,\\,5.0,\\,8.0\\}\\,\\mathrm{s}$,\n- Boundary times: $t \\in \\{1.0,\\,4.0,\\,7.0\\}\\,\\mathrm{s}$,\n- Initial positions: $x \\in \\{0.0,\\,3.\\overline{3}\\times 10^{-7},\\,6.\\overline{6}\\times 10^{-7},\\,1.0\\times 10^{-6}\\}\\,\\mathrm{m}$,\n- Data points: $(x,t,c_{\\mathrm{data}}) \\in \\{(0.75L,\\,5.0,\\,15100.0),\\,(0.25L,\\,5.0,\\,14950.0)\\}$,\n- Loss weights: $\\lambda_{\\mathrm{pde}} = 1.0$, $\\lambda_{0} = 10.0$, $\\lambda_{L} = 10.0$, $\\lambda_{\\mathrm{ic}} = 5.0$, $\\lambda_{\\mathrm{data}} = 2.0$.\n\nCase $\\mathbf{3}$ (near saturation, lower overpotential):\n- $m = 3$,\n- $L = 1.0\\times 10^{-6}\\,\\mathrm{m}$,\n- $D = 1.0\\times 10^{-14}\\,\\mathrm{m^2/s}$,\n- $T = 298.0\\,\\mathrm{K}$,\n- $R = 8.314\\,\\mathrm{J/(mol\\cdot K)}$,\n- $F = 96485.0\\,\\mathrm{C/mol}$,\n- $\\alpha_a = 0.5$, $\\alpha_c = 0.5$,\n- $U_{\\mathrm{ref}} = 4.0\\,\\mathrm{V}$,\n- $c_{\\max} = 25000.0\\,\\mathrm{mol/m^3}$,\n- $c_0 = 24000.0\\,\\mathrm{mol/m^3}$,\n- $k_0 = 4.0\\,\\mathrm{A/m^2}$,\n- $E_{\\mathrm{app}} = 3.9\\,\\mathrm{V}$,\n- $\\epsilon = 1.0\\,\\mathrm{mol/m^3}$,\n- Weights: $W_1 = \\begin{bmatrix} 1.0\\times 10^{6} & -1.0 \\\\ -1.0\\times 10^{6} & 2.0 \\\\ 5.0\\times 10^{5} & -0.5 \\end{bmatrix}$, $b_1 = \\begin{bmatrix} 0.0 \\\\ 0.1 \\\\ -0.1 \\end{bmatrix}$, $W_2 = \\begin{bmatrix} 50.0 \\\\ -25.0 \\\\ 12.5 \\end{bmatrix}$, $b_2 = 24000.0$,\n- Interior collocation: $x \\in \\{2.5\\times 10^{-7},\\,5.0\\times 10^{-7},\\,7.5\\times 10^{-7}\\}\\,\\mathrm{m}$, $t \\in \\{2.0,\\,5.0,\\,8.0\\}\\,\\mathrm{s}$,\n- Boundary times: $t \\in \\{1.0,\\,4.0,\\,7.0\\}\\,\\mathrm{s}$,\n- Initial positions: $x \\in \\{0.0,\\,3.\\overline{3}\\times 10^{-7},\\,6.\\overline{6}\\times 10^{-7},\\,1.0\\times 10^{-6}\\}\\,\\mathrm{m}$,\n- Data points: $(x,t,c_{\\mathrm{data}}) \\in \\{(0.75L,\\,5.0,\\,23950.0),\\,(0.25L,\\,5.0,\\,24050.0)\\}$,\n- Loss weights: $\\lambda_{\\mathrm{pde}} = 1.0$, $\\lambda_{0} = 10.0$, $\\lambda_{L} = 10.0$, $\\lambda_{\\mathrm{ic}} = 5.0$, $\\lambda_{\\mathrm{data}} = 2.0$.\n\nRequired final output format:\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (e.g., $[\\ell_1,\\ell_2,\\ell_3]$), where the entries are the composite loss values (floats) for Case $\\mathbf{1}$, Case $\\mathbf{2}$, and Case $\\mathbf{3}$, respectively. No other text should be printed.",
            "solution": "The problem is valid. It presents a well-posed, scientifically grounded task to compute the composite loss of a Physics-Informed Neural Network (PINN) designed to model solid-state diffusion in a battery electrode. All necessary physical laws, model equations, network parameters, and evaluation points are provided, enabling a direct and verifiable computation.\n\n### Principle-Based Design for PINN Loss Computation\n\nThe core of this problem lies in evaluating how well a given neural network, with fixed parameters $\\theta$, satisfies a set of physical laws and data constraints. This is quantified by a composite loss function, $\\mathcal{L}(\\theta)$. The PINN framework replaces the traditional numerical discretization of a Partial Differential Equation (PDE) system with a differentiable, analytical representation—the neural network—and recasts the problem of solving the PDE into an optimization problem of minimizing the loss function. Here, the task is a single forward pass: to compute the loss for a pre-defined network, not to perform the optimization (training).\n\n**1. Physical System and Mathematical Model**\n\nThe physical system is the one-dimensional diffusion of lithium ions within a solid active material slab of thickness $L$. The concentration of lithium, $c(x,t)$, is governed by Fick's second law, a fundamental principle of mass transfer:\n$$\n\\frac{\\partial c}{\\partial t} = D \\frac{\\partial^2 c}{\\partial x^2}\n$$\nwhere $D$ is the diffusion coefficient, $x \\in [0,L]$ is the spatial coordinate, and $t$ is time. The system is subject to specific initial and boundary conditions that define a unique physical scenario:\n- **Initial Condition:** At time $t=0$, the concentration is uniform: $c(x,0) = c_0$.\n- **Symmetry Boundary Condition:** At the center of the slab ($x=0$), there is no flux, representing symmetry: $\\frac{\\partial c}{\\partial x}(0,t) = 0$.\n- **Flux Boundary Condition:** At the slab's surface ($x=L$), the flux of lithium ions is driven by an electrochemical reaction. The flux is related to the Butler-Volmer current density, $j_{\\mathrm{BV}}$, which models the kinetics of the charge-transfer reaction:\n$$\n-D \\frac{\\partial c}{\\partial x}(L,t) = \\frac{j_{\\mathrm{BV}}(\\tilde{c}_s(L,t))}{nF}\n$$\nThe Butler-Volmer equation depends on the surface overpotential $\\eta = E_{\\mathrm{app}} - U(c_s)$, which is the difference between the applied potential $E_{\\mathrm{app}}$ and the Nernst equilibrium potential $U(c_s)$. The Nernst potential itself is a function of the surface concentration $c_s = c(L,t)$, and the exchange current density $i_0$ also depends on $c_s$. These relationships tightly couple the PDE to electrochemical principles.\n\n**2. The PINN Approximation**\n\nThe PINN, denoted $\\hat{c}(x,t;\\theta)$, serves as an analytical surrogate for the true concentration field $c(x,t)$. For this problem, a single-hidden-layer feedforward network with hyperbolic tangent ($\\tanh$) activation functions is specified. The network's output is:\n$$\n\\hat{c}(x,t;\\theta) = b_2 + \\sum_{k=1}^{m} W_{2,k}\\,\\tanh(b_{1,k} + W_{1,k,1} x + W_{1,k,2} t)\n$$\nA key advantage of this representation is that its derivatives with respect to its inputs, $x$ and $t$, can be computed analytically and exactly via the chain rule. The problem provides these analytical expressions, which are crucial for evaluating the PDE and boundary condition residuals without numerical differentiation errors. For instance, the time derivative is:\n$$\n\\frac{\\partial \\hat{c}}{\\partial t} = \\sum_{k=1}^m W_{2,k}\\,\\operatorname{sech}^2(z_k)\\,W_{1,k,2}\n$$\nwhere $z_k$ is the argument of the $k$-th neuron's activation function and $\\operatorname{sech}^2$ is the derivative of $\\tanh$.\n\n**3. The Composite Loss Function**\n\nThe composite loss function, $\\mathcal{L}(\\theta)$, is the sum of mean squared residuals, where each residual measures the violation of a specific physical law or data constraint. The total loss is a weighted sum of five components:\n\n- **PDE Residual Loss ($\\mathcal{L}_{\\mathrm{pde}}$):** This term enforces Fick's second law at a set of collocation points in the interior of the $(x,t)$ domain. The residual is $r_{\\mathrm{pde}} = \\frac{\\partial \\hat{c}}{\\partial t} - D\\frac{\\partial^2 \\hat{c}}{\\partial x^2}$. A small residual indicates that the network's output is a good solution to the PDE.\n- **Symmetry Boundary Loss ($\\mathcal{L}_{0}$):** This term enforces the no-flux condition at $x=0$. The residual is $r_{0} = \\frac{\\partial \\hat{c}}{\\partial x}(0,t)$.\n- **Flux Boundary Loss ($\\mathcal{L}_{L}$):** This term enforces the Butler-Volmer flux condition at $x=L$. The residual is $r_{L} = -D\\frac{\\partial \\hat{c}}{\\partial x}(L,t) - \\frac{j_{\\mathrm{BV}}(\\tilde{c}_s(L,t))}{nF}$. This is the most complex term, as it involves evaluating the non-linear Butler-Volmer kinetics based on the PINN's predicted surface concentration. A regularization, $\\tilde{c}_s = \\max(\\epsilon, \\min(c_s, c_{\\max}-\\epsilon))$, is used to ensure numerical stability in the logarithmic and square-root terms of the Nernst and exchange current density models, preventing arguments from reaching $0$ or $c_{\\max}$.\n- **Initial Condition Loss ($\\mathcal{L}_{\\mathrm{ic}}$):** This term anchors the simulation to its starting state by penalizing deviations from the initial concentration $c_0$. The residual is $r_{\\mathrm{ic}}(x_{\\ell}) = \\hat{c}(x_\\ell,0) - c_0$.\n- **Data Mismatch Loss ($\\mathcal{L}_{\\mathrm{data}}$):** This term represents the data assimilation aspect of the digital twin. It measures the discrepancy between the PINN's prediction and sparse \"sensor\" measurements, $c_{\\mathrm{data}}$, at specific locations $(x_d, t_d)$. The residual is $r_{\\mathrm{data}}(x_d,t_d) = \\hat{c}(x_d,t_d) - c_{\\mathrm{data}}$.\n\nThe total loss is the weighted sum of the mean squared values of these residuals:\n$$\n\\mathcal{L}(\\theta) = \\lambda_{\\mathrm{pde}}\\,\\mathcal{L}_{\\mathrm{pde}}\n+ \\lambda_{0}\\,\\mathcal{L}_{0}\n+ \\lambda_{L}\\,\\mathcal{L}_{L}\n+ \\lambda_{\\mathrm{ic}}\\,\\mathcal{L}_{\\mathrm{ic}}\n+ \\lambda_{\\mathrm{data}}\\,\\mathcal{L}_{\\mathrm{data}}\n$$\nThe weights $\\lambda_{\\cdot}$ balance the relative importance of each physical constraint and data source.\n\n**4. Algorithmic Implementation**\n\nThe solution program implements this framework precisely.\n1.  **Parameterization:** The physical constants, model parameters, network weights, collocation points, and loss weights for each of the three test cases are organized into data structures.\n2.  **Vectorized PINN Functions:** The PINN output $\\hat{c}$ and its analytical derivatives ($\\frac{\\partial\\hat{c}}{\\partial t}$, $\\frac{\\partial\\hat{c}}{\\partial x}$, $\\frac{\\partial^2\\hat{c}}{\\partial x^2}$) are implemented as vectorized Python functions using `NumPy`. This allows for efficient evaluation over batches of $(x,t)$ points. For example, the summation over neurons becomes a matrix-vector product.\n3.  **Residual Calculation:** For each of the five loss components, the corresponding residuals are calculated:\n    - Points for each residual type are generated as specified.\n    - The PINN and its derivative functions are called with these points to get the necessary terms.\n    - The non-linear electrochemical functions (Nernst, exchange current, Butler-Volmer) are evaluated as needed for the $\\mathcal{L}_L$ term.\n    - The residual for each point is computed according to its definition.\n4.  **Loss Aggregation:** The squared residuals for each component are averaged, and the final composite loss is computed as the weighted sum of these mean squared errors.\n5.  **Execution Loop:** A main loop iterates through the three test cases, executing the loss computation for each and collecting the results. The final output is formatted as a comma-separated list in brackets, as required.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to define test cases and compute the composite PINN loss for each.\n    \"\"\"\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # Case 1 (baseline, moderate flux)\n        {\n            \"m\": 3, \"L\": 1.0e-6, \"D\": 1.0e-14, \"T\": 298.0, \"R\": 8.314, \"F\": 96485.0,\n            \"alpha_a\": 0.5, \"alpha_c\": 0.5, \"U_ref\": 4.0, \"c_max\": 25000.0, \"c_0\": 15000.0,\n            \"k_0\": 5.0, \"E_app\": 4.2, \"epsilon\": 1.0, \"n\": 1.0,\n            \"W1\": np.array([[1.0e6, -1.0], [-1.0e6, 2.0], [5.0e5, -0.5]]),\n            \"b1\": np.array([0.0, 0.1, -0.1]),\n            \"W2\": np.array([100.0, -50.0, 25.0]),\n            \"b2\": 15000.0,\n            \"x_pde_rel\": np.array([1/4, 1/2, 3/4]), \"t_pde\": np.array([2.0, 5.0, 8.0]),\n            \"t_bc\": np.array([1.0, 4.0, 7.0]),\n            \"x_ic_rel\": np.array([0.0, 1/3, 2/3, 1.0]),\n            \"data_points\": np.array([[0.75, 5.0, 15050.0], [0.25, 5.0, 14980.0]]),\n            \"lambdas\": {\"pde\": 1.0, \"bc0\": 10.0, \"bcL\": 10.0, \"ic\": 5.0, \"data\": 2.0}\n        },\n        # Case 2 (strong kinetics and higher overpotential)\n        {\n            \"m\": 3, \"L\": 1.0e-6, \"D\": 5.0e-15, \"T\": 298.0, \"R\": 8.314, \"F\": 96485.0,\n            \"alpha_a\": 0.5, \"alpha_c\": 0.5, \"U_ref\": 4.0, \"c_max\": 25000.0, \"c_0\": 15000.0,\n            \"k_0\": 8.0, \"E_app\": 4.5, \"epsilon\": 1.0, \"n\": 1.0,\n            \"W1\": np.array([[0.8e6, -0.8], [-0.8e6, 1.5], [0.4e6, -0.3]]),\n            \"b1\": np.array([0.05, -0.05, 0.1]),\n            \"W2\": np.array([120.0, -60.0, 30.0]),\n            \"b2\": 15000.0,\n            \"x_pde_rel\": np.array([1/4, 1/2, 3/4]), \"t_pde\": np.array([2.0, 5.0, 8.0]),\n            \"t_bc\": np.array([1.0, 4.0, 7.0]),\n            \"x_ic_rel\": np.array([0.0, 1/3, 2/3, 1.0]),\n            \"data_points\": np.array([[0.75, 5.0, 15100.0], [0.25, 5.0, 14950.0]]),\n            \"lambdas\": {\"pde\": 1.0, \"bc0\": 10.0, \"bcL\": 10.0, \"ic\": 5.0, \"data\": 2.0}\n        },\n        # Case 3 (near saturation, lower overpotential)\n        {\n            \"m\": 3, \"L\": 1.0e-6, \"D\": 1.0e-14, \"T\": 298.0, \"R\": 8.314, \"F\": 96485.0,\n            \"alpha_a\": 0.5, \"alpha_c\": 0.5, \"U_ref\": 4.0, \"c_max\": 25000.0, \"c_0\": 24000.0,\n            \"k_0\": 4.0, \"E_app\": 3.9, \"epsilon\": 1.0, \"n\": 1.0,\n            \"W1\": np.array([[1.0e6, -1.0], [-1.0e6, 2.0], [5.0e5, -0.5]]),\n            \"b1\": np.array([0.0, 0.1, -0.1]),\n            \"W2\": np.array([50.0, -25.0, 12.5]),\n            \"b2\": 24000.0,\n            \"x_pde_rel\": np.array([1/4, 1/2, 3/4]), \"t_pde\": np.array([2.0, 5.0, 8.0]),\n            \"t_bc\": np.array([1.0, 4.0, 7.0]),\n            \"x_ic_rel\": np.array([0.0, 1/3, 2/3, 1.0]),\n            \"data_points\": np.array([[0.75, 5.0, 23950.0], [0.25, 5.0, 24050.0]]),\n            \"lambdas\": {\"pde\": 1.0, \"bc0\": 10.0, \"bcL\": 10.0, \"ic\": 5.0, \"data\": 2.0}\n        }\n    ]\n\n    results = []\n    for params in test_cases:\n        loss = compute_composite_loss(params)\n        results.append(loss)\n\n    print(f\"[{','.join(f'{r:.6f}' for r in results)}]\")\n\ndef compute_composite_loss(params):\n    \"\"\"\n    Computes the total composite loss for a given set of parameters.\n    \"\"\"\n    \n    # Unpack network parameters for convenience\n    W1, b1, W2, b2 = params[\"W1\"], params[\"b1\"], params[\"W2\"], params[\"b2\"]\n    \n    # --- PINN and derivatives definitions ---\n    def get_z(x, t):\n        xt_pairs = np.stack([x.flatten(), t.flatten()], axis=1)\n        z = xt_pairs @ W1.T + b1\n        return z\n\n    def pinn_c(x, t):\n        z = get_z(x, t)\n        c = np.tanh(z) @ W2 + b2\n        return c.reshape(x.shape)\n\n    def pinn_dc_dx(x, t):\n        z = get_z(x, t)\n        sech_z_sq = (1.0 / np.cosh(z))**2\n        dc_dx = (sech_z_sq * W1[:, 0]) @ W2\n        return dc_dx.reshape(x.shape)\n\n    def pinn_dc_dt(x, t):\n        z = get_z(x, t)\n        sech_z_sq = (1.0 / np.cosh(z))**2\n        dc_dt = (sech_z_sq * W1[:, 1]) @ W2\n        return dc_dt.reshape(x.shape)\n\n    def pinn_d2c_dx2(x, t):\n        z = get_z(x, t)\n        tanh_z = np.tanh(z)\n        sech_z_sq = (1.0 / np.cosh(z))**2\n        term = -2 * tanh_z * sech_z_sq * (W1[:, 0]**2)\n        d2c_dx2 = term @ W2\n        return d2c_dx2.reshape(x.shape)\n\n    # --- Electrochemical functions ---\n    def butler_volmer(c_s):\n        R, T, F = params[\"R\"], params[\"T\"], params[\"F\"]\n        c_max, k_0 = params[\"c_max\"], params[\"k_0\"]\n        alpha_a, alpha_c = params[\"alpha_a\"], params[\"alpha_c\"]\n        E_app, U_ref, epsilon = params[\"E_app\"], params[\"U_ref\"], params[\"epsilon\"]\n\n        c_s_reg = np.maximum(epsilon, np.minimum(c_s, c_max - epsilon))\n        \n        # Exchange current density i_0\n        i_0 = k_0 * np.sqrt(c_s_reg * (c_max - c_s_reg))\n        \n        # Nernst potential U\n        U = U_ref + (R * T / F) * np.log(c_s_reg / (c_max - c_s_reg))\n        \n        # Overpotential eta\n        eta = E_app - U\n        \n        # BV equation\n        term_exp = F * eta / (R * T)\n        j_bv = i_0 * (np.exp(alpha_a * term_exp) - np.exp(-alpha_c * term_exp))\n        return j_bv\n\n    # --- Residual Calculations ---\n    L = params[\"L\"]\n    \n    # 1. PDE Loss\n    x_pde_grid, t_pde_grid = np.meshgrid(params[\"x_pde_rel\"] * L, params[\"t_pde\"])\n    dc_dt_vals = pinn_dc_dt(x_pde_grid, t_pde_grid)\n    d2c_dx2_vals = pinn_d2c_dx2(x_pde_grid, t_pde_grid)\n    r_pde = dc_dt_vals - params[\"D\"] * d2c_dx2_vals\n    loss_pde = np.mean(r_pde**2)\n    \n    # 2. Boundary Loss at x=0\n    x_bc0 = np.zeros_like(params[\"t_bc\"])\n    r_bc0 = pinn_dc_dx(x_bc0, params[\"t_bc\"])\n    loss_bc0 = np.mean(r_bc0**2)\n    \n    # 3. Boundary Loss at x=L\n    x_bcL = np.full_like(params[\"t_bc\"], L)\n    c_s_L = pinn_c(x_bcL, params[\"t_bc\"])\n    j_bv_vals = butler_volmer(c_s_L)\n    dc_dx_L = pinn_dc_dx(x_bcL, params[\"t_bc\"])\n    r_bcL = -params[\"D\"] * dc_dx_L - j_bv_vals / (params[\"n\"] * params[\"F\"])\n    loss_bcL = np.mean(r_bcL**2)\n    \n    # 4. Initial Condition Loss\n    t_ic = np.zeros_like(params[\"x_ic_rel\"])\n    c_ic = pinn_c(params[\"x_ic_rel\"] * L, t_ic)\n    r_ic = c_ic - params[\"c_0\"]\n    loss_ic = np.mean(r_ic**2)\n\n    # 5. Data Loss\n    if params[\"data_points\"].shape[0] > 0:\n        x_data = params[\"data_points\"][:, 0] * L\n        t_data = params[\"data_points\"][:, 1]\n        c_target = params[\"data_points\"][:, 2]\n        c_pred = pinn_c(x_data, t_data)\n        r_data = c_pred - c_target\n        loss_data = np.mean(r_data**2)\n    else:\n        loss_data = 0.0\n\n    # --- Composite Loss ---\n    lmb = params[\"lambdas\"]\n    total_loss = (lmb[\"pde\"] * loss_pde +\n                    lmb[\"bc0\"] * loss_bc0 +\n                    lmb[\"bcL\"] * loss_bcL +\n                    lmb[\"ic\"] * loss_ic +\n                    lmb[\"data\"] * loss_data)\n    \n    return total_loss\n\nif __name__ == \"__main__\":\n    solve()\n\n```"
        }
    ]
}