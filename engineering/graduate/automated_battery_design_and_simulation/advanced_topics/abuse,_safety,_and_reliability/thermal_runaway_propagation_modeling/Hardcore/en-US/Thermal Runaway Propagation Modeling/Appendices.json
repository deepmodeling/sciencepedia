{
    "hands_on_practices": [
        {
            "introduction": "A crucial first step in thermal modeling is deciding on the appropriate level of spatial detail. This exercise guides you through deriving the Biot number from first principles, providing a quantitative tool to justify the choice between a simple lumped-capacitance model and a more complex, spatially-resolved conduction model. Understanding this distinction is fundamental to building efficient and accurate simulations for battery thermal management .",
            "id": "3956756",
            "problem": "A lithium-ion pouch cell in a module is modeled during the early stage of thermal runaway propagation. The electrode stack can be idealized as a one-dimensional slab of thickness $L$ bounded on one face by a cold-plate coolant and on the opposite face by a thermally insulating backing (neighboring components provide negligible heat removal compared to the cold plate). The cold plate imposes convection characterized by a heat transfer coefficient $h$ to a fluid at temperature $T_{\\infty}$. Within the electrode stack, heat conducts in the through-thickness direction with an effective thermal conductivity $k$ that accounts for the layered composite of electrodes, separator, and current collectors. During a rapid exothermic event, internal volumetric heating may occur, but for the purpose of assessing the appropriateness of spatial lumping, focus on the competition between internal conduction across the thickness and external convection at the cooled face.\n\nStarting only from Fourier’s law of heat conduction and Newton’s law of convective cooling, construct a dimensionless group that compares the internal conduction resistance across the thickness to the external convective resistance at the cooled surface for this one-sided cooling configuration. Then evaluate this dimensionless group for the following parameters that are representative of a large-format pouch cell:\n- Electrode stack thickness $L = 3.75\\ \\mathrm{mm}$,\n- Through-thickness effective thermal conductivity $k = 0.30\\ \\mathrm{W\\,m^{-1}\\,K^{-1}}$,\n- Convective heat transfer coefficient at the cooled face $h = 500\\ \\mathrm{W\\,m^{-2}\\,K^{-1}}$.\n\nState, based on first principles and the meaning of your constructed dimensionless group, the physical criterion for when a lumped-capacitance thermal model is justified and when a layered conduction model is required in the electrode stack during thermal runaway propagation. Express your computed dimensionless number as a pure number and round your answer to four significant figures.",
            "solution": "The problem statement is evaluated to be scientifically grounded, well-posed, objective, and complete. It is based on fundamental principles of heat transfer (Fourier's law and Newton's law of cooling) applied to a realistic engineering scenario in battery thermal management. The given parameters are physically plausible and dimensionally consistent. The problem is therefore valid and a solution will be provided.\n\nThe objective is to derive a dimensionless group that compares the internal thermal resistance to conduction across the cell thickness with the external thermal resistance to convection at the cooled surface. This requires formulating expressions for these two resistances based on first principles.\n\nLet us consider a one-dimensional slab of thickness $L$ and cross-sectional area $A$. Heat flows in the through-thickness direction, which we define as the $x$-direction, from the insulated face at $x=0$ to the cooled face at $x=L$.\n\nThe internal thermal resistance due to conduction, $R_{\\text{cond}}$, is derived from Fourier's law of heat conduction. The law states that the heat flux, $q_x$, is proportional to the temperature gradient:\n$$q_x = -k \\frac{dT}{dx}$$\nwhere $k$ is the thermal conductivity. The total heat transfer rate, $Q$, across an area $A$ is $Q = q_x A$. For steady-state heat conduction across the slab of thickness $L$, we can approximate the temperature gradient as $\\frac{\\Delta T_{\\text{internal}}}{L}$, where $\\Delta T_{\\text{internal}}$ is the temperature difference between the insulated face and the cooled face. The heat transfer rate is then:\n$$Q \\approx kA \\frac{\\Delta T_{\\text{internal}}}{L}$$\nThermal resistance is defined as the ratio of the temperature difference driving heat flow to the heat flow rate itself. Therefore, the internal conduction resistance is:\n$$R_{\\text{cond}} = \\frac{\\Delta T_{\\text{internal}}}{Q} = \\frac{L}{kA}$$\nNote that in this one-sided cooling configuration, the full thickness $L$ represents the characteristic length for conduction.\n\nThe external thermal resistance due to convection, $R_{\\text{conv}}$, is derived from Newton's law of cooling. This law describes heat transfer from a solid surface at temperature $T_s$ to a surrounding fluid at temperature $T_{\\infty}$:\n$$Q = hA (T_s - T_{\\infty})$$\nwhere $h$ is the convective heat transfer coefficient and $\\Delta T_{\\text{external}} = T_s - T_{\\infty}$ is the temperature difference between the surface and the fluid. The external convective resistance is therefore:\n$$R_{\\text{conv}} = \\frac{\\Delta T_{\\text{external}}}{Q} = \\frac{1}{hA}$$\n\nThe problem asks for a dimensionless group that compares the internal conduction resistance to the external convective resistance. We construct this by taking their ratio:\n$$\\text{Dimensionless Group} = \\frac{R_{\\text{cond}}}{R_{\\text{conv}}} = \\frac{L/kA}{1/hA}$$\nThe area $A$ cancels, yielding the expression:\n$$\\text{Dimensionless Group} = \\frac{hL}{k}$$\nThis dimensionless group is known as the Biot number, denoted as $Bi$.\n\nThe physical significance of the Biot number, $Bi = \\frac{hL}{k}$, is that it represents the ratio of heat transfer resistance *inside* the body to the heat transfer resistance *at the surface* of the body.\n\nA lumped-capacitance thermal model is justified when the temperature gradients inside the body are negligible, meaning the body's temperature can be considered uniform throughout its volume at any given time. This condition occurs when the internal resistance to heat conduction is much smaller than the external resistance to heat convection ($R_{\\text{cond}} \\ll R_{\\text{conv}}$). If internal resistance is low, heat can redistribute itself within the body much faster than it is removed from the surface. In terms of the Biot number, this criterion is expressed as:\n$$Bi = \\frac{hL}{k} \\ll 1$$\nIn engineering practice, a lumped-capacitance model is typically considered appropriate for $Bi  0.1$. For values of $Bi$ that are not small (e.g., $Bi  0.1$), the temperature gradients inside the body are significant. This means that a layered conduction model (i.e., solving the partial differential heat equation) is required to accurately capture the spatial temperature distribution within the electrode stack.\n\nNow, we evaluate this dimensionless group for the given parameters:\n- Electrode stack thickness $L = 3.75\\ \\mathrm{mm} = 3.75 \\times 10^{-3}\\ \\mathrm{m}$\n- Through-thickness effective thermal conductivity $k = 0.30\\ \\mathrm{W\\,m^{-1}\\,K^{-1}}$\n- Convective heat transfer coefficient $h = 500\\ \\mathrm{W\\,m^{-2}\\,K^{-1}}$\n\nSubstituting these values into the expression for the Biot number:\n$$Bi = \\frac{hL}{k} = \\frac{(500\\ \\mathrm{W\\,m^{-2}\\,K^{-1}}) \\times (3.75 \\times 10^{-3}\\ \\mathrm{m})}{0.30\\ \\mathrm{W\\,m^{-1}\\,K^{-1}}}$$\n$$Bi = \\frac{1.875\\ \\mathrm{W\\,m^{-1}\\,K^{-1}}}{0.30\\ \\mathrm{W\\,m^{-1}\\,K^{-1}}}$$\n$$Bi = 6.25$$\nThe problem requires the answer to be rounded to four significant figures.\n$$Bi = 6.250$$\nSince $Bi = 6.250$, which is significantly greater than $0.1$, the internal conduction resistance is more than $6$ times larger than the external convective resistance. This implies that substantial temperature gradients will develop across the thickness of the electrode stack. Therefore, a lumped-capacitance model would be highly inaccurate for this scenario, and a layered conduction model is necessary.",
            "answer": "$$\\boxed{6.250}$$"
        },
        {
            "introduction": "Once a modeling approach is selected, a key task is to analyze the system's stability and dynamic behavior. This practice delves into the linear stability analysis of a lumped-parameter thermal model to derive a characteristic time scale for thermal runaway. Calculating this time scale provides critical insight into the speed of an exothermic event, which directly informs the response time requirements for safety sensors and control systems .",
            "id": "3956764",
            "problem": "A single lithium-ion cell in a pack is modeled as a spatially lumped thermal mass with temperature $T(t)$. The first-principles energy balance is\n$m c_{p} \\,\\frac{dT}{dt} = \\dot{Q}_{\\text{rxn}}(T) - h A \\left(T - T_{\\text{amb}}\\right)$,\nwhere $m$ is the cell mass, $c_{p}$ is the isobaric heat capacity, $\\dot{Q}_{\\text{rxn}}(T)$ is the thermally activated exothermic heat-generation rate from decomposition reactions, $h$ is the effective convective heat transfer coefficient to the cooling stream, $A$ is the external heat transfer area, and $T_{\\text{amb}}$ is the ambient temperature. Assume there exists a steady state at $T^{\\ast}$ satisfying $\\dot{Q}_{\\text{rxn}}(T^{\\ast}) = h A \\left(T^{\\ast} - T_{\\text{amb}}\\right)$. The reaction heat rate is Arrhenius-activated, with $\\dot{Q}_{\\text{rxn}}(T) = Q_{0}\\,\\exp\\!\\left(-\\frac{E}{R\\,T}\\right)$, where $Q_{0}$ is a pre-exponential factor, $E$ is the activation energy, and $R$ is the universal gas constant.\n\nUsing only the energy balance and the Arrhenius form, perform a first-order linearization about $T^{\\ast}$ to obtain a scalar linear ordinary differential equation for the perturbation $\\theta(t) \\equiv T(t)-T^{\\ast}$ of the form $\\frac{d\\theta}{dt} = \\lambda\\,\\theta$, and from it identify the characteristic time scale $\\tau \\equiv \\lambda^{-1}$ in terms of fundamental quantities evaluated at $T^{\\ast}$. Then, using the data below, compute the numerical value of $\\tau$.\n\nGiven data:\n- $m = 0.070$ kg, $c_{p} = 1000$ J kg$^{-1}$ K$^{-1}$, so that $m c_{p}$ is finite and positive.\n- $h = 8.0$ W m$^{-2}$ K$^{-1}$ and $A = 0.010$ m$^{2}$.\n- $T_{\\text{amb}} = 300$ K and $T^{\\ast} = 500$ K.\n- $E = 1.10 \\times 10^{5}$ J mol$^{-1}$ and $R = 8.314$ J mol$^{-1}$ K$^{-1}$.\n- The steady exothermic heat release at $T^{\\ast}$ is $\\dot{Q}_{\\text{rxn}}(T^{\\ast}) = 50.0$ W.\n\nInstructions:\n1. Derive symbolically the linearized growth rate $\\lambda$ from first principles, clearly indicating how the quantities at $T^{\\ast}$ enter.\n2. Evaluate $\\frac{\\partial \\dot{Q}_{\\text{rxn}}}{\\partial T}\\big|_{T^{\\ast}}$ using the Arrhenius form and the given data.\n3. Compute the characteristic time scale $\\tau \\equiv \\lambda^{-1}$ and express your final result in seconds. Round your answer to three significant figures.\nYour final answer must be a single number (no units in the final boxed answer). In your derivation, state any assumptions you make and justify each step from the given base equations.",
            "solution": "The problem is first validated against the specified criteria.\n\n**Step 1: Extract Givens**\n- Governing ordinary differential equation: $m c_{p} \\,\\frac{dT}{dt} = \\dot{Q}_{\\text{rxn}}(T) - h A \\left(T - T_{\\text{amb}}\\right)$.\n- Heat-generation rate: $\\dot{Q}_{\\text{rxn}}(T) = Q_{0}\\,\\exp\\!\\left(-\\frac{E}{R\\,T}\\right)$.\n- Steady-state condition: $\\dot{Q}_{\\text{rxn}}(T^{\\ast}) = h A \\left(T^{\\ast} - T_{\\text{amb}}\\right)$ at a steady-state temperature $T^{\\ast}$.\n- Perturbation variable: $\\theta(t) \\equiv T(t)-T^{\\ast}$.\n- Desired linearized form: $\\frac{d\\theta}{dt} = \\lambda\\,\\theta$.\n- Definition of characteristic time scale: $\\tau \\equiv \\lambda^{-1}$.\n- Data:\n  - $m = 0.070$ kg\n  - $c_{p} = 1000$ J kg$^{-1}$ K$^{-1}$\n  - $h = 8.0$ W m$^{-2}$ K$^{-1}$\n  - $A = 0.010$ m$^{2}$\n  - $T_{\\text{amb}} = 300$ K\n  - $T^{\\ast} = 500$ K\n  - $E = 1.10 \\times 10^{5}$ J mol$^{-1}$\n  - $R = 8.314$ J mol$^{-1}$ K$^{-1}$\n  - $\\dot{Q}_{\\text{rxn}}(T^{\\ast}) = 50.0$ W\n\n**Step 2: Validate Using Extracted Givens**\nThe problem is deemed valid based on the following analysis:\n- **Scientifically Grounded**: The problem describes a lumped-parameter thermal model, which is a standard and valid simplification in heat transfer and chemical engineering. The energy balance equation is a direct application of the first law of thermodynamics. The use of an Arrhenius rate law for the reaction term is a fundamental principle of chemical kinetics. The method of linear stability analysis is a standard mathematical technique for analyzing the behavior of systems near a steady state.\n- **Well-Posed**: The problem is well-posed. It provides a clear governing equation, all necessary parameters and boundary conditions, and a specific set of tasks (derivation and calculation). The information is sufficient to determine a unique solution for the characteristic time scale $\\tau$.\n- **Objective**: The problem is stated using precise, objective scientific language. It is free of ambiguity, subjective claims, or opinion-based statements.\n- **Consistency**: All provided data are dimensionally consistent and physically plausible for the system being modeled (a lithium-ion cell). The steady-state condition is explicitly given and is consistent with the governing equation.\n\n**Step 3: Verdict and Action**\nThe problem is valid. The solution will now be derived.\n\nThe derivation begins with the given energy balance for the cell temperature $T(t)$:\n$$m c_{p} \\,\\frac{dT}{dt} = \\dot{Q}_{\\text{rxn}}(T) - h A \\left(T - T_{\\text{amb}}\\right)$$\nWe are asked to analyze the stability of the system around a steady-state temperature $T^{\\ast}$. At this steady state, the temperature is constant, so $\\frac{dT}{dt} = 0$. The governing equation at steady state is:\n$$0 = \\dot{Q}_{\\text{rxn}}(T^{\\ast}) - h A \\left(T^{\\ast} - T_{\\text{amb}}\\right)$$\nThis is consistent with the provided steady-state condition.\n\nTo perform a linear stability analysis, we introduce a small perturbation $\\theta(t)$ to the steady-state temperature:\n$$T(t) = T^{\\ast} + \\theta(t)$$\nDifferentiating with respect to time, and noting that $T^{\\ast}$ is a constant, we get:\n$$\\frac{dT}{dt} = \\frac{d\\theta}{dt}$$\nSubstituting these into the original energy balance gives:\n$$m c_{p} \\frac{d\\theta}{dt} = \\dot{Q}_{\\text{rxn}}(T^{\\ast} + \\theta) - h A \\left((T^{\\ast} + \\theta) - T_{\\text{amb}}\\right)$$\nWe can rearrange the right-hand side (RHS) as:\n$$\\text{RHS} = \\dot{Q}_{\\text{rxn}}(T^{\\ast} + \\theta) - h A \\left(T^{\\ast} - T_{\\text{amb}}\\right) - h A \\theta$$\nUsing the steady-state condition $\\dot{Q}_{\\text{rxn}}(T^{\\ast}) = h A (T^{\\ast} - T_{\\text{amb}})$, we can make a substitution, but it is more direct to linearize the entire RHS. Let $F(T) = \\dot{Q}_{\\text{rxn}}(T) - h A (T - T_{\\text{amb}})$. We perform a first-order Taylor series expansion of $F(T)$ around $T = T^{\\ast}$:\n$$F(T) \\approx F(T^{\\ast}) + \\frac{dF}{dT}\\bigg|_{T^{\\ast}} (T - T^{\\ast})$$\nFrom the steady-state definition, $F(T^{\\ast})=0$. The derivative is:\n$$\\frac{dF}{dT} = \\frac{d}{dT} \\left[ \\dot{Q}_{\\text{rxn}}(T) - h A (T - T_{\\text{amb}}) \\right] = \\frac{d\\dot{Q}_{\\text{rxn}}}{dT} - h A$$\nEvaluating at $T^{\\ast}$:\n$$\\frac{dF}{dT}\\bigg|_{T^{\\ast}} = \\frac{d\\dot{Q}_{\\text{rxn}}}{dT}\\bigg|_{T^{\\ast}} - h A$$\nSubstituting these back into the expansion for $F(T) = F(T^{\\ast}+\\theta)$:\n$$F(T^{\\ast}+\\theta) \\approx 0 + \\left( \\frac{d\\dot{Q}_{\\text{rxn}}}{dT}\\bigg|_{T^{\\ast}} - h A \\right) \\theta$$\nThe assumption made here is that the perturbation $\\theta$ is small enough for this first-order approximation to be accurate. The linearized differential equation for $\\theta(t)$ is therefore:\n$$m c_{p} \\frac{d\\theta}{dt} = \\left( \\frac{d\\dot{Q}_{\\text{rxn}}}{dT}\\bigg|_{T^{\\ast}} - h A \\right) \\theta$$\nTo match the requested form $\\frac{d\\theta}{dt} = \\lambda \\theta$, we divide by the thermal mass $m c_{p}$:\n$$\\frac{d\\theta}{dt} = \\frac{1}{m c_{p}} \\left( \\frac{d\\dot{Q}_{\\text{rxn}}}{dT}\\bigg|_{T^{\\ast}} - h A \\right) \\theta$$\nFrom this, we identify the linearized growth rate $\\lambda$:\n$$\\lambda = \\frac{1}{m c_{p}} \\left( \\frac{d\\dot{Q}_{\\text{rxn}}}{dT}\\bigg|_{T^{\\ast}} - h A \\right)$$\n\nNext, we evaluate the derivative of the heat generation rate using the Arrhenius form $\\dot{Q}_{\\text{rxn}}(T) = Q_{0} \\exp\\left(-\\frac{E}{RT}\\right)$. Using the chain rule:\n$$\\frac{d\\dot{Q}_{\\text{rxn}}}{dT} = Q_{0} \\cdot \\exp\\left(-\\frac{E}{RT}\\right) \\cdot \\frac{d}{dT}\\left(-\\frac{E}{RT}\\right)$$\n$$\\frac{d\\dot{Q}_{\\text{rxn}}}{dT} = Q_{0} \\exp\\left(-\\frac{E}{RT}\\right) \\cdot \\left(\\frac{E}{RT^2}\\right)$$\nWe can recognize the term $Q_{0} \\exp\\left(-\\frac{E}{RT}\\right)$ as $\\dot{Q}_{\\text{rxn}}(T)$ itself. So, we can write:\n$$\\frac{d\\dot{Q}_{\\text{rxn}}}{dT} = \\dot{Q}_{\\text{rxn}}(T) \\frac{E}{RT^2}$$\nEvaluating this at the steady-state temperature $T^{\\ast}$ gives:\n$$\\frac{d\\dot{Q}_{\\text{rxn}}}{dT}\\bigg|_{T^{\\ast}} = \\dot{Q}_{\\text{rxn}}(T^{\\ast}) \\frac{E}{R(T^{\\ast})^2}$$\nThis completes the symbolic derivation. Now we compute the numerical values.\n\nFirst, we calculate the value of the derivative term (Instruction 2):\n$$\\frac{d\\dot{Q}_{\\text{rxn}}}{dT}\\bigg|_{T^{\\ast}} = (50.0 \\, \\text{W}) \\frac{1.10 \\times 10^5 \\, \\text{J mol}^{-1}}{(8.314 \\, \\text{J mol}^{-1} \\text{K}^{-1})(500 \\, \\text{K})^2} = \\frac{50.0 \\times 1.10 \\times 10^5}{8.314 \\times 250000} \\, \\text{W K}^{-1}$$\n$$\\frac{d\\dot{Q}_{\\text{rxn}}}{dT}\\bigg|_{T^{\\ast}} = \\frac{5.5 \\times 10^6}{2.0785 \\times 10^6} \\, \\text{W K}^{-1} \\approx 2.64614 \\, \\text{W K}^{-1}$$\n\nNext, we compute the other terms needed for $\\lambda$:\n- Thermal mass term: $m c_{p} = (0.070 \\, \\text{kg}) \\times (1000 \\, \\text{J kg}^{-1} \\text{K}^{-1}) = 70 \\, \\text{J K}^{-1}$.\n- Heat loss term: $h A = (8.0 \\, \\text{W m}^{-2} \\text{K}^{-1}) \\times (0.010 \\, \\text{m}^2) = 0.080 \\, \\text{W K}^{-1}$.\n\nNow we can compute $\\lambda$:\n$$\\lambda = \\frac{1}{70 \\, \\text{J K}^{-1}} \\left( 2.64614 \\, \\text{W K}^{-1} - 0.080 \\, \\text{W K}^{-1} \\right)$$\n$$\\lambda = \\frac{2.56614 \\, \\text{W K}^{-1}}{70 \\, \\text{J K}^{-1}} = \\frac{2.56614 \\, (\\text{J s}^{-1}) \\text{K}^{-1}}{70 \\, \\text{J K}^{-1}} \\approx 0.036659 \\, \\text{s}^{-1}$$\n\nFinally, we compute the characteristic time scale $\\tau = \\lambda^{-1}$ (Instruction 3):\n$$\\tau = \\frac{1}{\\lambda} \\approx \\frac{1}{0.036659 \\, \\text{s}^{-1}} \\approx 27.278 \\, \\text{s}$$\nRounding the result to three significant figures, as requested:\n$$\\tau \\approx 27.3 \\, \\text{s}$$",
            "answer": "$$\\boxed{27.3}$$"
        },
        {
            "introduction": "The predictive power of any thermal runaway model depends on the accuracy of its parameters, such as the activation energy $E_a$ for exothermic reactions. This practice provides a hands-on exercise in parameter estimation, guiding you through the formulation of a Bayesian inference problem to determine Arrhenius parameters from noisy experimental data. Mastering this technique is essential for creating models that are well-grounded in physical measurements and for quantifying the uncertainty in your predictions .",
            "id": "3956820",
            "problem": "Consider the automated battery design and simulation task of parameter inference for thermal runaway propagation modeling. In many established models, the dominant exothermic reaction heat-release rate of a single cell in the pre-propagation regime is captured by an Arrhenius-type relation. Let the measured heat generation rate at absolute temperature $T$ be modeled as $q(T) = A \\exp\\!\\left(-\\frac{E_a}{R T}\\right)$, where $A$ is the pre-exponential factor in watts and $E_a$ is the activation energy in joules per mole. Assume the measurement process is affected by multiplicative noise that is log-normal with independent Gaussian logarithmic errors. Specifically, define observed data $\\{(T_i, y_i)\\}_{i=1}^n$ with the logarithmic measurement model\n$$\n\\ln y_i = \\ln A - \\frac{E_a}{R\\,T_i} + \\varepsilon_i,\n$$\nwhere $R$ is the universal gas constant and $\\varepsilon_i \\sim \\mathcal{N}(0,\\sigma^2)$ are independent and identically distributed. Suppose independent Gaussian priors are placed on $E_a$ and $\\ln A$,\n$$\nE_a \\sim \\mathcal{N}(\\mu_E, \\sigma_E^2), \\quad \\ln A \\sim \\mathcal{N}(\\mu_A, \\sigma_A^2),\n$$\nwith no correlation between $E_a$ and $\\ln A$ a priori.\n\nStarting from these assumptions and only the fundamental base above (Arrhenius relation and Gaussian noise), reformulate the inference in the linear-Gaussian regression form by an appropriate reparameterization of the slope associated with $1/T$. Then, derive the likelihood from the Gaussian noise model, derive the Gaussian posterior for the linear parameters using Bayes' rule, and map that posterior back to the activation energy $E_a$ to obtain its posterior mean and variance in closed form. Your program must compute the posterior mean and posterior variance of $E_a$ for each test case below and produce the final outputs as specified.\n\nConstants and units:\n- Use $R = 8.314$ joules per mole per kelvin.\n- All temperatures $T_i$ are given in kelvin.\n- All heat rates $y_i$ are given in watts.\n- Report posterior means of $E_a$ in joules per mole and posterior variances in $(\\text{joules per mole})^2$.\n\nTest suite (each case is $(\\{T_i\\}, \\{y_i\\}, \\sigma, \\mu_A, \\sigma_A^2, \\mu_E, \\sigma_E^2)$):\n\n1. General case (moderate noise, informative priors):\n   - Temperatures: $[500.0, 520.0, 540.0, 560.0, 580.0]$.\n   - Measured heat rates: $[1.733, 4.129, 12.91, 26.33, 62.0]$.\n   - Noise standard deviation: $\\sigma = 0.15$.\n   - Prior for $\\ln A$: mean $\\mu_A = 26.937$, variance $\\sigma_A^2 = 0.25$.\n   - Prior for $E_a$: mean $\\mu_E = 110000.0$, variance $\\sigma_E^2 = 10000.0^2$.\n\n2. Boundary case (near-zero noise, weakly informative priors):\n   - Temperatures: $[500.0, 520.0, 540.0, 560.0, 580.0]$.\n   - Measured heat rates: $[1.65, 4.47, 11.45, 27.4, 62.0]$.\n   - Noise standard deviation: $\\sigma = 1.0\\times 10^{-6}$.\n   - Prior for $\\ln A$: mean $\\mu_A = 26.937$, variance $\\sigma_A^2 = 1.0$.\n   - Prior for $E_a$: mean $\\mu_E = 110000.0$, variance $\\sigma_E^2 = 20000.0^2$.\n\n3. High-noise case (data highly perturbed):\n   - Temperatures: $[500.0, 520.0, 540.0, 560.0, 580.0]$.\n   - Measured heat rates: $[2.720, 2.999, 13.99, 20.31, 68.52]$.\n   - Noise standard deviation: $\\sigma = 0.5$.\n   - Prior for $\\ln A$: mean $\\mu_A = 26.937$, variance $\\sigma_A^2 = 0.25$.\n   - Prior for $E_a$: mean $\\mu_E = 110000.0$, variance $\\sigma_E^2 = 10000.0^2$.\n\n4. Edge case (minimal data points):\n   - Temperatures: $[520.0, 580.0]$.\n   - Measured heat rates: $[4.60, 60.77]$.\n   - Noise standard deviation: $\\sigma = 0.15$.\n   - Prior for $\\ln A$: mean $\\mu_A = 26.937$, variance $\\sigma_A^2 = 0.25$.\n   - Prior for $E_a$: mean $\\mu_E = 110000.0$, variance $\\sigma_E^2 = 10000.0^2$.\n\n5. Prior-mismatch case (strongly biased priors):\n   - Temperatures: $[500.0, 520.0, 540.0, 560.0, 580.0]$.\n   - Measured heat rates: $[1.733, 4.129, 12.91, 26.33, 62.0]$.\n   - Noise standard deviation: $\\sigma = 0.15$.\n   - Prior for $\\ln A$: mean $\\mu_A = 24.0, variance $\\sigma_A^2 = 0.04$.\n   - Prior for $E_a$: mean $\\mu_E = 80000.0, variance $\\sigma_E^2 = 5000.0^2$.\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, in the order of test cases. For each test case, append the posterior mean of $E_a$ (in joules per mole) followed immediately by the posterior variance of $E_a$ (in $(\\text{joules per mole})^2$). For example, the final output should look like $[m_1,v_1,m_2,v_2,m_3,v_3,m_4,v_4,m_5,v_5]$ where $m_k$ and $v_k$ are floats.",
            "solution": "The problem requires the derivation and computation of the posterior mean and variance for the activation energy $E_a$ within a Bayesian framework. The physical model is the Arrhenius relation for heat generation, and the statistical model assumes log-normal multiplicative noise on the measurements. The derivation proceeds in four principal steps: reformulating the problem as a standard Bayesian linear regression, deriving the prior distributions for the linear model parameters, applying Bayes' theorem to find the posterior distribution of the linear parameters, and finally transforming this posterior back to obtain the desired statistics for $E_a$.\n\n### Step 1: Reformulation as a Linear-Gaussian Model\n\nThe given measurement model is:\n$$\n\\ln y_i = \\ln A - \\frac{E_a}{R\\,T_i} + \\varepsilon_i\n$$\nwhere $\\varepsilon_i \\sim \\mathcal{N}(0, \\sigma^2)$ are independent and identically distributed noise terms. This equation is already in the form of a linear model. To align with standard regression notation, we perform a reparameterization. Let $z_i = \\ln y_i$ be the response variable and $x_i = 1/T_i$ be the predictor variable. We define the linear parameters $\\beta_0$ and $\\beta_1$ as:\n$$\n\\beta_0 = \\ln A \\quad \\text{and} \\quad \\beta_1 = -\\frac{E_a}{R}\n$$\nWith these definitions, the measurement model for a single observation $i$ becomes:\n$$\nz_i = \\beta_0 + \\beta_1 x_i + \\varepsilon_i\n$$\nFor the full dataset of $n$ observations $\\{(T_i, y_i)\\}_{i=1}^n$, we can express this in matrix form:\n$$\n\\mathbf{z} = \\mathbf{X}\\boldsymbol{\\beta} + \\boldsymbol{\\varepsilon}\n$$\nwhere:\n- $\\mathbf{z} = [\\ln y_1, \\ln y_2, \\dots, \\ln y_n]^T$ is the $n \\times 1$ vector of observed log-heat-rates.\n- $\\boldsymbol{\\beta} = [\\beta_0, \\beta_1]^T$ is the $2 \\times 1$ vector of unknown parameters.\n- $\\mathbf{X}$ is the $n \\times 2$ design matrix, where the $i$-th row is $[1, x_i] = [1, 1/T_i]$.\n$$\n\\mathbf{X} = \\begin{pmatrix}\n1  1/T_1 \\\\\n1  1/T_2 \\\\\n\\vdots  \\vdots \\\\\n1  1/T_n\n\\end{pmatrix}\n$$\n- $\\boldsymbol{\\varepsilon} = [\\varepsilon_1, \\varepsilon_2, \\dots, \\varepsilon_n]^T$ is the $n \\times 1$ vector of noise terms, with the distribution $\\boldsymbol{\\varepsilon} \\sim \\mathcal{N}(\\mathbf{0}, \\sigma^2 \\mathbf{I}_n)$, where $\\mathbf{I}_n$ is the $n \\times n$ identity matrix.\n\nFrom this formulation, the likelihood of the data $\\mathbf{z}$ given the parameters $\\boldsymbol{\\beta}$ is a multivariate Gaussian distribution:\n$$\np(\\mathbf{z} | \\boldsymbol{\\beta}, \\sigma^2) = \\mathcal{N}(\\mathbf{z} | \\mathbf{X}\\boldsymbol{\\beta}, \\sigma^2 \\mathbf{I}_n) \\propto \\exp\\left(-\\frac{1}{2\\sigma^2} (\\mathbf{z} - \\mathbf{X}\\boldsymbol{\\beta})^T (\\mathbf{z} - \\mathbf{X}\\boldsymbol{\\beta})\\right)\n$$\n\n### Step 2: Derivation of the Prior Distribution\n\nThe problem specifies independent Gaussian priors on the original physical parameters, $\\ln A$ and $E_a$:\n$$\n\\ln A \\sim \\mathcal{N}(\\mu_A, \\sigma_A^2) \\quad \\text{and} \\quad E_a \\sim \\mathcal{N}(\\mu_E, \\sigma_E^2)\n$$\nWe must transform these into a prior for our linear parameter vector $\\boldsymbol{\\beta} = [\\beta_0, \\beta_1]^T$.\nThe prior for $\\beta_0 = \\ln A$ is given directly:\n$$\np(\\beta_0) = \\mathcal{N}(\\beta_0 | \\mu_A, \\sigma_A^2)\n$$\nFor $\\beta_1 = -E_a/R$, we use the properties of linear transformations of Gaussian random variables. The mean and variance of $\\beta_1$ are:\n$$\n\\mathbb{E}[\\beta_1] = \\mathbb{E}[-E_a/R] = -\\frac{1}{R}\\mathbb{E}[E_a] = -\\frac{\\mu_E}{R}\n$$\n$$\n\\text{Var}(\\beta_1) = \\text{Var}(-E_a/R) = \\left(-\\frac{1}{R}\\right)^2 \\text{Var}(E_a) = \\frac{\\sigma_E^2}{R^2}\n$$\nSo, the prior for $\\beta_1$ is:\n$$\np(\\beta_1) = \\mathcal{N}\\left(\\beta_1 \\Big| -\\frac{\\mu_E}{R}, \\frac{\\sigma_E^2}{R^2}\\right)\n$$\nSince $\\ln A$ and $E_a$ are a priori independent, $\\beta_0$ and $\\beta_1$ are also a priori independent. The joint prior distribution for $\\boldsymbol{\\beta}$ is a multivariate Gaussian $p(\\boldsymbol{\\beta}) = \\mathcal{N}(\\boldsymbol{\\beta} | \\boldsymbol{\\mu}_0, \\boldsymbol{\\Sigma}_0)$ with mean vector $\\boldsymbol{\\mu}_0$ and covariance matrix $\\boldsymbol{\\Sigma}_0$:\n$$\n\\boldsymbol{\\mu}_0 = \\begin{pmatrix} \\mu_A \\\\ -\\mu_E/R \\end{pmatrix}, \\quad \\boldsymbol{\\Sigma}_0 = \\begin{pmatrix} \\sigma_A^2  0 \\\\ 0  \\sigma_E^2/R^2 \\end{pmatrix}\n$$\n\n### Step 3: Derivation of the Posterior Distribution\n\nWe use Bayes' rule to find the posterior distribution of $\\boldsymbol{\\beta}$:\n$$\np(\\boldsymbol{\\beta} | \\mathbf{z}) \\propto p(\\mathbf{z} | \\boldsymbol{\\beta}) p(\\boldsymbol{\\beta})\n$$\nSince the likelihood and the prior are both Gaussian, the posterior will also be a Gaussian, i.e., $p(\\boldsymbol{\\beta} | \\mathbf{z}) = \\mathcal{N}(\\boldsymbol{\\beta} | \\boldsymbol{\\mu}_n, \\boldsymbol{\\Sigma}_n)$. This is a standard result for Bayesian linear regression with a conjugate prior. The posterior covariance matrix $\\boldsymbol{\\Sigma}_n$ and posterior mean vector $\\boldsymbol{\\mu}_n$ are given by:\n$$\n\\boldsymbol{\\Sigma}_n = \\left(\\boldsymbol{\\Sigma}_0^{-1} + \\frac{1}{\\sigma^2}\\mathbf{X}^T\\mathbf{X}\\right)^{-1}\n$$\n$$\n\\boldsymbol{\\mu}_n = \\boldsymbol{\\Sigma}_n \\left(\\boldsymbol{\\Sigma}_0^{-1}\\boldsymbol{\\mu}_0 + \\frac{1}{\\sigma^2}\\mathbf{X}^T\\mathbf{z}\\right)\n$$\nwhere the prior precision matrix $\\boldsymbol{\\Sigma}_0^{-1}$ is:\n$$\n\\boldsymbol{\\Sigma}_0^{-1} = \\begin{pmatrix} 1/\\sigma_A^2  0 \\\\ 0  R^2/\\sigma_E^2 \\end{pmatrix}\n$$\nThese equations provide a closed-form solution for the posterior distribution of the linear parameters $\\beta_0$ and $\\beta_1$.\n\n### Step 4: Mapping the Posterior to $E_a$\n\nThe final step is to find the posterior mean and variance of the original parameter of interest, $E_a$. We use the relationship $E_a = -R\\beta_1$. The posterior distribution for $\\boldsymbol{\\beta}$ is a multivariate Gaussian. This implies that the marginal distribution for any single component, such as $\\beta_1$, is also Gaussian. From the posterior $\\mathcal{N}(\\boldsymbol{\\beta} | \\boldsymbol{\\mu}_n, \\boldsymbol{\\Sigma}_n)$, the marginal distribution for $\\beta_1$ is:\n$$\np(\\beta_1 | \\mathbf{z}) = \\mathcal{N}(\\beta_1 | \\mu_{n,1}, \\Sigma_{n,11})\n$$\nwhere $\\mu_{n,1}$ is the second element of $\\boldsymbol{\\mu}_n$, and $\\Sigma_{n,11}$ is the second diagonal element (at index $(1,1)$) of $\\boldsymbol{\\Sigma}_n$.\n\nUsing the linear transformation $E_a = -R\\beta_1$, we can find the posterior mean and variance of $E_a$:\n-   **Posterior Mean of $E_a$**:\n    $$\n    \\mathbb{E}[E_a | \\mathbf{z}] = \\mathbb{E}[-R\\beta_1 | \\mathbf{z}] = -R \\cdot \\mathbb{E}[\\beta_1| \\mathbf{z}] = -R \\cdot \\mu_{n,1}\n    $$\n-   **Posterior Variance of $E_a$**:\n    $$\n    \\text{Var}(E_a | \\mathbf{z}) = \\text{Var}(-R\\beta_1 | \\mathbf{z}) = (-R)^2 \\cdot \\text{Var}(\\beta_1| \\mathbf{z}) = R^2 \\cdot \\Sigma_{n,11}\n    $$\nThese formulas allow for the direct computation of the required quantities for each test case. The algorithm implemented in the provided code directly follows these derived expressions.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef compute_posterior(T_data, y_data, sigma, mu_A, sigma_A2, mu_E, sigma_E2):\n    \"\"\"\n    Computes the posterior mean and variance of the activation energy Ea.\n\n    Args:\n        T_data (list): List of temperatures in Kelvin.\n        y_data (list): List of measured heat rates in Watts.\n        sigma (float): Standard deviation of the logarithmic measurement noise.\n        mu_A (float): Prior mean of ln(A).\n        sigma_A2 (float): Prior variance of ln(A).\n        mu_E (float): Prior mean of Ea.\n        sigma_E2 (float): Prior variance of Ea.\n\n    Returns:\n        tuple: A tuple containing the posterior mean of Ea and posterior variance of Ea.\n    \"\"\"\n    R = 8.314  # Universal gas constant in J/(mol·K)\n\n    # Convert data lists to numpy arrays for vectorized operations\n    T = np.array(T_data, dtype=np.float64)\n    y = np.array(y_data, dtype=np.float64)\n    n = len(T)\n\n    # Step 1: Reformulate as a linear model z = X*beta + epsilon\n    # z = ln(y), x = 1/T\n    # beta = [beta_0, beta_1]^T = [ln(A), -Ea/R]^T\n    z = np.log(y)\n    x = 1.0 / T\n\n    # Construct the design matrix X\n    X = np.ones((n, 2), dtype=np.float64)\n    X[:, 1] = x\n\n    # Step 2: Define the prior distribution for beta\n    # Prior mean for beta\n    mu_0 = np.array([mu_A, -mu_E / R], dtype=np.float64)\n\n    # Prior covariance and precision for beta\n    Sigma_0 = np.array([[sigma_A2, 0.0], [0.0, sigma_E2 / (R**2)]], dtype=np.float64)\n    # Check for non-invertible prior covariance (e.g., zero variance)\n    if np.abs(np.linalg.det(Sigma_0))  1e-30:\n        # Use pseudo-inverse for stability, although not expected here\n        Sigma_0_inv = np.linalg.pinv(Sigma_0)\n    else:\n        Sigma_0_inv = np.linalg.inv(Sigma_0)\n\n    # Step 3: Compute the posterior distribution N(mu_n, Sigma_n) for beta\n    # Precision of the likelihood\n    lambda_lik = 1.0 / (sigma**2)\n\n    # Posterior precision matrix\n    # Sigma_n_inv = Sigma_0_inv + (1/sigma^2) * X^T * X\n    XTX = X.T @ X\n    Sigma_n_inv = Sigma_0_inv + lambda_lik * XTX\n\n    # Posterior covariance matrix\n    Sigma_n = np.linalg.inv(Sigma_n_inv)\n\n    # Posterior mean vector\n    # mu_n = Sigma_n * (Sigma_0_inv * mu_0 + (1/sigma^2) * X^T * z)\n    XTz = X.T @ z\n    mu_n = Sigma_n @ (Sigma_0_inv @ mu_0 + lambda_lik * XTz)\n\n    # Step 4: Map the posterior of beta back to the posterior of Ea\n    # The posterior for beta_1 is Gaussian with mean mu_n[1] and variance Sigma_n[1, 1].\n    # Ea = -R * beta_1\n    mu_n_beta1 = mu_n[1]\n    Sigma_n_beta1_var = Sigma_n[1, 1]\n\n    # Posterior mean of Ea\n    Ea_posterior_mean = -R * mu_n_beta1\n    \n    # Posterior variance of Ea\n    Ea_posterior_variance = (R**2) * Sigma_n_beta1_var\n\n    return Ea_posterior_mean, Ea_posterior_variance\n\ndef solve():\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # 1. General case\n        (\n            [500.0, 520.0, 540.0, 560.0, 580.0],\n            [1.733, 4.129, 12.91, 26.33, 62.0],\n            0.15, 26.937, 0.25, 110000.0, 10000.0**2\n        ),\n        # 2. Boundary case (near-zero noise)\n        (\n            [500.0, 520.0, 540.0, 560.0, 580.0],\n            [1.65, 4.47, 11.45, 27.4, 62.0],\n            1.0e-6, 26.937, 1.0, 110000.0, 20000.0**2\n        ),\n        # 3. High-noise case\n        (\n            [500.0, 520.0, 540.0, 560.0, 580.0],\n            [2.720, 2.999, 13.99, 20.31, 68.52],\n            0.5, 26.937, 0.25, 110000.0, 10000.0**2\n        ),\n        # 4. Edge case (minimal data)\n        (\n            [520.0, 580.0],\n            [4.60, 60.77],\n            0.15, 26.937, 0.25, 110000.0, 10000.0**2\n        ),\n        # 5. Prior-mismatch case\n        (\n            [500.0, 520.0, 540.0, 560.0, 580.0],\n            [1.733, 4.129, 12.91, 26.33, 62.0],\n            0.15, 24.0, 0.04, 80000.0, 5000.0**2\n        ),\n    ]\n\n    results = []\n    for case in test_cases:\n        # Unpack the case tuple and call the computation function\n        mean, variance = compute_posterior(*case)\n        # Append results to the list\n        results.append(mean)\n        results.append(variance)\n\n    # Final print statement in the exact required format.\n    # Format each number to a reasonable number of decimal places for consistency\n    formatted_results = [f\"{r:.8f}\" for r in results]\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```"
        }
    ]
}