{
    "hands_on_practices": [
        {
            "introduction": "The first step in any validation process is to define what \"good\" performance means. Since no model is perfect, we require quantitative metrics to assess its fidelity against ground-truth data. Different metrics are sensitive to different types of errors, and understanding their properties is crucial for a meaningful evaluation. This practice establishes a foundational toolkit for model validation, exploring how metrics like Root Mean Square Error (RMSE), Mean Absolute Error (MAE), and energy deviation allow for a nuanced assessment of a model's strengths and weaknesses .",
            "id": "3918330",
            "problem": "A battery management system (BMS) model is validated in Software-in-the-Loop (SIL) and Hardware-in-the-Loop (HIL) configurations against a laboratory ground truth for terminal voltage, current, temperature, and power during a dynamic automotive drive cycle. Let the ground-truth signal be denoted by $y(t)$ and the SIL/HIL output be denoted by $\\hat{y}(t)$. For discrete-time sampling at rate $f_{\\mathrm{s}}$ with $N$ samples, denote the sequences by $y_k = y(k/f_{\\mathrm{s}})$ and $\\hat{y}_k = \\hat{y}(k/f_{\\mathrm{s}})$ for $k \\in \\{1,2,\\dots,N\\}$. Consider the error signal $e_k = \\hat{y}_k - y_k$ and the continuous-time error $e(t) = \\hat{y}(t) - y(t)$. Assume the following foundational facts: the $L_2$ and $L_1$ norms of an error quantify average squared and average absolute deviations, respectively;\ncross-correlation $R_{xy}(\\tau)$ identifies time-lag relationships between signals;\nand energy delivered or absorbed by the battery over an interval is the time integral of power, with $P(t) = V(t) I(t)$, where $V(t)$ is terminal voltage and $I(t)$ is current. In HIL, communication and acquisition subsystems may introduce a fixed latency $\\tau$, and occasional measurement spikes may occur.\n\nSelect all options that correctly define the named metrics for comparing SIL/HIL outputs to ground truth and correctly explain when each metric is appropriate in the context of automated battery design and simulation validation.\n\nA. Root Mean Square Error (RMSE): $ \\mathrm{RMSE} = \\sqrt{ \\frac{1}{N} \\sum_{k=1}^{N} \\left( \\hat{y}_k - y_k \\right)^2 } $. Appropriate when errors are approximately Gaussian and large transient mismatches (e.g., rapid voltage excursions at high $C$-rate) should be penalized more heavily than small errors.\n\nB. Mean Absolute Error (MAE): $ \\mathrm{MAE} = \\frac{1}{N} \\sum_{k=1}^{N} \\left| \\hat{y}_k - y_k \\right| $. Appropriate when robustness to outliers (e.g., sporadic sensor spikes or quantization artifacts in HIL) is desired, and median-like performance is preferred over variance-like sensitivity.\n\nC. Time-aligned dynamic error: $ E_{\\mathrm{dyn}} = \\min_{\\tau \\in \\mathbb{R}} \\sqrt{ \\frac{1}{N'} \\sum_{k=1}^{N'} \\left( \\hat{y}_{k+\\tau'} - y_k \\right)^2 } $, where $\\tau'$ is the discrete index shift corresponding to continuous-time lag $\\tau$ and $N'$ is the number of indices over which both signals overlap for a given $\\tau'$. The lag $\\tau$ is estimated by maximizing the cross-correlation $R_{y\\hat{y}}(\\tau) = \\int_{0}^{T} y(t)\\,\\hat{y}(t+\\tau)\\, dt$. Appropriate when evaluating dynamic shape agreement under a fixed latency in HIL, so that alignment-focused comparison prevents latency from dominating the error.\n\nD. Energy deviation over $[0,T]$: $ \\Delta E = \\int_{0}^{T} \\left( \\hat{P}(t) - P(t) \\right) dt = \\int_{0}^{T} \\left( \\hat{V}(t)\\,\\hat{I}(t) - V(t)\\,I(t) \\right) dt $. Appropriate when assessing bias in net energy throughput and its implications for thermal loading, efficiency, and state-of-charge tracking over a drive cycle.\n\nE. RMSE is less sensitive than MAE to occasional large error spikes because the square operation attenuates outlier influence;\ntherefore RMSE is preferred over MAE when outliers are present in HIL.\n\nF. An energy deviation measure for battery validation can be computed as $ \\Delta E_V = \\int_{0}^{T} \\left( \\hat{V}(t) - V(t) \\right) dt $;\nthis is appropriate for quantifying total energy throughput differences between SIL/HIL and ground truth because voltage alone captures energy deviations sufficiently.",
            "solution": "Begin with the definitions and physical bases. For a discrete-time error sequence $e_k = \\hat{y}_k - y_k$, the $L_2$ norm provides a measure proportional to the average squared deviation, while the $L_1$ norm provides a measure proportional to the average absolute deviation. In signal processing, cross-correlation $R_{xy}(\\tau) = \\int_{0}^{T} x(t)\\,y(t+\\tau)\\,dt$ identifies time lag $\\tau$ that best aligns the shapes of $x(t)$ and $y(t)$, which is relevant when a fixed latency shifts the signal in Hardware-in-the-Loop (HIL). For energy, the energy over an interval $[0,T]$ is $E = \\int_{0}^{T} P(t) \\, dt$, with $P(t) = V(t)\\,I(t)$.\n\nOption A: The formula $ \\mathrm{RMSE} = \\sqrt{ \\frac{1}{N} \\sum_{k=1}^{N} \\left( \\hat{y}_k - y_k \\right)^2 } $ is the standard Root Mean Square Error (RMSE), derived from the $L_2$ norm scaled by $1/\\sqrt{N}$. Under the assumption that errors $e_k$ are approximately independent and identically distributed Gaussian with zero mean, the squared loss is optimal in a maximum likelihood sense and penalizes larger deviations more than smaller ones because $\\left( e_k \\right)^2$ grows quadratically. In battery validation, rapid transients (e.g., voltage excursions during high $C$-rate pulses) require a metric that strongly penalizes peak mismatches. Hence, the definition and the stated appropriateness are correct. Verdict: Correct.\n\nOption B: The formula $ \\mathrm{MAE} = \\frac{1}{N} \\sum_{k=1}^{N} \\left| \\hat{y}_k - y_k \\right| $ is the standard Mean Absolute Error (MAE), derived from the $L_1$ norm scaled by $1/N$. The $L_1$ loss is more robust to outliers than the $L_2$ loss because the penalty grows linearly with $|e_k|$ rather than quadratically. If HIL introduces sporadic spikes due to Analog-to-Digital Converter (ADC) quantization or communication glitches, MAE provides a central tendency less influenced by rare large errors, akin to the property that the median minimizes $L_1$ risk under Laplacian noise. In battery validation contexts where the focus is typical performance rather than peak-error sensitivity, MAE is appropriate. Verdict: Correct.\n\nOption C: Time-aligned dynamic error seeks to decouple shape mismatch from fixed latency. The continuous-time cross-correlation $R_{y\\hat{y}}(\\tau) = \\int_{0}^{T} y(t)\\,\\hat{y}(t+\\tau)\\, dt$ identifies the lag $\\tau$ that maximizes similarity. Equivalently, minimizing mean squared error over a lag $\\tau$ aligns signals: $ E_{\\mathrm{dyn}}(\\tau) = \\sqrt{ \\frac{1}{N'(\\tau)} \\sum_{k=1}^{N'(\\tau)} \\left( \\hat{y}_{k+\\tau'} - y_k \\right)^2 } $, with $N'(\\tau)$ being the overlap length. In HIL, a fixed latency from communication or actuation shifts $\\hat{y}(t)$ in time. Computing the minimum over $\\tau$ isolates dynamic shape fidelity from latency effects, which is appropriate when the goal is to assess model dynamics rather than timing infrastructure. The definition using minimization over $\\tau$ and cross-correlation for lag estimation is correct, and the appropriateness is accurate. Verdict: Correct.\n\nOption D: Energy is $E = \\int_{0}^{T} P(t)\\, dt$ with $P(t) = V(t)\\, I(t)$. The energy deviation $ \\Delta E = \\int_{0}^{T} \\left( \\hat{P}(t) - P(t) \\right) dt = \\int_{0}^{T} \\left( \\hat{V}(t)\\,\\hat{I}(t) - V(t)\\,I(t) \\right) dt $ quantifies the bias in net energy throughput, which directly impacts thermal loading, efficiency, and State-of-Charge (SOC) tracking. In automated battery validation, matching energy over drive cycles is crucial for capacity and thermal predictions. Therefore both the definition and the described use case are correct. Verdict: Correct.\n\nOption E: The claim that RMSE is less sensitive than MAE to outliers is false because the square operation $e_k^2$ amplifies large errors; RMSE penalizes outliers more heavily than MAE. Under sporadic spikes, MAE is generally preferred for robustness. Thus, both the statement and the rationale are incorrect. Verdict: Incorrect.\n\nOption F: Computing an energy deviation as $ \\Delta E_V = \\int_{0}^{T} \\left( \\hat{V}(t) - V(t) \\right) dt $ ignores current $I(t)$ and therefore does not represent energy, which depends on the product $V(t)\\,I(t)$. Voltage alone cannot capture power or energy throughput differences; for example, two cases with identical voltage but different current yield different energy. The stated appropriateness (that voltage alone captures energy deviations sufficiently) is incorrect. Verdict: Incorrect.\n\nIn summary, options A, B, C, and D correctly define the metrics and appropriately explain their use in SIL/HIL battery validation, while options E and F are incorrect based on fundamental norm properties and energy definitions.",
            "answer": "$$\\boxed{ABCD}$$"
        },
        {
            "introduction": "Many critical battery states, such as State of Charge (SOC), cannot be measured directly and must be estimated by the Battery Management System (BMS). Before we can validate an SOC estimator, we must answer a more fundamental question: is the state even observable from the available measurements, such as terminal voltage? This exercise connects the physical properties of a battery, specifically the slope of its Open-Circuit Voltage (OCV) curve $k = \\partial E/\\partial \\mathrm{SOC}$, to the mathematical concept of observability from control theory. By working through this problem, you will learn how to formally test for observability and understand why state estimation becomes unreliable in regions where the OCV curve is flat—a critical insight for designing robust validation scenarios and certifiable BMS algorithms .",
            "id": "3918287",
            "problem": "A battery pack is modeled for automated battery design and simulation using an Equivalent Circuit Model with a single resistive-capacitive polarization branch and the State of Charge (SOC). The model is embedded in both Software-in-the-Loop (SIL) and Hardware-in-the-Loop (HIL) validation environments. Consider a constant-current charge experiment over a finite horizon $[0, T]$, with known charging current $I$ and nominal state $(\\mathrm{SOC}_{0}, v_{rc,0})$. The terminal voltage measurement is available. Define Open-Circuit Voltage (OCV) as a function $E(\\mathrm{SOC})$, with local slope $k \\equiv \\partial E/\\partial \\mathrm{SOC}\\big|_{\\mathrm{SOC}_{0}}$.\n\nStarting from conservation of charge and linear energy storage in the polarization branch, linearize the system about $(\\mathrm{SOC}_{0}, v_{rc,0})$ under constant-current charging. Let the small-signal state vector be $x = [x_{1}, x_{2}]^{\\top}$, where $x_{1}$ is the SOC deviation and $x_{2}$ is the polarization voltage deviation. Assume the resistive drop from the series resistance is compensated in post-processing using the known current $I$, so the small-signal output is $y(t) = E(\\mathrm{SOC}_{0} + x_{1}(t)) - E(\\mathrm{SOC}_{0}) + x_{2}(t)$.\n\nUnder these conditions:\n- The SOC deviation $x_{1}$ obeys charge conservation with constant current (no small-signal input), and the polarization voltage $x_{2}$ relaxes with a time constant $\\tau > 0$.\n- The local linearization yields a linear time-invariant state-space model with state matrix $A$ and output matrix $C$ depending on $k$ and $\\tau$.\n\nConstruct an observability test for SOC by deriving the finite-horizon observability Gramian over $[0, T]$ for the linearized model and computing its determinant. Then, to eliminate units and isolate the role of time scales, report the dimensionless normalized determinant\n$$\\Delta \\equiv \\frac{\\det(W_{o})}{k^{2} \\tau^{2}},$$\nwhere $W_{o}$ is the observability Gramian over $[0, T]$.\n\nJustify, through your derivation, how the slope $k = \\partial E/\\partial \\mathrm{SOC}\\big|_{\\mathrm{SOC}_{0}}$ enters the observability Gramian and affects SOC observability. Provide your final answer as a single closed-form analytic expression for $\\Delta$ in terms of $T$ and $\\tau$. No numerical evaluation or rounding is required. Acronyms to use: State of Charge (SOC), Open-Circuit Voltage (OCV), Hardware-in-the-Loop (HIL), Software-in-the-Loop (SIL).",
            "solution": "The user wants me to solve the problem by following these steps:\n1.  **Validate the problem statement**: I will check for scientific soundness, well-posedness, and other criteria.\n2.  If valid, **derive the solution**: I will formulate the state-space model, derive the observability Gramian, compute its determinant, and finally find the normalized determinant $\\Delta$.\n\n### Step 1: Extract Givens\n-   System: Battery pack modeled with a single resistive-capacitive (RC) polarization branch and State of Charge (SOC).\n-   Validation context: Software-in-the-Loop (SIL) and Hardware-in-the-Loop (HIL).\n-   Experiment: Constant-current charge with current $I$ over a time horizon $[0, T]$.\n-   Initial state: Nominal state $(\\mathrm{SOC}_{0}, v_{rc,0})$.\n-   Measurement: Terminal voltage.\n-   Definition: Open-Circuit Voltage (OCV) is a function $E(\\mathrm{SOC})$.\n-   Parameter: $k \\equiv \\partial E/\\partial \\mathrm{SOC}\\big|_{\\mathrm{SOC}_{0}}$.\n-   Linearization: About $(\\mathrm{SOC}_{0}, v_{rc,0})$.\n-   Small-signal state vector: $x = [x_{1}, x_{2}]^{\\top}$, where $x_{1}$ is SOC deviation and $x_{2}$ is polarization voltage deviation.\n-   Small-signal output: $y(t) = E(\\mathrm{SOC}_{0} + x_{1}(t)) - E(\\mathrm{SOC}_{0}) + x_{2}(t)$, assuming series resistance drop is compensated.\n-   Dynamics assumption 1: SOC deviation $x_{1}$ obeys charge conservation with constant current (no small-signal input).\n-   Dynamics assumption 2: Polarization voltage deviation $x_{2}$ relaxes with a time constant $\\tau > 0$.\n-   Task 1: Construct an observability test by deriving the finite-horizon observability Gramian $W_{o}$ over $[0, T]$.\n-   Task 2: Compute its determinant, $\\det(W_o)$.\n-   Task 3: Report the dimensionless normalized determinant $\\Delta \\equiv \\frac{\\det(W_{o})}{k^{2} \\tau^{2}}$.\n-   Task 4: Justify how $k$ affects SOC observability through the derivation.\n-   Task 5: Provide the final answer for $\\Delta$ as a closed-form expression in terms of $T$ and $\\tau$.\n\n### Step 2: Validate Using Extracted Givens\nThe problem is scientifically grounded. The use of an Equivalent Circuit Model (ECM) with an RC branch, state-space representation, linearization, and observability analysis are all standard, well-established techniques in battery modeling, simulation, and control for automated design. The problem is well-posed, providing sufficient information and clear assumptions to construct a linear time-invariant (LTI) model and perform the required analysis. The language is objective and precise. The assumptions, such as \"no small-signal input\" for the autonomous system observability analysis and the defined form of the small-signal output, are explicit and allow for a unique formalization. The problem is self-contained and does not violate any physical or mathematical principles. There are no contradictions or ambiguities.\n\n### Step 3: Verdict and Action\nThe problem is valid. I will proceed with the solution.\n\nThe solution is structured as follows: First, we derive the linearized state-space model $(A, C)$ based on the problem description. Second, we justify the role of the OCV slope $k$ in observability. Third, we compute the finite-horizon observability Gramian $W_o$. Fourth, we calculate its determinant. Finally, we derive the normalized determinant $\\Delta$.\n\n**1. State-Space Model Formulation**\n\nWe are asked to find a linear time-invariant state-space model of the form $\\dot{x}(t) = Ax(t)$ and $y(t) = Cx(t)$ for the small-signal deviations $x(t) = [x_1(t), x_2(t)]^\\top$.\n\nThe state $x_1$ represents the SOC deviation. The fundamental equation for SOC is $\\frac{d(\\mathrm{SOC})}{dt} = \\frac{I(t)}{Q_n}$, where $Q_n$ is the nominal capacity and $I(t)$ is the input current. For observability analysis of an LTI system, we consider the autonomous system (zero input). The problem states \"no small-signal input,\" which implies we analyze the system's inherent dynamics. The SOC itself is not a function of the other states (SOC, $v_{rc}$), but is driven by the integral of current. In the absence of a small-signal current input, the rate of change of the SOC *deviation* is zero. This corresponds to the dynamics of a pure integrator. Therefore, the state equation for $x_1$ is:\n$$\n\\dot{x}_1(t) = 0\n$$\n\nThe state $x_2$ is the polarization voltage deviation. The problem states that this deviation \"relaxes with a time constant $\\tau > 0$\". This describes a first-order decay process, characteristic of an RC circuit's voltage response in the absence of an input current. The dynamics are therefore:\n$$\n\\dot{x}_2(t) = -\\frac{1}{\\tau} x_2(t)\n$$\n\nCombining these two equations into a matrix form $\\dot{x} = Ax$:\n$$\n\\begin{pmatrix} \\dot{x}_1 \\\\ \\dot{x}_2 \\end{pmatrix} = \\begin{pmatrix} 0 & 0 \\\\ 0 & -\\frac{1}{\\tau} \\end{pmatrix} \\begin{pmatrix} x_1 \\\\ x_2 \\end{pmatrix}\n$$\nThus, the state matrix $A$ is:\n$$\nA = \\begin{pmatrix} 0 & 0 \\\\ 0 & -\\frac{1}{\\tau} \\end{pmatrix}\n$$\n\nNext, we formulate the output equation $y = Cx$. The problem defines the small-signal output as $y(t) = E(\\mathrm{SOC}_{0} + x_{1}(t)) - E(\\mathrm{SOC}_{0}) + x_{2}(t)$. To linearize this, we use a first-order Taylor expansion for $E(\\mathrm{SOC})$ around $\\mathrm{SOC}_0$:\n$$\nE(\\mathrm{SOC}_{0} + x_{1}(t)) \\approx E(\\mathrm{SOC}_{0}) + \\frac{\\partial E}{\\partial \\mathrm{SOC}}\\bigg|_{\\mathrm{SOC}_{0}} x_1(t) = E(\\mathrm{SOC}_{0}) + k x_1(t)\n$$\nSubstituting this into the expression for $y(t)$:\n$$\ny(t) \\approx (E(\\mathrm{SOC}_{0}) + k x_1(t)) - E(\\mathrm{SOC}_{0}) + x_2(t) = k x_1(t) + x_2(t)\n$$\nIn matrix form, this is:\n$$\ny(t) = \\begin{pmatrix} k & 1 \\end{pmatrix} \\begin{pmatrix} x_1(t) \\\\ x_2(t) \\end{pmatrix}\n$$\nThus, the output matrix $C$ is:\n$$\nC = \\begin{pmatrix} k & 1 \\end{pmatrix}\n$$\n\n**2. Justification of the Role of $k$ in Observability**\n\nObservability determines whether the initial state of the system can be uniquely determined from the output measurements over a period of time. The parameter $k = \\partial E/\\partial\\mathrm{SOC}$ represents the sensitivity of the open-circuit voltage to changes in the state of charge.\n\nPhysically, the state $x_1$ (SOC deviation) influences the output $y$ only through the term $k x_1$. If $k=0$, the OCV-SOC curve is flat at the operating point, meaning the voltage provides no information about small changes in SOC. In this case, the output becomes $y(t) = x_2(t)$, and it is impossible to infer anything about $x_1$ from the measurement, making the SOC unobservable.\n\nMathematically, this is verified by the Kalman observability rank condition. The observability matrix $\\mathcal{O}$ for this system is:\n$$\n\\mathcal{O} = \\begin{pmatrix} C \\\\ CA \\end{pmatrix}\n$$\nWe compute $CA$:\n$$\nCA = \\begin{pmatrix} k & 1 \\end{pmatrix} \\begin{pmatrix} 0 & 0 \\\\ 0 & -\\frac{1}{\\tau} \\end{pmatrix} = \\begin{pmatrix} 0 & -\\frac{1}{\\tau} \\end{pmatrix}\n$$\nThe observability matrix is:\n$$\n\\mathcal{O} = \\begin{pmatrix} k & 1 \\\\ 0 & -\\frac{1}{\\tau} \\end{pmatrix}\n$$\nThe system is observable if and only if $\\mathcal{O}$ has full rank, which for a $2 \\times 2$ matrix means its determinant is non-zero.\n$$\n\\det(\\mathcal{O}) = (k)\\left(-\\frac{1}{\\tau}\\right) - (1)(0) = -\\frac{k}{\\tau}\n$$\nSince $\\tau > 0$, the system is observable if and only if $k \\neq 0$. This provides a rigorous justification for the critical role of $k$.\n\n**3. Observability Gramian Calculation**\n\nThe finite-horizon observability Gramian over the interval $[0, T]$ is given by:\n$$\nW_o = \\int_0^T e^{A^\\top t} C^\\top C e^{At} dt\n$$\nFirst, we find the state transition matrix $e^{At}$. Since $A$ is a diagonal matrix, its exponential is the exponential of its diagonal elements:\n$$\ne^{At} = \\begin{pmatrix} e^{0 \\cdot t} & 0 \\\\ 0 & e^{-\\frac{1}{\\tau}t} \\end{pmatrix} = \\begin{pmatrix} 1 & 0 \\\\ 0 & e^{-t/\\tau} \\end{pmatrix}\n$$\nSince $A$ is symmetric, $A^\\top = A$, and thus $e^{A^\\top t} = e^{At}$.\nNext, we calculate the product $C^\\top C$:\n$$\nC^\\top C = \\begin{pmatrix} k \\\\ 1 \\end{pmatrix} \\begin{pmatrix} k & 1 \\end{pmatrix} = \\begin{pmatrix} k^2 & k \\\\ k & 1 \\end{pmatrix}\n$$\nNow we compute the integrand $e^{A^\\top t} C^\\top C e^{At}$:\n$$\ne^{At} C^\\top C e^{At} = \\begin{pmatrix} 1 & 0 \\\\ 0 & e^{-t/\\tau} \\end{pmatrix} \\begin{pmatrix} k^2 & k \\\\ k & 1 \\end{pmatrix} \\begin{pmatrix} 1 & 0 \\\\ 0 & e^{-t/\\tau} \\end{pmatrix}\n$$\n$$\n= \\begin{pmatrix} k^2 & k \\\\ k e^{-t/\\tau} & e^{-t/\\tau} \\end{pmatrix} \\begin{pmatrix} 1 & 0 \\\\ 0 & e^{-t/\\tau} \\end{pmatrix} = \\begin{pmatrix} k^2 & k e^{-t/\\tau} \\\\ k e^{-t/\\tau} & e^{-2t/\\tau} \\end{pmatrix}\n$$\nFinally, we integrate this matrix from $t=0$ to $t=T$ to obtain $W_o$:\n$$\nW_o = \\int_0^T \\begin{pmatrix} k^2 & k e^{-t/\\tau} \\\\ k e^{-t/\\tau} & e^{-2t/\\tau} \\end{pmatrix} dt = \\begin{pmatrix} \\int_0^T k^2 dt & \\int_0^T k e^{-t/\\tau} dt \\\\ \\int_0^T k e^{-t/\\tau} dt & \\int_0^T e^{-2t/\\tau} dt \\end{pmatrix}\n$$\nWe evaluate each integral:\n$$\nW_{o,11} = \\int_0^T k^2 dt = k^2 [t]_0^T = k^2 T\n$$\n$$\nW_{o,12} = W_{o,21} = \\int_0^T k e^{-t/\\tau} dt = k \\left[ -\\tau e^{-t/\\tau} \\right]_0^T = k(-\\tau e^{-T/\\tau} + \\tau e^0) = k\\tau(1 - e^{-T/\\tau})\n$$\n$$\nW_{o,22} = \\int_0^T e^{-2t/\\tau} dt = \\left[ -\\frac{\\tau}{2} e^{-2t/\\tau} \\right]_0^T = -\\frac{\\tau}{2} e^{-2T/\\tau} + \\frac{\\tau}{2} e^0 = \\frac{\\tau}{2}(1 - e^{-2T/\\tau})\n$$\nThe observability Gramian is:\n$$\nW_o = \\begin{pmatrix} k^2 T & k\\tau(1 - e^{-T/\\tau}) \\\\ k\\tau(1 - e^{-T/\\tau}) & \\frac{\\tau}{2}(1 - e^{-2T/\\tau}) \\end{pmatrix}\n$$\nHere again, we see that if $k=0$, the first row and column of $W_o$ become zero, rendering the matrix singular ($\\det(W_o)=0$) and the system unobservable.\n\n**4. Determinant of the Gramian and Normalized Determinant $\\Delta$**\n\nWe compute the determinant of $W_o$:\n$$\n\\det(W_o) = (W_{o,11})(W_{o,22}) - (W_{o,12})^2\n$$\n$$\n\\det(W_o) = (k^2 T) \\left(\\frac{\\tau}{2}(1 - e^{-2T/\\tau})\\right) - \\left(k\\tau(1 - e^{-T/\\tau})\\right)^2\n$$\n$$\n\\det(W_o) = \\frac{k^2 T \\tau}{2}(1 - e^{-2T/\\tau}) - k^2 \\tau^2 (1 - e^{-T/\\tau})^2\n$$\nThe problem asks for the normalized determinant $\\Delta = \\frac{\\det(W_o)}{k^2 \\tau^2}$.\n$$\n\\Delta = \\frac{1}{k^2 \\tau^2} \\left[ \\frac{k^2 T \\tau}{2}(1 - e^{-2T/\\tau}) - k^2 \\tau^2 (1 - e^{-T/\\tau})^2 \\right]\n$$\n$$\n\\Delta = \\frac{T}{2\\tau}(1 - e^{-2T/\\tau}) - (1 - e^{-T/\\tau})^2\n$$\nThis expression can be left as is. For clarity, we will use the `\\exp` function notation as required.\n$$\n\\Delta = \\frac{T}{2\\tau}(1 - \\exp(-2T/\\tau)) - (1 - \\exp(-T/\\tau))^2\n$$\nThis is the final closed-form analytic expression for the dimensionless normalized determinant in terms of the experiment duration $T$ and the polarization time constant $\\tau$.",
            "answer": "$$ \\boxed{ \\frac{T}{2\\tau} \\left( 1 - \\exp\\left(-\\frac{2T}{\\tau}\\right) \\right) - \\left( 1 - \\exp\\left(-\\frac{T}{\\tau}\\right) \\right)^{2} } $$"
        },
        {
            "introduction": "Hardware-in-the-Loop (HIL) simulation is not just about model accuracy; it is also about executing the model, control, and data acquisition tasks within strict real-time deadlines. Failing to meet these deadlines can invalidate the simulation or lead to instability. This practice delves into the practical engineering of a HIL testbed by applying Rate-Monotonic Scheduling (RMS), a cornerstone of real-time systems, to manage competing computational tasks. You will analyze task utilization to guarantee schedulability, ensuring that high-priority functions like state estimation are never unacceptably delayed by lower-priority ones like data logging .",
            "id": "3918331",
            "problem": "A battery Hardware-in-the-Loop (HIL) and Software-in-the-Loop (SIL) validation rig executes three periodic real-time tasks under a single-core preemptive fixed-priority kernel using Rate-Monotonic Scheduling (RMS): a state estimator for a reduced-order electrochemical model, a current-control loop to drive the load emulator, and a data logger that writes synchronized measurements and state estimates to non-volatile storage. All tasks have deadlines equal to their periods, synchronous release at time $t = 0$, negligible release jitter, and zero context-switch and interrupt overheads. The estimator and controller have measured worst-case execution times on the target platform, while the logger’s worst-case execution time must be chosen to ensure schedulability.\n\n- Estimator task $E$: period $T_{E} = 1$ ms, worst-case execution time $C_{E} = 0.18$ ms.\n- Control task $C$: period $T_{C} = 2$ ms, worst-case execution time $C_{C} = 0.22$ ms.\n- Logging task $L$: period $T_{L} = 10$ ms, worst-case execution time $C_{L}$ (to be determined).\n\nTasks are prioritized by their periods according to Rate-Monotonic Scheduling. Using first principles of fixed-priority schedulability analysis and the classical utilization-based sufficient schedulability bound for periodic tasks, do the following:\n\n1. Determine the maximum allowable $C_{L}$ that guarantees the task set is schedulable under Rate-Monotonic Scheduling.\n2. Construct the executable schedule over one hyperperiod from $t = 0$ to $t = 10$ ms at the computed maximum $C_{L}$, indicating the preemption points among $E$, $C$, and $L$, and argue why $L$ meets its deadline at $t = 10$ ms.\n\nRound your final numerical answer for the maximum allowable $C_{L}$ to four significant figures. Express the final answer in milliseconds.",
            "solution": "The problem statement is coherent, internally consistent, and grounded in the established principles of real-time systems scheduling theory. All necessary parameters for analysis are provided. The context, a Hardware-in-the-Loop (HIL) and Software-in-the-Loop (SIL) validation rig for battery systems, is a credible and relevant application of such theory. The problem is therefore deemed valid and a formal solution can be constructed.\n\nThe problem requires a two-part solution: first, to determine the maximum worst-case execution time $C_L$ for the logging task $L$ that guarantees schedulability based on a sufficient utilization-based test; second, to construct the explicit schedule over one hyperperiod to demonstrate that the lowest-priority task meets its deadline.\n\n**1. Determination of Maximum Allowable $C_L$**\n\nThe scheduling policy is Rate-Monotonic Scheduling (RMS), a preemptive fixed-priority scheme where priority is inversely proportional to the task's period. The given tasks are:\n- Estimator task $E$: $T_{E} = 1$ ms, $C_{E} = 0.18$ ms.\n- Control task $C$: $T_{C} = 2$ ms, $C_{C} = 0.22$ ms.\n- Logging task $L$: $T_{L} = 10$ ms, $C_{L}$ to be determined.\n\nGiven $T_{E} < T_{C} < T_{L}$, the priority assignment is $Priority(E) > Priority(C) > Priority(L)$.\n\nThe problem specifies using the classical utilization-based sufficient schedulability bound for a set of $n$ periodic tasks, established by Liu and Layland. The condition states that a task set is schedulable under RMS if its total processor utilization $U$ does not exceed a specific bound:\n$$ U = \\sum_{i=1}^{n} \\frac{C_i}{T_i} \\le n(2^{1/n} - 1) $$\nFor the given system, the number of tasks is $n = 3$. The utilization bound is:\n$$ U_{bound} = 3(2^{1/3} - 1) $$\nWe calculate the utilizations of the known tasks:\n$$ U_E = \\frac{C_E}{T_E} = \\frac{0.18\\,\\text{ms}}{1\\,\\text{ms}} = 0.18 $$\n$$ U_C = \\frac{C_C}{T_C} = \\frac{0.22\\,\\text{ms}}{2\\,\\text{ms}} = 0.11 $$\nThe utilization of the logging task is $U_L = \\frac{C_L}{T_L} = \\frac{C_L}{10}$.\n\nThe total utilization $U = U_E + U_C + U_L$ must satisfy the schedulability condition:\n$$ 0.18 + 0.11 + \\frac{C_L}{10} \\le 3(2^{1/3} - 1) $$\n$$ 0.29 + \\frac{C_L}{10} \\le 3(2^{1/3} - 1) $$\nTo find the maximum allowable $C_L$, we solve for $C_L$:\n$$ \\frac{C_L}{10} \\le 3(2^{1/3} - 1) - 0.29 $$\n$$ C_L \\le 10 \\left( 3(2^{1/3} - 1) - 0.29 \\right) $$\nNumerically evaluating the expression:\n$$ C_L \\le 10 \\left( 3(1.259921...) - 3 - 0.29 \\right) $$\n$$ C_L \\le 10 \\left( 0.779763... - 0.29 \\right) $$\n$$ C_L \\le 10 \\left( 0.489763... \\right) $$\n$$ C_L \\le 4.89763... \\,\\text{ms} $$\nRounding to four significant figures as required, the maximum allowable worst-case execution time for the logging task is $C_L = 4.898$ ms.\n\n**2. Schedule Construction and Verification**\n\nWe now construct the schedule for one hyperperiod using the computed value $C_L = 4.898$ ms. The hyperperiod is the least common multiple of the task periods: $H = \\text{lcm}(1, 2, 10) = 10$ ms. All tasks are released synchronously at $t=0$.\n\nThe schedule over the interval $[0, 10]$ ms is as follows, tracking the execution of each job and noting preemptions:\n- **`t = 0.000`**: Jobs $E_1$, $C_1$, and $L_1$ are released. $E_1$ (highest priority) runs.\n- **`[0.000, 0.180]`**: $E_1$ executes for $C_E=0.18$ ms and completes.\n- **`[0.180, 0.400]`**: $C_1$ (next highest priority) executes for $C_C=0.22$ ms and completes.\n- **`[0.400, 1.000]`**: $L_1$ (lowest priority) executes for $0.600$ ms. Remaining execution time for $L_1$ is $4.898 - 0.600 = 4.298$ ms.\n- **`t = 1.000`**: Job $E_2$ is released and preempts $L_1$.\n- **`[1.000, 1.180]`**: $E_2$ executes and completes.\n- **`[1.180, 2.000]`**: $L_1$ resumes, executing for $0.820$ ms. Remaining $C_L = 4.298 - 0.820 = 3.478$ ms.\n- **`t = 2.000`**: Jobs $E_3$ and $C_2$ are released. $E_3$ preempts $L_1$.\n- **`[2.000, 2.180]`**: $E_3$ executes and completes.\n- **`[2.180, 2.400]`**: $C_2$ executes and completes.\n- **`[2.400, 3.000]`**: $L_1$ resumes, executing for $0.600$ ms. Remaining $C_L = 3.478 - 0.600 = 2.878$ ms.\n- **`t = 3.000`**: Job $E_4$ is released and preempts $L_1$.\n- **`[3.000, 3.180]`**: $E_4$ executes and completes.\n- **`[3.180, 4.000]`**: $L_1$ resumes, executing for $0.820$ ms. Remaining $C_L = 2.878 - 0.820 = 2.058$ ms.\n- **`t = 4.000`**: Jobs $E_5$ and $C_3$ are released. $E_5$ preempts $L_1$.\n- **`[4.000, 4.180]`**: $E_5$ executes and completes.\n- **`[4.180, 4.400]`**: $C_3$ executes and completes.\n- **`[4.400, 5.000]`**: $L_1$ resumes, executing for $0.600$ ms. Remaining $C_L = 2.058 - 0.600 = 1.458$ ms.\n- **`t = 5.000`**: Job $E_6$ is released and preempts $L_1$.\n- **`[5.000, 5.180]`**: $E_6$ executes and completes.\n- **`[5.180, 6.000]`**: $L_1$ resumes, executing for $0.820$ ms. Remaining $C_L = 1.458 - 0.820 = 0.638$ ms.\n- **`t = 6.000`**: Jobs $E_7$ and $C_4$ are released. $E_7$ preempts $L_1$.\n- **`[6.000, 6.180]`**: $E_7$ executes and completes.\n- **`[6.180, 6.400]`**: $C_4$ executes and completes.\n- **`[6.400, 7.000]`**: $L_1$ resumes, executing for $0.600$ ms. Remaining $C_L = 0.638 - 0.600 = 0.038$ ms.\n- **`t = 7.000`**: Job $E_8$ is released and preempts $L_1$.\n- **`[7.000, 7.180]`**: $E_8$ executes and completes.\n- **`[7.180, 7.218]`**: $L_1$ resumes, executing for its final $0.038$ ms. **$L_1$ completes at $t=7.218$ ms.**\n- **`t > 7.218`**: The processor is idle until the next job release at $t=8.000$. Subsequent jobs ($E_9, C_5, E_{10}$) also run and complete well within their deadlines in the remaining portion of the hyperperiod.\n\n**Argument for Deadline Satisfaction:**\nThe analysis of the schedule provides the definitive argument. The first and only job of the logging task, $L_1$, is released at $t=0$ and has a deadline at $t=T_L=10$ ms. The detailed schedule simulation shows that after being preempted by $8$ jobs of task $E$ and $4$ jobs of task $C$, job $L_1$ accumulates its required execution time of $4.898$ ms and completes at time $t_{finish} = 7.218$ ms. Since its completion time $t_{finish} = 7.218$ ms is less than its deadline $D_L = 10$ ms, task $L$ meets its deadline. By inspection, all higher-priority tasks also meet their deadlines, as they are subject to no preemption. Therefore, the task set is schedulable with $C_L = 4.898$ ms.",
            "answer": "$$\\boxed{4.898}$$"
        }
    ]
}