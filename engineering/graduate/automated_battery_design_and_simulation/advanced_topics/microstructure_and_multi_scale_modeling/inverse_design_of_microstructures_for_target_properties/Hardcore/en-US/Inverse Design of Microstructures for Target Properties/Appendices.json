{
    "hands_on_practices": [
        {
            "introduction": "The foundation of any inverse design strategy is a robust \"forward model\" capable of predicting material properties from a given microstructure. This exercise guides you through building such a model by implementing the Finite Volume Method (FVM) to solve for steady-state electrical conduction in a heterogeneous medium. By computing the effective conductivity of different microstructures, you will gain hands-on experience with the numerical techniques that form the predictive engine of computational materials design .",
            "id": "3921852",
            "problem": "You are given a two-dimensional voxelized microstructure represented on an $N \\times N$ square grid covering a unit square domain of side length $L_x = L_y = 1\\,\\mathrm{m}$. Each voxel (cell) carries a local scalar conductivity $k(\\mathbf{x})$ in $\\mathrm{S/m}$ corresponding to one of two phases. Under steady-state direct-current conduction with an applied potential difference $\\Delta \\phi = 1\\,\\mathrm{V}$ along the $x$-direction, and with no-flux (Neumann) boundary conditions along the $y$-direction, the governing equations are the conservation of current density and the local linear constitutive relation, namely $ \\nabla \\cdot \\mathbf{J} = 0$ and $\\mathbf{J} = -k(\\mathbf{x}) \\nabla \\phi(\\mathbf{x})$, where $ \\phi$ is the electric potential and $\\mathbf{J}$ is the current density.\n\nYour task is to implement the Finite Volume Method (FVM) to compute the effective conductivity $K^{\\text{eff}}$ of the microstructure in $\\mathrm{S/m}$, defined by the macroscopic relation $I = K^{\\text{eff}} A \\frac{\\Delta \\phi}{L_x}$, where $I$ is the total current through the left boundary under the applied potential difference $\\Delta \\phi$, and $A$ is the cross-sectional area perpendicular to the $x$-direction. In this two-dimensional setting, interpret the domain as having unit thickness in the out-of-plane direction, so that $A = L_y \\times 1 = 1\\,\\mathrm{m}^2$. The discretization must enforce Dirichlet boundary conditions $\\phi = 0\\,\\mathrm{V}$ at $x=0$ and $\\phi = 1\\,\\mathrm{V}$ at $x=1$, and Neumann (no-flux) boundary conditions at $y=0$ and $y=1$. Use harmonic averaging of conductivities at internal faces to approximate fluxes between adjacent cells.\n\nStarting from the fundamental laws of electromagnetism in the static limit and the definitions above, derive and implement a cell-centered FVM discretization on a uniform mesh of size $h = 1/N$, with cell centers located at $(x_i, y_j) = \\left( \\frac{i+1/2}{N}, \\frac{j+1/2}{N} \\right)$ for integer indices $i,j \\in \\{0,\\dots,N-1\\}$. In your algorithm, for an internal face between cells with conductivities $k_1$ and $k_2$, use the harmonic average $k_f = \\left( \\frac{1}{2} \\left( \\frac{1}{k_1} + \\frac{1}{k_2} \\right) \\right)^{-1}$ to compute the face conductance. For boundary faces at $x=0$ and $x=1$, impose Dirichlet conditions using a half-cell distance $h/2$ and face area $h$, resulting in a boundary face conductance equal to $2\\,k$ at the boundary-adjacent cell. After solving for the discrete potential field $\\phi_{i,j}$, compute the total current $I$ through the left boundary by summing the boundary fluxes, and then compute $K^{\\text{eff}}$ in $\\mathrm{S/m}$.\n\nAdditionally, estimate the discretization error $\\mathcal{E}(h)$ as a function of mesh size $h$ by comparing the computed $K^{\\text{eff}}(h)$ to a reference solution $K^{\\text{eff}}(h_{\\text{ref}})$ obtained on a finer mesh with $h_{\\text{ref}} = 1/N_{\\text{ref}}$. Report the absolute error $\\mathcal{E}(h) = \\left| K^{\\text{eff}}(h) - K^{\\text{eff}}(h_{\\text{ref}})\\right|$ in $\\mathrm{S/m}$.\n\nDefine the following test suite of microstructures and phase conductivities, each to be sampled at the specified resolutions:\n\n- Test case $1$ (happy path, heterogeneous inclusion):\n    - Geometry: circular inclusion centered at $(0.5, 0.5)$ with radius $r = 0.3$.\n    - Phase conductivities: inclusion phase $k_{\\text{in}} = 12.0\\,\\mathrm{S/m}$, matrix phase $k_{\\text{out}} = 0.5\\,\\mathrm{S/m}$.\n    - Resolutions: $N \\in \\{16, 32, 64\\}$ and reference $N_{\\text{ref}} = 128$.\n\n- Test case $2$ (high-conductivity stripe, near-percolation edge):\n    - Geometry: vertical stripe spanning the entire height with $x \\in [0.4, 0.6]$.\n    - Phase conductivities: stripe phase $k_{\\text{stripe}} = 50.0\\,\\mathrm{S/m}$, matrix phase $k_{\\text{matrix}} = 1.0\\,\\mathrm{S/m}$.\n    - Resolutions: $N \\in \\{16, 32, 64\\}$ and reference $N_{\\text{ref}} = 128$.\n\n- Test case $3$ (uniform medium, verification boundary case):\n    - Geometry: entire domain is a single phase.\n    - Phase conductivity: uniform $k_{\\text{uni}} = 3.0\\,\\mathrm{S/m}$.\n    - Resolutions: $N \\in \\{8, 16, 32\\}$ and reference $N_{\\text{ref}} = 128$.\n\nFor each test case, construct $k(\\mathbf{x})$ by sampling the analytic microstructure definition at the cell centers. Compute $K^{\\text{eff}}(h)$ for each $N$ and the reference $K^{\\text{eff}}(h_{\\text{ref}})$, and then compute the error $\\mathcal{E}(h)$ for each $N$.\n\nThe required final output format is as follows: Your program should produce a single line of output containing a list of results, one per test case, where each test case result is a list of floats in $\\mathrm{S/m}$, ordered as $[K^{\\text{eff}}(h_{\\text{ref}}), K^{\\text{eff}}(h_1), \\mathcal{E}(h_1), K^{\\text{eff}}(h_2), \\mathcal{E}(h_2), K^{\\text{eff}}(h_3), \\mathcal{E}(h_3)]$. For example, the overall output should look like $[[\\dots],[\\dots],[\\dots]]$, with all floats expressed in $\\mathrm{S/m}$ and no additional text.\n\nYour program must be self-contained, require no input, and adhere to the specified execution environment. All computations and reported values of $K^{\\text{eff}}$ and $\\mathcal{E}(h)$ must be in $\\mathrm{S/m}$, expressed as decimal floats.",
            "solution": "The problem is subjected to validation against the specified criteria.\n\n### Step 1: Extract Givens\n- **Governing Physics**: Steady-state DC conduction described by the conservation of current density, $\\nabla \\cdot \\mathbf{J} = 0$, and the linear constitutive relation (Ohm's law), $\\mathbf{J} = -k(\\mathbf{x}) \\nabla \\phi(\\mathbf{x})$, where $\\phi$ is the electric potential, $\\mathbf{J}$ is the current density, and $k(\\mathbf{x})$ is the local scalar conductivity in $\\mathrm{S/m}$.\n- **Domain**: A two-dimensional unit square, $L_x = L_y = 1\\,\\mathrm{m}$, with unit thickness. The cross-sectional area is $A = L_y \\times 1 = 1\\,\\mathrm{m}^2$.\n- **Boundary Conditions (BCs)**:\n    - Dirichlet BCs on the vertical boundaries: $\\phi(x=0) = 0\\,\\mathrm{V}$ and $\\phi(x=1) = 1\\,\\mathrm{V}$. The applied potential difference is $\\Delta \\phi = 1\\,\\mathrm{V}$.\n    - Neumann BCs on the horizontal boundaries: no-flux, i.e., $\\frac{\\partial \\phi}{\\partial y} = 0$ at $y=0$ and $y=1$.\n- **Discretization**: Cell-centered Finite Volume Method (FVM) on a uniform $N \\times N$ grid. The mesh size is $h = 1/N$. Cell centers are at $(x_i, y_j) = \\left( \\frac{i+1/2}{N}, \\frac{j+1/2}{N} \\right)$ for $i,j \\in \\{0, \\dots, N-1\\}$.\n- **Flux Approximation**:\n    - For internal faces between cells with conductivities $k_1$ and $k_2$, the face conductivity $k_f$ is the harmonic average: $k_f = \\left( \\frac{1}{2} \\left( \\frac{1}{k_1} + \\frac{1}{k_2} \\right) \\right)^{-1}$.\n    - For Dirichlet boundary faces, the conductance is specified to be $2k$ where $k$ is the conductivity of the boundary-adjacent cell.\n- **Quantity of Interest**: The effective conductivity $K^{\\text{eff}}$ in $\\mathrm{S/m}$, defined by the macroscopic relation $I = K^{\\text{eff}} A \\frac{\\Delta \\phi}{L_x}$, where $I$ is the total current.\n- **Error Estimation**: The absolute error $\\mathcal{E}(h) = \\left| K^{\\text{eff}}(h) - K^{\\text{eff}}(h_{\\text{ref}})\\right|$ is to be computed with respect to a reference solution on a finer mesh ($h_{\\text{ref}}=1/N_{\\text{ref}}$).\n- **Test Cases**: Three distinct heterogeneous microstructures are defined with specific geometries, phase conductivities, and resolutions for analysis.\n\n### Step 2: Validate Using Extracted Givens\n- **Scientific Grounding**: The problem is fundamentally sound. It describes steady-state electrical conduction in a heterogeneous medium, a classic elliptic boundary value problem governed by the equation $\\nabla \\cdot (k(\\mathbf{x}) \\nabla \\phi(\\mathbf{x})) = 0$. The FVM is a standard and robust numerical method for this class of problems. The use of harmonic averaging for conductivity is a physically appropriate choice that ensures continuity of the normal component of the current density across cell faces.\n- **Well-Posedness**: The problem is well-posed. The combination of Dirichlet and Neumann boundary conditions on a closed domain ensures the existence of a unique, stable solution for the potential field $\\phi(\\mathbf{x})$. The quantity of interest, $K^{\\text{eff}}$, is uniquely determined from this solution.\n- **Objectivity and Completeness**: The problem is stated in precise, objective language. All parameters, equations, boundary conditions, and numerical schemes are explicitly defined, rendering the problem self-contained and free of ambiguity. The definitions are internally consistent.\n- **Feasibility**: The physical parameters and computational tasks are realistic and feasible.\n- **Structure**: The problem is well-structured, guiding the user from first principles to numerical implementation and analysis. It is not trivial and requires a substantive application of numerical methods for partial differential equations.\n\n### Step 3: Verdict and Action\nThe problem is **valid**. A rigorous solution will now be derived and implemented.\n\n### Derivation of the Finite Volume Method\n\nThe governing partial differential equation is obtained by combining the conservation law and the constitutive relation:\n$$\n\\nabla \\cdot (-k(\\mathbf{x}) \\nabla \\phi(\\mathbf{x})) = 0\n$$\nWe employ a cell-centered Finite Volume Method. We integrate the governing equation over a control volume $\\Omega_{i,j}$, corresponding to the cell centered at $(x_i, y_j)$:\n$$\n\\int_{\\Omega_{i,j}} \\nabla \\cdot (-k \\nabla \\phi) \\, dV = 0\n$$\nApplying the divergence theorem, we convert the volume integral into a surface integral over the boundary of the control volume, $\\partial\\Omega_{i,j}$:\n$$\n\\oint_{\\partial\\Omega_{i,j}} (-k \\nabla \\phi) \\cdot \\mathbf{n} \\, dS = 0\n$$\nThis equation expresses the conservation of current: the net current flowing out of any control volume is zero. For a 2D square cell of side length $h=1/N$ and unit thickness, this integral becomes a sum of currents over the four faces (East, West, North, South):\n$$\nI_e + I_w + I_n + I_s = 0\n$$\nwhere $I_f$ is the total current flowing outwards through face $f$. The current through a face is approximated using a finite difference for the potential gradient. For the east face, separating cell $(i,j)$ and cell $(i+1,j)$, the current is:\n$$\nI_e = -k_e A_e \\frac{\\phi_{i+1,j} - \\phi_{i,j}}{h}\n$$\nwhere $A_e = h \\times 1 = h$ is the face area. The face conductivity $k_e$ is the harmonic average of the conductivities of the adjacent cells, $k_{i,j}$ and $k_{i+1,j}$:\n$$\nk_e = \\frac{2 k_{i,j} k_{i+1,j}}{k_{i,j} + k_{i+1,j}}\n$$\nWe define the face conductance $g_f = k_f A_f / \\delta$, where $\\delta$ is the distance between cell centers. For an internal face, $\\delta=h$ and $A_f=h$, so the conductance is simply $g_f=k_f$. The currents through the four faces of an internal cell $(i,j)$ are:\n- $I_e = g_e (\\phi_{i,j} - \\phi_{i+1,j})$\n- $I_w = g_w (\\phi_{i,j} - \\phi_{i-1,j})$\n- $I_n = g_n (\\phi_{i,j} - \\phi_{i,j+1})$\n- $I_s = g_s (\\phi_{i,j} - \\phi_{i,j-1})$\n\nSubstituting these into the conservation equation yields the discrete algebraic equation for an internal cell $(i,j)$:\n$$\n(g_e + g_w + g_n + g_s)\\phi_{i,j} - g_e \\phi_{i+1,j} - g_w \\phi_{i-1,j} - g_n \\phi_{i,j+1} - g_s \\phi_{i,j-1} = 0\n$$\n\n**Boundary Conditions:**\n1.  **Neumann (No-Flux) at $y=0$ and $y=1$**: For cells at the bottom boundary ($j=0$), the flux across the south face is zero, so $I_s=0$, which implies $g_s=0$. Similarly, for cells at the top boundary ($j=N-1$), $I_n=0$ and thus $g_n=0$.\n\n2.  **Dirichlet (Fixed Potential) at $x=0$ and $x=1$**: For a cell $(0,j)$ at the left boundary, the potential is fixed at $\\phi(x=0) = \\phi_L = 0\\,\\mathrm{V}$. The distance from the cell center to the boundary is $h/2$. The current from the boundary into the cell is approximated as:\n    $$\n    I_w = -k_{0,j} A_w \\frac{\\phi_{0,j} - \\phi_L}{h/2} = -k_{0,j} h \\frac{\\phi_{0,j} - 0}{h/2} = -2 k_{0,j} \\phi_{0,j}\n    $$\n    The corresponding westward conductance is $g_w = 2k_{0,j}$. The equation for cell $(0,j)$ includes this known boundary potential, which is zero.\n    For a cell $(N-1,j)$ at the right boundary, the potential is fixed at $\\phi(x=1) = \\phi_R = 1\\,\\mathrm{V}$. The eastward conductance is similarly $g_e = 2k_{N-1,j}$. The current flowing out to the boundary is $I_e = g_e(\\phi_{N-1,j} - \\phi_R)$. The equation for cell $(N-1,j)$ becomes:\n    $$\n    (g_e + g_w + g_n + g_s)\\phi_{N-1,j} - g_w \\phi_{N-2,j} - g_n \\phi_{N-1,j+1} - g_s \\phi_{N-1,j-1} = g_e \\phi_R = g_e\n    $$\n    This introduces a non-zero source term on the right-hand side of the linear system.\n\n**System of Equations and Solution:**\nAssembling the equations for all $N \\times N$ cells results in a large, sparse system of linear equations of the form $M\\mathbf{\\Phi} = \\mathbf{b}$, where $\\mathbf{\\Phi}$ is the vector of unknown cell potentials $\\phi_{i,j}$. The matrix $M$ is diagonally dominant and symmetric, guaranteeing a unique solution. We construct $M$ and $\\mathbf{b}$ and solve for $\\mathbf{\\Phi}$ using a sparse linear algebra solver.\n\n**Calculation of Effective Conductivity $K^{\\text{eff}}$:**\nAfter solving for the potential field $\\mathbf{\\Phi}$, we compute the total current $I$ flowing through the domain. By conservation, the current entering at $x=0$ equals the current exiting at $x=1$. We calculate the total current exiting through the right boundary:\n$$\nI = \\sum_{j=0}^{N-1} I_{e,j} = \\sum_{j=0}^{N-1} g_{e,j} (\\phi_R - \\phi_{N-1,j}) = \\sum_{j=0}^{N-1} 2 k_{N-1,j} (1 - \\phi_{N-1,j})\n$$\nThe problem defines $K^{\\text{eff}}$ via $I = K^{\\text{eff}} A \\frac{\\Delta \\phi}{L_x}$. Given $A=1\\,\\mathrm{m}^2$, $L_x=1\\,\\mathrm{m}$, and $\\Delta\\phi=1\\,\\mathrm{V}$, this simplifies to $K^{\\text{eff}} = I$. Thus, the effective conductivity is numerically equal to the total current computed above. For a uniform medium with conductivity $k_{\\text{uni}}$, the analytical solution is $\\phi(x)=x$, and our FVM scheme exactly recovers $K^{\\text{eff}} = k_{\\text{uni}}$, serving as a robust verification of the method.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.sparse import lil_matrix\nfrom scipy.sparse.linalg import spsolve\n\ndef generate_k_map(N, case_params):\n    \"\"\"\n    Generates the conductivity map k(x, y) for a given microstructure.\n    \"\"\"\n    h = 1.0 / N\n    x = np.linspace(h / 2, 1.0 - h / 2, N)\n    y = np.linspace(h / 2, 1.0 - h / 2, N)\n    xx, yy = np.meshgrid(x, y)\n\n    case_type = case_params['type']\n    \n    if case_type == 'circle':\n        k_in = case_params['k_in']\n        k_out = case_params['k_out']\n        center = case_params['center']\n        radius = case_params['radius']\n        mask = (xx - center[0])**2 + (yy - center[1])**2  radius**2\n        k_map = np.full((N, N), k_out)\n        k_map[mask] = k_in\n    elif case_type == 'stripe':\n        k_stripe = case_params['k_stripe']\n        k_matrix = case_params['k_matrix']\n        x_range = case_params['x_range']\n        mask = (xx >= x_range[0])  (xx = x_range[1])\n        k_map = np.full((N, N), k_matrix)\n        k_map[mask] = k_stripe\n    elif case_type == 'uniform':\n        k_uni = case_params['k_uni']\n        k_map = np.full((N, N), k_uni)\n    else:\n        raise ValueError(\"Unknown case type\")\n        \n    return k_map\n\ndef compute_Keff(N, k_map):\n    \"\"\"\n    Computes the effective conductivity of a microstructure using FVM.\n    \"\"\"\n    num_vars = N * N\n    M = lil_matrix((num_vars, num_vars))\n    b = np.zeros(num_vars)\n\n    # Flatten conductivity map for easier indexing\n    k_flat = k_map.flatten(order='C') # Row-major\n\n    for j in range(N):\n        for i in range(N):\n            p = j * N + i  # Linear index for cell (i, j)\n            k_center = k_map[j, i]\n            \n            # Diagonal term accumulator\n            diag_sum = 0.0\n            \n            # South neighbor (j-1)\n            if j > 0:\n                k_s = k_map[j-1, i]\n                g_s = (2.0 * k_center * k_s) / (k_center + k_s)\n                M[p, p - N] = g_s\n                diag_sum += g_s\n            # else: no-flux (gs=0)\n            \n            # North neighbor (j+1)\n            if j  N - 1:\n                k_n = k_map[j+1, i]\n                g_n = (2.0 * k_center * k_n) / (k_center + k_n)\n                M[p, p + N] = g_n\n                diag_sum += g_n\n            # else: no-flux (gn=0)\n            \n            # West neighbor (i-1)\n            if i > 0:\n                k_w = k_map[j, i-1]\n                g_w = (2.0 * k_center * k_w) / (k_center + k_w)\n                M[p, p - 1] = g_w\n                diag_sum += g_w\n            else: # i=0, Dirichlet boundary phi=0\n                g_w = 2.0 * k_center\n                diag_sum += g_w\n                # Source term is g_w * phi_L = g_w * 0 = 0\n            \n            # East neighbor (i+1)\n            if i  N - 1:\n                k_e = k_map[j, i+1]\n                g_e = (2.0 * k_center * k_e) / (k_center + k_e)\n                M[p, p + 1] = g_e\n                diag_sum += g_e\n            else: # i=N-1, Dirichlet boundary phi=1\n                g_e = 2.0 * k_center\n                diag_sum += g_e\n                b[p] = -g_e * 1.0\n            \n            M[p, p] = -diag_sum\n\n    # Solve the linear system\n    M_csc = M.tocsc()\n    phi_vec = spsolve(M_csc, b)\n    phi_map = phi_vec.reshape((N, N))\n\n    # Calculate total current and K_eff\n    k_right_boundary = k_map[:, N-1]\n    phi_right_boundary = phi_map[:, N-1]\n    \n    # I = sum(g_e * (phi_R - phi_cell)) = sum(2*k * (1 - phi))\n    # With L=1, A=1, dPhi=1, K_eff = I\n    K_eff = np.sum(2.0 * k_right_boundary * (1.0 - phi_right_boundary))\n    \n    return K_eff\n\ndef solve():\n    test_suite = [\n        {\n            'params': {'type': 'circle', 'k_in': 12.0, 'k_out': 0.5, 'center': (0.5, 0.5), 'radius': 0.3},\n            'resolutions': [16, 32, 64],\n            'ref_resolution': 128\n        },\n        {\n            'params': {'type': 'stripe', 'k_stripe': 50.0, 'k_matrix': 1.0, 'x_range': [0.4, 0.6]},\n            'resolutions': [16, 32, 64],\n            'ref_resolution': 128\n        },\n        {\n            'params': {'type': 'uniform', 'k_uni': 3.0},\n            'resolutions': [8, 16, 32],\n            'ref_resolution': 128\n        }\n    ]\n\n    all_results = []\n\n    for test_case in test_suite:\n        params = test_case['params']\n        resolutions = test_case['resolutions']\n        N_ref = test_case['ref_resolution']\n        \n        # Compute reference solution\n        k_map_ref = generate_k_map(N_ref, params)\n        K_eff_ref = compute_Keff(N_ref, k_map_ref)\n        \n        case_results = [K_eff_ref]\n        \n        # Compute for other resolutions and calculate errors\n        for N in resolutions:\n            k_map = generate_k_map(N, params)\n            K_eff = compute_Keff(N, k_map)\n            error = abs(K_eff - K_eff_ref)\n            case_results.extend([K_eff, error])\n            \n        all_results.append(case_results)\n\n    # Format output as a list of lists of floats\n    print(all_results)\n\nsolve()\n```"
        },
        {
            "introduction": "Moving from prediction to inference, this practice tackles a real-world inverse problem: extracting microstructural properties from experimental-like data. You will use synthetic Electrochemical Impedance Spectroscopy (EIS) data to recover the underlying Distribution of Relaxation Times (DRT) through a sparse, regularized inversion. This exercise demonstrates how to bridge macroscopic measurements with latent physical processes, ultimately allowing you to estimate the electrode's tortuosityâ€”a key parameter for battery performance .",
            "id": "3921846",
            "problem": "You are asked to implement an inverse design routine that recovers a sparse Distribution of Relaxation Times (DRT) for electrochemical impedance data and then maps the recovered dominant diffusion time constant to microstructural tortuosity and porosity in a porous battery electrode. The Distribution of Relaxation Times (DRT) represents the imaginary part of the impedance response as a superposition of standard relaxation kernels. The goal is to recover a sparse DRT from synthetic impedance data and use the recovered time constants to estimate tortuosity under different porosities.\n\nThe base physics and definitions are as follows:\n- Electrode processes measured by Electrochemical Impedance Spectroscopy (EIS) can be represented by a distribution of characteristic relaxation times. The imaginary part of the impedance response is modeled by\n$$\nZ''(\\omega) = \\int_{-\\infty}^{+\\infty} \\gamma(\\tau) \\, \\frac{\\omega \\tau}{1 + (\\omega \\tau)^2} \\, d\\ln \\tau,\n$$\nwhere $Z''(\\omega)$ is the imaginary part of the impedance at angular frequency $\\omega$, $\\gamma(\\tau)$ is a nonnegative measure describing the DRT amplitude at relaxation time $\\tau$, and $\\frac{\\omega \\tau}{1 + (\\omega \\tau)^2}$ is the standard kernel for a first-order process. We restrict ourselves to nonnegative $\\gamma(\\tau)$ consistent with passive, dissipative processes.\n- Under homogenization and effective medium theory for porous media, the effective diffusivity $D_{\\text{eff}}$ is related to the bulk diffusivity $D$, porosity $\\varepsilon$ (dimensionless fraction), and tortuosity $\\mathcal{T}$ (dimensionless) by\n$$\nD_{\\text{eff}} = \\frac{D \\, \\varepsilon}{\\mathcal{T}}.\n$$\n- The dominant diffusion-related relaxation time $\\tau_{\\text{diff}}$ for transport across an electrode of thickness $L$ obeys the scaling\n$$\n\\tau_{\\text{diff}} \\approx \\frac{L^2}{D_{\\text{eff}}} = \\frac{L^2 \\, \\mathcal{T}}{D \\, \\varepsilon}.\n$$\nThus, an estimate of tortuosity from a recovered diffusion time constant is\n$$\n\\widehat{\\mathcal{T}} = \\frac{\\tau_{\\text{diff}} \\, D \\, \\varepsilon}{L^2}.\n$$\n\nDiscretize the inverse problem for the DRT on a uniform grid in $\\ln \\tau$. Let $\\{\\tau_j\\}_{j=1}^{N_\\tau}$ be the grid of relaxation times in seconds and $\\{\\omega_i\\}_{i=1}^{N_\\omega}$ the angular frequencies in radians per second. Define the linear operator matrix $K \\in \\mathbb{R}^{N_\\omega \\times N_\\tau}$ with entries\n$$\nK_{ij} = \\frac{\\omega_i \\tau_j}{1 + (\\omega_i \\tau_j)^2}.\n$$\nGiven data $y_i = Z''(\\omega_i)$, solve the convex optimization for the discretized DRT amplitudes $\\gamma \\in \\mathbb{R}^{N_\\tau}$:\n$$\n\\min_{\\gamma \\ge 0} \\; \\frac{1}{2} \\left\\| K \\gamma - y \\right\\|_2^2 + \\lambda \\left\\| \\gamma \\right\\|_1,\n$$\nwhere $\\lambda  0$ promotes sparsity. Implement a proximal gradient (Iterative Soft-Thresholding Algorithm) scheme with nonnegativity projection to solve this problem.\n\nAfter recovering $\\gamma$, detect peaks and select the dominant diffusion-related time constant $\\tau_{\\text{diff}}$ as the largest relaxation time among detected peaks. Use this to estimate the tortuosity via\n$$\n\\widehat{\\mathcal{T}} = \\frac{\\tau_{\\text{diff}} \\, D \\, \\varepsilon}{L^2}.\n$$\n\nUnits and precision requirements:\n- All relaxation times $\\tau$ must be in seconds.\n- Frequency inputs are in Hertz; convert to angular frequency in radians per second via $\\omega = 2\\pi f$.\n- Thickness $L$ must be in meters, bulk diffusivity $D$ in $\\mathrm{m}^2/\\mathrm{s}$, porosity $\\varepsilon$ and tortuosity $\\mathcal{T}$ are dimensionless.\n- The output tortuosity estimates must be expressed as floating-point values (no percentage sign).\n\nTest suite specification:\nYou must generate synthetic $Z''(\\omega)$ by summing a small number of idealized DRT peaks at known time constants and amplitudes:\n$$\nZ''(\\omega) = \\sum_{k=1}^{K} a_k \\frac{\\omega \\tau_k}{1 + (\\omega \\tau_k)^2},\n$$\nwith $a_k \\ge 0$ and $\\tau_k  0$. Add independent zero-mean Gaussian noise with standard deviation equal to $0.005$ times the maximum magnitude of $Z''(\\omega)$ in each test case to simulate measurement noise.\n\nUse a uniform logarithmic frequency grid $f \\in [10^{-5}, 10^{3}]$ Hertz with $N_\\omega = 60$ points for all test cases. Use a DRT grid with $N_\\tau = 200$ points over $\\tau \\in [10^{-4}, 10^{5}]$ seconds, uniform in $\\ln \\tau$.\n\nProvide three test cases:\n\n- Case A (general case):\n    - $L = 100 \\times 10^{-6}$ meters, $\\varepsilon = 0.4$, $D = 1 \\times 10^{-10}$ $\\mathrm{m}^2/\\mathrm{s}$.\n    - True tortuosity $\\mathcal{T}_{\\text{true}} = 2.5$.\n    - Diffusion time constant $\\tau_{\\text{diff,true}} = \\dfrac{L^2 \\mathcal{T}_{\\text{true}}}{D \\varepsilon}$.\n    - Peaks: $(\\tau, a)$ equal to $(1, 0.3)$, $(\\tau_{\\text{diff,true}}, 0.5)$, and $(50, 0.1)$.\n\n- Case B (high porosity):\n    - $L = 100 \\times 10^{-6}$ meters, $\\varepsilon = 0.8$, $D = 1 \\times 10^{-10}$ $\\mathrm{m}^2/\\mathrm{s}$.\n    - True tortuosity $\\mathcal{T}_{\\text{true}} = 1.5$.\n    - Diffusion time constant $\\tau_{\\text{diff,true}} = \\dfrac{L^2 \\mathcal{T}_{\\text{true}}}{D \\varepsilon}$.\n    - Peaks: $(\\tau, a)$ equal to $(0.8, 0.25)$, $(\\tau_{\\text{diff,true}}, 0.5)$, and $(30, 0.15)$.\n\n- Case C (low porosity, thicker electrode, long-time edge case):\n    - $L = 150 \\times 10^{-6}$ meters, $\\varepsilon = 0.2$, $D = 1 \\times 10^{-10}$ $\\mathrm{m}^2/\\mathrm{s}$.\n    - True tortuosity $\\mathcal{T}_{\\text{true}} = 4.0$.\n    - Diffusion time constant $\\tau_{\\text{diff,true}} = \\dfrac{L^2 \\mathcal{T}_{\\text{true}}}{D \\varepsilon}$.\n    - Peaks: $(\\tau, a)$ equal to $(2, 0.3)$, $(\\tau_{\\text{diff,true}}, 0.6)$, and $(70, 0.1)$.\n\nYour program must:\n- Construct the kernel matrix $K$, synthesize $Z''(\\omega)$ with noise for each case, solve the sparse inversion with the stated constraints using proximal gradient iterations, detect peaks of the recovered $\\gamma(\\tau)$, select the largest detected $\\tau$ as $\\tau_{\\text{diff}}$, and compute $\\widehat{\\mathcal{T}}$ for each case using the formula above.\n- Use a regularization strength $\\lambda$ that scales with the problem, for example based on the infinity norm of $K^\\top y$, and a step size based on the Lipschitz constant of the gradient (the spectral norm of $K^\\top K$).\n- Ensure reproducibility by using a fixed random seed for noise generation.\n\nFinal output format:\nYour program should produce a single line of output containing the estimated tortuosities for the three test cases as a comma-separated list enclosed in square brackets, in the order Case A, Case B, Case C. For example, the output must look like\n$$\n[\\widehat{\\mathcal{T}}_{\\mathrm{A}},\\widehat{\\mathcal{T}}_{\\mathrm{B}},\\widehat{\\mathcal{T}}_{\\mathrm{C}}].\n$$\nEach entry must be a floating-point value.",
            "solution": "The problem presented is valid. It is a scientifically grounded, well-posed, and objective problem in the domain of computational materials science and electrochemistry. It asks for the implementation of an inverse design workflow to estimate a key microstructural parameter of a battery electrode, the tortuosity $\\mathcal{T}$, from synthetic electrochemical impedance spectroscopy (EIS) data. The approach is based on the recovery of the Distribution of Relaxation Times (DRT) and its connection to physical transport phenomena. All required physical models, mathematical formulations, numerical parameters, and test cases are provided, forming a complete and consistent specification.\n\nThe solution is developed by following a sequence of steps derived from first principles. First, we establish the physical and mathematical models connecting the measurable impedance data to the underlying material properties. Second, we formulate the inverse problem of recovering the DRT. Third, we detail the numerical algorithm used to solve this inverse problem. Finally, we describe the process of extracting the target physical parameter from the numerical solution.\n\nThe fundamental physical model is the representation of the imaginary part of the impedance, $Z''(\\omega)$, as an integral over a Distribution of Relaxation Times, $\\gamma(\\tau)$. This is expressed as:\n$$\nZ''(\\omega) = \\int_{-\\infty}^{+\\infty} \\gamma(\\tau) \\, K(\\omega, \\tau) \\, d\\ln \\tau, \\quad \\text{with } K(\\omega, \\tau) = \\frac{\\omega \\tau}{1 + (\\omega \\tau)^2}\n$$\nHere, $\\omega$ is the angular frequency, $\\tau$ is the relaxation time, and the kernel $K(\\omega, \\tau)$ represents the response of a single, first-order Debye relaxation process. The function $\\gamma(\\tau)$ is a non-negative distribution that quantifies the contribution of processes occurring at the characteristic time $\\tau$.\n\nThe connection to the electrode microstructure is made through the dominant diffusion process. For a porous electrode of thickness $L$, the effective diffusivity $D_{\\text{eff}}$ of the active species is related to its bulk diffusivity $D$, the electrode porosity $\\varepsilon$, and the tortuosity $\\mathcal{T}$ via the effective medium relation:\n$$\nD_{\\text{eff}} = \\frac{D \\varepsilon}{\\mathcal{T}}\n$$\nThe tortuosity $\\mathcal{T}$ is a dimensionless factor greater than or equal to $1$ that accounts for the convoluted path that ions must take through the porous structure, making the effective path length longer than the electrode thickness. The characteristic time scale for diffusion across this thickness, $\\tau_{\\text{diff}}$, is given by the scaling law:\n$$\n\\tau_{\\text{diff}} \\approx \\frac{L^2}{D_{\\text{eff}}} = \\frac{L^2 \\mathcal{T}}{D \\varepsilon}\n$$\nBy inverting this relationship, we can obtain an estimate for the tortuosity, $\\widehat{\\mathcal{T}}$, if we can determine $\\tau_{\\text{diff}}$ from the impedance data:\n$$\n\\widehat{\\mathcal{T}} = \\frac{\\tau_{\\text{diff}} D \\varepsilon}{L^2}\n$$\nThe core of the problem lies in recovering $\\gamma(\\tau)$ from a discrete set of noisy measurements of $Z''(\\omega)$. This is a classic ill-posed inverse problem. To address this, we first discretize the integral equation. We define a grid of $N_\\omega$ angular frequencies $\\{\\omega_i\\}_{i=1}^{N_\\omega}$ and a grid of $N_\\tau$ relaxation times $\\{\\tau_j\\}_{j=1}^{N_\\tau}$ (uniform in the logarithmic domain). The measurements are $y_i = Z''(\\omega_i)$, and we seek the discrete DRT amplitudes $\\gamma_j = \\gamma(\\tau_j)$. This transforms the integral equation into a linear system of equations:\n$$\ny \\approx K \\gamma\n$$\nwhere $y \\in \\mathbb{R}^{N_\\omega}$, $\\gamma \\in \\mathbb{R}^{N_\\tau}$, and $K \\in \\mathbb{R}^{N_\\omega \\times N_\\tau}$ is the kernel matrix with entries $K_{ij} = \\frac{\\omega_i \\tau_j}{1 + (\\omega_i \\tau_j)^2}$.\n\nDue to the ill-posed nature of the problem, a naive least-squares solution would be highly unstable and dominated by noise. We introduce regularization to obtain a stable and physically meaningful solution. The problem specifies an L1-norm penalty, which promotes a sparse solution for $\\gamma$. This reflects the physical intuition that the electrochemical response is often dominated by a few distinct processes. The non-negativity of physical dissipation rates requires the constraint $\\gamma_j \\ge 0$. The resulting optimization problem is a non-negative LASSO problem:\n$$\n\\min_{\\gamma \\ge 0} \\; \\frac{1}{2} \\left\\| K \\gamma - y \\right\\|_2^2 + \\lambda \\left\\| \\gamma \\right\\|_1\n$$\nwhere $\\lambda  0$ is the regularization parameter that balances data fidelity against sparsity.\n\nThis convex optimization problem is solved using a proximal gradient method, specifically the Iterative Soft-Thresholding Algorithm (ISTA). The algorithm iteratively performs a gradient descent step on the least-squares term followed by a proximal mapping step that enforces sparsity and non-negativity. The update rule at each iteration $k$ is composed of two steps:\n1.  **Gradient descent step:** Compute an intermediate variable $z^{(k)}$ by taking a step in the negative gradient direction of the data-fidelity term:\n    $$ z^{(k)} = \\gamma^{(k)} - \\alpha K^\\top(K\\gamma^{(k)} - y) $$\n    where $\\alpha$ is the step size.\n2.  **Proximal mapping step:** Apply the proximal operator for the combined L1-norm and non-negativity constraints to $z^{(k)}$ to get the updated solution:\n    $$ \\gamma^{(k+1)} = \\max\\left(0, z^{(k)} - \\alpha\\lambda\\right) $$\nThe step size $\\alpha$ is chosen to ensure convergence, typically $\\alpha \\le 1/L$, where $L$ is the Lipschitz constant of the gradient $\\nabla f$. This constant is the maximum eigenvalue of $K^\\top K$, which is equal to the squared maximum singular value of $K$, $L = \\sigma_{\\text{max}}(K)^2$. The regularization parameter $\\lambda$ is scaled with the data, specifically $\\lambda \\propto \\|K^\\top y\\|_{\\infty}$, to adapt to different problem scales.\n\nAfter a sufficient number of iterations, the algorithm converges to a sparse, non-negative vector $\\gamma$. From this recovered DRT, we identify the peaks. According to the problem specification, the largest relaxation time $\\tau$ corresponding to a detected peak is identified as the diffusion time constant, $\\tau_{\\text{diff}}$. This estimated $\\tau_{\\text{diff}}$ is then used in the final step to compute the tortuosity estimate $\\widehat{\\mathcal{T}}$. The entire procedure is applied to three distinct test cases with varying physical parameters, and the resulting tortuosity estimates are reported.",
            "answer": "```python\nimport numpy as np\nfrom scipy.signal import find_peaks\n\ndef inverse_design_tortuosity():\n    \"\"\"\n    Solves for electrode tortuosity from synthetic impedance data.\n\n    This function implements the full workflow described in the problem statement.\n    It iterates through three test cases, and for each case:\n    1. Generates synthetic noisy impedance data based on true physical parameters.\n    2. Constructs the DRT kernel matrix.\n    3. Solves the sparse, non-negative regularized inverse problem using ISTA\n       to recover the Distribution of Relaxation Times (DRT).\n    4. Identifies peaks in the recovered DRT.\n    5. Selects the diffusion time constant based on the specified rule.\n    6. Computes the estimated tortuosity.\n    Finally, it prints the results for all cases in the required format.\n    \"\"\"\n\n    # --- Global Parameters ---\n    # Grids\n    N_FREQ = 60\n    N_TAU = 200\n    FREQ_MIN, FREQ_MAX = 1e-5, 1e3  # Hz\n    TAU_MIN, TAU_MAX = 1e-4, 1e5    # s\n\n    # Algorithm parameters\n    ISTA_ITERATIONS = 2000\n    LAMBDA_SCALE_FACTOR = 0.02\n    PEAK_HEIGHT_RATIO = 0.05\n\n    # Reproducibility\n    RANDOM_SEED = 42\n    np.random.seed(RANDOM_SEED)\n\n    # --- Grid Setup ---\n    # Frequencies (f in Hz, omega in rad/s)\n    f_grid = np.logspace(np.log10(FREQ_MIN), np.log10(FREQ_MAX), N_FREQ)\n    omega_grid = 2 * np.pi * f_grid\n    \n    # Relaxation times (tau in s)\n    tau_grid = np.logspace(np.log10(TAU_MIN), np.log10(TAU_MAX), N_TAU)\n\n    # --- Test Cases ---\n    test_cases = [\n        {\n            \"name\": \"Case A (general)\",\n            \"L\": 100e-6, \"epsilon\": 0.4, \"D\": 1e-10, \"T_true\": 2.5,\n            \"base_peaks\": [(1.0, 0.3), (50.0, 0.1)]\n        },\n        {\n            \"name\": \"Case B (high porosity)\",\n            \"L\": 100e-6, \"epsilon\": 0.8, \"D\": 1e-10, \"T_true\": 1.5,\n            \"base_peaks\": [(0.8, 0.25), (30.0, 0.15)]\n        },\n        {\n            \"name\": \"Case C (low porosity, thick)\",\n            \"L\": 150e-6, \"epsilon\": 0.2, \"D\": 1e-10, \"T_true\": 4.0,\n            \"base_peaks\": [(2.0, 0.3), (70.0, 0.1)]\n        }\n    ]\n    \n    estimated_tortuosities = []\n\n    # --- Main Loop ---\n    for case in test_cases:\n        L, epsilon, D, T_true = case[\"L\"], case[\"epsilon\"], case[\"D\"], case[\"T_true\"]\n\n        # 1. Calculate true diffusion time and complete the peak list\n        tau_diff_true = (L**2 * T_true) / (D * epsilon)\n        true_peaks = case[\"base_peaks\"] + [(tau_diff_true, 0.5 if case[\"name\"] != \"Case C (low porosity, thick)\" else 0.6)]\n\n        # 2. Generate synthetic impedance data Z''\n        Z_imag_true = np.zeros_like(omega_grid)\n        for tau_k, a_k in true_peaks:\n            Z_imag_true += a_k * (omega_grid * tau_k) / (1 + (omega_grid * tau_k)**2)\n        \n        noise_std = 0.005 * np.max(np.abs(Z_imag_true))\n        noise = np.random.normal(0, noise_std, size=Z_imag_true.shape)\n        y = Z_imag_true + noise\n\n        # 3. Construct kernel matrix K\n        K = (omega_grid[:, np.newaxis] * tau_grid[np.newaxis, :]) / \\\n            (1 + (omega_grid[:, np.newaxis] * tau_grid[np.newaxis, :])**2)\n\n        # 4. Set ISTA hyperparameters\n        # Step size (alpha) based on Lipschitz constant\n        s_max = np.linalg.svd(K, compute_uv=False)[0]\n        lipschitz_const = s_max**2\n        alpha = 1.0 / lipschitz_const\n        \n        # Regularization parameter (lambda) scaled by data\n        lambda_reg = LAMBDA_SCALE_FACTOR * np.linalg.norm(K.T @ y, ord=np.inf)\n\n        # 5. Solve for DRT (gamma) using ISTA\n        gamma = np.zeros(N_TAU)\n        for _ in range(ISTA_ITERATIONS):\n            grad = K.T @ (K @ gamma - y)\n            z = gamma - alpha * grad\n            gamma = np.maximum(z - alpha * lambda_reg, 0)\n        \n        # 6. Peak detection in the recovered DRT\n        peak_height_threshold = PEAK_HEIGHT_RATIO * np.max(gamma)\n        peak_indices, _ = find_peaks(gamma, height=peak_height_threshold)\n        \n        if len(peak_indices) == 0:\n            # Fallback if no peaks are detected (unlikely but robust)\n            # Use the tau corresponding to the max gamma value\n            tau_diff_est = tau_grid[np.argmax(gamma)]\n        else:\n            # 7. Select largest relaxation time among detected peaks\n            detected_taus = tau_grid[peak_indices]\n            tau_diff_est = np.max(detected_taus)\n\n        # 8. Compute estimated tortuosity\n        T_hat = (tau_diff_est * D * epsilon) / (L**2)\n        estimated_tortuosities.append(T_hat)\n\n    # --- Final Output ---\n    print(f\"[{','.join([f'{val:.6f}' for val in estimated_tortuosities])}]\")\n\nif __name__ == '__main__':\n    inverse_design_tortuosity()\n```"
        },
        {
            "introduction": "The predictive power of our computational models depends critically on their accuracy. This final practice addresses the ubiquitous challenge of finite-size effects, where simulations on limited domain sizes introduce systematic bias. You will apply principles of finite-size scaling and statistical model selection to quantify this bias in tortuosity calculations and extrapolate your results to the infinite-domain limit. Mastering this skill is essential for ensuring that your computational predictions are reliable and representative of bulk material behavior .",
            "id": "3921820",
            "problem": "Consider the inverse design of porous electrode microstructures for target transport properties in automated battery design and simulation. Let the tortuosity, denoted by $\\tau$, be defined for an isotropic medium as the dimensionless ratio $\\tau = D_0 / D_{\\mathrm{eff}}$, where $D_0$ is the reference free-space diffusivity and $D_{\\mathrm{eff}}$ is the effective diffusivity obtained by homogenizing the steady-state diffusion equation $-\\nabla \\cdot (D(\\mathbf{x}) \\nabla c) = 0$ over a representative volume element. In practice, $\\tau$ is estimated on finite samples of linear size $L$ using periodic boundary conditions and spatially averaging fluxes, which introduces a finite-size bias. Under standard mixing and ergodicity assumptions for stationary random media, the bias in $\\tau(L)$ admits a leading-order algebraic decay in $L$ due to the truncation of long-range correlations at the sample boundary.\n\nStarting from this fundamental base, assume the following asymptotic measurement model for the tortuosity estimator on a cubic sample of size $L$:\n$$\n\\tau(L) = \\tau_\\infty + c\\,L^{-p} + \\varepsilon,\n$$\nwhere $\\tau_\\infty$ is the infinite-domain tortuosity (the target quantity for inverse design), $c$ is an unknown coefficient, $p  0$ is an unknown exponent determined by correlation decay and boundary conditions, and $\\varepsilon$ is a zero-mean stochastic error representing numerical solver noise and sample-to-sample fluctuations, modeled as independent and identically distributed Gaussian random variables with standard deviation $\\sigma$. All tortuosities and $\\sigma$ are dimensionless; lengths $L$ are in the same arbitrary but consistent length unit.\n\nYour task is to design a principled estimator and extrapolation procedure for $\\tau_\\infty$ and to quantify the finite-size error, using only the assumptions stated above and first principles from homogenization and statistical estimation. Specifically, implement the following steps for each test case:\n\n- Generate synthetic measurements $\\tau(L_i)$ at prescribed sizes $L_i$ from the model $\\tau(L_i) = \\tau_\\infty + c\\,L_i^{-p} + \\varepsilon_i$, where $\\varepsilon_i \\sim \\mathcal{N}(0,\\sigma^2)$, using the provided random seed for reproducibility.\n- For model selection, consider the candidate set of exponents $\\mathcal{P} = \\{1.0, 1.5, 2.0\\}$. For each $p \\in \\mathcal{P}$, fit the linear regression model $\\tau(L) = a + b\\,L^{-p}$ by ordinary least squares to estimate $(a,b)$ from the measured pairs $(L_i, \\tau(L_i))$. Denote the residual sum of squares by $\\mathrm{RSS}(p)$. Select $\\hat{p}$ by minimizing the Bayesian Information Criterion (BIC):\n$$\n\\mathrm{BIC}(p) = n \\ln\\!\\left(\\frac{\\mathrm{RSS}(p)}{n}\\right) + k \\ln(n),\n$$\nwith $n$ equal to the number of measurements and $k = 2$ equal to the number of fitted parameters in $(a,b)$.\n- The extrapolated infinite-domain tortuosity estimate is $\\widehat{\\tau}_\\infty = \\hat{a}$, the intercept corresponding to $\\hat{p}$. The estimated finite-size bias at size $L$ is $\\widehat{\\mathrm{bias}}(L) = \\hat{b}\\,L^{-\\hat{p}}$.\n- Quantify the finite-size error across the provided sizes by the root-mean-square finite-size bias\n$$\n\\mathrm{RMSB} = \\sqrt{\\frac{1}{n}\\sum_{i=1}^{n} \\left(\\hat{b}\\,L_i^{-\\hat{p}}\\right)^2 }.\n$$\n- Compute the minimal sample size $L_\\star$ that ensures $|\\widehat{\\mathrm{bias}}(L_\\star)| \\le \\varepsilon_{\\mathrm{tol}}$ for a given tolerance $\\varepsilon_{\\mathrm{tol}}$:\n$$\nL_\\star = \n\\begin{cases}\n0,  \\text{if } \\hat{b} = 0,\\\\\n\\left(\\dfrac{|\\hat{b}|}{\\varepsilon_{\\mathrm{tol}}}\\right)^{1/\\hat{p}},  \\text{otherwise}.\n\\end{cases}\n$$\nExpress $L_\\star$ in the same length unit as the inputs.\n\n- For evaluation on synthetic data, also report the absolute estimation error $|\\widehat{\\tau}_\\infty - \\tau_\\infty|$ using the ground-truth $\\tau_\\infty$ provided in each test case.\n\nYour program must implement the full pipeline above and produce, for each test case, a list containing:\n$[\\widehat{\\tau}_\\infty,\\ |\\widehat{\\tau}_\\infty - \\tau_\\infty|,\\ \\hat{p},\\ \\mathrm{RMSB},\\ L_\\star]$.\n\nTest suite and data generation details:\n\n- For each test case, use the specified parameters $(\\tau_\\infty, c, p, \\sigma, \\{L_i\\}, \\varepsilon_{\\mathrm{tol}}, \\text{seed})$ as given below, and generate $\\tau(L_i)$ with the formula $\\tau(L_i) = \\tau_\\infty + c\\,L_i^{-p} + \\varepsilon_i$, with $\\varepsilon_i \\overset{\\mathrm{iid}}{\\sim} \\mathcal{N}(0,\\sigma^2)$ and the random number generator seeded by the provided seed.\n\n- Test case $1$ (general case with moderate finite-size effect and moderate noise):\n  - $\\tau_\\infty = 2.0$\n  - $c = 20.0$\n  - $p = 1.5$\n  - $\\sigma = 0.02$\n  - $\\{L_i\\} = [50.0, 75.0, 100.0, 150.0, 200.0]$\n  - $\\varepsilon_{\\mathrm{tol}} = 0.01$\n  - $\\text{seed} = 12345$\n\n- Test case $2$ (small finite-size effect dominated by measurement noise):\n  - $\\tau_\\infty = 1.75$\n  - $c = 0.5$\n  - $p = 2.0$\n  - $\\sigma = 0.01$\n  - $\\{L_i\\} = [30.0, 40.0, 60.0, 90.0]$\n  - $\\varepsilon_{\\mathrm{tol}} = 0.005$\n  - $\\text{seed} = 24680$\n\n- Test case $3$ (strong finite-size effect with a slow $L^{-1}$ decay):\n  - $\\tau_\\infty = 3.2$\n  - $c = 12.0$\n  - $p = 1.0$\n  - $\\sigma = 0.05$\n  - $\\{L_i\\} = [20.0, 30.0, 50.0, 80.0]$\n  - $\\varepsilon_{\\mathrm{tol}} = 0.02$\n  - $\\text{seed} = 13579$\n\nFinal output format:\n\n- Your program should produce a single line of output containing a list of per-test-case results, where each per-test-case result is a list $[\\widehat{\\tau}_\\infty,\\ |\\widehat{\\tau}_\\infty - \\tau_\\infty|,\\ \\hat{p},\\ \\mathrm{RMSB},\\ L_\\star]$. For example, the output format should be like $[[x_1,y_1,z_1,u_1,v_1],[x_2,y_2,z_2,u_2,v_2],[x_3,y_3,z_3,u_3,v_3]]$ with all entries as decimals. All tortuosities and $\\sigma$ are dimensionless; $L_\\star$ is reported in the same length unit as the input $L_i$ values. Angles are not used. Do not include a percentage sign anywhere; any proportion such as a confidence level must be written as a decimal.",
            "solution": "The problem presented is a well-posed and scientifically grounded exercise in data analysis, specifically addressing the estimation of physical properties from finite-size computational experiments. The context is the inverse design of battery electrodes, where the bulk (infinite-domain) tortuosity $\\tau_\\infty$ of a porous microstructure is a critical transport property. We are tasked with estimating $\\tau_\\infty$ from a series of simulated measurements $\\tau(L_i)$ performed on samples of finite linear size $L_i$. These measurements are subject to both systematic finite-size bias and random noise.\n\nThe problem provides an asymptotic model for the measured tortuosity:\n$$\n\\tau(L) = \\tau_\\infty + c\\,L^{-p} + \\varepsilon\n$$\nHere, $\\tau_\\infty$ is the true property we seek. The term $c\\,L^{-p}$ represents the leading-order finite-size bias, which decays algebraically with system size $L$. The exponent $p  0$ depends on the nature of spatial correlations in the medium. The term $\\varepsilon$ is a zero-mean Gaussian random variable, $\\varepsilon \\sim \\mathcal{N}(0, \\sigma^2)$, accounting for numerical noise and statistical fluctuations between different samples of the same size.\n\nOur objective is to devise a procedure to estimate $\\tau_\\infty$ by fitting this model to synthetic data and to quantify associated errors and scaling behaviors. The core challenge lies in the fact that both the coefficients $(\\tau_\\infty, c)$ and the exponent $p$ are unknown. The prescribed methodology involves a model selection step to determine the most plausible exponent from a candidate set $\\mathcal{P} = \\{1.0, 1.5, 2.0\\}$.\n\nThe procedure consists of the following steps for each provided test case.\n\nFirst, we generate synthetic measurement data. For a given set of ground-truth parameters $(\\tau_\\infty, c, p, \\sigma)$, a set of sample sizes $\\{L_i\\}_{i=1}^n$, and a random seed for reproducibility, we compute the measured tortuosity values:\n$$\n\\tau(L_i) = \\tau_\\infty + c\\,L_i^{-p} + \\varepsilon_i\n$$\nwhere each $\\varepsilon_i$ is an independent draw from the normal distribution $\\mathcal{N}(0, \\sigma^2)$.\n\nSecond, we perform model selection. For each candidate exponent $p_j \\in \\mathcal{P}$, we linearize the model by defining a new independent variable $x_j = L^{-p_j}$. The model then takes the form of a simple linear equation:\n$$\n\\tau(L) = a + b\\,x_j\n$$\nwhere the intercept $a$ corresponds to $\\tau_\\infty$ (since $x_j \\to 0$ as $L \\to \\infty$) and the slope $b$ corresponds to the coefficient $c$. We fit this linear model to the data pairs $(x_{j,i}, \\tau(L_i))$ for $i=1, \\dots, n$ using the method of Ordinary Least Squares (OLS). OLS determines the parameters $(\\hat{a}_j, \\hat{b}_j)$ that minimize the Residual Sum of Squares ($\\mathrm{RSS}$):\n$$\n\\mathrm{RSS}(p_j) = \\sum_{i=1}^{n} \\left( \\tau(L_i) - (\\hat{a}_j + \\hat{b}_j L_i^{-p_j}) \\right)^2\n$$\nTo select the best exponent $\\hat{p}$ from the set $\\mathcal{P}$, we cannot simply choose the one with the lowest $\\mathrm{RSS}$, as this would favor more complex models. Instead, we use the Bayesian Information Criterion (BIC), which penalizes model complexity. The BIC for a model with candidate exponent $p_j$ is given by:\n$$\n\\mathrm{BIC}(p_j) = n \\ln\\!\\left(\\frac{\\mathrm{RSS}(p_j)}{n}\\right) + k \\ln(n)\n$$\nHere, $n$ is the number of data points, and $k=2$ is the number of fitted parameters ($a$ and $b$). The exponent $\\hat{p}$ that yields the minimum BIC is selected as the best model for the data.\n\nThird, with the optimal exponent $\\hat{p}$ identified, we obtain the final parameter estimates. The extrapolated infinite-domain tortuosity is $\\widehat{\\tau}_\\infty = \\hat{a}$, and the bias coefficient is $\\hat{b}$, both taken from the OLS fit corresponding to $\\hat{p}$.\n\nFourth, we quantify the errors and scaling behavior based on our selected model.\nThe absolute estimation error for our synthetic test case is $|\\widehat{\\tau}_\\infty - \\tau_\\infty|$, where $\\tau_\\infty$ is the known ground-truth value.\nThe estimated finite-size bias at a given size $L$ is $\\widehat{\\mathrm{bias}}(L) = \\hat{b}\\,L^{-\\hat{p}}$. To characterize the overall magnitude of this bias across the measurement sizes, we compute the Root-Mean-Square Bias (RMSB):\n$$\n\\mathrm{RMSB} = \\sqrt{\\frac{1}{n}\\sum_{i=1}^{n} \\left(\\widehat{\\mathrm{bias}}(L_i)\\right)^2} = \\sqrt{\\frac{1}{n}\\sum_{i=1}^{n} \\left(\\hat{b}\\,L_i^{-\\hat{p}}\\right)^2}\n$$\nFinally, we calculate the minimum sample size $L_\\star$ required to reduce the magnitude of the finite-size bias to a specified tolerance $\\varepsilon_{\\mathrm{tol}}$. This is found by solving $|\\widehat{\\mathrm{bias}}(L_\\star)| = \\varepsilon_{\\mathrm{tol}}$ for $L_\\star$:\n$$\n|\\hat{b}\\,L_\\star^{-\\hat{p}}| = \\varepsilon_{\\mathrm{tol}} \\implies L_\\star = \\left(\\frac{|\\hat{b}|}{\\varepsilon_{\\mathrm{tol}}}\\right)^{1/\\hat{p}}\n$$\nThis formula is valid for $\\hat{b} \\ne 0$; if $\\hat{b} = 0$, the estimated bias is zero for all sizes, so we define $L_\\star = 0$.\n\nThis comprehensive procedure allows for a principled extrapolation to the infinite-size limit and provides practical metrics for assessing and controlling finite-size errors in computational materials science. The implementation will follow these steps rigorously for each test case.",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to process all test cases and print the final results.\n    \"\"\"\n    # Test cases as specified in the problem statement.\n    test_cases = [\n        # case 1\n        {\n            \"tau_inf_true\": 2.0, \"c\": 20.0, \"p_true\": 1.5, \"sigma\": 0.02,\n            \"L_values\": [50.0, 75.0, 100.0, 150.0, 200.0],\n            \"epsilon_tol\": 0.01, \"seed\": 12345\n        },\n        # case 2\n        {\n            \"tau_inf_true\": 1.75, \"c\": 0.5, \"p_true\": 2.0, \"sigma\": 0.01,\n            \"L_values\": [30.0, 40.0, 60.0, 90.0],\n            \"epsilon_tol\": 0.005, \"seed\": 24680\n        },\n        # case 3\n        {\n            \"tau_inf_true\": 3.2, \"c\": 12.0, \"p_true\": 1.0, \"sigma\": 0.05,\n            \"L_values\": [20.0, 30.0, 50.0, 80.0],\n            \"epsilon_tol\": 0.02, \"seed\": 13579\n        }\n    ]\n\n    # Candidate exponents for model selection\n    candidate_p = [1.0, 1.5, 2.0]\n\n    all_results = []\n\n    for case in test_cases:\n        # Unpack case parameters\n        tau_inf_true = case[\"tau_inf_true\"]\n        c_true = case[\"c\"]\n        p_true = case[\"p_true\"]\n        sigma = case[\"sigma\"]\n        L_values = np.array(case[\"L_values\"])\n        epsilon_tol = case[\"epsilon_tol\"]\n        seed = case[\"seed\"]\n\n        n = len(L_values)\n        k = 2  # Number of parameters in the linear model (a, b)\n\n        # 1. Generate synthetic data\n        rng = np.random.default_rng(seed)\n        epsilon = rng.normal(0, sigma, size=n)\n        tau_measured = tau_inf_true + c_true * L_values**(-p_true) + epsilon\n\n        # 2. Model selection\n        model_fits = []\n        for p_cand in candidate_p:\n            # Linearize the model: y = a + b*x, where x = L^(-p)\n            x_var = L_values**(-p_cand)\n            y_var = tau_measured\n            \n            # Design matrix for OLS: A * [a, b]^T = y\n            A = np.vstack([np.ones(n), x_var]).T\n\n            # Perform Ordinary Least Squares using numpy\n            # Solves for coefficients [a, b] that minimize ||y - A*coeffs||^2\n            coeffs, residuals, _, _ = np.linalg.lstsq(A, y_var, rcond=None)\n            a_hat, b_hat = coeffs[0], coeffs[1]\n            \n            # The 'residuals' output from lstsq is the RSS if the system is overdetermined\n            rss = residuals[0] if residuals.size > 0 else np.sum((y_var - (a_hat + b_hat * x_var))**2)\n\n            # Calculate BIC\n            bic = n * np.log(rss / n) + k * np.log(n)\n            \n            model_fits.append({'p': p_cand, 'a': a_hat, 'b': b_hat, 'bic': bic})\n\n        # Find the best model (minimum BIC)\n        best_model = min(model_fits, key=lambda x: x['bic'])\n        hat_p = best_model['p']\n        hat_a = best_model['a']\n        hat_b = best_model['b']\n\n        # 3. Extrapolate and estimate bias\n        hat_tau_inf = hat_a\n        \n        # 4. Quantify errors\n        abs_estimation_error = abs(hat_tau_inf - tau_inf_true)\n        \n        bias_terms = hat_b * L_values**(-hat_p)\n        rmsb = np.sqrt(np.mean(bias_terms**2))\n        \n        if hat_b == 0:\n            L_star = 0.0\n        else:\n            L_star = (abs(hat_b) / epsilon_tol)**(1 / hat_p)\n            \n        # Compile results for the current case\n        case_results = [hat_tau_inf, abs_estimation_error, hat_p, rmsb, L_star]\n        all_results.append(case_results)\n\n    # Format output as a list of lists strings, then join\n    # e.g., [\"[1,2,3]\", \"[4,5,6]\"] -> join -> \"[1,2,3],[4,5,6]\"\n    # then wrap with another pair of brackets\n    # This ensures no spaces in the final output format.\n    results_str_list = [f\"[{','.join(map(str, res))}]\" for res in all_results]\n    final_output_str = f\"[{','.join(results_str_list)}]\"\n    \n    print(final_output_str)\n\nsolve()\n```"
        }
    ]
}