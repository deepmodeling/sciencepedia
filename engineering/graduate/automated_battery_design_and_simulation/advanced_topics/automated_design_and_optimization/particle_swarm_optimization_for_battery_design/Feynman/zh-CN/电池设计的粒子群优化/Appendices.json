{
    "hands_on_practices": [
        {
            "introduction": "在一个有界的设计空间内进行优化时，例如在电极孔隙度的有效范围内，一个关键挑战是如何处理试图移出这些边界的粒子。本练习探讨了一个称为边界偏倚的常见问题，并引入速度钳位作为一种解决方案。您将运用几何推理来推导出一个最大速度限制，以帮助粒子在不被卡在边缘的情况下有效探索整个区域 。",
            "id": "3938424",
            "problem": "一个自动化的锂离子电池设计过程旨在通过两个设计变量——电极厚度和孔隙率——来联合优化阴极微观结构。为了数值稳定性和单位一致性，这两个设计变量都被仿射归一化到单位区间，因此粒子群在归一化域 $\\Omega = [0,1]^2$ 中运行。搜索过程使用粒子群优化（PSO）算法，其中每个粒子的位置 $\\boldsymbol{x}_t \\in \\Omega$ 通过 $\\boldsymbol{x}_{t+1} = \\boldsymbol{x}_t + \\boldsymbol{v}_{t+1}$ 进行更新，其速度遵循带有惯性权重和随机加速项的经典更新规则。当位置更新超出 $\\Omega$ 时，粒子会被投影回 $\\Omega$ 的最近边界上。\n\n投影通过截断越界移动而导致边界偏置，这增加了粒子在 $\\partial \\Omega$ 上或其附近停留的时间。作为使用收缩因子间接减小速度大小的替代方案，可以考虑采用速度钳位：在归一化空间中对每个分量施加一个界限 $|v_{t+1}^{(i)}| \\leq v_{\\text{max}}$（其中 $i \\in \\{1,2\\}$），$v_{\\text{max}}$ 是一个应用于两个维度的标量。\n\n从 PSO 运动学的核心定义和 $\\Omega$ 中子集的几何测度出发，论证为何速度钳位可以通过直接控制可能发生单步边界交互的位置集合，来抑制有界归一化设计域中的边界偏置。然后，在假设更新时刻粒子位置在 $\\Omega$ 中近似均匀分布的前提下，定义一个目标上界 $\\alpha \\in (0,1)$，该上界代表在单次迭代中可能与边界发生交互（即从距离 $\\partial \\Omega$ 不到一个钳位步长的范围内开始移动）的粒子比例。仅使用归一化域中的这种几何推理，推导出最大安全钳位值 $v_{\\text{max}}(\\alpha)$，以确保边界交互比例不超过 $\\alpha$。\n\n将你的最终答案表示为 $v_{\\text{max}}$ 关于 $\\alpha$ 的单个闭式解析表达式，以归一化单位表示。无需进行数值计算。",
            "solution": "该问题要求论证速度钳位作为一种减少粒子群优化（PSO）中边界偏置的方法的合理性，并推导最大速度钳位值 $v_{\\text{max}}$ 作为期望边界交互比例 $\\alpha$ 的函数。\n\n首先，我们验证问题陈述的有效性。\n该问题设定在群体智能和数值优化的标准框架内。所有给定的元素都定义明确且一致：\n- 优化域是一个归一化的单位正方形，$\\Omega = [0,1]^2$。\n- PSO 运动学公式 $\\boldsymbol{x}_{t+1} = \\boldsymbol{x}_t + \\boldsymbol{v}_{t+1}$ 是经典的。\n- 边界处理方法（投影）及其相关问题（边界偏置）是 PSO 文献中的已知现象。\n- 提议的缓解策略，即速度钳位（$|v_{t+1}^{(i)}| \\leq v_{\\text{max}}$），是一种标准技术。\n- 推导 $v_{\\text{max}}(\\alpha)$ 的要求基于清晰的几何解释和一个简化但可形式化的假设（粒子均匀分布）。\n该问题具有科学依据，是适定的、客观的，并包含足够的信息以获得唯一解。它没有违反任何无效性标准。因此，该问题被认为是有效的，并将构建一个解决方案。\n\n**第一部分：速度钳位的论证**\n\n在域 $\\Omega = [0,1]^2$ 中，位于位置 $\\boldsymbol{x}_t = (x_t^{(1)}, x_t^{(2)})$ 的粒子只有在其新位置 $\\boldsymbol{x}_{t+1} = \\boldsymbol{x}_t + \\boldsymbol{v}_{t+1}$ 位于 $\\Omega$ 之外时，才会在更新到步骤 $t+1$ 的过程中与边界发生交互。这意味着 $\\boldsymbol{x}_{t+1}$ 的至少一个分量必须小于 $0$ 或大于 $1$。\n\n如果没有速度钳位，速度向量 $\\boldsymbol{v}_{t+1}$ 的分量可以是任意大的。这意味着位于 $\\Omega$ 中任何位置的粒子，即使是在中心 $(\\frac{1}{2}, \\frac{1}{2})$，也可能产生足够大的速度，使其在单一步骤内移出域外，从而触发投影机制。这种从广泛起始位置出发的频繁投影导致粒子在边界处积聚，这一现象被称为边界偏置。\n\n速度钳位对每个速度分量的大小引入了一个硬性限制 $v_{\\text{max}}$：$|v_{t+1}^{(i)}| \\leq v_{\\text{max}}$，其中 $i \\in \\{1,2\\}$。这直接限制了粒子在单个时间步内沿任一维度可以移动的最大距离。\n\n让我们分析粒子越过边界的条件。对于第一个分量 $x^{(1)}$，如果 $x_{t+1}^{(1)}  0$ 或 $x_{t+1}^{(1)} > 1$，则发生越界移动。\n代入更新规则，即 $x_t^{(1)} + v_{t+1}^{(1)}  0$ 或 $x_t^{(1)} + v_{t+1}^{(1)} > 1$。\n\n在速度钳位下，$v_{t+1}^{(1)}$ 的最小值为 $-v_{\\text{max}}$，最大值为 $+v_{\\text{max}}$。\n- 要越过下边界（$x_{t+1}^{(1)}  0$），粒子必须满足 $x_t^{(1)} + v_{t+1}^{(1)}  0$。这只有在 $x_t^{(1)}$ 足够小，能被负速度所抵消时才可能发生。最极端的情况是 $x_t^{(1)} - v_{\\text{max}}  0$，这意味着 $x_t^{(1)}  v_{\\text{max}}$。\n- 要越过上边界（$x_{t+1}^{(1)} > 1$），粒子必须满足 $x_t^{(1)} + v_{t+1}^{(1)} > 1$。这只有在 $x_t^{(1)}$ 足够大时才可能发生。最极端的情况是 $x_t^{(1)} + v_{\\text{max}} > 1$，这意味着 $x_t^{(1)} > 1 - v_{\\text{max}}$。\n\n因此，只有当粒子的位置 $x_t^{(1)}$ 位于集合 $[0, v_{\\text{max}}) \\cup (1-v_{\\text{max}}, 1]$ 内时，它才能与 $x^{(1)}=0$ 或 $x^{(1)}=1$ 处的边界发生交互。对于位置满足 $x_t^{(1)} \\in [v_{\\text{max}}, 1-v_{\\text{max}}]$ 的粒子，可以保证它在下一步中不会越过这些特定的边界。\n\n通过施加速度钳位，我们在 $\\Omega$ 内定义了一个“安全”子区域，从该区域出发，单步内不可能发生边界交互。因此，边界偏置效应被抑制了，因为易受投影影响的粒子集合被明确地限制在一个定义明确的“边界交互区”内。这通过限制每个粒子的运动可达范围，直接解决了不受控制的边界交互问题。\n\n**第二部分：$v_{\\text{max}}(\\alpha)$ 的推导**\n\n该问题要求找到最大钳位值 $v_{\\text{max}}$，使得可能与边界交互的粒子比例不超过一个目标上界 $\\alpha$。我们需要假设粒子位置在归一化域 $\\Omega = [0,1]^2$ 中近似均匀分布。\n\n在均匀分布的假设下，$\\Omega$ 中任何子集内的粒子比例等于该子集的面积，因为 $\\Omega$ 的总面积为 $1^2=1$。因此，目标是求出边界交互区的面积，将其设为 $\\alpha$，然后求解 $v_{\\text{max}}$。\n\n如第一部分所推导，位于位置 $\\boldsymbol{x} = (x^{(1)}, x^{(2)})$ 的粒子如果满足以下任一条件，就可能与边界发生交互：\n- $x^{(1)}  v_{\\text{max}}$\n- $x^{(1)} > 1 - v_{\\text{max}}$\n- $x^{(2)}  v_{\\text{max}}$\n- $x^{(2)} > 1 - v_{\\text{max}}$\n\n这组点构成了环绕单位正方形 $\\Omega$ 周边的一个“框架”。更方便的做法是计算其补集，即“安全区” $S$ 的面积，然后用总面积减去这个面积。安全区 $S$ 是粒子*无法*与边界交互的区域。一个粒子位于 $S$ 内，如果其位置满足以下所有条件：\n- $v_{\\text{max}} \\leq x^{(1)} \\leq 1 - v_{\\text{max}}$\n- $v_{\\text{max}} \\leq x^{(2)} \\leq 1 - v_{\\text{max}}$\n\n这在几何上定义了一个位于 $\\Omega$ 中心的正方形。这个内部正方形的边长是 $(1 - v_{\\text{max}}) - v_{\\text{max}} = 1 - 2v_{\\text{max}}$。为了使其成为一个有效的、非退化的正方形，我们必须有 $1 - 2v_{\\text{max}} > 0$，即 $v_{\\text{max}}  \\frac{1}{2}$。考虑到 $\\alpha \\in (0,1)$，最终得到的 $v_{\\text{max}}$ 将满足此条件。\n\n安全区面积 $A_S$ 是其边长的平方：\n$$A_S = (1 - 2v_{\\text{max}})^2$$\n\n边界交互区面积 $A_Z$ 是 $\\Omega$ 的总面积减去安全区的面积：\n$$A_Z = A_{\\Omega} - A_S = 1 - (1 - 2v_{\\text{max}})^2$$\n\n问题要求这个粒子比例（也就是这个面积）不超过 $\\alpha$。为了找到最大安全钳位值 $v_{\\text{max}}$，我们将这个面积设为等于 $\\alpha$：\n$$1 - (1 - 2v_{\\text{max}})^2 = \\alpha$$\n\n我们现在求解这个关于 $v_{\\text{max}}$ 的方程：\n$$(1 - 2v_{\\text{max}})^2 = 1 - \\alpha$$\n\n对两边取平方根，我们选择正根，因为边长 $1 - 2v_{\\text{max}}$ 必须是正数：\n$$1 - 2v_{\\text{max}} = \\sqrt{1 - \\alpha}$$\n条件 $\\alpha \\in (0,1)$ 确保了 $1 - \\alpha > 0$，因此平方根是良定义且为实数。\n\n整理各项以分离出 $v_{\\text{max}}$：\n$$2v_{\\text{max}} = 1 - \\sqrt{1 - \\alpha}$$\n$$v_{\\text{max}}(\\alpha) = \\frac{1 - \\sqrt{1 - \\alpha}}{2}$$\n这个表达式也可以写成 $\\frac{1}{2}(1 - \\sqrt{1 - \\alpha})$。这就是作为期望边界交互比例 $\\alpha$ 的函数的最大安全钳位值的最终闭式表达式。",
            "answer": "$$\\boxed{\\frac{1}{2}\\left(1 - \\sqrt{1 - \\alpha}\\right)}$$"
        },
        {
            "introduction": "粒子群优化算法擅长全局探索，但在精确定位最优点时可能速度较慢。本练习将指导您构建一个强大的混合算法，它将PSO的全局搜索能力与基于梯度方法的快速局部收敛特性相结合。此练习的一个关键部分是开发并实现量化标准，以判断梯度信息何时足够可靠，可以用于局部精炼 。",
            "id": "3938429",
            "problem": "要求您为无量纲电池电极设计问题设计并实现一种混合粒子群优化 (PSO) 算法。该混合算法必须在有前景的设计附近应用基于局部梯度的精化步骤，但仅当从代理模型或伴随计算中获得的梯度被原则性的、定量的标准判定为可靠时才执行。您的实现必须在固定的随机种子下产生确定性结果，并且必须将多个测试用例的结果汇总到指定格式的单行输出中。\n\n基本原理与定义域。考虑一个连续设计向量 $\\mathbf{x} = (p,s,t) \\in [0,1]^3$，它代表归一化孔隙率 $p$、归一化固相分数 $s$ 和归一化厚度 $t$。设设计目标为一个可微的标量函数 $J(\\mathbf{x})$，该函数权衡了能量密度、欧姆行为和反应动力学。设计目标是解决以下约束最小化问题\n$$\n\\min_{\\mathbf{x} \\in [0,1]^3} J(\\mathbf{x}),\n$$\n其中\n$$\nJ(p,s,t) = -s\\,t\\,\\left(1 - 0.5\\,p\\right) + 0.2\\,\\frac{t^2}{p + 0.1} + 0.3\\,\\left(1-p\\right)^2 + 0.1\\,\\frac{s^2}{0.3 + p} + 0.02\\,\\sin(5\\,p)\\,\\cos(5\\,s)\\,\\sin(5\\,t).\n$$\n所有变量都是无量纲的，因此输出中不需要物理单位。\n\n算法要求。您的程序必须实现：\n- 一种混合粒子群优化 (PSO) 算法，基于随机搜索和个体最优/全局最优信息共享的基本思想。对于迭代 $k$ 次时的 $N$ 个粒子，PSO 使用 $[0,1]^3$ 范围内的有界步长来更新位置 $\\mathbf{x}_{i}^{(k)}$ 和速度 $\\mathbf{v}_{i}^{(k)}$，并采用标准的惯性和加速系数。除了带有惯性以及吸引至个体和全局最优位置的迭代搜索的基本定义外，不要依赖任何快捷公式。\n- 一种围绕有前景的设计（例如，按目标函数值表现最佳的设计）的局部梯度精化步骤，每 $r$ 次迭代执行一次，使用带有步长 $\\alpha$ 的回溯线搜索和到 $[0,1]^3$ 上的投影。精化步骤仅在梯度可靠性检查通过时才能进行，具体如下所述。\n\n梯度源与可靠性标准。您的混合方法必须支持三种梯度源：\n- 精确梯度：从给定的 $J(\\mathbf{x})$ 推导出的解析梯度 $\\nabla J(\\mathbf{x})$ 在此设置中被视为始终可靠。\n- 代理梯度：使用 $K$ 个先前评估过的最近点，通过在 $\\mathbf{x}$ 周围进行局部二次代理拟合来计算 $\\tilde{\\nabla} J(\\mathbf{x})$。仅当满足两个条件时，才接受基于代理的梯度：\n  1. 代理模型在其 $K$ 个点上的预测的局部均方根误差 (RMSE) 不超过阈值 $\\varepsilon$。\n  2. 代理模型在 $\\mathbf{x}$ 处的梯度接近于有限差分估计，即\n  $$\n  \\frac{\\left\\|\\tilde{\\nabla} J(\\mathbf{x}) - \\nabla_h J(\\mathbf{x})\\right\\|_2}{\\left\\|\\nabla_h J(\\mathbf{x})\\right\\|_2 + 10^{-12}} \\le \\delta,\n  $$\n  其中 $\\nabla_h J(\\mathbf{x})$ 是采用小步长 $h$ 的中心有限差分梯度。\n- 伴随梯度：通过用标准差为 $\\sigma$ 的零均值高斯噪声扰动精确梯度来模拟一个类伴随梯度 $\\tilde{\\nabla} J(\\mathbf{x})$。仅当方向导数测试通过时才接受此梯度：对于 $D$ 个随机单位方向 $\\mathbf{u}_j$，预测的方向导数 $\\tilde{\\nabla} J(\\mathbf{x})^\\top \\mathbf{u}_j$ 与有限差分结果一致，\n  $$\n  \\left|\\frac{\\tilde{\\nabla} J(\\mathbf{x})^\\top \\mathbf{u}_j - \\frac{J(\\mathbf{x} + h\\mathbf{u}_j) - J(\\mathbf{x} - h\\mathbf{u}_j)}{2h}}{\\frac{\\left|J(\\mathbf{x} + h\\mathbf{u}_j) - J(\\mathbf{x} - h\\mathbf{u}_j)\\right|}{2h} + 10^{-12}}\\right| \\le \\tau,\n  $$\n  对于至少 $\\rho$ 比例的 $D$ 个方向成立，并且平均相对误差不超过 $\\tau$。这里 $h$ 是有限差分步长。\n\n精化步骤。当一个有前景的设计存在可靠梯度 $\\mathbf{g}(\\mathbf{x})$ 时，执行投影回溯线搜索，尝试步长 $\\mathbf{x}_{\\text{new}} = \\Pi_{[0,1]^3}\\left(\\mathbf{x} - \\alpha\\,\\mathbf{g}(\\mathbf{x})\\right)$，并以几何级数缩小 $\\alpha$，直到找到一个下降步或达到最小步长。相应地更新粒子的个体最优和全局最优。\n\n测试套件。您的程序必须在以下五个测试用例上评估混合优化器。对于每个案例，输出找到的最佳目标函数值，四舍五入到 $6$ 位小数。这些案例是：\n\n- 案例 1 (理想路径，精确梯度):\n  - 梯度源: $\\text{exact}$ (精确)。\n  - 粒子群规模 $N = 24$，迭代次数 $T = 60$，精化周期 $r = 5$。\n  - PSO 系数：惯性权重 $w = 0.7$，认知系数 $c_1 = 1.5$，社会系数 $c_2 = 1.5$。\n  - 随机种子 $= 42$。\n\n- 案例 2 (代理梯度，可靠):\n  - 梯度源: $\\text{surrogate}$ (代理)。\n  - $N = 28$，$T = 70$，$r = 4$，$K = 25$ 个最近邻，岭正则化 $\\lambda = 10^{-6}$。\n  - 代理 RMSE 阈值 $\\varepsilon = 10^{-3}$，梯度相对误差阈值 $\\delta = 0.25$。\n  - $w = 0.7$，$c_1 = 1.5$，$c_2 = 1.5$，种子 $= 1337$。\n\n- 案例 3 (代理梯度，不可靠):\n  - 梯度源: $\\text{surrogate}$ (代理)。\n  - $N = 18$，$T = 50$，$r = 4$，$K = 20$，$\\lambda = 10^{-6}$。\n  - $\\varepsilon = 10^{-6}$，$\\delta = 0.10$。\n  - $w = 0.7$，$c_1 = 1.5$，$c_2 = 1.5$，种子 $= 202$。\n\n- 案例 4 (类伴随梯度，低噪声):\n  - 梯度源: $\\text{adjoint}$ (伴随)。\n  - $N = 22$，$T = 60$，$r = 5$，噪声 $\\sigma = 0.01$，方向样本大小 $D = 5$，接受比例 $\\rho = 0.6$，容差 $\\tau = 0.20$。\n  - $w = 0.7$，$c_1 = 1.5$，$c_2 = 1.5$，种子 $= 99$。\n\n- 案例 5 (类伴随梯度，高噪声，边界初始化):\n  - 梯度源: $\\text{adjoint}$ (伴随)。\n  - $N = 22$，$T = 60$，$r = 5$，$\\sigma = 0.30$，$D = 5$，$\\rho = 0.6$，$\\tau = 0.15$。\n  - 将一半粒子初始化在下边界附近（$\\mathbf{x}\\approx \\mathbf{0}$），另一半在上边界附近（$\\mathbf{x}\\approx \\mathbf{1}$），然后在每次更新时应用投影。\n  - $w = 0.7$，$c_1 = 1.5$，$c_2 = 1.5$，种子 $= 111$。\n\n最终输出格式。您的程序应生成单行输出，其中包含一个用方括号括起来的、逗号分隔的五个最佳目标函数值列表，四舍五入到 $6$ 位小数（例如，$[v_1,v_2,v_3,v_4,v_5]$）。不应打印任何其他输出。",
            "solution": "所呈现的问题是计算优化领域中一个适定 (well-posed) 的任务，特别关注于一个混合元启发式算法，用于解决一个风格化为电池电极设计的约束连续优化问题。该问题具有科学依据、自成体系（一些次要的标准参数留给实现者自行决定），并且有客观的规定。因此，它被认为是有效的。以下解决方案概述了所需实现的理论和算法框架。\n\n### 1. 问题公式化\n\n问题的核心是在一个三维连续设计空间 $\\mathbf{x} \\in [0,1]^3$ 上找到一个标量目标函数 $J(\\mathbf{x})$ 的最小值。设计向量为 $\\mathbf{x} = (p,s,t)$，分别代表归一化孔隙率、固相分数和厚度。待最小化的目标函数由下式给出：\n$$\nJ(p,s,t) = -s\\,t\\,\\left(1 - 0.5\\,p\\right) + 0.2\\,\\frac{t^2}{p + 0.1} + 0.3\\,\\left(1-p\\right)^2 + 0.1\\,\\frac{s^2}{0.3 + p} + 0.02\\,\\sin(5\\,p)\\,\\cos(5\\,s)\\,\\sin(5\\,t)\n$$\n该函数在其关注的定义域 $[0,1]^3$ 内是非凸且处处可微的，因为对于 $p \\in [0,1]$，分母 $(p+0.1)$ 和 $(0.3+p)$ 恒为正。\n\n### 2. 算法框架：混合粒子群优化\n\n所选的优化策略是一种混合粒子群优化 (PSO) 算法。该方法将 PSO 的全局搜索能力与基于梯度的方法的局部收敛特性相结合。\n\n#### 2.1. 粒子群优化核心\n\nPSO 算法维护一个由 $N$ 个粒子组成的粒子群，其中每个粒子 $i$ 都有一个位置 $\\mathbf{x}_i \\in [0,1]^3$ 和一个速度 $\\mathbf{v}_i \\in \\mathbb{R}^3$。在每次迭代 $k$ 中，每个粒子的速度和位置根据其自身已知的最佳位置 $\\mathbf{p}_{\\text{best},i}$ 和群体中任何粒子找到的全局最佳位置 $\\mathbf{g}_{\\text{best}}$ 进行更新。\n\n更新方程为：\n$$\n\\mathbf{v}_i^{(k+1)} = w\\,\\mathbf{v}_i^{(k)} + c_1\\,r_1 \\left(\\mathbf{p}_{\\text{best},i}^{(k)} - \\mathbf{x}_i^{(k)}\\right) + c_2\\,r_2 \\left(\\mathbf{g}_{\\text{best}}^{(k)} - \\mathbf{x}_i^{(k)}\\right)\n$$\n$$\n\\mathbf{x}_i^{(k+1)} = \\Pi_{[0,1]^3} \\left( \\mathbf{x}_i^{(k)} + \\mathbf{v}_i^{(k+1)} \\right)\n$$\n其中：\n- $w$ 是惯性权重。\n- $c_1$ 和 $c_2$ 是认知和社会加速系数。\n- $r_1, r_2 \\sim U(0,1)$ 是为每个粒子和维度独立抽样的随机数。\n- $\\Pi_{[0,1]^3}(\\cdot)$ 是将向量分量限制在区间 $[0,1]$ 内的投影算子。\n\n速度也被限制在一个合理的范围 $[-0.5, 0.5]^3$ 内，以防止发散。如果一个粒子找到了一个具有更低目标函数值的位置，则其个体最优 $\\mathbf{p}_{\\text{best},i}$ 会被更新。当任何粒子的个体最优优于现有的全局最优时，全局最优 $\\mathbf{g}_{\\text{best}}$ 就会被更新。\n\n#### 2.2. 基于局部梯度的精化\n\n每隔 $r$ 次迭代，针对最有前景的设计触发一个局部精化步骤，该设计被认为是当前的全局最优位置 $\\mathbf{g}_{\\text{best}}$。该步骤使用基于梯度的方法在 $\\mathbf{g}_{\\text{best}}$ 附近搜索更好的解。然而，只有在能够获得可靠梯度的情况下（根据特定于梯度源的标准确定），才会执行此精化。\n\n### 3. 梯度源与可靠性评估\n\n该混合算法支持三种不同的梯度 $\\nabla J(\\mathbf{x})$ 来源。\n\n#### 3.1. 精确梯度\n解析梯度 $\\nabla J(\\mathbf{x})$ 是通过 $J(p,s,t)$ 的偏导数直接计算得出的：\n$$\n\\frac{\\partial J}{\\partial p} = 0.5st - \\frac{0.2 t^2}{(p+0.1)^2} - 0.6(1-p) - \\frac{0.1 s^2}{(0.3+p)^2} + 0.1\\cos(5p)\\cos(5s)\\sin(5t)\n$$\n$$\n\\frac{\\partial J}{\\partial s} = -t(1-0.5p) + \\frac{0.2s}{0.3+p} - 0.1\\sin(5p)\\sin(5s)\\sin(5t)\n$$\n$$\n\\frac{\\partial J}{\\partial t} = -s(1-0.5p) + \\frac{0.4t}{p+0.1} + 0.1\\sin(5p)\\cos(5s)\\cos(5t)\n$$\n在此问题背景下，精确梯度被认为是完全可靠的，并且在指定时总是用于精化。\n\n#### 3.2. 代理梯度\n构建一个局部二次代理模型来近似关注点 $\\mathbf{x}^*$ 周围的 $J(\\mathbf{x})$。该模型形式为 $\\tilde{J}(\\mathbf{x}) = \\mathbf{w}^T \\phi(\\mathbf{x})$，其中 $\\phi(\\mathbf{x}) = (1, p, s, t, p^2, s^2, t^2, ps, pt, st)^T$ 是一个二次特征向量。系数向量 $\\mathbf{w} \\in \\mathbb{R}^{10}$ 通过将模型与所有函数评估历史中离 $\\mathbf{x}^*$ 最近的 $K$ 个点进行拟合来确定，使用岭回归求解 $(\\mathbf{\\Phi}^T\\mathbf{\\Phi} + \\lambda \\mathbf{I})\\mathbf{w} = \\mathbf{\\Phi}^T\\mathbf{y}$。\n仅当满足以下条件时，此代理模型的梯度 $\\tilde{\\nabla} J(\\mathbf{x}^*) = \\nabla (\\mathbf{w}^T \\phi(\\mathbf{x}^*))$ 才被认为是可靠的：\n1.  代理模型在 $K$ 个训练点上的预测的均方根误差 (RMSE) 低于阈值 $\\varepsilon$。\n2.  代理梯度 $\\tilde{\\nabla} J(\\mathbf{x}^*)$ 与通过步长为 $h=10^{-6}$ 的中心有限差分法获得的数值梯度估计 $\\nabla_h J(\\mathbf{x}^*)$ 足够接近，满足 $\\frac{\\left\\|\\tilde{\\nabla} J(\\mathbf{x}^*) - \\nabla_h J(\\mathbf{x}^*)\\right\\|_2}{\\left\\|\\nabla_h J(\\mathbf{x}^*)\\right\\|_2 + 10^{-12}} \\le \\delta$。\n\n#### 3.3. 类伴随梯度\n通过用零均值高斯噪声扰动精确梯度来模拟类伴随梯度：$\\tilde{\\nabla} J(\\mathbf{x}) = \\nabla J(\\mathbf{x}) + \\mathbf{z}$，其中 $\\mathbf{z} \\sim \\mathcal{N}(0, \\sigma^2 I)$。如果此带噪梯度通过方向导数测试，则被认为是可靠的：\n1.  对于 $D$ 个随机单位方向 $\\mathbf{u}_j$ 中的至少 $\\rho$ 比例，由带噪梯度预测的方向导数 $\\tilde{\\nabla} J(\\mathbf{x})^\\top \\mathbf{u}_j$ 与有限差分近似 $\\frac{J(\\mathbf{x} + h\\mathbf{u}_j) - J(\\mathbf{x} - h\\mathbf{u}_j)}{2h}$ 之间的相对误差必须小于或等于容差 $\\tau$。\n2. 在所有 $D$ 个方向上的此相对误差的平均值不得超过 $\\tau$。使用 $h=10^{-6}$ 的有限差分步长。\n\n### 4. 投影回溯线搜索\n\n如果为点 $\\mathbf{x}$ 获得了一个可靠的梯度 $\\mathbf{g}(\\mathbf{x})$，则执行回溯线搜索以找到一个更好的点。搜索过程从初始步长 $\\alpha=1.0$ 开始，通过测试候选点 $\\mathbf{x}_{\\text{new}} = \\Pi_{[0,1]^3}(\\mathbf{x} - \\alpha\\,\\mathbf{g}(\\mathbf{x}))$ 来进行。如果新点没有使目标函数值减小，即 $J(\\mathbf{x}_{\\text{new}}) \\ge J(\\mathbf{x})$，则步长 $\\alpha$ 按几何级数减小（例如，乘以因子 $0.5$）并重复该过程。当找到一个下降步或 $\\alpha$ 低于最小阈值 $10^{-8}$ 时，搜索终止。如果找到了更好的点，则相应地更新全局最优位置和值。\n\n### 5. 测试套件执行\n\n对五个指定的测试用例中的每一个执行混合 PSO 算法。每个案例都定义了粒子群规模 $N$、总迭代次数 $T$、精化周期 $r$、PSO 系数（$w, c_1, c_2$）、一个随机种子以及特定梯度源的参数。通过为每个案例设置伪随机数生成器的种子来确保过程的确定性。每个案例的最终结果是找到的最佳目标函数值 $\\min(J(\\mathbf{g}_{\\text{best}}))$，四舍五入到六位小数。",
            "answer": "```python\nimport numpy as np\nimport collections\n\n#\n# Problem-specific functions: Objective function and its exact gradient\n#\n\ndef objective_function(x):\n    \"\"\"Computes the objective function J(x) for a given design vector x=(p,s,t).\"\"\"\n    p, s, t = x[0], x[1], x[2]\n    term1 = -s * t * (1 - 0.5 * p)\n    term2 = 0.2 * (t**2) / (p + 0.1)\n    term3 = 0.3 * (1 - p)**2\n    term4 = 0.1 * (s**2) / (0.3 + p)\n    term5 = 0.02 * np.sin(5 * p) * np.cos(5 * s) * np.sin(5 * t)\n    return term1 + term2 + term3 + term4 + term5\n\ndef exact_gradient(x):\n    \"\"\"Computes the analytical gradient of J(x) at a given design vector x=(p,s,t).\"\"\"\n    p, s, t = x[0], x[1], x[2]\n    grad = np.zeros(3)\n    \n    # Gradient w.r.t. p\n    grad[0] = (0.5 * s * t) \\\n            - (0.2 * t**2 / (p + 0.1)**2) \\\n            - (0.6 * (1 - p)) \\\n            - (0.1 * s**2 / (0.3 + p)**2) \\\n            + (0.1 * np.cos(5*p) * np.cos(5*s) * np.sin(5*t))\n\n    # Gradient w.r.t. s\n    grad[1] = -t * (1 - 0.5 * p) \\\n            + (0.2 * s / (0.3 + p)) \\\n            - (0.1 * np.sin(5*p) * np.sin(5*s) * np.sin(5*t))\n\n    # Gradient w.r.t. t\n    grad[2] = -s * (1 - 0.5 * p) \\\n            + (0.4 * t / (p + 0.1)) \\\n            + (0.1 * np.sin(5*p) * np.cos(5*s) * np.cos(5*t))\n            \n    return grad\n\n#\n# Hybrid PSO Solver\n#\n\nclass HybridPSOSolver:\n    def __init__(self, params):\n        self.params = params\n        self.rng = np.random.default_rng(self.params['seed'])\n        self.dim = 3\n        \n        # PSO parameters\n        self.N = params['N']\n        self.T = params['T']\n        self.w = params['w']\n        self.c1 = params['c1']\n        self.c2 = params['c2']\n        \n        # Refinement parameters\n        self.r = params['r']\n        self.gradient_source = params['gradient_source']\n\n        # Shared parameters\n        self.h_fd = 1e-6 # Finite difference step size\n\n        # Initialize state\n        self.positions = None\n        self.velocities = None\n        self.p_best_pos = None\n        self.p_best_val = None\n        self.g_best_pos = None\n        self.g_best_val = np.inf\n        \n        # History for surrogate models\n        self.history_pos = []\n        self.history_val = []\n\n    def _initialize_swarm(self):\n        \"\"\"Initializes the swarm's positions and velocities.\"\"\"\n        if self.params.get('special_init', False):\n            # Case 5 specific initialization\n            n_half = self.N // 2\n            self.positions = np.zeros((self.N, self.dim))\n            self.positions[:n_half, :] = self.rng.uniform(0.0, 0.1, size=(n_half, self.dim))\n            self.positions[n_half:, :] = self.rng.uniform(0.9, 1.0, size=(self.N - n_half, self.dim))\n        else:\n            self.positions = self.rng.uniform(0.0, 1.0, size=(self.N, self.dim))\n\n        self.velocities = np.zeros((self.N, self.dim))\n        \n        self.p_best_pos = np.copy(self.positions)\n        self.p_best_val = np.array([objective_function(p) for p in self.positions])\n        \n        self.history_pos.extend(list(self.positions))\n        self.history_val.extend(list(self.p_best_val))\n        \n        best_particle_idx = np.argmin(self.p_best_val)\n        self.g_best_val = self.p_best_val[best_particle_idx]\n        self.g_best_pos = self.p_best_pos[best_particle_idx]\n\n    def _finite_diff_gradient(self, x):\n        \"\"\"Computes gradient using central finite differences.\"\"\"\n        grad = np.zeros(self.dim)\n        for i in range(self.dim):\n            x_plus_h = x.copy()\n            x_plus_h[i] += self.h_fd\n            x_minus_h = x.copy()\n            x_minus_h[i] -= self.h_fd\n            grad[i] = (objective_function(x_plus_h) - objective_function(x_minus_h)) / (2 * self.h_fd)\n        return grad\n\n    def _get_surrogate_gradient(self, x_ref):\n        \"\"\"Computes and validates a gradient from a surrogate model.\"\"\"\n        K = self.params['K']\n        reg = self.params.get('lambda', 1e-6)\n        \n        if len(self.history_pos)  K:\n            return None\n\n        # Find K nearest neighbors\n        hist_pos_arr = np.array(self.history_pos)\n        distances = np.linalg.norm(hist_pos_arr - x_ref, axis=1)\n        k_indices = np.argsort(distances)[:K]\n        \n        neighbor_pos = hist_pos_arr[k_indices]\n        neighbor_val = np.array(self.history_val)[k_indices]\n        \n        # Build feature matrix for quadratic model\n        def get_features(x):\n            p, s, t = x\n            return [1, p, s, t, p**2, s**2, t**2, p*s, p*t, s*t]\n        \n        phi_matrix = np.array([get_features(pos) for pos in neighbor_pos])\n        \n        # Solve for coefficients w using ridge regression\n        try:\n            A = phi_matrix.T @ phi_matrix + reg * np.identity(phi_matrix.shape[1])\n            b = phi_matrix.T @ neighbor_val\n            w = np.linalg.solve(A, b)\n        except np.linalg.LinAlgError:\n            return None\n\n        # --- Reliability Check 1: RMSE ---\n        y_pred = phi_matrix @ w\n        rmse = np.sqrt(np.mean((y_pred - neighbor_val)**2))\n        if rmse > self.params['epsilon']:\n            return None\n\n        # --- Reliability Check 2: Gradient Match ---\n        p_ref, s_ref, t_ref = x_ref\n        grad_phi_p = np.array([0, 1, 0, 0, 2*p_ref, 0, 0, s_ref, t_ref, 0])\n        grad_phi_s = np.array([0, 0, 1, 0, 0, 2*s_ref, 0, p_ref, 0, t_ref])\n        grad_phi_t = np.array([0, 0, 0, 1, 0, 0, 2*t_ref, 0, p_ref, s_ref])\n        \n        g_surr = np.array([grad_phi_p @ w, grad_phi_s @ w, grad_phi_t @ w])\n        g_fd = self._finite_diff_gradient(x_ref)\n        \n        g_fd_norm = np.linalg.norm(g_fd)\n        rel_err = np.linalg.norm(g_surr - g_fd) / (g_fd_norm + 1e-12)\n\n        if rel_err > self.params['delta']:\n            return None\n\n        return g_surr\n\n    def _get_adjoint_gradient(self, x_ref):\n        \"\"\"Computes and validates an adjoint-like gradient.\"\"\"\n        g_exact = exact_gradient(x_ref)\n        noise = self.rng.normal(0, self.params['sigma'], size=self.dim)\n        g_adj = g_exact + noise\n\n        # --- Reliability Check: Directional Derivatives ---\n        D = self.params['D']\n        rho = self.params['rho']\n        tau = self.params['tau']\n        \n        passed_count = 0\n        total_rel_err = 0.0\n        \n        for _ in range(D):\n            u = self.rng.normal(size=self.dim)\n            u /= np.linalg.norm(u)\n            \n            dd_adj = g_adj @ u\n            dd_fd = (objective_function(x_ref + self.h_fd * u) - objective_function(x_ref - self.h_fd * u)) / (2 * self.h_fd)\n            \n            # Record historical evaluations for surrogates\n            self.history_pos.append(x_ref + self.h_fd * u)\n            self.history_pos.append(x_ref - self.h_fd * u)\n            self.history_val.append(objective_function(x_ref + self.h_fd * u))\n            self.history_val.append(objective_function(x_ref - self.h_fd * u))\n\n            denominator = abs(dd_fd) + 1e-12\n            rel_err = abs(dd_adj - dd_fd) / denominator\n            \n            total_rel_err += rel_err\n            if rel_err = tau:\n                passed_count += 1\n        \n        mean_rel_err = total_rel_err / D\n        fraction_passed = passed_count / D\n        \n        if fraction_passed = rho and mean_rel_err = tau:\n            return g_adj\n        else:\n            return None\n\n    def _backtracking_line_search(self, x, g):\n        \"\"\"Performs a projected backtracking line search.\"\"\"\n        alpha = 1.0\n        beta = 0.5\n        min_alpha = 1e-8\n        \n        current_val = objective_function(x)\n\n        for _ in range(10): # Max 10 backtracking steps\n            x_new = x - alpha * g\n            x_new = np.clip(x_new, 0, 1)\n            \n            new_val = objective_function(x_new)\n            self.history_pos.append(x_new)\n            self.history_val.append(new_val)\n            \n            if new_val  current_val:\n                return x_new, new_val\n            \n            alpha *= beta\n            if alpha  min_alpha:\n                break\n        \n        return x, current_val\n        \n    def _refinement_step(self):\n        \"\"\"Executes the gradient-based refinement step on the global best position.\"\"\"\n        x_ref = self.g_best_pos\n        g = None\n        \n        if self.gradient_source == 'exact':\n            g = exact_gradient(x_ref)\n        elif self.gradient_source == 'surrogate':\n            g = self._get_surrogate_gradient(x_ref)\n        elif self.gradient_source == 'adjoint':\n            g = self._get_adjoint_gradient(x_ref)\n        \n        if g is not None:\n            new_pos, new_val = self._backtracking_line_search(x_ref, g)\n            if new_val  self.g_best_val:\n                self.g_best_pos = new_pos\n                self.g_best_val = new_val\n\n    def optimize(self):\n        self._initialize_swarm()\n        \n        v_max = 0.5\n\n        for k in range(self.T):\n            r1 = self.rng.uniform(0, 1, size=(self.N, self.dim))\n            r2 = self.rng.uniform(0, 1, size=(self.N, self.dim))\n\n            # Update velocities\n            cognitive_comp = self.c1 * r1 * (self.p_best_pos - self.positions)\n            social_comp = self.c2 * r2 * (self.g_best_pos - self.positions)\n            self.velocities = self.w * self.velocities + cognitive_comp + social_comp\n            \n            # Clamp velocities\n            self.velocities = np.clip(self.velocities, -v_max, v_max)\n\n            # Update positions\n            self.positions += self.velocities\n            self.positions = np.clip(self.positions, 0, 1)\n\n            # Evaluate objective\n            current_vals = np.array([objective_function(p) for p in self.positions])\n            self.history_pos.extend(list(self.positions))\n            self.history_val.extend(list(current_vals))\n\n            # Update personal bests\n            improvement_mask = current_vals  self.p_best_val\n            self.p_best_pos[improvement_mask] = self.positions[improvement_mask]\n            self.p_best_val[improvement_mask] = current_vals[improvement_mask]\n            \n            # Update global best\n            best_particle_idx = np.argmin(self.p_best_val)\n            if self.p_best_val[best_particle_idx]  self.g_best_val:\n                self.g_best_val = self.p_best_val[best_particle_idx]\n                self.g_best_pos = self.p_best_pos[best_particle_idx]\n\n            # Perform refinement step periodically\n            if (k + 1) % self.r == 0:\n                self._refinement_step()\n        \n        return self.g_best_val\n\ndef solve():\n    test_cases = [\n        # Case 1 (happy path, exact gradient)\n        {\n            'gradient_source': 'exact', 'N': 24, 'T': 60, 'r': 5,\n            'w': 0.7, 'c1': 1.5, 'c2': 1.5, 'seed': 42\n        },\n        # Case 2 (surrogate gradient, reliable)\n        {\n            'gradient_source': 'surrogate', 'N': 28, 'T': 70, 'r': 4,\n            'K': 25, 'lambda': 1e-6, 'epsilon': 1e-3, 'delta': 0.25,\n            'w': 0.7, 'c1': 1.5, 'c2': 1.5, 'seed': 1337\n        },\n        # Case 3 (surrogate gradient, unreliable)\n        {\n            'gradient_source': 'surrogate', 'N': 18, 'T': 50, 'r': 4,\n            'K': 20, 'lambda': 1e-6, 'epsilon': 1e-6, 'delta': 0.10,\n            'w': 0.7, 'c1': 1.5, 'c2': 1.5, 'seed': 202\n        },\n        # Case 4 (adjoint-like gradient, low noise)\n        {\n            'gradient_source': 'adjoint', 'N': 22, 'T': 60, 'r': 5,\n            'sigma': 0.01, 'D': 5, 'rho': 0.6, 'tau': 0.20,\n            'w': 0.7, 'c1': 1.5, 'c2': 1.5, 'seed': 99\n        },\n        # Case 5 (adjoint-like gradient, high noise, boundary initialization)\n        {\n            'gradient_source': 'adjoint', 'N': 22, 'T': 60, 'r': 5,\n            'sigma': 0.30, 'D': 5, 'rho': 0.6, 'tau': 0.15,\n            'w': 0.7, 'c1': 1.5, 'c2': 1.5, 'seed': 111,\n            'special_init': True\n        }\n    ]\n\n    results = []\n    for params in test_cases:\n        solver = HybridPSOSolver(params)\n        best_value = solver.optimize()\n        results.append(f\"{best_value:.6f}\")\n\n    print(f\"[{','.join(results)}]\")\n\nif __name__ == '__main__':\n    solve()\n```"
        },
        {
            "introduction": "标准PSO算法的性能在很大程度上依赖于惯性权重等手动调整的参数。这项高级实践将挑战您通过实现一种自适应惯性权重机制，来创建一个更智能、更自主的粒子群。您将推导一种方法，使粒子群能够实时评估自身进展，并利用该信息动态调整其惯性，从而在无需人工干预的情况下平衡探索与利用 。",
            "id": "3938452",
            "problem": "您的任务是为自动化电池设计推导并实现一种自适应粒子群优化(PSO)程序。该自适应过程必须基于使用适应度提升的移动平均值对进度进行在线估计。核心要求是，从基本原理出发，推导出一个进度估计器和一个有原则的映射，以调整惯性权重从而避免停滞。然后，实现完整的算法来解决一个无量纲的代理电池设计问题。\n\n该代理电池设计问题定义在一个四维连续决策向量 $x = [f_{\\mathrm{c}}, f_{\\mathrm{a}}, \\phi, \\tau]$ 上，其中 $f_{\\mathrm{c}}$ 是阴极活性材料体积分数，$f_{\\mathrm{a}}$ 是阳极活性材料体积分数，$\\phi$ 是电解质孔隙率，$\\tau$ 是一个无量纲的隔膜厚度比例因子。其边界范围是：\n- $f_{\\mathrm{c}} \\in [0.3, 0.7]$\n- $f_{\\mathrm{a}} \\in [0.3, 0.7]$\n- $\\phi \\in [0.2, 0.5]$\n- $\\tau \\in [0.4, 1.0]$\n\n需要最小化的复合无量纲成本定义为\n$$\nF(x;k_E,k_R) = k_R \\cdot \\frac{\\tau}{\\phi^{1.5}} - k_E \\cdot (f_{\\mathrm{c}} + f_{\\mathrm{a}})\\cdot (1 - 0.5\\,\\tau)\\cdot(1 - 0.4\\,\\phi),\n$$\n为了进行鲁棒性测试，可以选择性地添加高斯评估噪声 $n \\sim \\mathcal{N}(0,\\sigma^2)$，从而得到评估成本\n$$\n\\tilde{F}(x) = F(x;k_E,k_R) + n.\n$$\n\n您的推导必须从标准的PSO更新规则（一个经过充分测试的基础）开始：\n- 位置更新: $x_{i}(t+1) = x_{i}(t) + v_{i}(t+1)$\n- 速度更新: $v_{i}(t+1) = w_t\\, v_{i}(t) + c_1\\, r_{1}(t)\\, (p_{i}(t) - x_{i}(t)) + c_2\\, r_{2}(t)\\, (g(t) - x_{i}(t))$\n其中 $i$ 是粒子索引，$t$ 是迭代次数，$w_t$ 是时间 $t$ 的惯性权重，$c_1$ 和 $c_2$ 是加速系数，$r_1(t)$ 和 $r_2(t)$ 是在 $[0,1]$ 上独立的均匀分布随机变量，$p_i(t)$ 是粒子 $i$ 的个体最优位置，$g(t)$ 是全局最优位置。\n\n在此基础上，您必须：\n- 使用全局最优成本的非负改进量来定义一个在线进度信号 $\\Delta_t = \\max\\{0,\\, \\tilde{F}(g(t-1)) - \\tilde{F}(g(t))\\}$。\n- 使用简单移动平均(SMA)或指数移动平均(EMA)构建 $\\Delta_t$ 的短期和长期移动平均值，并确保您的估计器是因果且数值稳定的。将它们分别表示为 $S_t$ 和 $L_t$，其中 $S_t$ 强调近期进度，$L_t$ 捕捉趋势级进度。\n- 从 $S_t$ 和 $L_t$ 推导出对停滞与持续改进敏感的无量纲进度比率 $R_t$。\n- 基于此进度估计器，推导一个单调映射 $w_t = \\mathcal{W}(R_t)$，当 $R_t$ 表明停滞时增加 $w_t$（以鼓励探索），当 $R_t$ 表明进展显著时减少 $w_t$（以鼓励开采）。强制 $w_t \\in [w_{\\min}, w_{\\max}]$，其中固定的 $w_{\\min}$ 和 $w_{\\max}$ 旨在保持稳定性。\n\n您的程序必须实现带有推导出的 $w_t$ 规律的完整PSO算法，将其应用于代理电池设计问题，并报告指定测试套件的结果。您必须使用 $c_1 = 1.4$ 和 $c_2 = 1.4$。每次位置更新后，粒子的位置必须被限制在边界内。个体最优值 $p_i(t)$ 和全局最优值 $g(t)$ 必须仅在严格改进时才更新。\n\n测试套件：\n为以下四个测试用例提供结果，每个用例由粒子数量 $N$、迭代次数 $T$、短期和长期EMA系数 $\\alpha_s$ 和 $\\alpha_\\ell$、惯性边界 $w_{\\min}$ 和 $w_{\\max}$、进度到惯性映射参数 $\\kappa$ 和 $r_0$、噪声标准差 $\\sigma$、代理参数 $k_E$ 和 $k_R$、伪随机种子 $\\text{seed}$，以及所有粒子是否从相同的中点位置开始 $\\text{init\\_same}$ 指定：\n\n- 用例1：$N=30$, $T=120$, $\\alpha_s=0.20$, $\\alpha_\\ell=0.05$, $w_{\\min}=0.30$, $w_{\\max}=0.90$, $\\kappa=4.0$, $r_0=1.0$, $\\sigma=0.01$, $k_E=1.00$, $k_R=0.35$, $\\text{seed}=42$, $\\text{init\\_same}=\\text{False}$。\n- 用例2：$N=20$, $T=120$, $\\alpha_s=0.20$, $\\alpha_\\ell=0.02$, $w_{\\min}=0.40$, $w_{\\max}=0.95$, $\\kappa=5.0$, $r_0=1.2$, $\\sigma=0.00$, $k_E=0.50$, $k_R=0.35$, $\\text{seed}=123$, $\\text{init\\_same}=\\text{False}$。\n- 用例3：$N=10$, $T=80$, $\\alpha_s=0.25$, $\\alpha_\\ell=0.05$, $w_{\\min}=0.30$, $w_{\\max}=0.95$, $\\kappa=4.0$, $r_0=1.0$, $\\sigma=0.00$, $k_E=1.00$, $k_R=0.35$, $\\text{seed}=7$, $\\text{init\\_same}=\\text{True}$。\n- 用例4：$N=40$, $T=150$, $\\alpha_s=0.15$, $\\alpha_\\ell=0.03$, $w_{\\min}=0.35$, $w_{\\max}=0.95$, $\\kappa=4.0$, $r_0=0.8$, $\\sigma=0.05$, $k_E=1.00, k_R=0.35$, $\\text{seed}=2024$, $\\text{init\\_same}=\\text{False}$。\n\n输出规范：\n- 对于每个测试用例，运行您的自适应PSO并记录最终的最优成本值 $\\tilde{F}(g(T))$，结果为四舍五入到4位小数的实数。\n- 您的程序应生成单行输出，其中包含一个方括号括起来的、按测试用例顺序排列的逗号分隔列表，例如：$[\\text{result}_1,\\text{result}_2,\\text{result}_3,\\text{result}_4]$。\n- 每个列表元素必须是浮点数。由于目标函数和输出在构造上是无量纲的，因此不涉及单位。",
            "solution": "为代理电池设计问题设计一个自适应粒子群优化(PSO)算法，在计算优化和工程领域是一项有效、适定且有科学依据的任务。该问题为完整且可验证的解决方案提供了所有必要的定义、常数和测试用例。我们将首先按要求推导自适应机制，然后实现完整的算法。\n\n### 自适应惯性权重机制的推导\n\n我们自适应PSO的基础是标准的更新方程组。对于迭代 $t$ 中的每个粒子 $i$，其速度 $v_i$ 和位置 $x_i$ 更新如下：\n$$v_{i}(t+1) = w_t\\, v_{i}(t) + c_1\\, r_{1}(t)\\, (p_{i}(t) - x_{i}(t)) + c_2\\, r_{2}(t)\\, (g(t) - x_{i}(t))$$\n$$x_{i}(t+1) = x_{i}(t) + v_{i}(t+1)$$\n其中 $w_t$ 是我们旨在推导的自适应惯性权重。$p_i(t)$ 是粒子 $i$ 的个体最优位置，$g(t)$ 是迄今为止粒子群发现的全局最优位置。系数 $c_1$ 和 $c_2$ 是加速常数，$r_1(t), r_2(t)$是从均匀分布 $U(0,1)$ 中采样的随机数。\n\n目标是根据搜索进度动态调整 $w_t$，以平衡探索（搜索新区域）和开采（精炼现有的优良解）。高惯性权重鼓励探索，而低惯性权重有利于开采。\n\n**1. 在线进度信号 ($\\Delta_t$)**\n我们基于每次迭代中全局最优成本的改进来定义一个进度信号。设 $\\tilde{F}(x)$ 是我们寻求最小化的评估成本函数。在迭代 $t$ 时的全局最优成本是 $\\tilde{F}(g(t))$。从迭代 $t-1$到 $t$ 的改进量 $\\Delta_t$ 定义为该成本的非负变化：\n$$\\Delta_t = \\max\\{0, \\tilde{F}(g(t-1)) - \\tilde{F}(g(t))\\}$$\n当找到更优解时，此信号为正，否则为零。\n\n**2. 短期和长期进度平均值 ($S_t, L_t$)**\n为了区分近期表现和长期趋势，我们采用进度信号 $\\Delta_t$ 的两个指数移动平均(EMA)。选择EMA是因为其计算效率高和具有因果性。\n短期平均值 $S_t$ 使用一个较大的平滑因子 $\\alpha_s$，以便对近期的进度变化更敏感。\n$$S_t = \\alpha_s \\Delta_t + (1 - \\alpha_s) S_{t-1}$$\n长期平均值 $L_t$ 使用一个较小的平滑因子 $\\alpha_\\ell$（其中 $\\alpha_\\ell  \\alpha_s$），以捕捉更广泛的改进趋势。\n$$L_t = \\alpha_\\ell \\Delta_t + (1 - \\alpha_\\ell) L_{t-1}$$\n两个平均值都初始化为零，即 $S_0 = 0$ 和 $L_0 = 0$。\n\n**3. 无量纲进度比率 ($R_t$)**\n我们构建一个无量纲比率 $R_t$ 来量化搜索的状态。该比率将短期进度与长期进度进行比较：\n$$R_t = \\frac{S_t + \\epsilon}{L_t + \\epsilon}$$\n在分子和分母上都加上一个小的正常数 $\\epsilon$（例如 $10^{-9}$），以确保数值稳定性，特别是在搜索开始时 $S_t$ 和 $L_t$ 都可能为零的情况下。\n- 如果 $R_t > 1$，意味着近期进度大于长期平均水平，表明粒子群进展良好（开采可能是有益的）。\n- 如果 $R_t  1$，意味着近期进度已低于长期平均水平，表明搜索可能正在停滞（可能需要探索）。\n\n**4. 惯性权重映射 ($w_t = \\mathcal{W}(R_t)$)**\n最后一步是创建一个从进度比率 $R_t$ 到惯性权重 $w_t$ 的映射。该映射必须满足两个标准：\n- 它必须是单调的，将 $R_t \\in [0, \\infty)$ 映射到 $w_t \\in [w_{\\min}, w_{\\max}]$。\n- 当 $R_t$ 很小（停滞）时，它必须增加 $w_t$；当 $R_t$ 很大（进展显著）时，它必须减少 $w_t$。这意味着 $\\mathcal{W}$ 必须是 $R_t$ 的单调递减函数。\n\n一个满足这些要求并包含所提供的测试参数 $\\kappa$ 和 $r_0$ 的合适函数是反向逻辑（sigmoid）函数。我们将该映射定义为：\n$$w_t = \\mathcal{W}(R_t) = w_{\\min} + (w_{\\max} - w_{\\min}) \\cdot \\frac{1}{1 + \\exp\\left(\\kappa (R_t - r_0)\\right)}$$\n我们来分析这个映射：\n- 参数 $r_0$ 作为进度比率的参考点或枢轴点。当 $R_t = r_0$ 时，指数项为 $\\exp(0) = 1$，分数部分变为 $1/2$，此时 $w_t$ 被设置为其范围的中点：$w_t = w_{\\min} + 0.5(w_{\\max} - w_{\\min})$。\n- 参数 $\\kappa > 0$ 控制过渡的陡峭程度。较大的 $\\kappa$ 会导致在枢轴点 $r_0$ 附近，探索和开采之间的切换更为激进。\n- 当 $R_t \\to \\infty$（进展显著）时，指数项趋于无穷大，分数部分趋近于 $0$，而 $w_t \\to w_{\\min}$。这正确地减小了惯性，以鼓励对有希望的区域进行开采。\n- 当 $R_t \\to 0$（停滞）时，指数项趋近于 $\\exp(-\\kappa r_0)$，分数部分趋近于 $(1+\\exp(-\\kappa r_0))^{-1}$，这个值接近 $1$，因此 $w_t$ 趋近于 $w_{\\max}$。这正确地增大了惯性，以促进探索并逃离局部最小值。\n\n$w_t$ 的最终值被裁剪到区间 $[w_{\\min}, w_{\\max}]$ 内以严格执行边界，尽管所选函数自然地将值保持在此范围内。第一次迭代的初始惯性权重 $w_0$ 设置为 $w_{\\max}$，以鼓励在开始时进行广泛的探索。\n\n### 代理电池设计问题\n\n优化在四维向量 $x = [f_{\\mathrm{c}}, f_{\\mathrm{a}}, \\phi, \\tau]$ 上进行，其边界为：\n- $f_{\\mathrm{c}} \\in [0.3, 0.7]$\n- $f_{\\mathrm{a}} \\in [0.3, 0.7]$\n- $\\phi \\in [0.2, 0.5]$\n- $\\tau \\in [0.4, 1.0]$\n\n需要最小化的评估成本为 $\\tilde{F}(x) = F(x;k_E,k_R) + n$，其中 $n \\sim \\mathcal{N}(0,\\sigma^2)$ 是高斯噪声，基础成本为：\n$$F(x;k_E,k_R) = k_R \\cdot \\frac{\\tau}{\\phi^{1.5}} - k_E \\cdot (f_{\\mathrm{c}} + f_{\\mathrm{a}})\\cdot (1 - 0.5\\,\\tau)\\cdot(1 - 0.4\\,\\phi)$$\n\n实现将遵循上述推导的逻辑，为问题陈述中指定的每个测试用例执行自适应PSO。",
            "answer": "```python\nimport numpy as np\n\ndef run_adaptive_pso(\n    N, T, alpha_s, alpha_ell, w_min, w_max, kappa, r_0,\n    sigma, k_E, k_R, seed, init_same\n):\n    \"\"\"\n    Runs the adaptive Particle Swarm Optimization algorithm for one test case.\n\n    Args:\n        N (int): Number of particles.\n        T (int): Number of iterations.\n        alpha_s (float): Short-term EMA coefficient.\n        alpha_ell (float): Long-term EMA coefficient.\n        w_min (float): Minimum inertia weight.\n        w_max (float): Maximum inertia weight.\n        kappa (float): Steepness parameter for inertia mapping.\n        r_0 (float): Pivot parameter for inertia mapping.\n        sigma (float): Standard deviation of evaluation noise.\n        k_E (float): Energy parameter for the objective function.\n        k_R (float): Resistance parameter for the objective function.\n        seed (int): Seed for the pseudo-random number generator.\n        init_same (bool): If True, all particles start at the center of the search space.\n\n    Returns:\n        float: The best cost found by the algorithm.\n    \"\"\"\n    # Constants and parameters from the problem statement\n    DIMS = 4\n    C1 = 1.4\n    C2 = 1.4\n    EPSILON = 1e-9  # For numerical stability in progress ratio\n\n    # Search space bounds\n    bounds_lo = np.array([0.3, 0.3, 0.2, 0.4])\n    bounds_hi = np.array([0.7, 0.7, 0.5, 1.0])\n\n    # Initialize random number generator for reproducibility\n    rng = np.random.default_rng(seed)\n\n    def objective_function(x_vec):\n        \"\"\"Calculates the surrogate cost for a given design vector x.\"\"\"\n        f_c, f_a, phi, tau = x_vec[0], x_vec[1], x_vec[2], x_vec[3]\n        term_R = k_R * tau / (phi**1.5)\n        term_E = k_E * (f_c + f_a) * (1.0 - 0.5 * tau) * (1.0 - 0.4 * phi)\n        cost = term_R - term_E\n        noise = rng.normal(0, sigma) if sigma > 0 else 0.0\n        return cost + noise\n\n    # Initialization (t=0)\n    if init_same:\n        mid_point = (bounds_lo + bounds_hi) / 2.0\n        positions = np.tile(mid_point, (N, 1))\n    else:\n        positions = rng.uniform(low=bounds_lo, high=bounds_hi, size=(N, DIMS))\n    \n    velocities = np.zeros((N, DIMS))\n    \n    # Evaluate initial positions\n    costs = np.array([objective_function(p) for p in positions])\n    \n    # Initialize personal and global bests\n    pbest_positions = np.copy(positions)\n    pbest_costs = np.copy(costs)\n    \n    min_cost_idx = np.argmin(pbest_costs)\n    gbest_position = np.copy(pbest_positions[min_cost_idx])\n    gbest_cost = pbest_costs[min_cost_idx]\n    \n    # Initialize adaptive mechanism variables\n    short_term_avg = 0.0\n    long_term_avg = 0.0\n    w = w_max  # Start with high inertia for exploration\n    prev_gbest_cost = gbest_cost\n\n    # Main PSO loop for T iterations\n    for _ in range(T):\n        # Update velocities and positions for all particles (vectorized)\n        r1 = rng.random(size=(N, DIMS))\n        r2 = rng.random(size=(N, DIMS))\n        \n        cognitive_comp = C1 * r1 * (pbest_positions - positions)\n        social_comp = C2 * r2 * (gbest_position - positions)\n        \n        velocities = w * velocities + cognitive_comp + social_comp\n        positions = positions + velocities\n        \n        # Apply bounds (clipping)\n        positions = np.clip(positions, bounds_lo, bounds_hi)\n        \n        # Evaluate new positions\n        costs = np.array([objective_function(p) for p in positions])\n        \n        # Update personal bests (strict improvement)\n        improved_mask = costs  pbest_costs\n        pbest_positions[improved_mask] = positions[improved_mask]\n        pbest_costs[improved_mask] = costs[improved_mask]\n        \n        # Update global best (strict improvement)\n        min_pbest_idx = np.argmin(pbest_costs)\n        if pbest_costs[min_pbest_idx]  gbest_cost:\n            gbest_cost = pbest_costs[min_pbest_idx]\n            gbest_position = pbest_positions[min_pbest_idx]\n\n        # --- Adaptive Inertia Weight Update ---\n        # 1. Calculate progress signal\n        delta = max(0, prev_gbest_cost - gbest_cost)\n        prev_gbest_cost = gbest_cost\n        \n        # 2. Update moving averages\n        short_term_avg = alpha_s * delta + (1.0 - alpha_s) * short_term_avg\n        long_term_avg = alpha_ell * delta + (1.0 - alpha_ell) * long_term_avg\n        \n        # 3. Calculate progress ratio\n        progress_ratio = (short_term_avg + EPSILON) / (long_term_avg + EPSILON)\n        \n        # 4. Calculate new inertia weight using the derived mapping\n        sigmoid_term = 1.0 / (1.0 + np.exp(kappa * (progress_ratio - r_0)))\n        w_new = w_min + (w_max - w_min) * sigmoid_term\n        w = np.clip(w_new, w_min, w_max)\n        \n    return gbest_cost\n\ndef solve():\n    \"\"\"\n    Defines and runs the test suite for the adaptive PSO algorithm.\n    \"\"\"\n    test_cases = [\n        # Case 1\n        {\"N\": 30, \"T\": 120, \"alpha_s\": 0.20, \"alpha_ell\": 0.05, \"w_min\": 0.30, \n         \"w_max\": 0.90, \"kappa\": 4.0, \"r_0\": 1.0, \"sigma\": 0.01, \"k_E\": 1.00, \n         \"k_R\": 0.35, \"seed\": 42, \"init_same\": False},\n        # Case 2\n        {\"N\": 20, \"T\": 120, \"alpha_s\": 0.20, \"alpha_ell\": 0.02, \"w_min\": 0.40, \n         \"w_max\": 0.95, \"kappa\": 5.0, \"r_0\": 1.2, \"sigma\": 0.00, \"k_E\": 0.50, \n         \"k_R\": 0.35, \"seed\": 123, \"init_same\": False},\n        # Case 3\n        {\"N\": 10, \"T\": 80, \"alpha_s\": 0.25, \"alpha_ell\": 0.05, \"w_min\": 0.30, \n         \"w_max\": 0.95, \"kappa\": 4.0, \"r_0\": 1.0, \"sigma\": 0.00, \"k_E\": 1.00, \n         \"k_R\": 0.35, \"seed\": 7, \"init_same\": True},\n        # Case 4\n        {\"N\": 40, \"T\": 150, \"alpha_s\": 0.15, \"alpha_ell\": 0.03, \"w_min\": 0.35, \n         \"w_max\": 0.95, \"kappa\": 4.0, \"r_0\": 0.8, \"sigma\": 0.05, \"k_E\": 1.00, \n         \"k_R\": 0.35, \"seed\": 2024, \"init_same\": False},\n    ]\n\n    results = []\n    for params in test_cases:\n        final_cost = run_adaptive_pso(**params)\n        results.append(round(final_cost, 4))\n        \n    # Print the results in the specified format\n    print(f\"[{','.join(map(str, results))}]\")\n\n# Execute the solver\nsolve()\n```"
        }
    ]
}