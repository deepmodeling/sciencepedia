## 引言
在新一代储能技术（尤其是先进电池）的研发竞赛中，发现具有优越性能的新材料是取得突破的关键。然而，材料的设计空间极其广阔且复杂，传统的试错法研究模式已难以满足快速创新的需求。[实验设计](@entry_id:142447)（Design of Experiments, DOE）与虚拟筛选（Virtual Screening）作为数据驱动科学的核心方法论，提供了一条系统性、高效率的路径，用以加速材料的发现、优化和验证过程，从而解决了这一根本性的挑战。

本文旨在全面介绍[实验设计](@entry_id:142447)与虚拟筛选在自动化电池研发中的应用。通过本文的学习，您将掌握从构建高效实验到实现闭环自主发现的完整知识体系。在第一部分“原理与机制”中，我们将深入探讨[实验设计](@entry_id:142447)的基本变量、响应曲面建模、贝叶斯代理模型以及不确定性量化的核心概念。接着，在第二部分“应用与跨学科联系”中，我们将展示这些原理如何应用于[高通量筛选](@entry_id:271166)、融合模拟与实验，以及在自动化实验室中实现包含安全约束的复杂[多目标优化](@entry_id:637420)。最后，通过第三部分“动手实践”，您将有机会通过解决具体问题，将理论知识转化为实践技能。

本系列文章将引导您从基础理论出发，逐步深入前沿应用，最终掌握在您自己的研究领域中实施高效数据驱动策略的能力。让我们首先从构建科学探究结构的基础——[实验设计](@entry_id:142447)的原理与机制开始。

## 原理与机制

### [实验设计](@entry_id:142447)的基础：构建探究的结构

在自动化电池发现的背景下，[实验设计](@entry_id:142447)（Design of Experiments, DOE）和[虚拟筛选](@entry_id:171634)（Virtual Screening, VS）为我们提供了一套系统性的方法，用以高效地探索广阔的设计空间、理解材料-性能关系并最终优化[电池性能](@entry_id:1121436)。其核心在于通过精心设计的实验来最大化信息获取，同时最小化资源消耗。要构建这样的实验，我们必须首先清晰地界定实验中涉及的各种变量类型。

根据其在实验过程中的角色，变量可以分为三类 ：

1.  **可控因子（Controllable Factors）**：这些是实验者可以根据设计意图精确设定其水平的变量。在电解液配方研究中，可控因子是实验的核心，例如，锂盐在溶剂中的摩尔分数（$x_{\mathrm{LiPF_6}}$）、不同溶剂（如碳酸亚乙酯EC与碳酸甲乙[酯](@entry_id:187919)EMC）的体积比（$r_{\mathrm{EC:EMC}}$）、以及添加剂（如碳酸氟代亚乙酯FEC）的浓度（$c_{\mathrm{FEC}}$）。环境仓的设定温度（$T_{\mathrm{set}}$）也属于可控因子，因为它是实验者预设的条件。

2.  **不可控因子（Uncontrollable Factors）或噪声因子（Noise Factors）**：这些变量会影响实验结果，但实验者无法对其进行精确控制或设定。它们是实验变异性的来源。例如，实验室环境的相对湿度（$h$）可能随天气变化而波动，如果无法控制或精确记录，它就成为一个噪声因子。同样，来自不同供应商或批次的[电极材料](@entry_id:199373)也可能存在微观结构（如孔隙度 $\phi$ 和曲折度 $\tau$）的差异，如果实验者无法为特定实验选择特定批次，那么这种批次间的差异就构成了噪声。

3.  **[协变](@entry_id:634097)量（Covariates）**：这些变量不由实验者设定，但可以在每次实验运行时进行测量。在数据分析阶段，[协变](@entry_id:634097)量被纳入模型中，以调整其对响应的影响，从而提高模型精度并减少对可控因子效应估计的偏差。例如，尽管我们设定了环境温度 $T_{\mathrm{set}}$，但电池在测试（如电化学阻抗谱EIS测量）期间的实际温度 $T_{\mathrm{actual}}$ 可能存在微小偏离。通过测量 $T_{\mathrm{actual}}$，我们可以在分析中校正温度的真实影响。类似地，电解液中痕量的水分含量（$w$）对性能有显著影响，虽然难以精确控制，但可以通过[卡尔·费休滴定](@entry_id:265713)法在每次运行时测量，作为协变量进行分析。仪器的校准偏移（$\delta$）也可以通过每日的基准测量被当作[协变](@entry_id:634097)量来修正结果。

识别并恰当处理这些变量是设计稳健实验的第一步。对于已知的、会引入系统性差异的干扰变量（nuisance variable），我们可以采用**区组化（Blocking）**的策略。区组是一组具有共同干扰效应的实验单元。通过在每个区组内完整地实施一次[实验设计](@entry_id:142447)，我们可以将区组间的差异从[实验误差](@entry_id:143154)中分离出来，从而提高实验的精度。

例如，在一个电池研究实验室中，假设有三个[手套箱](@entry_id:264554)（glovebox）用于组装扣式电池 。尽管这些[手套箱](@entry_id:264554)的标称规格相同，但它们内部的微量水分、氧气含量等环境条件可能存在细微差异，从而系统性地影响电池性能。此时，[手套箱](@entry_id:264554)便构成了一个天然的区组。如果我们需要测试一个包含8种不同处理组合（例如，由电解液摩尔浓度、正极载量和化成电流三个两水平因子构成的 $2^3$ 全[因子设计](@entry_id:921332)）的实验，而每个[手套箱](@entry_id:264554)恰好可以容纳8个电池的组装，那么最佳策略就是采用**[随机完全区组设计](@entry_id:900213)（Randomized Complete Block Design, RCBD）**。在该设计中，每个[手套箱](@entry_id:264554)（区组）内部都完整地进行一次包含全部8种处理的实验，并将这8种处理的组装顺序在每个[手套箱](@entry_id:264554)内进行随机化。

在分析RCBD数据时，我们还需要决定如何处理区组效应。如果我们的目标仅仅是理解这三个特定[手套箱](@entry_id:264554)内的效应，我们可以将[手套箱](@entry_id:264554)视为**固定效应（fixed effect）**。然而，如果我们的目标是获得具有普遍性的结论——即我们希望从这三个[手套箱](@entry_id:264554)的实验结果推断出未来在任何[手套箱](@entry_id:264554)中组装电池时的[处理效应](@entry_id:636010)，那么就应将[手套箱](@entry_id:264554)视为**随机效应（random effect）**。这种做法假设我们所用的三个[手套箱](@entry_id:264554)是从一个更大的、具有代表性的[手套箱](@entry_id:264554)总体中随机抽取的样本。为了实现结果的**普适性（generalizability）**，这对于旨在为虚拟筛选流程提供参数的实验至关重要，[随机效应模型](@entry_id:914467)是更合适的选择。

因此，一个恰当的分析模型是**[线性混合效应模型](@entry_id:917842)（linear mixed-effects model）**。对于在[手套箱](@entry_id:264554) $g$ 中处理 $i$ 的响应 $y_{ig}$，模型可以表示为：
$$
y_{ig} = (\text{固定效应}) + (\text{随机效应}) + (\text{误差})
$$
具体地，展开固定效应部分，模型为：
$$
y_{ig} = \mu + \alpha_{A(i)} + \beta_{B(i)} + \gamma_{C(i)} + (\alpha\beta)_{A(i)B(i)} + (\alpha\gamma)_{A(i)C(i)} + (\beta\gamma)_{B(i)C(i)} + (\alpha\beta\gamma)_{A(i)B(i)C(i)} + b_g + \varepsilon_{ig}
$$
其中，$\mu$ 是总均值，$\alpha, \beta, \gamma$ 及其交互项代表了因子A、B、C的固定效应。$b_g$ 是[手套箱](@entry_id:264554)的随机效应，通常假设服从正态分布 $b_g \sim \mathcal{N}(0,\sigma_b^2)$，其方差 $\sigma_b^2$ 度量了[手套箱](@entry_id:264554)间的变异性。$\varepsilon_{ig}$ 是[随机误差](@entry_id:144890)项，假设 $\varepsilon_{ig} \sim \mathcal{N}(0,\sigma^2)$。通过这种方式，我们不仅能准确估计[处理效应](@entry_id:636010)，还能量化并分离出[手套箱](@entry_id:264554)带来的变异，使得对[处理效应](@entry_id:636010)的推断更为准确和普适。

### 响应曲面建模：从线性模型到代理模型

[实验设计](@entry_id:142447)的核心目标之一是建立输入因子与输出响应之间的数学模型，即**响应曲面模型（Response Surface Model, RSM）**。这个模型使我们能够预测未曾实验过的因子组合的性能，并找到最优的设置。

#### 经典方法：[响应曲面法](@entry_id:1130964)

在许多情况下，一个局部的响应曲面可以通过一个低阶多项式来近似。**二阶响应曲面模型**（或称“全二次模型”）是RSM中最常用的模型之一，因为它能够捕捉到线性和曲率效应，以及因子间的[交互作用](@entry_id:164533) 。对于 $k$ 个因子 $x_1, x_2, \dots, x_k$，全二次模型表达式为：
$$
y = \beta_0 + \sum_{i=1}^{k} \beta_i x_i + \sum_{i=1}^{k} \beta_{ii} x_i^2 + \sum_{1 \le i  j \le k} \beta_{ij} x_i x_j + \varepsilon
$$
该模型包含一个截距项 $\beta_0$，$k$ 个线性项 $\beta_i$，$k$ 个纯二次项 $\beta_{ii}$，以及 $\binom{k}{2}$ 个二因子交互项 $\beta_{ij}$。总共有 $p = 1 + k + k + \frac{k(k-1)}{2} = \frac{(k+1)(k+2)}{2}$ 个参数需要估计。

为了能够唯一地估计所有这些参数，[实验设计](@entry_id:142447)必须满足**[可辨识性](@entry_id:194150)（identifiability）**条件。在线性模型 $Y = X\beta + \varepsilon$ 的框架下，这意味着[设计矩阵](@entry_id:165826) $X$ 必须是**列满秩（full column rank）**的，等价于信息矩阵 $(X^\top X)$ 是非奇异的（即可逆的）。要满足此条件，实验运行次数 $n$ 必须至少等于参数个数 $p$（即 $n \ge p$），并且实验点的选择必须确保 $X$ 的任何一列都不是其他[列的线性组合](@entry_id:150240)。例如，为了估计纯二次项 $\beta_{ii}x_i^2$，因子 $x_i$ 必须至少取三个不同的水平。如果一个因子只取两个水平（如-1和+1），那么 $x_i^2$ 将恒等于1，导致其对应的列与截距项的列完全相同，从而使 $(X^\top X)$ 奇异。值得注意的是，简单地在某个[设计点](@entry_id:748327)上进行**重复实验（replication）**虽然可以帮助我们估计纯误差，但并不能增加设计矩阵的秩，因此无法解决因[设计点](@entry_id:748327)选择不当而导致的可辨识性问题。

#### 现代方法：贝叶斯代理建模

当响应曲面非常复杂，难以用低阶多项式描述时，现代自动化实验平台转向了更灵活的**贝叶斯代理模型（Bayesian Surrogate Model）**，其中**高斯过程（Gaussian Process, GP）**回归是应用最广泛的技术。

一个[高斯过程](@entry_id:182192)是一种对函数的分布，它将函数 $f(\mathbf{x})$ 视为一个[随机变量](@entry_id:195330)的集合，其中任意有限个点的函数值的[联合分布](@entry_id:263960)都服从多元高斯分布 。一个GP由其**[均值函数](@entry_id:264860)** $m(\mathbf{x})$ 和**协方差函数**（或称**核函数**）$k(\mathbf{x},\mathbf{x}')$ 完全定义，记为 $f(\mathbf{x}) \sim \mathcal{GP}(m(\mathbf{x}), k(\mathbf{x},\mathbf{x}'))$。

- **[均值函数](@entry_id:264860) $m(\mathbf{x})$**：通常设置为一个简单的函数（如常数或线性函数），用于捕捉数据的全局趋势。
- **核函数 $k(\mathbf{x},\mathbf{x}')$**：这是GP模型的核心，它编码了我们对函数性质的先验信念，尤其是**光滑度（smoothness）**。[核函数](@entry_id:145324)定义了任意两点 $\mathbf{x}$ 和 $\mathbf{x}'$ 处函数值之间的协方差，即 $k(\mathbf{x},\mathbf{x}') = \mathrm{cov}(f(\mathbf{x}), f(\mathbf{x}'))$。如果两个点在输入空间中彼此接近，我们通常期望它们的函数值也相似，核函数的值就应该较大。

核函数的选择及其**超参数（hyperparameters）**极大地影响了模型的行为：
- **信号方差（signal variance）$\sigma_f^2$**：作为[核函数](@entry_id:145324)的一个[乘性](@entry_id:187940)因子，它控制了函数 $f(\mathbf{x})$ 偏离其均值的典型幅度。较大的 $\sigma_f^2$ 意味着我们先验地认为函数会有较大的波动。这与测量噪声 $\sigma_n^2$ 是两个独立的概念，后者描述了观测值 $y$ 在真实函数值 $f(\mathbf{x})$ 周围的散布程度。

- **长度尺度（length-scale）$l_j$**：在诸如**[平方指数核](@entry_id:191141)（Squared-Exponential Kernel）**中，长度尺度控制了函数在特定维度上的变化速度。一个较大的长度尺度 $l_j$ 意味着函数在维度 $j$ 上变化平缓，相关性会延伸到较远的距离。相反，一个较小的长度尺度意味着函数在该维度上变化迅速且“崎岖”，表明该输入维度对函数值影响很大。通过为每个输入维度 $j$ 分配一个独立的长度尺度 $l_j$，即**自动相关性判定（Automatic Relevance Determination, ARD）**，GP可以自动地从数据中学习到不同因子的相对重要性。

- **光滑度参数 $\nu$**：某些核族，如**Matérn核**，含有一个光滑度参数 $\nu$。这个参数直接控制了GP样本路径（即从GP先验中抽取的函数）的均方[可微性](@entry_id:140863)。与直觉相反，$\nu$ 值越小，函数越“粗糙”（不可微）；$\nu$ 值越大，函数越光滑。例如，当 $\nu = 1/2$ 时，函数是[连续但不可微](@entry_id:261860)的；当 $\nu \to \infty$ 时，Matérn核趋近于无限次可微的[平方指数核](@entry_id:191141)。

在贝叶斯框架下，给定观测数据，GP模型会给出一个后验分布。对于任何新的测试点 $\mathbf{x}_\star$，其预测结果不是一个单一的值，而是一个完整的概率分布（也是高斯分布）。这个[预测分布](@entry_id:165741)包含了我们对该点性能的期望（后验均值）和不确定性（后验方差）。正是这种[量化不确定性](@entry_id:272064)的能力，使GP成为[序贯决策](@entry_id:145234)的理想工具。

### 理解并管理不确定性

在贝叶斯代理建模中，精确地区分和处理不同类型的不确定性至关重要，因为它直接影响我们的实验策略和决策制定 。预测中的不确定性主要来源于两个方面：

1.  **认知不确定性（Epistemic Uncertainty）**：这种不确定性源于我们对真实潜在函数 $f(\mathbf{x})$ 的知识有限。它体现在代理模型的后验分布的宽度上（例如，GP的后验方差 $\sigma_f^2(\mathbf{x})$）。在数据稀疏的区域，认知不确定性较大；在数据密集的区域，认知不确定性较小。原则上，通过收集更多的实验数据，认知不确定性是可以被**缩减**的。

2.  **[偶然不确定性](@entry_id:634772)（Aleatoric Uncertainty）**：这种不确定性是数据生成过程本身固有的、不可避免的随机性，对应于模型 $y = f(\mathbf{x}) + \varepsilon(\mathbf{x})$ 中的噪声项 $\varepsilon(\mathbf{x})$。即使我们完全知道了函数 $f(\mathbf{x})$，每次重复实验的测量结果仍然会因为制造工艺的微小差异、测量仪器的噪声等因素而波动。这种不确定性是**不可缩减**的。其方差 $\sigma^2_{\text{alea}}(\mathbf{x})$ 可以是**同方差的（homoscedastic）**（在整个设计空间中为常数），也可以是**异方差的（heteroscedastic）**（随 $\mathbf{x}$ 的变化而变化）。

根据**[全方差公式](@entry_id:177482)（Law of Total Variance）**，对一个新观测 $y$ 的总预测方差是这两种不确定性的加和：
$$
\operatorname{Var}(y \mid \mathbf{x}, \mathcal{D}) = \underbrace{\operatorname{Var}_{f \mid \mathcal{D}} \left( \mathbb{E}[y \mid f, \mathbf{x}, \mathcal{D}] \right)}_{\text{认知不确定性}, \sigma_f^2(\mathbf{x})} + \underbrace{\mathbb{E}_{f \mid \mathcal{D}} \left[ \operatorname{Var}(y \mid f, \mathbf{x}, \mathcal{D}) \right]}_{\text{偶然不确定性}, \sigma^2_{\text{alea}}(\mathbf{x})}
$$
这种分解具有深刻的实践意义：
- **探索（Exploration）**的目标是减少认知不确定性。像**上置信界（Upper Confidence Bound, UCB）**这样的采集函数，其探索项明确地与认知不确定性 $\sigma_f(\mathbf{x})$ 成正比，引导实验走向模型最不确定的区域。
- **重复实验（Replication）**的主要作用是更精确地估计特定点 $\mathbf{x}$ 的均值响应 $f(\mathbf{x})$，从而降低该点的认知不确定性。进行 $n$ 次重复实验，均值的方差会降为 $\sigma^2_{\text{alea}}(\mathbf{x})/n$，这使得我们能够更精确地“钉住”响应曲面在该点的位置。然而，重复实验并不能改变[偶然不确定性](@entry_id:634772) $\sigma^2_{\text{alea}}(\mathbf{x})$ 本身的大小，它只是帮助我们更准确地估计它。
- 在进行**[风险规避](@entry_id:137406)型优化**时，[偶然不确定性](@entry_id:634772)变得至关重要。例如，如果目标是最大化性能高于某个阈值 $\tau$ 的概率，即 $\mathbb{P}(y \ge \tau)$，那么总预测方差 $\sigma_f^2(\mathbf{x}) + \sigma^2_{\text{alea}}(\mathbf{x})$ 会出现在计算公式的分母中。这意味着，即使某个设计的预测均值很高，如果其固有的[偶然不确定性](@entry_id:634772) $\sigma^2_{\text{alea}}(\mathbf{x})$ 也很大，那么它满足条件的可靠性可能会降低，从而在排序中被惩罚。

### 序贯设计：自动化实验的逻辑

将代理模型和[不确定性量化](@entry_id:138597)结合起来，我们便能构建一个[序贯决策](@entry_id:145234)的闭环，这正是自动化实验平台的核心逻辑。每一步，平台都会利用当前所有的数据来更新代理模型，并基于该模型决定下一个最有价值的实验点。这个决策过程体现了著名的**[探索-利用权衡](@entry_id:1124776)（Exploration-Exploitation Trade-off）**。

- **利用（Exploitation）**是指在当前模型认为性能最优的区域进行采样，以期尽快收敛到最佳解。
- **探索（Exploration）**是指在模型不确定性高的区域进行采样，以减少全局的不确定性，避免过早地陷入局部最优。

**多臂老虎机（Multi-armed Bandit, MAB）**问题是理解这一权衡的经典模型。想象我们有两个配方（两臂），每次测试都会得到一个服从某个未知分布的寿命值。我们的目标是在有限的测试次数内找到[平均寿命](@entry_id:195236)最长的配方 。

- **上置信界（UCB）**策略体现了“面对不确定性时的乐观主义”。它为每个配方计算一个指数，该指数是当前样本均值（利用项）加上一个与不确定性（即样本量）相关的奖励项（探索项）。UCB总是选择指数最高的臂，确定性地在当前最有潜力的选项（高均值或高不确定性）上进行投入。
- **汤普森采样（Thompson Sampling, TS）**则是一种概率匹配策略。它首先为每个配方的真实[平均寿命](@entry_id:195236) $\mu_i$ 维护一个后验概率分布（例如，基于[贝叶斯更新](@entry_id:179010)得到的高斯分布）。在每一轮决策时，它从每个臂的后验分布中各抽取一个样本值，然[后选择](@entry_id:154665)样本值最大的那个臂进行实验。这种[随机化](@entry_id:198186)的方式天然地平衡了[探索与利用](@entry_id:174107)：一个均值高但方差小（确定性高）的臂会大概率被抽到高值，而一个均值较低但方差极大（不确定性高）的臂也有机会抽到一个非常高的值，从而获得被探索的机会。

从MAB问题扩展到连续的设计空间，就构成了**[贝叶斯优化](@entry_id:175791)（Bayesian Optimization, BO）**。BO使用GP作为代理模型，并设计**采集函数（acquisition function）**来量化在每个候选点进行下一次实验的“价值”，从而指导[序贯决策](@entry_id:145234)。

在复杂的实际应用中，我们的最终目标不仅仅是走好下一步，而是要优化整个实验流程。一个精确的**统计目标**应当是寻找一个最优的自适应实验**策略（policy）** $\pi$ 和最终推荐规则 $r$，以最大化最终推荐设计 $\hat{x}$ 的期望真实性能 $\mathbb{E}[L(\hat{x})]$，同时满足诸如总实验时间预算 $T$ 之类的约束 。这可以被形式化为一个约束[随机优化](@entry_id:178938)问题：
$$
\sup_{\pi,\, r} \;\mathbb{E}\big[\, L\big(\hat{x}^{\pi,r}\big) \,\big] \quad \text{s.t.} \quad \mathbb{E}\Big[ \sum_{t=1}^{N^{\pi}} C\big(X^{\pi}_t\big) \Big] \le T
$$
其中，期望涵盖了所有不确定性来源，包括对潜在性能函数 $L(\cdot)$ 的先验、[测量噪声](@entry_id:275238)以及随机的实验成本 $C(x)$。这个全局视角提醒我们，短视的、仅关注下一步的决策（如纯探索或纯利用）通常不是最优的。

### 设计高效的实验：经典与最优方法

在启动序贯学习循环之前，以及在某些情况下为了直接建立模型，我们需要选择一组初始的或一次性的实验点。[实验设计](@entry_id:142447)理论为此提供了强大的指导。

#### 筛选设计

当面临大量潜在因子时，我们的首要任务可能是**筛选（screening）**出对响应影响最显著的少数几个因子。**[部分因子设计](@entry_id:926683)（fractional factorial designs）**是一种经典且高效的筛选方法 。它只执行一个$2^k$全因子实验的一个精心选择的“分数”，从而大幅减少实验次数。

这种效率的代价是**混淆（aliasing或[别名](@entry_id:146322)）**：某些效应的估计值会与其他效应的估计值混杂在一起。设计的**分辨率（resolution）**是衡量混淆严重程度的关键指标，它等于定义关系中最短字（word）的长度。
- **分辨率IV设计**：在此类设计中，主效应（main effects）与二阶交互作用（2-factor interactions, 2FIs）不混淆，但二阶交互作用之间会彼此混淆。这意味着我们可以无偏地估计主效应（假设三阶及以上[交互作用](@entry_id:164533)可忽略），但无法将某个二阶交互作用（如 $D_1 \times D_2$）与其他二阶[交互作用](@entry_id:164533)（如 $D_3 \times T$）清晰地分离开。
- **分辨率V设计**：在此类设计中，主效应和二阶交互作用都不会与其他主效应或二阶交互作用混淆。它们的混淆项至少是三阶[交互作用](@entry_id:164533)。因此，如果我们能做出“效应[稀疏性](@entry_id:136793)”假设（即高阶交互作用可忽略），分辨率V设计允许我们无偏地估计所有主效应和所有二阶[交互作用](@entry_id:164533)。

在进行[正极材料](@entry_id:161536)掺杂研究以识别协同效应时，选择分辨率V设计虽然需要更多实验（如$n=32$的$2^{6-1}$设计），但能确保我们准确地识别出关键的二因子交互作用。而分辨率IV设计（如$n=16$的$2^{6-2}$设计）虽然成本更低，但可能会因为[交互作用](@entry_id:164533)间的混淆而导致错误的结论。

#### 最优设计

当我们确定了要拟合的模型（如一个二阶响应曲面模型）后，**最优设计（optimal design）**理论可以帮助我们精确地挑选实验点，以最有效地估计模型参数或进行预测。这通常通过优化基于**信息矩阵** $M = X^\top X$ 的某个标量函数来实现 。

- **[D-最优性](@entry_id:748151)（D-optimality）**：最大化信息[矩阵的行列式](@entry_id:148198) $\det(M)$。这等价于最小化[参数估计](@entry_id:139349)值 $\hat{\beta}$ 的置信椭球体积，从而获得关于参数整体的最精确信息。
- **[A-最优性](@entry_id:746181)（A-optimality）**：最小化 $M^{-1}$ 的迹 $\mathrm{tr}(M^{-1})$。这等价于最小化[参数估计](@entry_id:139349)值的平均方差，适用于希望所有参数都有较高[平均精度](@entry_id:911309)的场景。
- **E-最优性（E-optimality）**：最大化 $M$ 的[最小特征值](@entry_id:177333) $\lambda_{\min}(M)$。这等价于最小化最坏情况下的参数估计方差，是一种稳健的设计标准。
- **G-最优性（G-optimality）**：最小化在整个设计区域 $\mathcal{X}$ 内的最大预测方差 $\sup_{x\in \mathcal{X}} x^\top M^{-1} x$。这对于目标是建立一个在整个关心区域内都表现良好的预测模型的场景尤为重要。

这些标准之间存在深刻的联系。著名的**Kiefer-Wolfowitz等价定理**指出，对于近似设计，D-最优设计与G-最优设计是等价的。此外，一个有趣的结论是，如果一个设计的信息矩阵在保持总信息量（$\mathrm{tr}(M)$）不变的情况下是各向同性的（即所有特征值相等），那么该设计能同时满足D、A和E最优性标准，体现了信息均衡分布的优越性 。

### 综合：一个完整的[虚拟筛选](@entry_id:171634)工作流程

最后，我们可以将上述所有原理和机制整合成一个用于自动化[电池材料发现](@entry_id:1121423)的、完整的虚拟筛选工作流程 。

1.  **问题定义与描述符构建**：明确优化目标（如最大化[离子电导率](@entry_id:156401) $\sigma$）和约束条件（如粘度 $\eta$ 和电化学稳定性窗口 $E_{\mathrm{ox}}$）。构建一套**[物理化学](@entry_id:145220)意义明确的描述符（descriptors）**，这些描述符应能有效捕捉控制目标性能的关键物理过程。例如，基于Nernst-Einstein和[Stokes-Einstein关系](@entry_id:138244)，描述符应包括对[混合物粘度](@entry_id:1127976)、介[电常数](@entry_id:272823)、[离子溶剂化](@entry_id:186215)能、[溶剂化](@entry_id:146105)[离子水合](@entry_id:1126701)半径等的预测或代理。

2.  **初始[实验设计](@entry_id:142447)**：为了训练初始的代理模型，需要一组初始实验数据。应采用**[空间填充设计](@entry_id:755078)（space-filling design）**，如在成分单纯形上进行的拉丁超立方采样（Latin Hypercube Sampling, LHS），以确保在整个设计空间内有良好的覆盖。进行重复实验以估计[偶然不确定性](@entry_id:634772)。

3.  **迭代学习与优化**：
    a.  基于当前所有实验数据，为目标性能（$\sigma$）和约束（$\eta, E_{\mathrm{ox}}$）分别训练GP代理模型。
    b.  采用**[约束贝叶斯优化](@entry_id:197240)**的采集函数，如**约束[期望提升](@entry_id:749168)（constrained Expected Improvement, cEI）**，来选择下一批（batch）实验点。cEI会平衡对高预测性能区域的“利用”和高不确定性区域的“探索”，同时优先考虑满足所有约束条件的可能性。

4.  **验证性测试**：当实验预算耗尽或优化收敛时，从虚拟筛选循环中选出的最优候选配方必须进入严格的**验证性测试**阶段。这包括使用标准实验技术（如用EIS测量电导率、用流变仪测量粘度、用[循环伏安法](@entry_id:156391)测量稳定性）进行精确的、有重复的测量。最终，最有希望的配方还应在全电池（如扣式电池或[软包电池](@entry_id:1130000)）中进行循环性能测试，以确认其在实际应用环境中的表现。

这一从基础原理到综合应用的完整流程，构成了现代[自动化电池设计](@entry_id:1121262)与仿真中[实验设计](@entry_id:142447)和虚拟筛选的核心方法论。