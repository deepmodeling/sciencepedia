## 引言
在数据空前丰富的时代，科学与工程领域面临的一个核心挑战是如何将海量的复杂数据集提炼成简洁、可预测且具有物理解释性的数学模型——即系统的控制方程。实现这一发现过程的自动化，有望彻底改变[材料设计](@entry_id:160450)、气候建模和系统生物学等领域，极大地加速从观测到理解、再到预测的科学循环。

然而，尽管潜力巨大，将原始的、往往充满噪声的数据转化为精确的[微分](@entry_id:158422)方程语言，仍然面临着重大的理论与实践障碍。本文旨在深入应对这一挑战，为“数据驱动的控制[方程发现](@entry_id:1124591)”这一前沿领域提供一份全面的指南。

为了系统地探索这一激动人心的领域，我们将踏上一段结构化的旅程。第一章 **“原理与机制”** 将奠定理论基石，深入剖析对含噪数据进行[微分](@entry_id:158422)的核心挑战，并介绍为克服这一挑战而设计的强大框架，如[稀疏回归](@entry_id:276495)（SINDy）和物理信息神经网络（[PINNs](@entry_id:145229)）。在此基础上，第二章 **“应用与交叉学科联系”** 将连接理论与实践，展示这些方法如何被应用于解决复杂的现实问题，特别聚焦于[自动化电池设计](@entry_id:1121262)，并探讨其在不同科学学科中的深远影响。最后，为了巩固您的学习成果，第三章 **“动手实践”** 将引导您完成一系列实践练习，将理论知识转化为实用的技能。这次全面的探索将使您掌握必要的工具，不仅能够理解，更能亲自参与到这场正在进行的自动化科学发现的革命中。

## 原理与机制

本章旨在深入探讨从数据中发现控制方程的核心科学原理与关键技术机制。在“引言”章节的基础上，我们将系统性地剖析现有方法的理论基础、内在挑战以及它们在[自动化电池设计](@entry_id:1121262)与仿真等前沿领域的具体应用。我们将从一个根本性问题出发：如何从充满噪声的观测数据中可靠地提取动力学信息，并逐步构建起一套完整的方法论体系，涵盖[稀疏回归](@entry_id:276495)、[物理信息神经网络](@entry_id:145229)、[弱形式](@entry_id:142897)方法等多种范式。

### 核心挑战：通过数据[微分](@entry_id:158422)发现动力学

绝大多数物理系统的演化都可以通过[微分](@entry_id:158422)方程来描述。一个动力学系统的状态向量 $\mathbf{x}(t)$ 的时间演化由一个（通常未知的）向量场 $\mathbf{f}$ 决定，其形式为：
$$
\frac{d\mathbf{x}}{dt} = \dot{\mathbf{x}} = \mathbf{f}(\mathbf{x}, t)
$$
因此，从数据中“发现”控制方程的核心任务，就是辨识出函数 $\mathbf{f}$ 的结构与参数。一个直观的思路是：如果我们能从实验或仿真中获得系统状态 $\mathbf{x}(t)$ 的[时间序列数据](@entry_id:262935)，我们就可以通过数值方法估计其时间导数 $\dot{\mathbf{x}}(t)$，然后将问题转化为一个回归问题，即寻找一个函数 $\mathbf{f}$，使得 $\dot{\mathbf{x}}$ 与 $\mathbf{f}(\mathbf{x})$ 之间的误差最小。

然而，这一看似简单的路径隐藏着一个根本性的挑战：**[数值微分](@entry_id:144452)对噪声的极端敏感性**。在实际应用中，例如通过传感器阵列测量[电池电极](@entry_id:1121399)内的温度分布，我们获得的测量值 $U(x_i, t)$ 总是真实值 $u(x_i, t)$ 与一个随机噪声 $\epsilon_i$ 的叠加，即 $U(x_i) = u(x_i) + \epsilon_i$。当我们尝试使用这些带噪数据来计算导数时，噪声会被急剧放大。

为了理解这一现象，我们可以考察[有限差分法](@entry_id:1124968)。假设我们使用[中心差分格式](@entry_id:1122205)来估计一阶和二阶空间导数 。设各测量点的噪声 $\epsilon_i$ [相互独立](@entry_id:273670)，均值为零，方差为 $\sigma^2$。

[一阶导数](@entry_id:749425)的估计值为：
$$
D^{(1)}U_{i} = \frac{U_{i+1}-U_{i-1}}{2\Delta x} = \frac{u_{i+1}-u_{i-1}}{2\Delta x} + \frac{\epsilon_{i+1}-\epsilon_{i-1}}{2\Delta x}
$$
其噪声部分 $\eta^{(1)}_{i} = (\epsilon_{i+1}-\epsilon_{i-1})/(2\Delta x)$ 的方差为：
$$
\operatorname{Var}(\eta^{(1)}_{i}) = \frac{\operatorname{Var}(\epsilon_{i+1}) + \operatorname{Var}(\epsilon_{i-1})}{(2\Delta x)^2} = \frac{2\sigma^2}{4\Delta x^2} = \frac{\sigma^2}{2\Delta x^2}
$$
二阶导数的估计值为：
$$
D^{(2)}U_{i} = \frac{U_{i+1}-2U_{i}+U_{i-1}}{\Delta x^2} = \frac{u_{i+1}-2u_{i}+u_{i-1}}{\Delta x^2} + \frac{\epsilon_{i+1}-2\epsilon_{i}+\epsilon_{i-1}}{\Delta x^2}
$$
其噪声部分 $\eta^{(2)}_{i} = (\epsilon_{i+1}-2\epsilon_{i}+\epsilon_{i-1})/\Delta x^2$ 的方差为：
$$
\operatorname{Var}(\eta^{(2)}_{i}) = \frac{\operatorname{Var}(\epsilon_{i+1}) + 4\operatorname{Var}(\epsilon_{i}) + \operatorname{Var}(\epsilon_{i-1})}{(\Delta x^2)^2} = \frac{6\sigma^2}{\Delta x^4}
$$
比较两者可以发现，[导数估计](@entry_id:1123569)中噪声的方差与空间步长 $\Delta x$ 的高次幂成反比。当为了提高精度而减小 $\Delta x$ 时，一阶导数估计中的噪声方差以 $\Delta x^{-2}$ 的速率增长，而二阶导数则以 $\Delta x^{-4}$ 的速率急剧增长。这意味着，**阶数越高的导数，其数值估计受[噪声污染](@entry_id:188797)的影响就越严重**。这一根本性困难使得直接基于[数值微分](@entry_id:144452)的回归方法往往难以奏效，并催生了后续将要讨论的更为精巧的发现方法。

### [稀疏回归](@entry_id:276495)框架：[非线性动力学的稀疏辨识](@entry_id:276479)

尽管许多物理系统极其复杂，但其底层的控制方程通常是简洁的，即只由少数几个关键的物理项构成。这一“简约性”或“稀疏性”假设是现代数据驱动发现方法的核心基石。**[非线性动力学的稀疏辨识](@entry_id:276479) (Sparse Identification of Nonlinear Dynamics, [SINDy](@entry_id:266063))** 框架正是利用这一假设的典范。

#### SINDy 算法

[SINDy](@entry_id:266063) 算法将发现控制方程的问题巧妙地转化为一个稀疏线性回归问题，其基本流程如下 ：

1.  **[数据采集](@entry_id:273490)与导数计算**: 首先，从实验或仿真中获得系统状态 $\mathbf{x}(t)$ 在多个时间点上的测量值，构成数据矩阵 $\mathbf{X}$。然后，利用数值方法估计其时间导数，得到导数矩阵 $\dot{\mathbf{X}}$。尽[管存](@entry_id:1127299)在前述的噪声放大问题，[SINDy](@entry_id:266063) 框架通过后续的稀疏化步骤来缓解这一影响。

2.  **构建候选函数库**: 这是 [SINDy](@entry_id:266063) 的核心步骤。我们构建一个大型的候选函数库 $\Theta(\mathbf{X})$，其每一列都代表一个可能的动力学项。例如，对于一个二维系统 $\mathbf{x} = [x_1, x_2]^T$，这个库可以包含常数项、线性项、多项式项、[三角函数](@entry_id:178918)项等，如：
    $$
    \Theta(\mathbf{X}) = \begin{pmatrix} 1 & x_1(t_1) & x_2(t_1) & x_1(t_1)^2 & x_1(t_1)x_2(t_1) & \sin(x_2(t_1)) & \dots \\ 1 & x_1(t_2) & x_2(t_2) & x_1(t_2)^2 & x_1(t_2)x_2(t_2) & \sin(x_2(t_2)) & \dots \\ \vdots & \vdots & \vdots & \vdots & \vdots & \vdots & \ddots \end{pmatrix}
    $$
    这个库代表了我们对系统可能遵循的动力学形式的所有先验猜测。

3.  **求解[稀疏回归](@entry_id:276495)**: 基于[稀疏性](@entry_id:136793)假设，我们认为 $\dot{\mathbf{X}}$ 中的每一列（即每个[状态变量](@entry_id:138790)的导数）都可以由 $\Theta(\mathbf{X})$ 中的少数几列线性组合而成。这可以表示为一个[线性系统](@entry_id:147850)：
    $$
    \dot{\mathbf{X}} = \Theta(\mathbf{X}) \boldsymbol{\Xi}
    $$
    其中，$\boldsymbol{\Xi}$ 是一个待求的[系数矩阵](@entry_id:151473)。由于我们期望 $\boldsymbol{\Xi}$ 是稀疏的（即大部分元素为零），这个问题就转化为一个[稀疏回归](@entry_id:276495)问题。非零的系数项即对应于控制方程中存在的物理项。

#### 强制[稀疏性](@entry_id:136793)：[正则化技术](@entry_id:261393)

为了从上述线性系统中求解出稀疏的系数矩阵 $\boldsymbol{\Xi}$，我们需要在标准的[最小二乘回归](@entry_id:262382)目标中加入一个惩罚项（或正则化项），以鼓励解的稀疏性。考虑对 $\dot{\mathbf{X}}$ 的某一列 $\mathbf{y}$（代表某个状态变量的导数）进行回归，[目标函数](@entry_id:267263)通常写为：
$$
\min_{\boldsymbol{\xi}} \frac{1}{2} \|\mathbf{y} - \mathbf{X}\boldsymbol{\xi}\|_2^2 + \lambda R(\boldsymbol{\xi})
$$
其中 $\boldsymbol{\xi}$ 是 $\boldsymbol{\Xi}$ 的一列，$\lambda > 0$ 是[正则化参数](@entry_id:162917)，用于平衡模型的[拟合优度](@entry_id:176037)与稀疏度。不同的正则化函数 $R(\boldsymbol{\xi})$ 会产生截然不同的效果 。

-   **$\ell_2$ 正则化 ([岭回归](@entry_id:140984))**: 当 $R(\boldsymbol{\xi}) = \|\boldsymbol{\xi}\|_2^2 = \sum_j \xi_j^2$ 时，称为[岭回归](@entry_id:140984)。它通过惩罚系数的平方和来[压缩系数](@entry_id:272630)的大小，能有效处理候选库中存在[多重共线性](@entry_id:141597)（即某些列高度相关）的情况，提高模型的稳定性。然而，$\ell_2$ 正则化只会使系数趋向于零，**但不能将它们精确地设置为零**，因此它本身无法产生[稀疏模型](@entry_id:755136)。

-   **$\ell_1$ 正则化 ([LASSO](@entry_id:751223))**: 当 $R(\boldsymbol{\xi}) = \|\boldsymbol{\xi}\|_1 = \sum_j |\xi_j|$ 时，称为 [LASSO](@entry_id:751223) (Least Absolute Shrinkage and Selection Operator)。由于其菱形的几何约束，$\ell_1$ 范数在优化过程中能够**有效地将许多不重要的系数精确地压缩为零**，从而实现[特征选择](@entry_id:177971)和[稀疏建模](@entry_id:204712)。这正是 SINDy 框架中最常用的方法。其代价是会引入“收缩偏误”（shrinkage bias），即非零系数的估计值也会被向零压缩，可能导致其物理意义（如扩散系数）失真。一种常见的补救措施是，在通过 [LASSO](@entry_id:751223) 确定了非零项（即模型结构）后，再对这些选定的项进行一次无惩罚的[最小二乘回归](@entry_id:262382)，以获得无偏的系数值。

-   **$\ell_0$ 正则化**: $R(\boldsymbol{\xi}) = \|\boldsymbol{\xi}\|_0$ 是指 $\boldsymbol{\xi}$ 中非零元素的个数。这在概念上是“最纯粹”的稀疏性度量。然而，最小化 $\ell_0$ 范数是一个非凸的[组合优化](@entry_id:264983)问题，计算上非常困难（NP-hard）。在实践中，通常采用[贪心算法](@entry_id:260925)或迭代硬阈值（Iterative Hard Thresholding, IHT）等[启发式方法](@entry_id:637904)来近似求解。这些方法在[信噪比](@entry_id:271861)高、候选库相关性低的情况下可能找到正确的模型，但对噪声和[共线性](@entry_id:270224)非常敏感，解的稳定性较差。

#### 融合物理先验：构建更优的候选库

[SINDy](@entry_id:266063) 的威力不仅在于其[稀疏回归](@entry_id:276495)的核心，更在于构建候选库的灵活性。一个纯数学的函数库（如多项式）可能需要非常多的项才能拟合出物理上有意义的结构，效率低下且[可解释性](@entry_id:637759)差。一个更强大的策略是**将已知的物理先验知识直接编码到候选库中** 。

以[锂离子电池](@entry_id:150991)多孔电极中的电化学过程为例，假设我们关心[电解质](@entry_id:261072)浓度 $c_e$ 和电势 $\phi_e$ 的演化。基于基础物理定律，我们可以构建一个高度相关的候选库：

-   **[质量守恒](@entry_id:204015)与[菲克定律](@entry_id:155177)**: [质量守恒定律](@entry_id:147377) $\partial_t c_e + \nabla \cdot \mathbf{N}_e = R_e$ 表明，浓度的变化与物种通量 $\mathbf{N}_e$ 的散度有关。[菲克扩散定律](@entry_id:270426)指出，扩散通量与浓度梯度成正比。因此，包含如 $\nabla c_e$, $\nabla^2 c_e$ 或更复杂的 $\nabla \cdot (D(c_e)\nabla c_e)$ 等项是至关重要的，它们直接对应于[扩散过程](@entry_id:268015)。

-   **[电荷守恒](@entry_id:264158)与欧姆定律**: [电荷守恒](@entry_id:264158)定律 $\nabla \cdot \mathbf{i}_e = a_s F j$ 表明，[电解质](@entry_id:261072)电流密度 $\mathbf{i}_e$ 的散度等于界面反应产生的源/汇项。而[电解质](@entry_id:261072)中的电流可由[欧姆定律](@entry_id:276027)的推广形式描述，$\mathbf{i}_e = -\kappa(c_e) \nabla \phi_e$，其中 $\kappa(c_e)$ 是浓度依赖的电导率。因此，将 $\nabla \cdot (\kappa(c_e)\nabla \phi_e)$ 作为一个完整的算子项加入库中，为发现[电荷守恒](@entry_id:264158)方程提供了强物理先验。

-   **[反应动力学](@entry_id:150220)与 Butler-Volmer 方程**: 界面反应电流密度 $j$ 通常由 Butler-Volmer 方程描述，它与过电势 $\eta$ 呈[非线性](@entry_id:637147)关系。在对称[电荷转移](@entry_id:155270)的假设下，该关系可以简化为[双曲正弦函数](@entry_id:167630)，即 $j \propto \sinh(k\eta)$。因此，在库中加入 $\sinh(\eta)$ 项，能够直接捕捉电化学反应的核心[非线性](@entry_id:637147)特征。

通过这种方式构建的物理信息库，使得 SINDy 算法不再是盲目地从大量函数中进行搜索，而是在一组具有明确物理意义的“积木”中进行选择和组合，极大地提高了发现过程的效率、鲁棒性和最终模型的可解释性。

### [偏微分方程发现](@entry_id:753285)的替代范式

[SINDy](@entry_id:266063) 框架直面了计算带噪数据导数的挑战，并通过[稀疏性](@entry_id:136793)假设来克服它。然而，也存在其他从根本上回避直接计算数据导数的范式，其中最具代表性的是物理信息神经网络和弱形式方法。

#### [物理信息神经网络](@entry_id:145229) (Physics-Informed Neural Networks - PINNs)

[PINNs](@entry_id:145229) 采用了一种与 SINDy 截然不同的哲学。它不试图直接拟合导数，而是**将[微分](@entry_id:158422)方程本身作为神经网络训练过程中的一种正则化约束** 。

其核心思想是：用一个[深度神经网络](@entry_id:636170) $u_\theta(\mathbf{x}, t)$ 来逼近待求的物理场（如电池中的[电解质](@entry_id:261072)浓度 $c_e(\mathbf{x}, t)$），其中 $\theta$ 是网络的权重和偏置。这个网络以时空坐标 $(\mathbf{x}, t)$ 为输入，输出对应的物理量值。训练网络的目标是最小化一个复合损失函数 $\mathcal{L}$，该函数通常由以下几部分构成：

1.  **数据损失 ($\mathcal{L}_{\mathrm{data}}$)**: 如果我们拥有一些在特定时空点上的测量数据 $\{(\mathbf{x}_i, t_i, c_i)\}_{i=1}^N$，这部分损失就是网络预测值与真实测量值之间的差异，例如均方误差：
    $$
    \mathcal{L}_{\mathrm{data}} = \frac{1}{N} \sum_{i=1}^{N} (c_\theta(\mathbf{x}_i, t_i) - c_i)^2
    $$

2.  **物理损失 ($\mathcal{L}_{\mathrm{phys}}$)**: 这是 PINNs 的精髓。我们定义一个物理残差 $r_{\mathrm{PDE}}(\mathbf{x}, t)$，它代表了将网络解 $c_\theta$ 代入到待求的 PDE 中所产生的误差。例如，对于反应扩散方程 $\partial_t c_e - \nabla \cdot (D_e \nabla c_e) = S$，残差为：
    $$
    r_{\mathrm{PDE}}(\mathbf{x}, t) = \frac{\partial c_\theta}{\partial t} - \nabla \cdot (D_e \nabla c_\theta) - S
    $$
    关键在于，所有对网络输出 $c_\theta$ 的导数（如 $\partial c_\theta/\partial t$, $\nabla c_\theta$）都是通过**[自动微分](@entry_id:144512) (Automatic Differentiation, AD)** 计算的。AD 是一种精确计算函数导数的技术，它作用于光滑的神经网络函数，而非带噪的离散数据。因此，AD 计算出的导数是“无噪声”的。物理损失就是这个残差在大量[随机采样](@entry_id:175193)的“[配置点](@entry_id:169000)”上的[均方误差](@entry_id:175403)：
    $$
    \mathcal{L}_{\mathrm{phys}} = \frac{1}{M} \sum_{j=1}^{M} r_{\mathrm{PDE}}(\mathbf{x}_j, t_j)^2
    $$

3.  **边界与初始条件损失 ($\mathcal{L}_{\mathrm{bc}}, \mathcal{L}_{\mathrm{ic}}$)**: 同样地，我们可以定义残差来惩罚网络解在边界和初始时刻对给定条件的偏离。

总[损失函数](@entry_id:634569)是这些分量的加权和：$\mathcal{L} = \lambda_d \mathcal{L}_{\mathrm{data}} + \lambda_p \mathcal{L}_{\mathrm{phys}} + \dots$。通过[梯度下降法](@entry_id:637322)优化 $\theta$ 来最小化 $\mathcal{L}$，我们最终得到的神经网络 $c_\theta$ 不仅拟合了观测数据，还在整个时空域上近似满足了物理定律。

更进一步，[PINNs](@entry_id:145229) 框架非常适合求解“[逆问题](@entry_id:143129)”。如果 PDE 中的某些参数（如扩散系数 $D_e$）或某个函数（如源项 $S(\mathbf{x}, t)$）未知，我们可以将它们也作为可学习的参数或另一个神经网络，与主网络 $c_\theta$ 一同进行优化，从而从数据中发现它们。

与 [SINDy](@entry_id:266063) 相比，[PINNs](@entry_id:145229) 学习的是一个用于表示*解*的[黑箱函数](@entry_id:163083)逼近器（神经网络），并将 PDE 作为软约束；而 [SINDy](@entry_id:266063) 学习的是*动力学向量场*本身的稀疏、符号化表达式 。SINDy 的结果通常更具[可解释性](@entry_id:637759)，而 [PINNs](@entry_id:145229) 在处理复杂的几何形状和边界条件时则更为灵活。

#### [弱形式](@entry_id:142897)方法：基于积分的发现

弱形式（或变分形式）方法提供了另一种从根本上规避对噪声数据进行高阶[微分](@entry_id:158422)的途径 。其核心思想在于，将[微分](@entry_id:158422)方程转化为等价的积分方程，从而降低对解的[光滑性](@entry_id:634843)要求并平滑噪声。

考虑一个一般的 PDE 残差形式 $R(u) = \partial_t u + \mathcal{N}(u) = 0$，其中 $\mathcal{N}$ 是一个空间[微分算子](@entry_id:140145)。[弱形式](@entry_id:142897)的推导过程如下：

1.  将 PDE 残差与一个任意的光滑“[测试函数](@entry_id:166589)” $w(x,t)$ 相乘。如果 PDE 在整个域上成立，那么这个乘积在整个时空域 $Q$ 上的积分也必须为零：
    $$
    \int_Q w \cdot R(u) \,dx\,dt = \int_Q w \cdot (\partial_t u + \mathcal{N}(u)) \,dx\,dt = 0
    $$

2.  利用**分部积分 (Integration by Parts)**，将作用在可能带噪的解 $u$ 上的导数“转移”到光滑、已知的测试函数 $w$ 上。例如，对于时间导数项：
    $$
    \int_Q w (\partial_t u) \,dx\,dt = [ \int w u \,dx ]_{t=0}^{T} - \int_Q (\partial_t w) u \,dx\,dt
    $$
    如果我们选择[测试函数](@entry_id:166589) $w$ 在时间边界 $t=0, T$ 上为零，那么边界项就消失了，原积分就转化为了 $-\int_Q (\partial_t w) u \,dx\,dt$。这样，我们就不再需要计算 $\partial_t u$，而是计算我们自己选择的[光滑函数](@entry_id:267124) $w$ 的导数。

3.  同样的技术可以应用于空间导数项。例如，对于二阶扩散项 $-\partial_x(D\partial_x u)$，一次分部积分可以将其转化为：
    $$
    -\int_Q w \partial_x(D\partial_x u) \,dx\,dt = \int_Q (\partial_x w)(D\partial_x u) \,dx\,dt - [w D \partial_x u]_{\text{boundary}}
    $$
    这不仅将 $u$ 上的导数从二阶降为一阶，还自然地引出了边界通量项，使得我们可以将已知的边界条件直接代入[积分方程](@entry_id:138643)中。

最终，原始的[微分](@entry_id:158422)方程被转化成了一个不再包含对 $u$ 的[高阶导数](@entry_id:140882)的积分恒等式。这个恒等式对噪声的鲁棒性远强于原始的 PDE。然后，可以将这个弱形式的方程作为基础，应用[稀疏回归](@entry_id:276495)技术（这种方法常被称为 **Weak SINDy**）来辨识未知的函数或参数。

### 高级主题与实践考量

在掌握了核心方法之后，我们还需要关注一些更高级但至关重要的概念，它们决定了数据驱动发现的深度和成败。

#### 守恒定律：局部与全局形式

[物理学中的守恒定律](@entry_id:266475)可以有两种等价的数学表述：局部形式和全局形式 。

-   **局部形式**即我们通常所见的微分形式，如[质量守恒](@entry_id:204015) $\partial_t u + \nabla \cdot \mathbf{f} = s$，其中 $u$ 是密度，$\mathbf{f}$ 是通量， $s$ 是源项。它描述了空间中每一点的物理关系。[SINDy](@entry_id:266063) 和标准 PINNs 的物理残差都是基于这种局部形式。

-   **全局形式**是积分形式，通过对局部形式在任意一个固定的控制体积 $\Omega$ 上进行积分，并应用[散度定理](@entry_id:143110)得到：
    $$
    \frac{d}{dt}\int_{\Omega} u \, dV + \int_{\partial \Omega} \mathbf{f} \cdot \mathbf{n} \, dS = \int_{\Omega} s \, dV
    $$
    这个表达式的物理意义非常直观：控制体积内总量的变化率 = 穿过边界的净通量 + 体积内的总源项。

在数据驱动发现中，这两种形式各有其用。局部形式提供了最精细的约束，但如前所述，它对噪声敏感。全局形式则提供了一种在空间上平均的约束。例如，在 [PINNs](@entry_id:145229) 中加入对全局守恒定律的惩罚（有时被称为 Conservative PINNs 或 c[PINNs](@entry_id:145229)），可以作为一种强大的正则化手段，确保学习到的解在宏观上遵守物理守恒，即使在数据稀疏或噪声较大的情况下也能提高模型的稳定性和泛化能力。同样，[弱形式](@entry_id:142897)方法本质上也是利用了积分形式的思想，通过在整个域上（或[子域](@entry_id:155812)上）强制积分平衡来实现对噪声的鲁棒性。

#### [稀疏性](@entry_id:136793)的贝叶斯视角

LASSO 等经典[稀疏回归](@entry_id:276495)方法提供了一个系数的[点估计](@entry_id:174544)，但没有系统地量化模型结构本身的不确定性。贝叶斯框架为此提供了一个更完整的视角 。

在贝叶斯[稀疏回归](@entry_id:276495)中，我们为每个候选系数 $\beta_j$ 引入一个二元[指示变量](@entry_id:266428) $\gamma_j \in \{0, 1\}$，其中 $\gamma_j=1$ 表示第 $j$ 个项被包含在模型中，$\gamma_j=0$ 则表示不被包含。然后，我们为系数设置一个**“尖峰与厚板” (spike-and-slab) 先验**：
$$
\beta_j \mid \gamma_j \sim (1-\gamma_j)\delta_0 + \gamma_j \mathcal{N}(0, \tau_j^2)
$$
这里，$\delta_0$ 是在零点的一个狄拉克函数（尖峰），代表系数恰好为零的情况；$\mathcal{N}(0, \tau_j^2)$ 是一个零均值、较大方差的正态分布（厚板），代表系数不为零的情况。

在给定数据 $y$ 后，通过贝叶斯定理，我们可以计算每个[指示变量](@entry_id:266428)的[后验概率](@entry_id:153467) $\Pr(\gamma_j=1 \mid y)$，这被称为**[后验包含概率](@entry_id:914744) (Posterior Inclusion Probability, PIP)**。PIP 的值在 $[0, 1]$ 之间，直接度量了数据支持第 $j$ 个候选项成为真实模型一部分的可信度。

PIP 与系数的[点估计](@entry_id:174544)（如后验均值 $\mathbb{E}[\beta_j \mid y]$）是两个不同的概念。后验均值同时受到了结构不确定性（PIP的大小）和幅度不确定性（在包含该项的条件下，系数的可能取值）的影响。一个接近于零的[后验均值](@entry_id:173826)，可能是因为该项根本不重要（PIP很低），也可能是因为该项确实存在但其效应很小（PIP很高，但系数本身接近于零）。PIP 将模型*结构*的不确定性从参数*幅度*的不确定性中分离出来，为评估每个物理项的重要性提供了更深刻、更稳健的度量。

#### 复杂[动力学建模](@entry_id:204326)：[混合系统](@entry_id:271183)

许多真实系统，如电池，在不同工况下会表现出截然不同的行为。例如，在低温或大电流充电时，锂离子除了嵌入电极材料外，还可能在电极表面沉积形成金属锂，即“[析锂](@entry_id:1127358)”。这是一种状态的质变，单一的[动力学方程](@entry_id:751029)难以描述。

这类系统被称为**[混合系统](@entry_id:271183) (Hybrid Systems)** ，其特点是包含：
-   在离散的“模式”（如“嵌入模式”、“[析锂](@entry_id:1127358)模式”）内部的[连续动力学](@entry_id:268176)。
-   由状态变量跨越特定阈值（称为“守卫条件”）触发的模式之间的瞬时切换。

例如，析锂可能仅在过电势 $\eta$ 低于某个临界值 $\eta_c$ 时发生。这种行为可以严谨地用[分段函数](@entry_id:160275)或亥维赛德[阶跃函数](@entry_id:159192) $H(z)$ 来数学建模：
$$
\dot{x} = f_{\text{嵌入}}(x) H(\eta(x) - \eta_c) + f_{\text{析锂}}(x) H(\eta_c - \eta(x))
$$
这种非光滑、分段定义的模型在结构上与[光滑模](@entry_id:752104)型有本质区别。在实践中，为了便于使用[基于梯度的优化](@entry_id:169228)算法进行辨识，研究者有时会用一个光滑的[S型函数](@entry_id:137244)（如 logistic 函数）来近似亥维赛德函数，实现“软切换”。但这是一种为了计算便利而做的近似，我们必须清楚它与原始[混合系统](@entry_id:271183)模型在形式上的区别。

#### 发现的极限：可辨识性

最后，一个至关重要的问题是：我们所寻求的参数或模型结构，是否能够从数据中被唯一地确定出来？这就是**可辨识性 (Identifiability)** 问题 。

可辨识性分为两种：

-   **结构[可辨识性](@entry_id:194150) (Structural Identifiability)**: 这是一个理论性质，与[数据质量](@entry_id:185007)无关。它问的是：在拥有理想数据（无限量、无噪声、连续测量）和足够丰富的输入激励下，模型中的未知参数是否能被唯一确定？如果存在两组或多组不同的参数值，能够产生完全相同的系统输出，那么这些参数就是结构不可辨识的。这种情况常常出现在参数以特定组合形式影响系统行为时。例如，在扩散问题中，扩散系数 $D_s$ 和特征长度 $R$ 往往以 $D_s/R^2$ 的组合形式出现。通过[量纲分析](@entry_id:140259)可以有效地揭示这类参数组合，从而判断单个参数是否可辨识。

-   **实践可辨识性 (Practical Identifiability)**: 这是一个与具体实验相关的性质。它问的是：对于一个给定的、有限且带噪声的数据集，我们能否以足够高的精度估计出参数？一个参数即使是结构可辨识的，也可能在实践中不可辨识。这可能是因为实验的输入信号没有充分“激励”起与该参数相关的动态，或者[信噪比](@entry_id:271861)太低，导致参数的微小变化被淹没在噪声中。实践可辨识性通常通过Fisher信息矩阵的性质或[参数估计](@entry_id:139349)的[置信区间](@entry_id:142297)大小来量化。

理解这两种[可辨识性](@entry_id:194150)的区别至关重要。结构可辨识性是实践[可辨识性](@entry_id:194150)的必要非充分条件。在进行任何[数据驱动的发现](@entry_id:274863)任务之前，对模型进行结构[可辨识性分析](@entry_id:182774)，可以帮助我们明确哪些参数组合是可能被发现的，从而避免徒劳的尝试，[并指](@entry_id:276731)导我们设计出信息更丰富的实验来改善实践[可辨识性](@entry_id:194150)。