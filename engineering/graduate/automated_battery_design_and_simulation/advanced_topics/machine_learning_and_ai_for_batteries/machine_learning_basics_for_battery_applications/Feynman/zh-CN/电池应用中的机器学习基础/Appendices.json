{
    "hands_on_practices": [
        {
            "introduction": "可靠的机器学习模型始于严谨的数据划分和评估策略。在电池失效预测等应用中，我们常面临两类挑战：一是数据不平衡，即某些失效模式（如内部短路）的样本远少于正常样本；二是批次效应，即不同生产批次的电芯存在性能差异。本练习将引导你思考如何通过分层采样，并结合对批次多样性的要求，来构建具有代表性的交叉验证数据集，从而确保模型评估的公正性与可靠性。",
            "id": "3926147",
            "problem": "一个用于自动化电池设计与仿真的电池故障预测数据集，包含了按生产批次分组的电芯级测量数据。每个电芯被标记为三个类别之一：类别 $0$（健康）、类别 $1$（早期容量衰减）和类别 $2$（内部短路）。该数据集共有 $B=10$ 个批次，总计 $N=500$ 个电芯。各批次的计数如下：\n- 批次 $1$：类别 $0$：$50$，类别 $1$：$5$，类别 $2$：$2$。\n- 批次 $2$：类别 $0$：$40$，类别 $1$：$8$，类别 $2$：$0$。\n- 批次 $3$：类别 $0$：$45$，类别 $1$：$9$，类别 $2$：$1$。\n- 批次 $4$：类别 $0$：$48$，类别 $1$：$8$，类别 $2$：$3$。\n- 批次 $5$：类别 $0$：$42$，类别 $1$：$12$，类别 $2$：$2$。\n- 批次 $6$：类别 $0$：$39$，类别 $1$：$10$，类别 $2$：$1$。\n- 批次 $7$：类别 $0$：$45$，类别 $1$：$12$，类别 $2$：$0$。\n- 批次 $8$：类别 $0$：$41$，类别 $1$：$8$，类别 $2$：$5$。\n- 批次 $9$：类别 $0$：$25$，类别 $1$：$5$，类别 $2$：$3$。\n- 批次 $10$：类别 $0$：$25$，类别 $1$：$3$，类别 $2$：$3$。\n\n总计为类别 $0$：$400$，类别 $1$：$80$，类别 $2$：$20$，因此全局类别比例为 $p_0=400/500=0.8$，$p_1=80/500=0.16$ 和 $p_2=20/500=0.04$。\n\n要求您在以下约束条件下为交叉验证（CV）构建 $K=5$ 个分层折，这些约束旨在确保少数故障类别的最小批次代表性：\n- 每个折必须包含来自至少 $m_1=3$ 个包含类别 $1$ 的不同批次的样本，以及来自至少 $m_2=2$ 个包含类别 $2$ 的不同批次的样本。\n- 如果一个批次为某个折提供了类别 $1$ 的样本，则从该批次中分配至少 $s_{\\min,1}=2$ 个类别 $1$ 的样本到该折。如果一个批次为某个折提供了类别 $2$ 的样本，则从该批次中分配至少 $s_{\\min,2}=1$ 个类别 $2$ 的样本到该折。\n- 在一个折中满足这些最小批次代表性约束后，通过对其余样本池进行分层抽样来填充该折中的剩余位置，并尽可能保持剩余样本的全局类别比例。\n- 每个折的大小为 $N/K=100$。\n\n从分层抽样的定义和全期望定律出发，解释在具有批次效应的电池数据集中，分层划分如何处理不平衡的故障类别，并计算在上述约束条件下每个折中的期望类别比例。为每个折的期望类别比例选择正确的选项。\n\nA. 类别 $0$：$0.80$，类别 $1$：$0.16$，类别 $2$：$0.04$。\n\nB. 类别 $0$：$0.78$，类别 $1$：$0.18$，类别 $2$：$0.04$。\n\nC. 类别 $0$：$0.80$，类别 $1$：$0.12$，类别 $2$：$0.08$。\n\nD. 类别 $0$：$0.79$，类别 $1$：$0.15$，类别 $2$：$0.06$。",
            "solution": "问题陈述已经过验证，在其约束的標準解釋下被认为是具有科学依据、一致且定义明确的。所有给定数据，包括类别计数（$N_0=400$，$N_1=80$，$N_2=20$）和总样本量（$N=500$），都是内部一致的。任务是双重的：首先，解释分层划分对于具有批次效应的不平衡数据集的作用；其次，计算 $K=5$ 个交叉验证折中每个折的期望类别比例。\n\n**分层划分的概念性解释**\n\n在机器学习中，尤其是在处理像电池故障预测这样的不平衡数据集时，用于交叉验证的标准随机抽样可能会产生问题。像“内部短路”（类别 $2$）这样的少数类别，可能会偶然地完全不出现在某个测试折中。这将导致在该次交叉验证迭代中无法对该类别进行性能评估，从而得出一个不可靠且有偏差的整体性能估计。\n\n分层抽样直接解决了这个问题。根据定义，分层是在抽样前将总体划分为同质子组（层）的过程。在交叉验证的背景下，这些层就是类别。分层划分确保每个折都是整个数据集的一个缩影，尽可能地保持全局类别比例。例如，如果类别 $2$ 占总数据的 $4\\%$，那么每个折也将包含大约 $4\\%$ 的类别 $2$ 样本。这保证了模型在每个折中都能在所有类别上进行训练和评估，从而对其泛化性能产生更稳定和准确的评估。\n\n问题引入了一个额外的复杂性层面：批次效应。来自不同生产批次的电池电芯可能存在影响其性能和故障模式的微妙差异。一个模型可能在处理来自一个批次的故障时表现良好，但在处理另一个批次时表现不佳。为故障类别（类别 $1$ 为 $m_1=3$，类别 $2$ 为 $m_2=2$）包含来自最少数量不同批次的样本的约束，正是为了应对这个问题。这迫使每个测试折都包含来自不同批次的多种故障“特征”，从而为模型不仅跨样本泛化，而且跨生产批次泛化的能力提供了更严格的测试。\n\n**期望类别比例的推导**\n\n问题要求计算每个折中的期望类别比例。这可以根据概率和对称性的第一性原理来确定，这个结论可以通过逐步执行所描述的复杂抽样过程来验证。\n\n**方法1：基于对称性和期望的论证**\n\n设 $N_c$ 为数据集中类别 $c$ 的总样本数，其中 $c \\in \\{0, 1, 2\\}$。我们有 $N_0 = 400$，$N_1 = 80$ 和 $N_2 = 20$。总样本数为 $N = \\sum_c N_c = 500$。任务是将这 $N$ 个样本划分到 $K=5$ 个折中。\n\n设 $N_{k,c}$ 是表示特定折 $k$ 中类别 $c$ 样本数的随机变量。划分规则意味着每个样本必须恰好属于一个折，因此对所有折求和必须得到该类别的总样本数：\n$$ \\sum_{k=1}^{K} N_{k,c} = N_c $$\n根据期望的线性性质，期望值的总和等于总和的期望：\n$$ \\sum_{k=1}^{K} E[N_{k,c}] = E\\left[\\sum_{k=1}^{K} N_{k,c}\\right] = E[N_c] = N_c $$\n最后的等式成立，因为 $N_c$ 是一个给定的固定量。\n\n问题描述了一套构建折的规则。关键的是，这些规则对每个折都是相同的；该过程不区分折 $1$、折 $2$ 等。因此，根据对称性，每个折的期望构成必须相同。这意味着类别 $c$ 的期望样本数对所有折都是相同的：\n$$ E[N_{1,c}] = E[N_{2,c}] = \\dots = E[N_{K,c}] $$\n让我们将这个共同的期望值表示为 $E_c$。将其代入总和中：\n$$ \\sum_{k=1}^{K} E_c = K \\cdot E_c = N_c $$\n这给了我们一个关于任何给定折 $k$ 中任何类别 $c$ 的期望样本数的基本结果：\n$$ E[N_{k,c}] = \\frac{N_c}{K} $$\n只要问题中指定的约束条件允许有效的划分，这个结果就成立，而它们确实允许。\n\n使用给定的值：\n- 类别 $0$ 的期望计数：$E[N_{k,0}] = \\frac{400}{5} = 80$。\n- 类别 $1$ 的期望计数：$E[N_{k,1}] = \\frac{80}{5} = 16$。\n- 类别 $2$ 的期望计数：$E[N_{k,2}] = \\frac{20}{5} = 4$。\n\n每个折的大小为 $N/K = 500/5 = 100$。期望比例为：\n- 类别 $0$ 的比例：$\\frac{80}{100} = 0.80$。\n- 类别 $1$ 的比例：$\\frac{16}{100} = 0.16$。\n- 类别 $2$ 的比例：$\\frac{4}{100} = 0.04$。\n\n这些期望比例与全局类别比例相同。\n\n**方法2：通过指定的抽样过程进行验证**\n\n我们可以通过仔细遵循所描述的两阶段过程来验证这一结果。这表明复杂的程序与对称性论证是一致的。该过程包括一个“约束分配”阶段，然后是一个“分层填充”阶段。我们假设模糊的短语“分配至少 $s_{\\min}$”意味着为约束部分精确分配所需的最小样本数，这是一个标准的解释。\n\n**阶段1：约束分配**\n对于 $K=5$ 个折中的每一个，我们必须分配样本以满足最小批次代表性约束。\n- 对于类别 $1$：每个折需要来自 $m_1=3$ 个批次的样本，每个批次至少 $s_{\\min,1}=2$ 个样本。预分配给每个折的类别 $1$ 样本数为 $3 \\times 2 = 6$。\n- 对于类别 $2$：每个折需要来自 $m_2=2$ 个批次的样本，每个批次至少 $s_{\\min,2}=1$ 个样本。预分配给每个折的类别 $2$ 样本数为 $2 \\times 1 = 2$。\n- 对于类别 $0$：没有此类约束，因此预分配 $0$ 个样本。\n\n在此阶段，分配到所有 $5$ 个折中的总样本数为：\n- 类别 $1$：$5 \\text{ 折} \\times 6 \\text{ 样本/折} = 30$ 个样本。\n- 类别 $2$：$5 \\text{ 折} \\times 2 \\text{ 样本/折} = 10$ 个样本。\n- 类别 $0$：$5 \\text{ 折} \\times 0 \\text{ 样本/折} = 0$ 个样本。\n\n**阶段2：分层填充**\n现在，我们计算待分配的剩余样本池。\n- 剩余类别 $0$ 样本：$400 - 0 = 400$。\n- 剩余类别 $1$ 样本：$80 - 30 = 50$。\n- 剩余类别 $2$ 样本：$20 - 10 = 10$。\n- 剩余总样本数：$400 + 50 + 10 = 460$。\n\n接下来，我们计算每个折中剩余的空位数。\n- 每个折的总大小为 $100$。\n- 在阶段1中，每个折被分配了 $6$（类别 $1$）$+ 2$（类别 $2$）$= 8$ 个样本。\n- 每个折的剩余空位数：$100 - 8 = 92$。\n- 所有折的总剩余空位数：$5 \\times 92 = 460$，这与剩余总样本数相匹配，证实了一致性。\n\n每个折的这 $92$ 个空位通过对剩余的 $460$ 个样本池进行分层抽样来填充。添加到每个折的各类别的期望样本数为：\n- 新增类别 $0$ 样本：$92 \\times \\frac{400}{460} = 92 \\times \\frac{40}{46} = 2 \\times 40 = 80$。\n- 新增类别 $1$ 样本：$92 \\times \\frac{50}{460} = 92 \\times \\frac{5}{46} = 2 \\times 5 = 10$。\n- 新增类别 $2$ 样本：$92 \\times \\frac{10}{460} = 92 \\times \\frac{1}{46} = 2 \\times 1 = 2$。\n\n**最终构成**\n每个折中各类别的总期望计数是阶段1和阶段2的总和。\n- 期望类别 $0$ 计数：$0 (\\text{阶段 } 1) + 80 (\\text{阶段 } 2) = 80$。\n- 期望类别 $1$ 计数：$6 (\\text{阶段 } 1) + 10 (\\text{阶段 } 2) = 16$。\n- 期望类别 $2$ 计数：$2 (\\text{阶段 } 1) + 2 (\\text{阶段 } 2) = 4$。\n\n每个折的总计数为 $80 + 16 + 4 = 100$。期望比例为：\n- 类别 $0$ 比例：$80/100 = 0.80$。\n- 类别 $1$ 比例：$16/100 = 0.16$。\n- 类别 $2$ 比例：$4/100 = 0.04$。\n\n两种方法得出了相同的结果。这些复杂的约束在确保批次多样性的同时，其构建方式在期望上完美地保留了分层原则。\n\n**逐项分析**\n\nA. 类别 $0$：$0.80$，类别 $1$：$0.16$，类别 $2$：$0.04$。\n此选项与我们推导出的期望比例 $\\{0.80, 0.16, 0.04\\}$ 相匹配。\n**结论：正确。**\n\nB. 类别 $0$：$0.78$，类别 $1$：$0.18$，类别 $2$：$0.04$。\n此选项表明有 $78$ 个类别 $0$ 样本，$18$ 个类别 $1$ 样本，和 $4$ 个类别 $2$ 样本。这与我们的推导不一致。\n**结论：不正确。**\n\nC. 类别 $0$：$0.80$，类别 $1$：$0.12$，类别 $2$：$0.08$。\n此选项表明有 $80$ 个类别 $0$ 样本，$12$ 个类别 $1$ 样本，和 $8$ 个类别 $2$ 样本。这与我们的推导不一致。\n**结论：不正确。**\n\nD. 类别 $0$：$0.79$，类别 $1$：$0.15$，类别 $2$：$0.06$。\n此选项表明有 $79$ 个类别 $0$ 样本，$15$ 个类别 $1$ 样本，和 $6$ 个类别 $2$ 样本。这与我们的推导不一致。\n**结论：不正确。**",
            "answer": "$$\\boxed{A}$$"
        },
        {
            "introduction": "在建立稳健的评估框架后，下一步是处理和理解输入特征。电池测试数据，如电压曲线或阻抗谱，往往可以提取出大量特征，形成高维特征空间。本练习将通过主成分分析（PCA）这一核心降维技术，向你展示如何从复杂数据中识别并提取最重要的信息。通过从第一性原理推导其对方差的解释能力，你将深刻理解PCA的工作机制及其在电池数据分析中的价值。",
            "id": "3926067",
            "problem": "一个包含 $n$ 个锂离子电池循环的数据集由每个循环提取的 $p$ 个标量特征描述：充电过程中的电压平台持续时间、$\\mathrm{LiC}_6/\\mathrm{LiC}_{12}$ 相变附近的微分容量峰值大小、中频下的阻抗幅值、达到预设截止条件的充电时间以及往返能量效率。数据集中的每个特征都被标准化为零均值和单位方差。设均值中心化和标准化后的数据矩阵为 $X \\in \\mathbb{R}^{n \\times p}$，无偏样本协方差矩阵为 $\\Sigma \\in \\mathbb{R}^{p \\times p}$。\n\n请定义主成分分析 (PCA)，并从协方差和标准正交特征分解的定义出发，根据第一性原理推导由前 $k$ 个主成分解释的总方差分数与 $\\Sigma$ 的特征值之间的关系表达式。\n\n然后，在 $p = 5$ 的特定情况下，当 $\\Sigma$ 的特征值为 $\\lambda_{1} = 2.1$, $\\lambda_{2} = 1.3$, $\\lambda_{3} = 0.9$, $\\lambda_{4} = 0.5$ 和 $\\lambda_{5} = 0.2$ 时，计算前 $k = 2$ 个主成分所解释的方差分数。请将最终结果表示为小数，并四舍五入至四位有效数字。不要使用百分号。",
            "solution": "首先对问题进行验证，以确保其科学性、适定性和客观性。\n\n**步骤1：提取已知条件**\n- 一个包含 $n$ 个锂离子电池循环的数据集。\n- 每个循环提取 $p$ 个标量特征。\n- 特征被标准化为零均值和单位方差。\n- 均值中心化和标准化的数据矩阵为 $X \\in \\mathbb{R}^{n \\times p}$。\n- 无偏样本协方差矩阵为 $\\Sigma \\in \\mathbb{R}^{p \\times p}$。\n- 任务1：定义主成分分析 (PCA)，并从协方差和标准正交特征分解的定义出发，推导由前 $k$ 个主成分解释的总方差分数与 $\\Sigma$ 的特征值之间的关系表达式。推导必须从协方差和标准正交特征分解的定义开始。\n- 任务2：在 $p=5$ 且 $\\Sigma$ 的特征值为 $\\lambda_{1} = 2.1$, $\\lambda_{2} = 1.3$, $\\lambda_{3} = 0.9$, $\\lambda_{4} = 0.5$ 和 $\\lambda_{5} = 0.2$ 的特定情况下，计算前 $k=2$ 个主成分解释的方差分数。\n- 最终数值结果必须表示为小数，并四舍五入至四位有效数字。\n\n**步骤2：使用提取的已知条件进行验证**\n- **科学性：** 该问题在现实应用（电池数据分析）的背景下，使用了线性代数和统计学中标准且成熟的原理（PCA、协方差、特征值）。其前提是合理的。一个关键的一致性检查是：对于标准化数据（其中每个特征的方差为1），总方差等于特征数量 $p$。总方差也等于协方差矩阵的迹，即其特征值之和。此处，$p=5$，给定特征值之和为 $\\lambda_1 + \\lambda_2 + \\lambda_3 + \\lambda_4 + \\lambda_5 = 2.1 + 1.3 + 0.9 + 0.5 + 0.2 = 5.0$。这与 $p=5$ 相符，证实了问题陈述的内部一致性和科学有效性。\n- **适定性：** 该问题要求进行标准的理论推导和具体的计算，并为获得唯一解提供了所有必要信息。\n- **客观性：** 语言清晰、精确，没有主观论断。\n\n**步骤3：结论与行动**\n问题有效。将提供解答，首先进行推导，然后进行具体计算。\n\n### 第1部分：推导\n\n主成分分析 (PCA) 是一种用于降维的线性变换技术。它将一组可能相关的变量的观测值转换为一组称为主成分的线性不相关变量的值。该变换的定义方式使得第一个主成分具有尽可能大的方差（即，它解释了数据中尽可能多的变异性），而后续的每个成分则在与前面所有成分正交的约束下，具有尽可能大的方差。\n\n设均值中心化后的数据矩阵为 $X \\in \\mathbb{R}^{n \\times p}$。无偏样本协方差矩阵 $\\Sigma$ 由下式给出：\n$$\n\\Sigma = \\frac{1}{n-1} X^T X\n$$\n一个主成分是原始特征的线性组合。这个线性组合的方向可以由一个单位向量 $w \\in \\mathbb{R}^p$ (其中 $w^T w = 1$) 表示。$n$ 个数据点投影到这个方向上的得分为向量 $z = Xw$。\n\n这些投影得分的方差为：\n$$\n\\text{Var}(z) = \\frac{1}{n-1} z^T z = \\frac{1}{n-1} (Xw)^T (Xw) = \\frac{1}{n-1} w^T X^T X w\n$$\n代入 $\\Sigma$ 的表达式，我们得到：\n$$\n\\text{Var}(z) = w^T \\left( \\frac{1}{n-1} X^T X \\right) w = w^T \\Sigma w\n$$\n第一个主成分是通过选择使该方差最大化的方向 $w_1$ 来找到的，约束条件是 $w_1$ 为单位向量。这是一个约束优化问题：\n$$\n\\max_{w_1} w_1^T \\Sigma w_1 \\quad \\text{subject to} \\quad w_1^T w_1 = 1\n$$\n我们使用拉格朗日乘数法。拉格朗日函数为：\n$$\nL(w_1, \\lambda) = w_1^T \\Sigma w_1 - \\lambda(w_1^T w_1 - 1)\n$$\n为求最大值，我们计算关于 $w_1$ 的梯度并将其设为零。由于 $\\Sigma$ 是对称的，$w_1^T \\Sigma w_1$ 对 $w_1$ 的导数是 $2\\Sigma w_1$。$w_1^T w_1$ 的导数是 $2w_1$。\n$$\n\\frac{\\partial L}{\\partial w_1} = 2\\Sigma w_1 - 2\\lambda w_1 = 0\n$$\n这简化为特征值方程：\n$$\n\\Sigma w_1 = \\lambda w_1\n$$\n这表明最优方向 $w_1$ 必须是协方差矩阵 $\\Sigma$ 的一个特征向量，而 $\\lambda$ 是其对应的特征值。为了确定哪个特征向量能使方差最大化，我们将 $\\Sigma w_1 = \\lambda w_1$ 代回方差表达式：\n$$\n\\text{Var}(z) = w_1^T \\Sigma w_1 = w_1^T (\\lambda w_1) = \\lambda (w_1^T w_1)\n$$\n由于 $w_1^T w_1 = 1$，我们有：\n$$\n\\text{Var}(z) = \\lambda\n$$\n数据投影到某个特征向量上的方差等于对应的特征值。为了最大化方差，我们必须选择与最大特征值 $\\lambda_1$ 对应的特征向量 $w_1$。因此，第一个主成分是最大特征值对应特征向量的方向，其解释的方差为 $\\lambda_1$。\n\n后续的主成分通过在与所有先前成分正交的方向上最大化方差来找到。这个过程系统地按照对应特征值降序选择 $\\Sigma$ 的特征向量。第 $j$ 个主成分对应于第 $j$ 大特征值 $\\lambda_j$ 的特征向量 $w_j$，它解释的方差为 $\\lambda_j$。\n\n原始数据集的总方差是各个特征方差的总和，也就是协方差矩阵对角线元素之和，即其迹：\n$$\n\\text{Total Variance} = \\text{tr}(\\Sigma) = \\sum_{i=1}^{p} \\Sigma_{ii}\n$$\n协方差矩阵 $\\Sigma$ 是一个实对称矩阵，因此它可以进行标准正交特征分解 $\\Sigma = W \\Lambda W^T$，其中 $W$ 是一个正交矩阵 ($W^T W = I$)，其列是特征向量 $w_j$，$\\Lambda$ 是由特征值 $\\lambda_j$ 构成的对角矩阵。利用迹的循环性质 ($\\text{tr}(ABC) = \\text{tr}(BCA)$)：\n$$\n\\text{tr}(\\Sigma) = \\text{tr}(W \\Lambda W^T) = \\text{tr}(W^T W \\Lambda) = \\text{tr}(I \\Lambda) = \\text{tr}(\\Lambda)\n$$\n对角矩阵 $\\Lambda$ 的迹是其对角线元素之和，也就是特征值之和：\n$$\n\\text{Total Variance} = \\sum_{j=1}^{p} \\lambda_j\n$$\n数据集的总方差等于其协方差矩阵的特征值之和。\n\n前 $k$ 个主成分解释的方差是它们各自方差的总和：\n$$\n\\text{Variance explained by first } k \\text{ PCs} = \\sum_{j=1}^{k} \\lambda_j\n$$\n因此，前 $k$ 个主成分解释的总方差分数是它们解释的方差与总方差的比率：\n$$\n\\text{Fraction of Variance} = \\frac{\\sum_{j=1}^{k} \\lambda_j}{\\sum_{j=1}^{p} \\lambda_j}\n$$\n推导至此完成。\n\n### 第2部分：计算\n\n给定 $p=5$ 个特征，要求计算前 $k=2$ 个主成分解释的方差分数。特征值按降序给出：\n$\\lambda_{1} = 2.1$, $\\lambda_{2} = 1.3$, $\\lambda_{3} = 0.9$, $\\lambda_{4} = 0.5$, 和 $\\lambda_{5} = 0.2$。\n\n前 $k=2$ 个主成分解释的方差是前两个特征值之和：\n$$\n\\sum_{j=1}^{2} \\lambda_j = \\lambda_1 + \\lambda_2 = 2.1 + 1.3 = 3.4\n$$\n总方差是所有 $p=5$ 个特征值之和：\n$$\n\\sum_{j=1}^{5} \\lambda_j = \\lambda_1 + \\lambda_2 + \\lambda_3 + \\lambda_4 + \\lambda_5 = 2.1 + 1.3 + 0.9 + 0.5 + 0.2 = 5.0\n$$\n前 $k=2$ 个主成分解释的方差分数为：\n$$\n\\text{Fraction} = \\frac{\\sum_{j=1}^{2} \\lambda_j}{\\sum_{j=1}^{5} \\lambda_j} = \\frac{3.4}{5.0} = 0.68\n$$\n题目要求答案四舍五入到四位有效数字。\n$$\n0.68 = 0.6800\n$$",
            "answer": "$$\\boxed{0.6800}$$"
        },
        {
            "introduction": "当数据和特征准备就绪后，我们便进入模型训练的核心环节。然而，电池实验数据常伴随着测量噪声和异常值，这会严重影响标准损失函数（如均方误差）的性能。本练习将探讨Huber损失函数，它巧妙地结合了均方误差和绝对值误差的优点，从而实现对异常值的鲁棒性。通过推导其梯度，你将从根本上理解为何它能引导模型训练过程更加稳定，最终获得在真实世界含噪数据上表现更优的模型。",
            "id": "3926194",
            "problem": "在自动化电池设计和仿真中，考虑使用监督回归，从高保真模拟描述符中预测循环寿命。设输入描述符向量为 $\\{x_i\\}_{i=1}^{N}$，其中 $x_i \\in \\mathbb{R}^{d}$，测得的循环寿命为 $\\{y_i\\}_{i=1}^{N}$，其中每个 $y_i$ 是达到指定寿命终止标准前的充放电循环次数。假设一个线性预测器 $f_{\\theta}(x) = x^{\\top}\\theta$，其参数向量为 $\\theta \\in \\mathbb{R}^{d}$，残差为 $r_i(\\theta) = x_i^{\\top}\\theta - y_i$。由于测试中断和传感器校准失误，$y_i$ 的测量过程会偶尔出现较大误差，从而产生重尾残差分布。\n\n从经验风险最小化原则出发，定义一个鲁棒损失函数，该函数在小残差时使用平方损失，在大残差时使用绝对值损失，并在这两者之间进行插值。使用此定义作为数据保真项，为数据集 $\\{(x_i, y_i)\\}_{i=1}^{N}$ 构建经验目标函数 $J(\\theta)$，并推导出其梯度 $\\nabla_{\\theta} J(\\theta)$。您的推导必须从基于损失的风险的基本定义开始，并通过对向量值参数应用链式法则来进行。\n\n利用您推导出的梯度的结构，解释为什么在存在含噪声的电池寿命测量值的情况下，这种损失函数比纯平方损失对离群值更鲁棒。明确描述当 $|r_i(\\theta)|$ 增大时，每个样本对梯度的贡献如何变化，以及这在面对极端残差时如何影响优化稳定性。\n\n将您的最终答案表示为关于 $x_i$、$y_i$、$\\theta$ 和一个正阈值参数 $\\delta$ 的单个闭式解析表达式，其中样本数量为 $N$。不需要进行数值评估。不要报告中间结果。如果您在推导过程中引入任何辅助函数，请在推导中对其进行定义，但要确保最终答案写成单个表达式。最终答案必须是无单位的，并且不需要四舍五入。",
            "solution": "问题陈述经评估有效。它在科学上基于标准的机器学习原理，问题设定良好，目标明确，并且没有任何列出的无效缺陷。\n\n**1. 鲁棒损失函数的定义**\n\n经验风险最小化原则指出，我们寻求一个参数向量 $\\theta$ 来最小化目标函数 $J(\\theta)$，该函数定义为在数据集上的平均损失。\n$$\nJ(\\theta) = \\frac{1}{N} \\sum_{i=1}^{N} L(y_i, f_{\\theta}(x_i))\n$$\n问题要求一个鲁棒的损失函数，该函数在小残差时表现为平方损失（$L_2$），在大残差时表现为绝对值损失（$L_1$），并在这两者之间进行插值。这是Huber损失的特性，它使用一个正阈值参数 $\\delta$ 来定义。设残差为 $r = f_{\\theta}(x) - y = x^{\\top}\\theta - y$。Huber损失 $L_{\\delta}(r)$ 由下式给出：\n$$\nL_{\\delta}(r) =\n\\begin{cases}\n\\frac{1}{2} r^2  \\text{若 } |r| \\le \\delta \\\\\n\\delta|r| - \\frac{1}{2}\\delta^2  \\text{若 } |r| > \\delta\n\\end{cases}\n$$\n对于小残差（$|r| \\le \\delta$），该函数是二次的，以提高效率；对于大残差（$|r| > \\delta$），该函数是线性的，以提供对离群值的鲁棒性。项 $-\\frac{1}{2}\\delta^2$ 确保了函数在点 $|r| = \\delta$ 处是连续的。损失函数关于残差 $r$ 的一阶导数也是连续的：\n$$\n\\frac{dL_{\\delta}}{dr}(r) =\n\\begin{cases}\nr  \\text{若 } |r| \\le \\delta \\\\\n\\delta \\cdot \\text{sgn}(r)  \\text{若 } |r| > \\delta\n\\end{cases}\n$$\n其中 $\\text{sgn}(r)$ 是符号函数。\n\n**2. 经验目标函数的构建与梯度推导**\n\n使用Huber损失作为数据保真项，数据集 $\\{(x_i, y_i)\\}_{i=1}^{N}$ 的经验目标函数 $J(\\theta)$ 是所有样本的平均损失：\n$$\nJ(\\theta) = \\frac{1}{N} \\sum_{i=1}^{N} L_{\\delta}(r_i(\\theta))\n$$\n其中 $r_i(\\theta) = x_i^{\\top}\\theta - y_i$。\n\n为了求得梯度 $\\nabla_{\\theta} J(\\theta)$，我们将 $J(\\theta)$ 对向量 $\\theta$ 求导。根据梯度算子的线性性质：\n$$\n\\nabla_{\\theta} J(\\theta) = \\nabla_{\\theta} \\left( \\frac{1}{N} \\sum_{i=1}^{N} L_{\\delta}(r_i(\\theta)) \\right) = \\frac{1}{N} \\sum_{i=1}^{N} \\nabla_{\\theta} L_{\\delta}(r_i(\\theta))\n$$\n我们对求和中的每一项应用向量值参数的链式法则。损失 $L_{\\delta}$ 是标量残差 $r_i$ 的标量函数，而 $r_i$ 又是向量参数 $\\theta$ 的标量函数。\n$$\n\\nabla_{\\theta} L_{\\delta}(r_i(\\theta)) = \\frac{dL_{\\delta}}{dr_i}(r_i(\\theta)) \\cdot \\nabla_{\\theta} r_i(\\theta)\n$$\n首先，我们计算残差 $r_i(\\theta)$ 关于 $\\theta$ 的梯度：\n$$\nr_i(\\theta) = x_i^{\\top}\\theta - y_i\n$$\n$$\n\\nabla_{\\theta} r_i(\\theta) = \\nabla_{\\theta} (x_i^{\\top}\\theta - y_i) = x_i\n$$\n现在，将导数代回链式法则表达式中：\n$$\n\\nabla_{\\theta} L_{\\delta}(r_i(\\theta)) = \\left( \\begin{cases} r_i(\\theta)  \\text{若 } |r_i(\\theta)| \\le \\delta \\\\ \\delta \\cdot \\text{sgn}(r_i(\\theta))  \\text{若 } |r_i(\\theta)| > \\delta \\end{cases} \\right) \\cdot x_i\n$$\n代入 $r_i(\\theta) = x_i^{\\top}\\theta - y_i$，每个样本对梯度的贡献是：\n$$\n\\nabla_{\\theta} L_{\\delta}(r_i(\\theta)) =\n\\begin{cases}\n(x_i^{\\top}\\theta - y_i)x_i  \\text{若 } |x_i^{\\top}\\theta - y_i| \\le \\delta \\\\\n\\delta \\cdot \\text{sgn}(x_i^{\\top}\\theta - y_i) \\cdot x_i  \\text{若 } |x_i^{\\top}\\theta - y_i| > \\delta\n\\end{cases}\n$$\n最后，对所有 $N$ 个样本求和并除以 $N$，得到目标函数的完整梯度：\n$$\n\\nabla_{\\theta} J(\\theta) = \\frac{1}{N} \\sum_{i=1}^{N}\n\\begin{cases}\n(x_i^{\\top}\\theta - y_i)x_i  \\text{若 } |x_i^{\\top}\\theta - y_i| \\le \\delta \\\\\n\\delta \\cdot \\text{sgn}(x_i^{\\top}\\theta - y_i) \\cdot x_i  \\text{若 } |x_i^{\\top}\\theta - y_i| > \\delta\n\\end{cases}\n$$\n\n**3. 对离群值的鲁棒性分析**\n\nHuber损失的鲁棒性从其梯度的结构中可以明显看出，特别是与纯平方损失（均方误差，MSE）的梯度相比时。对于MSE，单个样本的损失是 $\\frac{1}{2}r_i^2$，其对应的梯度贡献始终是 $r_i(\\theta)x_i = (x_i^{\\top}\\theta - y_i)x_i$。\n\n-   **对于小残差（$|r_i(\\theta)| \\le \\delta$）：**Huber损失的梯度贡献是 $(x_i^{\\top}\\theta - y_i)x_i$。这与平方损失的梯度贡献相同。在这个区域，数据点被认为是“内点”并且能很好地拟合模型，优化过程的行为类似于标准最小二乘法。\n\n-   **对于大残差（$|r_i(\\theta)| > \\delta$）：**这是鲁棒性的关键区域。\n    -   对于**平方损失**，梯度贡献的量级 $\\|(x_i^{\\top}\\theta - y_i)x_i\\| = |r_i(\\theta)| \\|x_i\\|$ 随着残差量级 $|r_i(\\theta)|$ 的增加而*线性无界地增长*。一个具有非常大残差的离群值（由于传感器校准失误等原因）将产生一个不成比例的巨大梯度。在像梯度下降这样的优化算法中，这单个离群值可能会主导梯度更新步骤，将参数向量 $\\theta$ 拉离对其他数据而言最优的解。这会导致不稳定性，并使最终模型严重偏向离群值。\n\n    -   对于**Huber损失**，一旦残差超过 $\\delta$，梯度贡献的量级就变为常数。其贡献为 $\\delta \\cdot \\text{sgn}(x_i^{\\top}\\theta - y_i) \\cdot x_i$，量级为 $\\|\\delta \\cdot \\text{sgn}(r_i(\\theta)) \\cdot x_i\\| = \\delta \\|x_i\\|$。该值与残差量级 $|r_i(\\theta)|$ *无关*。这意味着一个具有极端大残差的离群值对梯度更新的贡献，并不比一个其残差刚刚超过 $\\delta$ 的点的贡献更大。梯度被有效地“裁剪”了。\n\n这种裁剪机制防止了离群值对梯度施加无界的影响。它确保了优化过程更加稳定，并且最终的参数 $\\theta$ 反映了大部分数据的基本趋势，而不是被少数异常测量值所扭曲。因此，在存在重尾噪声和离群值（例如问题中描述的含噪声的电池寿命测量值）的情况下，Huber损失比平方损失更鲁棒。",
            "answer": "$$ \\boxed{ \\frac{1}{N} \\sum_{i=1}^{N} \\begin{cases} (x_i^{\\top}\\theta - y_i)x_i  \\text{若 } |x_i^{\\top}\\theta - y_i| \\le \\delta \\\\ \\delta \\, \\text{sgn}(x_i^{\\top}\\theta - y_i) x_i  \\text{若 } |x_i^{\\top}\\theta - y_i| > \\delta \\end{cases} } $$"
        }
    ]
}