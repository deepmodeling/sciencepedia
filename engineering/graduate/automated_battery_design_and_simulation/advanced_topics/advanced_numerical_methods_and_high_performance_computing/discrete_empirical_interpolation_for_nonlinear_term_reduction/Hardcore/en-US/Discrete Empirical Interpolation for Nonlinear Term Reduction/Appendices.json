{
    "hands_on_practices": [
        {
            "introduction": "The journey into model reduction for nonlinear systems begins with capturing the essential dynamics in a low-dimensional subspace. This first practice focuses on the foundational step of constructing this subspace basis from a collection of system 'snapshots' . By applying the Singular Value Decomposition (SVD) to a small snapshot matrix, you will directly compute the basis vectors that form the building blocks for the DEIM approximation, gaining a hands-on understanding of how dominant patterns are extracted from data.",
            "id": "3907533",
            "problem": "In automated battery design and simulation, the Discrete Empirical Interpolation Method (DEIM) is employed to reduce the computational burden of nonlinear source terms, such as those arising from the Butler–Volmer kinetics in lithium-ion cells. A standard approach constructs a low-dimensional basis for the nonlinear term from a snapshot matrix using the Singular Value Decomposition (SVD). Consider a training snapshot matrix assembled from spatially discretized evaluations of a nonlinear vector field across parameter and state samples,\n$$\nS=\\begin{bmatrix}\n2 & 0 \\\\\n0 & 1 \\\\\n1 & 1\n\\end{bmatrix},\n$$\nwhere each column corresponds to a sampled nonlinear snapshot at a different operating condition. Starting from the foundational linear-algebraic principle that any real matrix admits an SVD and that the left singular vectors are the orthonormal eigenvectors of $S S^T$ associated with the nonzero singular values, determine the first two left singular vectors to construct the DEIM basis\n$$\nU \\in \\mathbb{R}^{3 \\times 2}.\n$$\nExpress $U$ as a closed-form analytic expression in radicals. The final answer must be the matrix $U$; no units are required.",
            "solution": "The goal is to compute the first two left singular vectors of the matrix $S \\in \\mathbb{R}^{3 \\times 2}$. By the fundamental properties of the Singular Value Decomposition (SVD), for any real matrix $S$, there exists an SVD $S = U \\Sigma V^T$, where $U \\in \\mathbb{R}^{3 \\times 3}$ has orthonormal columns (the left singular vectors), $\\Sigma \\in \\mathbb{R}^{3 \\times 2}$ is a diagonal matrix with nonnegative singular values, and $V \\in \\mathbb{R}^{2 \\times 2}$ has orthonormal columns (the right singular vectors). Moreover, the columns of $U$ are the orthonormal eigenvectors of the symmetric positive semidefinite matrix $S S^T$, with eigenvalues equal to the squares of the singular values.\n\nWe proceed from these foundational facts.\n\n1. Compute $S S^T$:\n$$\nS S^T\n=\n\\begin{bmatrix}\n2 & 0 \\\\\n0 & 1 \\\\\n1 & 1\n\\end{bmatrix}\n\\begin{bmatrix}\n2 & 0 & 1 \\\\\n0 & 1 & 1\n\\end{bmatrix}\n=\n\\begin{bmatrix}\n4 & 0 & 2 \\\\\n0 & 1 & 1 \\\\\n2 & 1 & 2\n\\end{bmatrix}.\n$$\n\n2. Compute the eigenvalues of $S S^T$ by solving $\\det(S S^T - \\lambda I) = 0$. Let\n$$\nA = S S^T = \\begin{bmatrix}\n4 & 0 & 2 \\\\\n0 & 1 & 1 \\\\\n2 & 1 & 2\n\\end{bmatrix}.\n$$\nThe characteristic polynomial is\n$$\n\\det(A - \\lambda I)\n=\n\\begin{vmatrix}\n4 - \\lambda & 0 & 2 \\\\\n0 & 1 - \\lambda & 1 \\\\\n2 & 1 & 2 - \\lambda\n\\end{vmatrix}\n=\n-\\lambda \\left(\\lambda^{2} - 7\\lambda + 9\\right).\n$$\nThus, the eigenvalues are\n$$\n\\lambda_{1} = \\frac{7 + \\sqrt{13}}{2}, \\quad\n\\lambda_{2} = \\frac{7 - \\sqrt{13}}{2}, \\quad\n\\lambda_{3} = 0.\n$$\nThe singular values are $\\sigma_{i} = \\sqrt{\\lambda_{i}}$, and the associated left singular vectors are the normalized eigenvectors of $A$ for $\\lambda_{1}$ and $\\lambda_{2}$.\n\n3. Compute an eigenvector for $\\lambda_{1} = \\frac{7 + \\sqrt{13}}{2}$ by solving $(A - \\lambda_{1} I)\\mathbf{v}_{1} = \\mathbf{0}$. The system\n$$\n\\begin{cases}\n\\left(4 - \\lambda_{1}\\right) x + 2 z = 0, \\\\\n\\left(1 - \\lambda_{1}\\right) y + z = 0, \\\\\n2 x + y + \\left(2 - \\lambda_{1}\\right) z = 0,\n\\end{cases}\n$$\nhas the solution proportional to\n$$\n\\mathbf{v}_{1} = \\begin{bmatrix}\n1 \\\\\n\\frac{\\sqrt{13} - 3}{4} \\\\\n\\frac{\\sqrt{13} - 1}{4}\n\\end{bmatrix}.\n$$\nNormalize $\\mathbf{v}_{1}$:\n$$\n\\|\\mathbf{v}_{1}\\|^{2}\n=\n1^{2}\n+\n\\left(\\frac{\\sqrt{13} - 3}{4}\\right)^{2}\n+\n\\left(\\frac{\\sqrt{13} - 1}{4}\\right)^{2}\n=\n\\frac{13 - 2\\sqrt{13}}{4},\n$$\nso\n$$\n\\|\\mathbf{v}_{1}\\|\n=\n\\sqrt{\\frac{13 - 2\\sqrt{13}}{4}}\n=\n\\frac{\\sqrt{13 - 2\\sqrt{13}}}{2}.\n$$\nTherefore, the normalized eigenvector (first left singular vector) is\n$$\n\\mathbf{u}_{1}\n=\n\\frac{\\mathbf{v}_{1}}{\\|\\mathbf{v}_{1}\\|}\n=\n\\begin{bmatrix}\n\\frac{2}{\\sqrt{13 - 2\\sqrt{13}}} \\\\\n\\frac{\\sqrt{13} - 3}{2\\sqrt{13 - 2\\sqrt{13}}} \\\\\n\\frac{\\sqrt{13} - 1}{2\\sqrt{13 - 2\\sqrt{13}}}\n\\end{bmatrix}.\n$$\n\n4. Compute an eigenvector for $\\lambda_{2} = \\frac{7 - \\sqrt{13}}{2}$ by solving $(A - \\lambda_{2} I)\\mathbf{v}_{2} = \\mathbf{0}$. The system\n$$\n\\begin{cases}\n\\left(4 - \\lambda_{2}\\right) x + 2 z = 0, \\\\\n\\left(1 - \\lambda_{2}\\right) y + z = 0, \\\\\n2 x + y + \\left(2 - \\lambda_{2}\\right) z = 0,\n\\end{cases}\n$$\nhas the solution proportional to\n$$\n\\mathbf{v}_{2} = \\begin{bmatrix}\n1 \\\\\n-\\frac{\\sqrt{13} + 3}{4} \\\\\n-\\frac{\\sqrt{13} + 1}{4}\n\\end{bmatrix}.\n$$\nNormalize $\\mathbf{v}_{2}$:\n$$\n\\|\\mathbf{v}_{2}\\|^{2}\n=\n1^{2}\n+\n\\left(\\frac{\\sqrt{13} + 3}{4}\\right)^{2}\n+\n\\left(\\frac{\\sqrt{13} + 1}{4}\\right)^{2}\n=\n\\frac{13 + 2\\sqrt{13}}{4},\n$$\nso\n$$\n\\|\\mathbf{v}_{2}\\|\n=\n\\sqrt{\\frac{13 + 2\\sqrt{13}}{4}}\n=\n\\frac{\\sqrt{13 + 2\\sqrt{13}}}{2}.\n$$\nTherefore, the normalized eigenvector (second left singular vector) is\n$$\n\\mathbf{u}_{2}\n=\n\\frac{\\mathbf{v}_{2}}{\\|\\mathbf{v}_{2}\\|}\n=\n\\begin{bmatrix}\n\\frac{2}{\\sqrt{13 + 2\\sqrt{13}}} \\\\\n-\\frac{\\sqrt{13} + 3}{2\\sqrt{13 + 2\\sqrt{13}}} \\\\\n-\\frac{\\sqrt{13} + 1}{2\\sqrt{13 + 2\\sqrt{13}}}\n\\end{bmatrix}.\n$$\n\n5. Assemble the DEIM basis matrix $U \\in \\mathbb{R}^{3 \\times 2}$ from the first two left singular vectors:\n$$\nU\n=\n\\begin{bmatrix}\n\\frac{2}{\\sqrt{13 - 2\\sqrt{13}}}\n&\n\\frac{2}{\\sqrt{13 + 2\\sqrt{13}}}\n\\\\\n\\frac{\\sqrt{13} - 3}{2\\sqrt{13 - 2\\sqrt{13}}}\n&\n-\\frac{\\sqrt{13} + 3}{2\\sqrt{13 + 2\\sqrt{13}}}\n\\\\\n\\frac{\\sqrt{13} - 1}{2\\sqrt{13 - 2\\sqrt{13}}}\n&\n-\\frac{\\sqrt{13} + 1}{2\\sqrt{13 + 2\\sqrt{13}}}\n\\end{bmatrix}.\n$$\nBy construction, the columns are orthonormal eigenvectors of $S S^T$ associated with the two positive eigenvalues, and hence they are the first two left singular vectors of $S$, forming the DEIM basis for the nonlinear term reduction.",
            "answer": "$$\\boxed{\n\\begin{pmatrix}\n\\frac{2}{\\sqrt{13 - 2\\sqrt{13}}} & \\frac{2}{\\sqrt{13 + 2\\sqrt{13}}} \\\\\n\\frac{\\sqrt{13} - 3}{2\\sqrt{13 - 2\\sqrt{13}}} & -\\frac{\\sqrt{13} + 3}{2\\sqrt{13 + 2\\sqrt{13}}} \\\\\n\\frac{\\sqrt{13} - 1}{2\\sqrt{13 - 2\\sqrt{13}}} & -\\frac{\\sqrt{13} + 1}{2\\sqrt{13 + 2\\sqrt{13}}}\n\\end{pmatrix}\n}$$"
        },
        {
            "introduction": "With a reduced basis in hand, the next challenge is to avoid computing the full nonlinear term for projection. The Discrete Empirical Interpolation Method (DEIM) ingeniously solves this by selecting a small number of strategic 'interpolation points' where the function is actually evaluated. This exercise  guides you through the core DEIM greedy algorithm, demonstrating how these crucial points are chosen to ensure the resulting small linear system is well-conditioned and the approximation is robust.",
            "id": "3907604",
            "problem": "In reduced-order modeling of nonlinear source terms in automated battery design and simulation, consider a nonlinear map that arises from electrochemical kinetics and transport, for example in the Butler–Volmer reaction term coupled to electrolyte transport. After obtaining a reduced basis of nonlinear snapshots, the Discrete Empirical Interpolation Method (DEIM) is applied to select interpolation indices for efficient online evaluation. Let the reduced basis matrix be given by\n$$\nU \\;=\\; \\frac{1}{\\sqrt{2}}\\begin{bmatrix}\n1 & 0\\\\\n1 & 1\\\\\n0 & 1\n\\end{bmatrix},\n$$\nwhere the columns of $U$ span the two-dimensional approximation subspace for the nonlinear term. Using the standard greedy DEIM selection procedure with the convention that ties are broken by choosing the smallest index, compute the DEIM interpolation indices $p_1$ and $p_2$. Define the sampling matrix $P \\in \\mathbb{R}^{3\\times 2}$ by $P = \\begin{bmatrix} e_{p_1} & e_{p_2} \\end{bmatrix}$, where $e_i$ is the $i$-th column of the identity matrix in $\\mathbb{R}^{3\\times 3}$. Verify that $P^T U$ is invertible by evaluating its determinant. Report the ordered pair $(p_1,p_2)$ as your final answer. No rounding is required and no units are needed.",
            "solution": "The problem requires the computation of the first two Discrete Empirical Interpolation Method (DEIM) indices, $p_1$ and $p_2$, for a given reduced basis matrix $U$. The DEIM algorithm is a greedy procedure for selecting a set of interpolation points. Let the columns of the reduced basis matrix $U \\in \\mathbb{R}^{n \\times m}$ be denoted by $u_1, u_2, \\dots, u_m$. In this problem, $n=3$ and $m=2$.\n\nThe given reduced basis matrix is:\n$$\nU \\;=\\; \\frac{1}{\\sqrt{2}}\\begin{bmatrix}\n1 & 0\\\\\n1 & 1\\\\\n0 & 1\n\\end{bmatrix}\n$$\nThe columns of $U$ are the basis vectors $u_1$ and $u_2$:\n$$\nu_1 = \\frac{1}{\\sqrt{2}}\\begin{bmatrix} 1 \\\\ 1 \\\\ 0 \\end{bmatrix}, \\quad u_2 = \\frac{1}{\\sqrt{2}}\\begin{bmatrix} 0 \\\\ 1 \\\\ 1 \\end{bmatrix}\n$$\n\nThe DEIM algorithm proceeds as follows:\n\n**Step 1: Compute the first interpolation index $p_1$.**\nThe first index $p_1$ is chosen as the index of the component of the first basis vector, $u_1$, that has the largest absolute value.\n$$\np_1 = \\arg\\max_{i \\in \\{1, 2, 3\\}} |(u_1)_i|\n$$\nThe components of $u_1$ are $(u_1)_1 = \\frac{1}{\\sqrt{2}}$, $(u_1)_2 = \\frac{1}{\\sqrt{2}}$, and $(u_1)_3 = 0$. The absolute values are $|\\frac{1}{\\sqrt{2}}|$, $|\\frac{1}{\\sqrt{2}}|$, and $|0|$. The maximum absolute value is $\\frac{1}{\\sqrt{2}}$, which occurs at indices $i=1$ and $i=2$. According to the problem statement, ties are broken by choosing the smallest index. Therefore, we select:\n$$\np_1 = 1\n$$\n\n**Step 2: Compute the second interpolation index $p_2$.**\nThe second index $p_2$ is found by first computing the residual vector $r_2$. This residual is the error between the second basis vector $u_2$ and its projection onto the subspace spanned by the first basis vector $u_1$. The projection is constructed using the first interpolation point $p_1=1$.\n\nThe approximation of $u_2$ is of the form $c_1 u_1$. The coefficient $c_1$ is determined by enforcing that the approximation matches $u_2$ at the first interpolation point $p_1=1$:\n$$\n(u_2)_{p_1} = c_1 (u_1)_{p_1}\n$$\nSubstituting the values for $p_1=1$:\n$$\n(u_2)_1 = c_1 (u_1)_1 \\implies \\frac{1}{\\sqrt{2}}(0) = c_1 \\frac{1}{\\sqrt{2}}(1) \\implies 0 = c_1\n$$\nThe coefficient is $c_1 = 0$.\n\nThe residual vector $r_2$ is then computed as:\n$$\nr_2 = u_2 - c_1 u_1 = u_2 - 0 \\cdot u_1 = u_2\n$$\nSo, the residual vector is simply $r_2 = u_2 = \\frac{1}{\\sqrt{2}}\\begin{bmatrix} 0 \\\\ 1 \\\\ 1 \\end{bmatrix}$.\n\nThe second index $p_2$ is the index of the component of the residual vector $r_2$ with the largest absolute value:\n$$\np_2 = \\arg\\max_{i \\in \\{1, 2, 3\\}} |(r_2)_i|\n$$\nThe components of $r_2$ are $(r_2)_1 = 0$, $(r_2)_2 = \\frac{1}{\\sqrt{2}}$, and $(r_2)_3 = \\frac{1}{\\sqrt{2}}$. The absolute values are $|0|$, $|\\frac{1}{\\sqrt{2}}|$, and $|\\frac{1}{\\sqrt{2}}|$. The maximum absolute value is $\\frac{1}{\\sqrt{2}}$, which occurs at indices $i=2$ and $i=3$. Again, breaking the tie by choosing the smallest index, we get:\n$$\np_2 = 2\n$$\nThe DEIM interpolation indices are therefore the ordered pair $(p_1, p_2) = (1, 2)$.\n\n**Step 3: Verification of invertibility of $P^T U$.**\nThe problem requires verification that the matrix $P^T U$ is invertible. The sampling matrix $P$ is constructed from the standard basis vectors $e_i \\in \\mathbb{R}^3$ corresponding to the computed indices:\n$$\nP = \\begin{bmatrix} e_{p_1} & e_{p_2} \\end{bmatrix} = \\begin{bmatrix} e_1 & e_2 \\end{bmatrix} = \\begin{bmatrix} 1 & 0 \\\\ 0 & 1 \\\\ 0 & 0 \\end{bmatrix}\n$$\nThe transpose of $P$ is:\n$$\nP^T = \\begin{bmatrix} 1 & 0 & 0 \\\\ 0 & 1 & 0 \\end{bmatrix}\n$$\nNow, we compute the product $P^T U$:\n$$\nP^T U = \\begin{bmatrix} 1 & 0 & 0 \\\\ 0 & 1 & 0 \\end{bmatrix} \\left( \\frac{1}{\\sqrt{2}}\\begin{bmatrix} 1 & 0\\\\ 1 & 1\\\\ 0 & 1 \\end{bmatrix} \\right) = \\frac{1}{\\sqrt{2}} \\begin{bmatrix} 1 \\cdot 1 + 0 \\cdot 1 + 0 \\cdot 0 & 1 \\cdot 0 + 0 \\cdot 1 + 0 \\cdot 1 \\\\ 0 \\cdot 1 + 1 \\cdot 1 + 0 \\cdot 0 & 0 \\cdot 0 + 1 \\cdot 1 + 0 \\cdot 1 \\end{bmatrix}\n$$\n$$\nP^T U = \\frac{1}{\\sqrt{2}} \\begin{bmatrix} 1 & 0 \\\\ 1 & 1 \\end{bmatrix}\n$$\nTo verify invertibility, we compute the determinant of this $2 \\times 2$ matrix:\n$$\n\\det(P^T U) = \\det\\left(\\frac{1}{\\sqrt{2}} \\begin{bmatrix} 1 & 0 \\\\ 1 & 1 \\end{bmatrix}\\right) = \\left(\\frac{1}{\\sqrt{2}}\\right)^2 \\det\\left(\\begin{bmatrix} 1 & 0 \\\\ 1 & 1 \\end{bmatrix}\\right)\n$$\n$$\n\\det(P^T U) = \\frac{1}{2} \\left( (1)(1) - (0)(1) \\right) = \\frac{1}{2}(1) = \\frac{1}{2}\n$$\nSince $\\det(P^T U) = \\frac{1}{2} \\neq 0$, the matrix $P^T U$ is invertible. This completes the verification.\n\nThe final answer is the ordered pair of DEIM interpolation indices $(p_1, p_2)$.",
            "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n1 & 2\n\\end{pmatrix}\n}\n$$"
        },
        {
            "introduction": "Having practiced the core mechanics of basis construction and point selection, it is time to assemble these components into a complete, working implementation. This capstone practice  involves applying the POD-DEIM methodology to accelerate the simulation of a nonlinear partial differential equation, the Allen-Cahn equation. You will write code to generate snapshots, build the reduced model, and critically evaluate the approximation error, gaining invaluable experience in the practical application and performance analysis of hyper-reduction techniques.",
            "id": "3383598",
            "problem": "Implement a Discrete Empirical Interpolation Method (DEIM) approximation with oversampling for the nonlinear term in the one-dimensional Allen–Cahn equation using a Chebyshev spectral collocation discretization, and quantify the approximation error as the number of interpolation points increases while the reduced basis rank remains fixed.\n\nYou are given the nonlinear operator of the Allen–Cahn equation\n$$\nf(u) = u^3 - u,\n$$\nand the partial differential equation\n$$\nu_t = \\varepsilon^2 u_{xx} + f(u),\n$$\nposed on the interval $[-1,1]$ with homogeneous Dirichlet boundary conditions $u(-1,t)=0$ and $u(1,t)=0$. Use a Chebyshev spectral collocation method with $N+1$ Chebyshev–Gauss–Lobatto points\n$$\nx_j = \\cos\\left(\\frac{\\pi j}{N}\\right), \\quad j=0,1,\\ldots,N,\n$$\nand the standard Chebyshev first derivative differentiation matrix $D \\in \\mathbb{R}^{(N+1)\\times(N+1)}$ to construct the second derivative matrix $D^{(2)} = D D$. Restrict to the $n=N-1$ interior nodes, which correspond to indices $j=1,\\ldots,N-1$. Let $D^{(2)}_{\\mathrm{int}} \\in \\mathbb{R}^{n\\times n}$ denote the interior block of $D^{(2)}$ after imposing homogeneous Dirichlet boundary conditions.\n\nTime-integrate the semi-discrete system using a first-order implicit–explicit (IMEX) Euler method that treats the diffusion term implicitly and the nonlinear reaction term explicitly. For a time step size $\\Delta t$, define\n$$\nA = I_n - \\Delta t\\, \\varepsilon^2 D^{(2)}_{\\mathrm{int}} \\in \\mathbb{R}^{n\\times n},\n$$\nand update interior degrees of freedom by\n$$\nu^{k+1}_{\\mathrm{int}} = A^{-1}\\left(u^k_{\\mathrm{int}} + \\Delta t\\, f\\!\\left(u^k_{\\mathrm{int}}\\right)\\right),\n$$\nwhere $I_n$ is the $n\\times n$ identity matrix and $f$ is applied componentwise.\n\nConstruct a snapshot matrix of nonlinear evaluations\n$$\nF = \\begin{bmatrix} f\\!\\left(u^{1}_{\\mathrm{int}}\\right) & f\\!\\left(u^{2}_{\\mathrm{int}}\\right) & \\cdots & f\\!\\left(u^{K}_{\\mathrm{int}}\\right)\\end{bmatrix} \\in \\mathbb{R}^{n\\times K},\n$$\ncomputed along the above time integration of the full-order model. Compute a rank-$r$ Proper Orthogonal Decomposition (POD) basis for the range of $F$ by taking the first $r$ left singular vectors of $F$, i.e., $U_r \\in \\mathbb{R}^{n\\times r}$ from the singular value decomposition $F = U \\Sigma V^T$.\n\nFor empirical interpolation, select interpolation indices using the QR factorization with column pivoting of $U_r^T \\in \\mathbb{R}^{r\\times n}$. Let the permutation indices be $p_1,\\ldots,p_n$, ordered by pivot importance. For a chosen number of interpolation points $m$ with $m \\ge r$, define the selection operator $P_m \\in \\mathbb{R}^{n\\times m}$ that extracts the rows at indices $p_1,\\ldots,p_m$. The DEIM with oversampling constructs an approximation of $f(u) \\in \\mathbb{R}^{n}$ as\n$$\nf(u) \\approx \\widehat{f}_m(u) = U_r c_m(u),\n$$\nwhere the coefficient vector $c_m(u) \\in \\mathbb{R}^{r}$ is obtained by solving the overdetermined least-squares problem\n$$\n\\min_{c \\in \\mathbb{R}^{r}} \\left\\| P_m^T U_r\\, c - P_m^T f(u) \\right\\|_2,\n$$\nwhose normal least-squares solution is\n$$\nc_m(u) = \\left(P_m^T U_r\\right)^{\\dagger} P_m^T f(u),\n$$\nwith $\\left(\\cdot\\right)^{\\dagger}$ the Moore–Penrose pseudoinverse. When $m=r$, this reduces to the classical square Discrete Empirical Interpolation Method.\n\nUsing the above, perform the following:\n\n1. Construct the Chebyshev collocation differentiation matrices and set up the semi-discrete system on the $n=N-1$ interior nodes for homogeneous Dirichlet boundary conditions.\n2. Choose a smooth deterministic initial condition $u_{\\mathrm{int}}^0$ on $[-1,1]$ restricted to interior nodes, evolve the implicit–explicit Euler scheme for $K$ steps, and assemble the snapshot matrix $F \\in \\mathbb{R}^{n\\times K}$ of the nonlinear evaluations along the trajectory.\n3. Compute the rank-$r$ POD basis $U_r$ from the snapshots via singular value decomposition.\n4. Determine a pivot ordering by performing a column-pivoted QR factorization of $U_r^T$, and for each prescribed $m \\ge r$, form the oversampled DEIM approximation map\n$$\n\\widehat{f}_m(\\cdot) = U_r \\left(P_m^T U_r\\right)^{\\dagger} P_m^T (\\cdot).\n$$\n5. For each $m$, evaluate the DEIM approximation $\\widehat{f}_m$ on every snapshot column of $F$ and compute the relative error per snapshot\n$$\ne_k^{(m)} = \\frac{\\left\\| f\\!\\left(u_{\\mathrm{int}}^{k}\\right) - \\widehat{f}_m\\!\\left(u_{\\mathrm{int}}^{k}\\right)\\right\\|_2}{\\left\\| f\\!\\left(u_{\\mathrm{int}}^{k}\\right)\\right\\|_2}, \\quad k=1,\\ldots,K,\n$$\nand aggregate them by taking the maximum over all snapshots,\n$$\nE^{(m)} = \\max_{1 \\le k \\le K} e_k^{(m)}.\n$$\n\nUse the following parameter values to produce a reproducible test suite:\n- Chebyshev order: $N=64$ (so $n=63$ interior nodes).\n- Diffusion parameter: $\\varepsilon = 0.03$.\n- Time step and horizon: $\\Delta t = 10^{-3}$, $K=200$ steps (so final time $T=0.2$).\n- Initial condition restricted to interior nodes: for interior grid points $x$, set\n$$\nu_{\\mathrm{int}}^0(x) = 0.2 \\sin(\\pi x) + 0.1 \\cos(2\\pi x).\n$$\n- POD rank: $r=8$.\n- Interpolation counts: $m \\in \\{8, 12, 16, 24\\}$.\n\nYour program must:\n- Implement all the above steps.\n- For each $m$ in the test suite, compute $E^{(m)}$ as defined.\n- Produce as its only output a single line containing the results as a comma-separated list enclosed in square brackets, in the same order of $m$ values, i.e., in the format\n$$\n[\\;E^{(8)},\\,E^{(12)},\\,E^{(16)},\\,E^{(24)}\\;].\n$$\nNo physical units are involved. Angles, where present, are in radians by construction. The output values must be floating-point numbers.",
            "solution": "The user's request is to implement and evaluate the Discrete Empirical Interpolation Method (DEIM) with oversampling for approximating a nonlinear term. The context is the one-dimensional Allen-Cahn equation, discretized using a Chebyshev spectral collocation method. The problem is numerically well-defined, scientifically sound, and all necessary parameters and procedures are specified. The problem is declared valid.\n\nThe solution proceeds in several stages: first, the construction of a high-fidelity full-order model (FOM) using spectral methods and an implicit-explicit (IMEX) time integrator; second, the generation of a reduced basis for the nonlinear term via Proper Orthogonal Decomposition (POD); third, the selection of interpolation points and construction of the oversampled DEIM approximant; and finally, the quantification of the approximation error.\n\n**1. Full-Order Model (FOM) Construction**\n\nThe Allen-Cahn equation, $u_t = \\varepsilon^2 u_{xx} + f(u)$ with $f(u) = u^3 - u$, is posed on the spatial domain $x \\in [-1, 1]$ with homogeneous Dirichlet boundary conditions $u(\\pm 1, t) = 0$.\n\nA Chebyshev spectral collocation method is employed for spatial discretization. The domain is discretized using the $N+1$ Chebyshev-Gauss-Lobatto points, given by $x_j = \\cos(\\frac{\\pi j}{N})$ for $j=0, 1, \\ldots, N$. The first derivative of a function evaluated at these points can be approximated by multiplication with the Chebyshev differentiation matrix $D \\in \\mathbb{R}^{(N+1)\\times(N+1)}$. Consequently, the second derivative operator $u_{xx}$ is approximated by a matrix-vector product with the second derivative matrix, $D^{(2)} = D^2$.\n\nTo enforce the homogeneous Dirichlet boundary conditions, we restrict the system to the $n=N-1$ interior grid points, corresponding to indices $j=1, \\ldots, N-1$. This is achieved by extracting the interior block of the second derivative matrix, yielding $D^{(2)}_{\\mathrm{int}} \\in \\mathbb{R}^{n\\times n}$.\n\nThe semi-discretized system of ordinary differential equations is integrated in time using a first-order IMEX Euler scheme. This scheme treats the stiff linear diffusion term implicitly and the non-stiff nonlinear reaction term explicitly. Given a time step $\\Delta t$, the update rule for the vector of state variables at the interior nodes, $u_{\\mathrm{int}} \\in \\mathbb{R}^n$, from time step $t_k$ to $t_{k+1}$ is:\n$$\nu^{k+1}_{\\mathrm{int}} = A^{-1}\\left(u^k_{\\mathrm{int}} + \\Delta t\\, f(u^k_{\\mathrm{int}})\\right)\n$$\nwhere $f(\\cdot)$ is applied component-wise to the vector $u^k_{\\mathrm{int}}$, and the matrix $A \\in \\mathbb{R}^{n\\times n}$ is defined as:\n$$\nA = I_n - \\Delta t\\, \\varepsilon^2 D^{(2)}_{\\mathrm{int}}\n$$\nHere, $I_n$ is the $n \\times n$ identity matrix. The matrix $A$ is constant throughout the simulation, so its inverse or LU decomposition can be pre-computed for efficiency.\n\n**2. Snapshot Collection and Basis Generation (POD)**\n\nTo build a reduced model for the nonlinear term $f(u)$, we first require a representative dataset. This is generated by simulating the FOM for $K$ steps, starting from a given initial condition $u^0_{\\mathrm{int}}$. This simulation produces a sequence of states $u^1_{\\mathrm{int}}, u^2_{\\mathrm{int}}, \\ldots, u^K_{\\mathrm{int}}$. The evaluations of the nonlinear term at these states are collected as columns of a snapshot matrix:\n$$\nF = \\begin{bmatrix} f(u^{1}_{\\mathrm{int}}) & f(u^{2}_{\\mathrm{int}}) & \\cdots & f(u^{K}_{\\mathrm{int}})\\end{bmatrix} \\in \\mathbb{R}^{n\\times K}\n$$\nThe goal of model reduction is to find a low-dimensional subspace that well-approximates the space spanned by the columns of $F$. Proper Orthogonal Decomposition (POD) provides an optimal low-rank basis for this purpose in the least-squares sense. The POD basis is computed via the Singular Value Decomposition (SVD) of the snapshot matrix, $F = U \\Sigma V^T$. The rank-$r$ POD basis, $U_r \\in \\mathbb{R}^{n\\times r}$, consists of the first $r$ left singular vectors of $F$ (the first $r$ columns of $U$), which correspond to the $r$ largest singular values. Any vector $v$ in the range of $F$ can then be approximated as $v \\approx U_r U_r^T v$.\n\n**3. Oversampled Discrete Empirical Interpolation Method (DEIM)**\n\nWhile POD provides a basis to approximate the nonlinear term, evaluating the projection $U_r^T f(u)$ still requires computing the full $n$-dimensional vector $f(u)$. DEIM provides a way to circumvent this by approximating $f(u)$ using only a small number of its components.\n\nThe DEIM approximation of a vector $v = f(u)$ has the form $\\widehat{v} = U_r c$, where the coefficient vector $c \\in \\mathbb{R}^r$ is determined by enforcing equality between $v$ and its approximation $\\widehat{v}$ at a small set of $m \\ge r$ interpolation points. The indices of these points, $p_1, \\ldots, p_m$, are chosen greedily to be \"most representative.\" A standard and efficient algorithm for this selection process is the QR factorization with column pivoting of the matrix $U_r^T$. The resulting pivot indices provide the desired ordering of grid points.\n\nLet $P_m \\in \\mathbb{R}^{n \\times m}$ be the matrix operator that selects the rows corresponding to the first $m$ pivot indices. The coefficients $c$ are determined by solving the (typically overdetermined when $m > r$) linear system $P_m^T U_r c = P_m^T v$ in a least-squares sense:\n$$\n\\min_{c \\in \\mathbb{R}^{r}} \\left\\| P_m^T U_r\\, c - P_m^T v \\right\\|_2\n$$\nThe solution is given by $c_m(v) = (P_m^T U_r)^{\\dagger} P_m^T v$, where $(\\cdot)^{\\dagger}$ denotes the Moore-Penrose pseudoinverse. The final DEIM approximation is:\n$$\n\\widehat{f}_m(u) = U_r \\left( (P_m^T U_r)^{\\dagger} P_m^T f(u) \\right)\n$$\nThis expression approximates the full $n$-dimensional vector $f(u)$ using only its $m$ components at the selected interpolation points. When $m=r$, the system is square and this reduces to the classical DEIM. When $m>r$, the method is referred to as oversampled DEIM, which often provides better stability and accuracy.\n\n**4. Error Quantification**\n\nThe accuracy of the oversampled DEIM approximation is evaluated for a fixed POD basis rank $r=8$ and for an increasing number of interpolation points $m \\in \\{8, 12, 16, 24\\}$. For each choice of $m$, we compute the approximation $\\widehat{f}_m(u_{\\mathrm{int}}^k)$ for every state $u_{\\mathrm{int}}^k$ ($k=1, \\ldots, K$) used to generate the snapshots. The error is measured using the relative 2-norm for each snapshot:\n$$\ne_k^{(m)} = \\frac{\\left\\| f(u_{\\mathrm{int}}^{k}) - \\widehat{f}_m(u_{\\mathrm{int}}^{k})\\right\\|_2}{\\left\\| f(u_{\\mathrm{int}}^{k})\\right\\|_2}\n$$\nTo obtain a single aggregate error metric for each $m$, we take the maximum error over all snapshots:\n$$\nE^{(m)} = \\max_{1 \\le k \\le K} e_k^{(m)}\n$$\nThe final output consists of the values $E^{(m)}$ for the specified sequence of $m$. The parameters used are $N=64$ ($n=63$), $\\varepsilon=0.03$, $\\Delta t=10^{-3}$, $K=200$, POD rank $r=8$, and the initial condition $u_{\\mathrm{int}}^0(x) = 0.2 \\sin(\\pi x) + 0.1 \\cos(2\\pi x)$ on the interior grid.",
            "answer": "```python\nimport numpy as np\nfrom scipy.linalg import qr\n\ndef chebyshev_diff_matrix(N):\n    \"\"\"\n    Constructs the Chebyshev differentiation matrix D and the Gauss-Lobatto points x.\n    \n    Args:\n        N (int): The order of the Chebyshev polynomial, N+1 points.\n\n    Returns:\n        tuple: A tuple containing:\n            - np.ndarray: The Chebyshev-Gauss-Lobatto points x of shape (N+1,).\n            - np.ndarray: The Chebyshev differentiation matrix D of shape (N+1, N+1).\n    \"\"\"\n    if N == 0:\n        return np.array([0]), np.array([[0]])\n    \n    x = np.cos(np.pi * np.arange(N + 1) / N)\n    c = np.ones(N + 1)\n    c[0] = 2.0\n    c[N] = 2.0\n    \n    D = np.zeros((N + 1, N + 1))\n    \n    for i in range(N + 1):\n        for j in range(N + 1):\n            if i == j:\n                if i == 0:\n                    D[i, j] = (2 * N**2 + 1) / 6.0\n                elif i == N:\n                    D[i, j] = -(2 * N**2 + 1) / 6.0\n                else:\n                    D[i, j] = -x[j] / (2.0 * (1.0 - x[j]**2))\n            else:\n                D[i, j] = (c[i] / c[j]) * ((-1)**(i + j)) / (x[i] - x[j])\n                \n    return x, D\n\ndef solve():\n    \"\"\"\n    Implements the oversampled DEIM for the Allen-Cahn equation\n    and computes the approximation error for different numbers of interpolation points.\n    \"\"\"\n    # 1. Parameter setup\n    N = 64\n    n = N - 1\n    epsilon = 0.03\n    dt = 1e-3\n    K = 200\n    r = 8\n    m_values = [8, 12, 16, 24]\n\n    # Nonlinear function f(u) = u^3 - u\n    f_nonlin = lambda u: u**3 - u\n\n    # 2. Chebyshev Discretization and FOM setup\n    x, D = chebyshev_diff_matrix(N)\n    D2 = D @ D\n    \n    # Impose homogeneous Dirichlet boundary conditions by taking interior nodes\n    x_int = x[1:-1]\n    D2_int = D2[1:-1, 1:-1]\n\n    # IMEX Euler matrix A and its inverse\n    I_n = np.identity(n)\n    A = I_n - dt * epsilon**2 * D2_int\n    A_inv = np.linalg.inv(A)\n\n    # 3. FOM Simulation to generate snapshots\n    # Initial condition\n    u0_int = 0.2 * np.sin(np.pi * x_int) + 0.1 * np.cos(2 * np.pi * x_int)\n\n    # Time integration and state collection\n    states = [u0_int]\n    u_current = u0_int\n    for _ in range(K):\n        f_eval = f_nonlin(u_current)\n        u_next = A_inv @ (u_current + dt * f_eval)\n        states.append(u_next)\n        u_current = u_next\n        \n    # Assemble snapshot matrix F = [f(u^1), ..., f(u^K)]\n    snapshots_F = np.array([f_nonlin(s) for s in states[1:]]).T\n\n    # 4. POD Basis Generation\n    U, _, _ = np.linalg.svd(snapshots_F, full_matrices=False)\n    Ur = U[:, :r]\n\n    # 5. DEIM Point Selection via QR with column pivoting\n    _, _, pivot_indices = qr(Ur.T, pivoting=True)\n\n    # 6. Error Quantification Loop\n    max_errors_E = []\n    \n    for m in m_values:\n        # Select first m pivot indices\n        p_m = pivot_indices[:m]\n        \n        # Form (P_m^T U_r)\n        Ur_sampled = Ur[p_m, :]\n        \n        # Pre-compute the pseudoinverse\n        pinv_Ur_sampled = np.linalg.pinv(Ur_sampled)\n        \n        snapshot_rel_errors = []\n        for k in range(K):\n            f_k = snapshots_F[:, k]\n            \n            # Sample the snapshot vector\n            # This is P_m^T f(u^k)\n            f_k_sampled = f_k[p_m]\n            \n            # Compute DEIM coefficients\n            coeffs = pinv_Ur_sampled @ f_k_sampled\n            \n            # Reconstruct the approximation\n            f_k_approx = Ur @ coeffs\n            \n            # Compute relative error for the snapshot\n            error_norm = np.linalg.norm(f_k - f_k_approx)\n            fk_norm = np.linalg.norm(f_k)\n            \n            if fk_norm > 0:\n              rel_error = error_norm / fk_norm\n              snapshot_rel_errors.append(rel_error)\n\n        # Aggregate error for this m is the maximum over all snapshots\n        if snapshot_rel_errors:\n            max_errors_E.append(np.max(snapshot_rel_errors))\n        else:\n            max_errors_E.append(0.0) # Should not happen in this problem\n\n    # Final print statement in the exact required format\n    print(f\"[{','.join(map(str, max_errors_E))}]\")\n\nsolve()\n\n```"
        }
    ]
}