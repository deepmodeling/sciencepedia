{
    "hands_on_practices": [
        {
            "introduction": "在开始复杂的并行优化之前，首先必须理解并行计算的基本限制。Amdahl定律为我们提供了一个关键的理论框架，用于估算在给定处理器数量下可实现的最大加速比。这个练习将指导你应用Amdahl定律来分析一个典型的电池求解器，通过识别和量化串行瓶颈，你将深入理解为什么即使在拥有大量处理器的情况下，性能提升也存在一个硬性上限。",
            "id": "3936184",
            "problem": "考虑在一个自动化电池设计循环中的单次外层迭代的强扩展性研究，该循环在一个使用消息传递接口（MPI）的分布式内存集群上，采用全隐式牛顿-克雷洛夫方法求解多孔电极电化学-热模型。在单个处理单元上，主要仿真阶段测得的实际运行时间分解如下（每个设计迭代进行一次端到端求解）：\n\n- 在网格上进行残差和雅可比矩阵组装（可在空间子域上并行化）：54.0。\n- 克雷洛夫迭代中的局部线性代数核，包括稀疏矩阵向量运算和预条件子应用（可在子域上并行化）：30.0。\n- 全局收敛性检查和线搜索决策逻辑（在此强扩展性极限下被视为本质上是串行的，因为它们需要全局归约和协调）：3.0。\n- 时间步自适应控制器决策（串行）：1.5。\n- 用于重启文件的检查点输入/输出（串行）：1.5。\n- 由于线程不安全的数据结构，预条件子设置和符号分解被限制在单个进程上（串行）：4.0。\n- 其他串行开销（初始化、参数解析和日志记录）：1.0。\n\n假设并行部分具有理想的负载均衡，除了已在列出的串行项中计入的通信成本外，没有额外的通信成本，并且问题规模固定（强扩展）。设 $T(1)$ 表示在单个处理单元上的总时间，$T_{\\mathrm{s}}$ 表示在上述假设下不能从并行化中受益的组件所花费的总时间，而 $T_{\\mathrm{p}}$ 表示可以完全并行化的组件所花费的时间。定义在 $N$ 个处理单元上的加速比为 $S(N) = T(1)/T(N)$。\n\n从 $S(N)$、$T_{\\mathrm{s}}$ 和 $T_{\\mathrm{p}}$ 的定义出发，并仅使用理想的强扩展模型 $T(N) = T_{\\mathrm{s}} + T_{\\mathrm{p}}/N$，推导出一个用并行分数 $P = T_{\\mathrm{p}}/T(1)$ 表示的 $S(N)$ 表达式，然后计算当 $N$ 无限增长时 $S(N)$ 的紧上界。将最终的界限表示为一个精确的有理数。此外，简要说明在给定模型下，当 $N$ 变得很大时，哪些列出的组件会主导运行时间。最终报告的答案必须是单个界限值（无量纲）。",
            "solution": "首先根据指定标准对问题进行验证。\n\n**步骤1：提取给定条件**\n- **模型：** 用于多孔电极电化学-热模型的全隐式牛顿-克雷洛夫方法。\n- **扩展类型：** 强扩展（固定问题规模）。\n- **环境：** 带MPI的分布式内存集群。\n- **计时数据（在1个处理单元上）：**\n  - 可并行化组件：\n    - 残差和雅可比矩阵组装：54.0。\n    - 局部线性代数核：30.0。\n  - 串行组件：\n    - 全局收敛性检查和线搜索：3.0。\n    - 时间步自适应控制器：1.5。\n    - 检查点输入/输出：1.5。\n    - 预条件子设置和符号分解：4.0。\n    - 其他串行开销：1.0。\n- **假设：**\n  - 可并行化部分具有理想的负载均衡。\n  - 除串行组件中已包含的成本外，无额外通信成本。\n  - 问题规模固定。\n- **定义：**\n  - $T(1)$: 在一个处理单元上的总时间。\n  - $T(N)$: 在 $N$ 个处理单元上的总时间。\n  - $T_{\\mathrm{s}}$: 串行组件的总时间。\n  - $T_{\\mathrm{p}}$: 可并行化组件的总时间。\n  - $S(N) = T(1)/T(N)$: 在 $N$ 个处理单元上的加速比。\n  - $P = T_{\\mathrm{p}}/T(1)$: 并行分数。\n  - **控制模型（阿姆达尔定律）：** $T(N) = T_{\\mathrm{s}} + T_{\\mathrm{p}}/N$。\n\n**步骤2：使用提取的给定条件进行验证**\n这个问题具有科学依据，它使用公认的阿姆达尔定律来为并行算法的性能建模，这是计算科学和工程领域的标准做法。电池仿真的背景是现实的，将计算任务分解为串行和可并行化组件对于此类代码是典型的。这个问题是适定的，提供了得出唯一、有意义解所需的所有数据和定义。它是客观的，没有歧义。因此，该问题被视为**有效的**。\n\n**求解推导**\n任务是推导加速比 $S(N)$ 的表达式并计算其上界。\n\n首先，我们根据为单个处理单元提供的数据计算串行和可并行化组件的总时间。\n\n可并行化组件的总时间 $T_{\\mathrm{p}}$ 是残差/雅可比矩阵组装和局部线性代数核的时间之和：\n$$T_{\\mathrm{p}} = 54.0 + 30.0 = 84.0$$\n\n串行组件的总时间 $T_{\\mathrm{s}}$ 是所有明确说明为串行的组件的时间之和：\n$$T_{\\mathrm{s}} = 3.0 + 1.5 + 1.5 + 4.0 + 1.0 = 11.0$$\n\n在单个处理单元上的总时间 $T(1)$ 是串行和可并行化部分之和：\n$$T(1) = T_{\\mathrm{p}} + T_{\\mathrm{s}} = 84.0 + 11.0 = 95.0$$\n\n在 $N$ 个处理单元上的加速比 $S(N)$ 定义为 $S(N) = T(1)/T(N)$。使用给定的理想强扩展模型 $T(N) = T_{\\mathrm{s}} + T_{\\mathrm{p}}/N$，我们可以将加速比写为：\n$$S(N) = \\frac{T(1)}{T_{\\mathrm{s}} + \\frac{T_{\\mathrm{p}}}{N}}$$\n\n为了用并行分数 $P = T_{\\mathrm{p}}/T(1)$ 来表示它，我们首先认识到串行分数是 $1-P$。\n$1 - P = 1 - \\frac{T_{\\mathrm{p}}}{T(1)} = \\frac{T(1) - T_{\\mathrm{p}}}{T(1)} = \\frac{T_{\\mathrm{s}}}{T(1)}$。\n根据这些定义，我们可以用 $T(1)$ 和 $P$ 来表示 $T_{\\mathrm{p}}$ 和 $T_{\\mathrm{s}}$：\n$$T_{\\mathrm{p}} = P \\cdot T(1)$$\n$$T_{\\mathrm{s}} = (1-P) \\cdot T(1)$$\n\n将这些代入 $S(N)$ 的表达式中：\n$$S(N) = \\frac{T(1)}{(1-P) \\cdot T(1) + \\frac{P \\cdot T(1)}{N}}$$\n分子和分母同时除以 $T(1)$，得到所需的用 $P$ 表示的 $S(N)$ 表达式：\n$$S(N) = \\frac{1}{(1-P) + \\frac{P}{N}}$$\n这是阿姆达尔定律的标准公式。\n\n为了找到当处理单元数量 $N$ 无限增长时 $S(N)$ 的紧上界，我们计算 $S(N)$ 当 $N \\to \\infty$ 时的极限：\n$$S_{\\max} = \\lim_{N \\to \\infty} S(N) = \\lim_{N \\to \\infty} \\frac{1}{(1-P) + \\frac{P}{N}}$$\n当 $N \\to \\infty$ 时，项 $P/N$ 趋近于 $0$。因此，极限为：\n$$S_{\\max} = \\frac{1}{1-P}$$\n\n这表明，理论上的最大加速比与代码的串行分数成反比。我们也可以直接用 $T_{\\mathrm{s}}$ 和 $T(1)$ 来表示：\n$$S_{\\max} = \\frac{1}{T_{\\mathrm{s}} / T(1)} = \\frac{T(1)}{T_{\\mathrm{s}}}$$\n\n使用计算出的 $T(1)$ 和 $T_{\\mathrm{s}}$ 的值：\n$$S_{\\max} = \\frac{95.0}{11.0} = \\frac{95}{11}$$\n\n当 $N$ 变得很大时，可并行化部分的时间 $T_{\\mathrm{p}}/N$ 减小并趋近于零。总实际运行时间 $T(N) = T_{\\mathrm{s}} + T_{\\mathrm{p}}/N$ 趋近于 $T_{\\mathrm{s}}$。因此，执行时间变得由串行组件主导，这些组件构成了性能瓶颈，无法通过增加更多处理单元来减少。在这个问题中，串行组件是全局收敛性检查、时间步自适应、I/O、预条件子设置以及其他杂项开销。对此串行瓶颈的最大单一贡献者是“由于线程不安全的数据结构，预条件子设置和符号分解被限制在单个进程上”，其时间为 4.0。",
            "answer": "$$\\boxed{\\frac{95}{11}}$$"
        },
        {
            "introduction": "理论模型（如Amdahl定律）为了简化问题，通常将所有并行开销归为一个“串行部分”。在实践中，这些开销来自不同的来源，如通信延迟、数据传输带宽和同步操作。本练习将带你进入一个更真实的性能建模场景，你将为多GPU系统上的电解质扩散求解器构建一个精细的性能模型，并计算其并行效率。通过这个过程，你将学会如何量化通信成本，并评估计算与通信重叠等优化技术带来的实际效益。",
            "id": "3936108",
            "problem": "考虑一个用于三维域的多图形处理单元（GPU）电解质扩散求解器，该求解器使用均匀显式有限体积法离散化，并采用 7 点模板处理菲克扩散。该域的维度为 $N_x = 2048$、$N_y = 2048$ 和 $N_z = 1024$，求解器前进 $N_t = 1000$ 个时间步。每个单元格更新执行 $f = 20$ 次浮点运算，并存储一个 8 字节的双精度标量。基准的单GPU实现在一个GPU上执行整个域的计算，其持续算术吞吐量为 $R = 5.0 \\times 10^{12}$ 次浮点运算每秒。\n\n一个多GPU实现采用 $G = 4$ 个GPU，并沿 $z$ 方向进行板状域分解。这些GPU通过NVIDIA NVLink高速互连（NVLink）以环形拓扑连接，其持续点对点带宽为 $B = 200 \\times 10^{9}$ 字节/秒，每条消息的启动延迟为 $L = 2.0 \\times 10^{-6}$ 秒。在每个时间步，每个内部GPU交换两个厚度为一个单元格的光晕面（一个与上面的邻居交换，一个与下面的邻居交换）。一个光晕面的大小为 $N_x \\times N_y$ 个单元格。每个面的打包和解包耗时固定为 $T_{\\mathrm{pack}} = 5.0 \\times 10^{-5}$ 秒，与消息大小无关。通信/计算重叠分数为 $f_{\\mathrm{ov}} = 0.6$，意味着总通信时间的 $f_{\\mathrm{ov}}$ 部分被计算完全重叠，而剩余部分没有被重叠，并增加到步长时间中。在每个时间步结束时，全局同步屏障的成本为 $T_{\\mathrm{sync}} = 2.0 \\times 10^{-5}$ 秒。\n\n假设每个GPU上具有完美的负载均衡和相同的持续算术吞吐量 $R$。为了确定多GPU实现中每个时间步的关键路径，使用内部GPU的计时（两端的GPU只与一个邻居通信，因此不是速率限制因素）。从第一性原理（运行时、加速比和强扩展的定义）出发，并使用给定的物理参数和互连特性，推导出多GPU实现相对于单GPU基准的强扩展效率。将最终效率表示为小数。将您的答案四舍五入到 $4$ 位有效数字。",
            "solution": "该问题被评估为有效，因为它在科学上基于高性能计算的原理，问题提出得当，提供了所有必要的参数，并使用客观、正式的语言进行了阐述。它提出了一个并行性能建模中的标准问题。\n\n目标是推导具有 $G$ 个GPU的多GPU实现相对于单GPU基准的强扩展效率 $E_G$。强扩展效率定义为：\n$$E_G = \\frac{S_G}{G}$$\n其中 $S_G$ 是在 $G$ 个GPU上的加速比，定义为单GPU执行时间 $T_1$ 与多GPU执行时间 $T_G$ 的比率：\n$$S_G = \\frac{T_1}{T_G}$$\n结合这些，效率为：\n$$E_G = \\frac{T_1}{G \\cdot T_G}$$\n由于两种情况下的时间步数 $N_t$ 相同，我们可以基于完成单个时间步所需的时间来分析性能。设 $T_{step,1}$ 为单GPU情况下每步的时间， $T_{step,G}$ 为多GPU情况下每步的时间。那么效率可以写成：\n$$E_G = \\frac{N_t \\cdot T_{step,1}}{G \\cdot (N_t \\cdot T_{step,G})} = \\frac{T_{step,1}}{G \\cdot T_{step,G}}$$\n\n首先，我们确定单GPU每步的时间 $T_{step,1}$。这纯粹是计算工作。\n域中的单元格总数为 $N_{cells} = N_x N_y N_z$。\n每个时间步的总浮点运算次数（FLOPs）为 $W_{step} = N_{cells} \\cdot f$。\n在具有持续吞吐量 $R$ 的单个GPU上执行这些操作所需的时间是：\n$$T_{step,1} = \\frac{W_{step}}{R} = \\frac{N_x N_y N_z f}{R}$$\n\n接下来，我们为多GPU情况下的每步时间 $T_{step,G}$ 建模。问题陈述我们应该使用内部GPU的计时，因为它代表了关键路径。一个内部GPU每步的时间是其计算时间与任何未重叠的通信和同步开销的总和。\n每步的时间由以下模型给出：\n$$T_{step,G} = T_{comp,G} + (1 - f_{\\mathrm{ov}}) T_{comm,G} + T_{\\mathrm{sync}}$$\n其中 $T_{comp,G}$ 是 $G$ 个GPU之一每步的计算时间，$T_{comm,G}$ 是该GPU每步的总通信时间，$f_{\\mathrm{ov}}$ 是与计算重叠的通信时间的分数，而 $T_{\\mathrm{sync}}$ 是最终同步屏障的成本。\n\n在完美的负载均衡下，计算工作负载均匀分布在 $G$ 个GPU之间。域沿 $z$ 方向分解，因此每个GPU处理一个大小为 $N_x \\times N_y \\times (N_z/G)$ 的子域。\n每个GPU的计算时间为：\n$$T_{comp,G} = \\frac{N_x N_y (N_z/G) f}{R} = \\frac{N_x N_y N_z f}{G R} = \\frac{T_{step,1}}{G}$$\n\n现在，我们为通信时间 $T_{comm,G}$ 建模。一个内部GPU在环形拓扑中与其两个邻居各交换一个光晕面。一个面的数据由 $N_x \\times N_y$ 个单元格组成，其中每个单元格是一个 $s=8$ 字节的双精度标量。\n单个消息（一个光晕面）的大小为：\n$$M = N_x \\times N_y \\times s$$\n传输一条消息的时间被建模为固定延迟 $L$ 和依赖于带宽的项 $M/B$ 的总和。此外，每次面交换还有打包/解包开销 $T_{\\mathrm{pack}}$。\n与一个邻居进行单次光晕交换的时间是 $L + M/B + T_{\\mathrm{pack}}$。\n由于一个内部GPU与两个邻居通信，因此每步的总通信时间为：\n$$T_{comm,G} = 2 \\left( L + \\frac{M}{B} + T_{\\mathrm{pack}} \\right) = 2 \\left( L + \\frac{N_x N_y s}{B} + T_{\\mathrm{pack}} \\right)$$\n\n将 $T_{step,1}$ 和 $T_{step,G}$ 的表达式代入效率公式：\n$$E_G = \\frac{T_{step,1}}{G \\cdot T_{step,G}} = \\frac{G \\cdot T_{comp,G}}{G \\cdot T_{step,G}} = \\frac{T_{comp,G}}{T_{step,G}}$$\n$$E_G = \\frac{T_{comp,G}}{T_{comp,G} + (1 - f_{\\mathrm{ov}})T_{comm,G} + T_{\\mathrm{sync}}}$$\n这个公式表示总时间中用于有效计算部分所占的比例。\n\n现在，我们代入给定的数值：\n- 域: $N_x = 2048$, $N_y = 2048$, $N_z = 1024$\n- 运算: $f = 20$\n- GPU: $G = 4$\n- 吞吐量: $R = 5.0 \\times 10^{12}$ FLOPS\n- 单元格大小: $s = 8$ 字节\n- 带宽: $B = 200 \\times 10^{9}$ 字节/秒\n- 延迟: $L = 2.0 \\times 10^{-6}$ s\n- 打包时间: $T_{\\mathrm{pack}} = 5.0 \\times 10^{-5}$ s\n- 重叠分数: $f_{\\mathrm{ov}} = 0.6$\n- 同步成本: $T_{\\mathrm{sync}} = 2.0 \\times 10^{-5}$ s\n\n计算 $T_{comp,G}$：\n$$T_{comp,G} = \\frac{2048 \\times 2048 \\times (1024/4) \\times 20}{5.0 \\times 10^{12}} = \\frac{2048 \\times 2048 \\times 256 \\times 20}{5.0 \\times 10^{12}}$$\n$$T_{comp,G} = \\frac{(2^{11}) \\times (2^{11}) \\times (2^8) \\times 20}{5.0 \\times 10^{12}} = \\frac{2^{30} \\times 20}{5.0 \\times 10^{12}} = \\frac{1073741824 \\times 20}{5.0 \\times 10^{12}}$$\n$$T_{comp,G} = \\frac{21474836480}{5.0 \\times 10^{12}} = 4.294967296 \\times 10^{-3} \\text{ s}$$\n\n计算 $T_{comm,G}$：\n消息大小 $M = 2048 \\times 2048 \\times 8 = 33554432$ 字节。\n$$T_{comm,G} = 2 \\left( 2.0 \\times 10^{-6} + \\frac{33554432}{200 \\times 10^{9}} + 5.0 \\times 10^{-5} \\right)$$\n$$T_{comm,G} = 2 \\left( 2.0 \\times 10^{-6} + 1.6777216 \\times 10^{-4} + 5.0 \\times 10^{-5} \\right)$$\n$$T_{comm,G} = 2 \\left( 0.02 \\times 10^{-4} + 1.6777216 \\times 10^{-4} + 0.5 \\times 10^{-4} \\right)$$\n$$T_{comm,G} = 2 \\left( 2.1977216 \\times 10^{-4} \\right) = 4.3954432 \\times 10^{-4} \\text{ s}$$\n\n计算添加到时间步的总开销时间 $T_{overhead}$：\n$$T_{overhead} = (1 - f_{\\mathrm{ov}})T_{comm,G} + T_{\\mathrm{sync}}$$\n$$T_{overhead} = (1 - 0.6) \\times (4.3954432 \\times 10^{-4}) + 2.0 \\times 10^{-5}$$\n$$T_{overhead} = 0.4 \\times 4.3954432 \\times 10^{-4} + 0.2 \\times 10^{-4}$$\n$$T_{overhead} = 1.75817728 \\times 10^{-4} + 0.2 \\times 10^{-4} = 1.95817728 \\times 10^{-4} \\text{ s}$$\n\n最后，计算效率 $E_G$：\n$$E_G = \\frac{T_{comp,G}}{T_{comp,G} + T_{overhead}}$$\n$$E_G = \\frac{4.294967296 \\times 10^{-3}}{4.294967296 \\times 10^{-3} + 1.95817728 \\times 10^{-4}}$$\n$$E_G = \\frac{42.94967296 \\times 10^{-4}}{42.94967296 \\times 10^{-4} + 1.95817728 \\times 10^{-4}}$$\n$$E_G = \\frac{42.94967296}{44.90785024} = 0.956396$$\n\n将结果四舍五入到 $4$ 位有效数字，我们得到：\n$$E_G \\approx 0.9564$$",
            "answer": "$$\\boxed{0.9564}$$"
        },
        {
            "introduction": "性能分析是第一步，而最终目标是通过先进的算法设计来提升性能。本练习将从分析转向实践，指导你实现一种称为“无矩阵”或“和因子分解”（sum-factorization）的高效算子应用方法，这是现代谱元法求解器的核心技术。通过编写代码实现该算法并量化其相对于传统稀疏矩阵方法的内存优势，你将掌握一种能显著降低内存占用并提升计算效率的强大并行计算策略。",
            "id": "3936147",
            "problem": "考虑电池电解质子域中的电解质浓度场 $c_e(\\boldsymbol{x},t)$，其中扩散算子涉及作用于 $c_e$ 的拉普拉斯算子 $\\Delta$。在一个映射到参考立方体 $[-1,1]^3$ 的单个六面体单元上，对于常数扩散系数等于 $1$ 的张量积谱元离散化，离散算子的应用可以通过构建一个全局稀疏矩阵，或者通过利用一维多项式结构的无矩阵求和分解策略来实现。\n\n从以下基础出发：\n- 拉普拉斯算子定义 $\\Delta u = \\nabla \\cdot \\nabla u = \\partial_{x}^2 u + \\partial_{y}^2 u + \\partial_{z}^2 u$。\n- 在切比雪夫–高斯–洛巴托 (Chebyshev–Gauss–Lobatto, CGL) 点上的节点多项式插值，其节点由每个维度中的 $x_k = \\cos\\left(\\dfrac{\\pi k}{p}\\right)$ 定义，其中 $k=0,1,\\dots,p$，多项式次数为 $p$，节点数为 $n = p+1$。\n- 重心拉格朗日插值框架，其中一维 CGL 网格上的微分矩阵由重心权重 $w_k$ 和节点差分导出，而张量积构造允许通过一维收缩序列来应用算子。\n\n您的任务是实现一个完整、可运行的程序，该程序：\n1. 对于每个空间坐标中给定的多项式次数 $p$，构造一维 CGL 节点 $x_k$ 以及相应的重心权重 $w_k$（$k=0,1,\\dots,p$），其中符号随 $(-1)^k$ 交替变化，且端点处的权重幅值与内部点不同。\n2. 构建由 CGL 节点上的重心微分所隐含的一维一阶导数矩阵 $D \\in \\mathbb{R}^{n \\times n}$，其中非对角线元素使用重心公式，对角线元素通过行和来保证一致性。\n3. 在三维张量网格上，通过沿每个坐标方向顺序应用 $D$ 以通过重复的一维收缩实现二阶导数 $\\partial_{x}^2 u$、$\\partial_{y}^2 u$ 和 $\\partial_{z}^2 u$ 并将其相加，从而实现拉普拉斯算子 $\\Delta$ 对节点场 $u$ 的无矩阵求和分解应用。\n4. 通过在测试函数 $u(x,y,z) = \\sin(\\pi x)\\sin(\\pi y)\\sin(\\pi z)$ 上评估离散算子，将节点上的结果与解析拉普拉斯算子 $\\Delta u = -3\\pi^2 \\sin(\\pi x)\\sin(\\pi y)\\sin(\\pi z)$ 进行比较，并为每个测试用例报告最大绝对节点误差（以浮点数形式），来验证无矩阵拉普拉斯算子应用的正确性。\n5. 与显式存储单个张量积单元的全局三维拉普拉斯算子的稀疏矩阵方法相比，量化使用无矩阵方法时的内存占用减少。假设稀疏矩阵以压缩稀疏行 (Compressed Sparse Row, CSR) 格式存储，使用 64 位浮点数表示值，使用 32 位整数表示列索引和行指针。对于稀疏方法，导出由密集一维二阶导数矩阵的克罗内克和 (Kronecker-sum) 组装的全局三维算子中的非零条目总数，并计算总内存（以字节为单位）作为值存储和索引存储之和。对于无矩阵方法，仅考虑存储一维一阶导数矩阵 $D$ 和一维重心权重 $w$（两者在所有三个轴上重复使用），并计算表示该算子以供应用所需的总内存（以字节为单位）。\n6. 为每个测试用例报告由 $(\\text{sparse\\_bytes} - \\text{matrixfree\\_bytes})/\\text{sparse\\_bytes}$ 定义的内存占用减少的小数分数。\n\n使用以下包含多项式次数 $p$ 的测试套件：\n- 用例 1：$p=1$（具有最小非平凡多项式次数的边界情况）。\n- 用例 2：$p=4$（中等多项式次数）。\n- 用例 3：$p=8$（强调张量收缩的更高多项式次数）。\n\n对于每个用例，您的程序必须计算并收集两个浮点数结果：\n- 内存减少的小数分数 $(\\text{sparse\\_bytes} - \\text{matrixfree\\_bytes})/\\text{sparse\\_bytes}$。\n- 拉普拉斯算子应用于 $u(x,y,z) = \\sin(\\pi x)\\sin(\\pi y)\\sin(\\pi z)$ 时的最大绝对节点误差。\n\n最终输出格式：\n- 您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表，按测试用例排序，并交替显示内存减少量和误差。具体来说，输出必须是以下形式：\n$[\\text{reduction}_{p=1},\\text{error}_{p=1},\\text{reduction}_{p=4},\\text{error}_{p=4},\\text{reduction}_{p=8},\\text{error}_{p=8}]$。\n\n所有浮点结果必须以标准十进制形式打印。不需要物理单位，并且根据 CGL 节点的构造，所有角度都以弧度为单位。",
            "solution": "该问题要求实现并验证一种在谱元环境下应用拉普拉斯算子的无矩阵求和分解方法，并将其内存占用与标准稀疏矩阵组装方法进行定量比较。\n\n解决方案分几步进行：首先，我们为切比雪夫–高斯–洛巴托 (CGL) 节点上的一维微分奠定理论基础。其次，我们使用张量积将其扩展到三维，并描述求和分解算法。第三，我们对无矩阵和稀疏矩阵方法的内存成本进行形式化分析。最后，我们描述使用已知解析解的验证过程。\n\n设每个维度的多项式次数为 $p$。一维中的节点数为 $n = p+1$。\n\n**1. CGL 网格上的一维谱微分**\n\n在参考区间 $[-1, 1]$ 上，谱元方法的基础是节点（nodal points）的选择。切比雪夫–高斯–洛巴托 (CGL) 节点是 $p$ 次切比雪夫多项式的极值点，由以下公式给出：\n$$ x_k = \\cos\\left(\\frac{\\pi k}{p}\\right), \\quad k = 0, 1, \\dots, p $$\n一个函数 $u(x)$ 可由一个唯一的 $p$ 次多项式来近似，该多项式在这些 $n$ 个节点上对函数进行插值。这个插值多项式可以用拉格朗日多项式表示，但对于数值微分，重心坐标公式（barycentric formulation）更稳定、更高效。\n\nCGL 节点的重心权重 $w_k$ 由下式给出：\n$$ w_k = (-1)^k \\delta_k, \\quad \\text{where} \\quad \\delta_k = \\begin{cases} 1/2  \\text{if } k=0 \\text{ or } k=p \\\\ 1  \\text{if } 0  k  p \\end{cases} $$\n在节点 $x_i$ 处计算的插值多项式的导数可以表示为矩阵-向量乘积 $(D\\boldsymbol{u})_i$，其中 $\\boldsymbol{u}$ 是节点值的向量 $[u(x_0), \\dots, u(x_p)]^T$，$D$ 是 $n \\times n$ 的一阶导数矩阵。$D$ 的元素使用 CGL 节点 $x_k$ 和重心权重 $w_k$ 计算：\n对于非对角线元素 ($i \\neq j$)：\n$$ D_{ij} = \\frac{w_j/w_i}{x_i - x_j} \\quad \\text{for } i \\neq j, \\quad i,j \\in \\{0, \\dots, p\\} $$\n对角线元素由常数函数（例如，$u(x)=1$）的导数必须为零的性质确定。这意味着 $D$ 的每一行之和必须为零：\n$$ \\sum_{j=0}^{p} D_{ij} = 0 \\implies D_{ii} = -\\sum_{j=0, j \\neq i}^{p} D_{ij} $$\n一维二阶导数算子矩阵 $D_2$ 简单地是一阶导数矩阵的平方：$D_2 = D^2$。\n\n**2. 使用求和分解的三维拉普拉斯算子**\n\n在三维空间中，参考单元是立方体 $[-1, 1]^3$。网格是一维 CGL 节点的张量积，形成一个包含 $n^3 = (p+1)^3$ 个点 $(x_i, y_j, z_k)$ 的网格。函数 $u(x,y,z)$ 由其在该网格上的节点值表示，存储在一个大小为 $n \\times n \\times n$ 的三维张量 $U$ 中，其中 $U_{ijk} = u(x_i, y_j, z_k)$。\n\n拉普拉斯算子为 $\\Delta u = \\partial_{x}^2 u + \\partial_{y}^2 u + \\partial_{z}^2 u$。无矩阵求和分解方法通过沿张量 $U$ 的每个轴应用一维二阶导数算子 $D_2$ 并将结果相加来计算离散拉普拉斯算子 $\\Delta_h U$ 的作用。\n\n设 $U_{xx}$、$U_{yy}$ 和 $U_{zz}$ 是表示二阶偏导数节点值的张量。它们的计算方式如下：\n- **x-导数：** 沿 x 轴（第一个索引）对 $U$ 的每一列应用 $D_2$。\n$$ (U_{xx})_{ijk} = \\sum_{l=0}^{p} (D_2)_{il} U_{ljk} $$\n- **y-导数：** 沿 y 轴（第二个索引）对 $U$ 的每一列应用 $D_2$。\n$$ (U_{yy})_{ijk} = \\sum_{l=0}^{p} (D_2)_{jl} U_{ilk} $$\n- **z-导数：** 沿 z 轴（第三个索引）对 $U$ 的每一列应用 $D_2$。\n$$ (U_{zz})_{ijk} = \\sum_{l=0}^{p} (D_2)_{kl} U_{ijl} $$\n离散拉普拉斯算子是这些张量的逐元素和：\n$$ \\Delta_h U = U_{xx} + U_{yy} + U_{zz} $$\n这种方法避免了构建庞大的 $n^3 \\times n^3$ 全局算子矩阵，而是依赖于一系列较小的矩阵运算（例如，矩阵-矩阵或矩阵-张量积），这在计算上和内存上都非常高效。\n\n**3. 内存占用分析**\n\n我们比较两种方法表示算子所需的内存。我们假设使用 64 位浮点数（8 字节）和 32 位整数（4 字节）。一维中的节点数为 $n=p+1$。\n\n- **无矩阵方法：** 算子由可复用的一维组件隐式定义。根据问题要求，我们存储 $n \\times n$ 的一阶导数矩阵 $D$ 和包含 $n$ 个元素的重心权重向量 $w$。\n    - $D$ 的内存：$n^2$ 个浮点数 $\\implies n^2 \\times 8$ 字节。\n    - $w$ 的内存：$n$ 个浮点数 $\\implies n \\times 8$ 字节。\n    - 无矩阵总内存：$\\text{matrixfree\\_bytes} = (n^2 + n) \\times 8$。\n\n- **稀疏矩阵方法：** 全局离散拉普拉斯算子 $L_{3D}$ 是一个 $N \\times N$ 矩阵，其中 $N=n^3$。其结构源于一维稠密算子的克罗内克和 (Kronecker sum)，$L_{3D} = D_2 \\otimes I_n \\otimes I_n + I_n \\otimes D_2 \\otimes I_n + I_n \\otimes I_n \\otimes D_2$。对于一个节点 $(x_i, y_j, z_k)$，该算子将其与穿过它且平行于坐标轴的直线上的所有其他节点相连接。在 3 个方向上，每个方向的此类连接数为 $(n-1)$，再加上节点本身。每个节点的总连接数为 $3(n-1) + 1 = 3n-2$。\n    - 行/列数：$N = n^3$。\n    - 每行的非零元素数：$3n-2$。\n    - 总非零元素数 (nnz)：$\\text{nnz} = N \\times (3n-2) = n^3 (3n-2)$。\n    - 矩阵以压缩稀疏行 (CSR) 格式存储：\n        - 值数组 (`data`)：$\\text{nnz}$ 个浮点数 $\\implies \\text{nnz} \\times 8$ 字节。\n        - 列索引数组 (`indices`)：$\\text{nnz}$ 个整数 $\\implies \\text{nnz} \\times 4$ 字节。\n        - 行指针数组 (`indptr`)：$N+1$ 个整数 $\\implies (N+1) \\times 4$ 字节。\n    - 稀疏矩阵总内存：\n      $\\text{sparse\\_bytes} = \\text{nnz} \\times (8+4) + (N+1) \\times 4 = 12 \\cdot n^3(3n-2) + 4(n^3+1)$。\n\n内存减少量计算为以下分数：\n$$ \\text{reduction} = \\frac{\\text{sparse\\_bytes} - \\text{matrixfree\\_bytes}}{\\text{sparse\\_bytes}} $$\n\n**4. 验证**\n\n为验证无矩阵实现的正确性，我们将离散拉普拉斯算子 $\\Delta_h$ 应用于一个具有已知解析拉普拉斯算子的测试函数。\n- 测试函数：$u(x,y,z) = \\sin(\\pi x)\\sin(\\pi y)\\sin(\\pi z)$\n- 解析拉普拉斯算子：$\\Delta u(x,y,z) = -3\\pi^2 \\sin(\\pi x)\\sin(\\pi y)\\sin(\\pi z)$\n\n步骤如下：\n1.  构造三维 CGL 网格 $(x_i, y_j, z_k)$。\n2.  在此网格上评估测试函数，得到节点张量 $U_{ijk}$。\n3.  使用求和分解应用离散拉普拉斯算子，得到 $\\Delta_h U$。\n4.  在同一网格上评估解析拉普拉斯算子 $\\Delta u$。\n5.  计算所有节点上的最大绝对误差：\n    $$ E = \\max_{i,j,k} | (\\Delta_h U)_{ijk} - \\Delta u(x_i, y_j, z_k) | $$\n较小的误差 $E$ 表明实现正确。对于 $p=1$，测试函数的节点值全为零，因此预期误差为 $0$。对于更高的 $p$，误差应减小，这表明了谱收敛性。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to run test cases and print results.\n    \"\"\"\n    \n    test_cases = [1, 4, 8]\n    results = []\n\n    def run_case(p):\n        \"\"\"\n        Runs the complete analysis for a given polynomial degree p.\n        Returns the memory reduction fraction and the max nodal error.\n        \"\"\"\n        n = p + 1\n\n        # 1. Construct CGL nodes and barycentric weights\n        if p == 0:  # Not in test cases, but for robustness\n            x = np.array([0.0])\n            w = np.array([1.0])\n        else:\n            k = np.arange(n)\n            x = np.cos(np.pi * k / p)\n            w = (-1.0)**k\n            w[0] *= 0.5\n            w[-1] *= 0.5\n            \n        # 2. Build the 1D first-derivative matrix D\n        D = np.zeros((n, n), dtype=np.float64)\n        for i in range(n):\n            row_sum = 0.0\n            for j in range(n):\n                if i != j:\n                    term = (w[j] / w[i]) / (x[i] - x[j])\n                    D[i, j] = term\n                    row_sum += term\n            D[i, i] = -row_sum\n\n        # 3. Implement matrix-free sum-factorization for the Laplacian\n        # Create the 3D grid and evaluate the test function\n        X, Y, Z = np.meshgrid(x, x, x, indexing='ij')\n        U = np.sin(np.pi * X) * np.sin(np.pi * Y) * np.sin(np.pi * Z)\n\n        # Pre-compute the 1D second-derivative matrix\n        D2 = D @ D\n\n        # Apply D2 along each axis using Einstein summation for clarity\n        # U_xx = D2 @ U (along axis 0)\n        U_xx = np.einsum('il,ljk-ijk', D2, U, optimize=True)\n        # U_yy = U @ D2.T (along axis 1)\n        U_yy = np.einsum('jl,ilk-ijk', D2, U, optimize=True)\n        # U_zz = U @ D2.T (along axis 2)\n        U_zz = np.einsum('kl,ijl-ijk', D2, U, optimize=True)\n        \n        # Sum the contributions to get the numerical Laplacian\n        lap_U_numeric = U_xx + U_yy + U_zz\n\n        # 4. Verify correctness and calculate the maximum nodal error\n        # Analytic Laplacian: Δu = -3π² sin(πx)sin(πy)sin(πz) = -3π² * u\n        lap_U_analytic = -3.0 * np.pi**2 * U\n        max_error = np.max(np.abs(lap_U_numeric - lap_U_analytic))\n\n        # 5. Quantify memory footprint reduction\n        bytes_float = 8  # 64-bit float\n        bytes_int = 4    # 32-bit integer\n\n        # Matrix-free memory: store D (n x n) and w (n)\n        matrixfree_bytes = (n**2 * bytes_float) + (n * bytes_float)\n\n        # Sparse matrix memory (CSR format)\n        N = n**3  # Total number of nodes in 3D\n        nnz = N * (3 * n - 2)\n        \n        # Memory = nnz*(float+int) for data/indices + (N+1)*int for indptr\n        sparse_bytes = nnz * (bytes_float + bytes_int) + (N + 1) * bytes_int\n        \n        # 6. Report memory reduction fraction\n        if sparse_bytes == 0:\n            reduction = 0.0 # Avoid division by zero\n        else:\n            reduction = (sparse_bytes - matrixfree_bytes) / sparse_bytes\n\n        return reduction, max_error\n\n    results_flat = []\n    for p_val in test_cases:\n        reduction_val, error_val = run_case(p_val)\n        results_flat.append(reduction_val)\n        results_flat.append(error_val)\n    \n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results_flat))}]\")\n\nsolve()\n```"
        }
    ]
}