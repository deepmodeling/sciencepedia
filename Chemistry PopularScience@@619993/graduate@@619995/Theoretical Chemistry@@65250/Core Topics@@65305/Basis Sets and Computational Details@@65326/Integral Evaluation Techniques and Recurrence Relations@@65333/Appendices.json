{"hands_on_practices": [{"introduction": "We begin with a cornerstone of computational quantum chemistry: the analytical evaluation of the overlap integral between two general Cartesian Gaussian-type orbitals (GTOs). This foundational exercise guides you through the essential steps of applying the Gaussian product theorem, separating the three-dimensional problem into one-dimensional moment integrals, and arriving at a general closed-form expression [@problem_id:2780117]. Mastering this derivation provides the blueprint for evaluating all other types of molecular integrals and is a crucial step in understanding the structure of quantum chemistry software.", "id": "2780117", "problem": "Two primitive Cartesian Gaussian-type orbitals (GTOs) are centered at nuclei located at positions $\\mathbf{A} = (A_{x},A_{y},A_{z})$ and $\\mathbf{B} = (B_{x},B_{y},B_{z})$ with positive exponents $\\alpha_{a}$ and $\\alpha_{b}$, and Cartesian angular momentum tuples $(i_{a},j_{a},k_{a})$ and $(i_{b},j_{b},k_{b})$, respectively. Let\n$$\n\\phi_{a}(\\mathbf{r}) \\;=\\; N_{a}\\,(x-A_{x})^{i_{a}}(y-A_{y})^{j_{a}}(z-A_{z})^{k_{a}}\\,\\exp\\!\\big(-\\alpha_{a}\\,|\\mathbf{r}-\\mathbf{A}|^{2}\\big),\n$$\n$$\n\\phi_{b}(\\mathbf{r}) \\;=\\; N_{b}\\,(x-B_{x})^{i_{b}}(y-B_{y})^{j_{b}}(z-B_{z})^{k_{b}}\\,\\exp\\!\\big(-\\alpha_{b}\\,|\\mathbf{r}-\\mathbf{B}|^{2}\\big),\n$$\nwhere $N_{a}$ and $N_{b}$ are real normalization constants (not necessarily equal and not necessarily unity). Using only fundamental, well-tested facts including the Gaussian product theorem, the separability of three-dimensional Cartesian integrals into products of one-dimensional integrals, and the Hermite Gaussian expansion, derive from first principles a fully explicit closed-form analytic expression for the overlap integral\n$$\nS_{ab} \\;=\\; \\int_{\\mathbb{R}^{3}} \\phi_{a}(\\mathbf{r})\\,\\phi_{b}(\\mathbf{r}) \\, d\\mathbf{r}.\n$$\nYour derivation must: (i) identify and define the composite exponent $p=\\alpha_{a}+\\alpha_{b}$, the Gaussian product center $\\mathbf{P}=\\big(P_{x},P_{y},P_{z}\\big)$ with $P_{q}=\\big(\\alpha_{a}A_{q}+\\alpha_{b}B_{q}\\big)/p$ for $q\\in\\{x,y,z\\}$, and the reduced exponent $\\mu=\\alpha_{a}\\alpha_{b}/p$; (ii) make clear how the Hermite expansion organizes the polynomial prefactors into derivatives with respect to $\\mathbf{P}$; and (iii) evaluate the necessary one-dimensional Gaussian moments to obtain a result expressed explicitly as products of finite sums with binomial coefficients and double factorials. Express your final closed-form result in terms of $\\alpha_{a}$, $\\alpha_{b}$, $\\mathbf{A}$, $\\mathbf{B}$, $N_{a}$, $N_{b}$, and the angular momentum integers. No numerical evaluation is required. Present the final answer as a single closed-form analytic expression. Do not provide intermediate identities as your final answer, and do not include any units.", "solution": "The problem as stated is a well-defined and fundamental task in theoretical quantum chemistry. It requests the derivation of the analytic expression for the overlap integral between two general Cartesian Gaussian-type orbitals (GTOs). The problem is scientifically grounded, self-contained, and objective. All provided definitions are standard in the field. Therefore, the problem is valid and I shall proceed with the derivation.\n\nThe overlap integral $S_{ab}$ is given by:\n$$S_{ab} \\;=\\; \\int_{\\mathbb{R}^{3}} \\phi_{a}(\\mathbf{r})\\,\\phi_{b}(\\mathbf{r}) \\, d\\mathbf{r}$$\nSubstituting the definitions for the GTOs $\\phi_a$ and $\\phi_b$:\n$$S_{ab} = N_{a}N_{b}\\int_{\\mathbb{R}^{3}} (x-A_{x})^{i_{a}}(y-A_{y})^{j_{a}}(z-A_{z})^{k_{a}} (x-B_{x})^{i_{b}}(y-B_{y})^{j_{b}}(z-B_{z})^{k_{b}} \\exp(-\\alpha_{a}|\\mathbf{r}-\\mathbf{A}|^2 - \\alpha_{b}|\\mathbf{r}-\\mathbf{B}|^2) \\, d^3\\mathbf{r}$$\nThe derivation proceeds in three main steps: application of the Gaussian product theorem, separation of the integral, and evaluation of the resulting one-dimensional integrals.\n\n**Step 1: Gaussian Product Theorem**\n\nThe product of the two Gaussian exponential functions is a single Gaussian function. We analyze the exponent:\n$$-\\alpha_{a}|\\mathbf{r}-\\mathbf{A}|^2 - \\alpha_{b}|\\mathbf{r}-\\mathbf{B}|^2 = -\\alpha_{a}(\\mathbf{r}\\cdot\\mathbf{r} - 2\\mathbf{r}\\cdot\\mathbf{A} + \\mathbf{A}\\cdot\\mathbf{A}) - \\alpha_{b}(\\mathbf{r}\\cdot\\mathbf{r} - 2\\mathbf{r}\\cdot\\mathbf{B} + \\mathbf{B}\\cdot\\mathbf{B})$$\n$$= -(\\alpha_a+\\alpha_b)r^2 + 2(\\alpha_a\\mathbf{A}+\\alpha_b\\mathbf{B})\\cdot\\mathbf{r} - (\\alpha_a A^2 + \\alpha_b B^2)$$\nWe define the composite exponent $p = \\alpha_{a}+\\alpha_{b}$ and the center of the product Gaussian $\\mathbf{P} = \\frac{\\alpha_a\\mathbf{A}+\\alpha_b\\mathbf{B}}{p}$. The exponent can be rewritten by completing the square with respect to $\\mathbf{r}$:\n$$-p|\\mathbf{r}-\\mathbf{P}|^2 = -p(r^2 - 2\\mathbf{r}\\cdot\\mathbf{P} + P^2) = -pr^2 + 2p\\mathbf{P}\\cdot\\mathbf{r} - pP^2$$\nSubstituting this into our expression for the exponent, we obtain:\n$$-p|\\mathbf{r}-\\mathbf{P}|^2 + pP^2 - (\\alpha_a A^2 + \\alpha_b B^2)$$\nThe constant term simplifies to:\n$$p P^2 - (\\alpha_a A^2 + \\alpha_b B^2) = \\frac{(\\alpha_a\\mathbf{A}+\\alpha_b\\mathbf{B})^2}{p} - (\\alpha_a A^2 + \\alpha_b B^2) = -\\frac{\\alpha_a\\alpha_b}{p}|\\mathbf{A}-\\mathbf{B}|^2$$\nWith the reduced exponent $\\mu = \\frac{\\alpha_a\\alpha_b}{p}$, the product of the two exponentials is:\n$$\\exp(-\\alpha_a|\\mathbf{r}-\\mathbf{A}|^2)\\exp(-\\alpha_b|\\mathbf{r}-\\mathbf{B}|^2) = \\exp(-\\mu |\\mathbf{A}-\\mathbf{B}|^2) \\exp(-p|\\mathbf{r}-\\mathbf{P}|^2)$$\nLet $K_{AB} = \\exp(-\\mu|\\mathbf{A}-\\mathbf{B}|^2)$. The integral becomes:\n$$S_{ab} = N_a N_b K_{AB} \\int \\left(\\prod_{q=x,y,z} (q-A_{q})^{\\ell_{a}^{(q)}} (q-B_{q})^{\\ell_{b}^{(q)}}\\right) \\exp(-p|\\mathbf{r}-\\mathbf{P}|^2) \\, d^3\\mathbf{r}$$\nwhere $\\ell_a^{(x)}=i_a, \\ell_a^{(y)}=j_a, \\ell_a^{(z)}=k_a$ and similarly for $b$.\n\n**Step 2: Separation of Variables**\n\nThe three-dimensional integral is separable into a product of three one-dimensional integrals:\n$$S_{ab} = N_a N_b K_{AB} \\cdot I_x \\cdot I_y \\cdot I_z$$\nwhere the one-dimensional integral for the $x$-coordinate is:\n$$I_x = \\int_{-\\infty}^{\\infty} (x-A_{x})^{i_{a}} (x-B_{x})^{i_{b}} \\exp(-p(x-P_x)^2) \\, dx$$\nwith analogous expressions for $I_y$ and $I_z$. We will solve for $I_x$; the solutions for $I_y$ and $I_z$ follow by simple substitution of variables and indices.\n\n**Step 3: Evaluation of the One-Dimensional Integrals**\n\nWe expand the polynomial prefactor by first expressing it relative to the new center $P_x$. Let $u = x-P_x$. Then $x-A_x = u + (P_x-A_x)$ and $x-B_x = u + (P_x-B_x)$. The integrand's polynomial part becomes:\n$$(u + (P_x-A_x))^{i_a} (u + (P_x-B_x))^{i_b}$$\nUsing the binomial theorem, this is expanded as:\n$$\\left(\\sum_{l=0}^{i_a} \\binom{i_a}{l} (P_x-A_x)^{i_a-l} u^l\\right) \\left(\\sum_{m=0}^{i_b} \\binom{i_b}{m} (P_x-B_x)^{i_b-m} u^m\\right)$$\n$$= \\sum_{l=0}^{i_a} \\sum_{m=0}^{i_b} \\binom{i_a}{l} \\binom{i_b}{m} (P_x-A_x)^{i_a-l} (P_x-B_x)^{i_b-m} u^{l+m}$$\nThe integral $I_x$ is then a sum of terms involving Gaussian moments:\n$$I_x = \\sum_{l=0}^{i_a} \\sum_{m=0}^{i_b} \\binom{i_a}{l} \\binom{i_b}{m} (P_x-A_x)^{i_a-l} (P_x-B_x)^{i_b-m} \\int_{-\\infty}^{\\infty} u^{l+m} \\exp(-pu^2) \\, du$$\nLet $M_k = \\int_{-\\infty}^{\\infty} u^k \\exp(-pu^2) \\, du$. Due to the symmetry of the integration interval, $M_k = 0$ if $k$ is an odd integer.\nFor even $k=2n$, we can derive the value using a recurrence relation as suggested by the 'Hermite expansion' context. Note that for any function $f(u)$, $\\frac{d}{du} f(u) = -\\frac{d}{dP_x} f(u)$ where $u=x-P_x$. We have $u \\exp(-pu^2) = -\\frac{1}{2p}\\frac{d}{du}\\exp(-pu^2)$.\nUsing integration by parts for $M_{2n} = \\int u^{2n-1} (u \\exp(-pu^2)) du$:\n$$M_{2n} = \\left[u^{2n-1} \\left(-\\frac{1}{2p}\\exp(-pu^2)\\right)\\right]_{-\\infty}^{\\infty} - \\int \\left(-\\frac{1}{2p}\\exp(-pu^2)\\right) (2n-1)u^{2n-2} du = \\frac{2n-1}{2p} M_{2n-2}$$\nThe base case is $M_0 = \\int_{-\\infty}^{\\infty} \\exp(-pu^2) \\, du = \\sqrt{\\frac{\\pi}{p}}$.\nBy repeated application of the recurrence, we find:\n$$M_{2n} = \\frac{(2n-1)!!}{(2p)^n} M_0 = \\frac{(2n-1)!!}{(2p)^n} \\sqrt{\\frac{\\pi}{p}}$$\nwhere $(2n-1)!! = (2n-1)(2n-3)\\cdots1$ is the double factorial, and we define $(-1)!!=1$.\n\nSubstituting this result for the moments into the expression for $I_x$, we sum only over terms where $k=l+m$ is even:\n$$I_x = \\sqrt{\\frac{\\pi}{p}} \\sum_{l=0}^{i_a} \\sum_{m=0}^{i_b} \\delta_{l+m, \\text{even}} \\binom{i_a}{l} \\binom{i_b}{m} (P_x-A_x)^{i_a-l} (P_x-B_x)^{i_b-m} \\frac{(l+m-1)!!}{(2p)^{(l+m)/2}}$$\nwhere $\\delta_{l+m, \\text{even}}$ is $1$ if $l+m$ is even and $0$ otherwise.\n\nThe factors involving $P_x$ can be expressed in terms of $A_x, B_x$:\n$$P_x - A_x = \\frac{\\alpha_a A_x + \\alpha_b B_x}{p} - A_x = \\frac{\\alpha_b(B_x-A_x)}{p}$$\n$$P_x - B_x = \\frac{\\alpha_a A_x + \\alpha_b B_x}{p} - B_x = \\frac{\\alpha_a(A_x-B_x)}{p}$$\nSubstituting these yields a more fundamental form for the summation terms. Let us define a component sum $E_q$ for each coordinate $q \\in \\{x,y,z\\}$. For $x$:\n$$E_x(i_a, i_b) = \\sum_{l=0}^{i_a} \\sum_{m=0}^{i_b} \\delta_{l+m, \\text{even}} \\binom{i_a}{l}\\binom{i_b}{m} \\left(\\frac{\\alpha_b(B_x-A_x)}{p}\\right)^{i_a-l} \\left(\\frac{\\alpha_a(A_x-B_x)}{p}\\right)^{i_b-m} \\frac{(l+m-1)!!}{(2p)^{(l+m)/2}}$$\nThen $I_x = \\sqrt{\\pi/p} \\cdot E_x(i_a, i_b)$. Analogous expressions hold for $I_y, I_z$.\nThe total overlap integral is:\n$$S_{ab} = N_a N_b K_{AB} (\\pi/p)^{3/2} E_x(i_a, i_b) E_y(j_a, j_b) E_z(k_a, k_b)$$\nThis is the final closed-form expression. We now write it out in full for the final answer.", "answer": "$$\n\\boxed{\n\\begin{aligned}\nS_{ab} = \\; & N_a N_b \\exp\\left(-\\frac{\\alpha_a \\alpha_b}{\\alpha_a+\\alpha_b}|\\mathbf{A}-\\mathbf{B}|^2\\right) \\left(\\frac{\\pi}{\\alpha_a+\\alpha_b}\\right)^{3/2} \\\\\n& \\times \\left[ \\sum_{l_x=0}^{i_a} \\sum_{m_x=0}^{i_b} \\delta_{l_x+m_x, \\text{even}} \\binom{i_a}{l_x} \\binom{i_b}{m_x} (P_x-A_x)^{i_a-l_x} (P_x-B_x)^{i_b-m_x} \\frac{(l_x+m_x-1)!!}{(2(\\alpha_a+\\alpha_b))^{(l_x+m_x)/2}} \\right] \\\\\n& \\times \\left[ \\sum_{l_y=0}^{j_a} \\sum_{m_y=0}^{j_b} \\delta_{l_y+m_y, \\text{even}} \\binom{j_a}{l_y} \\binom{j_b}{m_y} (P_y-A_y)^{j_a-l_y} (P_y-B_y)^{j_b-m_y} \\frac{(l_y+m_y-1)!!}{(2(\\alpha_a+\\alpha_b))^{(l_y+m_y)/2}} \\right] \\\\\n& \\times \\left[ \\sum_{l_z=0}^{k_a} \\sum_{m_z=0}^{k_b} \\delta_{l_z+m_z, \\text{even}} \\binom{k_a}{l_z} \\binom{k_b}{m_z} (P_z-A_z)^{k_a-l_z} (P_z-B_z)^{k_b-m_z} \\frac{(l_z+m_z-1)!!}{(2(\\alpha_a+\\alpha_b))^{(l_z+m_z)/2}} \\right]\n\\end{aligned}\n}\n$$"}, {"introduction": "While overlap integrals are fully analytic, the far more challenging two-electron repulsion integrals reduce to a class of special functions known as Boys functions, $F_{n}(T)$. This exercise shifts our focus from the initial spatial integration to the robust and efficient evaluation of these functions [@problem_id:2780098]. You will derive the power series representation useful for small arguments $T$, establish rigorous error bounds for its truncation, and uncover the crucial three-term recurrence relation that enables the stable and efficient calculation of a whole ladder of Boys functions.", "id": "2780098", "problem": "In electronic structure theory, electron-repulsion integrals over Gaussian-type orbitals can be reduced to the evaluation of the Boys function, which for nonnegative integer $n$ is defined by the convergent integral\n$$\nF_{n}(T) \\equiv \\int_{0}^{1} x^{2n} \\exp\\!\\big(-T x^{2}\\big)\\, dx, \\quad T \\ge 0.\n$$\nStarting from this integral definition and using only foundational tools from real analysis and calculus (such as the series definition of the exponential function and integration by parts), do the following:\n\n1. By expanding the exponential function in a Maclaurin series and justifying term-by-term integration on the interval $[0,1]$, derive a small-$T$ power series of the form\n$$\nF_{n}(T) = \\sum_{k=0}^{\\infty} \\frac{(-T)^{k}}{k! \\big(2n + 2k + 1\\big)}.\n$$\n2. Denote by $S_{N}(T)$ the $(N+1)$-term truncation of this series,\n$$\nS_{N}(T) \\equiv \\sum_{k=0}^{N} \\frac{(-T)^{k}}{k! \\big(2n + 2k + 1\\big)},\n$$\nand define the remainder $R_{N}(T) \\equiv F_{n}(T) - S_{N}(T)$. Establish two rigorous upper bounds for $|R_{N}(T)|$:\n   - A general-purpose bound valid for all $T \\ge 0$ and fixed $n \\in \\mathbb{N}_{0}$ of the form\n   $$\n   |R_{N}(T)| \\le \\frac{C(T)}{2n + 2N + 3}\\, \\frac{T^{N+1}}{(N+1)!},\n   $$\n   where $C(T)$ is an explicit function you must determine.\n   - An alternating-series bound specialized to $0 < T \\le 1$ that exploits monotone decrease of term magnitudes.\n3. Starting from the integral definition of $F_{n}(T)$, derive a three-term linear recurrence relation connecting $F_{n+1}(T)$, $F_{n}(T)$, and $\\exp(-T)$, without introducing any special functions beyond the exponential. State the recurrence explicitly and indicate its direction of numerical stability for small $T$.\n4. For the concrete case $T = 0.8$ and $n = 2$, determine the smallest nonnegative integer $N$ such that the absolute truncation error incurred by $S_{N}(T)$ satisfies\n$$\n|R_{N}(T)| < 1.0 \\times 10^{-10}.\n$$\nUse the alternating-series error control justified in part 2 for $0 < T \\le 1$. Give the smallest such $N$ as your final answer. The final answer must be a single integer; no rounding instructions are needed.", "solution": "We begin from the integral definition\n$$\nF_{n}(T) \\equiv \\int_{0}^{1} x^{2n} \\exp\\!\\big(-T x^{2}\\big)\\, dx,\n$$\nwith $n \\in \\mathbb{N}_{0}$ and $T \\ge 0$.\n\n1. Series derivation for small $T$. The exponential function has the Maclaurin series\n$$\n\\exp\\!\\big(-T x^{2}\\big) = \\sum_{k=0}^{\\infty} \\frac{(-T x^{2})^{k}}{k!} = \\sum_{k=0}^{\\infty} \\frac{(-T)^{k}}{k!} x^{2k},\n$$\nwhich is absolutely and uniformly convergent on $x \\in [0,1]$ for any fixed $T \\ge 0$ by the Weierstrass $M$-test, since\n$$\n\\left|\\frac{(-T)^{k}}{k!} x^{2k}\\right| \\le \\frac{T^{k}}{k!} \\quad \\text{and} \\quad \\sum_{k=0}^{\\infty} \\frac{T^{k}}{k!} = \\exp(T) < \\infty.\n$$\nTherefore, we may integrate term-by-term:\n$$\nF_{n}(T)\n= \\int_{0}^{1} x^{2n} \\left(\\sum_{k=0}^{\\infty} \\frac{(-T)^{k}}{k!} x^{2k}\\right)\\, dx\n= \\sum_{k=0}^{\\infty} \\frac{(-T)^{k}}{k!} \\int_{0}^{1} x^{2n+2k}\\, dx\n= \\sum_{k=0}^{\\infty} \\frac{(-T)^{k}}{k!} \\frac{1}{2n + 2k + 1}.\n$$\nHence,\n$$\nF_{n}(T) = \\sum_{k=0}^{\\infty} \\frac{(-T)^{k}}{k!\\big(2n + 2k + 1\\big)}.\n$$\n\n2. Truncation error bounds. Define\n$$\nS_{N}(T) \\equiv \\sum_{k=0}^{N} \\frac{(-T)^{k}}{k!\\big(2n + 2k + 1\\big)}, \n\\quad\nR_{N}(T) \\equiv F_{n}(T) - S_{N}(T) = \\sum_{k=N+1}^{\\infty} \\frac{(-T)^{k}}{k!\\big(2n + 2k + 1\\big)}.\n$$\n- General-purpose bound for all $T \\ge 0$. For $k \\ge N+1$ we have $2n + 2k + 1 \\ge 2n + 2(N+1) + 1 = 2n + 2N + 3$, so\n$$\n|R_{N}(T)| \\le \\sum_{k=N+1}^{\\infty} \\frac{T^{k}}{k!\\big(2n + 2k + 1\\big)}\n\\le \\frac{1}{2n + 2N + 3} \\sum_{k=N+1}^{\\infty} \\frac{T^{k}}{k!}.\n$$\nUsing the Lagrange form of the remainder for the exponential series gives\n$$\n\\sum_{k=N+1}^{\\infty} \\frac{T^{k}}{k!} \\le \\exp(T)\\,\\frac{T^{N+1}}{(N+1)!}.\n$$\nTherefore an explicit bound valid for all $T \\ge 0$ is\n$$\n|R_{N}(T)| \\le \\frac{\\exp(T)}{2n + 2N + 3}\\,\\frac{T^{N+1}}{(N+1)!}.\n$$\nThus the required identification is $C(T) = \\exp(T)$.\n\n- Alternating-series bound for $0 < T \\le 1$. For $T > 0$ the series terms alternate in sign. Let\n$$\na_{k} \\equiv \\frac{T^{k}}{k!\\big(2n + 2k + 1\\big)}, \\quad k \\ge 0.\n$$\nWe show that $\\{a_{k}\\}_{k \\ge 0}$ is strictly decreasing for $0 < T \\le 1$:\n$$\n\\frac{a_{k+1}}{a_{k}} = \\frac{T}{k+1} \\cdot \\frac{2n + 2k + 1}{2n + 2k + 3} < \\frac{T}{k+1} \\le T \\le 1,\n$$\nso $a_{k+1} < a_{k}$ holds for all $k \\ge 0$ when $0 < T \\le 1$. By the Leibniz criterion (alternating series test), the remainder after truncation at $N$ satisfies\n$$\n|R_{N}(T)| \\le a_{N+1} = \\frac{T^{N+1}}{(N+1)!\\big(2n + 2(N+1) + 1\\big)} = \\frac{T^{N+1}}{(N+1)!\\big(2n + 2N + 3\\big)}.\n$$\n\n3. Three-term recurrence by integration by parts. Starting from\n$$\nF_{n+1}(T) = \\int_{0}^{1} x^{2n+2} \\exp\\!\\big(-T x^{2}\\big)\\, dx,\n$$\nconsider\n$$\n2T F_{n+1}(T) = \\int_{0}^{1} \\big(2T x\\big) x^{2n+1} \\exp\\!\\big(-T x^{2}\\big)\\, dx.\n$$\nSet $u = x^{2n+1}$ and $dv = 2T x \\exp(-T x^{2})\\, dx$, so $du = (2n+1) x^{2n}\\, dx$ and $v = -\\exp(-T x^{2})$. Integration by parts yields\n$$\n2T F_{n+1}(T) = \\big[ - x^{2n+1} \\exp(-T x^{2}) \\big]_{0}^{1} + (2n+1) \\int_{0}^{1} x^{2n} \\exp(-T x^{2})\\, dx.\n$$\nThe boundary term evaluates to $- \\exp(-T)$ at $x=1$ and $0$ at $x=0$, so\n$$\n2T F_{n+1}(T) = - \\exp(-T) + (2n+1) F_{n}(T).\n$$\nEquivalently,\n$$\n2T F_{n+1}(T) = (2n+1) F_{n}(T) - \\exp(-T).\n$$\nFor small $T$ this recurrence is stable in the downward direction (from larger $n$ to smaller $n$), whereas the upward direction can suffer loss of significance due to the subtraction of $\\exp(-T)$ when $T$ is small.\n\nAdditionally, differentiating under the integral sign shows\n$$\n\\frac{d}{dT} F_{n}(T) = - \\int_{0}^{1} x^{2n+2} \\exp(-T x^{2})\\, dx = - F_{n+1}(T),\n$$\nwhich is compatible with the recurrence.\n\n4. Minimal $N$ for $T = 0.8$ and $n = 2$ to achieve $|R_{N}(T)| < 1.0 \\times 10^{-10}$. Since $0 < T \\le 1$, we may use the alternating-series next-term bound:\n$$\n|R_{N}(T)| \\le a_{N+1} = \\frac{T^{N+1}}{(N+1)!\\big(2n + 2N + 3\\big)}.\n$$\nHere $T = 0.8$ and $n = 2$, so\n$$\na_{N+1} = \\frac{(0.8)^{N+1}}{(N+1)!\\,\\big(2\\cdot 2 + 2N + 3\\big)} = \\frac{(0.8)^{N+1}}{(N+1)!\\,\\big(2N + 7\\big)}.\n$$\nWe seek the smallest $N \\in \\mathbb{N}_{0}$ such that $a_{N+1} < 1.0 \\times 10^{-10}$. Evaluate $a_{k}$ sequentially (monotone decrease ensures once below threshold it stays below):\n- $k = 1$: $a_{1} = \\dfrac{0.8}{7} \\approx 1.142857142857143 \\times 10^{-1}$.\n- $k = 2$: $a_{2} = \\dfrac{0.8^{2}}{2!\\cdot 9} = \\dfrac{0.64}{18} \\approx 3.555555555555556 \\times 10^{-2}$.\n- $k = 3$: $a_{3} = \\dfrac{0.8^{3}}{3!\\cdot 11} = \\dfrac{0.512}{66} \\approx 7.757575757575758 \\times 10^{-3}$.\n- $k = 4$: $a_{4} = \\dfrac{0.8^{4}}{4!\\cdot 13} = \\dfrac{0.4096}{312} \\approx 1.312820512820513 \\times 10^{-3}$.\n- $k = 5$: $a_{5} = \\dfrac{0.8^{5}}{5!\\cdot 15} = \\dfrac{0.32768}{1800} \\approx 1.820444444444444 \\times 10^{-4}$.\n- $k = 6$: $a_{6} = \\dfrac{0.8^{6}}{6!\\cdot 17} = \\dfrac{0.262144}{12240} \\approx 2.142483660130719 \\times 10^{-5}$.\n- $k = 7$: $a_{7} = \\dfrac{0.8^{7}}{7!\\cdot 19} = \\dfrac{0.2097152}{95760} \\approx 2.189021506105006 \\times 10^{-6}$.\n- $k = 8$: $a_{8} = \\dfrac{0.8^{8}}{8!\\cdot 21} = \\dfrac{0.16777216}{846720} \\approx 1.983272279840681 \\times 10^{-7}$.\n- $k = 9$: $a_{9} = \\dfrac{0.8^{9}}{9!\\cdot 23} = \\dfrac{0.134217728}{8346240} \\approx 1.608221429316317 \\times 10^{-8}$.\n- $k = 10$: $a_{10} = \\dfrac{0.8^{10}}{10!\\cdot 25} = \\dfrac{0.1073741824}{90720000} \\approx 1.184094767932489 \\times 10^{-9}$.\n- $k = 11$: $a_{11} = \\dfrac{0.8^{11}}{11!\\cdot 27} = \\dfrac{0.08589934592}{1077753600} \\approx 7.964090027311383 \\times 10^{-11}$.\n\nThe first index with $a_{k} < 1.0 \\times 10^{-10}$ is $k = 11$. Since $a_{N+1} = a_{k}$ with $k = N+1$, the smallest $N$ satisfying the required bound is $N = 10$.\n\nTherefore, using the alternating-series bound for $0 < T \\le 1$, the minimal truncation order is $N = 10$.", "answer": "$$\\boxed{10}$$"}, {"introduction": "For larger arguments of the Boys function, series expansions become inefficient, necessitating more advanced numerical strategies. This practice introduces an elegant and powerful alternative used in modern quantum chemistry programs: the Rys quadrature [@problem_id:2780078]. You will implement the core logic of this method, constructing a custom Gaussian quadrature from its fundamental moments and exploring the deep connection between orthogonal polynomials, the Golub-Welsch algorithm, and the highly accurate evaluation of molecular integrals.", "id": "2780078", "problem": "Implement a complete program that demonstrates a two-root Rys quadrature evaluation for a representative electron repulsion integral of the type $\\left(d\\, s \\mid p\\, s\\right)$ between four primitive Cartesian Gaussian functions. The goal is to compute the Rys nodes and weights associated with the Boys-function parameter and to demonstrate the exact contraction of polynomial factors up to cubic degree using these nodes and weights. The demonstration must be framed purely in mathematical terms and must be self-contained.\n\nConsider four primitive Cartesian Gaussian functions centered at points $\\mathbf{A}$, $\\mathbf{B}$, $\\mathbf{C}$, and $\\mathbf{D}$ in three-dimensional space, with orbital angular momenta $\\ell = 2$ (a single Cartesian $d$-type function), $\\ell = 0$ (an $s$-type function), $\\ell = 1$ (a single Cartesian $p$-type function), and $\\ell = 0$ (an $s$-type function), respectively. For definiteness, take the $d$-type and $p$-type to be the Cartesian components with all angular momentum along the $x$-axis, i.e., $d_{xx}$ and $p_x$, and take the $s$-type functions to be isotropic. Let the Gaussian exponents be $\\alpha_a$, $\\alpha_b$, $\\alpha_c$, and $\\alpha_d$ for the functions on $\\mathbf{A}$, $\\mathbf{B}$, $\\mathbf{C}$, and $\\mathbf{D}$, respectively.\n\nUse the Gaussian product theorem to define the composite exponents and centers for the bra and ket pairs:\n- $p = \\alpha_a + \\alpha_b$, $q = \\alpha_c + \\alpha_d$,\n- $\\mathbf{P} = \\dfrac{\\alpha_a \\mathbf{A} + \\alpha_b \\mathbf{B}}{p}$, $\\mathbf{Q} = \\dfrac{\\alpha_c \\mathbf{C} + \\alpha_d \\mathbf{D}}{q}$.\n\nDefine the standard Boys-function parameter\n$$\n\\rho = \\dfrac{p\\, q}{p+q}, \\quad T = \\rho \\, \\lVert \\mathbf{P} - \\mathbf{Q} \\rVert^2.\n$$\nFor the $\\left(d\\, s \\mid p\\, s\\right)$ case with all angular momentum along the $x$-axis, the total Cartesian angular momentum along $x$ is $L_x = 3$, while along $y$ and $z$ it is $L_y = 0$ and $L_z = 0$. In a Rys-quadrature formulation this implies a two-root quadrature ($n = 2$) in the auxiliary variable $u \\in [0,1]$ against the weight function $\\exp(-T u^2)$, because the polynomial factors in $u$ do not exceed degree $3$.\n\nYour task is to:\n1. For each specified parameter set, compute $p$, $q$, $\\mathbf{P}$, $\\mathbf{Q}$, $\\rho$, and $T$.\n2. Compute the first four weighted moments of the form\n$$\nM_k(T) = \\int_0^1 u^k \\, e^{-T u^2} \\, du = \\dfrac{1}{2} \\int_0^1 s^{\\frac{k-1}{2}} e^{-T s} \\, ds = \\dfrac{1}{2} \\, \\dfrac{\\gamma\\!\\left(\\dfrac{k+1}{2},\\, T\\right)}{T^{\\frac{k+1}{2}}}\n$$\nfor $k \\in \\{0,1,2,3\\}$, where $\\gamma(a,x)$ denotes the lower incomplete gamma function.\n3. Construct the two-node Gaussian quadrature on $[0,1]$ with weight $\\exp(-T u^2)$ by using the Stieltjes procedure to obtain the first two recurrence coefficients of the monic orthogonal polynomials with respect to the inner product $\\langle f,g\\rangle = \\int_0^1 f(u) g(u) e^{-T u^2} \\, du$:\n   - Define $\\mu_k = M_k(T)$ for $k \\in \\{0,1,2,3\\}$, set the monic polynomials $\\pi_0(u) = 1$ and $\\pi_1(u) = u - \\alpha_0$ with\n     $$\n     \\alpha_0 = \\dfrac{\\mu_1}{\\mu_0}.\n     $$\n   - Define\n     $$\n     \\langle \\pi_1, \\pi_1 \\rangle = \\mu_2 - 2 \\alpha_0 \\mu_1 + \\alpha_0^2 \\mu_0, \\quad\n     \\langle u \\pi_1, \\pi_1 \\rangle = \\mu_3 - 2 \\alpha_0 \\mu_2 + \\alpha_0^2 \\mu_1.\n     $$\n     Then\n     $$\n     \\alpha_1 = \\dfrac{\\langle u \\pi_1, \\pi_1 \\rangle}{\\langle \\pi_1, \\pi_1 \\rangle}, \\quad\n     \\beta_1 = \\dfrac{\\langle \\pi_1, \\pi_1 \\rangle}{\\langle \\pi_0, \\pi_0 \\rangle} = \\dfrac{\\langle \\pi_1, \\pi_1 \\rangle}{\\mu_0}.\n     $$\n   - Form the $2 \\times 2$ Jacobi matrix\n     $$\n     J = \\begin{bmatrix}\n     \\alpha_0 & \\sqrt{\\beta_1} \\\\\n     \\sqrt{\\beta_1} & \\alpha_1\n     \\end{bmatrix}.\n     $$\n     Its eigenvalues $\\{u_1,u_2\\}$ are the nodes in $(0,1)$, and the corresponding normalized eigenvectors $\\mathbf{v}_i$ yield the weights $w_i = \\mu_0 \\, (\\mathbf{v}_i)_1^2$, where $(\\mathbf{v}_i)_1$ denotes the first component of $\\mathbf{v}_i$.\n4. Verify the exact contraction of polynomial factors up to degree $3$ by reconstructing the four moments with the two-node quadrature:\n$$\n\\widehat{M}_k(T) = \\sum_{i=1}^2 w_i \\, u_i^k, \\quad k \\in \\{0,1,2,3\\}.\n$$\nFor each parameter set, compute the maximum absolute deviation\n$$\n\\varepsilon = \\max_{k \\in \\{0,1,2,3\\}} \\left| \\widehat{M}_k(T) - M_k(T) \\right|.\n$$\nReport this $\\varepsilon$ as a floating-point number.\n\nTest suite and input data are embedded directly in the program and must not require user input. Use the following three cases to cover a typical scenario, a near-coincident limit (small $T$), and a large-separation limit (large $T). In each case, all coordinates are in the same arbitrary Cartesian system and all exponents are positive reals.\n\n- Case $1$ (moderate separation):\n  - $\\alpha_a = 0.8$, $\\alpha_b = 0.5$, $\\alpha_c = 0.7$, $\\alpha_d = 0.6$,\n  - $\\mathbf{A} = (0.0, 0.0, 0.0)$, $\\mathbf{B} = (0.0, 0.0, 0.0)$,\n  - $\\mathbf{C} = (1.1, 0.0, 0.0)$, $\\mathbf{D} = (1.1, 0.0, 0.0)$.\n\n- Case $2$ (near-coincident centers for the ket pair):\n  - $\\alpha_a = 0.8$, $\\alpha_b = 0.5$, $\\alpha_c = 0.7$, $\\alpha_d = 0.6$,\n  - $\\mathbf{A} = (0.0, 0.0, 0.0)$, $\\mathbf{B} = (0.0, 0.0, 0.0)$,\n  - $\\mathbf{C} = (0.01, 0.0, 0.0)$, $\\mathbf{D} = (0.01, 0.0, 0.0)$.\n\n- Case $3$ (large separation):\n  - $\\alpha_a = 0.8$, $\\alpha_b = 0.5$, $\\alpha_c = 0.7$, $\\alpha_d = 0.6$,\n  - $\\mathbf{A} = (0.0, 0.0, 0.0)$, $\\mathbf{B} = (0.0, 0.0, 0.0)$,\n  - $\\mathbf{C} = (4.0, 0.0, 0.0)$, $\\mathbf{D} = (4.0, 0.0, 0.0)$.\n\nYour program must:\n- Compute $T$ for each case,\n- Construct the two-node Rys quadrature via the Stieltjes and Golubâ€“Welsch steps for the weight $\\exp(-T u^2)$ on $[0,1]$,\n- Evaluate $\\varepsilon$ as defined above for each case,\n- Produce a single line of output containing the three results as a comma-separated list enclosed in square brackets, for example, $\\left[\\varepsilon_1,\\varepsilon_2,\\varepsilon_3\\right]$.\n\nNo physical units are required, and all computations are dimensionless by construction. The final output must be exactly one line with the required list format and no additional text.", "solution": "The objective is to implement and verify a two-node Rys quadrature for the weight function $w(u) = \\exp(-T u^2)$ on the interval $[0,1]$. This specific quadrature is central to the evaluation of certain electron repulsion integrals in quantum chemistry. For a polynomial prefactor of degree up to $3$, a two-node Gaussian quadrature provides an exact result, a principle we will demonstrate. The procedure involves several distinct mathematical steps, which are executed for each of the three provided test cases.\n\nFirst, we determine the parameter $T$ which characterizes the quadrature. This parameter arises from the physical properties of the interacting Gaussian functions. Given four primitive Cartesian Gaussian functions centered at $\\mathbf{A}$, $\\mathbf{B}$, $\\mathbf{C}$, and $\\mathbf{D}$ with exponents $\\alpha_a$, $\\alpha_b$, $\\alpha_c$, and $\\alpha_d$, we apply the Gaussian product theorem. This theorem combines pairs of Gaussians into single Gaussians. For the bra-pair $(\\phi_a, \\phi_b)$ and ket-pair $(\\phi_c, \\phi_d)$, the composite exponents and centers are:\n$$\np = \\alpha_a + \\alpha_b, \\quad \\mathbf{P} = \\dfrac{\\alpha_a \\mathbf{A} + \\alpha_b \\mathbf{B}}{p}\n$$\n$$\nq = \\alpha_c + \\alpha_d, \\quad \\mathbf{Q} = \\dfrac{\\alpha_c \\mathbf{C} + \\alpha_d \\mathbf{D}}{q}\n$$\nThe parameter $T$ is then defined as:\n$$\nT = \\rho \\, \\lVert \\mathbf{P} - \\mathbf{Q} \\rVert^2, \\quad \\text{where} \\quad \\rho = \\dfrac{p\\, q}{p+q}\n$$\nFor the given test cases, the centers are such that $\\mathbf{A} = \\mathbf{B}$ and $\\mathbf{C} = \\mathbf{D}$, which simplifies the composite centers to $\\mathbf{P} = \\mathbf{A}$ and $\\mathbf{Q} = \\mathbf{C}$.\n\nSecond, we compute the first four moments, $\\mu_k$, of the weight function $w(u) = \\exp(-T u^2)$ on the interval $[0,1]$. These moments are necessary for constructing the orthogonal polynomials associated with the quadrature. The moments are defined by the integral:\n$$\n\\mu_k \\equiv M_k(T) = \\int_0^1 u^k \\, e^{-T u^2} \\, du\n$$\nThis integral can be evaluated analytically in terms of the lower incomplete gamma function, $\\gamma(a,x)$. By substituting $s = u^2$, we obtain the expression provided in the problem statement:\n$$\nM_k(T) = \\dfrac{1}{2} \\int_0^1 s^{\\frac{k-1}{2}} e^{-T s} \\, ds = \\dfrac{1}{2} \\, \\dfrac{\\gamma\\!\\left(\\dfrac{k+1}{2},\\, T\\right)}{T^{\\frac{k+1}{2}}}\n$$\nWe compute these moments for $k \\in \\{0, 1, 2, 3\\}$.\n\nThird, we construct the $2 \\times 2$ Jacobi matrix using the moments. This is achieved via the Stieltjes procedure, which generates the recurrence coefficients for the family of monic polynomials $\\{\\pi_j(u)\\}$ that are orthogonal with respect to the inner product $\\langle f,g\\rangle = \\int_0^1 f(u) g(u) e^{-T u^2} \\, du$. These polynomials satisfy a three-term recurrence relation $\\pi_{j+1}(u) = (u - \\alpha_j)\\pi_j(u) - \\beta_j \\pi_{j-1}(u)$. For a two-node quadrature ($n=2$), we need the coefficients $\\alpha_0$, $\\alpha_1$, and $\\beta_1$.\nThe first monic polynomial is $\\pi_0(u)=1$.\nThe recurrence coefficients are determined from the moments $\\mu_k$:\n$$\n\\alpha_0 = \\dfrac{\\langle u\\pi_0, \\pi_0 \\rangle}{\\langle \\pi_0, \\pi_0 \\rangle} = \\dfrac{\\mu_1}{\\mu_0}\n$$\nThe second monic polynomial is $\\pi_1(u) = u - \\alpha_0$. Using this, we find $\\beta_1$ and $\\alpha_1$:\n$$\n\\beta_1 = \\dfrac{\\langle \\pi_1, \\pi_1 \\rangle}{\\langle \\pi_0, \\pi_0 \\rangle} = \\dfrac{\\mu_2 - 2\\alpha_0\\mu_1 + \\alpha_0^2\\mu_0}{\\mu_0}\n$$\n$$\n\\alpha_1 = \\dfrac{\\langle u\\pi_1, \\pi_1 \\rangle}{\\langle \\pi_1, \\pi_1 \\rangle} = \\dfrac{\\mu_3 - 2\\alpha_0\\mu_2 + \\alpha_0^2\\mu_1}{\\mu_2 - 2\\alpha_0\\mu_1 + \\alpha_0^2\\mu_0}\n$$\nThese coefficients form the symmetric tridiagonal Jacobi matrix for $n=2$:\n$$\nJ = \\begin{bmatrix}\n\\alpha_0 & \\sqrt{\\beta_1} \\\\\n\\sqrt{\\beta_1} & \\alpha_1\n\\end{bmatrix}\n$$\n\nFourth, we obtain the quadrature nodes $u_i$ and weights $w_i$ by solving the eigensystem of the Jacobi matrix $J$. This is the essence of the Golub-Welsch algorithm. The eigenvalues of $J$ are the quadrature nodes $\\{u_1, u_2\\}$. The corresponding normalized eigenvectors $\\mathbf{v}_i$ are used to calculate the weights:\n$$\nw_i = \\mu_0 \\, (\\mathbf{v}_i)_1^2\n$$\nwhere $(\\mathbf{v}_i)_1$ denotes the first component of the eigenvector $\\mathbf{v}_i$.\n\nFinally, we verify that the constructed two-node quadrature is exact for polynomials of degree up to $3$. This is done by using the computed nodes and weights to numerically evaluate the first four moments:\n$$\n\\widehat{M}_k(T) = \\sum_{i=1}^2 w_i \\, u_i^k, \\quad \\text{for } k \\in \\{0, 1, 2, 3\\}\n$$\nThe theoretical exactness implies that $\\widehat{M}_k(T)$ should be equal to $M_k(T)$. We quantify any deviation, which arises from floating-point inaccuracies, by computing the maximum absolute error across these four moments:\n$$\n\\varepsilon = \\max_{k \\in \\{0,1,2,3\\}} \\left| \\widehat{M}_k(T) - M_k(T) \\right|\n$$\nThis value of $\\varepsilon$ is computed for each test case and reported as the final result. The expected result is an error on the order of machine precision.", "answer": "```python\nimport numpy as np\nfrom scipy.special import gamma, gammainc\n\ndef solve():\n    \"\"\"\n    Main function to solve the problem for the given test cases.\n    It computes the maximum absolute deviation for the Rys quadrature\n    for each test case and prints the results in the required format.\n    \"\"\"\n    test_cases = [\n        # Case 1 (moderate separation)\n        {\n            'alphas': (0.8, 0.5, 0.7, 0.6),\n            'centers': (np.array([0.0, 0.0, 0.0]), np.array([0.0, 0.0, 0.0]),\n                        np.array([1.1, 0.0, 0.0]), np.array([1.1, 0.0, 0.0])),\n        },\n        # Case 2 (near-coincident centers)\n        {\n            'alphas': (0.8, 0.5, 0.7, 0.6),\n            'centers': (np.array([0.0, 0.0, 0.0]), np.array([0.0, 0.0, 0.0]),\n                        np.array([0.01, 0.0, 0.0]), np.array([0.01, 0.0, 0.0])),\n        },\n        # Case 3 (large separation)\n        {\n            'alphas': (0.8, 0.5, 0.7, 0.6),\n            'centers': (np.array([0.0, 0.0, 0.0]), np.array([0.0, 0.0, 0.0]),\n                        np.array([4.0, 0.0, 0.0]), np.array([4.0, 0.0, 0.0])),\n        },\n    ]\n\n    results = []\n    for case in test_cases:\n        error = compute_quadrature_error(case)\n        results.append(error)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\ndef compute_quadrature_error(case):\n    \"\"\"\n    Performs the full calculation for a single test case.\n    1. Computes the Boys function parameter T.\n    2. Computes the first four moments M_k(T).\n    3. Constructs the 2x2 Jacobi matrix via Stieltjes procedure.\n    4. Computes quadrature nodes and weights via Golub-Welsch.\n    5. Verifies the quadrature by reconstructing moments and calculating error.\n    \"\"\"\n    alpha_a, alpha_b, alpha_c, alpha_d = case['alphas']\n    A, B, C, D = case['centers']\n\n    # Step 1: Compute T\n    p = alpha_a + alpha_b\n    q = alpha_c + alpha_d\n    \n    # Since A=B and C=D for all cases, P=A and Q=C\n    P = A\n    Q = C\n    \n    rho = (p * q) / (p + q)\n    dist_sq = np.sum((P - Q)**2)\n    T = rho * dist_sq\n\n    # Step 2: Compute moments M_k(T)\n    # M_k(T) = (1/2) * gamma((k+1)/2, T) / T**((k+1)/2)\n    # gamma(a,x) = gammainc(a,x) * Gamma(a)\n    moments = np.zeros(4)\n    for k in range(4):\n        a = (k + 1.0) / 2.0\n        if T > 0:\n            val = 0.5 * gammainc(a, T) * gamma(a) / (T**a)\n        else: # Handle T=0 case separately\n            val = 1.0 / (k + 1.0)\n        moments[k] = val\n    \n    mu0, mu1, mu2, mu3 = moments\n\n    # Step 3: Construct the Jacobi matrix\n    # Recurrence coefficients for monic orthogonal polynomials\n    alpha0 = mu1 / mu0\n    \n    # Using simplified forms for numerical stability\n    # <pi_1, pi_1> = mu2 - mu1^2/mu0\n    inner_pi1_pi1 = mu2 - alpha0 * mu1\n    \n    beta1 = inner_pi1_pi1 / mu0\n    \n    # <u*pi_1, pi_1> = mu3 - 2*alpha0*mu2 + alpha0^2*mu1\n    inner_upi1_pi1 = mu3 - 2.0 * alpha0 * mu2 + alpha0**2 * mu1\n    \n    alpha1 = inner_upi1_pi1 / inner_pi1_pi1\n\n    # Form the 2x2 Jacobi matrix\n    J = np.array([\n        [alpha0, np.sqrt(beta1)],\n        [np.sqrt(beta1), alpha1]\n    ])\n\n    # Step 4: Compute nodes and weights\n    # Eigenvalues of J are the nodes.\n    # Weights are derived from the first component of the eigenvectors.\n    eigenvalues, eigenvectors = np.linalg.eigh(J)\n    \n    nodes = eigenvalues\n    # weights w_i = mu_0 * (v_i)_1^2\n    weights = mu0 * (eigenvectors[0, :]**2)\n\n    # Step 5: Verify exactness and compute error\n    reconstructed_moments = np.zeros(4)\n    for k in range(4):\n        reconstructed_moments[k] = np.sum(weights * (nodes**k))\n\n    abs_deviations = np.abs(reconstructed_moments - moments)\n    max_deviation = np.max(abs_deviations)\n    \n    return max_deviation\n\nsolve()\n```"}]}