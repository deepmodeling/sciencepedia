{"hands_on_practices": [{"introduction": "A cornerstone of modeling open systems is understanding how a complex environment, or 'bath', influences a simpler system of interest. The effect of the bath is encapsulated in the memory kernel of a Generalized Langevin Equation (GLE), which describes non-Markovian friction. This exercise provides direct, hands-on practice in deriving this kernel from a given microscopic model of system-bath coupling, as characterized by the spectral density [@problem_id:2825430]. By working through the derivation for the common Drude-Lorentz model, you will gain proficiency in the transform methods that connect these two fundamental quantities and develop a concrete understanding of the transition to the memoryless, or Markovian, limit.", "problem": "Consider a classical particle coupled linearly to a harmonic bath that gives rise to a generalized Langevin equation (GLE) with a causal friction memory kernel. In the standard system-bath framework with linear coupling, the spectral density $J(\\omega)$ characterizes the coupling strengths of the bath modes. In the classical limit, a well-tested relation from the fluctuation-dissipation theorem (FDT) connects the spectral density $J(\\omega)$ to the causal friction memory kernel $\\gamma(t)$ via the cosine transform\n$$\n\\gamma(t)\\;=\\;\\frac{2}{\\pi}\\int_{0}^{\\infty}\\frac{J(\\omega)}{\\omega}\\,\\cos(\\omega t)\\,d\\omega,\\qquad t>0.\n$$\nAssume an Ohmic spectral density with Drude cutoff given by\n$$\nJ(\\omega)\\;=\\;\\frac{\\eta\\,\\omega\\,\\omega_{c}^{2}}{\\omega_{c}^{2}+\\omega^{2}},\n$$\nwhere $\\eta>0$ is a friction scale and $\\omega_{c}>0$ is the cutoff frequency. Starting only from the above definitions and standard complex analysis or integral transform facts, derive the explicit form of the causal memory kernel $\\gamma(t)$ for $t>0$. Then, analyze the Markovian limit $\\omega_{c}\\to\\infty$ by showing how $\\gamma(t)$ approaches a distribution concentrated at $t=0$ and explain how this recovers memoryless friction in the GLE in both time and Laplace domains.\n\nProvide the final answer as a single closed-form analytic expression for $\\gamma(t)$ in terms of $\\eta$, $\\omega_{c}$, and $t$ for $t>0$. No units are required. No numerical approximation is needed.", "solution": "The problem presented is a standard and well-posed exercise in the theory of open systems and non-equilibrium statistical mechanics. It is scientifically grounded, self-contained, and requires a rigorous derivation. We shall proceed with the solution.\n\nFirst, we are tasked with deriving the explicit form of the causal friction memory kernel, $\\gamma(t)$, for a system with an Ohmic spectral density with a Drude cutoff.\n\nThe givens are:\n$1$. The relation between the kernel $\\gamma(t)$ and the spectral density $J(\\omega)$ for $t>0$:\n$$ \\gamma(t) = \\frac{2}{\\pi}\\int_{0}^{\\infty}\\frac{J(\\omega)}{\\omega}\\,\\cos(\\omega t)\\,d\\omega $$\n$2$. The form of the spectral density:\n$$ J(\\omega) = \\frac{\\eta\\,\\omega\\,\\omega_{c}^{2}}{\\omega_{c}^{2}+\\omega^{2}} $$\nwhere $\\eta>0$ and $\\omega_{c}>0$ are constants.\n\nWe substitute the expression for $J(\\omega)$ into the integral for $\\gamma(t)$. The factor of $\\omega$ in the numerator of $J(\\omega)$ cancels with the $\\omega$ in the denominator of the integrand.\n$$ \\gamma(t) = \\frac{2}{\\pi}\\int_{0}^{\\infty} \\frac{1}{\\omega} \\left( \\frac{\\eta\\,\\omega\\,\\omega_{c}^{2}}{\\omega_{c}^{2}+\\omega^{2}} \\right) \\cos(\\omega t)\\,d\\omega $$\n$$ \\gamma(t) = \\frac{2\\eta\\omega_{c}^{2}}{\\pi} \\int_{0}^{\\infty} \\frac{\\cos(\\omega t)}{\\omega_{c}^{2}+\\omega^{2}}\\,d\\omega $$\nThe integral is a standard Fourier cosine transform. We can evaluate it using complex analysis via the residue theorem. The integrand is an even function of $\\omega$, so we may write:\n$$ \\int_{0}^{\\infty} \\frac{\\cos(\\omega t)}{\\omega_{c}^{2}+\\omega^{2}}\\,d\\omega = \\frac{1}{2} \\int_{-\\infty}^{\\infty} \\frac{\\cos(\\omega t)}{\\omega_{c}^{2}+\\omega^{2}}\\,d\\omega = \\frac{1}{2} \\text{Re} \\left[ \\int_{-\\infty}^{\\infty} \\frac{e^{i\\omega t}}{\\omega_{c}^{2}+\\omega^{2}}\\,d\\omega \\right] $$\nConsider the complex integral $\\oint_{C} \\frac{e^{izt}}{z^{2}+\\omega_{c}^{2}}\\,dz$. The integrand has simple poles at $z=\\pm i\\omega_{c}$. For $t>0$, we close the contour in the upper half-plane, enclosing the pole at $z=i\\omega_{c}$. By Jordan's lemma, the integral over the semicircular arc vanishes as its radius tends to infinity. The integral along the real axis is then given by $2\\pi i$ times the residue at the enclosed pole.\n$$ \\text{Res}(z=i\\omega_{c}) = \\lim_{z \\to i\\omega_{c}} (z-i\\omega_{c})\\frac{e^{izt}}{(z-i\\omega_{c})(z+i\\omega_{c})} = \\frac{e^{i(i\\omega_{c})t}}{2i\\omega_{c}} = \\frac{e^{-\\omega_{c}t}}{2i\\omega_{c}} $$\nTherefore, the integral along the real axis is:\n$$ \\int_{-\\infty}^{\\infty} \\frac{e^{i\\omega t}}{\\omega_{c}^{2}+\\omega^{2}}\\,d\\omega = 2\\pi i \\cdot \\text{Res}(z=i\\omega_{c}) = 2\\pi i \\left( \\frac{e^{-\\omega_{c}t}}{2i\\omega_{c}} \\right) = \\frac{\\pi}{\\omega_{c}} e^{-\\omega_{c}t} $$\nThis result is purely real, so taking the real part is trivial. The original integral from $0$ to $\\infty$ is half of this value:\n$$ \\int_{0}^{\\infty} \\frac{\\cos(\\omega t)}{\\omega_{c}^{2}+\\omega^{2}}\\,d\\omega = \\frac{1}{2} \\left( \\frac{\\pi}{\\omega_{c}} e^{-\\omega_{c}t} \\right) = \\frac{\\pi}{2\\omega_{c}} e^{-\\omega_{c}t} $$\nSubstituting this result back into our expression for $\\gamma(t)$:\n$$ \\gamma(t) = \\frac{2\\eta\\omega_{c}^{2}}{\\pi} \\left( \\frac{\\pi}{2\\omega_{c}} e^{-\\omega_{c}t} \\right) = \\eta\\omega_{c} e^{-\\omega_{c}t} $$\nThis is the explicit form of the memory kernel for $t>0$.\n\nNext, we analyze the Markovian limit, which corresponds to an infinitely fast bath, i.e., $\\omega_{c} \\to \\infty$. The memory time of the kernel is of order $1/\\omega_{c}$.\nThe memory kernel becomes $\\gamma(t) = \\eta\\omega_{c}e^{-\\omega_{c}t}$.\nFor any fixed time $t>0$, the limit is:\n$$ \\lim_{\\omega_{c}\\to\\infty} \\gamma(t) = \\lim_{\\omega_{c}\\to\\infty} \\eta\\omega_{c}e^{-\\omega_{c}t} = 0 $$\nas the exponential decay dominates the linear factor.\nAt $t=0$, $\\gamma(0) = \\eta\\omega_{c}$, which diverges as $\\omega_{c}\\to\\infty$.\nThe function thus becomes infinitely sharp and infinitely high at $t=0$, while being zero for all $t>0$. This is characteristic of a Dirac delta distribution. To determine the strength of this distribution, we compute the integral of the kernel over its domain:\n$$ \\int_{0}^{\\infty} \\gamma(t)\\,dt = \\int_{0}^{\\infty} \\eta\\omega_{c}e^{-\\omega_{c}t}\\,dt = \\eta\\omega_{c} \\left[ -\\frac{1}{\\omega_{c}} e^{-\\omega_{c}t} \\right]_{0}^{\\infty} = \\eta\\omega_{c} \\left( 0 - \\left(-\\frac{1}{\\omega_{c}}\\right) \\right) = \\eta $$\nThe integral of the function $\\gamma(t)$ is $\\eta$, independent of $\\omega_{c}$. A sequence of functions that becomes infinitely peaked at the origin, is zero elsewhere, and maintains a constant integral represents a delta distribution. Therefore, in the sense of distributions:\n$$ \\lim_{\\omega_{c}\\to\\infty} \\gamma(t) = \\eta \\delta(t) $$\nHere, $\\delta(t)$ is the Dirac delta function, understood in the context of causal systems where its support is concentrated at $t=0^{+}$.\n\nWe now demonstrate how this limit recovers memoryless friction in the generalized Langevin equation (GLE). The friction term in the GLE is given by the convolution integral $-\\int_{0}^{t} \\gamma(t-\\tau)v(\\tau)\\,d\\tau$, where $v(t)$ is the particle's velocity.\nIn the Markovian limit, this term becomes:\n$$ -\\int_{0}^{t} \\left( \\lim_{\\omega_{c}\\to\\infty} \\gamma(t-\\tau) \\right) v(\\tau)\\,d\\tau = -\\int_{0}^{t} \\eta\\delta(t-\\tau)v(\\tau)\\,d\\tau $$\nBy the sifting property of the delta function, where the spike is at $\\tau=t$ (the upper limit of integration), for a causal system this integral evaluates to:\n$$ -\\eta v(t) $$\nThe friction term thus becomes proportional to the instantaneous velocity, which is the definition of memoryless, or Markovian, friction. The friction coefficient is $\\eta$.\n\nThis result can be confirmed in the Laplace domain. The Laplace transform of the memory kernel, $\\tilde{\\gamma}(s) = \\mathcal{L}\\{\\gamma(t)\\}$, is:\n$$ \\tilde{\\gamma}(s) = \\int_{0}^{\\infty} e^{-st} (\\eta\\omega_{c}e^{-\\omega_{c}t})\\,dt = \\eta\\omega_{c} \\int_{0}^{\\infty} e^{-(s+\\omega_{c})t}\\,dt = \\frac{\\eta\\omega_{c}}{s+\\omega_{c}} $$\nNow, we take the Markovian limit $\\omega_{c}\\to\\infty$:\n$$ \\lim_{\\omega_{c}\\to\\infty} \\tilde{\\gamma}(s) = \\lim_{\\omega_{c}\\to\\infty} \\frac{\\eta\\omega_{c}}{s+\\omega_{c}} = \\lim_{\\omega_{c}\\to\\infty} \\frac{\\eta}{(s/\\omega_{c})+1} = \\eta $$\nThe Laplace transform of the friction term in the GLE is $-\\tilde{\\gamma}(s)\\tilde{v}(s)$. In the limit, this becomes $-\\eta\\tilde{v}(s)$. The inverse Laplace transform of this term is $-\\eta v(t)$, which again confirms that the friction becomes memoryless with coefficient $\\eta$. The consistency between the time and Laplace domain analyses confirms the correctness of our conclusions. A typical point of confusion regarding a factor of $2$ arises from relating the causal kernel to the symmetrized noise correlation function via the fluctuation-dissipation theorem, but as shown, a careful and consistent application of mathematical definitions resolves any apparent paradox.", "answer": "$$\\boxed{\\eta\\,\\omega_{c}\\,\\exp(-\\omega_{c}\\,t)}$$", "id": "2825430"}, {"introduction": "The Mori–Zwanzig formalism provides a rigorous way to derive equations of motion for a reduced set of 'relevant' variables, but what is the physical origin of the resulting memory kernel? This practice delves into this conceptual question by applying the formalism to a classical harmonic oscillator, a system whose dynamics are exactly solvable [@problem_id:2825473]. You will explore how the choice of relevant variables—specifically, whether you track only position or both position and momentum—directly determines the structure of the memory kernel, revealing that memory effects are a direct consequence of projecting out essential dynamical information.", "problem": "Consider a classical one-dimensional harmonic oscillator modeling a single molecular vibrational mode with Hamiltonian $H(q,p) = \\frac{p^{2}}{2 m} + \\frac{1}{2} m \\omega^{2} q^{2}$ in contact with a canonical heat bath at temperature $T$. Let the equilibrium average be denoted by $\\langle \\cdot \\rangle_{\\mathrm{eq}}$, and define fluctuations by $\\delta A = A - \\langle A \\rangle_{\\mathrm{eq}}$. Use the inner product $(A,B) = \\langle \\delta A \\, \\delta B \\rangle_{\\mathrm{eq}}$.\n\n1) Starting from the microscopic variable set $\\{q, p\\}$, construct an orthonormal relevant set $\\{A_{1}, A_{2}\\}$ by Gram–Schmidt orthonormalization with respect to the inner product $(\\cdot,\\cdot)$.\n\n2) Using the Mori–Zwanzig (MZ) projection operator formalism and the Generalized Langevin Equation (GLE) with the Liouville operator $i \\mathcal{L}$ (defined via the classical Poisson bracket) and projection onto the one-dimensional subspace spanned by $A_{1}$, derive from first principles an expression for the memory kernel at $t=0$, namely $M(0)$, in terms of $i \\mathcal{L}$ and equilibrium averages. Then, evaluate $M(0)$ explicitly for this system in terms of $m$, $\\omega$, $k_{B}$ (Boltzmann constant), and $T$.\n\n3) Briefly justify how extending the relevant set from $\\{A_{1}\\}$ to $\\{A_{1}, A_{2}\\}$ modifies the short-time behavior of the memory kernel.\n\nProvide as your final answer the single dimensionless quantity $M(0)/\\omega^{2}$. No numerical evaluation is required, and no units are needed for the final answer since it is dimensionless.", "solution": "The problem is validated as self-contained, scientifically grounded, and well-posed. The solution proceeds as follows.\n\nFirst, we establish the necessary equilibrium averages for a classical one-dimensional harmonic oscillator in a canonical ensemble at temperature $T$. The Hamiltonian is $H = \\frac{p^2}{2m} + \\frac{1}{2}m\\omega^2 q^2$. The probability distribution in phase space is proportional to $\\exp(-\\beta H)$, where $\\beta = 1/(k_B T)$. Due to the quadratic form of the Hamiltonian, the potential energy is an even function of $q$ and the kinetic energy is an even function of $p$. Consequently, the averages of any odd powers of $q$ or $p$ are zero.\n$$ \\langle q \\rangle_{\\mathrm{eq}} = 0, \\quad \\langle p \\rangle_{\\mathrm{eq}} = 0 $$\nThe fluctuations are thus identical to the variables themselves: $\\delta q = q$ and $\\delta p = p$.\nFrom the equipartition theorem, we have:\n$$ \\left\\langle \\frac{1}{2} m \\omega^2 q^2 \\right\\rangle_{\\mathrm{eq}} = \\frac{1}{2} k_B T \\implies \\langle q^2 \\rangle_{\\mathrm{eq}} = \\frac{k_B T}{m \\omega^2} $$\n$$ \\left\\langle \\frac{p^2}{2m} \\right\\rangle_{\\mathrm{eq}} = \\frac{1}{2} k_B T \\implies \\langle p^2 \\rangle_{\\mathrm{eq}} = m k_B T $$\nThe cross-correlation is zero due to the separability of the Hamiltonian in $q$ and $p$:\n$$ \\langle q p \\rangle_{\\mathrm{eq}} = \\frac{\\iint qp \\, \\exp(-\\beta H) \\, dq \\, dp}{\\iint \\exp(-\\beta H) \\, dq \\, dp} = 0 $$\nThe inner product $(A, B) = \\langle \\delta A \\, \\delta B \\rangle_{\\mathrm{eq}}$ simplifies to $(A, B) = \\langle A B \\rangle_{\\mathrm{eq}}$ for linear combinations of $q$ and $p$.\n\n1) Construction of the orthonormal set $\\{A_1, A_2\\}$.\nWe apply the Gram-Schmidt procedure to the set $\\{q, p\\}$.\nFirst, select the variable $v_1 = q$. Its norm-squared is:\n$$ (v_1, v_1) = (q, q) = \\langle q^2 \\rangle_{\\mathrm{eq}} = \\frac{k_B T}{m \\omega^2} $$\nThe first orthonormal variable $A_1$ is obtained by normalization:\n$$ A_1 = \\frac{v_1}{\\sqrt{(v_1, v_1)}} = \\frac{q}{\\sqrt{\\langle q^2 \\rangle_{\\mathrm{eq}}}} = q \\sqrt{\\frac{m \\omega^2}{k_B T}} $$\nNext, select the variable $v_2 = p$. We find the component of $v_2$ orthogonal to $A_1$. Since variables $q$ and $p$ are already orthogonal, $(v_1, v_2) = (q, p) = \\langle qp \\rangle_{\\mathrm{eq}} = 0$, the orthogonalization step is trivial. We only need to normalize $v_2$. The norm-squared of $v_2$ is:\n$$ (v_2, v_2) = (p, p) = \\langle p^2 \\rangle_{\\mathrm{eq}} = m k_B T $$\nThe second orthonormal variable $A_2$ is:\n$$ A_2 = \\frac{v_2}{\\sqrt{(v_2, v_2)}} = \\frac{p}{\\sqrt{\\langle p^2 \\rangle_{\\mathrm{eq}}}} = \\frac{p}{\\sqrt{m k_B T}} $$\nThus, the orthonormal set is $\\{A_1, A_2\\} = \\left\\{ q \\sqrt{\\frac{m \\omega^2}{k_B T}}, \\frac{p}{\\sqrt{m k_B T}} \\right\\}$.\n\n2) Derivation and evaluation of the memory kernel $M(0)$.\nThe Mori-Zwanzig formalism provides a Generalized Langevin Equation for a relevant variable, here taken as $A_1$. The dynamics are projected onto the subspace spanned by $A_1$ using the projection operator $\\mathcal{P}$:\n$$ \\mathcal{P} X = \\frac{(A_1, X)}{(A_1, A_1)} A_1 = (A_1, X) A_1 $$\nwhere the second equality holds because $A_1$ is normalized. The complementary projection is $\\mathcal{Q} = 1 - \\mathcal{P}$. The memory kernel $M(t)$ is defined via the autocorrelation of the random force $F(t) = \\exp(i\\mathcal{Q}\\mathcal{L}t) i\\mathcal{Q}\\mathcal{L}A_1$:\n$$ M(t) = \\frac{(F(t), F(0))}{(A_1, A_1)} = (F(0), e^{-i\\mathcal{Q}\\mathcal{L}t} F(0)) $$\nwhere we have used the self-adjointness of the propagator in the inner product. At time $t=0$, this gives:\n$$ M(0) = (F(0), F(0)) = (i\\mathcal{Q}\\mathcal{L}A_1, i\\mathcal{Q}\\mathcal{L}A_1) $$\nUsing $\\mathcal{Q} = 1 - \\mathcal{P}$ and expanding, we obtain the general expression for $M(0)$ in terms of the Liouvillian $i\\mathcal{L}$ and equilibrium averages (inner products):\n$$ M(0) = (i\\mathcal{L}A_1 - \\mathcal{P}(i\\mathcal{L}A_1), i\\mathcal{L}A_1 - \\mathcal{P}(i\\mathcal{L}A_1)) = (i\\mathcal{L}A_1, i\\mathcal{L}A_1) - ((A_1, i\\mathcal{L}A_1)A_1, i\\mathcal{L}A_1) - (i\\mathcal{L}A_1, (A_1, i\\mathcal{L}A_1)A_1) + ((A_1, i\\mathcal{L}A_1)A_1, (A_1, i\\mathcal{L}A_1)A_1) $$\n$$ M(0) = (i\\mathcal{L}A_1, i\\mathcal{L}A_1) - (A_1, i\\mathcal{L}A_1)^2 - (A_1, i\\mathcal{L}A_1)^2 + (A_1, i\\mathcal{L}A_1)^2(A_1, A_1) $$\nSince $(A_1, A_1) = 1$, this simplifies to:\n$$ M(0) = (i\\mathcal{L}A_1, i\\mathcal{L}A_1) - (A_1, i\\mathcal{L}A_1)^2 $$\nThis expression connects $M(0)$ to the Liouvillian and equilibrium averages, as requested.\n\nTo evaluate this for our system, we first compute the action of $i\\mathcal{L}$ on $A_1$. The operator $i\\mathcal{L}$ acts as the Poisson bracket with the Hamiltonian, $i\\mathcal{L}X = \\{X, H\\}$.\n$$ i\\mathcal{L}A_1 = \\{A_1, H\\} = \\left\\{q \\sqrt{\\frac{m \\omega^2}{k_B T}}, \\frac{p^2}{2m} + \\frac{1}{2}m\\omega^2 q^2\\right\\} = \\sqrt{\\frac{m \\omega^2}{k_B T}} \\{q, H\\} $$\n$$ \\{q, H\\} = \\frac{\\partial q}{\\partial q}\\frac{\\partial H}{\\partial p} - \\frac{\\partial q}{\\partial p}\\frac{\\partial H}{\\partial q} = 1 \\cdot \\frac{p}{m} - 0 = \\frac{p}{m} $$\nSo,\n$$ i\\mathcal{L}A_1 = \\sqrt{\\frac{m \\omega^2}{k_B T}} \\left(\\frac{p}{m}\\right) = p \\sqrt{\\frac{\\omega^2}{m k_B T}} $$\nUsing the definition $A_2 = p/\\sqrt{m k_B T}$, we find a compact relation:\n$$ i\\mathcal{L}A_1 = \\omega A_2 $$\nNow we evaluate the two terms in the expression for $M(0)$:\n$$ (A_1, i\\mathcal{L}A_1) = (A_1, \\omega A_2) = \\omega (A_1, A_2) = 0 $$\nThis is the frequency term $i\\Omega_{11}$, which is null.\n$$ (i\\mathcal{L}A_1, i\\mathcal{L}A_1) = (\\omega A_2, \\omega A_2) = \\omega^2 (A_2, A_2) = \\omega^2 $$\nsince $A_2$ is normalized. Substituting these into the formula for $M(0)$:\n$$ M(0) = \\omega^2 - 0^2 = \\omega^2 $$\n\n3) Modification of the memory kernel by extending the relevant set.\nThe memory kernel arises from the dynamics projected onto the subspace orthogonal to the set of relevant variables. For the one-variable set $\\{A_1\\}$, the orthogonal subspace contains $A_2$. The time evolution of $A_1$, given by $i\\mathcal{L}A_1 = \\omega A_2$, is entirely directed into this orthogonal subspace. This \"orthogonal flux\", $i\\mathcal{Q}\\mathcal{L}A_1 = i\\mathcal{L}A_1$, is the source of the memory effect, and its initial magnitude squared gives $M(0) = \\omega^2$.\n\nWhen the relevant set is extended to $\\{A_1, A_2\\}$, the projection operator becomes $\\mathcal{P}_{12} = (A_1, \\cdot)A_1 + (A_2, \\cdot)A_2$, and the orthogonal projector is $\\mathcal{Q}_{12} = 1 - \\mathcal{P}_{12}$. The dynamics of the variables in the set are described by the Liouvillian. We have $i\\mathcal{L}A_1 = \\omega A_2$. We also compute $i\\mathcal{L}A_2$:\n$$ i\\mathcal{L}A_2 = \\{A_2, H\\} = \\left\\{\\frac{p}{\\sqrt{m k_B T}}, H\\right\\} = \\frac{1}{\\sqrt{m k_B T}} \\{p, H\\} $$\n$$ \\{p, H\\} = \\frac{\\partial p}{\\partial q}\\frac{\\partial H}{\\partial p} - \\frac{\\partial p}{\\partial p}\\frac{\\partial H}{\\partial q} = 0 - 1 \\cdot (m\\omega^2 q) = -m\\omega^2 q $$\n$$ i\\mathcal{L}A_2 = \\frac{-m\\omega^2 q}{\\sqrt{m k_B T}} = -\\omega \\left( q \\sqrt{\\frac{m\\omega^2}{k_B T}} \\right) = -\\omega A_1 $$\nThe time evolution of both $A_1$ and $A_2$ under $i\\mathcal{L}$ produces vectors that remain within the span of $\\{A_1, A_2\\}$. This means the set $\\{A_1, A_2\\}$ is closed under the action of the Liouvillian.\nConsequently, the projection of the time derivatives onto the orthogonal subspace is zero:\n$$ i\\mathcal{Q}_{12}\\mathcal{L}A_1 = (1-\\mathcal{P}_{12})(\\omega A_2) = \\omega A_2 - ((A_1, \\omega A_2)A_1 + (A_2, \\omega A_2)A_2) = \\omega A_2 - (0 \\cdot A_1 + \\omega \\cdot A_2) = 0 $$\n$$ i\\mathcal{Q}_{12}\\mathcal{L}A_2 = (1-\\mathcal{P}_{12})(-\\omega A_1) = -\\omega A_1 - ((A_1, -\\omega A_1)A_1 + (A_2, -\\omega A_1)A_2) = -\\omega A_1 - (-\\omega \\cdot A_1 + 0 \\cdot A_2) = 0 $$\nSince the random force components $F_1(t)$ and $F_2(t)$ are generated by these terms, they are identically zero for all time. This implies that the entire memory kernel matrix $\\mathbf{M}(t)$ for the two-variable system is zero. In particular, the element $M_{11}(0)$, which would be the analogue of the scalar kernel from the first case, is zero.\nExtending the relevant set from $\\{A_1\\}$ to $\\{A_1, A_2\\}$ thus reduces the initial value of the memory kernel associated with $A_1$ from $M(0) = \\omega^2$ to $M_{11}(0) = 0$. This inclusion of the momentum variable fully captures the short-time (in fact, all-time) dynamics, leaving no \"memory\" effects from an orthogonal bath.\n\nThe final answer required is the dimensionless quantity $M(0)/\\omega^2$, where $M(0)$ is the kernel from the one-dimensional projection in part 2.\n$$ \\frac{M(0)}{\\omega^2} = \\frac{\\omega^2}{\\omega^2} = 1 $$", "answer": "$$\\boxed{1}$$", "id": "2825473"}, {"introduction": "The ultimate test of a theoretical framework is its ability to predict measurable quantities. This practice bridges the gap between theory and computation by focusing on the evaluation of transport coefficients using Green–Kubo relations [@problem_id:2825461]. You will grapple with a common challenge in molecular simulation: how to accurately compute the time integral of a noisy correlation function that exhibits a long-time tail. This exercise challenges you to compare the statistical properties of different numerical techniques and appreciate how a GLE-based approach, leveraging the memory kernel, can offer a sophisticated and noise-robust solution.", "problem": "A molecular dynamics simulation of a three-dimensional fluid produces an estimate of the stationary microscopic current autocorrelation function $C_{JJ}(t)=\\langle J(0)J(t)\\rangle$, where $t$ is time and $\\langle\\cdot\\rangle$ denotes an equilibrium ensemble average. From linear response theory via the Green–Kubo relation, the associated transport coefficient $\\kappa$ is given by $\\kappa = \\beta \\int_{0}^{\\infty} C_{JJ}(t)\\, dt$, where $\\beta = 1/(k_{\\mathrm{B}} T)$, $k_{\\mathrm{B}}$ is the Boltzmann constant, and $T$ is temperature. In a typical simulation, the estimate of $C_{JJ}(t)$ is accurate at short times but becomes dominated by noise beyond a crossover time $t^{\\ast}$. Hydrodynamic theory for $d=3$ predicts a long-time tail $C_{JJ}(t) \\sim A\\, t^{-3/2}$ as $t \\to \\infty$ for some amplitude $A>0$. You consider three numerical strategies to compute $\\int_{0}^{\\infty} C_{JJ}(t)\\, dt$ from the noisy data: (i) direct time integration with truncation at a finite cutoff $t_c$, (ii) tail fitting to an analytical asymptotic form and integrating the fitted tail from $t_c$ to $+\\infty$, and (iii) frequency-domain integration using the zero-frequency limit of the power spectral density, defined by the two-sided Fourier transform $S_{JJ}(\\omega)=\\int_{-\\infty}^{\\infty} e^{i \\omega t} C_{JJ}(t)\\, dt$, where $\\omega$ is angular frequency. In addition, you contemplate modeling the dynamics by a Generalized Langevin Equation (GLE), obtained from the Mori–Zwanzig projection operator formalism, in which $C_{JJ}(t)$ obeys a Volterra equation with a memory kernel $K(t)$.\n\nSelect all statements that are correct about the bias, variance, and consistency of these strategies under the stated assumptions.\n\nA. In $d=3$, if $C_{JJ}(t) \\sim A\\, t^{-3/2}$ for large $t$, then direct truncation at a cutoff $t_c$ induces a tail bias equal to $\\int_{t_c}^{\\infty} A\\, t^{-3/2}\\, dt = 2A\\, t_c^{-1/2}$. For fixed total simulation time $T_{\\mathrm{tot}}$, the standard deviation of the truncated time integral typically scales like a constant times $t_c^{1/2}/T_{\\mathrm{tot}}^{1/2}$, indicating a bias–variance tradeoff in the choice of $t_c$.\n\nB. If the true asymptotic tail is $C_{JJ}(t) \\sim A\\, t^{-3/2}$, then fitting $C_{JJ}(t)$ on a window $[t_1,t_2]$ with $t_1 \\gg \\tau_{\\mathrm{mic}}$ (where $\\tau_{\\mathrm{mic}}$ is a microscopic decorrelation time) to the functional form $A\\, t^{-3/2}$ and integrating the fitted tail from $t_c$ to $+\\infty$ yields an estimator whose asymptotic bias vanishes as $t_1, t_c \\to \\infty$, and which typically has reduced variance compared to pure truncation, provided the fit window is within the asymptotic regime.\n\nC. In the frequency domain, multiplying $C_{JJ}(t)$ by any smooth taper (window) and then evaluating the discrete Fourier transform at $\\omega=0$ always yields an unbiased estimate of $\\int_{0}^{\\infty} C_{JJ}(t)\\, dt$, because windowing only modifies high frequencies and cannot affect the zero-frequency limit.\n\nD. In the GLE framework, the Laplace transform $\\tilde{C}_{JJ}(s)=\\int_{0}^{\\infty} e^{-s t} C_{JJ}(t)\\, dt$ satisfies $\\tilde{C}_{JJ}(s)=\\dfrac{C_{JJ}(0)}{s+\\tilde{K}(s)}$, where $\\tilde{K}(s)=\\int_{0}^{\\infty} e^{-s t} K(t)\\, dt$ is the Laplace transform of the memory kernel. Therefore, if $\\tilde{K}(0)$ exists and is finite, then $\\int_{0}^{\\infty} C_{JJ}(t)\\, dt=\\tilde{C}_{JJ}(0)=\\dfrac{C_{JJ}(0)}{\\tilde{K}(0)}$. Estimating $K(t)$ from short-time data and inferring $\\tilde{K}(0)$ provides a noise-robust alternative route to the transport coefficient.\n\nE. Using the Kramers–Kronig relations (which connect real and imaginary parts of causal response functions), one can obtain the transport coefficient from the low-frequency behavior of a susceptibility. A linear extrapolation of finite-frequency data to $\\omega \\to 0$ is guaranteed to be unbiased for sufficiently long time series, independent of the choice of windowing or sampling scheme.", "solution": "The problem statement is a valid description of a standard problem in the statistical mechanics of transport phenomena. It is scientifically grounded, well-posed, and objective. It outlines the common challenge of computing transport coefficients from noisy molecular simulation data, where long-time tails are significant. I will proceed with the analysis of each proposed statement.\n\nThe core quantity is the transport coefficient $\\kappa$, given by the Green-Kubo formula:\n$$ \\kappa = \\beta \\int_{0}^{\\infty} C_{JJ}(t)\\, dt $$\nwhere $C_{JJ}(t) = \\langle J(0)J(t) \\rangle$ is the current autocorrelation function, and the simulation provides a noisy estimate of this function. The problem states that for long times in $d=3$, the function has a hydrodynamic tail:\n$$ C_{JJ}(t) \\sim A\\, t^{-3/2} \\quad \\text{as } t \\to \\infty $$\nwith $A > 0$. We must evaluate the correctness of five statements regarding strategies to compute the integral.\n\nA. In $d=3$, if $C_{JJ}(t) \\sim A\\, t^{-3/2}$ for large $t$, then direct truncation at a cutoff $t_c$ induces a tail bias equal to $\\int_{t_c}^{\\infty} A\\, t^{-3/2}\\, dt = 2A\\, t_c^{-1/2}$. For fixed total simulation time $T_{\\mathrm{tot}}$, the standard deviation of the truncated time integral typically scales like a constant times $t_c^{1/2}/T_{\\mathrm{tot}}^{1/2}$, indicating a bias–variance tradeoff in the choice of $t_c$.\n\nThis statement consists of three parts to be validated.\n1.  **Bias Calculation**: Direct truncation means approximating the full integral $\\int_{0}^{\\infty} C_{JJ}(t)\\, dt$ with the truncated integral $\\int_{0}^{t_c} C_{JJ}(t)\\, dt$. The error introduced by this truncation is the bias, which is the neglected part of the integral. Assuming for $t \\ge t_c$ the function is well-described by its asymptotic form, the bias is:\n    $$ \\text{Bias} = \\int_{t_c}^{\\infty} C_{JJ}(t)\\, dt \\approx \\int_{t_c}^{\\infty} A\\, t^{-3/2}\\, dt $$\n    This integral is elementary:\n    $$ \\int_{t_c}^{\\infty} A\\, t^{-3/2}\\, dt = A \\left[ \\frac{t^{-1/2}}{-1/2} \\right]_{t_c}^{\\infty} = A \\left[ -2t^{-1/2} \\right]_{t_c}^{\\infty} = A \\left( 0 - (-2t_c^{-1/2}) \\right) = 2A\\, t_c^{-1/2} $$\n    The calculation is correct. This bias is a systematic error that decreases as the cutoff time $t_c$ increases.\n\n2.  **Variance Scaling**: The estimator for the integral, $I(t_c) = \\int_{0}^{t_c} \\hat{C}_{JJ}(t)\\, dt$, is calculated from a noisy estimate $\\hat{C}_{JJ}(t)$ obtained from a simulation of total length $T_{\\mathrm{tot}}$. The variance of this estimator, $\\mathrm{Var}[I(t_c)]$, for $t_c$ much smaller than $T_{\\mathrm{tot}}$ but larger than microscopic correlation times, is known from the theory of statistical errors in time correlation function integrals. It scales proportionally to the integration time $t_c$ and inversely with the total simulation time $T_{\\mathrm{tot}}$.\n    $$ \\mathrm{Var}[I(t_c)] \\propto \\frac{t_c}{T_{\\mathrm{tot}}} $$\n    Therefore, the standard deviation, which is the square root of the variance, scales as:\n    $$ \\sigma[I(t_c)] = \\sqrt{\\mathrm{Var}[I(t_c)]} \\propto \\sqrt{\\frac{t_c}{T_{\\mathrm{tot}}}} = \\frac{t_c^{1/2}}{T_{\\mathrm{tot}}^{1/2}} $$\n    This part of the statement is also correct. The statistical error (variance) increases as $t_c$ increases because one integrates the noisy signal for a longer duration.\n\n3.  **Bias–Variance Tradeoff**: The bias decreases with $t_c$ (as $t_c^{-1/2}$), while the standard deviation increases with $t_c$ (as $t_c^{1/2}$). To minimize the total error (a combination of bias and variance), one must choose an optimal $t_c$. Increasing $t_c$ reduces systematic error (bias) at the cost of increasing statistical error (variance). This is the definition of a bias-variance tradeoff.\n\nThe statement is entirely correct. Verdict: **Correct**.\n\nB. If the true asymptotic tail is $C_{JJ}(t) \\sim A\\, t^{-3/2}$, then fitting $C_{JJ}(t)$ on a window $[t_1,t_2]$ with $t_1 \\gg \\tau_{\\mathrm{mic}}$ (where $\\tau_{\\mathrm{mic}}$ is a microscopic decorrelation time) to the functional form $A\\, t^{-3/2}$ and integrating the fitted tail from $t_c$ to $+\\infty$ yields an estimator whose asymptotic bias vanishes as $t_1, t_c \\to \\infty$, and which typically has reduced variance compared to pure truncation, provided the fit window is within the asymptotic regime.\n\nThis describes a standard tail-correction procedure. The total integral is estimated as:\n$$ \\int_0^{t_c} \\hat{C}_{JJ}(t)\\,dt + \\int_{t_c}^\\infty A_{\\mathrm{fit}} t^{-3/2}\\,dt = \\int_0^{t_c} \\hat{C}_{JJ}(t)\\,dt + 2A_{\\mathrm{fit}} t_c^{-1/2} $$\nHere, $A_{\\mathrm{fit}}$ is obtained by fitting the simulation data $\\hat{C}_{JJ}(t)$ to the form $A\\, t^{-3/2}$ over a suitable intermediate time window $[t_1, t_2]$.\n1.  **Asymptotic Bias**: The bias of this estimator arises from two sources: (i) the model error (the true function is not exactly $A\\, t^{-3/2}$ for finite $t$), and (ii) the statistical error in the fitted parameter $A_{\\mathrm{fit}}$. As the fitting window start time $t_1 \\to \\infty$, the model error vanishes because the function approaches its asymptotic form. The statistical error in $A_{\\mathrm{fit}}$ decreases with longer fitting windows or longer total simulation time. Thus, the estimator is consistent and its bias vanishes in the limit of an infinitely long simulation and fitting at appropriately large times. The statement that the asymptotic bias vanishes as $t_1, t_c \\to \\infty$ is correct.\n2.  **Variance Reduction**: The alternative to this procedure is to continue the direct integration of $\\hat{C}_{JJ}(t)$ to very long times (large $t_c$) to reduce the truncation bias. As established in A, this drastically increases the variance. The tail-fitting method uses prior knowledge about the functional form of the tail to effectively \"average\" the noisy data in the fitting window to obtain a single, more stable parameter $A_{\\mathrm{fit}}$. The contribution to the variance from the fitted tail is determined by the variance of $A_{\\mathrm{fit}}$. This is generally much smaller than the variance that would be accumulated by direct integration through the noisy long-time region. Thus, compared to a direct truncation at a $t_c$ that would yield a similarly low bias, the tail-fitting approach has a significantly reduced variance.\n\nThe statement correctly describes the desirable statistical properties of the tail-fitting method. Verdict: **Correct**.\n\nC. In the frequency domain, multiplying $C_{JJ}(t)$ by any smooth taper (window) and then evaluating the discrete Fourier transform at $\\omega=0$ always yields an unbiased estimate of $\\int_{0}^{\\infty} C_{JJ}(t)\\, dt$, because windowing only modifies high frequencies and cannot affect the zero-frequency limit.\n\nThis statement is incorrect on multiple grounds.\n1.  **Effect of Windowing**: The integral of interest is related to the zero-frequency component of the power spectrum. Let $S_{JJ}(\\omega)$ be the two-sided Fourier transform of $C_{JJ}(t)$. Since $C_{JJ}(t)$ is an even function of time, $\\int_0^\\infty C_{JJ}(t) dt = \\frac{1}{2} S_{JJ}(0) = \\frac{1}{2}\\int_{-\\infty}^\\infty C_{JJ}(t) dt$.\n    When we multiply the time-domain signal $C_{JJ}(t)$ by a window function $w(t)$, we are computing the Fourier transform of the product $C_w(t) = C_{JJ}(t)w(t)$. By the convolution theorem, the Fourier transform of this product is the convolution of their individual Fourier transforms: $\\mathcal{F}\\{C_w\\}(\\omega) = (\\mathcal{F}\\{C_{JJ}\\} * \\mathcal{F}\\{w\\})(\\omega) = (S_{JJ} * W)(\\omega)$, where $W(\\omega) = \\mathcal{F}\\{w\\}$.\n    The estimate for the integral is proportional to the value at $\\omega=0$:\n    $$ \\int_{-\\infty}^{\\infty} C_w(t)\\, dt = \\int_{-\\infty}^{\\infty} C_{JJ}(t)w(t)\\, dt $$\n    An unbiased estimator for $\\int C_{JJ}(t) dt$ requires that the expected value of the estimate is the true value. The expected value is $\\int C_{JJ}(t)w(t) dt$. This equals the true integral $\\int C_{JJ}(t) dt$ only if $w(t)=1$ everywhere that $C_{JJ}(t)$ is non-zero. Since any practical window function for a finite-length signal must go to zero, it will necessarily attenuate parts of the signal, thus introducing a bias. For example, a simple rectangular window (truncation) sets the signal to zero beyond a cutoff, clearly introducing a bias. Smooth tapers are designed to reduce variance (spectral leakage) at the cost of increased (but controlled) bias.\n2.  **Faulty Justification**: The reason provided, \"windowing only modifies high frequencies and cannot affect the zero-frequency limit,\" is fundamentally false. As shown by the convolution theorem, windowing affects *all* frequencies by spreading power from one frequency to others. This affects the value at $\\omega=0$. The value of the transformed signal at $\\omega=0$ is simply the integral of the windowed signal in the time domain, which is not the same as the integral of the original signal.\n\nVerdict: **Incorrect**.\n\nD. In the GLE framework, the Laplace transform $\\tilde{C}_{JJ}(s)=\\int_{0}^{\\infty} e^{-s t} C_{JJ}(t)\\, dt$ satisfies $\\tilde{C}_{JJ}(s)=\\dfrac{C_{JJ}(0)}{s+\\tilde{K}(s)}$, where $\\tilde{K}(s)=\\int_{0}^{\\infty} e^{-s t} K(t)\\, dt$ is the Laplace transform of the memory kernel. Therefore, if $\\tilde{K}(0)$ exists and is finite, then $\\int_{0}^{\\infty} C_{JJ}(t)\\, dt=\\tilde{C}_{JJ}(0)=\\dfrac{C_{JJ}(0)}{\\tilde{K}(0)}$. Estimating $K(t)$ from short-time data and inferring $\\tilde{K}(0)$ provides a noise-robust alternative route to the transport coefficient.\n\nThis statement describes an advanced but standard method based on the Mori-Zwanzig formalism.\n1.  **GLE Relation**: The evolution of the correlation function $C(t) = C_{JJ}(t)$ is governed by the memory equation:\n    $$ \\frac{dC(t)}{dt} = -\\int_0^t K(t-u)C(u)\\,du $$\n    Taking the one-sided Laplace transform of this equation yields:\n    $$ s\\tilde{C}(s) - C(0) = -\\tilde{K}(s)\\tilde{C}(s) $$\n    Rearranging for $\\tilde{C}(s)$ gives:\n    $$ \\tilde{C}(s) (s + \\tilde{K}(s)) = C(0) \\implies \\tilde{C}(s) = \\frac{C(0)}{s+\\tilde{K}(s)} $$\n    This formula is correct.\n2.  **Relation to the Integral**: The integral we seek is $\\int_0^\\infty C_{JJ}(t) dt$, which is precisely the definition of the Laplace transform $\\tilde{C}_{JJ}(s)$ evaluated at $s=0$. Taking the limit $s \\to 0$ in the above relation, we get:\n    $$ \\tilde{C}_{JJ}(0) = \\lim_{s\\to 0} \\frac{C_{JJ}(0)}{s + \\tilde{K}(s)} = \\frac{C_{JJ}(0)}{\\tilde{K}(0)} $$\n    This is valid provided that $\\tilde{K}(0) = \\int_0^\\infty K(t) dt$ exists, is finite, and is non-zero. For a system with a $t^{-3/2}$ tail in $C_{JJ}(t)$, mode-coupling theories predict that the memory kernel $K(t)$ decays faster, typically as $t^{-5/2}$. The integral of $t^{-5/2}$ converges, so $\\tilde{K}(0)$ is finite.\n3.  **Noise Robustness**: The fundamental idea behind this method is the separation of time scales. The memory kernel $K(t)$ often (though not always) decays on a much faster timescale than $C_{JJ}(t)$ itself. This means that $K(t)$ can be accurately determined from the short-time, low-noise part of the simulation data. Since its integral $\\tilde{K}(0)$ converges quickly, it is less susceptible to the long-time noise that plagues the direct integration of $C_{JJ}(t)$. $C_{JJ}(0)$ is a static property and is also typically easy to compute with high precision. Thus, this method provides an alternative path to the transport coefficient that can be significantly more robust to noise.\n\nThe statement is a correct representation of the theory and its practical application. Verdict: **Correct**.\n\nE. Using the Kramers–Kronig relations (which connect real and imaginary parts of causal response functions), one can obtain the transport coefficient from the low-frequency behavior of a susceptibility. A linear extrapolation of finite-frequency data to $\\omega \\to 0$ is guaranteed to be unbiased for sufficiently long time series, independent of the choice of windowing or sampling scheme.\n\nThis statement is incorrect due to a misunderstanding of the low-frequency behavior of systems with hydrodynamic tails.\n1.  **Low-Frequency Behavior**: The existence of a long-time tail in the correlation function $C_{JJ}(t) \\sim A t^{-3/2}$ has a direct and important consequence for the frequency spectrum $S_{JJ}(\\omega)$. The Fourier transform of a power-law function is non-analytic. Specifically, the $t^{-3/2}$ tail in the time domain corresponds to a non-analytic term in the frequency domain at $\\omega=0$:\n    $$ S_{JJ}(\\omega) = S_{JJ}(0) - B\\sqrt{|\\omega|} + O(\\omega) $$\n    where $B$ is a positive constant related to $A$. The presence of the $\\sqrt{|\\omega|}$ term means that the function $S_{JJ}(\\omega)$ has a cusp at $\\omega=0$ and is not differentiable there.\n2.  **Extrapolation Bias**: A linear extrapolation assumes that the function is analytic at $\\omega=0$ and can be approximated by a Taylor series, e.g., $S_{JJ}(\\omega) \\approx S_{JJ}(0) + c_1 \\omega + c_2 \\omega^2 + \\dots$. For an even function, the first odd term vanishes, so a linear-in-$\\omega^2$ fit would be the lowest order polynomial fit. However, any polynomial extrapolation is fundamentally incorrect because of the non-analytic $\\sqrt{|\\omega|}$ dependence. Such an extrapolation will systematically fail to capture the true behavior near $\\omega=0$ and will produce a biased estimate of $S_{JJ}(0)$.\n3.  **Guaranteed Unbiased**: The claim that the method is \"guaranteed to be unbiased\" is therefore false. It is, in fact, guaranteed to be biased for the very class of systems described in the problem setup. The other claims of independence from windowing are also unsupported, as established in the analysis of option C.\n\nVerdict: **Incorrect**.\n\nSummary:\n-   Option A: Correct.\n-   Option B: Correct.\n-   Option C: Incorrect.\n-   Option D: Correct.\n-   Option E: Incorrect.\n\nThe correct statements are A, B, and D.", "answer": "$$\\boxed{ABD}$$", "id": "2825461"}]}