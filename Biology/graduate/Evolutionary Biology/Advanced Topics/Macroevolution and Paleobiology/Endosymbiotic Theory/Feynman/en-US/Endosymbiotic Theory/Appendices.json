{
    "hands_on_practices": [
        {
            "introduction": "The endosymbiotic origin of mitochondria is thought to have provided the host with a profound bioenergetic advantage, fueling the evolution of eukaryotic complexity. The Lane-Martin hypothesis formalizes this idea by arguing that mitochondria decoupled energy production, which scales with membrane area, from cellular costs that scale with volume. This exercise  challenges you to translate this core bioenergetic principle into a quantitative model by deriving an expression for the net energy supply available per gene. This practice sharpens your ability to build mathematical formalisms from first principles and to reason quantitatively about major evolutionary transitions.",
            "id": "2703253",
            "problem": "A central prediction of the Lane–Martin bioenergetic theory is that endosymbiosis decouples energy supply from genome size by scaling adenosine triphosphate (ATP) production with respiratory membrane area, while many cellular costs scale with cell volume. Consider a eukaryotic cell at steady state in which mitochondria supply all ATP used by the cell. Let the total inner mitochondrial membrane area devoted to respiration be $A_{r}$, and let the net ATP synthesis rate density (ATP molecules per unit time per unit respiratory membrane area, already accounting for proton leak and coupling efficiency) be $j_{r}$. Thus, total mitochondrial ATP production rate is $J_{\\mathrm{prod}} = j_{r} A_{r}$. Assume the basal cellular ATP demand scales with cell volume $V$ with density $m_{v}$ (ATP molecules per unit time per unit volume), so that basal demand is $J_{\\mathrm{basal}} = m_{v} V$. In addition, maintaining mitochondrial deoxyribonucleic acid (mtDNA) imposes an ATP cost $s_{m}$ per mtDNA molecule per unit time, and there are $C_{m}$ mtDNA molecules per cell, giving an mtDNA-specific cost $J_{\\mathrm{mtDNA}} = s_{m} C_{m}$. Assume the steady-state net ATP available to power all gene-associated cellular work is the difference $J_{\\mathrm{net}} = J_{\\mathrm{prod}} - (J_{\\mathrm{basal}} + J_{\\mathrm{mtDNA}})$.\n\nLet the total number of nuclear gene copies per cell (including ploidy) be $G_{N}$, treated as a constant for the cell type considered. Let each mtDNA molecule encode $g_{m}$ genes, so the total number of mtDNA gene copies is $g_{m} C_{m}$. Define the ATP-per-gene supply $\\Phi$ as the steady-state net ATP available per unit time divided by the total number of gene copies that must be maintained and expressed, that is, total gene copies $G_{N} + g_{m} C_{m}$.\n\nStarting from these definitions and the steady-state assumption, and without invoking any specialized results beyond the scaling of production with area and costs with volume and copy number, derive a single closed-form analytic expression for $\\Phi$ as a function of $A_{r}$, $V$, and $C_{m}$, along with the constants $j_{r}$, $m_{v}$, $s_{m}$, $g_{m}$, and $G_{N}$. Express your final answer as an analytic expression. Do not include units in your final expression. You may assume the regime $J_{\\mathrm{prod}} > J_{\\mathrm{basal}} + J_{\\mathrm{mtDNA}}$ so that $\\Phi$ is positive.",
            "solution": "We are asked to derive an expression for the ATP-per-gene supply, denoted $\\Phi$, based on first principles of scaling: production with membrane area and costs with volume and copy number.\n\nBy definition, the total ATP production rate supplied by mitochondria is given by the product of the net ATP synthesis rate density and the total respiratory membrane area:\n$$\nJ_{\\mathrm{prod}} = j_{r} A_{r}.\n$$\nThe steady-state cellular ATP demand is decomposed into two parts. First, a basal maintenance cost that scales with cell volume:\n$$\nJ_{\\mathrm{basal}} = m_{v} V,\n$$\nwhere $m_{v}$ is the ATP demand density per unit volume. Second, a cost associated with maintaining, replicating, and expressing mitochondrial deoxyribonucleic acid (mtDNA), which scales linearly with the number of mtDNA molecules:\n$$\nJ_{\\mathrm{mtDNA}} = s_{m} C_{m},\n$$\nwhere $s_{m}$ is the ATP cost per mtDNA molecule per unit time and $C_{m}$ is the mtDNA copy number.\n\nUnder the steady-state assumption, the net ATP available to power gene-associated cellular work equals production minus the sum of demands:\n$$\nJ_{\\mathrm{net}} = J_{\\mathrm{prod}} - \\bigl(J_{\\mathrm{basal}} + J_{\\mathrm{mtDNA}}\\bigr) = j_{r} A_{r} - m_{v} V - s_{m} C_{m}.\n$$\n\nNext, we formalize the denominator: the total number of gene copies that must be maintained and expressed. The nuclear gene copies per cell (including ploidy) are taken as a constant $G_{N}$. Each mtDNA molecule carries $g_{m}$ genes, so the mtDNA gene copies are $g_{m} C_{m}$. Therefore, the total gene copies are\n$$\nG_{\\mathrm{tot}} = G_{N} + g_{m} C_{m}.\n$$\n\nBy the definition provided, the ATP-per-gene supply $\\Phi$ is the net ATP available per unit time divided by the total gene copies:\n$$\n\\Phi = \\frac{J_{\\mathrm{net}}}{G_{\\mathrm{tot}}}.\n$$\nSubstituting the expressions for $J_{\\mathrm{net}}$ and $G_{\\mathrm{tot}}$, we obtain\n$$\n\\Phi(A_{r}, V, C_{m}; j_{r}, m_{v}, s_{m}, g_{m}, G_{N}) = \\frac{j_{r} A_{r} - m_{v} V - s_{m} C_{m}}{G_{N} + g_{m} C_{m}}.\n$$\n\nWe can briefly verify dimensional consistency. The numerator has units of ATP per unit time: $j_{r} A_{r}$ is ATP per unit time, as is $m_{v} V$ and $s_{m} C_{m}$. The denominator is a pure count of gene copies. Hence, $\\Phi$ has units of ATP per unit time per gene copy, as intended. The assumed regime $j_{r} A_{r} > m_{v} V + s_{m} C_{m}$ ensures $\\Phi > 0$.\n\nThis expression captures the Lane–Martin intuition: increasing the respiratory membrane area $A_{r}$ raises $\\Phi$, increasing the cell volume $V$ reduces $\\Phi$ through elevated maintenance costs, and increasing mtDNA copy number $C_{m}$ imposes a trade-off by increasing both the numerator’s cost term and the denominator’s gene count, generally tending to reduce $\\Phi$ unless accompanied by compensatory increases in $A_{r}$ or $j_{r}$.",
            "answer": "$$\\boxed{\\frac{j_{r} A_{r} - m_{v} V - s_{m} C_{m}}{G_{N} + g_{m} C_{m}}}$$"
        },
        {
            "introduction": "The evolutionary journey of the mitochondrion involved a massive transfer of genetic material to the host nucleus, a process known as endosymbiotic gene transfer. This historical migration left a tangible \"fossil record\" in eukaryotic genomes in the form of nuclear mitochondrial DNA segments (NUMTs). This practice  invites you to model the dynamics of this genomic fossil record using a classic birth–death process, allowing you to calculate the expected equilibrium number of NUMTs. This exercise provides a hands-on application of stochastic modeling to understand how macroscopic genomic features evolve from microscopic rates of insertion and deletion.",
            "id": "2703231",
            "problem": "Endosymbiotic theory posits that the mitochondrion originated from an ancestral bacterium that became an obligate symbiont, with ongoing transfer of mitochondrial DNA to the nuclear genome over evolutionary time. A common footprint of this process is the presence of nuclear mitochondrial DNA segments (NUMTs) in the nuclear genome. Consider a minimal, well-mixed model of NUMT dynamics in a haploid nuclear genome of size $G$ base pairs. Assume the following:\n\n1. New NUMTs arise via independent insertion events that occur as a homogeneous Poisson process across the genome at a per-base rate $\\lambda$ per unit time, so that the total genome-wide insertion rate is $\\lambda G$, independent of the current number of NUMTs.\n2. Each existing NUMT is lost via deletion at a per-element rate $\\mu$ per unit time, independently of other NUMTs and of $G$.\n3. Let $X(t)$ denote the random number of NUMTs at time $t$, and let $n(t) = \\mathbb{E}[X(t)]$ denote the expected copy number. At initial time $t=0$, the expected copy number is $n(0)=n_{0}$, where $n_{0}\\ge 0$ is finite.\n\nUsing only these assumptions and standard properties of linear birth–death processes and expectations for continuous-time Markov chains, derive an expression for $n(t)$ and use it to determine the steady-state expected NUMT copy number as $t\\to\\infty$. Provide your final answer as a single closed-form expression in terms of $\\lambda$, $\\mu$, and $G$. Do not include units in your final answer. If you choose to present an intermediate time-dependent expression, it will not be graded; only the steady-state expression will be graded as the final answer.",
            "solution": "The evolution of the expected number of NUMTs, $n(t) = \\mathbb{E}[X(t)]$, can be described by a differential equation. The rate of change of $n(t)$, which is $\\frac{dn(t)}{dt}$, is the difference between the rate of gain (births) and the rate of loss (deaths) of NUMTs.\n\nThe process $X(t)$ is a continuous-time Markov chain on the non-negative integers. The change in the expectation over a small time interval $dt$ is given by:\n$$ n(t+dt) - n(t) = \\mathbb{E}[X(t+dt) - X(t)] $$\nAccording to the problem statement:\n1. The total rate of insertion (birth) is a constant, $\\lambda G$. This is an immigration process. The probability of one new insertion in a small interval $dt$ is $(\\lambda G) dt + o(dt)$.\n2. The rate of deletion (death) is proportional to the number of existing NUMTs. If the system is in state $k$ (i.e., $X(t) = k$), the total deletion rate is $k\\mu$. The probability of one deletion in $dt$, given $X(t)=k$, is $(k\\mu) dt + o(dt)$.\n\nUsing the property of linearity of expectation, we can write the time evolution of the expected value $n(t) = \\mathbb{E}[X(t)]$. The expected rate of increase is the total insertion rate, $\\lambda G$. The expected rate of decrease is the expectation of the total deletion rate, $\\mathbb{E}[\\mu X(t)]$. Since $\\mu$ is a constant, this is $\\mu \\mathbb{E}[X(t)] = \\mu n(t)$.\n\nTherefore, the dynamics of $n(t)$ are governed by the following first-order linear ordinary differential equation:\n$$ \\frac{dn(t)}{dt} = (\\text{Expected Rate of Gain}) - (\\text{Expected Rate of Loss}) $$\n$$ \\frac{dn(t)}{dt} = \\lambda G - \\mu n(t) $$\nThis equation is subject to the initial condition $n(0) = n_{0}$. We can rearrange the equation into standard form:\n$$ \\frac{dn(t)}{dt} + \\mu n(t) = \\lambda G $$\nThis is a first-order linear non-homogeneous differential equation. We solve it using an integrating factor, $I(t)$. The integrating factor is given by:\n$$ I(t) = \\exp\\left(\\int \\mu dt\\right) = \\exp(\\mu t) $$\nMultiplying the differential equation by $I(t)$:\n$$ \\exp(\\mu t) \\frac{dn(t)}{dt} + \\mu \\exp(\\mu t) n(t) = \\lambda G \\exp(\\mu t) $$\nThe left side of the equation is the derivative of the product $n(t) \\exp(\\mu t)$ with respect to $t$:\n$$ \\frac{d}{dt} \\left[ n(t) \\exp(\\mu t) \\right] = \\lambda G \\exp(\\mu t) $$\nIntegrating both sides with respect to $t$:\n$$ \\int \\frac{d}{dt} \\left[ n(t) \\exp(\\mu t) \\right] dt = \\int \\lambda G \\exp(\\mu t) dt $$\n$$ n(t) \\exp(\\mu t) = \\frac{\\lambda G}{\\mu} \\exp(\\mu t) + C $$\nwhere $C$ is the constant of integration. To find $n(t)$, we divide by $\\exp(\\mu t)$:\n$$ n(t) = \\frac{\\lambda G}{\\mu} + C \\exp(-\\mu t) $$\nWe use the initial condition $n(0) = n_{0}$ to determine the constant $C$:\n$$ n(0) = n_{0} = \\frac{\\lambda G}{\\mu} + C \\exp(0) $$\n$$ n_{0} = \\frac{\\lambda G}{\\mu} + C $$\n$$ C = n_{0} - \\frac{\\lambda G}{\\mu} $$\nSubstituting the expression for $C$ back into the general solution gives the complete time-dependent expression for the expected number of NUMTs:\n$$ n(t) = \\frac{\\lambda G}{\\mu} + \\left(n_{0} - \\frac{\\lambda G}{\\mu}\\right) \\exp(-\\mu t) $$\nThe question asks for the steady-state expected NUMT copy number, which is the limit of $n(t)$ as time $t$ approaches infinity. Let this steady-state value be $n_{ss}$.\n$$ n_{ss} = \\lim_{t \\to \\infty} n(t) = \\lim_{t \\to \\infty} \\left[ \\frac{\\lambda G}{\\mu} + \\left(n_{0} - \\frac{\\lambda G}{\\mu}\\right) \\exp(-\\mu t) \\right] $$\nFor a biologically meaningful process of loss, the deletion rate $\\mu$ must be a positive constant, $\\mu > 0$. Consequently, the term $\\exp(-\\mu t)$ approaches $0$ as $t \\to \\infty$.\n$$ \\lim_{t \\to \\infty} \\exp(-\\mu t) = 0 $$\nTherefore, the steady-state expected copy number is:\n$$ n_{ss} = \\frac{\\lambda G}{\\mu} + \\left(n_{0} - \\frac{\\lambda G}{\\mu}\\right) \\cdot 0 $$\n$$ n_{ss} = \\frac{\\lambda G}{\\mu} $$\nThis result represents the balance point where the constant rate of NUMT insertion is exactly matched by the expected rate of NUMT deletion.",
            "answer": "$$\\boxed{\\frac{\\lambda G}{\\mu}}$$"
        },
        {
            "introduction": "While most endosymbiont genes migrated to the nucleus, a small but critical subset was retained in the organellar genome. Explaining this retention pattern is a major goal of modern evolutionary research, with hypotheses like the CoRR (Colocation for Redox Regulation) theory proposing functional reasons. This exercise  moves from theory to application by asking you to design a valid statistical test for such a hypothesis, forcing you to grapple with the real-world complexities of comparative data. This problem develops the critical skill of designing rigorous tests for evolutionary hypotheses that account for phylogenetic non-independence and confounding variables, a cornerstone of modern evolutionary genomics.",
            "id": "2703261",
            "problem": "You are investigating the endosymbiotic gene retention bias predicted by the colocation for redox regulation (CoRR) hypothesis in the context of the electron transport chain (ETC). Specifically, you want to test whether redox-sensitive ETC core subunits are preferentially retained in organelle genomes independently of proteome hydrophobicity, across multiple eukaryotic lineages. Use the following foundational base to reason about a valid comparative test design: (i) correlated traits across species require phylogenetic comparative methods because observations are not independent under shared ancestry; (ii) gene presence in organelle genomes versus transfer to the nucleus is a binary outcome that can be modeled with a generalized linear model for binary data; (iii) hydrophobicity can confound retention because highly hydrophobic, multi-pass membrane proteins can be difficult to import post-translationally; (iv) orthology and protein-complex membership induce non-independence among observations at the gene level. You have assembled a dataset of orthologized ETC subunits from mitochondria and plastids across $S$ eukaryotic species with a dated species tree and variance-covariance matrix from Brownian motion, where for each protein $i$ in species $s$ you have: a retention status in the organelle genome $Y_{i,s}\\in\\{0,1\\}$, a redox-sensitivity annotation $R_{i}\\in\\{0,1\\}$ (based on structural proximity to redox-active centers in Complexes $I$–$IV$ or Photosystems), hydrophobicity metrics $H_{i,s}$ (e.g., transmembrane helix count and grand average of hydropathicity), and additional covariates such as protein length, expression proxies, targeting signals, and species-level genome features. Which study design would most directly and validly test the hypothesis that redox-sensitive ETC subunits are preferentially retained in organelle genomes independently of hydrophobicity?\n\nA. Fit a phylogenetic generalized linear mixed model (PGLMM) with a logistic link to the gene-level data across all species: model $\\Pr(Y_{i,s}=1)$ as a function of $R_{i}$, $H_{i,s}$, their interaction, and additional covariates; include a species-level random intercept with covariance proportional to the phylogenetic variance-covariance matrix, and random intercepts for ortholog group and protein complex to account for shared constraints. Test $H_{0}:\\beta_{R}=0$ versus $H_{1}:\\beta_{R}>0$ for the coefficient of $R_{i}$ while holding $H_{i,s}$ (and other covariates) constant. As a robustness check, perform constrained label permutations that shuffle $R_{i}$ within complexes and ortholog groups, preserving $H_{i,s}$ and phylogeny, to generate a null distribution for $\\hat{\\beta}_{R}$.\n\nB. Compute the pooled partial correlation between retention $Y$ and redox-sensitivity $R$ after regressing both on hydrophobicity $H$ using ordinary least squares across all proteins, then assess significance by a standard $t$-test, ignoring phylogeny and complex membership. Conclude preferential retention if the partial correlation remains positive and significant.\n\nC. For each species independently, conduct a Fisher’s exact test of $Y$ by $R$, then perform a fixed-effects inverse-variance meta-analysis across species. To remove hydrophobicity effects, first drop all proteins in the top hydrophobicity quartile, then re-run the pipeline. Conclude independence from hydrophobicity if the meta-analytic odds ratio remains greater than $1$.\n\nD. Within each species, match each redox-sensitive protein to a redox-insensitive protein with the closest hydrophobicity value (nearest-neighbor matching without replacement), then apply a paired McNemar test on matched pairs to compare retention frequencies, and finally average the within-species log-odds across species. Conclude independence from hydrophobicity if the average log-odds is positive and a one-sample $t$-test rejects $0$ at the chosen significance level.",
            "solution": "The problem asks for the most appropriate study design to test the colocation for redox regulation (CoRR) hypothesis, which predicts that redox-sensitive subunits of the electron transport chain (ETC) are preferentially retained in organelle genomes. The test must account for the confounding effect of protein hydrophobicity and multiple sources of non-independence in the data: shared ancestry among species, shared history of genes (orthology), and shared functional context (protein complex membership).\n\nThe goal is to model the probability of retention, $\\Pr(Y_{i,s}=1)$, as a function of redox sensitivity, $R_i$, while controlling for hydrophobicity, $H_{i,s}$, and accounting for the complex correlation structure. A valid model must address all four foundational principles.\n\n**Option A: Fit a phylogenetic generalized linear mixed model (PGLMM)...**\n\n-   **Analysis**: This design proposes a phylogenetic generalized linear mixed model (PGLMM). This is an advanced statistical framework specifically designed for problems of this nature.\n    1.  It uses a **generalized linear model** with a logistic link function, which is the correct approach for a binary response variable $Y_{i,s} \\in \\{0,1\\}$, as stated in principle (ii).\n    2.  It accounts for **phylogenetic non-independence** by including a species-level random intercept whose covariance structure is determined by the phylogenetic variance-covariance matrix. This correctly implements a phylogenetic comparative method, satisfying principle (i).\n    3.  It controls for the **confounding effect of hydrophobicity** by including $H_{i,s}$ as a fixed-effect covariate in the regression model. This is the standard, statistically powerful method for adjusting for a continuous confounder, fulfilling principle (iii). Investigating the interaction term is also good practice.\n    4.  It addresses the **gene-level non-independence** by incorporating random intercepts for ortholog groups and protein complexes. This correctly models the fact that observations on the same ortholog across different species, or on different proteins within the same complex, are not independent, as required by principle (iv).\n    5.  The null hypothesis test on the coefficient for redox sensitivity, $H_{0}:\\beta_{R}=0$, is a direct test of the central question. The proposed permutation test is a sophisticated and robust method for assessing significance that respects the data's dependency structure.\n\n-   **Verdict**: This option proposes a comprehensive and statistically sound approach that correctly addresses all the complexities laid out in the problem statement. It is the state-of-the-art method for this type of analysis. **Correct**.\n\n**Option B: Compute the pooled partial correlation... ignoring phylogeny and complex membership.**\n\n-   **Analysis**: This approach is fundamentally flawed.\n    1.  It proposes using **ordinary least squares (OLS)** to calculate residuals for a partial correlation. OLS is not the appropriate model for a binary outcome variable like $Y_{i,s}$.\n    2.  Most critically, it explicitly states to **ignore phylogeny and complex membership**. This directly violates principles (i) and (iv). Ignoring these sources of non-independence leads to pseudoreplication, which results in drastically underestimated standard errors and a highly inflated Type I error rate. The assumption of independent observations required for a standard $t$-test is grossly violated.\n\n-   **Verdict**: This design is statistically invalid and would produce unreliable, likely spurious, results. **Incorrect**.\n\n**Option C: For each species independently, conduct a Fisher’s exact test...**\n\n-   **Analysis**: This approach attempts to simplify the problem but introduces significant flaws.\n    1.  Analyzing each species independently and then combining results with a **meta-analysis** does not properly account for the known covariance structure due to phylogeny. This violates principle (i). The data points (per-species effect sizes) are not independent.\n    2.  The method for controlling for hydrophobicity—**discarding all proteins in the top hydrophobicity quartile**—is crude, arbitrary, and inefficient. It leads to a loss of statistical power and can introduce selection bias. The proper method is to include the confounder as a covariate in a model.\n    3.  This design fails to account for the non-independence due to orthology and complex membership, thus violating principle (iv).\n\n-   **Verdict**: This method is a sequence of improper statistical choices that fail to address the core challenges of the data structure. **Incorrect**.\n\n**Option D: Within each species, match each redox-sensitive protein...**\n\n-   **Analysis**: This design uses matching, a valid but often suboptimal technique, within a flawed larger framework.\n    1.  Like option C, this is a **species-by-species analysis**. Averaging the resulting log-odds across species is not a valid phylogenetic comparative method and fails to properly model the non-independence due to shared ancestry, violating principle (i).\n    2.  While **matching** on hydrophobicity is a valid concept for controlling for confounding, nearest-neighbor matching can be inefficient and sensitive to the distribution of the covariate. It also discards unmatched data. Regression adjustment, as proposed in option A, is generally superior.\n    3.  This design also completely ignores the non-independence at the gene level arising from orthology and protein complex membership, violating principle (iv). A McNemar test on pairs within a species does not resolve this issue.\n\n-   **Verdict**: This approach fails to correctly incorporate the phylogenetic and gene-level dependency structures of the data. **Incorrect**.\n\nIn conclusion, only Option A presents a statistically rigorous and comprehensive design that correctly integrates all the necessary components outlined in the problem statement: a proper model for binary data, and explicit handling of all specified sources of non-independence (phylogeny, orthology, complex membership) while correctly controlling for confounding variables.",
            "answer": "$$\\boxed{A}$$"
        }
    ]
}