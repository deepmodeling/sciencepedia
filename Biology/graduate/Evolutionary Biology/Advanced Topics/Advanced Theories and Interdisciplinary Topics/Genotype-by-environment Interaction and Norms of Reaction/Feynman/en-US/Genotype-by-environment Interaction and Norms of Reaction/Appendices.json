{
    "hands_on_practices": [
        {
            "introduction": "To quantitatively study genotype-by-environment interactions, we must first learn how to partition the total observed phenotypic variance ($V_P$) into its underlying causal components. This foundational exercise guides you through the derivation of the classic variance decomposition model in quantitative genetics . By engaging with this problem, you will not only understand the contribution of genetic variance ($V_G$), environmental variance ($V_E$), and genotype-by-environment interaction variance ($V_{G \\times E}$), but also appreciate how experimental design principles like randomization are essential for obtaining unbiased estimates of these components.",
            "id": "2718943",
            "problem": "A researcher studies reaction norms of a clonal panel across a controlled set of environments to quantify how phenotypic values depend on genotype and environment. For each clone and environment, the observed phenotype is modeled as the sum of a baseline plus contributions from genetic, environmental, and interaction components, together with measurement noise. Specifically, for a randomly sampled individual, let the phenotype be represented as\n$$\nP \\;=\\; \\mu \\;+\\; G \\;+\\; E \\;+\\; I_{G\\times E} \\;+\\; I_{G\\times G} \\;+\\; \\epsilon,\n$$\nwhere $P$ is the phenotype, $\\mu$ is a constant baseline, $G$ is the additive genetic contribution, $E$ is the environmental contribution indexing the realized macro-environment, $I_{G\\times E}$ is the genotype-by-environment interaction capturing non-parallel reaction norms, $I_{G\\times G}$ is epistatic deviation (genotype-by-genotype interaction), and $\\epsilon$ is the residual measurement noise. Assume $G$, $E$, $I_{G\\times E}$, $I_{G\\times G}$, and $\\epsilon$ are random variables with means $0$, and that $I_{G\\times E}$, $I_{G\\times G}$, and $\\epsilon$ are uncorrelated with $G$ and $E$ by construction of orthogonal random effects in a linear mixed-effects representation of reaction norms, except possibly for a nonzero $\\operatorname{Cov}(G,E)$ when genotypes are not randomized across environments. The quantities $V_G$, $V_E$, $V_{G\\times E}$, $V_{G\\times G}$, and $V_{\\epsilon}$ denote the variances of $G$, $E$, $I_{G\\times E}$, $I_{G\\times G}$, and $\\epsilon$, respectively.\n\nYour tasks are:\n- Starting only from the representation of $P$ as a sum of components and from the variance identity $\\operatorname{Var}(X+Y)=\\operatorname{Var}(X)+\\operatorname{Var}(Y)+2\\operatorname{Cov}(X,Y)$, derive an expression for the phenotypic variance $V_P \\equiv \\operatorname{Var}(P)$ in terms of $V_G$, $V_E$, $V_{G\\times E}$, $V_{G\\times G}$, $V_{\\epsilon}$, and any nonzero covariance terms that remain under the assumptions given.\n- Using first principles of experimental design, identify when $2\\operatorname{Cov}(G,E)$ is guaranteed to be $0$ by design in studies of norms of reaction.\n- In a common garden experiment with full randomization of genotypes across environments (so that the relevant design conditions you identify hold), suppose that $V_G = 2.4$, $V_E = 1.3$, $V_{G\\times E} = 0.8$, $V_{G\\times G} = 0.5$, and $V_{\\epsilon} = 0.6$. Compute $V_P$ for this design. Round your numerical answer to four significant figures. Express the final result as a pure number (no units).",
            "solution": "The problem as stated is subjected to validation before a solution is attempted.\n\nThe givens are:\nThe phenotypic model: $P \\;=\\; \\mu \\;+\\; G \\;+\\; E \\;+\\; I_{G\\times E} \\;+\\; I_{G\\times G} \\;+\\; \\epsilon$.\nComponent definitions: $\\mu$ is a constant baseline; $G$ is the additive genetic contribution; $E$ is the environmental contribution; $I_{G\\times E}$ is the genotype-by-environment interaction; $I_{G\\times G}$ is epistatic deviation; $\\epsilon$ is residual measurement noise.\nStatistical assumptions: $G$, $E$, $I_{G\\times E}$, $I_{G\\times G}$, and $\\epsilon$ are random variables with mean $0$. The components $I_{G\\times E}$, $I_{G\\times G}$, and $\\epsilon$ are uncorrelated with $G$ and $E$. They are also described as orthogonal random effects, which implies they are mutually uncorrelated. The covariance $\\operatorname{Cov}(G,E)$ may be non-zero.\nVariance definitions: $V_P = \\operatorname{Var}(P)$, $V_G = \\operatorname{Var}(G)$, $V_E = \\operatorname{Var}(E)$, $V_{G\\times E} = \\operatorname{Var}(I_{G\\times E})$, $V_{G\\times G} = \\operatorname{Var}(I_{G\\times G})$, and $V_{\\epsilon} = \\operatorname{Var}(\\epsilon)$.\nThe fundamental identity for variance of a sum: $\\operatorname{Var}(X+Y)=\\operatorname{Var}(X)+\\operatorname{Var}(Y)+2\\operatorname{Cov}(X,Y)$.\nFor the final calculation, numerical values are provided: $V_G = 2.4$, $V_E = 1.3$, $V_{G\\times E} = 0.8$, $V_{G\\times G} = 0.5$, and $V_{\\epsilon} = 0.6$ under conditions of a fully randomized common garden experiment.\n\nThe problem is scientifically grounded in the principles of quantitative genetics and experimental design. The linear model for partitioning phenotypic variance is a standard and fundamental concept. The problem is well-posed, with all necessary definitions and conditions specified for a unique solution. The language is objective and precise. The problem is therefore valid. We may proceed with the solution.\n\nThe first task is to derive an expression for the total phenotypic variance, $V_P$. We begin with the definition of the phenotype, $P$.\n$$\nP \\;=\\; \\mu \\;+\\; G \\;+\\; E \\;+\\; I_{G\\times E} \\;+\\; I_{G\\times G} \\;+\\; \\epsilon\n$$\nThe variance of $P$, denoted $V_P$, is $\\operatorname{Var}(P)$. Since $\\mu$ is a constant, its variance is $0$, and it does not covary with any random variable. Thus, it does not contribute to $V_P$.\n$$\nV_P = \\operatorname{Var}(G \\;+\\; E \\;+\\; I_{G\\times E} \\;+\\; I_{G\\times G} \\;+\\; \\epsilon)\n$$\nThe variance of a sum of several random variables is the sum of their individual variances plus twice the sum of all unique pairwise covariances. Let the random components be $X_1 = G$, $X_2 = E$, $X_3 = I_{G\\times E}$, $X_4 = I_{G\\times G}$, and $X_5 = \\epsilon$. The general formula is:\n$$\n\\operatorname{Var}\\left(\\sum_i X_i\\right) = \\sum_i \\operatorname{Var}(X_i) + 2 \\sum_{i<j} \\operatorname{Cov}(X_i, X_j)\n$$\nApplying this to our model, we have:\n$$\nV_P = \\operatorname{Var}(G) + \\operatorname{Var}(E) + \\operatorname{Var}(I_{G\\times E}) + \\operatorname{Var}(I_{G\\times G}) + \\operatorname{Var}(\\epsilon) + 2\\sum_{\\text{pairs}} \\operatorname{Cov}\n$$\nThe sum of variances is, by definition, $V_G + V_E + V_{G\\times E} + V_{G\\times G} + V_{\\epsilon}$. Now, we must evaluate the covariance terms based on the problem's assumptions.\nThe term $\\operatorname{Cov}(G,E)$ is explicitly stated to be potentially non-zero.\nThe problem states that $I_{G\\times E}$, $I_{G\\times G}$, and $\\epsilon$ are uncorrelated with $G$ and $E$. This implies:\n$\\operatorname{Cov}(G, I_{G\\times E})=0$, $\\operatorname{Cov}(G, I_{G\\times G})=0$, $\\operatorname{Cov}(G, \\epsilon)=0$.\n$\\operatorname{Cov}(E, I_{G\\times E})=0$, $\\operatorname{Cov}(E, I_{G\\times G})=0$, $\\operatorname{Cov}(E, \\epsilon)=0$.\nFurthermore, the description of these terms as \"orthogonal random effects\" implies they are mutually uncorrelated. This means:\n$\\operatorname{Cov}(I_{G\\times E}, I_{G\\times G})=0$, $\\operatorname{Cov}(I_{G\\times E}, \\epsilon)=0$, $\\operatorname{Cov}(I_{G\\times G}, \\epsilon)=0$.\nTherefore, the only covariance term that is not necessarily zero is $\\operatorname{Cov}(G,E)$. The complete expression for the phenotypic variance is:\n$$\nV_P = V_G + V_E + V_{G\\times E} + V_{G\\times G} + V_{\\epsilon} + 2\\operatorname{Cov}(G,E)\n$$\n\nThe second task is to identify the experimental design condition that guarantees $2\\operatorname{Cov}(G,E)=0$. The term $\\operatorname{Cov}(G,E)$ is the genotype-environment covariance. It is non-zero if particular genotypes are systematically associated with particular environments. For instance, if genotypes with higher potential yields (higher $G$) are preferentially placed in more fertile environments (higher $E$), $\\operatorname{Cov}(G,E)$ will be positive. To ensure $\\operatorname{Cov}(G,E)=0$, any such systematic association must be eliminated. The fundamental principle of experimental design that accomplishes this is **randomization**. In the context of studying norms of reaction, this requires that individuals representing the different genotypes (or clones) are randomly allocated across the full range of experimental environments. If every genotype has an equal probability of being raised in any given environment, then the genetic and environmental effects are by construction statistically independent, and their covariance will be zero. Common garden experiments, where different genotypes are grown together in a set of environments, must employ such a randomization protocol to eliminate this covariance.\n\nThe third task is a numerical calculation. We are given a common garden experiment with \"full randomization of genotypes across environments.\" Based on the reasoning for the second task, this design ensures that $\\operatorname{Cov}(G,E) = 0$. The expression for $V_P$ thus simplifies to:\n$$\nV_P = V_G + V_E + V_{G\\times E} + V_{G\\times G} + V_{\\epsilon}\n$$\nWe are provided with the following numerical values for the variance components: $V_G = 2.4$, $V_E = 1.3$, $V_{G\\times E} = 0.8$, $V_{G\\times G} = 0.5$, and $V_{\\epsilon} = 0.6$. Substituting these values into the simplified equation gives:\n$$\nV_P = 2.4 + 1.3 + 0.8 + 0.5 + 0.6\n$$\nPerforming the summation:\n$$\nV_P = (2.4 + 1.3) + (0.8 + 0.5) + 0.6 = 3.7 + 1.3 + 0.6 = 5.0 + 0.6 = 5.6\n$$\nThe problem requires the answer to be rounded to four significant figures. The calculated value $5.6$ must be expressed as $5.600$.",
            "answer": "$$\\boxed{5.600}$$"
        },
        {
            "introduction": "Beyond simply identifying GxE, a central goal of evolutionary biology is to predict how it evolves. This problem challenges you to apply the multivariate breeder's equation to the parameters of a reaction norm—its intercept ($\\alpha$) and slope ($\\beta$)—treating them as correlated heritable traits . You will derive the generational change in the population's average reaction norm by calculating environment-dependent selection gradients and combining them with the genetic (co)variance matrix ($\\mathbf{G}$), providing a powerful link between selection, genetics, and the evolution of plasticity.",
            "id": "2718891",
            "problem": "Consider a linear reaction norm for a quantitative phenotype under genotype-by-environment (G×E) interaction, where the phenotype expressed by an individual with reaction norm parameters is given by $z(E)=\\alpha+\\beta E$, with $E$ denoting an environmental covariate. Assume that environments experienced during selection are distributed as $E \\sim \\mathcal{N}(\\mu_{E},\\sigma_{E}^{2})$, independently of genotype. Suppose that relative fitness in environment $E$ for an individual expressing phenotype $z$ is\n$$\nW(z,E)=\\exp\\!\\big((b_{0}+b_{1}E)\\,z\\big),\n$$\nwhere $b_{0}$ and $b_{1}$ are constants that parameterize a log-linear, environment-dependent directional selection on the phenotype. Assume a standard additive genetic model for the reaction norm parameters $(\\alpha,\\beta)$ with constant additive genetic (co)variance matrix\n$$\n\\mathbf{G}=\\begin{pmatrix}G_{\\alpha\\alpha}&G_{\\alpha\\beta}\\\n$$4pt]G_{\\alpha\\beta}&G_{\\beta\\beta}\\end{pmatrix},\n$$\nrandom mating, and no genotype-by-environment covariance in the distribution of $E$ (i.e., the environmental distribution is the same across genotypes). Work at the population mean reaction norm.\n\nUsing core quantitative genetic principles that connect evolutionary response to additive genetic covariances and selection gradients, and defining selection gradients on the reaction norm parameters via the derivative of the logarithm of relative fitness, derive closed-form analytic expressions for the one-generation changes $\\Delta \\alpha$ and $\\Delta \\beta$ in terms of $G_{\\alpha\\alpha}$, $G_{\\alpha\\beta}$, $G_{\\beta\\beta}$, $\\mu_{E}$, $\\sigma_{E}^{2}$, $b_{0}$, and $b_{1}$. Express your final answer as a single row vector $\\big(\\Delta \\alpha,\\ \\Delta \\beta\\big)$.\n\nNo numerical approximation or rounding is required. Your final answer must be a closed-form expression.",
            "solution": "The problem statement is subjected to validation.\n\nStep 1: Extraction of Givens.\n- The phenotype $z$ is a linear function of an environmental covariate $E$: $z(E)=\\alpha+\\beta E$. The parameters $\\alpha$ (intercept) and $\\beta$ (slope) define the reaction norm.\n- The environmental covariate $E$ follows a normal distribution: $E \\sim \\mathcal{N}(\\mu_{E},\\sigma_{E}^{2})$.\n- The relative fitness $W$ of an individual with phenotype $z$ in environment $E$ is given by $W(z,E)=\\exp\\big((b_{0}+b_{1}E)\\,z\\big)$, where $b_0$ and $b_1$ are constants.\n- The reaction norm parameters $(\\alpha, \\beta)$ are heritable traits with a constant additive genetic covariance matrix $\\mathbf{G}$:\n$$\n\\mathbf{G}=\\begin{pmatrix}G_{\\alpha\\alpha}&G_{\\alpha\\beta}\\\\G_{\\alpha\\beta}&G_{\\beta\\beta}\\end{pmatrix}\n$$\n- The problem assumes random mating and no genotype-by-environment covariance in the distribution of $E$.\n- The task is to derive the one-generation changes in the mean reaction norm parameters, $\\Delta \\alpha$ and $\\Delta \\beta$.\n- The method prescribed is to use the multivariate breeder's equation, where selection gradients on reaction norm parameters are defined via the derivative of the logarithm of relative fitness.\n\nStep 2: Validation of Givens.\nThe problem is scientifically grounded, being a standard formulation in evolutionary quantitative genetics concerning the evolution of reaction norms. The specified models for the phenotype, fitness, and genetic architecture are canonical and widely used in theoretical studies (e.g., following the framework of Lande and Arnold). The problem is well-posed, providing all necessary information, parameters, and functional forms to derive a unique analytical solution. The terminology is precise and objective. There are no contradictions, missing data, or unscientific claims. The minor typographical error in the provided LaTeX for the matrix $\\mathbf{G}$ does not affect the conceptual validity of the problem.\n\nVerdict: The problem is valid.\n\nWe proceed with the derivation. The fundamental equation of multivariate quantitative genetics describes the per-generation evolutionary response of a vector of mean trait values, $\\Delta\\bar{\\mathbf{a}}$, to selection:\n$$\n\\Delta\\bar{\\mathbf{a}} = \\mathbf{G} \\boldsymbol{\\beta}_{s}\n$$\nIn this problem, the traits are the parameters of the reaction norm, $\\alpha$ and $\\beta$. We define the vector of traits as $\\mathbf{a} = \\begin{pmatrix} \\alpha & \\beta \\end{pmatrix}^T$. The change in the population mean values is thus $\\Delta\\bar{\\mathbf{a}} = \\begin{pmatrix} \\Delta \\alpha & \\Delta \\beta \\end{pmatrix}^T$, following the notation of the problem. The matrix $\\mathbf{G}$ is the additive genetic variance-covariance matrix for these traits, as given. The vector $\\boldsymbol{\\beta}_{s} = \\begin{pmatrix} \\beta_{\\alpha} & \\beta_{\\beta} \\end{pmatrix}^T$ contains the selection gradients on $\\alpha$ and $\\beta$.\n\nThe problem states that selection gradients are defined via the derivative of the logarithm of relative fitness. This implies the selection gradient on a trait is the expectation, over all sources of environmental variation, of the partial derivative of the logarithm of individual relative fitness with respect to that trait. First, we find the logarithm of the relative fitness function, which we denote $w(\\alpha, \\beta, E)$:\n$$\nw(\\alpha, \\beta, E) = \\ln\\Big( W(z(E), E) \\Big) = \\ln\\left( \\exp\\big( (b_{0}+b_{1}E)z(E) \\big) \\right) = (b_{0}+b_{1}E)z(E)\n$$\nSubstituting the expression for the phenotype, $z(E) = \\alpha + \\beta E$:\n$$\nw(\\alpha, \\beta, E) = (b_{0}+b_{1}E)(\\alpha + \\beta E) = b_{0}\\alpha + b_{0}\\beta E + b_{1}\\alpha E + b_{1}\\beta E^{2}\n$$\nThe selection gradients on the reaction norm parameters, $\\beta_{\\alpha}$ and $\\beta_{\\beta}$, are the expectations of the partial derivatives of $w$ with respect to $\\alpha$ and $\\beta$. The expectation is taken over the distribution of the environment, $E$.\n\nFirst, we calculate the partial derivatives:\n$$\n\\frac{\\partial w}{\\partial \\alpha} = b_{0} + b_{1}E\n$$\n$$\n\\frac{\\partial w}{\\partial \\beta} = b_{0}E + b_{1}E^{2}\n$$\nNext, we compute the expectation of these expressions over the distribution $E \\sim \\mathcal{N}(\\mu_{E},\\sigma_{E}^{2})$.\n\nThe selection gradient on the intercept, $\\alpha$, is:\n$$\n\\beta_{\\alpha} = \\mathbb{E}_{E}\\left[\\frac{\\partial w}{\\partial \\alpha}\\right] = \\mathbb{E}_{E}[b_{0} + b_{1}E]\n$$\nBy linearity of expectation:\n$$\n\\beta_{\\alpha} = b_{0} + b_{1}\\mathbb{E}_{E}[E]\n$$\nGiven that $\\mathbb{E}_{E}[E] = \\mu_{E}$, we have:\n$$\n\\beta_{\\alpha} = b_{0} + b_{1}\\mu_{E}\n$$\nThe selection gradient on the slope, $\\beta$, is:\n$$\n\\beta_{\\beta} = \\mathbb{E}_{E}\\left[\\frac{\\partial w}{\\partial \\beta}\\right] = \\mathbb{E}_{E}[b_{0}E + b_{1}E^{2}]\n$$\nBy linearity of expectation:\n$$\n\\beta_{\\beta} = b_{0}\\mathbb{E}_{E}[E] + b_{1}\\mathbb{E}_{E}[E^{2}]\n$$\nWe know $\\mathbb{E}_{E}[E] = \\mu_{E}$. For the second moment, $\\mathbb{E}_{E}[E^{2}]$, we use the identity $\\text{Var}(E) = \\mathbb{E}[E^{2}] - (\\mathbb{E}[E])^{2}$. This gives $\\mathbb{E}[E^{2}] = \\text{Var}(E) + (\\mathbb{E}[E])^{2} = \\sigma_{E}^{2} + \\mu_{E}^{2}$. Substituting these moments:\n$$\n\\beta_{\\beta} = b_{0}\\mu_{E} + b_{1}(\\sigma_{E}^{2} + \\mu_{E}^{2})\n$$\nWe can now assemble the selection gradient vector:\n$$\n\\boldsymbol{\\beta}_{s} = \\begin{pmatrix} \\beta_{\\alpha} \\\\ \\beta_{\\beta} \\end{pmatrix} = \\begin{pmatrix} b_{0} + b_{1}\\mu_{E} \\\\ b_{0}\\mu_{E} + b_{1}(\\sigma_{E}^{2} + \\mu_{E}^{2}) \\end{pmatrix}\n$$\nFinally, we compute the evolutionary response vector $\\begin{pmatrix} \\Delta \\alpha & \\Delta \\beta \\end{pmatrix}^T$ by multiplying the genetic covariance matrix $\\mathbf{G}$ by the selection gradient vector $\\boldsymbol{\\beta}_{s}$:\n$$\n\\begin{pmatrix} \\Delta \\alpha \\\\ \\Delta \\beta \\end{pmatrix} = \\mathbf{G} \\boldsymbol{\\beta}_{s} = \\begin{pmatrix} G_{\\alpha\\alpha} & G_{\\alpha\\beta} \\\\ G_{\\alpha\\beta} & G_{\\beta\\beta} \\end{pmatrix} \\begin{pmatrix} b_{0} + b_{1}\\mu_{E} \\\\ b_{0}\\mu_{E} + b_{1}(\\sigma_{E}^{2} + \\mu_{E}^{2}) \\end{pmatrix}\n$$\nPerforming the matrix-vector multiplication yields the individual expressions for $\\Delta \\alpha$ and $\\Delta \\beta$:\n$$\n\\Delta \\alpha = G_{\\alpha\\alpha}(b_{0} + b_{1}\\mu_{E}) + G_{\\alpha\\beta}\\big(b_{0}\\mu_{E} + b_{1}(\\sigma_{E}^{2} + \\mu_{E}^{2})\\big)\n$$\n$$\n\\Delta \\beta = G_{\\alpha\\beta}(b_{0} + b_{1}\\mu_{E}) + G_{\\beta\\beta}\\big(b_{0}\\mu_{E} + b_{1}(\\sigma_{E}^{2} + \\mu_{E}^{2})\\big)\n$$\nThe problem requires the final answer as a single row vector $(\\Delta \\alpha, \\Delta \\beta)$.",
            "answer": "$$\n\\boxed{\n\\begin{pmatrix}\nG_{\\alpha\\alpha}(b_{0} + b_{1}\\mu_{E}) + G_{\\alpha\\beta}\\left(b_{0}\\mu_{E} + b_{1}(\\sigma_{E}^{2} + \\mu_{E}^{2})\\right)\n&\nG_{\\alpha\\beta}(b_{0} + b_{1}\\mu_{E}) + G_{\\beta\\beta}\\left(b_{0}\\mu_{E} + b_{1}(\\sigma_{E}^{2} + \\mu_{E}^{2})\\right)\n\\end{pmatrix}\n}\n$$"
        },
        {
            "introduction": "Theoretical models provide insight, but real-world applications require grappling with statistical uncertainty. A significant consequence of GxE is rank reversal, where the \"best\" genotype changes across environments, and this computational exercise introduces a modern, simulation-based approach to quantify the probability of such reversals . By sampling from the posterior distribution of genotype performance, you will use Monte Carlo methods to directly estimate the likelihood of rank changes, a practical skill for interpreting experimental data in genetics, agriculture, and evolutionary studies.",
            "id": "2718879",
            "problem": "Consider a set of $K$ genotypes evaluated in $2$ environments. Let the reaction norm of genotype $g$ be the mapping from environment to expected phenotype (e.g., a mean performance), and let genotype-by-environment interaction occur when reaction norms are non-parallel. A rank reversal is an instance where the identity of the top-performing genotype differs between the two environments. Under uncertainty, we model the joint posterior distribution of the environment-specific genotype means as multivariate normal. Specifically, define the random vector\n$$\n\\boldsymbol{\\theta} = \\big(\\mu_{1,1}, \\mu_{2,1}, \\ldots, \\mu_{K,1}, \\mu_{1,2}, \\mu_{2,2}, \\ldots, \\mu_{K,2}\\big)^{\\top},\n$$\nwhere $\\mu_{g,e}$ is the posterior mean performance of genotype $g$ in environment $e \\in \\{1,2\\}$. Assume the joint posterior of $\\boldsymbol{\\theta}$ is multivariate normal with mean $\\boldsymbol{\\mu} \\in \\mathbb{R}^{2K}$ and positive definite covariance matrix $\\boldsymbol{\\Sigma} \\in \\mathbb{R}^{2K \\times 2K}$, written as $\\boldsymbol{\\theta} \\sim \\mathcal{N}(\\boldsymbol{\\mu}, \\boldsymbol{\\Sigma})$. This assumption is justified by well-tested large-sample asymptotics (e.g., the Central Limit Theorem and the asymptotic normality of maximum likelihood estimators) or by conjugate Bayesian analysis under normal likelihoods with known variance, leading to normal posteriors for means.\n\nDefine the event of rank reversal under uncertainty as\n$$\n\\mathcal{R} = \\left\\{ \\operatorname*{arg\\,max}_{g \\in \\{1,\\ldots,K\\}} \\mu_{g,1} \\;\\neq\\; \\operatorname*{arg\\,max}_{g \\in \\{1,\\ldots,K\\}} \\mu_{g,2} \\right\\}.\n$$\nThe probability of rank reversal is then\n$$\np_{\\mathrm{rev}} = \\mathbb{P}(\\mathcal{R}) = \\int \\mathbf{1}\\left\\{ \\operatorname*{arg\\,max}_{g} \\theta_{g,1} \\neq \\operatorname*{arg\\,max}_{g} \\theta_{g,2} \\right\\} \\, \\phi(\\boldsymbol{\\theta} \\,|\\, \\boldsymbol{\\mu}, \\boldsymbol{\\Sigma}) \\, d\\boldsymbol{\\theta},\n$$\nwhere $\\phi(\\cdot \\,|\\, \\boldsymbol{\\mu}, \\boldsymbol{\\Sigma})$ is the multivariate normal density and $\\mathbf{1}\\{\\cdot\\}$ is the indicator function. This integral is not available in closed form for general $K$ and covariance structures. However, it is a probability that can be approximated arbitrarily well via Monte Carlo integration by sampling from the joint posterior $\\mathcal{N}(\\boldsymbol{\\mu}, \\boldsymbol{\\Sigma})$.\n\nTask. Write a program that estimates $p_{\\mathrm{rev}}$ by Monte Carlo sampling for a set of five test cases. For each test case $i \\in \\{1,\\ldots,5\\}$, you are given:\n- an integer $K$,\n- a vector $\\boldsymbol{\\mu}^{(i)} \\in \\mathbb{R}^{2K}$ ordered as $\\left(\\mu_{1,1}, \\mu_{2,1}, \\ldots, \\mu_{K,1}, \\mu_{1,2}, \\ldots, \\mu_{K,2}\\right)$,\n- a covariance matrix $\\boldsymbol{\\Sigma}^{(i)} \\in \\mathbb{R}^{2K \\times 2K}$,\n- a Monte Carlo sample size $N^{(i)}$,\n- a random seed $s^{(i)}$ for reproducibility.\n\nFor each test case, estimate $p_{\\mathrm{rev}}$ by drawing $N^{(i)}$ independent samples $\\boldsymbol{\\theta}^{(b)} \\sim \\mathcal{N}(\\boldsymbol{\\mu}^{(i)}, \\boldsymbol{\\Sigma}^{(i)})$ for $b \\in \\{1,\\ldots,N^{(i)}\\}$, computing\n$$\n\\hat{p}_{\\mathrm{rev}}^{(i)} = \\frac{1}{N^{(i)}} \\sum_{b=1}^{N^{(i)}} \\mathbf{1}\\left\\{ \\operatorname*{arg\\,max}_{g} \\theta^{(b)}_{g,1} \\neq \\operatorname*{arg\\,max}_{g} \\theta^{(b)}_{g,2} \\right\\},\n$$\nand returning $\\hat{p}_{\\mathrm{rev}}^{(i)}$ as a floating-point number rounded to $4$ decimal places.\n\nUse the following test suite. In all cases, the ordering of entries in $\\boldsymbol{\\mu}$ is the first $K$ entries for environment $1$ followed by $K$ entries for environment $2$.\n\n- Test case $1$ (clear crossing reaction norms, near-certain rank reversal):\n  - $K = 2$,\n  - $\\boldsymbol{\\mu}^{(1)} = [\\, 1.0,\\, 0.0,\\, 0.0,\\, 1.0 \\,]$,\n  - $\\boldsymbol{\\Sigma}^{(1)} = \\mathrm{diag}([\\, 0.0001,\\, 0.0001,\\, 0.0001,\\, 0.0001 \\,])$,\n  - $N^{(1)} = 100000$,\n  - $s^{(1)} = 17$.\n\n- Test case $2$ (parallel reaction norms, near-zero rank reversal):\n  - $K = 2$,\n  - $\\boldsymbol{\\mu}^{(2)} = [\\, 1.0,\\, 0.0,\\, 1.0,\\, 0.0 \\,]$,\n  - $\\boldsymbol{\\Sigma}^{(2)} = \\mathrm{diag}([\\, 0.0001,\\, 0.0001,\\, 0.0001,\\, 0.0001 \\,])$,\n  - $N^{(2)} = 100000$,\n  - $s^{(2)} = 23$.\n\n- Test case $3$ (indistinguishable means, independent across environments; analytic symmetry suggests about $0.5$):\n  - $K = 2$,\n  - $\\boldsymbol{\\mu}^{(3)} = [\\, 0.0,\\, 0.0,\\, 0.0,\\, 0.0 \\,]$,\n  - $\\boldsymbol{\\Sigma}^{(3)} = \\mathrm{diag}([\\, 1.0,\\, 1.0,\\, 1.0,\\, 1.0 \\,])$,\n  - $N^{(3)} = 100000$,\n  - $s^{(3)} = 29$.\n\n- Test case $4$ ($K=3$ with strongly separated top genotype; near-zero rank reversal):\n  - $K = 3$,\n  - $\\boldsymbol{\\mu}^{(4)} = [\\, 2.0,\\, 1.0,\\, 0.0,\\, 1.9,\\, 1.8,\\, 1.7 \\,]$,\n  - $\\boldsymbol{\\Sigma}^{(4)} = \\mathrm{diag}([\\, 0.0001,\\, 0.0001,\\, 0.0001,\\, 0.0001,\\, 0.0001,\\, 0.0001 \\,])$,\n  - $N^{(4)} = 100000$,\n  - $s^{(4)} = 31$.\n\n- Test case $5$ (indistinguishable means, but strong positive cross-environment correlation for each genotype; reduces rank reversal below $0.5$):\n  - $K = 2$,\n  - $\\boldsymbol{\\mu}^{(5)} = [\\, 0.0,\\, 0.0,\\, 0.0,\\, 0.0 \\,]$,\n  - $\\boldsymbol{\\Sigma}^{(5)}$ is the $4 \\times 4$ matrix with diagonal entries $1.0$ and off-diagonal entries $0.95$ only between $(\\mu_{1,1}, \\mu_{1,2})$ and between $(\\mu_{2,1}, \\mu_{2,2})$, i.e.,\n    $$\n    \\boldsymbol{\\Sigma}^{(5)} =\n    \\begin{bmatrix}\n    1.0 & 0.0 & 0.95 & 0.0 \\\\\n    0.0 & 1.0 & 0.0 & 0.95 \\\\\n    0.95 & 0.0 & 1.0 & 0.0 \\\\\n    0.0 & 0.95 & 0.0 & 1.0\n    \\end{bmatrix},\n    $$\n  - $N^{(5)} = 100000$,\n  - $s^{(5)} = 37$.\n\nImplementation requirements:\n- Use Monte Carlo sampling with the specified $N^{(i)}$ and seeds $s^{(i)}$ to ensure reproducibility.\n- For each draw, compute the index of the top genotype in each environment using the standard zero-based indexing convention for implementation, but the mathematical definition above uses one-based indexing; this discrepancy does not affect the indicator.\n- Return the final result as a single line containing a comma-separated list of the five estimates $\\left[\\hat{p}_{\\mathrm{rev}}^{(1)}, \\hat{p}_{\\mathrm{rev}}^{(2)}, \\hat{p}_{\\mathrm{rev}}^{(3)}, \\hat{p}_{\\mathrm{rev}}^{(4)}, \\hat{p}_{\\mathrm{rev}}^{(5)}\\right]$, each rounded to $4$ decimal places. For example, an acceptable format is $\\left[0.1234,0.0000,0.5000,0.0001,0.1010\\right]$.",
            "solution": "The problem requires the estimation of the probability of rank reversal in genotype performance across two environments using a Monte Carlo simulation approach. Before proceeding to a solution, a rigorous validation of the problem statement is necessary.\n\nFirst, I will extract the given information verbatim.\nThe problem defines a set of $K$ genotypes in $2$ environments. The posterior distribution of genotype means is given by a random vector $\\boldsymbol{\\theta} = \\big(\\mu_{1,1}, \\mu_{2,1}, \\ldots, \\mu_{K,1}, \\mu_{1,2}, \\mu_{2,2}, \\ldots, \\mu_{K,2}\\big)^{\\top}$, where $\\mu_{g,e}$ is the mean performance of genotype $g$ in environment $e$. This vector follows a multivariate normal distribution, $\\boldsymbol{\\theta} \\sim \\mathcal{N}(\\boldsymbol{\\mu}, \\boldsymbol{\\Sigma})$, where $\\boldsymbol{\\mu} \\in \\mathbb{R}^{2K}$ and $\\boldsymbol{\\Sigma} \\in \\mathbb{R}^{2K \\times 2K}$ is a positive definite covariance matrix. The event of rank reversal is $\\mathcal{R} = \\left\\{ \\operatorname*{arg\\,max}_{g \\in \\{1,\\ldots,K\\}} \\mu_{g,1} \\;\\neq\\; \\operatorname*{arg\\,max}_{g \\in \\{1,\\ldots,K\\}} \\mu_{g,2} \\right\\}$. The probability of this event, $p_{\\mathrm{rev}} = \\mathbb{P}(\\mathcal{R})$, is to be estimated via Monte Carlo integration as $\\hat{p}_{\\mathrm{rev}}^{(i)} = \\frac{1}{N^{(i)}} \\sum_{b=1}^{N^{(i)}} \\mathbf{1}\\left\\{ \\operatorname*{arg\\,max}_{g} \\theta^{(b)}_{g,1} \\neq \\operatorname*{arg\\,max}_{g} \\theta^{(b)}_{g,2} \\right\\}$. The task is to compute this estimate for $5$ specific test cases.\n\n- Case $1$: $K = 2$, $\\boldsymbol{\\mu}^{(1)} = [\\, 1.0,\\, 0.0,\\, 0.0,\\, 1.0 \\,]$, $\\boldsymbol{\\Sigma}^{(1)} = \\mathrm{diag}([\\, 0.0001,\\, 0.0001,\\, 0.0001,\\, 0.0001 \\,])$, $N^{(1)} = 100000$, $s^{(1)} = 17$.\n- Case $2$: $K = 2$, $\\boldsymbol{\\mu}^{(2)} = [\\, 1.0,\\, 0.0,\\, 1.0,\\, 0.0 \\,]$, $\\boldsymbol{\\Sigma}^{(2)} = \\mathrm{diag}([\\, 0.0001,\\, 0.0001,\\, 0.0001,\\, 0.0001 \\,])$, $N^{(2)} = 100000$, $s^{(2)} = 23$.\n- Case $3$: $K = 2$, $\\boldsymbol{\\mu}^{(3)} = [\\, 0.0,\\, 0.0,\\, 0.0,\\, 0.0 \\,]$, $\\boldsymbol{\\Sigma}^{(3)} = \\mathrm{diag}([\\, 1.0,\\, 1.0,\\, 1.0,\\, 1.0 \\,])$, $N^{(3)} = 100000$, $s^{(3)} = 29$.\n- Case $4$: $K = 3$, $\\boldsymbol{\\mu}^{(4)} = [\\, 2.0,\\, 1.0,\\, 0.0,\\, 1.9,\\, 1.8,\\, 1.7 \\,]$, $\\boldsymbol{\\Sigma}^{(4)} = \\mathrm{diag}([\\, 0.0001,\\, 0.0001,\\, 0.0001,\\, 0.0001,\\, 0.0001,\\, 0.0001 \\,])$, $N^{(4)} = 100000$, $s^{(4)} = 31$.\n- Case $5$: $K = 2$, $\\boldsymbol{\\mu}^{(5)} = [\\, 0.0,\\, 0.0,\\, 0.0,\\, 0.0 \\,]$, $\\boldsymbol{\\Sigma}^{(5)} = \\begin{bmatrix} 1.0 & 0.0 & 0.95 & 0.0 \\\\ 0.0 & 1.0 & 0.0 & 0.95 \\\\ 0.95 & 0.0 & 1.0 & 0.0 \\\\ 0.0 & 0.95 & 0.0 & 1.0 \\end{bmatrix}$, $N^{(5)} = 100000$, $s^{(5)} = 37$.\n\nThe results must be rounded to $4$ decimal places and presented in a specific list format.\n\nNext, I will validate the problem statement.\nThe problem is scientifically grounded. The concepts of genotype-by-environment interaction, norms of reaction, and rank reversal are fundamental in evolutionary biology and quantitative genetics. The use of a multivariate normal posterior for genotype means is a standard, well-justified statistical modeling choice, often arising from asymptotic properties of estimators or from Bayesian analysis with conjugate priors.\nThe problem is well-posed. For each of the $5$ test cases, all necessary parameters ($K$, $\\boldsymbol{\\mu}$, $\\boldsymbol{\\Sigma}$, $N$, $s$) are explicitly provided. The objective—to estimate $p_{\\mathrm{rev}}$ via a specified Monte Carlo procedure—is unambiguous. The provided covariance matrices are positive definite, ensuring that the specified normal distributions are valid. Specifically, the diagonal matrices in cases $1-4$ have strictly positive diagonal entries. The matrix $\\boldsymbol{\\Sigma}^{(5)}$ can be shown to be positive definite by verifying that all its eigenvalues are positive, or by checking Sylvester's criterion on its principal minors, which are all positive. Thus, the problem is self-contained and mathematically consistent.\nThe problem is objective and uses precise scientific and mathematical language, free of ambiguity or subjective claims. There are no scientific or factual unsoundness, no missing information, and no contradictions. The task is a standard computational statistics problem that is directly verifiable and reproducible given the specified random seeds.\n\nThe verdict is that the problem is valid. I will now proceed with the solution.\n\nThe task is to estimate the probability of rank reversal, $p_{\\mathrm{rev}}$, via Monte Carlo integration. The underlying principle is the law of large numbers, which states that the average of results from a large number of independent trials will converge to the expected value. In this context, we simulate a large number of possible realities for the genotype means by drawing samples from their joint posterior distribution, $\\mathcal{N}(\\boldsymbol{\\mu}, \\boldsymbol{\\Sigma})$, and then compute the fraction of those realities in which a rank reversal occurs.\n\nThe algorithm to be implemented for each test case $i \\in \\{1, \\ldots, 5\\}$ is as follows:\n$1$. Initialize a modern pseudo-random number generator with the specified seed $s^{(i)}$. This ensures reproducibility of the results.\n$2$. Generate $N^{(i)}$ independent samples, denoted $\\boldsymbol{\\theta}^{(b)}$ for $b=1, \\ldots, N^{(i)}$, from the $2K$-dimensional multivariate normal distribution $\\mathcal{N}(\\boldsymbol{\\mu}^{(i)}, \\boldsymbol{\\Sigma}^{(i)})$. This step is executed once per test case, producing a large matrix of samples.\n$3$. Each sample vector $\\boldsymbol{\\theta}^{(b)}$ must be partitioned to correspond to the two environments. Based on the problem's specified ordering, the first $K$ elements $\\{\\theta_{g,1}^{(b)}\\}_{g=1}^K$ constitute the genotype means in environment $1$, and the subsequent $K$ elements $\\{\\theta_{g,2}^{(b)}\\}_{g=1}^K$ are the means in environment $2$.\n$4$. For each environment and for each of the $N^{(i)}$ samples, determine the index of the genotype with the maximum mean performance. Let these indices be $g_{1}^{(b)*} = \\operatorname*{arg\\,max}_{g} \\theta_{g,1}^{(b)}$ and $g_{2}^{(b)*} = \\operatorname*{arg\\,max}_{g} \\theta_{g,2}^{(b)}$.\n$5$. For each sample $b$, compare the two indices. The indicator function $\\mathbf{1}\\{g_{1}^{(b)*} \\neq g_{2}^{(b)*}\\}$ is equal to $1$ if a rank reversal occurs for that sample, and $0$ otherwise.\n$6$. The estimate $\\hat{p}_{\\mathrm{rev}}^{(i)}$ is the mean of these indicator values over all $N^{(i)}$ samples. This is equivalent to counting the total number of samples where a reversal occurred and dividing by $N^{(i)}$.\n$7$. Finally, the computed probability $\\hat{p}_{\\mathrm{rev}}^{(i)}$ is rounded to $4$ decimal places.\n\nFor computational efficiency, this algorithm is implemented using vectorized operations. The $N^{(i)}$ samples are generated into an $N^{(i)} \\times 2K$ matrix. This matrix is split into two $N^{(i)} \\times K$ matrices, one for each environment. The `argmax` operation is then applied along the genotype axis for each matrix, yielding two vectors of length $N^{(i)}$ containing the indices of the winning genotypes for each sample. A simple element-wise comparison of these two vectors reveals the samples for which rank reversals occurred. The final probability is then the sum of a boolean vector (where `True` is $1$ and `False` is $0$) divided by $N^{(i)}$. This vectorized approach avoids slow iterative loops in Python and leverages the optimized performance of numerical libraries like NumPy.",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Estimates the probability of rank reversal for five test cases using Monte Carlo simulation.\n    \"\"\"\n\n    test_cases = [\n        {\n            \"K\": 2,\n            \"mu\": np.array([1.0, 0.0, 0.0, 1.0]),\n            \"Sigma\": np.diag([0.0001, 0.0001, 0.0001, 0.0001]),\n            \"N\": 100000,\n            \"s\": 17,\n        },\n        {\n            \"K\": 2,\n            \"mu\": np.array([1.0, 0.0, 1.0, 0.0]),\n            \"Sigma\": np.diag([0.0001, 0.0001, 0.0001, 0.0001]),\n            \"N\": 100000,\n            \"s\": 23,\n        },\n        {\n            \"K\": 2,\n            \"mu\": np.array([0.0, 0.0, 0.0, 0.0]),\n            \"Sigma\": np.diag([1.0, 1.0, 1.0, 1.0]),\n            \"N\": 100000,\n            \"s\": 29,\n        },\n        {\n            \"K\": 3,\n            \"mu\": np.array([2.0, 1.0, 0.0, 1.9, 1.8, 1.7]),\n            \"Sigma\": np.diag([0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001]),\n            \"N\": 100000,\n            \"s\": 31,\n        },\n        {\n            \"K\": 2,\n            \"mu\": np.array([0.0, 0.0, 0.0, 0.0]),\n            \"Sigma\": np.array([\n                [1.0, 0.0, 0.95, 0.0],\n                [0.0, 1.0, 0.0, 0.95],\n                [0.95, 0.0, 1.0, 0.0],\n                [0.0, 0.95, 0.0, 1.0]\n            ]),\n            \"N\": 100000,\n            \"s\": 37,\n        },\n    ]\n\n    results = []\n\n    for case in test_cases:\n        K = case[\"K\"]\n        mu = case[\"mu\"]\n        Sigma = case[\"Sigma\"]\n        N = case[\"N\"]\n        seed = case[\"s\"]\n\n        # Initialize random number generator with the specified seed for reproducibility\n        rng = np.random.default_rng(seed)\n\n        # Draw N samples from the multivariate normal posterior distribution\n        # The resulting shape is (N, 2*K)\n        samples = rng.multivariate_normal(mu, Sigma, size=N)\n\n        # Split the samples into two sets, one for each environment\n        # Environment 1 samples are the first K columns\n        env1_samples = samples[:, :K]\n        # Environment 2 samples are the next K columns\n        env2_samples = samples[:, K:]\n\n        # Find the index of the top-performing genotype for each sample in each environment\n        # axis=1 performs the argmax over the genotypes for each sample\n        best_genotype_env1 = np.argmax(env1_samples, axis=1)\n        best_genotype_env2 = np.argmax(env2_samples, axis=1)\n\n        # A rank reversal occurs if the index of the best genotype is different\n        # between the two environments. We count how many times this happens.\n        reversal_count = np.sum(best_genotype_env1 != best_genotype_env2)\n\n        # The probability of rank reversal is the fraction of samples with a reversal\n        p_rev = reversal_count / N\n        \n        results.append(p_rev)\n\n    # Format the final output as a list of strings, each rounded to 4 decimal places\n    formatted_results = [f'{r:.4f}' for r in results]\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```"
        }
    ]
}