{
    "hands_on_practices": [
        {
            "introduction": "Wright-Fisher 模型是理解有限种群中性状频率因机遇而发生变化的基石，这一过程被称为文化漂变。本练习将引导你亲手推导群体遗传学中最基本的结果之一：一个中性文化变异的最终固定概率等于其初始频率。通过这个推导，你将对随机抽样在演化过程中的强大作用建立起深刻的直观认识。",
            "id": "2699390",
            "problem": "考虑一个大小恒为 $N$ 的有限种群，它在没有创新的情况下，根据用于文化传播的 Wright–Fisher 复制模型进行演化。时间是离散的，由 $t \\in \\{0,1,2,\\dots\\}$ 索引。每一代 $t+1$ 都是通过从第 $t$ 代中有放回地抽样 $N$ 个文化亲本而形成的，每次抽样都是从第 $t$ 代的 $N$ 个个体中均匀地选择一个亲本。存在两种文化变体，记为 $A$ 和 $B$。令 $X_t \\in \\{0,1,\\dots,N\\}$ 为第 $t$ 代中 $A$ 携带者的数量，并令 $x_t = X_t/N$ 为其对应的频率。假设中性和无创新：在每次抽样中，亲本都是独立且均匀地选择的，因此在 $X_t=i$ 的条件下，$X_{t+1}$ 的分布是 $\\mathrm{Binomial}(N, i/N)$。\n\n将固定概率 $\\phi(i;N)$ 定义为从 $X_0=i$ 开始，变体 $A$ 最终达到频率 $1$（即 $X_t$ 达到吸收态 $N$）的概率。等价地，用 $x_0=i/N$ 定义 $\\phi(x_0;N)$。\n\n仅使用上述基本定义，推导固定概率 $\\phi(x_0;N)$ 作为初始频率 $x_0 \\in [0,1]$ 和种群大小 $N$ 的函数的闭式表达式。将您的最终答案表示为单个解析表达式。无需四舍五入，也不涉及单位。",
            "solution": "该问题要求解在 Wright–Fisher 模型下演化的一个大小为 $N$ 的有限种群中，一个中性文化变体的固定概率。令 $X_t$ 为第 $t$ 代携带变体 $A$ 的个体数量，令 $x_t = X_t/N$ 为该变体的频率。该过程从初始数量 $X_0=i$ 开始，对应的初始频率为 $x_0 = i/N$。我们的任务是找到变体 $A$ 最终被固定的概率，即其频率达到 $1$。该概率记为 $\\phi(x_0;N)$。\n\n该过程的状态空间是 $\\{0, 1, \\dots, N\\}$。状态 $0$ 和 $N$ 是吸收态，分别对应于变体 $A$ 的丢失和固定。该过程根据以下转移规则演化：在 $X_t=k$ 的条件下，下一代中 $A$ 携带者的数量 $X_{t+1}$ 服从二项分布：\n$$ X_{t+1} | (X_t = k) \\sim \\mathrm{Binomial}(N, k/N) $$\n\n解决此问题的一个直接而严谨的方法是分析频率过程 $\\{x_t\\}_{t \\geq 0}$ 的性质。我们将证明，在指定的中性模型下，该变体的频率是一个鞅。一个过程 $\\{Y_t\\}$ 是鞅，如果 $\\mathbb{E}[Y_{t+1} | Y_t, Y_{t-1}, \\dots, Y_0] = Y_t$。\n\n让我们计算在给定时间 $t$ 状态的情况下 $x_{t+1}$ 的条件期望。假设在时间 $t$，状态为 $X_t = i$。频率为 $x_t = i/N$。在时间 $t+1$ 时，$A$ 携带者的期望数量是一个 $\\mathrm{Binomial}(N, p=i/N)$ 随机变量的期望。二项分布 $\\mathrm{Binomial}(n,p)$ 的期望是 $np$。因此，\n$$ \\mathbb{E}[X_{t+1} | X_t = i] = N \\cdot \\left(\\frac{i}{N}\\right) = i $$\n现在我们可以找到在时间 $t+1$ 时的期望频率：\n$$ \\mathbb{E}[x_{t+1} | X_t = i] = \\mathbb{E}\\left[\\frac{X_{t+1}}{N} \\Big| X_t = i\\right] = \\frac{1}{N} \\mathbb{E}[X_{t+1} | X_t = i] = \\frac{i}{N} $$\n由于我们定义了 $x_t = i/N$，这表明 $\\mathbb{E}[x_{t+1} | x_t] = x_t$。这个等式证实了频率过程 $\\{x_t\\}$ 是一个鞅。\n\n当过程达到吸收边界之一，即 $x_t=0$（丢失）或 $x_t=1$（固定）时，过程停止。令 $T$ 为该过程的停时，定义为：\n$$ T = \\inf\\{t \\geq 0 : x_t = 0 \\text{ or } x_t = 1\\} $$\n对于一个有限种群 $N$，最终被这些状态之一吸收是有保证的，这意味着停时 $T$ 是几乎必然有限的。鞅 $\\{x_t\\}$ 是有界的，因为它的值始终在区间 $[0,1]$ 内。\n\n这些条件——一个有界鞅和一个几乎必然有限的停时——使我们能够应用可选停止定理。该定理指出，鞅在停时处的期望值等于其初始值：\n$$ \\mathbb{E}[x_T] = x_0 $$\n过程在停时 $T$ 处的值 $x_T$ 是一个随机变量，它只能取两个值之一：如果变体 $A$ 固定，则为 $1$；如果它丢失，则为 $0$。固定概率正是我们要找的，即 $\\phi(x_0;N)$。因此，\n$$ P(x_T = 1) = \\phi(x_0;N) $$\n而丢失的概率是：\n$$ P(x_T = 0) = 1 - \\phi(x_0;N) $$\n期望 $\\mathbb{E}[x_T]$ 可以根据其定义计算得出：\n$$ \\mathbb{E}[x_T] = (1) \\cdot P(x_T = 1) + (0) \\cdot P(x_T = 0) = 1 \\cdot \\phi(x_0;N) + 0 \\cdot (1 - \\phi(x_0;N)) = \\phi(x_0;N) $$\n通过将 $\\mathbb{E}[x_T]$ 的两个表达式相等，我们得到最终结果：\n$$ \\phi(x_0;N) = x_0 $$\n这个结果展示了群体遗传学的一个基本原理：在没有选择、突变或迁移的情况下，一个中性等位基因或文化变体最终在种群中固定的概率等于其初始频率。该结果与种群大小 $N$ 无关。给定初始频率 $x_0 = i/N$，固定概率就是 $i/N$。",
            "answer": "$$\\boxed{x_{0}}$$"
        },
        {
            "introduction": "在掌握了理想化的理论模型后，将目光转向现实世界数据的复杂性至关重要。本练习探讨了观察的不完美性——这是社会和行为研究中的一个普遍问题——如何系统性地影响我们对文化传播过程（如从众偏见）的估计。通过推导这种“测量误差”所导致的估计偏差，你将学会以更具批判性的视角解读实证研究结果，并体会到在模型中审慎处理测量误差的必要性。",
            "id": "2699253",
            "problem": "考虑一个正在进行社会性学习且遵循从众传播规则的群体。设第 $i$ 组中某一文化变体的真实频率为 $p_i \\in (0,1)$，并定义对数几率 $x_i = \\operatorname{logit}(p_i) = \\ln\\!\\big(p_i/(1-p_i)\\big)$。假设在给定 $x_i$ 的条件下，观察者采纳该变体的概率服从一个逻辑斯谛响应，其从众指数为 $s>0$，因此在群体层面，采纳的对数几率为 $y_i = s x_i + \\epsilon_i$，其中 $\\epsilon_i$ 是一个均值为零、方差有限且独立于 $x_i$ 的扰动项。\n\n一位实证研究者试图通过将 $y_i$ 对感知到的对数几率 $\\tilde{x}_i$ 进行回归，来估计 $n$ 个群体中的 $s$。由于对频率的记忆性误解，感知到的预测变量在对数几率域中存在经典的加性误差：\n$$\n\\tilde{x}_i \\;=\\; x_i + u_i,\n$$\n其中 $u_i \\sim \\mathcal{N}(0,\\sigma^2)$ 独立于 $x_i$ 和 $\\epsilon_i$，且 $x_i$ 的方差有限，为 $\\operatorname{Var}(x_i)=\\tau^2>0$。研究者使用普通最小二乘法 (OLS) 来估计 $y_i$ 对 $\\tilde{x}_i$ 回归中的斜率 $\\hat{s}$。\n\n假设 $n$ 很大，使得 OLS 斜率收敛于总体回归斜率，请推导从众指数估计值的渐近偏差的闭式表达式，\n$$\n\\mathbb{B} \\;=\\; \\mathbb{E}[\\hat{s}] - s,\n$$\n该表达式应是 $s$、$\\sigma^2$ 和 $\\tau^2$ 的函数。请以单一解析表达式的形式给出你的答案。无需四舍五入，也无单位。",
            "solution": "在 $y_i$ 对 $\\tilde{x}_i$ 的简单线性回归中，斜率的 OLS 估计量 $\\hat{s}$ 由下式给出\n$$\n\\hat{s} = \\frac{\\sum_{i=1}^{n} (\\tilde{x}_i - \\bar{\\tilde{x}})(y_i - \\bar{y})}{\\sum_{i=1}^{n} (\\tilde{x}_i - \\bar{\\tilde{x}})^2}\n$$\n其中 $\\bar{\\tilde{x}}$ 和 $\\bar{y}$ 是样本均值。\n对于大样本容量 $n$，OLS 估计量 $\\hat{s}$ 在概率上收敛于总体回归斜率。这就是概率极限，记为 $\\operatorname{plim}(\\hat{s})$。渐近期望 $\\mathbb{E}[\\hat{s}]$ 对应于此极限。\n$$\n\\mathbb{E}[\\hat{s}] = \\operatorname{plim}_{n \\to \\infty} \\hat{s} = \\frac{\\operatorname{Cov}(\\tilde{x}_i, y_i)}{\\operatorname{Var}(\\tilde{x}_i)}\n$$\n我们的任务是利用模型设定来计算协方差项和方差项。\n\n首先，我们计算观测到的预测变量的方差 $\\operatorname{Var}(\\tilde{x}_i)$。\n预测变量的模型是 $\\tilde{x}_i = x_i + u_i$。\n由于已知 $x_i$ 和 $u_i$ 是独立的，所以它们和的方差是它们方差的和：\n$$\n\\operatorname{Var}(\\tilde{x}_i) = \\operatorname{Var}(x_i + u_i) = \\operatorname{Var}(x_i) + \\operatorname{Var}(u_i)\n$$\n我们已知 $\\operatorname{Var}(x_i) = \\tau^2$ 且测量误差 $u_i$ 的方差为 $\\sigma^2$。\n因此，\n$$\n\\operatorname{Var}(\\tilde{x}_i) = \\tau^2 + \\sigma^2\n$$\n\n接下来，我们计算观测到的预测变量 $\\tilde{x}_i$ 和结果 $y_i$ 之间的协方差 $\\operatorname{Cov}(\\tilde{x}_i, y_i)$。\n我们代入 $\\tilde{x}_i$ 和 $y_i$ 的表达式：\n$$\n\\operatorname{Cov}(\\tilde{x}_i, y_i) = \\operatorname{Cov}(x_i + u_i, s x_i + \\epsilon_i)\n$$\n利用协方差的双线性性质：\n$$\n\\operatorname{Cov}(\\tilde{x}_i, y_i) = \\operatorname{Cov}(x_i, s x_i) + \\operatorname{Cov}(x_i, \\epsilon_i) + \\operatorname{Cov}(u_i, s x_i) + \\operatorname{Cov}(u_i, \\epsilon_i)\n$$\n我们根据给定的独立性假设来评估每一项：\n$1$. $\\operatorname{Cov}(x_i, s x_i) = s \\operatorname{Cov}(x_i, x_i) = s \\operatorname{Var}(x_i) = s \\tau^2$。\n$2$. $\\operatorname{Cov}(x_i, \\epsilon_i) = 0$，因为 $x_i$ 和 $\\epsilon_i$ 是独立的。\n$3$. $\\operatorname{Cov(u_i, s x_i)} = s \\operatorname{Cov}(u_i, x_i) = 0$，因为 $u_i$ 和 $x_i$ 是独立的。\n$4$. $\\operatorname{Cov}(u_i, \\epsilon_i) = 0$，因为 $u_i$ 和 $\\epsilon_i$ 是独立的。\n将这些项相加，我们得到协方差：\n$$\n\\operatorname{Cov}(\\tilde{x}_i, y_i) = s \\tau^2 + 0 + 0 + 0 = s \\tau^2\n$$\n\n现在我们可以确定 OLS 估计量 $\\hat{s}$ 的渐近期望：\n$$\n\\mathbb{E}[\\hat{s}] = \\frac{\\operatorname{Cov}(\\tilde{x}_i, y_i)}{\\operatorname{Var}(\\tilde{x}_i)} = \\frac{s \\tau^2}{\\tau^2 + \\sigma^2}\n$$\n这个结果表明 OLS 估计量是渐近有偏的。因子 $\\frac{\\tau^2}{\\tau^2 + \\sigma^2}$ 被称为信度比。由于 $\\sigma^2 \\ge 0$ 且 $\\tau^2 > 0$，该比率始终在 $0$ 和 $1$ 之间。由于真实参数 $s$ 是正的，估计值 $\\hat{s}$ 被衰减，意味着它偏向于零。\n\n最后，我们计算问题陈述中定义的渐近偏差 $\\mathbb{B}$：\n$$\n\\mathbb{B} = \\mathbb{E}[\\hat{s}] - s\n$$\n代入我们关于 $\\mathbb{E}[\\hat{s}]$ 的表达式：\n$$\n\\mathbb{B} = \\frac{s \\tau^2}{\\tau^2 + \\sigma^2} - s\n$$\n为了简化，我们通分：\n$$\n\\mathbb{B} = s \\left( \\frac{\\tau^2}{\\tau^2 + \\sigma^2} - 1 \\right) = s \\left( \\frac{\\tau^2 - (\\tau^2 + \\sigma^2)}{\\tau^2 + \\sigma^2} \\right)\n$$\n$$\n\\mathbb{B} = s \\left( \\frac{\\tau^2 - \\tau^2 - \\sigma^2}{\\tau^2 + \\sigma^2} \\right) = s \\left( \\frac{-\\sigma^2}{\\tau^2 + \\sigma^2} \\right)\n$$\n这给出了渐近偏差的最终表达式：\n$$\n\\mathbb{B} = - \\frac{s \\sigma^2}{\\tau^2 + \\sigma^2}\n$$\n偏差是负的，这证实了衰减现象，其大小取决于真实斜率 $s$、测量误差的方差 $\\sigma^2$ 以及真实信号的方差 $\\tau^2$。",
            "answer": "$$\n\\boxed{- \\frac{s \\sigma^{2}}{\\tau^{2} + \\sigma^{2}}}\n$$"
        },
        {
            "introduction": "最后，本练习将我们直接带入文化演化数据分析的核心，运用强大的 Price 方程将观察到的总体性状均值变化分解为不同的演化组分。你将通过处理具体的数据集，学习如何从计算上分离文化选择（即某些榜样被更多人模仿）和传播偏见（即文化性状在代际传递过程中的系统性改变）的效应。这项技能对于从经验数据中准确诊断文化演化的驱动力至关重要。",
            "id": "2699362",
            "problem": "给定一个种群在一个代际步骤中的个体层面文化数据，该种群包含一组文化模型（父代）和一组学习者。每个学习者选择一个模型进行学习，并获得一个可能被修正的性状值。您的任务是计算种群层面文化变迁的两个组成部分，这两个部分将平均性状值的变化分解为：一个可归因于文化选择（模型的差异化影响）的组分，以及一个可归因于传递偏差（学习过程中的系统性谱系内变化）的组分。\n\n基本原理和定义：\n- 设有 $N$ 个模型，索引为 $i \\in \\{1,\\dots,N\\}$，每个模型具有性状值 $z_i \\in \\mathbb{R}$。设模型的平均性状为 $\\bar{z} = \\frac{1}{N} \\sum_{i=1}^N z_i$。\n- 设有 $M$ 个学习者，索引为 $j \\in \\{1,\\dots,M\\}$。每个学习者 $j$ 精确选择一个模型 $m(j) \\in \\{1,\\dots,N\\}$，并在学习后获得性状 $z'_j \\in \\mathbb{R}$。\n- 模型 $i$ 的文化影响力（学习者数量）为 $w_i = \\left| \\{ j : m(j) = i \\} \\right|$。平均影响力为 $\\bar{w} = \\frac{1}{N} \\sum_{i=1}^N w_i$。注意 $\\sum_{i=1}^N w_i = M$ 意味着 $\\bar{w} = M / N$。\n- 定义每个模型的学习者平均值 $\\mu_i$ 如下：若 $w_i > 0$，则 $\\mu_i = \\frac{1}{w_i} \\sum_{j : m(j) = i} z'_j$；若 $w_i = 0$，则采用约定 $\\mu_i = z_i$，这样 $\\mu_i - z_i = 0$ 对传递偏差没有贡献。\n\n您的程序必须针对每个提供的数据集计算：\n1. 文化选择协方差项 $S$，定义为相对影响力与模型性状之间的协方差，\n$$\nS \\equiv \\operatorname{Cov}\\!\\left(\\frac{w_i}{\\bar{w}}, z_i\\right) \\;=\\; \\frac{1}{N}\\sum_{i=1}^N \\left(\\frac{w_i}{\\bar{w}} - 1\\right)\\left(z_i - \\bar{z}\\right).\n$$\n2. 传递偏差项 $T$，定义为按相对影响力加权的预期谱系内变化，\n$$\nT \\equiv \\frac{1}{N}\\sum_{i=1}^N \\left(\\frac{w_i}{\\bar{w}}\\right)\\left(\\mu_i - z_i\\right).\n$$\n3. 在该代际步骤中平均性状的总变化，\n$$\n\\Delta \\bar{z} \\equiv \\left(\\frac{1}{M}\\sum_{j=1}^M z'_j\\right) - \\bar{z}.\n$$\n4. 一个解释代码，用于指示哪个组分的量值更大。设 $\\varepsilon = 10^{-9}$。定义\n$$\nd \\equiv \\left|S\\right| - \\left|T\\right|.\n$$\n针对每个数据集返回一个整数代码如下：若 $d > \\varepsilon$，返回 $1$（选择的量值超过传递）；若 $d < -\\varepsilon$，返回 $-1$（传递的量值超过选择）；否则返回 $0$（量值在容差范围内相当）。\n\n每个数据集的输入规范：\n- $N$ 和模型性状向量 $\\mathbf{z} = [z_1,\\dots,z_N]$。\n- 学习者到模型的索引向量 $\\mathbf{m} = [m(1),\\dots,m(M)]$，使用 $\\{0,\\dots,N-1\\}$ 中从零开始的索引。\n- 学习后的学习者性状向量 $\\mathbf{z}' = [z'_1,\\dots,z'_M]$。\n所有量均为无量纲实数。\n\n测试套件：\n提供以下四个数据集的结果。$\\mathbf{m}$ 中的索引是从零开始的。\n\n- 数据集 A：\n  - $N = 4$。\n  - $\\mathbf{z} = [0.0, 1.0, 2.0, 3.0]$。\n  - $\\mathbf{m} = [0, 1, 1, 2, 2, 3, 3, 3, 3, 3]$。\n  - $\\mathbf{z}' = [0.2, 1.0, 1.0, 1.9, 1.9, 2.8, 2.8, 2.8, 2.9, 2.9]$。\n\n- 数据集 B：\n  - $N = 3$。\n  - $\\mathbf{z} = [1.0, 2.0, 3.0]$。\n  - $\\mathbf{m} = [0, 0, 1, 1, 2, 2]$。\n  - $\\mathbf{z}' = [1.3, 1.3, 2.0, 2.0, 2.8, 2.8]$。\n\n- 数据集 C：\n  - $N = 3$。\n  - $\\mathbf{z} = [0.0, 1.0, 3.0]$。\n  - $\\mathbf{m} = [0, 1, 1, 2, 2, 2]$。\n  - $\\mathbf{z}' = [0.0, 1.0, 1.0, 3.0, 3.0, 3.0]$。\n\n- 数据集 D：\n  - $N = 4$。\n  - $\\mathbf{z} = [1.0, 2.0, 3.0, 4.0]$。\n  - $\\mathbf{m} = [1, 2, 3, 3]$。\n  - $\\mathbf{z}' = [1.9, 3.2, 3.7, 3.9]$。\n\n输出规范：\n- 对于每个数据集，输出一个形式为 $[S, T, \\Delta\\bar{z}, \\text{code}]$ 的列表，其中 $S$、$T$ 和 $\\Delta\\bar{z}$ 是四舍五入到六位小数的浮点数，而 $\\text{code}$ 是如上定义的整数。\n- 您的程序应生成单行输出，其中包含所有数据集的结果，格式为一个由方括号括起来的、逗号分隔的列表的列表。例如，输出格式必须是\n$[[S_A,T_A,\\Delta\\bar{z}_A,\\text{code}_A],[S_B,T_B,\\Delta\\bar{z}_B,\\text{code}_B],[S_C,T_C,\\Delta\\bar{z}_C,\\text{code}_C],[S_D,T_D,\\Delta\\bar{z}_D,\\text{code}_D]]$\n并应用了所要求的四舍五入。",
            "solution": "核心任务是将种群平均性状值的总变化 $\\Delta\\bar{z}$ 分解为两个组分：选择组分 $S$ 和传递偏差组分 $T$。问题为这三个量提供了定义。一个基本的一致性检验是证明总变化实际上是这两个组分之和，即 $\\Delta\\bar{z} = S + T$。这个恒等式构成了我们分析的基础。\n\n让我们从提供的定义开始。$N$ 个模型的平均性状是 $\\bar{z} = \\frac{1}{N} \\sum_{i=1}^N z_i$。下一代 $M$ 个学习者的平均性状是 $\\bar{z}' = \\frac{1}{M}\\sum_{j=1}^M z'_j$。总变化是 $\\Delta\\bar{z} = \\bar{z}' - \\bar{z}$。\n\n我们可以通过根据学习者选择的模型 $m(j)$ 对其进行分组来表示 $\\bar{z}'$。选择模型 $i$ 的学习者数量是其影响力 $w_i$。选择模型 $i$ 的学习者的性状值之和是 $\\sum_{j : m(j) = i} z'_j$。根据定义，对于 $w_i > 0$，每个模型的学习者平均值为 $\\mu_i = \\frac{1}{w_i} \\sum_{j : m(j) = i} z'_j$。因此，$\\sum_{j : m(j) = i} z'_j = w_i \\mu_i$。即使当 $w_i=0$ 时，这个关系也成立，因为两边都为零。学习者性状的总和是 $\\sum_{j=1}^M z'_j = \\sum_{i=1}^N \\sum_{j : m(j) = i} z'_j = \\sum_{i=1}^N w_i \\mu_i$。\n\n将此代入 $\\bar{z}'$ 的表达式中：\n$$\n\\bar{z}' = \\frac{1}{M} \\sum_{i=1}^N w_i \\mu_i\n$$\n平均影响力为 $\\bar{w} = \\sum_{i=1}^N w_i / N = M/N$。因此，$M = N\\bar{w}$。将此代入 $M$：\n$$\n\\bar{z}' = \\frac{1}{N\\bar{w}} \\sum_{i=1}^N w_i \\mu_i = \\frac{1}{N} \\sum_{i=1}^N \\frac{w_i}{\\bar{w}} \\mu_i\n$$\n现在，我们可以将总变化 $\\Delta\\bar{z}$ 写为：\n$$\n\\Delta\\bar{z} = \\bar{z}' - \\bar{z} = \\frac{1}{N} \\sum_{i=1}^N \\left(\\frac{w_i}{\\bar{w}}\\right) \\mu_i - \\bar{z}\n$$\n为了分解这个变化，我们通过加上再减去 $\\frac{1}{N} \\sum_{i=1}^N (\\frac{w_i}{\\bar{w}}) z_i$ 这一项来引入它：\n$$\n\\Delta\\bar{z} = \\left( \\frac{1}{N} \\sum_{i=1}^N \\left(\\frac{w_i}{\\bar{w}}\\right) \\mu_i - \\frac{1}{N} \\sum_{i=1}^N \\left(\\frac{w_i}{\\bar{w}}\\right) z_i \\right) + \\left( \\frac{1}{N} \\sum_{i=1}^N \\left(\\frac{w_i}{\\bar{w}}\\right) z_i - \\bar{z} \\right)\n$$\n让我们分析这两个括起来的项。第一项可以写成：\n$$\n\\frac{1}{N} \\sum_{i=1}^N \\left(\\frac{w_i}{\\bar{w}}\\right) (\\mu_i - z_i)\n$$\n这正是传递偏差项 $T$ 的定义。它代表了从模型到学习者的性状值的平均变化，并按每个模型的相对影响力加权。当 $w_i = 0$ 时约定 $\\mu_i = z_i$，确保了没有学习者的模型对该项没有贡献。\n\n第二项可以被识别为相对影响力 $\\frac{w_i}{\\bar{w}}$ 和模型性状 $z_i$ 之间的协方差。一个变量 $X_i$ 在模型种群上的期望是 $E[X] = \\frac{1}{N}\\sum_{i=1}^N X_i$。协方差是 $\\operatorname{Cov}(X, Y) = E[(X-E[X])(Y-E[Y])]$。令 $X_i = \\frac{w_i}{\\bar{w}}$ 和 $Y_i = z_i$。那么 $E[Y] = \\bar{z}$。$X_i$ 的期望是 $E[X] = \\frac{1}{N}\\sum_{i=1}^N \\frac{w_i}{\\bar{w}} = \\frac{1}{N\\bar{w}}\\sum_{i=1}^N w_i = \\frac{M}{N(M/N)} = 1$。第二项是 $E[XY] - \\bar{z} = E[XY] - E[X]E[Y]$，也就是 $\\operatorname{Cov}(X,Y)$。将其展开得到：\n$$\n\\operatorname{Cov}\\left(\\frac{w_i}{\\bar{w}}, z_i\\right) = \\frac{1}{N}\\sum_{i=1}^N \\left(\\frac{w_i}{\\bar{w}} - 1\\right) (z_i - \\bar{z})\n$$\n这正是文化选择项 $S$ 的定义。它衡量了模型的性状值与其文化影响力之间的统计关联。\n\n因此，我们证明了恒等式 $\\Delta\\bar{z} = S + T$。总变化被完美地分解。计算过程如下：\n\n对于每个数据集（$N$、$\\mathbf{z}$、$\\mathbf{m}$、$\\mathbf{z}'$）：\n1.  计算模型平均性状 $\\bar{z} = \\frac{1}{N}\\sum z_i$。\n2.  根据 $\\mathbf{m}$ 的长度确定学习者数量 $M$。\n3.  计算影响力向量 $\\mathbf{w}$，其中 $w_i$ 是模型索引 $i$ 在 $\\mathbf{m}$ 中出现的次数。$\\mathbf{m}$ 中的索引是给定的从零开始的索引，即 $\\{0, \\dots, N-1\\}$。\n4.  计算平均影响力 $\\bar{w} = M/N$。\n5.  确定每个模型的学习者平均值向量 $\\boldsymbol{\\mu}$。对每个模型 $i$，若 $w_i > 0$，$\\mu_i$ 是所有选择模型 $i$ 的学习者 $j$ 的 $z'_j$ 的平均值。若 $w_i = 0$，则设 $\\mu_i$ 为 $z_i$。\n6.  计算选择项 $S = \\frac{1}{N}\\sum_{i=0}^{N-1} (\\frac{w_i}{\\bar{w}} - 1)(z_i - \\bar{z})$。\n7.  计算传递偏差项 $T = \\frac{1}{N}\\sum_{i=0}^{N-1} (\\frac{w_i}{\\bar{w}})(\\mu_i - z_i)$。\n8.  计算总变化 $\\Delta\\bar{z} = (\\frac{1}{M}\\sum z'_j) - \\bar{z}$。作为验证，必须确认 $S + T$ 近似等于 $\\Delta\\bar{z}$。\n9.  计算量值差异 $d = |S| - |T|$，并根据给定的容差 $\\varepsilon = 10^{-9}$ 确定解释代码。若 $d > \\varepsilon$，代码为 $1$；若 $d < -\\varepsilon$，代码为 $-1$；否则代码为 $0$。\n10. 将结果格式化为列表 $[S, T, \\Delta\\bar{z}, \\text{code}]$，其中浮点数四舍五入到六位小数。\n\n此算法将被实现以处理所提供的测试套件。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the cultural evolution problem for all given test cases.\n    \"\"\"\n    \n    # Define the test cases from the problem statement.\n    test_cases = [\n        # Dataset A\n        {\n            \"N\": 4,\n            \"z_models\": [0.0, 1.0, 2.0, 3.0],\n            \"m_learners\": [0, 1, 1, 2, 2, 3, 3, 3, 3, 3],\n            \"z_prime_learners\": [0.2, 1.0, 1.0, 1.9, 1.9, 2.8, 2.8, 2.8, 2.9, 2.9],\n        },\n        # Dataset B\n        {\n            \"N\": 3,\n            \"z_models\": [1.0, 2.0, 3.0],\n            \"m_learners\": [0, 0, 1, 1, 2, 2],\n            \"z_prime_learners\": [1.3, 1.3, 2.0, 2.0, 2.8, 2.8],\n        },\n        # Dataset C\n        {\n            \"N\": 3,\n            \"z_models\": [0.0, 1.0, 3.0],\n            \"m_learners\": [0, 1, 1, 2, 2, 2],\n            \"z_prime_learners\": [0.0, 1.0, 1.0, 3.0, 3.0, 3.0],\n        },\n        # Dataset D\n        {\n            \"N\": 4,\n            \"z_models\": [1.0, 2.0, 3.0, 4.0],\n            \"m_learners\": [1, 2, 3, 3],\n            \"z_prime_learners\": [1.9, 3.2, 3.7, 3.9],\n        },\n    ]\n\n    results_str_list = []\n    for case in test_cases:\n        s, t, delta_z, code = calculate_components(\n            case[\"N\"],\n            case[\"z_models\"],\n            case[\"m_learners\"],\n            case[\"z_prime_learners\"]\n        )\n        \n        # Format the output for the current case\n        s_str = f\"{s:.6f}\"\n        t_str = f\"{t:.6f}\"\n        delta_z_str = f\"{delta_z:.6f}\"\n        \n        result_str = f\"[{s_str},{t_str},{delta_z_str},{code}]\"\n        results_str_list.append(result_str)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(results_str_list)}]\")\n\ndef calculate_components(N_models, z_models_list, m_learners_list, z_prime_learners_list):\n    \"\"\"\n    Computes S, T, delta_z, and the interpretation code for a single dataset.\n    \"\"\"\n    \n    # Convert lists to numpy arrays for vectorized operations\n    z_models = np.array(z_models_list, dtype=float)\n    m_learners = np.array(m_learners_list, dtype=int)\n    z_prime_learners = np.array(z_prime_learners_list, dtype=float)\n    \n    # Number of learners\n    M_learners = len(m_learners)\n\n    # 1. Compute model-level quantities\n    z_bar = np.mean(z_models)\n\n    # 2. Compute learner-level and linking quantities\n    # Influence of each model (number of learners choosing each model)\n    w = np.bincount(m_learners, minlength=N_models)\n    \n    # Mean influence\n    if N_models > 0:\n        w_bar = M_learners / N_models\n    else:\n        w_bar = 0\n\n    # 3. Calculate per-model learner mean mu\n    mu = np.zeros(N_models, dtype=float)\n    for i in range(N_models):\n        if w[i] > 0:\n            learners_of_model_i = z_prime_learners[m_learners == i]\n            mu[i] = np.mean(learners_of_model_i)\n        else:\n            # Convention: if w_i = 0, mu_i = z_i\n            mu[i] = z_models[i]\n\n    # Handle case where all models have zero influence\n    if w_bar == 0:\n        rel_w = np.zeros(N_models, dtype=float)\n    else:\n        rel_w = w / w_bar\n\n    # 4. Calculate S (Selection)\n    # S = (1/N) * sum((w_i/w_bar - 1) * (z_i - z_bar))\n    s_term_per_model = (rel_w - 1) * (z_models - z_bar)\n    S = np.mean(s_term_per_model)\n\n    # 5. Calculate T (Transmission)\n    # T = (1/N) * sum((w_i/w_bar) * (mu_i - z_i))\n    t_term_per_model = rel_w * (mu - z_models)\n    T = np.mean(t_term_per_model)\n\n    # 6. Calculate Delta z_bar (Total Change)\n    if M_learners > 0:\n        z_prime_bar = np.mean(z_prime_learners)\n    else:\n        z_prime_bar = z_bar # No learners, no change\n    delta_z_bar = z_prime_bar - z_bar\n\n    # 7. Calculate the interpretation code\n    epsilon = 1e-9\n    d = abs(S) - abs(T)\n    if d > epsilon:\n        code = 1\n    elif d  -epsilon:\n        code = -1\n    else:\n        code = 0\n        \n    return S, T, delta_z_bar, code\n\n# Execute the main function\nsolve()\n```"
        }
    ]
}