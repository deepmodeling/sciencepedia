{
    "hands_on_practices": [
        {
            "introduction": "在分析选择性清除时, 一个核心目标不仅是检测其发生, 更是要区分其模式——例如, 它是源于一个全新的有益突变 (硬清除) 还是源于群体中已存在的遗传变异 (软清除)？本练习将指导你通过计算一系列基于单倍型纯合性的关键统计量 ($H_1$, $H_{12}$ 和 $H_2/H_1$) 来解决这个问题 。通过这个实践, 你将学会如何从原始的单倍型计数数据中提取信息, 并将其与硬清除和软清除的理论预测联系起来, 从而深入理解这两种选择模式在基因组上留下的不同印记。",
            "id": "2750177",
            "problem": "在一个随机交配群体中，一个基因组窗口已通过高覆盖度测序，并对一个包含 $n=200$ 条染色体的样本确定了定相的单倍型。在此窗口内，三个最常见的单倍型以及单倍型谱的其余部分如下（计数单位为染色体）：\n- 单倍型 $h_{A}$: $80$\n- 单倍型 $h_{B}$: $60$\n- 单倍型 $h_{C}$: $30$\n- 所有其他观测到的单倍型: $30$ 个不同的单例（每个计数为 $1$）\n\n仅从以下基本定义出发：一个窗口内的单倍型纯合度是，从样本中进行两次独立随机抽样（有放回）得到相同单倍型的概率；并且合并类别等同于在计算此概率前将其频率相加。请完成以下任务：\n- 根据样本单倍型频率 $\\{p_{i}\\}$，推导 $H_{1}$ 的表达式。\n- 首先将两个最常见的单倍型合并为一个类别，然后根据上述定义计算纯合度，从而推导 $H_{12}$ 的表达式。\n- 推导 $H_{2}/H_{1}$ 的表达式，其中 $H_{2}$ 是除最常见单倍型外，所有其他单倍型对 $H_{1}$ 的贡献。\n\n然后，根据以上数据计算 $H_{1}$、$H_{12}$ 和 $H_{2}/H_{1}$。请用精确分数表示最终数值答案，不要四舍五入。以行矩阵 $\\left(H_{1},\\,H_{12},\\,H_{2}/H_{1}\\right)$ 的形式按顺序提供最终答案。\n\n最后，基于这些数值，不借助任何外部阈值，解释该窗口中的证据更符合近期强选择性清除（硬清除）还是软选择性清除（软清除），并从硬清除和软清除如何影响单倍型频率谱的第一性原理出发，论证你的推理。你的解释不会被数字评分，但必须与计算出的值在逻辑上保持一致。",
            "solution": "该问题陈述科学合理、内容独立且提法得当。所有必要的数据和定义均已提供，且无内部矛盾。根据所提供计数，染色体总数为 $80 + 60 + 30 + 30 \\times 1 = 200$，与给定的样本大小 $n=200$ 相符。因此，可以进行推导和计算。\n\n该问题要求从一个包含 $n=200$ 条染色体的样本中，推导和计算与单倍型纯合度相关的三个量。观测到的计数为：单倍型 $h_{A}$ 为 $c_{A} = 80$， $h_{B}$ 为 $c_{B} = 60$， $h_{C}$ 为 $c_{C} = 30$，以及 $30$ 个不同的单例单倍型各为 $c_{s_j} = 1$（$j=1, \\dots, 30$）。\n\n相应的样本频率为：\n$p_{A} = \\frac{c_{A}}{n} = \\frac{80}{200} = \\frac{2}{5}$\n$p_{B} = \\frac{c_{B}}{n} = \\frac{60}{200} = \\frac{3}{10}$\n$p_{C} = \\frac{c_{C}}{n} = \\frac{30}{200} = \\frac{3}{20}$\n$p_{s_j} = \\frac{c_{s_j}}{n} = \\frac{1}{200}$ for $j=1, \\dots, 30$.\n所有不同单倍型的集合为 $\\{h_i\\}$，其频率为 $\\{p_i\\}$。\n\n首先，我们推导总单倍型纯合度 $H_{1}$ 的表达式。根据定义，这是从样本中两次独立随机抽样得到相同单倍型的概率。设所有不同单倍型的集合由索引 $i$ 标记。抽取到单倍型 $h_i$ 的概率是其频率 $p_i$。由于两次抽样是独立的，连续两次抽到 $h_i$ 的概率是 $p_i \\times p_i = p_i^2$。抽取到每一种特定单倍型对（例如，两个 $h_A$，或两个 $h_B$）的事件是互斥的。因此，抽到任意相同对的总概率是所有可能单倍型概率的总和。\n$$H_{1} = \\sum_{i} p_i^2$$\n这是单倍型纯合度的一般表达式。\n\n使用给定数据，我们计算 $H_{1}$：\n$$H_{1} = p_{A}^2 + p_{B}^2 + p_{C}^2 + \\sum_{j=1}^{30} p_{s_j}^2$$\n$$H_{1} = \\left(\\frac{80}{200}\\right)^2 + \\left(\\frac{60}{200}\\right)^2 + \\left(\\frac{30}{200}\\right)^2 + 30 \\times \\left(\\frac{1}{200}\\right)^2$$\n直接使用计数和分母中的总样本量平方进行计算更为直接：\n$$H_{1} = \\frac{\\sum_{i} c_i^2}{n^2} = \\frac{80^2 + 60^2 + 30^2 + 30 \\times 1^2}{200^2}$$\n$$H_{1} = \\frac{6400 + 3600 + 900 + 30}{40000} = \\frac{10930}{40000} = \\frac{1093}{4000}$$\n\n其次，我们推导 $H_{12}$ 的表达式。这个量是在将两个最常见的单倍型 $h_A$ 和 $h_B$ 合并为一个类别后计算的纯合度。设这个新的合并类别为 $h_{AB}$。其频率 $p_{AB}$ 是其组成类别频率的总和：$p_{AB} = p_A + p_B$。现在的单倍型集合是 $\\{h_{AB}, h_C, h_{s_1}, \\dots, h_{s_{30}}\\}$。纯合度 $H_{12}$ 是这个新集合频率的平方和。\n$$H_{12} = p_{AB}^2 + p_C^2 + \\sum_{j=1}^{30} p_{s_j}^2 = (p_A + p_B)^2 + p_C^2 + \\sum_{j=1}^{30} p_{s_j}^2$$\n根据数据，合并类别的计数为 $c_{AB} = c_A + c_B = 80 + 60 = 140$。\n$$H_{12} = \\frac{c_{AB}^2 + c_C^2 + \\sum_{j=1}^{30} c_{s_j}^2}{n^2} = \\frac{(80+60)^2 + 30^2 + 30 \\times 1^2}{200^2}$$\n$$H_{12} = \\frac{140^2 + 30^2 + 30}{40000} = \\frac{19600 + 900 + 30}{40000} = \\frac{20530}{40000} = \\frac{2053}{4000}$$\n\n第三，我们推导比值 $H_{2}/H_{1}$ 的表达式。$H_{2}$ 定义为除最常见单倍型外，所有其他单倍型对 $H_{1}$ 的贡献。设单倍型按频率排序，$p_1 \\ge p_2 \\ge \\dots$。最常见的单倍型是 $h_1$，频率为 $p_1$（在我们的例子中是 $h_A$，频率为 $p_A$）。\n总纯合度为 $H_{1} = p_1^2 + p_2^2 + \\dots = \\sum_{i} p_i^2$。\n所有其他单倍型的贡献为 $H_{2} = p_2^2 + p_3^2 + \\dots = \\sum_{i>1} p_i^2$。\n因此，$H_2 = H_1 - p_1^2$。该比值为：\n$$\\frac{H_{2}}{H_{1}} = \\frac{\\sum_{i>1} p_i^2}{\\sum_{i} p_i^2} = \\frac{H_1 - p_1^2}{H_1} = 1 - \\frac{p_1^2}{H_1}$$\n根据我们的数据，最常见的单倍型是 $h_A$，其频率为 $p_A = 2/5$。\n我们已经计算出 $H_{1} = \\frac{1093}{4000}$。\n$H_{2}$ 是由 $h_B$、$h_C$ 和单例贡献的纯合度：\n$$H_{2} = p_{B}^2 + p_{C}^2 + \\sum_{j=1}^{30} p_{s_j}^2 = \\frac{60^2 + 30^2 + 30 \\times 1^2}{200^2}$$\n$$H_{2} = \\frac{3600 + 900 + 30}{40000} = \\frac{4530}{40000} = \\frac{453}{4000}$$\n因此，该比值为：\n$$\\frac{H_{2}}{H_{1}} = \\frac{453/4000}{1093/4000} = \\frac{453}{1093}$$\n分子 $453 = 3 \\times 151$。分母 $1093$ 不能被 $3$ 整除（数字和为 $13$），也不能被质数 $151$ 整除。因此，该分数为最简分数。\n\n最后，我们必须在硬清除与软清除的背景下解释这些结果。\n硬清除（hard sweep）发生于一个新的有益突变在某个特定单倍型上出现，并迅速扩展至高频。此过程会清除连锁位点的遗传变异。预期的信号是一个频率极高的单倍型（清除携带者）和一系列非常罕见且差异较大的单倍型。这导致总体纯合度（$H_1$）很高，但这种纯合度几乎完全由占主导地位的单倍型贡献。因此，比值 $H_2/H_1$ 应非常接近 $0$。\n软清除（soft sweep）发生于选择作用于已有的存量变异或复发突变，导致携带该有益等位基因的多个单倍型频率同时增加。预期的信号是存在两个或多个处于中到高频率的单倍型。这同样会导致纯合度（$H_1$）升高，但其中相当大一部分是由除最常见单倍型之外的其他单倍型贡献的。因此，$H_2/H_1$ 将远大于 $0$。\n\n在我们的样本中，单倍型频率分别为 $p_A = 0.4$、$p_B = 0.3$ 和 $p_C = 0.15$。存在两个非常常见的单倍型，以及第三个频率可观的单倍型，这并非经典硬清除的特征。\n我们的计算值量化了这一观察：\n1. $H_1 = \\frac{1093}{4000} \\approx 0.273$。与许多物种中的中性预期相比，该值偏高，这与近期发生过选择性清除的迹象一致。\n2. $H_2/H_1 = \\frac{453}{1093} \\approx 0.414$。这个值很大。它表明超过 $41\\%$ 的总纯合度是由最常见单倍型以外的其他单倍型贡献的。这与硬清除的预期（该比值接近于零）形成强烈反差。\n3. $H_{12} = \\frac{2053}{4000} \\approx 0.513$。该值显著高于 $H_1$。在合并两个最常见的单倍型（$h_A$ 和 $h_B$）后，纯合度的巨大跃升凸显了它们都是单倍型频率谱的主要贡献者。它们的合并频率为 $0.4 + 0.3 = 0.7$。如果它们是单一单倍型，其模式会更接近硬清除。而它们是不同的这一事实表明有多个单倍型频率上升。\n\n结论：存在至少两个高频单倍型（$h_A$ 和 $h_B$），定量地反映为高 $H_2/H_1$ 比值以及从 $H_1$ 到 $H_{12}$ 的大幅增加，这为该基因组区域经历了软清除而非硬清除提供了强有力的证据。",
            "answer": "$$\\boxed{\\begin{pmatrix} \\frac{1093}{4000} & \\frac{2053}{4000} & \\frac{453}{1093} \\end{pmatrix}}$$"
        },
        {
            "introduction": "除了分析单倍型结构, 位点频率谱 (SFS) 为检测选择性清除提供了另一条强有力的途径, 因为一次清除事件会独特地扭曲等位基因的频率分布。本练习将引导你应用一种在现代群体遗传学中至关重要的统计工具——复合似然比检验 。你将学习如何量化一个给定的SFS是更符合中性模型还是选择清除模型的证据, 从而让你亲身体验基因组扫描软件背后的核心统计逻辑。",
            "id": "2750222",
            "problem": "从单个基因组窗口中采集了一个大小为 $n_{\\text{sample}} = 20$ 条染色体的单倍体样本，其非折叠位点频率谱（site frequency spectrum (SFS)；通过外群定相的衍生等位基因计数）被归纳为 $K = 5$ 个不相交的衍生等位基因频率区间，这些区间划分了所有可能的非固定频率：\n- 区间 $1$：单例位点（衍生等位基因计数 $=1$），\n- 区间 $2$：双例位点（衍生等位基因计数 $=2$），\n- 区间 $3$：中低频位点（衍生等位基因计数 $=3$ 至 $5$），\n- 区间 $4$：中频位点（衍生等位基因计数 $=6$ 至 $10$），\n- 区间 $5$：高频衍生位点（衍生等位基因计数 $=11$ 至 $19$）。\n\n对于该窗口，在每个区间中观测到的分离位点计数为：\n- $n_1 = 100$，\n- $n_2 = 25$，\n- $n_3 = 35$，\n- $n_4 = 20$，\n- $n_5 = 20$。\n\n两个备选模型为这些区间分配了类别概率：\n- 中性基线模型概率 $q = (q_1,q_2,q_3,q_4,q_5) = (0.35, 0.20, 0.25, 0.15, 0.05)$，\n- 选择性清除模型概率 $p = (p_1,p_2,p_3,p_4,p_5) = (0.45, 0.15, 0.15, 0.10, 0.15)$，\n\n在每个模型中，概率总和为 $1$。假设在模型条件下，窗口内的位点是独立的（复合似然近似），并且计数产生于与这些区间概率一致的类别抽样。\n\n从类别计数的似然第一性原理出发，推导一个用于比较清除模型与中性模型的自然对数复合似然比的显式表达式，然后使用上述数值进行计算。在推导过程中，请明确说明计算的输入和输出。将最终数值答案四舍五入至四位有效数字。答案是无量纲的，不包含任何单位。",
            "solution": "所述问题具有科学依据、问题适定且客观。它是使用似然比检验进行统计模型比较的一个标准应用，这是计算生物学和统计学中的一种基本技术。所有必要的数据和参数都已提供，不存在内部矛盾或逻辑缺陷。我们可以开始求解。\n\n任务是推导并计算比较选择性清除模型 ($H_p$) 与中性基线模型 ($H_q$) 的自然对数复合似然比 $(\\lambda)$。输入是在 $K$ 个预定义频率区间中观测到的分离位点计数，以及两种竞争模型下与每个区间相关的类别概率。\n\n设观测计数向量为 $n = (n_1, n_2, \\dots, n_K)$，其中 $n_k$ 是区间 $k$ 中的位点数。对于此问题，我们有 $K=5$，计数为 $n = (100, 25, 35, 20, 20)$。\n观测到的分离位点总数为 $N = \\sum_{k=1}^{K} n_k$。\n\n两个模型由它们各自的概率向量定义，该向量表示一个位点落入 $K$ 个区间之一的概率：\n- 中性模型：$q = (q_1, q_2, \\dots, q_K) = (0.35, 0.20, 0.25, 0.15, 0.05)$\n- 清除模型：$p = (p_1, p_2, \\dots, p_K) = (0.45, 0.15, 0.15, 0.10, 0.15)$\n\n问题陈述假设在模型条件下位点是独立的。这意味着观测到特定计数集 $n$ 的概率由多项概率质量函数给出。在具有概率向量 $\\theta = (\\theta_1, \\dots, \\theta_K)$ 的通用模型下，数据 $n$ 的似然为：\n$$ L(\\theta|n) = \\frac{N!}{n_1! n_2! \\dots n_K!} \\prod_{k=1}^{K} \\theta_k^{n_k} $$\n项 $\\frac{N!}{n_1! n_2! \\dots n_K!}$ 是多项式系数，相对于模型参数 $\\theta$ 是一个常数。\n\n在清除模型 ($H_p$) 下数据的似然为：\n$$ L(p|n) = C \\cdot \\prod_{k=1}^{K} p_k^{n_k} $$\n其中 $C = \\frac{N!}{\\prod_{k=1}^{K} n_k!}$。\n\n在中性模型 ($H_q$) 下数据的似然为：\n$$ L(q|n) = C \\cdot \\prod_{k=1}^{K} q_k^{n_k} $$\n\n似然比 $\\Lambda$ 是备择模型（清除）的似然与零模型（中性）的似然之比：\n$$ \\Lambda = \\frac{L(p|n)}{L(q|n)} = \\frac{C \\cdot \\prod_{k=1}^{K} p_k^{n_k}}{C \\cdot \\prod_{k=1}^{K} q_k^{n_k}} $$\n常数 $C$ 被消去，这极大地简化了表达式。这种消去是对相同数据进行嵌套或非嵌套模型似然比检验的一个关键特征。\n$$ \\Lambda = \\frac{\\prod_{k=1}^{K} p_k^{n_k}}{\\prod_{k=1}^{K} q_k^{n_k}} = \\prod_{k=1}^{K} \\left(\\frac{p_k}{q_k}\\right)^{n_k} $$\n问题要求的是自然对数复合似然比 $\\lambda$。这通过取 $\\Lambda$ 的自然对数得到。\n$$ \\lambda = \\ln(\\Lambda) = \\ln\\left(\\prod_{k=1}^{K} \\left(\\frac{p_k}{q_k}\\right)^{n_k}\\right) $$\n利用对数的性质 $\\ln(ab) = \\ln(a) + \\ln(b)$ 和 $\\ln(x^y) = y\\ln(x)$，我们推导出 $\\lambda$ 的显式表达式：\n$$ \\lambda = \\sum_{k=1}^{K} \\ln\\left(\\left(\\frac{p_k}{q_k}\\right)^{n_k}\\right) = \\sum_{k=1}^{K} n_k \\ln\\left(\\frac{p_k}{q_k}\\right) $$\n这是分箱类别数据的对数似然比的通用表达式。\n\n现在，我们将提供的数值代入此表达式。输入为：\n- 计数：$n_1=100$, $n_2=25$, $n_3=35$, $n_4=20$, $n_5=20$。\n- 概率 $p$：$p_1=0.45$, $p_2=0.15$, $p_3=0.15$, $p_4=0.10$, $p_5=0.15$。\n- 概率 $q$：$q_1=0.35$, $q_2=0.20$, $q_3=0.25$, $q_4=0.15$, $q_5=0.05$。\n\n计算过程如下：\n$$ \\lambda = n_1 \\ln\\left(\\frac{p_1}{q_1}\\right) + n_2 \\ln\\left(\\frac{p_2}{q_2}\\right) + n_3 \\ln\\left(\\frac{p_3}{q_3}\\right) + n_4 \\ln\\left(\\frac{p_4}{q_4}\\right) + n_5 \\ln\\left(\\frac{p_5}{q_5}\\right) $$\n$$ \\lambda = 100 \\ln\\left(\\frac{0.45}{0.35}\\right) + 25 \\ln\\left(\\frac{0.15}{0.20}\\right) + 35 \\ln\\left(\\frac{0.15}{0.25}\\right) + 20 \\ln\\left(\\frac{0.10}{0.15}\\right) + 20 \\ln\\left(\\frac{0.15}{0.05}\\right) $$\n我们计算每一项：\n$$ 100 \\ln\\left(\\frac{9}{7}\\right) \\approx 100 \\times 0.2513147 = 25.13147 $$\n$$ 25 \\ln\\left(\\frac{3}{4}\\right) \\approx 25 \\times (-0.2876821) = -7.19205 $$\n$$ 35 \\ln\\left(\\frac{3}{5}\\right) \\approx 35 \\times (-0.5108256) = -17.87890 $$\n$$ 20 \\ln\\left(\\frac{2}{3}\\right) \\approx 20 \\times (-0.4054651) = -8.10930 $$\n$$ 20 \\ln(3) \\approx 20 \\times 1.0986123 = 21.97225 $$\n将这些单项相加，得到 $\\lambda$ 的最终值：\n$$ \\lambda \\approx 25.13147 - 7.19205 - 17.87890 - 8.10930 + 21.97225 $$\n$$ \\lambda \\approx 13.92347 $$\n问题要求答案四舍五入到四位有效数字。\n$$ \\lambda \\approx 13.92 $$\n对数似然比为正值，表明与中性模型相比，观测数据在选择性清除模型下更有可能出现。",
            "answer": "$$\\boxed{13.92}$$"
        },
        {
            "introduction": "检测群体特异性的适应性事件是进化生物学的一个激动人心的前沿。当一次选择性清除发生在一个群体中而非另一个群体中时, 它会在群体间的单倍型结构上留下极其鲜明的差异信号。在这个综合性练习中, 你的任务是根据第一性原理, 从头开始编程实现一个广泛应用的统计量——跨群体扩展单倍型纯合性(XP-EHH) 。通过将扩展单倍型纯合性 ($EHH$) 和连锁不平衡的理论概念转化为实际的代码, 你将获得检测群体间遗传分化和识别局域适应的宝贵实践经验。",
            "id": "2750224",
            "problem": "给定两个群体的定相单倍型数据和沿一维染色体的一组遗传标记位置。您的任务是，对每个测试用例，计算一个指定焦点（核心）标记的跨群体扩展单倍型纯合性 (XP-EHH)，并解释在该基因座上是否存在群体特异性选择性清除的证据。所有距离都必须视为以厘摩 (cM) 为单位的遗传距离，因此所有积分都必须以 cM 为单位表示。最终的数值统计量必须是一个无单位的实数。您的程序必须汇总所有测试用例的结果，并以指定的最终输出格式打印它们。\n\n使用的定义：\n- 扩展单倍型纯合性 (EHH)：对于一个拥有 $N$ 条染色体的群体，在核心标记 $c$ 的某一侧，设窗口包含从核心到该侧标记 $j$ 的所有标记。每条染色体为该窗口中的标记（包括核心标记）提供一个多位点单倍型字符串。假设在该窗口的 $N$ 条染色体中，存在 $K$ 个不同的单倍型字符串，其频率分别为 $p_1, p_2, \\dots, p_K$，其中 $\\sum_{k=1}^{K} p_k = 1$。在标记 $j$ 处的扩展单倍型纯合性为\n$$\nEHH(j) = \\sum_{k=1}^{K} p_k^2.\n$$\n- 对于右侧，窗口是从 $c$ 到 $j$（其中 $j \\ge c$），遗传距离为 $d_j^{(R)} = x_j - x_c$，其中 $x_j$ 是标记 $j$ 以 cM 为单位的位置。对于左侧，窗口是从 $j$ 到 $c$（其中 $j \\le c$），遗传距离为 $d_j^{(L)} = x_c - x_j$。在两侧都将核心本身作为距离为 $0$ 的点，并包含在单一位点窗口上计算的 $EHH(c)$。\n- 群体的整合单倍型纯合性 (iHH) 在此定义为左侧和右侧 $EHH$ 曲线的梯形积分之和，每个积分都从距离核心 $0$ 处开始，延伸到该侧最远的给定标记。如果一侧的采样距离为 $0 = d_0^{(s)} < d_1^{(s)} < \\dots < d_{M_s-1}^{(s)}$，对应的 $EHH$ 值为 $E_0^{(s)}, E_1^{(s)}, \\dots, E_{M_s-1}^{(s)}$，那么该侧的积分为\n$$\n\\sum_{m=1}^{M_s-1} \\frac{d_m^{(s)} - d_{m-1}^{(s)}}{2} \\left(E_m^{(s)} + E_{m-1}^{(s)}\\right),\n$$\n群体的 $iHH$ 是左侧和右侧积分的总和。$iHH$ 的单位是 cM。\n- 在核心处，群体 $A$ 和群体 $B$ 之间的跨群体扩展单倍型纯合性 (XP-EHH) 定义为两个积分值（$iHH$）比值的自然对数。为避免除以零，每个值都加上一个小的正则化项 $\\varepsilon$：\n$$\nX = \\ln\\!\\left(\\frac{iHH_A + \\varepsilon}{iHH_B + \\varepsilon}\\right),\n$$\n其中 $\\varepsilon = 10^{-8}$ cM。\n- 解释规则：给定一个阈值 $T > 0$，定义一个决策代码 $D$ 如下：\n$$\nD = \\begin{cases}\n1 & \\text{如果 } X > T \\quad (\\text{群体 A 中存在选择性清除的证据}),\\\\\n-1 & \\text{如果 } X < -T \\quad (\\text{群体 B 中存在选择性清除的证据}),\\\\\n0 & \\text{其他情况} \\quad (\\text{无决策}).\n\\end{cases}\n$$\n\n您程序的输入由代码中嵌入的测试套件固定。没有外部输入。每个测试用例包括：\n- 群体 A 的单倍型矩阵，形状为 $N_A \\times M$，只包含 $0$ 或 $1$，其中 $N_A$ 是染色体数量，$M$ 是标记数量。\n- 群体 B 的单倍型矩阵，形状为 $N_B \\times M$，定义类似。\n- 一个严格递增的标记位置数组 $x_0, x_1, \\dots, x_{M-1}$，单位为 cM。\n- 一个整数索引 $c$（$0 \\le c \\le M-1$），表示核心标记。\n- 一个严格为正的决策阈值 $T$。\n\n每个测试用例所需的输出是：\n- XP-EHH 值 $X$，四舍五入到 $6$ 位小数（作为实数）。\n- 决策代码 $D$，为 $\\{-1, 0, 1\\}$ 中的一个整数。\n\n您的程序应生成一行输出，其中包含用方括号括起来的、以逗号分隔的结果列表。每个元素本身必须是对应测试用例的 $[X,D]$ 形式的双元素列表。例如，一个有效的聚合输出可能看起来像 $[[0.123456,1],[0.000000,0],[-0.654321,-1]]$。\n\n测试套件：\n- 案例 1（正常路径，群体 A 中有明显抬升）：\n  - 群体 A 单倍型 ($N_A = 8$, $M = 5$)：\n    - $[0,1,1,1,1]$\n    - $[0,1,1,1,1]$\n    - $[0,1,1,1,1]$\n    - $[0,1,1,1,1]$\n    - $[1,1,1,1,1]$\n    - $[1,1,1,1,1]$\n    - $[1,1,1,1,1]$\n    - $[1,1,1,1,1]$\n  - 群体 B 单倍型 ($N_B = 8$, $M = 5$)：\n    - $[0,0,1,0,1]$\n    - $[1,0,1,1,0]$\n    - $[0,1,1,0,0]$\n    - $[1,1,1,1,1]$\n    - $[0,0,0,0,0]$\n    - $[1,0,0,1,1]$\n    - $[0,1,0,1,0]$\n    - $[1,1,0,0,1]$\n  - 位置（cM）：$[0.0, 0.1, 0.2, 0.3, 0.5]$\n  - 核心索引：$c = 2$\n  - 阈值：$T = 1.0$\n- 案例 2（边界情况，群体相同，预期接近零）：\n  - 群体 A 单倍型：与案例 1 的群体 A 相同\n  - 群体 B 单倍型：与案例 1 的群体 A 相同\n  - 位置（cM）：$[0.0, 0.1, 0.2, 0.3, 0.5]$\n  - 核心索引：$c = 2$\n  - 阈值：$T = 0.1$\n- 案例 3（相反抬升，群体 B 中有抬升）：\n  - 群体 A 单倍型：与案例 1 的群体 B 相同\n  - 群体 B 单倍型：与案例 1 的群体 A 相同\n  - 位置（cM）：$[0.0, 0.1, 0.2, 0.3, 0.5]$\n  - 核心索引：$c = 2$\n  - 阈值：$T = 1.0$\n- 案例 4（小样本量，最少标记）：\n  - 群体 A 单倍型 ($N_A = 2$, $M = 3$)：\n    - $[1,1,1]$\n    - $[1,1,1]$\n  - 群体 B 单倍型 ($N_B = 2$, $M = 3$)：\n    - $[0,1,0]$\n    - $[1,0,1]$\n  - 位置（cM）：$[1.0, 1.5, 2.0]$\n  - 核心索引：$c = 1$\n  - 阈值：$T = 0.6$\n\n实现说明：\n- 您必须完全按照所述定义进行实现。具体而言，使用从核心到所选侧标记 j 的窗口内的多位点单倍型频率来定义 EHH(j)，在两侧都包含核心点，并通过上述梯形法则将 iHH 计算为两侧积分之和。\n- 仅在指定的最终对数计算中，使用 $\\varepsilon = 10^{-8}$ cM 以保证数值稳定性。\n- 报告 X（四舍五入到 6 位小数）和 D（作为整数）。\n- 最终输出格式：打印一行，内容为一个带方括号的、逗号分隔的列表，其中包含按上述顺序列出的每个案例的结果，每个结果本身都是一个双元素列表 [X,D]。",
            "solution": "该问题要求计算跨群体扩展单倍型纯合性 ($XP-EHH$) 统计量，这是一个在群体遗传学中用于检测特定遗传位点上近期正向选择的度量。其核心原理是，选择性清除会迅速增加一个有益等位基因的频率，并通过遗传连锁，增加其所在单倍型的频率。与中性进化预期下的情况相比，这导致产生一个异常长的、高频率的单倍型。$XP-EHH$ 统计量比较了两个群体之间这种单倍型纯合性的程度，以识别群体特异性的选择性清除。一个群体中显著更高的整合单倍型纯合性表明，选择性清除发生在该群体中，而未发生在另一个群体中。\n\n计算过程通过遵循问题陈述中提供的精确定义来实现。整个过程可以分解为四个主要阶段：\n\n1.  **扩展单倍型纯合性 ($EHH$) 计算**：\n    对于给定的群体和索引为 $c$ 的核心标记，我们分析核心标记左侧和右侧的单倍型。对于某一侧的特定标记 $j$，我们考虑跨越从核心 $c$ 到 $j$（含）所有标记的多位点单倍型。设染色体数量为 $N$。我们识别此窗口中所有不同的单倍型 $k=1, \\dots, K$ 及其对应的频率 $p_k$。在标记 $j$ 处的 $EHH$ 是频率的平方和：\n    $$\n    EHH(j) = \\sum_{k=1}^{K} p_k^2\n    $$\n    该值表示从群体中随机选择的两条染色体携带从核心到标记 $j$ 的相同扩展单倍型的概率。$EHH$ 值为 $1$ 表示该窗口中所有染色体共享相同的单倍型。\n\n2.  **整合单倍型纯合性 ($iHH$) 计算**：\n    对于给定的核心等位基因，其 $EHH$ 值通常随着与核心标记距离的增加而减小，因为重组事件会随时间推移分解长程单倍型。我们通过对 $EHH$ 值按遗传距离进行积分来量化纯合性的总体程度。\n    对于每一侧（左侧，$s=L$，和右侧，$s=R$），我们有一组标记位置，这些位置被转换为与核心的遗传距离：对于 $j \\ge c$，有 $d_j^{(R)} = x_j - x_c$；对于 $j \\le c$，有 $d_j^{(L)} = x_c - x_j$。设一侧上已排序的唯一距离为 $0 = d_0^{(s)} < d_1^{(s)} < \\dots < d_{M_s-1}^{(s)}$，对应的 $EHH$ 值为 $E_0^{(s)}, E_1^{(s)}, \\dots, E_{M_s-1}^{(s)}$。根据指定，使用梯形法则计算 $EHH$ 曲线下的面积：\n    $$\n    \\text{Integral}^{(s)} = \\sum_{m=1}^{M_s-1} \\frac{d_m^{(s)} - d_{m-1}^{(s)}}{2} \\left(E_m^{(s)} + E_{m-1}^{(s)}\\right)\n    $$\n    一个群体的总整合单倍型纯合性 ($iHH$) 是左侧和右侧这些积分的总和。该值的单位是厘摩 (cM)。\n\n3.  **跨群体 $XP-EHH$ 统计量 ($X$) 计算**：\n    为了比较群体 A 和 B，我们计算它们各自 $iHH$ 值比值的自然对数。一个小的正则化常数 $\\varepsilon = 10^{-8}$ 被加到分子和分母上，以确保在 $iHH$ 值可能为零时数值的稳定性。$XP-EHH$ 统计量 $X$ 因此定义为：\n    $$\n    X = \\ln\\!\\left(\\frac{iHH_A + \\varepsilon}{iHH_B + \\varepsilon}\\right)\n    $$\n    $X$ 的一个大的正值表示 $iHH_A \\gg iHH_B$，表明在群体 A 中发生了选择性清除。一个大的负值表示 $iHH_B \\gg iHH_A$，表明在群体 B 中发生了选择性清除。一个接近零的值表明两个群体具有相似的单倍型纯合性特征。\n\n4.  **决策规则**：\n    最后，根据 $X$ 相对于给定的正阈值 $T$ 的值做出决策。决策代码 $D$ 按如下方式分配：\n    $$\n    D = \\begin{cases}\n    1 & \\text{如果 } X > T & (\\text{群体 A 中存在选择性清除的证据})\\\\\n    -1 & \\text{如果 } X < -T & (\\text{群体 B 中存在选择性清除的证据})\\\\\n    0 & \\text{其他情况} & (\\text{无决策})\n    \\end{cases}\n    $$\n实现封装了这些步骤。一个辅助函数计算单个群体的 $iHH$。该函数遍历核心左侧和右侧的标记，通过对扩展窗口中的唯一单倍型计数来计算每个点的 $EHH$，然后使用数值积分 (`numpy.trapz`) 来求面积。主函数为两个群体调用此辅助函数，计算 $X$，应用决策规则找到 $D$，并按要求格式化输出。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to solve the XP-EHH problem for the given test suite.\n    \"\"\"\n\n    test_cases = [\n        {\n            \"pop_A_haps\": np.array([\n                [0, 1, 1, 1, 1], [0, 1, 1, 1, 1], [0, 1, 1, 1, 1], [0, 1, 1, 1, 1],\n                [1, 1, 1, 1, 1], [1, 1, 1, 1, 1], [1, 1, 1, 1, 1], [1, 1, 1, 1, 1]\n            ]),\n            \"pop_B_haps\": np.array([\n                [0, 0, 1, 0, 1], [1, 0, 1, 1, 0], [0, 1, 1, 0, 0], [1, 1, 1, 1, 1],\n                [0, 0, 0, 0, 0], [1, 0, 0, 1, 1], [0, 1, 0, 1, 0], [1, 1, 0, 0, 1]\n            ]),\n            \"positions\": np.array([0.0, 0.1, 0.2, 0.3, 0.5]),\n            \"core_idx\": 2,\n            \"threshold\": 1.0\n        },\n        {\n            \"pop_A_haps\": np.array([\n                [0, 1, 1, 1, 1], [0, 1, 1, 1, 1], [0, 1, 1, 1, 1], [0, 1, 1, 1, 1],\n                [1, 1, 1, 1, 1], [1, 1, 1, 1, 1], [1, 1, 1, 1, 1], [1, 1, 1, 1, 1]\n            ]),\n            \"pop_B_haps\": np.array([\n                [0, 1, 1, 1, 1], [0, 1, 1, 1, 1], [0, 1, 1, 1, 1], [0, 1, 1, 1, 1],\n                [1, 1, 1, 1, 1], [1, 1, 1, 1, 1], [1, 1, 1, 1, 1], [1, 1, 1, 1, 1]\n            ]),\n            \"positions\": np.array([0.0, 0.1, 0.2, 0.3, 0.5]),\n            \"core_idx\": 2,\n            \"threshold\": 0.1\n        },\n        {\n            \"pop_A_haps\": np.array([\n                [0, 0, 1, 0, 1], [1, 0, 1, 1, 0], [0, 1, 1, 0, 0], [1, 1, 1, 1, 1],\n                [0, 0, 0, 0, 0], [1, 0, 0, 1, 1], [0, 1, 0, 1, 0], [1, 1, 0, 0, 1]\n            ]),\n            \"pop_B_haps\": np.array([\n                [0, 1, 1, 1, 1], [0, 1, 1, 1, 1], [0, 1, 1, 1, 1], [0, 1, 1, 1, 1],\n                [1, 1, 1, 1, 1], [1, 1, 1, 1, 1], [1, 1, 1, 1, 1], [1, 1, 1, 1, 1]\n            ]),\n            \"positions\": np.array([0.0, 0.1, 0.2, 0.3, 0.5]),\n            \"core_idx\": 2,\n            \"threshold\": 1.0\n        },\n        {\n            \"pop_A_haps\": np.array([\n                [1, 1, 1], [1, 1, 1]\n            ]),\n            \"pop_B_haps\": np.array([\n                [0, 1, 0], [1, 0, 1]\n            ]),\n            \"positions\": np.array([1.0, 1.5, 2.0]),\n            \"core_idx\": 1,\n            \"threshold\": 0.6\n        }\n    ]\n\n    def _calculate_ehh(hap_slice):\n        \"\"\"Helper to calculate EHH for a set of haplotypes (a slice of the main matrix).\"\"\"\n        n_chrom = hap_slice.shape[0]\n        if n_chrom == 0:\n            return 1.0\n        \n        _, counts = np.unique(hap_slice, axis=0, return_counts=True)\n        frequencies = counts / n_chrom\n        ehh = np.sum(frequencies**2)\n        return ehh\n\n    def _calculate_ihh(haplotypes, positions, core_idx):\n        \"\"\"Calculates iHH for a single population.\"\"\"\n        n_markers = haplotypes.shape[1]\n        core_pos = positions[core_idx]\n\n        # --- Right side calculation ---\n        right_indices = range(core_idx, n_markers)\n        right_distances = np.array([positions[j] - core_pos for j in right_indices])\n        right_ehh_values = np.array([_calculate_ehh(haplotypes[:, core_idx:j+1]) for j in right_indices])\n        \n        integral_right = 0.0\n        if len(right_distances) > 1:\n            integral_right = np.trapz(right_ehh_values, right_distances)\n\n        # --- Left side calculation ---\n        left_indices = range(core_idx, -1, -1)\n        left_distances = np.array([core_pos - positions[j] for j in left_indices])\n        left_ehh_values = np.array([_calculate_ehh(haplotypes[:, j:core_idx+1]) for j in left_indices])\n        \n        integral_left = 0.0\n        if len(left_distances) > 1:\n            integral_left = np.trapz(left_ehh_values, left_distances)\n\n        return integral_left + integral_right\n\n    results = []\n    epsilon = 1e-8\n\n    for case in test_cases:\n        hap_A = case[\"pop_A_haps\"]\n        hap_B = case[\"pop_B_haps\"]\n        positions = case[\"positions\"]\n        c = case[\"core_idx\"]\n        T = case[\"threshold\"]\n\n        ihh_A = _calculate_ihh(hap_A, positions, c)\n        ihh_B = _calculate_ihh(hap_B, positions, c)\n\n        X = np.log((ihh_A + epsilon) / (ihh_B + epsilon))\n\n        if X > T:\n            D = 1\n        elif X < -T:\n            D = -1\n        else:\n            D = 0\n        \n        results.append(f\"[{X:.6f},{D}]\")\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(results)}]\")\n\nsolve()\n```"
        }
    ]
}