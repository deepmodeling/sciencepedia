{
    "hands_on_practices": [
        {
            "introduction": "To truly master model selection, we must move from abstract formulas to concrete application. This first practice exercise is a fundamental workout in applying the Akaike Information Criterion ($AIC$) and Bayesian Information Criterion ($BIC$). By working through a realistic, albeit hypothetical, scenario with a set of nested nucleotide models, you will gain hands-on experience in counting parameters, calculating the criteria, and interpreting the results to select the best-fitting model for a given dataset .",
            "id": "2734801",
            "problem": "A nucleotide alignment of length $5000$ sites has been analyzed on a fixed, fully resolved unrooted topology relating $12$ taxa. For an unrooted binary phylogeny with $m$ taxa, there are $2m - 3$ branches, each with an independent branch-length parameter. The maximum log-likelihoods (natural logarithm) obtained under five time-homogeneous, time-reversible substitution models are given below, all estimated on the same topology and alignment:\n\n- JC69: $\\ln \\hat{L}_{\\mathrm{JC69}} = -7423.6$\n- HKY: $\\ln \\hat{L}_{\\mathrm{HKY}} = -7089.2$\n- GTR: $\\ln \\hat{L}_{\\mathrm{GTR}} = -7012.8$\n- GTR+G (four discrete gamma categories with a single shape parameter): $\\ln \\hat{L}_{\\mathrm{GTR+G}} = -6844.5$\n- GTR+G+I (gamma as above plus a proportion of invariable sites): $\\ln \\hat{L}_{\\mathrm{GTR+G+I}} = -6839.7$\n\nAssume standard parameterizations for nucleotide models: JC69 has equal base frequencies and equal exchangeabilities, contributing no free substitution-process parameters beyond the branch lengths; HKY adds one transition/transversion rate ratio parameter $\\kappa$ and three independent base-frequency parameters; GTR has five independent exchangeability parameters and three independent base-frequency parameters; the $+G$ extension adds one gamma shape parameter $\\alpha$; the $+I$ extension adds one parameter for the proportion of invariable sites. The number of discrete gamma categories is fixed and does not add parameters.\n\nUsing the canonical definitions of the Akaike Information Criterion (AIC) and the Bayesian Information Criterion (BIC), where each criterion balances the maximized log-likelihood against a penalty term that increases with the number of free parameters and, for BIC, with the sample size (here, the number of alignment sites), do the following:\n\n1. Determine the total number of free parameters $k$ for each model, including all branch lengths and model-specific parameters.\n2. Compute the AIC and BIC for each model.\n3. Identify the preferred model under AIC and under BIC (the model with the smallest value of each criterion).\n4. As your final numeric answer, report the Akaike weight (the normalized relative likelihood based on AIC) of the AIC-preferred model, expressed as a decimal fraction. Round your final numeric answer to four significant figures.",
            "solution": "The problem requires a comparative analysis of five nested models of nucleotide substitution using the Akaike Information Criterion (AIC) and the Bayesian Information Criterion (BIC). The objective is to identify the best-fitting model and quantify its support via its Akaike weight.\n\nFirst, we must define the criteria. The AIC is given by the formula:\n$$\nAIC = 2k - 2\\ln \\hat{L}\n$$\nwhere $k$ is the number of free parameters in the model and $\\ln \\hat{L}$ is the maximized natural log-likelihood. The BIC is given by:\n$$\nBIC = k \\ln(n) - 2\\ln \\hat{L}\n$$\nwhere $n$ is the sample size, which in this context is the number of sites in the nucleotide alignment, given as $n = 5000$.\n\nThe first step is to correctly determine the total number of free parameters, $k$, for each of the five models. The total number of parameters is the sum of the number of branch-length parameters and the number of substitution-process parameters.\nFor an unrooted binary phylogenetic tree with $m$ taxa, the number of branches is $2m - 3$. Here, with $m = 12$ taxa, the number of branches is $2(12) - 3 = 21$. Each branch has a length parameter, so all models share $k_{branches} = 21$ parameters.\n\nWe now determine the number of substitution-process parameters ($k_{subst}$) for each model as described:\n- **JC69**: This model assumes equal base frequencies and a single rate of substitution. It has no free parameters for the substitution process. Thus, $k_{subst, \\mathrm{JC69}} = 0$.\n- **HKY**: This model introduces a parameter for the transition/transversion rate ratio ($\\kappa$) and allows for unequal base frequencies. Since the four base frequencies must sum to $1$, there are $3$ free frequency parameters. Thus, $k_{subst, \\mathrm{HKY}} = 1 + 3 = 4$.\n- **GTR**: This is the general time-reversible model. It has $6$ exchangeability parameters, but they are relative, so only $5$ are free. It also has $3$ free base-frequency parameters. Thus, $k_{subst, \\mathrm{GTR}} = 5 + 3 = 8$.\n- **GTR+G**: This model adds a parameter for the gamma distribution of rates across sites, the shape parameter $\\alpha$. Thus, $k_{subst, \\mathrm{GTR+G}} = k_{subst, \\mathrm{GTR}} + 1 = 8 + 1 = 9$.\n- **GTR+G+I**: This model adds a parameter for the proportion of invariable sites, $p_{inv}$. Thus, $k_{subst, \\mathrm{GTR+G+I}} = k_{subst, \\mathrm{GTR+G}} + 1 = 9 + 1 = 10$.\n\nThe total number of parameters ($k$) for each model is:\n- $k_{\\mathrm{JC69}} = 21 + 0 = 21$\n- $k_{\\mathrm{HKY}} = 21 + 4 = 25$\n- $k_{\\mathrm{GTR}} = 21 + 8 = 29$\n- $k_{\\mathrm{GTR+G}} = 21 + 9 = 30$\n- $k_{\\mathrm{GTR+G+I}} = 21 + 10 = 31$\n\nWith the values of $k$, $\\ln \\hat{L}$, and $n=5000$, we can compute the AIC and BIC for each model.\n\n1. **JC69**: $k = 21$, $\\ln \\hat{L} = -7423.6$\n   $AIC_{\\mathrm{JC69}} = 2(21) - 2(-7423.6) = 42 + 14847.2 = 14889.2$\n   $BIC_{\\mathrm{JC69}} = 21\\ln(5000) - 2(-7423.6) \\approx 21(8.5172) + 14847.2 = 178.8612 + 14847.2 = 15026.0612$\n\n2. **HKY**: $k = 25$, $\\ln \\hat{L} = -7089.2$\n   $AIC_{\\mathrm{HKY}} = 2(25) - 2(-7089.2) = 50 + 14178.4 = 14228.4$\n   $BIC_{\\mathrm{HKY}} = 25\\ln(5000) - 2(-7089.2) \\approx 25(8.5172) + 14178.4 = 212.9300 + 14178.4 = 14391.3300$\n\n3. **GTR**: $k = 29$, $\\ln \\hat{L} = -7012.8$\n   $AIC_{\\mathrm{GTR}} = 2(29) - 2(-7012.8) = 58 + 14025.6 = 14083.6$\n   $BIC_{\\mathrm{GTR}} = 29\\ln(5000) - 2(-7012.8) \\approx 29(8.5172) + 14025.6 = 246.9988 + 14025.6 = 14272.5988$\n\n4. **GTR+G**: $k = 30$, $\\ln \\hat{L} = -6844.5$\n   $AIC_{\\mathrm{GTR+G}} = 2(30) - 2(-6844.5) = 60 + 13689.0 = 13749.0$\n   $BIC_{\\mathrm{GTR+G}} = 30\\ln(5000) - 2(-6844.5) \\approx 30(8.5172) + 13689.0 = 255.5160 + 13689.0 = 13944.5160$\n\n5. **GTR+G+I**: $k = 31$, $\\ln \\hat{L} = -6839.7$\n   $AIC_{\\mathrm{GTR+G+I}} = 2(31) - 2(-6839.7) = 62 + 13679.4 = 13741.4$\n   $BIC_{\\mathrm{GTR+G+I}} = 31\\ln(5000) - 2(-6839.7) \\approx 31(8.5172) + 13679.4 = 264.0332 + 13679.4 = 13943.4332$\n\nThe preferred model is the one that minimizes the information criterion score.\n- For AIC, the minimum value is $AIC_{min} = 13741.4$, corresponding to the **GTR+G+I** model.\n- For BIC, the minimum value is $BIC_{min} \\approx 13943.43$, also corresponding to the **GTR+G+I** model.\n\nFinally, we must calculate the Akaike weight of the preferred model under AIC, which is GTR+G+I. The Akaike weight ($w_i$) for model $i$ is a measure of its relative support among the set of candidate models. It is calculated as:\n$$\nw_i = \\frac{\\exp(-\\frac{1}{2}\\Delta_i)}{\\sum_{j=1}^{R} \\exp(-\\frac{1}{2}\\Delta_j)}\n$$\nwhere $\\Delta_i = AIC_i - AIC_{min}$ and $R=5$ is the number of models.\n\nFirst, we calculate the $\\Delta_i$ values for each model relative to $AIC_{min} = AIC_{\\mathrm{GTR+G+I}} = 13741.4$.\n- $\\Delta_{\\mathrm{JC69}} = 14889.2 - 13741.4 = 1147.8$\n- $\\Delta_{\\mathrm{HKY}} = 14228.4 - 13741.4 = 487.0$\n- $\\Delta_{\\mathrm{GTR}} = 14083.6 - 13741.4 = 342.2$\n- $\\Delta_{\\mathrm{GTR+G}} = 13749.0 - 13741.4 = 7.6$\n- $\\Delta_{\\mathrm{GTR+G+I}} = 13741.4 - 13741.4 = 0$\n\nNext, we calculate the numerator for the Akaike weight of the preferred model (GTR+G+I):\n$\\exp(-\\frac{1}{2}\\Delta_{\\mathrm{GTR+G+I}}) = \\exp(-\\frac{1}{2} \\times 0) = \\exp(0) = 1$.\n\nNow, we calculate the denominator, which is the sum of the relative likelihoods of all models:\n$\\sum_{j=1}^{5} \\exp(-\\frac{1}{2}\\Delta_j) = \\exp(-\\frac{1147.8}{2}) + \\exp(-\\frac{487.0}{2}) + \\exp(-\\frac{342.2}{2}) + \\exp(-\\frac{7.6}{2}) + \\exp(-\\frac{0}{2})$\n$\\sum_{j} \\exp(-\\frac{1}{2}\\Delta_j) = \\exp(-573.9) + \\exp(-243.5) + \\exp(-171.1) + \\exp(-3.8) + \\exp(0)$\nThe first three terms are vanishingly small and numerically negligible. We compute:\n$\\exp(-3.8) \\approx 0.0223708$\n$\\exp(0) = 1$\nSo, the sum is approximately $0 + 0 + 0 + 0.0223708 + 1 = 1.0223708$.\n\nThe Akaike weight for the GTR+G+I model is:\n$w_{\\mathrm{GTR+G+I}} = \\frac{1}{1.0223708} \\approx 0.978119$\n\nRounding to four significant figures, the Akaike weight of the AIC-preferred model is $0.9781$. This indicates that, given the data and the set of candidate models, there is approximately a $97.81\\%$ probability that the GTR+G+I model is the best model in the Kullback-Leibler sense.",
            "answer": "$$\\boxed{0.9781}$$"
        },
        {
            "introduction": "Information criteria are powerful, but their application requires careful thought about the comparison being made. This practice problem presents a crucial thought experiment that distinguishes between two common but conceptually distinct tasks in phylogenetics: selecting a substitution model on a fixed tree versus selecting a tree topology under a fixed model. Understanding how the penalty for complexity applies in each scenario is key to avoiding common interpretative errors .",
            "id": "2734810",
            "problem": "A multiple sequence alignment of $N=10$ taxa has $n=2000$ sites that, conditional on a phylogeny and a substitution model, are assumed to be independent and identically distributed across sites. Consider two distinct but closely related model selection tasks:\n\n- Task 1 (substitution model selection on a fixed topology): The unrooted, fully bifurcating tree topology $T^\\star$ is held fixed. You will compare three time-reversible, stationary, homogeneous substitution-process models that differ in parameterization. For each model $M_i$, let $k_i$ denote the total number of free parameters, including all branch lengths and all substitution-process parameters. The candidates and their maximized log-likelihoods are:\n  - $M_1=\\text{JC69}$ with $k_1=17$ and $\\ell_1=\\log L(M_1,T^\\star \\mid \\text{data})=-5500.0$.\n  - $M_2=\\text{HKY}$ with $k_2=21$ and $\\ell_2=\\log L(M_2,T^\\star \\mid \\text{data})=-5205.0$.\n  - $M_3=\\text{GTR}+\\Gamma+I$ with $k_3=27$ and $\\ell_3=\\log L(M_3,T^\\star \\mid \\text{data})=-5195.0$.\n\n- Task 2 (topology selection under a fixed substitution model): The substitution model is fixed to $M_2=\\text{HKY}$. You will compare three unrooted, fully bifurcating topologies $T_A,T_B,T_C$ on the same $N=10$ taxa. For each topology, all branch lengths and all $M_2$ parameters are optimized. Because all three topologies are fully resolved on the same taxon set under the same substitution model, the total parameter count is the same across them, $k_A=k_B=k_C=21$. The maximized log-likelihoods are:\n  - $\\ell_A=\\log L(M_2,T_A \\mid \\text{data})=-5200.0$,\n  - $\\ell_B=\\log L(M_2,T_B \\mid \\text{data})=-5192.0$,\n  - $\\ell_C=\\log L(M_2,T_C \\mid \\text{data})=-5195.0$.\n\nUsing only general principles of likelihood-based model comparison and information criteria, choose the single option that most accurately and completely:\n\n1) Clarifies the conceptual distinction between selecting among substitution models on a fixed topology versus selecting among tree topologies under a fixed substitution model, including how and why the complexity penalty enters differently in the two tasks.\n\n2) Correctly states, for the numerical values given above, which candidate is selected by the Akaike Information Criterion (AIC) and which by the Bayesian Information Criterion (BIC) in Task $1$, and which topology is selected by both criteria in Task $2$, together with the justification for why both criteria reduce to the same ranking across topologies in this setup.\n\nA. Under a fixed topology $T^\\star$, the three substitution models $M_1,M_2,M_3$ constitute distinct statistical models with different total parameter counts $k_i$, so both AIC and BIC trade off improved fit against added substitution-process and among-site-rate parameters. With the given $\\ell_i$ and $n=2000$, AIC selects $M_3$ while BIC selects $M_2$. Under a fixed substitution model and three fully bifurcating topologies on the same taxa, the total parameter count $k$ (all branch lengths plus substitution parameters) is identical across $T_A,T_B,T_C$, so the penalty terms are equal constants and both AIC and BIC reduce to choosing the maximum-likelihood topology, here $T_B$.\n\nB. The Bayesian Information Criterion should use the number of taxa $N=10$ as the sample size, so its penalty dominates for richer substitution models; therefore both AIC and BIC select $M_1$ in Task $1$. In Task $2$, BIC favors the most balanced topology topologically, so it would select $T_A$ even if its likelihood is lower.\n\nC. Information criteria cannot be applied to discrete objects like tree topologies; only likelihood ratio tests are appropriate. Because $T_A$ versus $T_B$ are non-nested, neither AIC nor BIC is meaningful, and one should pick $T_A$ by parsimony instead.\n\nD. When comparing topologies under a fixed substitution model, the number of parameters $k$ differs because branch length estimates differ across trees, so BIC penalizes trees with longer total branch length; in the given numbers it would pick $T_C$. In Task $1$, both AIC and BIC necessarily pick $M_3$ because it has the highest likelihood.\n\nE. Under a fixed topology, both AIC and BIC select the richest model $M_3$ given the likelihoods, and under a fixed substitution model both criteria select $T_B$; however, because BIC’s penalty varies across topologies even when the model is fixed, it can in principle reverse the likelihood ranking among fully bifurcating trees with the same number of taxa.",
            "solution": "We begin from the standard likelihood framework for phylogenetic inference under time-reversible, stationary, homogeneous substitution models with site independence. Given an alignment of $n$ sites and a candidate model (which consists of a substitution-process parameterization together with a tree topology and its branch lengths), the likelihood is\n$$\nL(\\text{model} \\mid \\text{data}) \\;=\\; \\prod_{i=1}^{n} p\\big(X_i \\mid \\text{model}\\big),\n$$\nwhere $X_i$ is the site pattern at site $i$ and $p(\\cdot \\mid \\text{model})$ is computed by Felsenstein’s pruning algorithm integrating over unobserved ancestral states. The log-likelihood is additive across sites:\n$$\n\\ell \\;=\\; \\log L \\;=\\; \\sum_{i=1}^{n} \\log p\\big(X_i \\mid \\text{model}\\big).\n$$\n\nInformation criteria provide principled, approximate ways to trade off data fit against model complexity. The Akaike Information Criterion (AIC) and the Bayesian Information Criterion (BIC) are defined by\n$$\n\\mathrm{AIC} \\;=\\; -2 \\ell \\;+\\; 2k, \n\\qquad\n\\mathrm{BIC} \\;=\\; -2 \\ell \\;+\\; k \\log n,\n$$\nwhere $k$ is the total number of free parameters of the model and $n$ is the sample size. Under the conventional independent-sites assumption, the appropriate sample size for BIC in phylogenetics is $n$ equal to the number of alignment sites. Lower values indicate preferred models.\n\nTwo conceptual points follow immediately from these definitions:\n\n- In Task $1$, the topology $T^\\star$ is fixed, so differences in $k$ across $M_1,M_2,M_3$ arise from the substitution-process parameterization (e.g., exchangeability rates, base frequencies, among-site rate variation parameters), while the number of branch-length parameters is the same across the $M_i$. Therefore, AIC and BIC will weigh improvements in $\\ell$ against increases in $k$ across the substitution models.\n\n- In Task $2$, the substitution model is fixed to $M_2$ and all three topologies $T_A,T_B,T_C$ are unrooted and fully bifurcating on the same $N=10$ taxa. Such trees all have the same number of branch-length parameters, namely $2N-3=17$, and the same number of substitution-process parameters (those of $M_2$), so the total $k$ is identical across the candidate topologies. Consequently, the penalty terms $2k$ (for AIC) and $k \\log n$ (for BIC) are equal constants across $T_A,T_B,T_C$, and both criteria reduce to ranking topologies by $\\ell$ alone, i.e., choosing the maximum-likelihood (ML) topology.\n\nWe now carry out the requested calculations.\n\nTask $1$ (fixed topology $T^\\star$, compare $M_1,M_2,M_3$):\n\n- Compute $-2\\ell$ for each model:\n  - $-2\\ell_1 = -2(-5500.0) = 11000.0$,\n  - $-2\\ell_2 = -2(-5205.0) = 10410.0$,\n  - $-2\\ell_3 = -2(-5195.0) = 10390.0$.\n\n- AIC values:\n  - $\\mathrm{AIC}(M_1) = 11000.0 + 2 \\times 17 = 11034.0$,\n  - $\\mathrm{AIC}(M_2) = 10410.0 + 2 \\times 21 = 10452.0$,\n  - $\\mathrm{AIC}(M_3) = 10390.0 + 2 \\times 27 = 10444.0$.\n  The smallest is $\\mathrm{AIC}(M_3)=10444.0$, so AIC selects $M_3$.\n\n- BIC values (with $n=2000$ sites and $\\log n = \\log 2000 \\approx 7.600902$):\n  - Penalties: $k_1 \\log n \\approx 17 \\times 7.600902 \\approx 129.215$, $k_2 \\log n \\approx 21 \\times 7.600902 \\approx 159.619$, $k_3 \\log n \\approx 27 \\times 7.600902 \\approx 205.224$.\n  - $\\mathrm{BIC}(M_1) \\approx 11000.0 + 129.215 = 11129.215$,\n  - $\\mathrm{BIC}(M_2) \\approx 10410.0 + 159.619 = 10569.619$,\n  - $\\mathrm{BIC}(M_3) \\approx 10390.0 + 205.224 = 10595.224$.\n  The smallest is $\\mathrm{BIC}(M_2)\\approx 10569.619$, so BIC selects $M_2$.\n\nThus, in Task $1$ the two criteria disagree in the intended way: AIC, with a parameter penalty that does not scale with $n$, is more permissive and selects the richer $M_3$, whereas BIC, with a penalty that grows with $\\log n$, is more conservative at $n=2000$ and selects the intermediate-complexity $M_2$.\n\nTask $2$ (fixed model $M_2$, compare topologies $T_A,T_B,T_C$):\n\n- Compute $-2\\ell$:\n  - $-2\\ell_A = -2(-5200.0) = 10400.0$,\n  - $-2\\ell_B = -2(-5192.0) = 10384.0$,\n  - $-2\\ell_C = -2(-5195.0) = 10390.0$.\n  Since $k_A=k_B=k_C=21$, both $\\mathrm{AIC}$ and $\\mathrm{BIC}$ differ across topologies only by $-2\\ell$, so both select the topology with the largest $\\ell$ (smallest $-2\\ell$), namely $T_B$.\n\nOption-by-option analysis:\n\n- Option A: This option correctly articulates the conceptual distinction: in Task $1$, differences in $k$ across substitution models drive the penalty trade-off, whereas in Task $2$, with fully bifurcating trees on the same taxa under a fixed substitution model, $k$ is identical across topologies, so penalties are equal constants and both criteria reduce to ML ranking. It also correctly identifies the selected models given the numbers: AIC selects $M_3$, BIC selects $M_2$ in Task $1$, and both select $T_B$ in Task $2$. Verdict — Correct.\n\n- Option B: This asserts that BIC should take the number of taxa $N=10$ as the sample size. Under the independent-sites model, the appropriate $n$ is the number of sites, not the number of taxa. It further claims both AIC and BIC pick $M_1$, which contradicts the explicit calculations above. It also invokes “balanced topology” as a BIC preference, which is not how information criteria operate. Verdict — Incorrect.\n\n- Option C: This claims information criteria cannot be applied to discrete objects like topologies and suggests likelihood ratio tests instead. Both AIC and BIC are explicitly designed to compare any finite set of fitted models, including discrete alternatives such as tree topologies. Moreover, likelihood ratio tests require nesting, which typically does not hold among distinct fully resolved topologies; information criteria are exactly for comparing such non-nested models. Verdict — Incorrect.\n\n- Option D: This claims $k$ differs across topologies because branch length estimates differ. The value estimates differ, but the number of free parameters $k$ does not: all fully bifurcating unrooted trees on the same taxon set have $2N-3$ branch lengths, hence the same $k$. It also asserts that BIC penalizes longer total branch length, which is false; penalties depend on parameter counts, not parameter magnitudes. Its claim that both AIC and BIC “necessarily pick $M_3$” in Task $1$ is contradicted by the BIC calculation above. Verdict — Incorrect.\n\n- Option E: While it correctly identifies $T_B$ in Task $2$, it incorrectly asserts that both AIC and BIC pick $M_3$ in Task $1$. It further claims that BIC’s penalty varies across fully bifurcating topologies with the same model and number of taxa, which is false in this setup because $k$ is the same across $T_A,T_B,T_C$. Verdict — Incorrect.\n\nTherefore, only Option A is correct.",
            "answer": "$$\\boxed{A}$$"
        },
        {
            "introduction": "The ultimate goal of model selection is to improve the accuracy of our inferences, but what happens when all our candidate models are wrong in some way? This advanced computational practice explores the important phenomenon of model misspecification. Through a guided simulation, you will investigate whether a highly flexible (but incorrect) model can actually achieve a better likelihood score than a simpler, true model, revealing a potential pitfall where complexity can mask topological error .",
            "id": "2406821",
            "problem": "You are asked to investigate a fundamental question in model selection for phylogenetics: can a complex substitution model with an incorrect tree topology achieve a higher maximum likelihood than a simple substitution model on the correct topology? Work within the setting of time-reversible nucleotide substitution models on fixed tree topologies and apply the standard likelihood for a Continuous-Time Markov Chain (CTMC) on a tree.\n\nBegin from the following bases:\n- A nucleotide substitution process along each branch is a CTMC with an instantaneous rate matrix denoted by $Q$, and transition probabilities along a branch of duration $t$ given by $P(t) = \\exp(Qt)$, where $\\exp$ denotes the matrix exponential.\n- The likelihood of an alignment on a fixed rooted binary tree under a time-reversible model can be computed by Felsenstein’s pruning algorithm using the stationary distribution $\\boldsymbol{\\pi}$ at the root and the transition probabilities for each branch. For a site, the likelihood is the sum over root states of the stationary probability multiplied by the product of conditional likelihoods propagated up from the leaves.\n- To model rate variation across sites, use the discrete-gamma approximation with $K$ categories: the per-site rate $r$ is drawn from a gamma distribution with shape parameter $\\alpha$ and mean $1$, approximated by $K$ equally probable categories with fixed rates $\\{r_k\\}_{k=1}^K$. The total site likelihood is the average over categories.\n\nYour task is to implement a simulation and likelihood evaluation demonstrating that a General Time Reversible (GTR) model with gamma-distributed rate heterogeneity across sites (GTR+$\\Gamma$) on a wrong topology can, in some cases, achieve a higher log-likelihood than the Jukes-Cantor $1969$ (JC$69$) model on the correct topology.\n\nFollow these specifications.\n\n1) Tree topologies and branch lengths.\n- Use $4$ taxa labeled $\\{A,B,C,D\\}$, and represent trees as rooted, strictly binary trees with a root at the internal node that splits into two internal nodes, each of which has two leaves. The root position is arbitrary under time-reversibility but must be fixed consistently for both simulation and likelihood calculation.\n- The “correct” topology is $((A,B),(C,D))$. The “wrong” topology is $((A,C),(B,D))$.\n- Each rooted tree has $6$ branches: root-to-left-internal ($\\ell_{RL}$), root-to-right-internal ($\\ell_{RR}$), and four pendant branches to leaves ($\\ell_A,\\ell_B,\\ell_C,\\ell_D$). A branch-length vector is $\\mathbf{\\ell} = [\\ell_A,\\ell_B,\\ell_C,\\ell_D,\\ell_{RL},\\ell_{RR}]$.\n- For evaluating likelihoods on the wrong topology, reuse the same branch-length vector $\\mathbf{\\ell}$ by assigning the same pendant lengths to the same leaves and the same two root-to-internal lengths to the two internal edges.\n\n2) Substitution models.\n- The simple model is JC$69$, with equal base frequencies and equal rates, scaled so that the expected substitution rate is $1$ per unit time. That is, for $i \\neq j$, $Q_{ij} = \\frac{1}{3}$ and $Q_{ii} = -1$, and the stationary distribution is $\\boldsymbol{\\pi}_{JC} = [\\frac{1}{4},\\frac{1}{4},\\frac{1}{4},\\frac{1}{4}]$.\n- The complex model is GTR+$\\Gamma$. Use a General Time Reversible (GTR) rate matrix with stationary base frequencies $\\boldsymbol{\\pi} = [\\pi_A,\\pi_C,\\pi_G,\\pi_T] = [0.36, 0.14, 0.24, 0.26]$ and symmetric exchangeability parameters for unordered nucleotide pairs:\n  - $r_{AC} = 0.7$, $r_{AG} = 2.0$, $r_{AT} = 0.3$, $r_{CG} = 0.5$, $r_{CT} = 1.5$, $r_{GT} = 0.7$.\n  - For $i \\neq j$, $Q_{ij} = r_{ij}\\,\\pi_j$, $Q_{ii} = -\\sum_{j\\neq i} Q_{ij}$. Scale $Q$ so that the mean substitution rate is $1$, i.e., $-\\sum_i \\pi_i Q_{ii} = 1$. Use $\\boldsymbol{\\pi}$ as the stationary distribution at the root.\n- For the gamma-distributed rates across sites, use $K=4$ categories with shape parameter $\\alpha$ and mean $1$; approximate category rates $\\{r_k\\}$ by the mid-quantiles of the $\\mathrm{Gamma}(\\alpha,\\text{scale} = \\frac{1}{\\alpha})$ distribution and rescale them so that $\\frac{1}{K}\\sum_{k=1}^K r_k = 1$.\n\n3) Simulation of alignments.\n- For each test case, simulate an alignment of $L$ independent and identically distributed sites on the correct topology under the GTR+$\\Gamma$ model with the specified $\\boldsymbol{\\pi}$, exchangeabilities $\\{r_{ij}\\}$, shape $\\alpha$, and branch-length vector $\\mathbf{\\ell}$. For each site, draw a rate category uniformly from the $K$ categories and generate nucleotide states at the leaves by propagating from the root (drawn from the stationary distribution $\\boldsymbol{\\pi}$) down the tree using $P(t) = \\exp(Q r_k t)$ along each branch for that site.\n\n4) Likelihood evaluations to compare.\n- Evaluate the log-likelihood on the correct topology under JC$69$ (no gamma), using the same branch-length vector $\\mathbf{\\ell}$ used for simulation. Denote this value by $\\mathcal{L}_{\\text{JC},\\text{correct}}$.\n- Evaluate the log-likelihood on the wrong topology under GTR+$\\Gamma$ with the true $\\boldsymbol{\\pi}$, $\\{r_{ij}\\}$, and the same $\\alpha$ and $K=4$, using the same branch-length vector $\\mathbf{\\ell}$. Denote this value by $\\mathcal{L}_{\\text{GTR}+\\Gamma,\\text{wrong}}$.\n- Use Felsenstein’s pruning algorithm with numerically stable scaling at internal nodes. For the gamma mixture, combine per-category site likelihoods by averaging across categories.\n\n5) Outputs and decision rule.\n- For each test case, compute the difference $\\Delta = \\mathcal{L}_{\\text{GTR}+\\Gamma,\\text{wrong}} - \\mathcal{L}_{\\text{JC},\\text{correct}}$ and then convert this to a boolean answer by testing whether $\\Delta > 0$.\n- The program should output a single line containing a list of booleans, one per test case, in the order given below, formatted as a Python-style list, e.g., \"[True,False,True]\".\n\n6) Test suite.\nUse the following three test cases, each fully specified by a random seed, alignment length $L$, gamma shape $\\alpha$, and branch-length vector $\\mathbf{\\ell} = [\\ell_A,\\ell_B,\\ell_C,\\ell_D,\\ell_{RL},\\ell_{RR}]$:\n- Case $1$ (short internal branches, strong rate variation): seed $= 7$, $L = 500$, $\\alpha = 0.3$, $\\mathbf{\\ell} = [0.3, 0.3, 0.3, 0.3, 0.01, 0.01]$.\n- Case $2$ (moderate internal branches, strong rate variation): seed $= 13$, $L = 1500$, $\\alpha = 0.3$, $\\mathbf{\\ell} = [0.3, 0.3, 0.3, 0.3, 0.2, 0.2]$.\n- Case $3$ (heterogeneous pendant lengths, moderate rate variation): seed $= 23$, $L = 2000$, $\\alpha = 1.5$, $\\mathbf{\\ell} = [0.5, 0.2, 0.5, 0.2, 0.4, 0.4]$.\n\nFinal output format:\n- Your program should produce a single line of output containing the results as a comma-separated Python-style list of booleans in the order of the three test cases, for example, \"[True,False,True]\".",
            "solution": "The problem presented is a valid inquiry into the phenomenon of model misspecification in molecular phylogenetics, a topic of central importance in computational biology. It asks whether a complex substitution model (GTR+$\\Gamma$) on an incorrect tree topology can yield a higher data likelihood than a simpler model (JC$69$) on the correct topology. This is a well-posed, scientifically grounded question, and all necessary parameters and procedures for a computational experiment have been provided. We shall therefore proceed with a formal solution.\n\nThe solution involves three main components: defining the phylogenetic models and tree structures, simulating sequence data under a specified scenario, and calculating the log-likelihood of this data under two competing hypotheses.\n\n**1. Phylogenetic Models and Continuous-Time Markov Chains**\n\nThe evolution of nucleotides at a single site along a branch of a phylogenetic tree is modeled as a Continuous-Time Markov Chain (CTMC). The process is defined by a $4 \\times 4$ instantaneous rate matrix $Q$, where the element $Q_{ij}$ for $i \\neq j$ represents the rate of substitution from nucleotide $i$ to nucleotide $j$. The diagonal elements are defined as $Q_{ii} = -\\sum_{j\\neq i} Q_{ij}$. The states correspond to the four nucleotides, which we index as $\\{A \\to 0, C \\to 1, G \\to 2, T \\to 3\\}$.\n\nThe probability of changing from state $i$ to state $j$ over a branch of length (duration) $t$ is given by the matrix exponential $P(t) = \\exp(Qt)$, where $(P(t))_{ij}$ is the desired transition probability. All models are assumed to be time-reversible, which implies that $\\pi_i Q_{ij} = \\pi_j Q_{ji}$ for all $i,j$, where $\\boldsymbol{\\pi} = [\\pi_A, \\pi_C, \\pi_G, \\pi_T]$ is the stationary distribution of the process.\n\n**1.1. Jukes-Cantor 1969 (JC69) Model**\n\nThis is the simplest substitution model. It assumes equal base frequencies and equal substitution rates.\n- The stationary distribution is uniform: $\\boldsymbol{\\pi}_{JC} = [\\frac{1}{4}, \\frac{1}{4}, \\frac{1}{4}, \\frac{1}{4}]$.\n- The rate matrix is structured such that all off-diagonal elements are equal. To ensure the expected number of substitutions per site per unit time is $1$, the matrix is scaled:\n$$\nQ_{JC} = \\begin{pmatrix} -1 & 1/3 & 1/3 & 1/3 \\\\ 1/3 & -1 & 1/3 & 1/3 \\\\ 1/3 & 1/3 & -1 & 1/3 \\\\ 1/3 & 1/3 & 1/3 & -1 \\end{pmatrix}\n$$\n\n**1.2. General Time Reversible (GTR) Model**\n\nThe GTR model is the most general time-reversible model. It is defined by:\n- A stationary distribution vector $\\boldsymbol{\\pi} = [\\pi_A, \\pi_C, \\pi_G, \\pi_T]$.\n- A symmetric matrix of exchangeability rates $R$, where $r_{ij} = r_{ji}$.\nThe off-diagonal elements of the unscaled GTR rate matrix, $Q'$, are $Q'_{ij} = r_{ij}\\pi_j$. The problem provides $\\boldsymbol{\\pi} = [0.36, 0.14, 0.24, 0.26]$ and the following exchangeabilities: $r_{AC}=0.7$, $r_{AG}=2.0$, $r_{AT}=0.3$, $r_{CG}=0.5$, $r_{CT}=1.5$, $r_{GT}=0.7$.\nThe matrix $Q$ is scaled such that the average rate of substitution is $1$:\n$$\n-\\sum_{i=0}^{3} \\pi_i Q_{ii} = 1\n$$\nThis is achieved by computing a scaling factor $\\beta = 1 / (-\\sum_i \\pi_i Q'_{ii})$ and setting $Q = \\beta Q'$.\n\n**1.3. Rate Heterogeneity Across Sites ($\\Gamma$ Model)**\n\nTo account for different evolutionary rates at different sites in an alignment, we use a discrete gamma distribution. The rates $r$ are drawn from a $\\mathrm{Gamma}(\\alpha, \\text{scale}=1/\\alpha)$ distribution, which has a mean of $1$. This continuous distribution is approximated by $K=4$ discrete rate categories. The rate for each category, $r_k$, is determined from the mid-points of the quantiles of the gamma distribution. Specifically, for $k \\in \\{1, 2, 3, 4\\}$, we find the value $r'_k$ at the cumulative probability of $(2k-1)/(2K)$. These rates are then rescaled to ensure their mean is $1$: $r_k = r'_k / (\\frac{1}{K}\\sum_j r'_j)$. The likelihood for a site is the average of the likelihoods computed for each of the $K$ rate categories.\n\n**2. Simulation of Sequence Data**\n\nSequence data (an alignment) is simulated on the \"correct\" tree topology, $((A,B),(C,D))$, using the GTR+$\\Gamma$ model. This rooted binary tree has a root node, two internal nodes, and four leaf (terminal) nodes labeled $A, B, C, D$. The branch lengths are given by the vector $\\mathbf{\\ell} = [\\ell_A,\\ell_B,\\ell_C,\\ell_D,\\ell_{RL},\\ell_{RR}]$.\n\nFor each of the $L$ sites in the alignment:\n1.  A rate category $k \\in \\{1, 2, 3, 4\\}$ is chosen uniformly at random. Let the corresponding rate be $r_k$.\n2.  A nucleotide state for the root is drawn from the stationary distribution $\\boldsymbol{\\pi}$.\n3.  This state is propagated down the tree. For each branch of length $t$, the state at the child node is drawn based on the transition probabilities $P(t \\cdot r_k) = \\exp(Q_{GTR} \\cdot t \\cdot r_k)$, conditional on the state of the parent node.\n4.  The process continues until states are determined for all four leaves, forming one column of the alignment.\nThis process is repeated $L$ times to generate the full alignment.\n\n**3. Likelihood Calculation via Felsenstein's Pruning Algorithm**\n\nThe log-likelihood of the simulated alignment is computed under two scenarios. Central to this is Felsenstein's pruning algorithm, which efficiently calculates the likelihood of the data for a given site on a fixed tree.\n\nLet $\\mathbf{D}_s$ be the data for site $s$ (the nucleotides at the four leaves). The algorithm computes the conditional likelihood vector $\\mathbf{L}_u^{(s)}$ for each node $u$ in the tree. This is a vector of four elements, where the $i$-th element, $L_{u,i}^{(s)}$, is the probability of observing the subtree data descending from $u$, given that node $u$ is in state $i$.\n\n-   **At the leaves:** For a leaf $u$ with observed nucleotide state $j$, the conditional likelihood vector is a \"one-hot\" vector: $L_{u,i}^{(s)} = \\delta_{ij}$, where $\\delta_{ij}$ is the Kronecker delta.\n-   **At an internal node:** For an internal node $u$ with children $v$ and $w$, connected by branches of lengths $t_v$ and $t_w$, the recursion is:\n    $$\n    L_{u,i}^{(s)} = \\left( \\sum_{j=0}^3 (P(t_v))_{ij} L_{v,j}^{(s)} \\right) \\left( \\sum_{k=0}^3 (P(t_w))_{ik} L_{w,k}^{(s)} \\right)\n    $$\n    This is a post-order traversal from leaves to the root.\n\nThe total likelihood for site $s$, given a model with stationary distribution $\\boldsymbol{\\pi}$, is calculated at the root (node $R$):\n$$\n\\mathcal{L}_s = P(\\mathbf{D}_s | \\text{Tree, Model}) = \\sum_{i=0}^3 \\pi_i L_{R,i}^{(s)}\n$$\nTo prevent numerical underflow with long alignments, the conditional likelihood vectors are rescaled at each internal node. The logarithm of the scaling factors is accumulated and added to the final log-likelihood.\n\nThe total log-likelihood for the entire alignment is the sum of the log-likelihoods of individual sites:\n$$\n\\mathcal{L} = \\sum_{s=1}^L \\log(\\mathcal{L}_s)\n$$\n\nFor the GTR+$\\Gamma$ model, the likelihood for a site is the average over the $K$ rate categories:\n$$\n\\mathcal{L}_s = \\frac{1}{K} \\sum_{k=1}^K P(\\mathbf{D}_s | \\text{Tree, Model with rate } r_k)\n$$\n\n**4. Comparison and Decision**\n\nWe perform two likelihood evaluations on the alignment simulated in Step 2:\n1.  $\\mathcal{L}_{\\text{JC},\\text{correct}}$: The log-likelihood under the JC$69$ model (without gamma rates, i.e., $K=1, r_1=1$) on the correct topology, $((A,B),(C,D))$.\n2.  $\\mathcal{L}_{\\text{GTR}+\\Gamma,\\text{wrong}}$: The log-likelihood under the GTR+$\\Gamma$ model (with the true simulation parameters) on the wrong topology, $((A,C),(B,D))$. The branch length vector $\\mathbf{\\ell}$ is reused by mapping pendant lengths to the corresponding leaves and internal lengths to the two new internal branches.\n\nThe final output is a boolean value indicating whether $\\mathcal{L}_{\\text{GTR}+\\Gamma,\\text{wrong}} > \\mathcal{L}_{\\text{JC},\\text{correct}}$. The phenomenon occurs when a more complex model (GTR+$\\Gamma$) finds a better fit for the data on an incorrect topology than a simpler, less flexible model (JC$69$) can achieve even on the correct topology. This highlights a potential pitfall in phylogenetic model selection, where model misspecification can mislead inference.\n```python\nimport numpy as np\nfrom scipy.linalg import expm\nfrom scipy.stats import gamma\nimport collections\n\n# Define nucleotide and taxa mapping\nNUCS = ['A', 'C', 'G', 'T']\nNUC_MAP = {n: i for i, n in enumerate(NUCS)}\nTAXA = ['A', 'B', 'C', 'D']\nTAXA_MAP = {t: i for i, t in enumerate(TAXA)}\n\ndef get_gtr_q_matrix(pi, r_params):\n    \"\"\"Constructs and scales the GTR rate matrix.\"\"\"\n    q_unscaled = np.zeros((4, 4))\n    r_mat = np.zeros((4, 4))\n    r_mat[0, 1] = r_mat[1, 0] = r_params['ac']\n    r_mat[0, 2] = r_mat[2, 0] = r_params['ag']\n    r_mat[0, 3] = r_mat[3, 0] = r_params['at']\n    r_mat[1, 2] = r_mat[2, 1] = r_params['cg']\n    r_mat[1, 3] = r_mat[3, 1] = r_params['ct']\n    r_mat[2, 3] = r_mat[3, 2] = r_params['gt']\n\n    for i in range(4):\n        for j in range(4):\n            if i != j:\n                q_unscaled[i, j] = r_mat[i, j] * pi[j]\n    \n    for i in range(4):\n        q_unscaled[i, i] = -np.sum(q_unscaled[i, :])\n\n    # Scale the matrix so the average rate is 1\n    mean_rate = -np.sum(pi * np.diag(q_unscaled))\n    if mean_rate == 0:\n        return q_unscaled \n    return q_unscaled / mean_rate\n\ndef get_jc69_q_matrix():\n    \"\"\"Constructs the JC69 rate matrix.\"\"\"\n    q = np.full((4, 4), 1/3)\n    np.fill_diagonal(q, -1)\n    return q\n\ndef get_gamma_rates(alpha, K):\n    \"\"\"Computes K discrete gamma rates with mean 1.\"\"\"\n    if alpha == np.inf: # Case of no rate variation\n        return np.ones(K)\n    \n    # Use mid-quantile approximation\n    probs = (np.arange(K) + 0.5) / K\n    rates = gamma.ppf(probs, a=alpha, scale=1/alpha)\n    \n    # Rescale to have a mean of 1\n    rates /= np.mean(rates)\n    return rates\n\ndef build_tree_from_case(case, topology_type):\n    \"\"\"Builds a tree dictionary based on topology and branch lengths.\"\"\"\n    l_A, l_B, l_C, l_D, l_RL, l_RR = case['l']\n    \n    leaf_A = {'name': 'A', 'bl': l_A, 'children': []}\n    leaf_B = {'name': 'B', 'bl': l_B, 'children': []}\n    leaf_C = {'name': 'C', 'bl': l_C, 'children': []}\n    leaf_D = {'name': 'D', 'bl': l_D, 'children': []}\n\n    if topology_type == 'correct':\n        # Topology: ((A,B),(C,D))\n        internal_1 = {'name': 'N1', 'bl': l_RL, 'children': [leaf_A, leaf_B]}\n        internal_2 = {'name': 'N2', 'bl': l_RR, 'children': [leaf_C, leaf_D]}\n        root = {'name': 'root', 'bl': 0.0, 'children': [internal_1, internal_2]}\n    elif topology_type == 'wrong':\n        # Topology: ((A,C),(B,D))\n        internal_1 = {'name': 'N1', 'bl': l_RL, 'children': [leaf_A, leaf_C]}\n        internal_2 = {'name': 'N2', 'bl': l_RR, 'children': [leaf_B, leaf_D]}\n        root = {'name': 'root', 'bl': 0.0, 'children': [internal_1, internal_2]}\n    else:\n        raise ValueError(\"Unknown topology type\")\n        \n    return root\n\ndef simulate_alignment(tree, q_matrix, pi, gamma_rates, L, rng):\n    \"\"\"Simulates a sequence alignment on the given tree.\"\"\"\n    K = len(gamma_rates)\n    alignment = np.zeros((L, 4), dtype=int)\n    \n    # Pre-calculate transition matrices for each branch and rate category\n    memo_p = {}\n    \n    for site_idx in range(L):\n        rate_idx = rng.choice(K)\n        rate = gamma_rates[rate_idx]\n        \n        # Simulate one column of the alignment top-down\n        q = collections.deque()\n        root_state = rng.choice(4, p=pi)\n        q.append((tree, root_state))\n        leaf_states = {}\n        \n        while q:\n            node, parent_state = q.popleft()\n            for child in node['children']:\n                bl = child['bl']\n                # Memoize P(t) computation\n                key = (bl, rate_idx)\n                if key not in memo_p:\n                    memo_p[key] = expm(q_matrix * bl * rate)\n                P = memo_p[key]\n                \n                child_state = rng.choice(4, p=P[parent_state, :])\n                if not child['children']:  # Leaf node\n                    leaf_states[child['name']] = child_state\n                else:  # Internal node\n                    q.append((child, child_state))\n    \n        for i, taxon_name in enumerate(TAXA):\n            alignment[site_idx, i] = leaf_states[taxon_name]\n            \n    return alignment\n\ndef calculate_log_likelihood(alignment, tree, q_matrix, pi, gamma_rates):\n    \"\"\"Calculates the log-likelihood of an alignment given a tree and model.\"\"\"\n    L = alignment.shape[0]\n    K = len(gamma_rates)\n    total_log_likelihood = 0.0\n    \n    # Memoize P(t) matrices\n    memo_p_lik = {}\n    \n    for site_idx in range(L):\n        site_data = {taxon: alignment[site_idx, tax_idx] for tax_idx, taxon in enumerate(TAXA)}\n        \n        per_category_likelihoods = np.zeros(K)\n        for k in range(K):\n            rate = gamma_rates[k]\n            \n            # Recursive computation of conditional likelihoods\n            log_scaler_sum, root_likelihood_vec = _pruning_recursion(tree, site_data, q_matrix, rate, memo_p_lik)\n            \n            site_lik_for_category = np.dot(pi, root_likelihood_vec)\n            \n            # Add log of site likelihood for this category\n            if site_lik_for_category > 0:\n                log_lik_for_category = np.log(site_lik_for_category) + log_scaler_sum\n                per_category_likelihoods[k] = np.exp(log_lik_for_category)\n\n        # Average likelihoods over categories\n        site_avg_likelihood = np.mean(per_category_likelihoods)\n        \n        if site_avg_likelihood > 0:\n            total_log_likelihood += np.log(site_avg_likelihood)\n            \n    return total_log_likelihood\n\ndef _pruning_recursion(node, site_data, q_matrix, rate, memo):\n    \"\"\"Recursive helper for Felsenstein's pruning algorithm.\"\"\"\n    if not node['children']: # Leaf node\n        likelihood_vec = np.zeros(4)\n        likelihood_vec[site_data[node['name']]] = 1.0\n        return 0.0, likelihood_vec\n\n    child_results = []\n    total_log_scaler = 0.0\n    \n    for child in node['children']:\n        log_scaler, child_likelihood_vec = _pruning_recursion(child, site_data, q_matrix, rate, memo)\n        total_log_scaler += log_scaler\n        \n        bl = child['bl']\n        key = (bl, rate)\n        if key not in memo:\n            memo[key] = expm(q_matrix * bl * rate)\n        P = memo[key]\n        \n        transformed_vec = P @ child_likelihood_vec\n        child_results.append(transformed_vec)\n    \n    # Element-wise product of children's likelihood vectors\n    node_likelihood_vec = child_results[0]\n    for i in range(1, len(child_results)):\n        node_likelihood_vec *= child_results[i]\n        \n    # Numerical scaling\n    scaler = np.sum(node_likelihood_vec)\n    if scaler > 1e-300: # Avoid log(0)\n        node_likelihood_vec /= scaler\n        total_log_scaler += np.log(scaler)\n        \n    return total_log_scaler, node_likelihood_vec\n\n\ndef solve():\n    test_cases = [\n        {'seed': 7, 'L': 500, 'alpha': 0.3, 'l': [0.3, 0.3, 0.3, 0.3, 0.01, 0.01]},\n        {'seed': 13, 'L': 1500, 'alpha': 0.3, 'l': [0.3, 0.3, 0.3, 0.3, 0.2, 0.2]},\n        {'seed': 23, 'L': 2000, 'alpha': 1.5, 'l': [0.5, 0.2, 0.5, 0.2, 0.4, 0.4]},\n    ]\n    \n    gtr_pi = np.array([0.36, 0.14, 0.24, 0.26])\n    gtr_r = {'ac': 0.7, 'ag': 2.0, 'at': 0.3, 'cg': 0.5, 'ct': 1.5, 'gt': 0.7}\n    \n    results = []\n    \n    for case in test_cases:\n        rng = np.random.default_rng(case['seed'])\n        \n        # --- 1. Simulation Setup ---\n        # GTR+Gamma model for simulation\n        q_gtr = get_gtr_q_matrix(gtr_pi, gtr_r)\n        gamma_rates_sim = get_gamma_rates(case['alpha'], K=4)\n        correct_tree = build_tree_from_case(case, 'correct')\n        \n        # Simulate alignment on CORRECT topology with GTR+Gamma\n        alignment = simulate_alignment(correct_tree, q_gtr, gtr_pi, gamma_rates_sim, case['L'], rng)\n        \n        # --- 2. Likelihood Calculation ---\n        \n        # Likelihood on CORRECT topology with JC69 model\n        q_jc69 = get_jc69_q_matrix()\n        pi_jc69 = np.array([0.25, 0.25, 0.25, 0.25])\n        # JC69 has no rate variation, so K=1, rate=1.0 is equivalent\n        gamma_rates_jc = np.array([1.0])\n        \n        log_lik_jc_correct = calculate_log_likelihood(alignment, correct_tree, q_jc69, pi_jc69, gamma_rates_jc)\n\n        # Likelihood on WRONG topology with GTR+Gamma model\n        wrong_tree = build_tree_from_case(case, 'wrong')\n        gamma_rates_gtr = get_gamma_rates(case['alpha'], K=4) # Use case alpha\n        \n        log_lik_gtr_wrong = calculate_log_likelihood(alignment, wrong_tree, q_gtr, gtr_pi, gamma_rates_gtr)\n        \n        # --- 3. Comparison ---\n        delta = log_lik_gtr_wrong - log_lik_jc_correct\n        results.append(delta > 0)\n        \n    print(f\"[{','.join(map(str, results))}]\")\n\n# This function call would be executed to generate the answer.\n# solve()\n```",
            "answer": "$$\\boxed{\\texttt{[True,True,False]}}$$"
        }
    ]
}