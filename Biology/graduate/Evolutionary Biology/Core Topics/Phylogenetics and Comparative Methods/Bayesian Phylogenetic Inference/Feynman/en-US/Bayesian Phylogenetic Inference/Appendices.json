{
    "hands_on_practices": [
        {
            "introduction": "At the heart of any phylogenetic likelihood calculation is a model of nucleotide substitution, which describes the process of evolutionary change along the branches of a tree. This first practice takes you back to these mathematical foundations by exploring the Jukes-Cantor (JC69) model, a fundamental continuous-time Markov chain for sequence evolution. By deriving the transition probabilities directly from the model's generator matrix, you will gain a concrete understanding of how branch lengths, measured in expected substitutions per site, translate into the probabilities of sequence change that underpin the entire inference process .",
            "id": "2694200",
            "problem": "In Bayesian phylogenetic inference, branch likelihoods are computed from nucleotide substitution probabilities along branches. Consider the Jukes–Cantor (JC69) nucleotide substitution model, which assumes a time-homogeneous continuous-time Markov chain (CTMC) on the alphabet $\\{A, C, G, T\\}$ with equal equilibrium frequencies $\\pi_{i} = \\frac{1}{4}$ and equal instantaneous substitution rates between any two distinct nucleotides. Let the CTMC generator (rate) matrix be $Q$, with entries $Q_{ij} = \\frac{\\mu}{3}$ for $i \\neq j$ and $Q_{ii} = -\\mu$, so that the mean instantaneous substitution rate is $\\mu$. The transition probability matrix along a branch of length $t$ is $P(t) = \\exp(Qt)$, and a branch length $t$ is defined by the standard scaling that the expected number of substitutions per site along the branch equals $t$. Under this scaling, the mean substitution rate equals $1$.\n\nStarting only from the CTMC definitions above and the scaling convention that makes the expected substitutions per site equal to the branch length $t$, derive closed-form expressions for the JC69 transition probabilities $P_{ii}(t)$ and $P_{ij}(t)$ for $i \\neq j$, and then compute the numerical value of $P_{ii}(0.1)$. Report the final numerical value of $P_{ii}(0.1)$ rounded to four significant figures.",
            "solution": "The problem statement is subjected to validation and is found to be scientifically grounded, well-posed, and internally consistent. It describes a standard derivation in molecular evolution. We shall proceed with the solution.\n\nThe problem requires the derivation of the transition probabilities for the Jukes-Cantor (JC69) model of nucleotide substitution, starting from the definition of its generator matrix $Q$. The state space is the set of four nucleotides $\\{A, C, G, T\\}$. The generator matrix $Q$ for a continuous-time Markov chain is given with entries $Q_{ij} = \\frac{\\mu}{3}$ for any two distinct states $i, j$ and $Q_{ii} = -\\mu$, where $\\mu$ is the mean instantaneous substitution rate.\n\nThe model assumes uniform equilibrium frequencies, $\\pi_i = \\frac{1}{4}$ for each nucleotide $i$. The overall mean substitution rate, averaged across all states at equilibrium, is defined as $r = -\\sum_{i} \\pi_i Q_{ii}$. Substituting the given values, we find $r = \\sum_{i} \\pi_i \\mu = \\sum_{i=1}^{4} \\frac{1}{4} \\mu = \\mu$.\n\nThe problem specifies a scaling convention where this mean substitution rate equals $1$. Therefore, we must have $\\mu=1$. This convention also ensures that the branch length $t$ is equal to the expected number of substitutions per site, as the expected number is given by the product of the mean rate and time, which is $r \\times t = 1 \\times t = t$.\n\nWith $\\mu=1$, the $4 \\times 4$ generator matrix $Q$ is:\n$$\nQ = \\begin{pmatrix}\n-1 & \\frac{1}{3} & \\frac{1}{3} & \\frac{1}{3} \\\\\n\\frac{1}{3} & -1 & \\frac{1}{3} & \\frac{1}{3} \\\\\n\\frac{1}{3} & \\frac{1}{3} & -1 & \\frac{1}{3} \\\\\n\\frac{1}{3} & \\frac{1}{3} & \\frac{1}{3} & -1\n\\end{pmatrix}\n$$\nThe transition probability matrix $P(t)$ over a branch of length $t$ is given by the matrix exponential $P(t) = \\exp(Qt)$. To compute this, we can express $Q$ as a linear combination of the identity matrix $I$ and the matrix of all ones, $J$. A direct inspection shows that $Q = \\frac{1}{3}J - \\frac{4}{3}I$.\nLet us verify this decomposition. For an off-diagonal element ($i \\neq j$), the $(i,j)$-th entry is $\\frac{1}{3}J_{ij} - \\frac{4}{3}I_{ij} = \\frac{1}{3}(1) - \\frac{4}{3}(0) = \\frac{1}{3}$. For a diagonal element ($i=j$), the $(i,i)$-th entry is $\\frac{1}{3}J_{ii} - \\frac{4}{3}I_{ii} = \\frac{1}{3}(1) - \\frac{4}{3}(1) = -\\frac{3}{3} = -1$. The decomposition is correct.\n\nSince the matrices $I$ and $J$ commute, we can write $\\exp(Qt) = \\exp((\\frac{1}{3}J - \\frac{4}{3}I)t) = \\exp(-\\frac{4}{3}tI) \\exp(\\frac{t}{3}J)$.\nThe first term is simply $\\exp(-\\frac{4}{3}t)I$.\nFor the second term, we use the Taylor series expansion of the exponential function, $\\exp(X) = \\sum_{k=0}^{\\infty} \\frac{X^k}{k!}$. We require the powers of $J$. For a $4 \\times 4$ matrix $J$, we have the property $J^k = 4^{k-1}J$ for $k \\ge 1$.\n$$\n\\exp\\left(\\frac{t}{3}J\\right) = I + \\sum_{k=1}^{\\infty} \\frac{(\\frac{t}{3}J)^k}{k!} = I + \\sum_{k=1}^{\\infty} \\frac{(\\frac{t}{3})^k J^k}{k!} = I + J \\sum_{k=1}^{\\infty} \\frac{t^k 4^{k-1}}{3^k k!}\n$$\n$$\n= I + \\frac{J}{4} \\sum_{k=1}^{\\infty} \\frac{(4t/3)^k}{k!} = I + \\frac{J}{4} \\left( \\sum_{k=0}^{\\infty} \\frac{(4t/3)^k}{k!} - 1 \\right) = I + \\frac{J}{4} \\left( \\exp\\left(\\frac{4t}{3}\\right) - 1 \\right)\n$$\nNow, we combine the terms to find $P(t)$:\n$$\nP(t) = \\exp\\left(-\\frac{4t}{3}\\right)I \\cdot \\left[ I + \\frac{J}{4}\\left(\\exp\\left(\\frac{4t}{3}\\right) - 1\\right) \\right] = \\exp\\left(-\\frac{4t}{3}\\right)I + \\frac{J}{4}\\left(1 - \\exp\\left(-\\frac{4t}{3}\\right)\\right)\n$$\nFrom this matrix equation, we derive the expressions for the individual transition probabilities.\nThe probability of remaining in the same state, $P_{ii}(t)$, is a diagonal element of $P(t)$.\n$$\nP_{ii}(t) = \\left( \\exp\\left(-\\frac{4t}{3}\\right)I \\right)_{ii} + \\left( \\frac{J}{4}\\left(1 - \\exp\\left(-\\frac{4t}{3}\\right)\\right) \\right)_{ii}\n$$\n$$\nP_{ii}(t) = \\exp\\left(-\\frac{4t}{3}\\right) \\cdot 1 + \\frac{1}{4}\\left(1 - \\exp\\left(-\\frac{4t}{3}\\right)\\right) \\cdot 1 = \\frac{1}{4} + \\frac{3}{4}\\exp\\left(-\\frac{4t}{3}\\right)\n$$\nThe probability of transitioning to a different specific state, $P_{ij}(t)$ for $i \\neq j$, is an off-diagonal element of $P(t)$.\n$$\nP_{ij}(t) = \\left( \\exp\\left(-\\frac{4t}{3}\\right)I \\right)_{ij} + \\left( \\frac{J}{4}\\left(1 - \\exp\\left(-\\frac{4t}{3}\\right)\\right) \\right)_{ij}\n$$\n$$\nP_{ij}(t) = \\exp\\left(-\\frac{4t}{3}\\right) \\cdot 0 + \\frac{1}{4}\\left(1 - \\exp\\left(-\\frac{4t}{3}\\right)\\right) \\cdot 1 = \\frac{1}{4}\\left(1 - \\exp\\left(-\\frac{4t}{3}\\right)\\right)\n$$\nThese are the required closed-form expressions.\n\nFinally, we must compute the numerical value of $P_{ii}(0.1)$, rounded to four significant figures. We substitute $t=0.1$ into our derived formula for $P_{ii}(t)$:\n$$\nP_{ii}(0.1) = \\frac{1}{4} + \\frac{3}{4}\\exp\\left(-\\frac{4 \\times 0.1}{3}\\right) = 0.25 + 0.75\\exp\\left(-\\frac{0.4}{3}\\right) = 0.25 + 0.75\\exp\\left(-\\frac{2}{15}\\right)\n$$\nThe exponent is $-\\frac{2}{15} \\approx -0.13333$.\nCalculating the value:\n$$\nP_{ii}(0.1) \\approx 0.25 + 0.75 \\times (0.8751850) = 0.25 + 0.65638875 = 0.90638875\n$$\nRounding to four significant figures gives $0.9064$.",
            "answer": "$$\\boxed{0.9064}$$"
        },
        {
            "introduction": "Bayesian phylogenetic inference relies on exploring the vast 'tree space' to find trees well-supported by the data, a task accomplished using Markov chain Monte Carlo (MCMC) methods. This exercise focuses on the core engine of this exploration: the Metropolis-Hastings acceptance rule . By calculating the acceptance probability for a single proposed move between two states, you will demystify how the algorithm intelligently navigates the posterior landscape, balancing moves toward better hypotheses against the proposal mechanism's own biases.",
            "id": "2694143",
            "problem": "In Bayesian phylogenetic inference, we target the posterior distribution over trees, where the posterior density for a tree state $x$ is denoted by $\\pi(x)$ and is proportional to the product of the likelihood of the sequence data under $x$ and the prior on trees and model parameters. A Metropolis–Hastings move is used to propose a new tree state $y$ from $x$ according to a proposal distribution with transition probability $q(x \\to y)$, and the move is then accepted with a probability designed to leave the target posterior invariant.\n\nSuppose we are performing Markov chain Monte Carlo on the posterior over rooted phylogenetic trees for a clade, and a single-tree move is proposed that does not change the dimensionality of the parameterization (so no Jacobian factor is required). You are given the following unnormalized posterior densities and proposal probabilities for the current state $x$ and the proposed state $y$:\n- $\\pi(x) = \\exp(-100)$,\n- $\\pi(y) = \\exp(-98)$,\n- $q(x \\to y) = 0.3$,\n- $q(y \\to x) = 0.6$.\n\nCompute the Metropolis–Hastings acceptance probability for this move. Express the final answer as a single real number between $0$ and $1$. No rounding is required.",
            "solution": "The problem asks for the computation of the Metropolis-Hastings acceptance probability for a proposed move in a Markov chain Monte Carlo (MCMC) simulation targeting a posterior distribution over phylogenetic trees.\n\nThe problem is first validated for correctness and solvability.\n\n**Step 1: Extract Givens**\n- Unnormalized posterior density of the current state $x$: $\\pi(x) = \\exp(-100)$.\n- Unnormalized posterior density of the proposed state $y$: $\\pi(y) = \\exp(-98)$.\n- Forward proposal probability from $x$ to $y$: $q(x \\to y) = 0.3$.\n- Reverse proposal probability from $y$ to $x$: $q(y \\to x) = 0.6$.\n- The move does not change parameter dimensionality, so the Jacobian determinant is $1$.\n\n**Step 2: Validate Using Extracted Givens**\nThe problem is scientifically grounded, as it describes a standard application of the Metropolis-Hastings algorithm, a cornerstone of MCMC methods used extensively in Bayesian statistics and computational biology. The problem is well-posed, providing all necessary quantities for the calculation. The definitions and values are objective, precise, and consistent. The problem is a straightforward, non-trivial test of understanding of the MCMC acceptance criterion. No flaws are identified.\n\n**Step 3: Verdict and Action**\nThe problem is deemed **valid**. A solution will be derived.\n\nThe Metropolis-Hastings algorithm ensures that the generated Markov chain has the target posterior distribution $\\pi$ as its stationary distribution. This is achieved by designing an acceptance probability $\\alpha(x \\to y)$ for a proposed move from state $x$ to state $y$. The general formula for this acceptance probability is:\n$$\n\\alpha(x \\to y) = \\min \\left( 1, \\frac{\\pi(y) q(y \\to x)}{\\pi(x) q(x \\to y)} |J| \\right)\n$$\nwhere $\\pi(\\cdot)$ is the target density, $q(\\cdot \\to \\cdot)$ is the proposal density, and $|J|$ is the Jacobian determinant for a transformation between parameter spaces. The problem states that the move does not change the dimensionality of the parameterization, which implies the transformation is within the same space and $|J| = 1$. Thus, the formula simplifies to:\n$$\n\\alpha(x \\to y) = \\min \\left( 1, \\frac{\\pi(y) q(y \\to x)}{\\pi(x) q(x \\to y)} \\right)\n$$\nThe posterior densities $\\pi(x)$ and $\\pi(y)$ need not be normalized, as the normalization constant would cancel out in the ratio.\n\nLet us define the acceptance ratio, $R$, as the second term inside the minimum function:\n$$\nR = \\frac{\\pi(y) q(y \\to x)}{\\pi(x) q(x \\to y)}\n$$\nWe substitute the given values into this expression:\n- $\\pi(x) = \\exp(-100)$\n- $\\pi(y) = \\exp(-98)$\n- $q(x \\to y) = 0.3$\n- $q(y \\to x) = 0.6$\n\nThe calculation proceeds as follows:\n$$\nR = \\frac{\\exp(-98) \\cdot 0.6}{\\exp(-100) \\cdot 0.3}\n$$\nWe can separate the ratio of posterior densities and the ratio of proposal probabilities:\n$$\nR = \\left( \\frac{\\exp(-98)}{\\exp(-100)} \\right) \\cdot \\left( \\frac{0.6}{0.3} \\right)\n$$\nThe ratio of the exponential terms is calculated using the property of exponents $\\frac{\\exp(a)}{\\exp(b)} = \\exp(a-b)$:\n$$\n\\frac{\\exp(-98)}{\\exp(-100)} = \\exp(-98 - (-100)) = \\exp(100 - 98) = \\exp(2)\n$$\nThe ratio of the proposal probabilities is:\n$$\n\\frac{0.6}{0.3} = 2\n$$\nCombining these results, the acceptance ratio $R$ is:\n$$\nR = \\exp(2) \\cdot 2 = 2e^2\n$$\nThe acceptance probability is therefore:\n$$\n\\alpha(x \\to y) = \\min(1, 2e^2)\n$$\nTo evaluate this expression, we must determine if $2e^2$ is greater than or less than $1$. The base of the natural logarithm, $e$, is a transcendental number with an approximate value of $2.71828$. Since $e > 1$, its square $e^2$ is also greater than $1$. Specifically, $e^2 \\approx (2.718)^2 \\approx 7.389$.\nThus, the value of $R$ is approximately $2 \\times 7.389 = 14.778$.\nSince $2e^2 > 1$, the minimum of $1$ and $2e^2$ is $1$.\n$$\n\\alpha(x \\to y) = 1\n$$\nThis means the proposed move from state $x$ to state $y$ will always be accepted. This is expected, as the proposed state $y$ has a higher posterior probability ($\\pi(y) > \\pi(x)$), and the Hastings correction term $\\frac{q(y \\to x)}{q(x \\to y)} = 2$ also favors the move.",
            "answer": "$$\\boxed{1}$$"
        },
        {
            "introduction": "A Bayesian MCMC analysis yields not one single tree but a large sample of trees from the posterior distribution, each representing a plausible evolutionary history. To interpret this complex output, we must summarize it, and the majority-rule consensus tree is a standard method for doing so. This hands-on coding challenge requires you to implement the algorithm for constructing such a tree from a posterior sample, tackling the essential details of representing tree topologies, counting bipartition frequencies, and applying deterministic tie-breaking rules .",
            "id": "2694213",
            "problem": "You are given a posterior sample of phylogenetic trees obtained from Markov Chain Monte Carlo (MCMC) under a Bayesian model of sequence evolution. Work in the unrooted setting on a fixed set of taxa in a fixed order. Each tree is represented by the set of its nontrivial edge-induced bipartitions (also called splits) encoded as integer bitmasks over that fixed taxon order. Your task is to implement a program that computes the majority-rule consensus at threshold $0.5$ on these splits, together with a deterministic, fully specified tie-handling rule for splits that occur with posterior frequency exactly $0.5$.\n\nBase definitions and assumptions you must use:\n- A bipartition of a taxon set $X$ with $\\lvert X \\rvert = n$ is a split of $X$ into two nonempty parts $A \\mid A^{c}$, where $A \\subset X$ and $A^{c} = X \\setminus A$. Only nontrivial splits are considered, meaning $1 \\lt \\lvert A \\rvert \\lt n-1$.\n- Fix an order of taxa and encode any subset $A$ as a bitmask $m \\in \\{0, 1, \\dots, 2^{n}-1\\}$ with bit $i$ set if and only if the taxon at position $i$ is in $A$.\n- Use a canonical representative for each split by always choosing the side $A$ with $\\lvert A \\rvert \\le n/2$. If $\\lvert A \\rvert = n/2$ (only possible when $n$ is even), choose the side whose bitmask is the smaller integer in $\\{m, \\tilde{m}\\}$, where $\\tilde{m}$ is the bitwise complement of $m$ restricted to the lowest $n$ bits.\n- Two splits $A \\mid A^{c}$ and $B \\mid B^{c}$ on the same $X$ are compatible if and only if one of $A \\cap B$, $A \\cap B^{c}$, or $A^{c} \\cap B$ is empty.\n- Let $N$ be the number of posterior trees. The posterior frequency of a split is $f = c/N$, where $c$ is the number of trees that contain this split.\n\nMajority-rule consensus tree at threshold $0.5$:\n- Include every split with posterior frequency $f \\gt 0.5$. It is a well-tested fact that such splits are mutually compatible.\n- Among splits with posterior frequency $f = 0.5$, include only those that are compatible with all splits already included, using a deterministic tie-handling rule defined below.\n- The tie-handling rule for $f = 0.5$ splits is: process them in ascending order by $\\lvert A \\rvert$ (clade size); break ties by ascending integer value of the canonical bitmask; add a split if and only if it is compatible with all splits already in the consensus set, otherwise skip it.\n\nAdditional implementation requirements:\n- For any bitmask $m$, let the universe mask be $U = 2^{n}-1$. For the canonicalization step, if $\\mathrm{popcount}(m) \\gt n/2$, replace $m$ by $\\tilde{m} = (\\neg m) \\,\\&\\, U$; if $\\mathrm{popcount}(m) = n/2$ and $\\tilde{m} \\lt m$, replace $m$ by $\\tilde{m}$.\n- For compatibility of two canonical bitmasks $a$ and $b$, use the bitwise condition with the universe mask $U$: they are compatible if and only if at least one of $(a \\,\\&\\, b)$, $\\bigl(a \\,\\&\\, (\\neg b \\,\\&\\, U)\\bigr)$, or $\\bigl((\\neg a \\,\\&\\, U) \\,\\&\\, b\\bigr)$ equals $0$.\n- The majority-rule inclusion order must be deterministic. First, include all splits with $f \\gt 0.5$ sorted by descending count $c$; break ties by ascending clade size $\\lvert A \\rvert$; and then by ascending bitmask. Second, process splits with $f = 0.5$ using the tie-handling rule above and record a tie trace.\n\nWhat to compute and return for each test case:\n- Let $C$ be the final set of canonical bitmasks included in the consensus. Output the list of integers in the exact order they were added to $C$ by the algorithm.\n- Also output a tie trace for splits with $f=0.5$. The tie trace is a flat list of integers of even length in the form $[m_{1},b_{1},m_{2},b_{2},\\dots]$, where each $m_{i}$ is a canonical bitmask of a split considered at tie frequency and $b_{i}$ is $1$ if it was included and $0$ if it was excluded, recorded in the exact processing order prescribed by the tie-handling rule.\n- For splits with frequency $f \\ne 0.5$, do not record them in the tie trace.\n\nYour program should aggregate the results for all test cases into a single line of output containing a list of results, one per test case, where each result is a two-element list of lists: the first is the consensus bitmask list $C$ and the second is the tie trace. The exact output format is a single line:\n- A string representation of a Python list whose elements are of the form $[C, T]$, where $C$ is a list of integers and $T$ is a flat list of integers as defined above.\n- No extra whitespace or text is permitted.\n\nTest suite:\n- Test case 1 (happy path, no ties): $n = 5$, posterior sample of $N = 10$ trees. Trees are represented as lists of canonical bitmasks of their nontrivial splits.\n  - Trees: $[[3,12],[3,12],[3,12],[3,20],[3,24],[3,12],[3,20],[5,10],[5,18],[9,6]]$.\n- Test case 2 (exact $0.5$ tie between incompatible splits): $n = 4$, $N = 10$.\n  - Trees: $[[3],[3],[3],[3],[3],[5],[5],[5],[5],[5]]$.\n- Test case 3 (boundary case, no nontrivial splits): $n = 3$, $N = 6$.\n  - Trees: $[[],[],[],[],[],[]]$.\n- Test case 4 (mix of $f \\gt 0.5$ and $f = 0.5$ incompatible ties): $n = 5$, $N = 10$.\n  - Trees: $[[3,12],[3,12],[3,12],[3,12],[3,20],[3,20],[3,20],[3,20],[12,17],[20,9]]$.\n\nScientifically realistic assumptions you must rely on:\n- The posterior set arises from a valid Bayesian phylogenetic inference; thus, splits within any single tree are pairwise compatible and are nontrivial.\n- Posterior frequencies are computed as $f = c/N$ by counting the occurrence of each canonical split across the sample.\n- Splits with $f \\gt 0.5$ are mutually compatible.\n\nYour program must produce a single line with a Python-style list whose entries correspond to the test cases in the order presented. Each entry must be the two-element list $[C, T]$ as described above.",
            "solution": "The problem statement is subjected to validation.\n\n**Step 1: Extract Givens**\n- **Taxon Set**: A set of taxa $X$ of size $\\lvert X \\rvert = n$.\n- **Nontrivial Split**: A bipartition of $X$ into $A \\mid A^c$ where $A \\subset X$, $A^c = X \\setminus A$, and $1 \\lt \\lvert A \\rvert \\lt n-1$.\n- **Bitmask Encoding**: For a fixed taxon order, a subset $A$ is encoded as an integer bitmask $m$, where bit $i$ is set if taxon $i \\in A$.\n- **Canonical Representative**: For a split represented by bitmask $m$:\n    - The universe mask is $U = 2^n - 1$.\n    - The complement bitmask is $\\tilde{m} = (\\neg m) \\,\\&\\, U$.\n    - The population count of a bitmask $m$ is denoted $\\mathrm{popcount}(m) = \\lvert A \\rvert$.\n    - If $\\mathrm{popcount}(m) > n/2$, the canonical form is $\\tilde{m}$.\n    - If $\\mathrm{popcount}(m) = n/2$, the canonical form is $\\min(m, \\tilde{m})$.\n    - Otherwise, the canonical form is $m$. A split with $p=n/2$ is not possible for odd $n$.\n- **Split Compatibility**: Two splits with canonical bitmasks $a$ and $b$ are compatible if and only if one of the bitwise intersections $(a \\,\\&\\, b)$, $(a \\,\\&\\, (\\neg b \\,\\&\\, U))$, or $((\\neg a \\,\\&\\, U) \\,\\&\\, b)$ is equal to $0$.\n- **Posterior Sample**: A sample of $N$ trees from an MCMC simulation. Each tree is a set of canonical bitmasks of its nontrivial splits.\n- **Posterior Frequency**: For a split with canonical bitmask $m$, its count across the sample is $c$. The frequency is $f = c/N$.\n- **Majority-Rule Consensus Algorithm**:\n    1.  **Phase 1 ($f > 0.5$)**: Include all splits with frequency $f > 0.5$. These splits are presorted by: (1) descending count $c$, (2) ascending clade size $\\lvert A \\rvert = \\mathrm{popcount}(m)$, and (3) ascending bitmask $m$.\n    2.  **Phase 2 ($f = 0.5$)**: Process splits with frequency $f = 0.5$. These are considered for inclusion in a specific order: (1) ascending clade size $\\lvert A \\rvert$, then (2) ascending bitmask $m$. A split is added to the consensus set if and only if it is compatible with all splits already included.\n- **Output**: For each test case, produce two lists:\n    1.  $C$: A list of canonical bitmasks in the consensus set, ordered exactly as they were added.\n    2.  $T$: A flat list of integers $[m_1, b_1, m_2, b_2, \\ldots]$, where $m_i$ are the canonical bitmasks of splits with $f = 0.5$ in their processing order, and $b_i$ is $1$ if included or $0$ if excluded.\n- **Test Cases**: Four test cases are provided with specified $n$, $N$, and posterior tree samples.\n- **Assumptions**: The origin of the posterior sample is a valid Bayesian phylogenetic inference; splits within a single tree are compatible and nontrivial; splits with $f > 0.5$ are mutually compatible.\n\n**Step 2: Validate Using Extracted Givens**\n- **Scientifically Grounded**: The problem is a standard task in computational biology and phylogenetics. Majority-rule consensus trees, bipartition (split) representation, bitmask encoding, and compatibility tests are all established concepts. The assumption that splits with frequency greater than $0.5$ are mutually compatible is a known property, ensuring the first phase of the algorithm is well-defined.\n- **Well-Posed**: The problem is algorithmically specified with complete determinism. The rules for canonicalization, sorting, tie-breaking, and inclusion are unambiguous. For any valid input, a unique output is guaranteed.\n- **Objective**: The problem is formulated in precise mathematical and algorithmic terms, devoid of any subjective or ambiguous language.\n\n**Step 3: Verdict and Action**\nThe problem statement is scientifically sound, well-posed, and objective. It contains no contradictions, missing information, or other fatal flaws. The problem is **valid**. A solution will be constructed.\n\n**Principle-Based Design**\n\nThe task is to implement a deterministic algorithm for constructing a majority-rule consensus tree from a posterior sample of phylogenetic trees. The solution is structured by breaking down the process into logical, sequential steps, beginning with data preprocessing and concluding with the application of the specified inclusion rules.\n\n**1. Data Preparation: Canonicalization and Frequency Calculation**\n\nLet the input be a posterior sample of $N$ trees, where each tree is a list of its nontrivial splits, each represented by a bitmask. The taxon set size is $n$. The universe mask is defined as $U = 2^n - 1$.\n\nFirst, all splits from all trees must be collated and converted to their canonical form. For each given bitmask $m$:\n- The clade size is computed as $p = \\mathrm{popcount}(m)$.\n- If $p > n/2$, the canonical representative is $m_{can} = (\\neg m) \\,\\&\\, U$.\n- If $p = n/2$ (possible only if $n$ is even), the canonical representative is $m_{can} = \\min(m, (\\neg m) \\,\\&\\, U)$.\n- Otherwise, if $p < n/2$, the canonical representative is $m_{can} = m$. A split with $p=n/2$ is not possible for odd $n$.\n\nAfter canonicalization, the frequencies of all unique canonical splits are computed. A hash map (dictionary) is used to store the counts $c_m$ for each canonical split $m$. The posterior frequency is $f_m = c_m / N$.\n\n**2. Grouping and Sorting of Splits**\n\nThe unique canonical splits are partitioned into two groups based on their posterior frequency $f$:\n- Group 1: Splits with $f > 0.5$.\n- Group 2: Splits with $f = 0.5$.\n\nThese groups are then sorted according to the specific rules of the algorithm to ensure a deterministic inclusion order.\n- Group 1 splits are sorted primarily by descending count $c$, secondarily by ascending clade size $p = \\mathrm{popcount}(m)$, and tertiarily by ascending bitmask value $m$.\n- Group 2 splits are sorted primarily by ascending clade size $p$, and secondarily by ascending bitmask value $m$.\n\n**3. Consensus Set Construction**\n\nThe final consensus set of splits, denoted $C$, is built in two phases. A trace of the tie-handling decisions, $T$, is also generated.\n\n**Phase 1: Inclusion of Splits with $f > 0.5$**\nThe sorted splits from Group 1 are added to the consensus set $C$ in their sorted order. The problem statement provides the crucial guarantee that all splits with $f > 0.5$ are mutually compatible. Therefore, no compatibility checks are needed in this phase. The list $C$ is initialized with these splits, preserving their sorted order.\n\n**Phase 2: Tie-Handling for Splits with $f = 0.5$**\nThe sorted splits from Group 2 are processed sequentially. For each split $m_{tie}$ from this group, its compatibility with the current consensus set $C$ must be evaluated. A split $m_{tie}$ is compatible with the set $C$ if and only if it is compatible with every split $m_{c} \\in C$.\n\nThe compatibility check between two canonical bitmasks $a$ and $b$ is performed using the provided bitwise formula: they are compatible if at least one of the three conditions holds:\n$$(a \\,\\&\\, b) = 0$$\n$$(a \\,\\&\\, ((\\neg b) \\,\\&\\, U)) = 0$$\n$$( ((\\neg a) \\,\\&\\, U) \\,\\&\\, b) = 0$$\n\nFor each $m_{tie}$ from Group 2:\n- If $m_{tie}$ is compatible with all splits currently in $C$, it is appended to $C$. Its entry in the tie trace $T$ is $[m_{tie}, 1]$.\n- If $m_{tie}$ is incompatible with at least one split in $C$, it is discarded. Its entry in the tie trace $T$ is $[m_{tie}, 0]$.\n\nThis procedure is repeated for all splits in Group 2, in their prescribed order. The final list $C$ contains the bitmasks of the consensus tree splits in the exact order they were added, and the list $T$ documents the decisions made during the tie-handling phase. The result for a single test case is the pair $[C, T]$. The final output is an aggregation of these results for all provided test cases.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to solve the problem for the given test suite.\n    \"\"\"\n    test_cases = [\n        # Test case 1: n=5, N=10\n        (5, 10, [[3,12],[3,12],[3,12],[3,20],[3,24],[3,12],[3,20],[5,10],[5,18],[9,6]]),\n        # Test case 2: n=4, N=10\n        (4, 10, [[3],[3],[3],[3],[3],[5],[5],[5],[5],[5]]),\n        # Test case 3: n=3, N=6\n        (3, 6, [[],[],[],[],[],[]]),\n        # Test case 4: n=5, N=10\n        (5, 10, [[3,12],[3,12],[3,12],[3,12],[3,20],[3,20],[3,20],[3,20],[12,17],[20,9]]),\n    ]\n\n    results = []\n    for n, N, tree_sample in test_cases:\n        result = compute_consensus(n, N, tree_sample)\n        results.append(result)\n\n    # Format the final output as a string representation of a Python list.\n    print(f\"[{','.join(map(str, results))}]\".replace(\" \", \"\"))\n\ndef compute_consensus(n, N, tree_sample):\n    \"\"\"\n    Computes the majority-rule consensus and tie trace for a single test case.\n    \n    Args:\n        n (int): The number of taxa.\n        N (int): The number of trees in the posterior sample.\n        tree_sample (list[list[int]]): The posterior sample of trees.\n\n    Returns:\n        list[list[int], list[int]]: A list containing the consensus splits C\n                                     and the tie trace T.\n    \"\"\"\n    universe_mask = (1  n) - 1\n\n    def popcount(m):\n        # In Python 3.10+, int.bit_count() is available and efficient.\n        return m.bit_count()\n\n    def canonicalize(m):\n        \"\"\"Computes the canonical bitmask for a given split.\"\"\"\n        pc = popcount(m)\n        if pc > n / 2:\n            return (~m)  universe_mask\n        if n % 2 == 0 and pc == n / 2:\n            complement = (~m)  universe_mask\n            return min(m, complement)\n        return m\n\n    def are_compatible(m1, m2):\n        \"\"\"Checks if two canonical splits are compatible.\"\"\"\n        # We use the three-part check from the problem description.\n        comp_m2 = (~m2)  universe_mask\n        comp_m1 = (~m1)  universe_mask\n\n        cond1 = (m1  m2) == 0\n        cond2 = (m1  comp_m2) == 0\n        cond3 = (comp_m1  m2) == 0\n        \n        return cond1 or cond2 or cond3\n\n    # Step 1: Data Aggregation and Canonicalization\n    all_splits_canonical = []\n    for tree in tree_sample:\n        for split_mask in tree:\n            all_splits_canonical.append(canonicalize(split_mask))\n\n    # Step 2: Split Frequency Calculation\n    split_counts = {}\n    for m in all_splits_canonical:\n        split_counts[m] = split_counts.get(m, 0) + 1\n\n    # Step 3: Group Splits by Frequency\n    gt_half_splits = []\n    eq_half_splits = []\n    if N > 0:\n        for m, c in split_counts.items():\n            if c / N > 0.5:\n                gt_half_splits.append((m, c))\n            elif c / N == 0.5:\n                eq_half_splits.append((m, c))\n\n    # Step 4: Process Splits with f > 0.5\n    # Sort by descending count, then ascending clade size, then ascending bitmask\n    gt_half_splits.sort(key=lambda item: (-item[1], popcount(item[0]), item[0]))\n    \n    C = [m for m, c in gt_half_splits]\n\n    # Step 5: Process Splits with f = 0.5 (Tie-Handling)\n    # Sort by ascending clade size, then ascending bitmask\n    eq_half_splits.sort(key=lambda item: (popcount(item[0]), item[0]))\n\n    T = []\n    for m_tie, _ in eq_half_splits:\n        is_compatible_with_all = all(are_compatible(m_tie, m_c) for m_c in C)\n        \n        if is_compatible_with_all:\n            C.append(m_tie)\n            T.extend([m_tie, 1])\n        else:\n            T.extend([m_tie, 0])\n\n    return [C, T]\n\nsolve()\n```"
        }
    ]
}