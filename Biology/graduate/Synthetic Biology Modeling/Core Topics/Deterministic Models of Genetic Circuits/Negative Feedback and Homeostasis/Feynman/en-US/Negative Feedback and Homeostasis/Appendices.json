{
    "hands_on_practices": [
        {
            "introduction": "Before we can analyze the dynamics of returning to a homeostatic setpoint, we must first confirm its existence and uniqueness. This foundational exercise explores a canonical model of negative autoregulation using a cooperative Hill function. By analyzing the intersections of the production and loss rate curves—a technique known as nullcline analysis—you will rigorously prove that this architecture guarantees a single, globally stable equilibrium, a property known as monostability . This practice provides essential skills in the qualitative analysis of nonlinear systems, revealing why simple negative feedback is a robust and widespread motif for achieving homeostasis.",
            "id": "3923020",
            "problem": "Consider a single-gene autoregulatory module in a synthetic biological circuit in which the protein concentration $x(t)$ negatively feeds back on its own transcription through a cooperative Hill-type repression. Assume well-mixed conditions and deterministic dynamics. The mass balance for $x(t)$ is modeled by the ordinary differential equation\n$$\n\\frac{dx}{dt} \\;=\\; \\frac{\\alpha}{1 + \\left(\\frac{x}{K}\\right)^{n}} \\;-\\; \\delta x,\n$$\nwhere $\\alpha > 0$ is the maximal synthesis rate, $K > 0$ is the repression threshold (often called the dissociation constant), $n \\geq 1$ is the Hill coefficient representing cooperativity in repression, and $\\delta > 0$ is the first-order loss rate due to dilution and degradation. The Hill repression function is widely used to model cooperative binding and is a decreasing function of $x$ for $n \\geq 1$.\n\nUsing the nullcline condition $\\frac{dx}{dt} = 0$ and a slope-based argument grounded in mass balance and monotonicity properties of the Hill function and first-order loss, determine whether this system can exhibit multistability (more than one stable steady state) or only monostable homeostasis (exactly one stable steady state). In particular, analyze the number of intersections of the production curve\n$$\np(x) \\;=\\; \\frac{\\alpha}{1 + \\left(\\frac{x}{K}\\right)^{n}}\n$$\nwith the loss curve\n$$\n\\ell(x) \\;=\\; \\delta x,\n$$\nby examining the sign of the derivative of the difference $f(x) = p(x) - \\ell(x)$ over $x \\geq 0$. Your analysis must begin from the stated model and fundamental properties (mass balance, monotonicity of Hill repression, and linear loss) without invoking any ad hoc shortcut formulas.\n\nReport your final answer as the maximum possible number of distinct steady states $N_{\\mathrm{ss}}$ that the model admits over all positive parameter values $\\alpha$, $K$, $n \\geq 1$, and $\\delta$ (i.e., the supremum over parameter space of the number of solutions to $p(x) = \\ell(x)$ with $x \\geq 0$). No rounding is required. Express your final answer as a single number without units.",
            "solution": "The problem as stated is scientifically grounded, well-posed, and objective. It represents a canonical model in synthetic biology for analyzing homeostasis under negative autoregulation. All parameters and conditions are clearly defined, allowing for a rigorous mathematical analysis. The problem is therefore valid.\n\nThe steady states of the system, denoted by $x^*$, are the non-negative concentrations $x$ for which the rate of change is zero. This is the nullcline condition, $\\frac{dx}{dt} = 0$. From the given ordinary differential equation, this condition is:\n$$\n\\frac{\\alpha}{1 + \\left(\\frac{x^*}{K}\\right)^{n}} - \\delta x^* = 0\n$$\nThis equation can be rewritten as an equality between the production rate and the loss rate:\n$$\np(x^*) = \\ell(x^*)\n$$\nwhere the production curve is $p(x) = \\frac{\\alpha}{1 + (x/K)^n}$ and the loss curve is $\\ell(x) = \\delta x$. The number of distinct steady states, $N_{\\mathrm{ss}}$, is the number of non-negative solutions to this equation.\n\nTo determine the number of solutions, we follow the prescribed method of analyzing the function $f(x) = p(x) - \\ell(x)$ for $x \\geq 0$. The steady states are the roots of the equation $f(x) = 0$.\n$$\nf(x) = \\frac{\\alpha}{1 + \\left(\\frac{x}{K}\\right)^{n}} - \\delta x\n$$\nWe analyze the properties of $f(x)$ over its physical domain, $x \\geq 0$.\n\nFirst, we evaluate $f(x)$ at the boundary $x=0$:\n$$\nf(0) = \\frac{\\alpha}{1 + \\left(\\frac{0}{K}\\right)^{n}} - \\delta(0) = \\frac{\\alpha}{1} - 0 = \\alpha\n$$\nGiven that the maximal synthesis rate $\\alpha > 0$, we have $f(0) > 0$.\n\nNext, we examine the asymptotic behavior of $f(x)$ as $x \\to \\infty$:\n$$\n\\lim_{x\\to\\infty} f(x) = \\lim_{x\\to\\infty} \\left( \\frac{\\alpha}{1 + \\left(\\frac{x}{K}\\right)^{n}} - \\delta x \\right)\n$$\nAs $x \\to \\infty$, the term $(x/K)^n \\to \\infty$ since $K>0$ and $n \\geq 1$. Consequently, the denominator of the first term $1 + (x/K)^n \\to \\infty$, causing the fraction to approach $0$. The second term, $-\\delta x$, approaches $-\\infty$ since the loss rate $\\delta > 0$.\n$$\n\\lim_{x\\to\\infty} f(x) = 0 - \\infty = -\\infty\n$$\nSince $f(x)$ is a continuous function for $x \\geq 0$, and it transitions from a positive value $f(0) = \\alpha$ to negative infinity, the Intermediate Value Theorem guarantees the existence of at least one root $x^* > 0$ such that $f(x^*) = 0$.\n\nTo determine the uniqueness of this root, we analyze the monotonicity of $f(x)$ by computing its derivative, $f'(x)$. A strictly monotonic function can cross the axis at most once.\n$$\nf'(x) = \\frac{d}{dx}f(x) = \\frac{d}{dx} \\left( p(x) - \\ell(x) \\right) = p'(x) - \\ell'(x)\n$$\nThe derivative of the loss curve $\\ell(x) = \\delta x$ is a constant:\n$$\n\\ell'(x) = \\delta\n$$\nThe derivative of the production curve $p(x) = \\alpha \\left(1 + K^{-n}x^n\\right)^{-1}$ is found using the chain rule:\n$$\np'(x) = \\alpha (-1) \\left(1 + K^{-n}x^n\\right)^{-2} \\cdot \\frac{d}{dx}\\left(1 + K^{-n}x^n\\right)\n$$\n$$\np'(x) = -\\alpha \\left(1 + \\left(\\frac{x}{K}\\right)^n\\right)^{-2} \\cdot \\left(n K^{-n} x^{n-1}\\right)\n$$\n$$\np'(x) = - \\frac{\\alpha n K^{-n} x^{n-1}}{\\left(1 + (x/K)^n\\right)^2} = - \\frac{\\alpha n x^{n-1}}{K^n \\left(1 + (x/K)^n\\right)^2}\n$$\nThe parameters are given as $\\alpha > 0$, $K > 0$, and $n \\geq 1$. For any $x > 0$, all terms in the expression for $p'(x)$ are positive, hence $p'(x)$ is strictly negative. For $x=0$, if $n>1$, $p'(0)=0$; if $n=1$, $p'(0) = -\\alpha/K < 0$. In all cases for $x \\geq 0$, the derivative of the production function is non-positive, $p'(x) \\leq 0$. This is a direct consequence of the negative feedback (repression), where an increase in $x$ leads to a decrease in its own production.\n\nNow we assemble the derivative of $f(x)$:\n$$\nf'(x) = p'(x) - \\delta\n$$\nWe have established that $p'(x) \\leq 0$ for all $x \\geq 0$. We are also given that $\\delta > 0$. Therefore, $f'(x)$ is the sum of a non-positive term and a strictly negative term:\n$$\nf'(x) = (\\text{non-positive value}) - (\\text{positive value}) < 0\n$$\nThus, $f'(x)$ is strictly negative for all $x \\geq 0$. This proves that $f(x)$ is a strictly monotonically decreasing function over its entire domain.\n\nIn summary:\n1. $f(x)$ is continuous for $x \\geq 0$.\n2. $f(0) > 0$.\n3. $\\lim_{x\\to\\infty} f(x) = -\\infty$.\n4. $f(x)$ is strictly monotonically decreasing for all $x \\geq 0$.\n\nA continuous, strictly decreasing function that starts from a positive value and tends to negative infinity must cross the horizontal axis exactly once. This means there is a unique solution $x^* > 0$ to the equation $f(x) = 0$.\n\nThis conclusion holds for all valid parameter values ($\\alpha>0, K>0, n\\geq1, \\delta>0$). Therefore, the system can only exhibit monostable homeostasis; it always possesses exactly one steady state. The maximum possible number of distinct steady states, $N_{\\mathrm{ss}}$, is $1$. The inability to exhibit multistability is a hallmark of this canonical negative feedback architecture, as the monotonically decreasing production function can only intersect the monotonically increasing linear loss function at a single point.",
            "answer": "$$\\boxed{1}$$"
        },
        {
            "introduction": "While negative feedback is a stabilizing force, the inherent delays in biological processes like transcription and translation introduce a critical challenge: the potential for instability and oscillations. This practice delves into this trade-off by modeling a simple feedback loop with a time delay . You will apply the Nyquist stability criterion, a cornerstone of frequency-domain analysis, to derive the precise boundary between stable homeostatic control and unstable oscillations, linking the maximum allowable feedback gain directly to the system's delay.",
            "id": "3923012",
            "problem": "A synthetic gene circuit implements homeostasis via integral negative feedback, such as in antithetic integral feedback (AIF), which robustly drives an output concentration to a setpoint by integrating the error over time. Consider the linear time-invariant (LTI) approximation of the circuit near the homeostatic setpoint, where the controlled molecular concentration is $x(t)$ and the actuator command is $u(t)$. To capture the core homeostatic integral action with transcriptional-translational delay, the closed-loop dynamics are modeled as a retarded delay differential equation (DDE):\n$$\n\\frac{d x(t)}{d t} = u(t), \\quad u(t) = -k\\,x(t-\\tau),\n$$\nwhere $k>0$ is the loop gain and $\\tau>0$ is the total feedback delay arising from sensing, transcription, translation, and processing. Assume unity negative feedback around the loop, no open-loop unstable poles, and that the linearization is valid in the neighborhood of the operating point.\n\nUsing the Nyquist stability criterion starting from first principles of frequency-domain analysis of LTI systems and the definition of the Laplace transform, determine the maximum permissible loop gain $k_{\\max}$ as an explicit function of the delay $\\tau$ such that the closed-loop system remains stable. Your final answer must be a single symbolic expression in terms of $\\tau$. No numerical rounding is required. Express the final answer without units.",
            "solution": "The objective is to determine the maximum permissible loop gain $k_{\\max}$ for the given closed-loop system to remain stable. The system is described by the linear time-invariant (LTI) retarded delay differential equation (DDE):\n$$\n\\frac{d x(t)}{d t} = u(t), \\quad u(t) = -k\\,x(t-\\tau)\n$$\nwhere $k>0$ and $\\tau>0$. We will use the Nyquist stability criterion, grounded in the principles of the Laplace transform and frequency-domain analysis.\n\nFirst, we derive the characteristic equation of the system. We substitute the expression for the actuator command $u(t)$ into the dynamic equation for the concentration $x(t)$:\n$$\n\\frac{d x(t)}{d t} = -k\\,x(t-\\tau)\n$$\nTo analyze the stability of this LTI system, we apply the Laplace transform. Let $X(s) = \\mathcal{L}\\{x(t)\\}$. Using the differentiation property $\\mathcal{L}\\{\\frac{dx}{dt}\\} = sX(s) - x(0)$ and the time-delay property $\\mathcal{L}\\{x(t-\\tau)\\} = e^{-s\\tau}X(s)$, and assuming zero initial conditions for transfer function analysis (i.e., $x(0)=0$), the transformed equation is:\n$$\nsX(s) = -k e^{-s\\tau} X(s)\n$$\nRearranging the terms to find the characteristic equation, we get:\n$$\n(s + k e^{-s\\tau}) X(s) = 0\n$$\nFor a non-trivial solution ($X(s) \\neq 0$), the term in the parenthesis must be zero. This gives the characteristic equation of the closed-loop system:\n$$\ns + k e^{-s\\tau} = 0\n$$\nThe roots of this equation are the poles of the closed-loop system. The system is stable if and only if all roots have negative real parts.\n\nTo apply the Nyquist stability criterion, we first identify the open-loop transfer function, $L(s)$. The standard form of a characteristic equation for a unity negative feedback system is $1 + L(s) = 0$. We can write our characteristic equation in this form:\n$$\n1 + \\frac{k e^{-s\\tau}}{s} = 0\n$$\nThus, the open-loop transfer function is:\n$$\nL(s) = \\frac{k e^{-s\\tau}}{s}\n$$\nThe Nyquist stability criterion relates the stability of the closed-loop system to the frequency response of the open-loop system. The criterion is given by the formula $Z = P + N$, where:\n- $Z$ is the number of unstable (right-half plane) poles of the closed-loop system. For stability, we require $Z=0$.\n- $P$ is the number of unstable (right-half plane) poles of the open-loop system $L(s)$.\n- $N$ is the number of clockwise encirclements of the critical point $-1+j0$ by the Nyquist contour of $L(s)$.\n\nThe open-loop transfer function $L(s)$ has a single pole at $s=0$. This pole lies on the imaginary axis, not in the right-half plane. Therefore, the number of open-loop unstable poles is $P=0$.\nFor stability ($Z=0$), the Nyquist criterion simplifies to $N=0$. This means the Nyquist plot of $L(s)$ must not encircle the point $-1+j0$.\n\nTo construct the Nyquist plot, we evaluate $L(s)$ along the imaginary axis by setting $s=j\\omega$, where $\\omega$ is the angular frequency.\n$$\nL(j\\omega) = \\frac{k e^{-j\\omega\\tau}}{j\\omega}\n$$\nWe analyze the magnitude and phase of $L(j\\omega)$:\nThe magnitude is:\n$$\n|L(j\\omega)| = \\left| \\frac{k e^{-j\\omega\\tau}}{j\\omega} \\right| = \\frac{|k| |e^{-j\\omega\\tau}|}{|j\\omega|} = \\frac{k}{\\omega} \\quad (\\text{since } k>0 \\text{ and for } \\omega>0)\n$$\nThe phase angle is:\n$$\n\\angle L(j\\omega) = \\angle(k) + \\angle(e^{-j\\omega\\tau}) - \\angle(j\\omega) = 0 - \\omega\\tau - \\frac{\\pi}{2} \\quad (\\text{radians})\n$$\nThe system is on the verge of instability, or marginally stable, when the Nyquist plot passes through the critical point $-1+j0$. At this point, the magnitude is $1$ and the phase is $-\\pi$ (or any odd multiple of $-\\pi$).\nWe first find the phase crossover frequency, $\\omega_{pc}$, which is the frequency at which the phase of $L(j\\omega)$ is equal to $-\\pi$.\n$$\n\\angle L(j\\omega_{pc}) = -\\omega_{pc}\\tau - \\frac{\\pi}{2} = -\\pi\n$$\nSolving for $\\omega_{pc}$:\n$$\n-\\omega_{pc}\\tau = -\\pi + \\frac{\\pi}{2} = -\\frac{\\pi}{2}\n$$\n$$\n\\omega_{pc} = \\frac{\\pi}{2\\tau}\n$$\nThis is the lowest positive frequency at which the plot crosses the negative real axis.\n\nNext, we evaluate the magnitude of $L(j\\omega)$ at this frequency:\n$$\n|L(j\\omega_{pc})| = \\frac{k}{\\omega_{pc}} = \\frac{k}{\\frac{\\pi}{2\\tau}} = \\frac{2k\\tau}{\\pi}\n$$\nFor the system to be marginally stable, this magnitude must be exactly equal to $1$. This condition defines the maximum permissible loop gain, $k_{\\max}$.\n$$\n|L(j\\omega_{pc})| = 1\n$$\n$$\n\\frac{2k_{\\max}\\tau}{\\pi} = 1\n$$\nSolving for $k_{\\max}$:\n$$\nk_{\\max} = \\frac{\\pi}{2\\tau}\n$$\nFor any gain $k < k_{\\max}$, the magnitude $|L(j\\omega_{pc})|$ will be less than $1$, meaning the Nyquist plot will cross the negative real axis between $0$ and $-1$. In this case, the number of encirclements $N$ of the point $-1+j0$ is zero, and the closed-loop system is stable. If $k > k_{\\max}$, the magnitude will be greater than $1$, the point $-1+j0$ will be encircled, and the system will be unstable.\n\nTherefore, the maximum permissible loop gain for stability is $k_{\\max} = \\frac{\\pi}{2\\tau}$.",
            "answer": "$$\\boxed{\\frac{\\pi}{2\\tau}}$$"
        },
        {
            "introduction": "Moving beyond analysis to design, how can we engineer a feedback system that is not only stable but also performs optimally? This advanced practice introduces the Linear Quadratic Regulator (LQR), a powerful framework for synthesizing controllers that balance performance against cost . Starting from the principles of dynamic programming, you will derive the optimal feedback law that minimizes both deviations from the homeostatic setpoint and the metabolic 'effort' of actuation, and then implement this solution numerically. This exercise bridges the gap between modern control theory and the practical engineering of high-performance synthetic circuits.",
            "id": "3923025",
            "problem": "You are modeling homeostasis in a synthetic gene circuit near a fixed homeostatic operating point. Let the deviation of molecular species concentrations from the steady state be represented by the state vector $x \\in \\mathbb{R}^n$, and let $u \\in \\mathbb{R}^m$ be a control actuation (for example, inducible transcriptional drive) that is applied as a negative feedback to maintain homeostasis. The linearized dynamics around the operating point are modeled as a continuous-time linear time-invariant system\n$$\n\\dot{x}(t) = A x(t) + B u(t),\n$$\nwhere $A \\in \\mathbb{R}^{n \\times n}$ and $B \\in \\mathbb{R}^{n \\times m}$ are known constant matrices obtained from linearization of a biophysical model. The design goal is to minimize both deviation from homeostasis and control effort over an infinite time horizon.\n\nFormulate the Linear Quadratic Regulator (LQR) problem by defining a quadratic cost functional over the infinite horizon with a state weighting matrix $Q \\in \\mathbb{R}^{n \\times n}$ and a control weighting matrix $R \\in \\mathbb{R}^{m \\times m}$, where $Q$ is symmetric positive semidefinite and $R$ is symmetric positive definite. Starting from the Hamilton–Jacobi–Bellman principle (also known as the dynamic programming optimality principle), derive the algebraic optimality condition for the value function and obtain the optimal static state feedback law $u(t) = -K x(t)$ in terms of $A, B, Q, R$. Clearly state any standard assumptions required to guarantee existence of a unique stabilizing solution.\n\nThen, implement a program that, for each provided test case, computes the optimal state feedback gain $K$ by solving the appropriate algebraic equation you derived. For numerical reporting, for each test case, return the entries of $K$ flattened in row-major order and rounded to $6$ decimal places.\n\nTest suite:\n- Case $1$ (scalar, open-loop weakly unstable gene product): \n  $$\n  A = \\begin{bmatrix} 0.1 \\end{bmatrix}, \\quad\n  B = \\begin{bmatrix} 1.0 \\end{bmatrix}, \\quad\n  Q = \\begin{bmatrix} 1.0 \\end{bmatrix}, \\quad\n  R = \\begin{bmatrix} 0.5 \\end{bmatrix}.\n  $$\n- Case $2$ (two-state transcription–translation with actuation on transcription):\n  $$\n  A = \\begin{bmatrix} -0.3 & 0.0 \\\\ 2.0 & -0.4 \\end{bmatrix}, \\quad\n  B = \\begin{bmatrix} 1.0 \\\\ 0.0 \\end{bmatrix}, \\quad\n  Q = \\begin{bmatrix} 10.0 & 0.0 \\\\ 0.0 & 1.0 \\end{bmatrix}, \\quad\n  R = \\begin{bmatrix} 0.2 \\end{bmatrix}.\n  $$\n- Case $3$ (two-state cross-coupled protein module, one input):\n  $$\n  A = \\begin{bmatrix} 0.05 & 0.2 \\\\ -0.3 & -0.1 \\end{bmatrix}, \\quad\n  B = \\begin{bmatrix} 0.5 \\\\ 0.1 \\end{bmatrix}, \\quad\n  Q = \\begin{bmatrix} 5.0 & 0.0 \\\\ 0.0 & 2.0 \\end{bmatrix}, \\quad\n  R = \\begin{bmatrix} 1.0 \\end{bmatrix}.\n  $$\n- Case $4$ (scalar with small control penalty):\n  $$\n  A = \\begin{bmatrix} -0.05 \\end{bmatrix}, \\quad\n  B = \\begin{bmatrix} 0.2 \\end{bmatrix}, \\quad\n  Q = \\begin{bmatrix} 0.1 \\end{bmatrix}, \\quad\n  R = \\begin{bmatrix} 0.001 \\end{bmatrix}.\n  $$\n- Case $5$ (two-state, two-input module with diagonally dominant actuation channels):\n  $$\n  A = \\begin{bmatrix} -0.2 & 1.0 \\\\ -1.5 & -0.3 \\end{bmatrix}, \\quad\n  B = \\begin{bmatrix} 1.0 & 0.0 \\\\ 0.0 & 0.5 \\end{bmatrix}, \\quad\n  Q = \\begin{bmatrix} 2.0 & 0.2 \\\\ 0.2 & 3.0 \\end{bmatrix}, \\quad\n  R = \\begin{bmatrix} 1.0 & 0.1 \\\\ 0.1 & 2.0 \\end{bmatrix}.\n  $$\n\nYour program should compute $K$ for each case and produce a single line of output containing the results as a comma-separated list enclosed in square brackets, where each element is itself a square-bracket-enclosed comma-separated list of the row-major entries of $K$ rounded to $6$ decimal places, for example $[ \\text{res}1, \\text{res}2, \\text{res}3 ]$ should appear as $[\\text{res}1,\\text{res}2,\\text{res}3]$ with no spaces. There are no physical units to report in this problem. The final outputs for each case must be lists of floats.",
            "solution": "The problem requires the derivation of the optimal state feedback controller for a continuous-time linear time-invariant (LTI) system using the Linear Quadratic Regulator (LQR) framework, starting from the Hamilton-Jacobi-Bellman (HJB) principle. This formulation is central to optimal control theory and widely applied in engineering and science, including the modeling of synthetic gene circuits for achieving homeostasis.\n\nThe system dynamics are given by the linear ordinary differential equation:\n$$\n\\dot{x}(t) = A x(t) + B u(t)\n$$\nwhere $x(t) \\in \\mathbb{R}^n$ is the state vector representing deviations from a homeostatic steady state, $u(t) \\in \\mathbb{R}^m$ is the control input, $A \\in \\mathbb{R}^{n \\times n}$ is the system matrix, and $B \\in \\mathbb{R}^{n \\times m}$ is the input matrix.\n\nThe objective is to find a control law $u(t)$ that minimizes the infinite-horizon quadratic cost functional $J$:\n$$\nJ = \\int_{0}^{\\infty} \\left( x(t)^T Q x(t) + u(t)^T R u(t) \\right) dt\n$$\nHere, $Q \\in \\mathbb{R}^{n \\times n}$ is a symmetric positive semidefinite state-weighting matrix ($Q = Q^T \\ge 0$), and $R \\in \\mathbb{R}^{m \\times m}$ is a symmetric positive definite control-weighting matrix ($R = R^T > 0$). The term $x^T Q x$ penalizes deviations from the equilibrium state $x=0$, while $u^T R u$ penalizes the control effort.\n\nWe proceed with the derivation using the principle of dynamic programming. The optimal cost-to-go, or value function $V(x)$, is defined as the minimum cost achievable starting from state $x$ at time $t=0$. For a time-invariant system over an infinite horizon, $V$ depends only on the state $x$:\n$$\nV(x) = \\min_{u(\\cdot)} \\int_{0}^{\\infty} \\left( x(\\tau)^T Q x(\\tau) + u(\\tau)^T R u(\\tau) \\right) d\\tau\n$$\nThe Hamilton-Jacobi-Bellman (HJB) equation provides a necessary condition for optimality. For the infinite-horizon LQR problem, the stationary HJB equation is:\n$$\n0 = \\min_{u} \\left\\{ L(x, u) + \\nabla V(x)^T \\dot{x} \\right\\}\n$$\nwhere $L(x, u) = x^T Q x + u^T R u$ is the instantaneous cost and $\\nabla V(x)$ is the gradient of the value function with respect to $x$. Substituting the system dynamics, we get:\n$$\n0 = \\min_{u} \\left\\{ x^T Q x + u^T R u + \\nabla V(x)^T (A x + B u) \\right\\}\n$$\nThe expression within the minimization is the Hamiltonian of the system. To find the optimal control $u^*(t)$, we find the $u$ that minimizes this Hamiltonian.\n\nLet us propose a quadratic form for the value function, $V(x) = x^T P x$, where $P \\in \\mathbb{R}^{n \\times n}$ is a symmetric positive definite matrix to be determined. The gradient of this value function is $\\nabla V(x) = 2 P x$. Substituting this into the HJB equation yields:\n$$\n0 = \\min_{u} \\left\\{ x^T Q x + u^T R u + (2 P x)^T (A x + B u) \\right\\}\n$$\n$$\n0 = \\min_{u} \\left\\{ x^T Q x + u^T R u + 2 x^T P A x + 2 x^T P B u \\right\\}\n$$\nTo find the control $u$ that minimizes this expression, we differentiate with respect to $u$ and set the result to zero. Since $R$ is symmetric, the derivative of $u^T R u$ is $2 R u$, and the derivative of $2 x^T P B u$ is $2 B^T P x$.\n$$\n\\frac{\\partial}{\\partial u} \\left( u^T R u + 2 x^T P B u \\right) = 2 R u + 2 B^T P x = 0\n$$\nSolving for the optimal control $u^*$:\n$$\nu^*(x) = -R^{-1} B^T P x\n$$\nThe existence of $R^{-1}$ is guaranteed because $R$ is positive definite. This result shows that the optimal control is a linear static state feedback law, $u(t) = -K x(t)$, where the optimal feedback gain matrix is given by:\n$$\nK = R^{-1} B^T P\n$$\nNow we substitute the optimal control $u^*$ back into the minimized HJB equation:\n$$\n0 = x^T Q x + (-R^{-1} B^T P x)^T R (-R^{-1} B^T P x) + 2 x^T P A x + 2 x^T P B (-R^{-1} B^T P x)\n$$\nUsing the property that $(XYZ)^T = Z^T Y^T X^T$ and that $R$ and $P$ are symmetric ($R=R^T, P=P^T$), we simplify the terms:\n$$\n0 = x^T Q x + (x^T P B R^{-1}) R (R^{-1} B^T P x) + x^T(P A + A^T P)x - 2 x^T P B R^{-1} B^T P x\n$$\n$$\n0 = x^T Q x + x^T P B R^{-1} B^T P x + x^T(A^T P + P A)x - 2 x^T P B R^{-1} B^T P x\n$$\nCombining terms, we get:\n$$\n0 = x^T \\left( A^T P + P A - P B R^{-1} B^T P + Q \\right) x\n$$\nThis equation must hold for any state vector $x \\in \\mathbb{R}^n$. This is only possible if the matrix expression inside the parentheses is the zero matrix. This gives us the algebraic optimality condition for $P$:\n$$\nA^T P + P A - P B R^{-1} B^T P + Q = 0\n$$\nThis is the Continuous-time Algebraic Riccati Equation (CARE).\n\nFor a unique, symmetric, positive semidefinite solution $P$ to the CARE to exist such that the closed-loop system $\\dot{x} = (A - B K)x$ is asymptotically stable, two standard assumptions are required:\n1.  The pair $(A, B)$ must be stabilizable. This means that any unstable modes of the system (eigenvalues of $A$ with non-negative real parts) must be controllable.\n2.  The pair $(C, A)$ with $C$ such that $Q = C^T C$ (e.g., $C=Q^{1/2}$) must be detectable. This means that any unobservable modes of the system must be inherently stable (have eigenvalues with negative real parts).\n\nIf these conditions are met, the CARE has a unique stabilizing solution $P \\ge 0$. The numerical procedure is to solve the CARE for this matrix $P$ and then compute the optimal gain matrix $K$ using the derived formula $K = R^{-1} B^T P$. Standard numerical libraries provide robust solvers for the CARE.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.linalg import solve_continuous_are\n\ndef solve():\n    \"\"\"\n    Computes the optimal LQR gain K for a set of test cases.\n\n    For each case, the function solves the Continuous-time Algebraic Riccati Equation (CARE)\n    A'P + PA - PBR^{-1}B'P + Q = 0 for the matrix P.\n    Then, it computes the optimal feedback gain K = R^{-1}B'P.\n    \"\"\"\n    \n    # Define the test cases from the problem statement.\n    test_cases = [\n        # Case 1: scalar, open-loop weakly unstable\n        (np.array([[0.1]]), np.array([[1.0]]), np.array([[1.0]]), np.array([[0.5]])),\n        \n        # Case 2: two-state transcription-translation\n        (np.array([[-0.3, 0.0], [2.0, -0.4]]), np.array([[1.0], [0.0]]), \n         np.array([[10.0, 0.0], [0.0, 1.0]]), np.array([[0.2]])),\n        \n        # Case 3: two-state cross-coupled module\n        (np.array([[0.05, 0.2], [-0.3, -0.1]]), np.array([[0.5], [0.1]]), \n         np.array([[5.0, 0.0], [0.0, 2.0]]), np.array([[1.0]])),\n        \n        # Case 4: scalar with small control penalty\n        (np.array([[-0.05]]), np.array([[0.2]]), np.array([[0.1]]), np.array([[0.001]])),\n\n        # Case 5: two-state, two-input module\n        (np.array([[-0.2, 1.0], [-1.5, -0.3]]), np.array([[1.0, 0.0], [0.0, 0.5]]), \n         np.array([[2.0, 0.2], [0.2, 3.0]]), np.array([[1.0, 0.1], [0.1, 2.0]]))\n    ]\n\n    results = []\n    for A, B, Q, R in test_cases:\n        # Solve the Continuous-time Algebraic Riccati Equation for P\n        # A.T @ P + P @ A - P @ B @ np.linalg.inv(R) @ B.T @ P + Q = 0\n        P = solve_continuous_are(A, B, Q, R)\n        \n        # Calculate the optimal feedback gain K\n        # K = R^{-1} * B^T * P\n        R_inv = np.linalg.inv(R)\n        K = R_inv @ B.T @ P\n        \n        # Flatten the K matrix in row-major order\n        k_flat = K.flatten().tolist()\n        \n        # Round the values to 6 decimal places\n        k_rounded = [round(val, 6) for val in k_flat]\n        \n        # Format the list as a string \"[v1,v2,...]\"\n        result_str = f\"[{','.join(map(str, k_rounded))}]\"\n        results.append(result_str)\n\n    # Final print statement in the exact required format.\n    # e.g., [[k_11,k_12],[k_21,k_22],...]\n    print(f\"[{','.join(results)}]\")\n\nsolve()\n```"
        }
    ]
}