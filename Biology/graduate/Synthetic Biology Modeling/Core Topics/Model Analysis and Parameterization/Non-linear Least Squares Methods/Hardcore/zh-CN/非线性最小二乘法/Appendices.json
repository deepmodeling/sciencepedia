{
    "hands_on_practices": [
        {
            "introduction": "理论知识需要通过实践来巩固。本节将引导你完成一系列动手练习，旨在加深你对非线性最小二乘法在合成生物学建模中应用的理解。让我们从一个基础练习开始，通过手动计算来揭开优化算法的神秘面纱。这项练习将要求你对经典的米氏方程模型，手动执行一次高斯-牛顿迭代，从而为更复杂的参数估计问题打下坚实的计算和概念基础 。",
            "id": "3923519",
            "problem": "基因线路中的一个合成酶模块遵循米氏动力学（Michaelis–Menten, MM）将底物转化为产物。在底物浓度为 $S$ 时，可测量的初始速率由模型 $v(S; V_{\\max}, K_{M}) = \\dfrac{V_{\\max} S}{K_{M} + S}$ 描述。现给定一组通过校准的微流控分析获得的底物浓度和相应的测量初始速率，该数据适用于最小二乘（least squares, LS）参数估计：\n- 底物浓度（单位为微摩尔）：$S \\in \\{5, 10, 20, 50\\}$。\n- 测量初始速率（单位为微摩尔/分钟）：$v^{\\mathrm{obs}} \\in \\left\\{\\dfrac{5}{8}, 1, \\dfrac{10}{7}, \\dfrac{25}{13}\\right\\}$。\n\n从初始参数猜测 $V_{\\max}^{(0)} = 2.0$ 和 $K_{M}^{(0)} = 10$ 开始，对旨在最小化残差平方和 $\\sum_{i} \\left(v_{i}^{\\mathrm{obs}} - v(S_{i}; V_{\\max}, K_{M})\\right)^{2}$ 的非线性最小二乘问题应用单次高斯-牛顿（Gauss–Newton, GN）迭代。从第一性原理出发，显式计算高斯-牛顿更新量，并报告单次迭代后更新的参数矢量 $\\left(V_{\\max}^{(1)}, K_{M}^{(1)}\\right)$。\n\n将最终数值结果四舍五入至四位有效数字。$V_{\\max}$ 的单位为微摩尔/分钟，$K_{M}$ 的单位为微摩尔。定义你引入的所有符号，并从第一性原理出发，以适用于合成生物学建模中非线性最小二乘法的形式，论证每一步的合理性。除了通过泰勒线性化和最小二乘法正规方程推导出的公式外，避免使用任何预先推导的快捷公式。为清晰起见，在首次出现时定义你使用的任何缩写词，例如米氏动力学（Michaelis–Menten, MM）、最小二乘法（least squares, LS）和高斯-牛顿法（Gauss–Newton, GN）。",
            "solution": "目标是通过应用单次高斯-牛顿（Gauss-Newton, GN）算法迭代，来优化米氏动力学（Michaelis–Menten, MM）参数 $V_{\\max}$ 和 $K_{M}$ 的初始估计值。该方法是解决非线性最小二乘（least squares, LS）问题的标准方法，这类问题在合成生物学中将机理模型与实验数据进行拟合时经常出现。\n\n设参数矢量表示为 $\\mathbf{p} = \\begin{pmatrix} V_{\\max} \\\\ K_{M} \\end{pmatrix}$。在给定底物浓度 $S$ 下，初始速率 $v$ 的模型由米氏方程给出：\n$$v(S; \\mathbf{p}) = \\frac{V_{\\max} S}{K_{M} + S}$$\n我们得到了一组 $n=4$ 个实验数据点 $(S_i, v_{i}^{\\mathrm{obs}})$。最小二乘问题的目标是找到参数矢量 $\\mathbf{p}$，以最小化残差平方和 $S(\\mathbf{p})$：\n$$S(\\mathbf{p}) = \\sum_{i=1}^{n} r_i(\\mathbf{p})^2 = \\sum_{i=1}^{n} \\left(v_{i}^{\\mathrm{obs}} - v(S_i; \\mathbf{p})\\right)^2$$\n其中 $r_i(\\mathbf{p})$ 是第 $i$ 个数据点的残差。\n\n高斯-牛顿算法是一种迭代方法，在每一步 $k$ 中，我们寻求一个更新量 $\\Delta\\mathbf{p}^{(k)}$ 来改进当前的参数估计 $\\mathbf{p}^{(k)}$。新的估计值为 $\\mathbf{p}^{(k+1)} = \\mathbf{p}^{(k)} + \\Delta\\mathbf{p}^{(k)}$。\n该算法通过围绕当前估计值 $\\mathbf{p}^{(k)}$ 对模型函数 $v(S_i; \\mathbf{p})$ 进行一阶泰勒展开来实现线性化：\n$$v(S_i; \\mathbf{p}) \\approx v(S_i; \\mathbf{p}^{(k)}) + \\nabla_{\\mathbf{p}} v(S_i; \\mathbf{p}^{(k)})^T (\\mathbf{p} - \\mathbf{p}^{(k)})$$\n此处，$\\nabla_{\\mathbf{p}} v(S_i; \\mathbf{p}^{(k)})$ 是在 $\\mathbf{p}^{(k)}$ 处计算的模型函数的梯度。令 $\\mathbf{J}$ 为雅可比矩阵，其元素为 $J_{ij} = \\frac{\\partial v(S_i; \\mathbf{p})}{\\partial p_j}$，在 $\\mathbf{p}^{(k)}$ 处计算。$\\mathbf{J}$ 的第 $i$ 行是 $\\nabla_{\\mathbf{p}} v(S_i; \\mathbf{p}^{(k)})^T$。\n将线性化结果代入残差定义中，得到：\n$$r_i(\\mathbf{p}) \\approx \\left(v_{i}^{\\mathrm{obs}} - v(S_i; \\mathbf{p}^{(k)})\\right) - \\sum_{j=1}^{m} J_{ij} (\\mathbf{p}_j - \\mathbf{p}_j^{(k)})$$\n其中 $m=2$ 是参数的数量。以矢量形式表示，其中 $\\mathbf{r}(\\mathbf{p})$ 是残差矢量，$\\Delta\\mathbf{p} = \\mathbf{p} - \\mathbf{p}^{(k)}$，该近似式为：\n$$\\mathbf{r}(\\mathbf{p}) \\approx \\mathbf{r}(\\mathbf{p}^{(k)}) - \\mathbf{J}(\\mathbf{p}^{(k)}) \\Delta\\mathbf{p}$$\n最小二乘问题随后变为找到使 $\\| \\mathbf{r}(\\mathbf{p}^{(k)}) - \\mathbf{J}(\\mathbf{p}^{(k)}) \\Delta\\mathbf{p} \\|_2^2$ 最小化的 $\\Delta\\mathbf{p}$。这是一个线性最小二乘问题，其解由正规方程给出：\n$$\\left(\\mathbf{J}^T \\mathbf{J}\\right) \\Delta\\mathbf{p} = \\mathbf{J}^T \\mathbf{r}(\\mathbf{p}^{(k)})$$\n因此，第 $k$ 次迭代的更新量为 $\\Delta\\mathbf{p}^{(k)} = \\left((\\mathbf{J}^{(k)})^T \\mathbf{J}^{(k)}\\right)^{-1} (\\mathbf{J}^{(k)})^T \\mathbf{r}(\\mathbf{p}^{(k)})$。\n\n我们现在从 $k=0$ 开始，执行一次迭代。\n\n**步骤 1：定义初始状态和数据**\n- 初始参数猜测：$\\mathbf{p}^{(0)} = \\begin{pmatrix} V_{\\max}^{(0)} \\\\ K_{M}^{(0)} \\end{pmatrix} = \\begin{pmatrix} 2.0 \\\\ 10 \\end{pmatrix}$。$V_{\\max}$ 的单位是 $\\mu\\mathrm{M} \\cdot \\mathrm{min}^{-1}$，$K_{M}$ 的单位是 $\\mu\\mathrm{M}$。\n- 数据点 $(S_i, v_{i}^{\\mathrm{obs}})$：$(5, 5/8)$, $(10, 1)$, $(20, 10/7)$, $(50, 25/13)$。\n\n**步骤 2：在 $\\mathbf{p}^{(0)}$ 处计算雅可比矩阵 $\\mathbf{J}$**\n$v(S; \\mathbf{p})$ 对各参数的偏导数是：\n$$\\frac{\\partial v}{\\partial V_{\\max}} = \\frac{S}{K_{M} + S}$$\n$$\\frac{\\partial v}{\\partial K_{M}} = V_{\\max} S \\left( -(K_{M} + S)^{-2} \\right) = -\\frac{V_{\\max} S}{(K_{M} + S)^2}$$\n在 $\\mathbf{p}^{(0)} = (2, 10)$ 处对每个 $S_i$ 进行计算：\n对于 $S_1 = 5$：$\\frac{\\partial v}{\\partial V_{\\max}} = \\frac{5}{15} = \\frac{1}{3}$，$\\frac{\\partial v}{\\partial K_{M}} = -\\frac{2 \\cdot 5}{15^2} = -\\frac{10}{225} = -\\frac{2}{45}$。\n对于 $S_2 = 10$：$\\frac{\\partial v}{\\partial V_{\\max}} = \\frac{10}{20} = \\frac{1}{2}$，$\\frac{\\partial v}{\\partial K_{M}} = -\\frac{2 \\cdot 10}{20^2} = -\\frac{20}{400} = -\\frac{1}{20}$。\n对于 $S_3 = 20$：$\\frac{\\partial v}{\\partial V_{\\max}} = \\frac{20}{30} = \\frac{2}{3}$，$\\frac{\\partial v}{\\partial K_{M}} = -\\frac{2 \\cdot 20}{30^2} = -\\frac{40}{900} = -\\frac{2}{45}$。\n对于 $S_4 = 50$：$\\frac{\\partial v}{\\partial V_{\\max}} = \\frac{50}{60} = \\frac{5}{6}$，$\\frac{\\partial v}{\\partial K_{M}} = -\\frac{2 \\cdot 50}{60^2} = -\\frac{100}{3600} = -\\frac{1}{36}$。\n在 $\\mathbf{p}^{(0)}$ 处的雅可比矩阵为：\n$$\\mathbf{J}^{(0)} = \\begin{pmatrix} 1/3  -2/45 \\\\ 1/2  -1/20 \\\\ 2/3  -2/45 \\\\ 5/6  -1/36 \\end{pmatrix}$$\n\n**步骤 3：计算残差矢量 $\\mathbf{r}(\\mathbf{p}^{(0)})$**\n首先，计算模型预测值 $v(S_i; \\mathbf{p}^{(0)}) = \\frac{2 S_i}{10+S_i}$：\n$v(5; \\mathbf{p}^{(0)}) = \\frac{2 \\cdot 5}{10+5} = \\frac{10}{15} = \\frac{2}{3}$。\n$v(10; \\mathbf{p}^{(0)}) = \\frac{2 \\cdot 10}{10+10} = \\frac{20}{20} = 1$。\n$v(20; \\mathbf{p}^{(0)}) = \\frac{2 \\cdot 20}{10+20} = \\frac{40}{30} = \\frac{4}{3}$。\n$v(50; \\mathbf{p}^{(0)}) = \\frac{2 \\cdot 50}{10+50} = \\frac{100}{60} = \\frac{5}{3}$。\n残差 $r_i^{(0)} = v_{i}^{\\mathrm{obs}} - v(S_i; \\mathbf{p}^{(0)})$ 为：\n$r_1 = \\frac{5}{8} - \\frac{2}{3} = \\frac{15-16}{24} = -\\frac{1}{24}$。\n$r_2 = 1 - 1 = 0$。\n$r_3 = \\frac{10}{7} - \\frac{4}{3} = \\frac{30-28}{21} = \\frac{2}{21}$。\n$r_4 = \\frac{25}{13} - \\frac{5}{3} = \\frac{75-65}{39} = \\frac{10}{39}$。\n残差矢量为：\n$$\\mathbf{r}^{(0)} = \\begin{pmatrix} -1/24 \\\\ 0 \\\\ 2/21 \\\\ 10/39 \\end{pmatrix} \\approx \\begin{pmatrix} -0.041667 \\\\ 0 \\\\ 0.095238 \\\\ 0.256410 \\end{pmatrix}$$\n\n**步骤 4：求解正规方程**\n我们必须求解 $(\\mathbf{J}^T \\mathbf{J}) \\Delta\\mathbf{p} = \\mathbf{J}^T \\mathbf{r}$。\n首先，计算 $(\\mathbf{J}^{(0)})^T \\mathbf{J}^{(0)}$：\n$$(\\mathbf{J}^{(0)})^T \\mathbf{J}^{(0)} = \\begin{pmatrix} 1/3  1/2  2/3  5/6 \\\\ -2/45  -1/20  -2/45  -1/36 \\end{pmatrix} \\begin{pmatrix} 1/3  -2/45 \\\\ 1/2  -1/20 \\\\ 2/3  -2/45 \\\\ 5/6  -1/36 \\end{pmatrix} $$\n$$ = \\begin{pmatrix} \\frac{1}{9}+\\frac{1}{4}+\\frac{4}{9}+\\frac{25}{36}  -\\frac{2}{135}-\\frac{1}{40}-\\frac{4}{135}-\\frac{5}{216} \\\\ -\\frac{2}{135}-\\frac{1}{40}-\\frac{4}{135}-\\frac{5}{216}  \\frac{4}{2025}+\\frac{1}{400}+\\frac{4}{2025}+\\frac{1}{1296} \\end{pmatrix} = \\begin{pmatrix} \\frac{3}{2}  -\\frac{5}{54} \\\\ -\\frac{5}{54}  \\frac{13}{1800} \\end{pmatrix}$$\n数值上，$(\\mathbf{J}^{(0)})^T \\mathbf{J}^{(0)} \\approx \\begin{pmatrix} 1.5  -0.092593 \\\\ -0.092593  0.007222 \\end{pmatrix}$。\n\n接下来，计算 $(\\mathbf{J}^{(0)})^T \\mathbf{r}^{(0)}$：\n$$(\\mathbf{J}^{(0)})^T \\mathbf{r}^{(0)} = \\begin{pmatrix} \\frac{1}{3}(-\\frac{1}{24}) + \\frac{1}{2}(0) + \\frac{2}{3}(\\frac{2}{21}) + \\frac{5}{6}(\\frac{10}{39}) \\\\ -\\frac{2}{45}(-\\frac{1}{24}) - \\frac{1}{20}(0) - \\frac{2}{45}(\\frac{2}{21}) - \\frac{1}{36}(\\frac{10}{39}) \\end{pmatrix} = \\begin{pmatrix} \\frac{575}{2184} \\\\ -\\frac{467}{49140} \\end{pmatrix}$$\n数值上，$(\\mathbf{J}^{(0)})^T \\mathbf{r}^{(0)} \\approx \\begin{pmatrix} 0.263278 \\\\ -0.009503 \\end{pmatrix}$。\n\n我们求解关于 $\\Delta\\mathbf{p}^{(0)} = \\begin{pmatrix} \\Delta V_{\\max} \\\\ \\Delta K_M \\end{pmatrix}$ 的线性系统：\n$$\\begin{pmatrix} 1.5  -0.092593 \\\\ -0.092593  0.007222 \\end{pmatrix} \\begin{pmatrix} \\Delta V_{\\max} \\\\ \\Delta K_M \\end{pmatrix} = \\begin{pmatrix} 0.263278 \\\\ -0.009503 \\end{pmatrix}$$\n解此系统可得：\n$$\\Delta V_{\\max} \\approx 0.451966$$\n$$\\Delta K_M \\approx 4.476483$$\n\n**步骤 5：更新参数矢量**\n新的参数估计值 $\\mathbf{p}^{(1)}$ 为：\n$$\\mathbf{p}^{(1)} = \\mathbf{p}^{(0)} + \\Delta\\mathbf{p}^{(0)} = \\begin{pmatrix} 2.0 \\\\ 10 \\end{pmatrix} + \\begin{pmatrix} 0.451966 \\\\ 4.476483 \\end{pmatrix} = \\begin{pmatrix} 2.451966 \\\\ 14.476483 \\end{pmatrix}$$\n\n**步骤 6：最终答案**\n将 $\\mathbf{p}^{(1)}$ 的分量四舍五入至四位有效数字，得到：\n$$V_{\\max}^{(1)} \\approx 2.452$$\n$$K_{M}^{(1)} \\approx 14.48$$\n更新后的参数矢量为 $(V_{\\max}^{(1)}, K_{M}^{(1)}) = (2.452, 14.48)$。",
            "answer": "$$\\boxed{\\begin{pmatrix} 2.452 & 14.48 \\end{pmatrix}}$$"
        },
        {
            "introduction": "在处理复杂的生物学模型时，线性化方法得到的置信区间可能并不可靠，特别是在参数存在耦合或可辨识性较差的情况下。为了解决这个问题，我们需要更强大的工具。这项练习将介绍一种计算密集但更为稳健的方法——轮廓似然分析（profile likelihood）。通过编写代码来系统地探索参数空间，你将学会如何评估参数（如此处的希尔系数 $n$）的可辨识性，并获得比线性近似更可靠的置信范围 。",
            "id": "3923524",
            "problem": "您将处理一个非线性回归问题，该问题源于一个在合成生物学建模中常用的稳态Hill型转录抑制模型。测量的可观测量是作为诱导剂浓度函数的稳态报告基因强度。该模型定义了从诱导剂浓度 $u$（单位为微摩尔，记作 $\\mu\\mathrm{M}$）到观测强度 $y$（单位为任意荧光单位）的映射关系，如下所示：\n$$\ny(u;p) \\;=\\; y_0 \\;+\\; \\frac{V}{1 + \\left(\\frac{u}{K}\\right)^{n}},\n$$\n其中，参数向量为 $p = (y_0, V, K, n)$，各参数分别为：$y_0 \\ge 0$（基线），$V \\ge 0$（动态范围），$K > 0$（半抑制浓度，单位为 $\\mu\\mathrm{M}$），以及 $n > 0$（Hill系数）。假设每个数据点都有独立的、已知标准差为 $\\sigma$ 的高斯测量噪声。对于给定的数据 $\\{(u_i, y_i)\\}_{i=1}^m$，加权非线性最小二乘的目标函数为\n$$\nS(p) \\;=\\; \\sum_{i=1}^{m} \\left(\\frac{y_i - y(u_i;p)}{\\sigma}\\right)^2.\n$$\n\n您将使用约束非线性最小二乘法，对Hill系数 $n$ 进行剖面似然分析。对于一个固定的 $n$ 值（视为标量），定义剖面目标函数\n$$\nS_{\\mathrm{prof}}(n) \\;=\\; \\min_{(y_0,V,K)} \\; S(y_0,V,K,n) \\quad \\text{subject to} \\quad y_0 \\ge 0,\\; V \\ge 0,\\; K \\in [10^{-3},10^{3}],\n$$\n并在 $n$ 遍历一个网格时追踪 $S_{\\mathrm{prof}}(n)$。在高斯噪声假设下，此过程对应于 $n$ 的剖面似然，并能够基于似然比原则对 $n$ 进行可辨识性评估。\n\n使用的基本原理和假设：\n- 分子生物学的中心法则为转录调控模型提供了理论基础，但对于本问题，仅需要使用上文给出的抑制性Hill函数的数学形式。\n- 对于具有已知方差的独立高斯噪声，最小化加权平方和 $S(p)$ 等同于最大化对数似然（相差一个加性常数）。\n- 对于单个标量参数，水平为 $0.95$ 的似然比检验使用自由度为1的卡方分布，因此 $0.95$ 分位数为 $\\chi^2_{1,0.95} \\approx 3.841458820694124$。从剖面导出的 $n$ 的 $95\\%$ 置信集为 $\\{ n: S_{\\mathrm{prof}}(n) - \\min_n S_{\\mathrm{prof}}(n) \\le \\chi^2_{1,0.95} \\}$。\n\n您的程序必须针对下面指定的每个测试用例，在 $n$ 值的网格上执行以下步骤，并产生指定的标量输出：\n1. 定义一个均匀网格 $n \\in [0.5, 6.0]$，间距为 $\\Delta n = 0.05$。\n2. 对于每个网格点 $n$，通过在边界约束 $y_0 \\in [0, 2000]$、$V \\in [0, 5000]$ 和 $K \\in [10^{-3}, 10^{3}]$ 下最小化 $S(y_0,V,K,n)$ 来计算 $S_{\\mathrm{prof}}(n)$。使用每个测试用例指定的相同 $\\sigma$。\n3. 设 $n^\\ast$ 为使 $S_{\\mathrm{prof}}(n)$ 达到全局最小值的网格点。\n\n您必须使用给定的诱导剂浓度和真实参数实现以下三个测试用例，并从模型中精确生成无噪声的观测值 $y_i$：\n- 测试用例A（宽动态范围，信息丰富）：\n  - 浓度（单位 $\\mu\\mathrm{M}$）：$u = [0.1, 0.3, 1, 3, 10, 30, 100]$。\n  - 真实参数：$y_0^{\\mathrm{true}} = 100$，$V^{\\mathrm{true}} = 900$，$K^{\\mathrm{true}} = 10$（单位 $\\mu\\mathrm{M}$），$n^{\\mathrm{true}} = 2.5$。\n  - 噪声标准差：$\\sigma = 30$（荧光单位）。\n  - 要求的标量结果：绝对误差 $|n^\\ast - n^{\\mathrm{true}}|$，以浮点数形式表示。\n\n- 测试用例B（低浓度范围，$n$ 可能不可辨识）：\n  - 浓度（单位 $\\mu\\mathrm{M}$）：$u = [0.1, 0.2, 0.3, 0.5, 0.8, 1.0, 1.5]$。\n  - 真实参数：$y_0^{\\mathrm{true}} = 100$，$V^{\\mathrm{true}} = 900$，$K^{\\mathrm{true}} = 10$（单位 $\\mu\\mathrm{M}$），$n^{\\mathrm{true}} = 2.5$。\n  - 噪声标准差：$\\sigma = 30$（荧光单位）。\n  - 可辨识性评估：使用剖面 $S_{\\mathrm{prof}}(n)$ 和阈值 $\\Delta S = \\chi^2_{1,0.95}$，将 $n$ 的 $95\\%$ 置信集定义为 $\\{n : S_{\\mathrm{prof}}(n) - \\min S_{\\mathrm{prof}} \\le \\chi^2_{1,0.95} \\}$。返回布尔值 $\\mathrm{identifiable}$，当且仅当此置信集是一个严格位于网格 $[0.5, 6.0]$ 内部的真有界区间时，该值为 $\\mathrm{True}$（意味着在网格内存在有限的下界和上界），否则为 $\\mathrm{False}$。\n\n- 测试用例C（高浓度范围，边界行为检查）：\n  - 浓度（单位 $\\mu\\mathrm{M}$）：$u = [30, 50, 80, 120, 200, 300]$。\n  - 真实参数：$y_0^{\\mathrm{true}} = 100$，$V^{\\mathrm{true}} = 900$，$K^{\\mathrm{true}} = 10$（单位 $\\mu\\mathrm{M}$），$n^{\\mathrm{true}} = 2.5$。\n  - 噪声标准差：$\\sigma = 30$（荧光单位）。\n  - 要求的标量结果：整数指示符 $b$，定义为：如果 $n^\\ast$恰好等于 $n$ 网格的左边界 $0.5$ 或右边界 $6.0$，则 $b=1$；否则 $b=0$。\n\n需要遵守的实现细节：\n- 对于固定 $n$ 的内部最小化问题，使用适合边界约束的算法求解关于 $(y_0,V,K)$ 的约束非线性最小二乘问题。\n- 使用加权残差形式 $(y_i - y(u_i;p))/\\sigma$，使得 $S(p)$ 等于这些残差的平方和。\n- 使用从数据导出的初始猜测值：$y_0^{(0)} = \\min_i y_i$，$V^{(0)} = \\max_i y_i - \\min_i y_i$ 以及 $K^{(0)} = \\mathrm{median}(u_i)$。\n- 角度单位不适用。物理单位已在适当之处指明。如下文所述，所有输出均无单位。\n\n最终输出格式：\n- 您的程序应生成单行输出，其中包含三个测试用例的结果，格式为方括号内以逗号分隔的列表，顺序为 $[\\text{A的结果}, \\text{B的结果}, \\text{C的结果}]$。\n- 第一个元素是浮点数 $|n^\\ast - n^{\\mathrm{true}}|$。第二个元素是布尔值 $\\mathrm{True}$ 或 $\\mathrm{False}$。第三个元素是整数 $0$ 或 $1$。\n- 例如，一个语法上有效的输出应如下所示：$[0.0123,True,0]$。",
            "solution": "该问题要求对一个转录抑制模型的Hill系数 $n$ 进行剖面似然分析。这是系统生物学中用于评估参数可辨識性的一项标准技术。解决方案涉及一种基于网格的数值方法。\n\n观测到的荧光强度 $y$ 作为诱导剂浓度 $u$ 函数的稳态模型由Hill型抑制函数给出：\n$$\ny(u;p) \\;=\\; y_0 \\;+\\; \\frac{V}{1 + \\left(\\frac{u}{K}\\right)^{n}}\n$$\n其中参数向量为 $p = (y_0, V, K, n)$。这些参数分别代表基线荧光 ($y_0$)、抑制的动态范围 ($V$)、半抑制浓度 ($K$) 以及量化响应陡峭程度的Hill系数 ($n$)。\n\n我们的任务是将此模型拟合到数据。假设测量值存在独立同分布且标准差 $\\sigma$ 已知的高斯噪声，参数的最大似然估计可以通过最小化加权残差平方和（SSR）来找到，该平方和定义了目标函数 $S(p)$：\n$$\nS(p) \\;=\\; \\sum_{i=1}^{m} \\left(\\frac{y_i - y(u_i;p)}{\\sigma}\\right)^2\n$$\n其中 $\\{(u_i, y_i)\\}_{i=1}^m$ 是 $m$ 个数据点。\n\n问题的核心是针对参数 $n$ 的剖面似然分析。剖面似然是关于单个目标参数的函数，通过对所有其他（讨厌）参数进行优化而得到。对于一个固定的 $n$ 值，我们将剖面目标函数 $S_{\\mathrm{prof}}(n)$ 定义为 $S(p)$ 的可能最小值，其中最小化是针对讨厌参数 $(y_0, V, K)$进行的：\n$$\nS_{\\mathrm{prof}}(n) \\;=\\; \\min_{(y_0,V,K)} \\; S(y_0,V,K,n)\n$$\n该最小化受限于箱式约束 $y_0 \\in [0, 2000]$、$V \\in [0, 5000]$ 和 $K \\in [10^{-3}, 10^{3}]$。\n\n算法流程如下：\n1. 在区间 $[0.5, 6.0]$ 内为Hill系数 $n$ 定义一个均匀网格，步长为 $\\Delta n = 0.05$。\n2. 对于此网格上的每个 $n$ 值，求解内部优化问题以找到 $S_{\\mathrm{prof}}(n)$。这是一个关于参数 $(y_0, V, K)$ 的约束非线性最小二乘问题。我们采用在 `scipy.optimize.least_squares` 中实现的信赖域反射（`trf`）算法，该算法适用于有界约束问题。优化过程使用从数据导出的 $(y_0, V, K)$ 初始猜测值进行初始化：$y_0^{(0)} = \\min_i y_i$，$V^{(0)} = \\max_i y_i - \\min_i y_i$ 以及 $K^{(0)} = \\mathrm{median}(u_i)$。\n3. 将网格上所有 $n$ 对应的 $S_{\\mathrm{prof}}(n)$ 值制成表格。该剖面的形状提供了关于 $n$ 可辨识性的信息。产生剖面最小值 $S_{min} = \\min_n S_{\\mathrm{prof}}(n)$ 的网格点 $n^\\ast$ 是 $n$ 的最大似然估计（限制在网格上）。\n\n使用从具有指定真实参数的模型生成的无噪声数据，对三个测试用例进行分析。\n- 对于测试用例A，要求的输出是绝对误差 $|n^\\ast - n^{\\mathrm{true}}|$。由于数据是无噪声的，并且覆盖了响应曲线的整个动态范围，因此剖面预计会很尖锐，优化过程行为良好，从而导致 $n^\\ast$ 非常接近或等于 $n^{\\mathrm{true}}$。\n- 对于测试用例B，我们评估可辨識性。基于似然比检验，$n$ 的 $95\\%$ 置信区间包括所有使得剖面值不超过其最小值加上某个阈值的 $n$ 值：$\\{ n : S_{\\mathrm{prof}}(n) - S_{min} \\le \\chi^2_{1,0.95} \\}$，其中 $\\chi^2_{1,0.95} \\approx 3.841458820694124$ 是自由度为1的卡方分布的 $95\\%$ 分位数。如果此置信区间是有限的且严格包含在分析网格 $[0.5, 6.0]$ 内，则参数 $n$ 被认为是可辨识的。来自有限浓度范围（低浓度区域）的数据预计会使 $n$ 的可辨识性差，导致一个延伸到网格边界的宽置信区间。\n- 对于测试用例C，数据仅在曲线的高浓度饱和部分采样。这为估计参数提供的信息很少，可能导致剖面平坦或扭曲。任务是确定所得的估计值 $n^\\ast$ 是否落在搜索网格的边界上，这是这种差的可辨识性的一个指标。要求的输出是一个整数标志。\n\n实现封装了这一逻辑，遍历所有测试用例，并对每个测试用例计算出的剖面应用指定的分析。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.optimize import least_squares\n\ndef solve():\n    \"\"\"\n    Solves the profile likelihood analysis problem for three test cases of a \n    Hill-type repression model.\n    \"\"\"\n    # Global constants as specified in the problem\n    CHI_SQUARED_VAL = 3.841458820694124\n    \n    def model_func(p, u):\n        \"\"\"\n        Hill-type repression model.\n        p: parameter vector (y0, V, K, n)\n        u: inducer concentration array\n        \"\"\"\n        y0, V, K, n = p\n        # Bounds on K in the optimizer prevent it from being zero.\n        term = u / K\n        return y0 + V / (1 + term**n)\n\n    def run_profile_analysis(u_data, p_true, sigma):\n        \"\"\"\n        Performs the profile likelihood analysis for a given test case.\n        It grids over n, and for each n, optimizes the other parameters.\n        \"\"\"\n        # Generate noise-free measurement data from the true model\n        y_data = model_func(p_true, u_data)\n\n        # 1. Define a uniform grid for the parameter n\n        n_grid = np.arange(0.5, 6.0 + 0.05 / 2, 0.05)\n\n        # Use initial guesses derived from the data for the inner optimization\n        y0_guess = np.min(y_data)\n        V_guess = np.max(y_data) - np.min(y_data)\n        K_guess = np.median(u_data)\n        p0_inner = [y0_guess, V_guess, K_guess]\n        \n        # Bounds for the inner optimization of (y0, V, K)\n        bounds_inner = ([0, 0, 1e-3], [2000, 5000, 1e3])\n        \n        s_prof_values = []\n\n        # Residuals function for scipy.optimize.least_squares\n        def residuals(p_inner, n_fixed, u, y, sigma_val):\n            y0, V, K = p_inner\n            p_full = (y0, V, K, n_fixed)\n            y_model = model_func(p_full, u)\n            return (y - y_model) / sigma_val\n\n        # 2. For each grid point n, compute S_prof(n) by minimizing over (y0, V, K)\n        for n_val in n_grid:\n            result = least_squares(\n                fun=residuals,\n                x0=p0_inner,\n                args=(n_val, u_data, y_data, sigma),\n                bounds=bounds_inner,\n                method='trf',\n                ftol=1e-9, gtol=1e-9, xtol=1e-9 # Stricter tolerances for accuracy\n            )\n            # S(p) = sum of squared residuals. result.cost is 0.5 * sum of squares.\n            s_prof_values.append(2 * result.cost)\n\n        s_prof_values = np.array(s_prof_values)\n\n        # 3. Find n* that attains the global minimum of S_prof(n) on the grid\n        s_min = np.min(s_prof_values)\n        min_idx = np.argmin(s_prof_values)\n        n_star = n_grid[min_idx]\n\n        return n_grid, s_prof_values, s_min, n_star\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        {\n            'u': np.array([0.1, 0.3, 1, 3, 10, 30, 100]),\n            'p_true': (100, 900, 10, 2.5),\n            'sigma': 30,\n            'type': 'A'\n        },\n        {\n            'u': np.array([0.1, 0.2, 0.3, 0.5, 0.8, 1.0, 1.5]),\n            'p_true': (100, 900, 10, 2.5),\n            'sigma': 30,\n            'type': 'B'\n        },\n        {\n            'u': np.array([30, 50, 80, 120, 200, 300]),\n            'p_true': (100, 900, 10, 2.5),\n            'sigma': 30,\n            'type': 'C'\n        }\n    ]\n    \n    results = []\n    \n    for case in test_cases:\n        n_grid, s_prof, s_min, n_star = run_profile_analysis(case['u'], case['p_true'], case['sigma'])\n        \n        if case['type'] == 'A':\n            n_true = case['p_true'][3]\n            result = abs(n_star - n_true)\n            results.append(result)\n            \n        elif case['type'] == 'B':\n            conf_set_mask = (s_prof - s_min) = CHI_SQUARED_VAL\n            conf_set_indices = np.where(conf_set_mask)[0]\n            \n            is_identifiable = False\n            # Check if confidence set is non-empty and strictly within grid boundaries\n            if len(conf_set_indices) > 0:\n                conf_set_lower_n = n_grid[conf_set_indices[0]]\n                conf_set_upper_n = n_grid[conf_set_indices[-1]]\n                \n                # 'strictly inside' means lower bound > grid minimum and upper bound  grid maximum\n                if conf_set_lower_n > n_grid[0] and conf_set_upper_n  n_grid[-1]:\n                    is_identifiable = True\n            \n            results.append(is_identifiable)\n            \n        elif case['type'] == 'C':\n            # Check if n* is exactly at a boundary. Direct comparison is fine as n_star\n            # is selected from the n_grid array.\n            is_at_boundary = (n_star == n_grid[0]) or (n_star == n_grid[-1])\n            result = 1 if is_at_boundary else 0\n            results.append(result)\n\n    # Final print statement in the exact required format.\n    print(f\"[{results[0]},{results[1]},{results[2]}]\")\n\nsolve()\n\n```"
        }
    ]
}