{
    "hands_on_practices": [
        {
            "introduction": "To begin our hands-on exploration of MCMC, we will start with the fundamental building block of the Metropolis-Hastings algorithm: the acceptance probability. This exercise  strips away the complexity of a full simulation to focus on the single, crucial decision of whether to accept or reject a proposed move. By calculating this probability directly for a simple target distribution, you will gain a concrete understanding of how the algorithm preferentially explores regions of higher probability.",
            "id": "1371728",
            "problem": "A data scientist is implementing a Markov Chain Monte Carlo (MCMC) simulation to draw samples from a posterior probability distribution for a parameter $x$. The target distribution, $\\pi(x)$, is proportional to the exponential of the negative absolute value of the parameter, such that $\\pi(x) \\propto \\exp(-|x|)$.\n\nThe scientist uses the Metropolis algorithm with a symmetric proposal distribution $q(x'|x)$, where the probability of proposing a new state $x'$ given the current state $x$ is equal to the probability of proposing $x$ given $x'$ (i.e., $q(x'|x) = q(x|x')$).\n\nSuppose that at a certain step in the simulation, the current state of the chain is $x = 1.5$. The algorithm then proposes a move to a new candidate state $x' = 2.0$.\n\nCalculate the acceptance probability for this specific move. Your answer should be a dimensionless real number. Round your final answer to four significant figures.",
            "solution": "The Metropolis acceptance probability for a move from $x$ to $x'$ with a symmetric proposal $q(x'|x)=q(x|x')$ is\n$$\n\\alpha(x \\to x')=\\min\\left(1,\\frac{\\pi(x')q(x|x')}{\\pi(x)q(x'|x)}\\right)=\\min\\left(1,\\frac{\\pi(x')}{\\pi(x)}\\right).\n$$\nGiven the target distribution $\\pi(x)\\propto \\exp(-|x|)$, the ratio simplifies to\n$$\n\\frac{\\pi(x')}{\\pi(x)}=\\frac{\\exp(-|x'|)}{\\exp(-|x|)}=\\exp\\!\\left(-\\left(|x'|-|x|\\right)\\right).\n$$\nWith $x=1.5$ and $x'=2.0$, we have $|x|=1.5$ and $|x'|=2.0$, so\n$$\n\\frac{\\pi(x')}{\\pi(x)}=\\exp\\!\\left(-\\left(2.0-1.5\\right)\\right)=\\exp(-0.5).\n$$\nTherefore,\n$$\n\\alpha(x \\to x')=\\min\\left(1,\\exp(-0.5)\\right)=\\exp(-0.5).\n$$\nNumerically, $\\exp(-0.5)\\approx 0.6065$ when rounded to four significant figures.",
            "answer": "$$\\boxed{0.6065}$$"
        },
        {
            "introduction": "A successful MCMC sampler must not only take valid steps but also explore the *entire* target distribution effectively, a property related to ergodicity. This thought experiment  presents a common scenario where an MCMC chain can fail: sampling from a multimodal distribution with a simple random-walk proposal. Analyzing this case is crucial for learning to diagnose poor mixing and understanding why the choice of proposal distribution is critical for complex problems in synthetic biology.",
            "id": "1316588",
            "problem": "An analyst is using a Markov chain Monte Carlo (MCMC) method to sample from a one-dimensional target probability density function (PDF), $p(x)$. The target distribution is a mixture of two well-separated Gaussian distributions:\n$$\np(x) \\propto \\exp\\left(-\\frac{(x - \\mu_1)^2}{2\\sigma^2}\\right) + \\exp\\left(-\\frac{(x - \\mu_2)^2}{2\\sigma^2}\\right)\n$$\nwhere the means $\\mu_1$ and $\\mu_2$ are far apart relative to the standard deviation $\\sigma$, such that $|\\mu_1 - \\mu_2| \\gg \\sigma$. This creates a bimodal distribution with a deep, low-probability \"valley\" between the two modes.\n\nThe analyst employs the Metropolis-Hastings algorithm with a symmetric random walk proposal. At each step $t$, a new state $x'$ is proposed from a Gaussian distribution centered at the current state $x_t$:\n$$\nq(x'|x_t) = \\frac{1}{\\sqrt{2\\pi\\epsilon^2}} \\exp\\left(-\\frac{(x' - x_t)^2}{2\\epsilon^2}\\right)\n$$\nThe step size $\\epsilon$ is chosen to be small, satisfying $\\epsilon \\ll \\sigma$, to ensure a high acceptance rate for proposals within a single mode.\n\nWhich of the following statements most accurately explains why this sampling strategy is highly inefficient and likely to fail to correctly characterize the target distribution $p(x)$?\n\nA. The sampler will become \"stuck\" in one of the modes for an extremely long time because proposed moves into the low-probability valley between the modes are almost always rejected.\n\nB. The symmetric nature of the proposal distribution, where $q(x'|x_t) = q(x_t|x')$, prevents the sampler from preferentially moving towards an under-sampled mode.\n\nC. The algorithm fails because the choice of a small step size $\\epsilon$ causes the detailed balance condition, which is necessary for convergence, to be violated.\n\nD. The overall acceptance rate for the sampler will be extremely low (near zero), causing the chain to barely move from its initial position.\n\nE. The chain will correctly explore both modes, but it will require a computationally impractical number of \"burn-in\" steps to forget its initial starting point.",
            "solution": "The Metropolis-Hastings acceptance probability for proposing $x'$ from the current state $x_{t}$ is\n$$\n\\alpha(x_{t},x')=\\min\\left(1,\\frac{p(x')\\,q(x_{t}\\mid x')}{p(x_{t})\\,q(x'\\mid x_{t})}\\right).\n$$\nWith a symmetric random-walk proposal, $q(x' \\mid x_{t})=q(x_{t}\\mid x')$, so\n$$\n\\alpha(x_{t},x')=\\min\\left(1,\\frac{p(x')}{p(x_{t})}\\right).\n$$\nThe target is a bimodal mixture\n$$\np(x)\\propto \\exp\\!\\left(-\\frac{(x-\\mu_{1})^{2}}{2\\sigma^{2}}\\right)+\\exp\\!\\left(-\\frac{(x-\\mu_{2})^{2}}{2\\sigma^{2}}\\right),\n$$\nwith $|\\mu_{1}-\\mu_{2}|\\gg \\sigma$. Near either mode, proposals with small $\\epsilon$ satisfy $|x'-x_{t}|\\sim \\epsilon\\ll \\sigma$, so $p(x')\\approx p(x_{t})$ and $\\alpha(x_{t},x')\\approx 1$, implying high acceptance and efficient local exploration within a single mode.\n\nTo move between modes, the chain must traverse the low-probability valley near $x^{*}=(\\mu_{1}+\\mu_{2})/2$. Using the unnormalized density for the acceptance ratio, evaluate the relative height of the barrier:\n$$\np(\\mu_{1})\\propto 1+\\exp\\!\\left(-\\frac{(\\mu_{1}-\\mu_{2})^{2}}{2\\sigma^{2}}\\right)\\approx 1,\n$$\n$$\np(x^{*})\\propto 2\\exp\\!\\left(-\\frac{(\\mu_{1}-\\mu_{2})^{2}}{8\\sigma^{2}}\\right).\n$$\nHence the barrier factor is\n$$\n\\frac{p(\\mu_{1})}{p(x^{*})}\\approx \\frac{1}{2}\\exp\\!\\left(\\frac{(\\mu_{1}-\\mu_{2})^{2}}{8\\sigma^{2}}\\right),\n$$\nwhich is exponentially large in $(\\mu_{1}-\\mu_{2})^{2}/\\sigma^{2}$. Therefore, any proposal that lands in or near the valley from a mode has acceptance probability\n$$\n\\alpha\\approx \\min\\left(1,\\frac{p(\\text{valley})}{p(\\text{mode})}\\right)\\ll 1.\n$$\nBecause the proposal step size satisfies $\\epsilon\\ll \\sigma\\ll |\\mu_{1}-\\mu_{2}|$, a single jump cannot reach the other mode; the chain would require an extremely long sequence of small moves against the density gradient. Metropolis dynamics in such a double-well potential exhibits exponentially large mixing times in the barrier height, so the chain becomes effectively trapped in one mode for an extremely long time, failing to correctly represent the bimodal target within practical computational budgets.\n\nAssessing the options:\n- A is correct: the chain becomes \"stuck\" in one mode because proposals into the low-probability valley have very low acceptance, and with small $\\epsilon$ it almost never crosses the barrier.\n- B is not the cause: symmetry of $q$ does not prevent mode switching; it is the small $\\epsilon$ and high barrier that matter.\n- C is false: detailed balance holds for any $\\epsilon$ in Metropolis-Hastings.\n- D is false: with small $\\epsilon$, the overall acceptance rate within a mode is high, not near zero.\n- E is misleading: the issue is not merely a long burn-in; it is poor mixing across modes, so the chain does not correctly explore both modes in feasible time.\n\nTherefore, the most accurate explanation is A.",
            "answer": "$$\\boxed{A}$$"
        },
        {
            "introduction": "Now, we will integrate these concepts into a complete, practical application relevant to synthetic biology and bioinformatics: implementing a Metropolis-Hastings sampler for Bayesian logistic regression. This coding exercise  challenges you to build a sampler from the ground up, from defining the posterior distribution to handling numerical stability and interpreting the output. This practice is key for moving from theoretical knowledge to the proficient application of MCMC for custom model inference.",
            "id": "4809452",
            "problem": "Consider independent binary outcomes for case-control data in medicine, where for each subject $i$ one observes a response $y_i \\in \\{0,1\\}$ indicating case ($y_i = 1$) or control ($y_i = 0$), along with covariates $\\mathbf{x}_i \\in \\mathbb{R}^p$. Assume a logistic regression model with canonical logit link, where the conditional probability of a case given covariates is $p(y_i = 1 \\mid \\mathbf{x}_i, \\boldsymbol{\\beta}) = \\sigma(\\eta_i)$ with $\\eta_i = \\mathbf{x}_i^\\top \\boldsymbol{\\beta}$ and $\\sigma(z) = \\frac{1}{1 + e^{-z}}$. The likelihood under independent observations is the product of Bernoulli probabilities. Assume a Bayesian model where the regression coefficients $\\boldsymbol{\\beta} \\in \\mathbb{R}^p$ have independent normal priors with mean $\\boldsymbol{\\mu}$ and diagonal variance $\\operatorname{diag}(\\boldsymbol{\\sigma}^2)$.\n\nUsing Bayes’ theorem, the posterior density is proportional to the product of the likelihood and the prior. Design a Metropolis-Hastings (MH) sampler within the framework of Markov Chain Monte Carlo (MCMC), where proposals are drawn from a multivariate normal random-walk centered at the current state with a specified symmetric covariance. Use numerically stable computations for the logistic likelihood evaluation. For each test case described below, implement the MH sampler, run it for a specified number of iterations, discard a burn-in, and thin the chain. Report the acceptance rate (as a decimal), the posterior mean of each coefficient, and the posterior predictive probability for a specified new covariate vector under the posterior.\n\nFundamental base to be used:\n- Bernoulli likelihood: for $y_i \\in \\{0,1\\}$, $P(y_i \\mid \\eta_i) = \\sigma(\\eta_i)^{y_i} \\left(1 - \\sigma(\\eta_i)\\right)^{1 - y_i}$.\n- Logistic function definition: $\\sigma(z) = \\frac{1}{1 + e^{-z}}$.\n- Bayes’ theorem: $\\pi(\\boldsymbol{\\beta} \\mid \\mathbf{y}, \\mathbf{X}) \\propto L(\\mathbf{y} \\mid \\mathbf{X}, \\boldsymbol{\\beta}) \\, \\pi(\\boldsymbol{\\beta})$.\n- Normal prior density: for independent components, $\\pi(\\boldsymbol{\\beta}) = \\prod_{j=1}^p \\mathcal{N}(\\beta_j \\mid \\mu_j, \\sigma_j^2)$.\n\nYou must solve the following three test cases. In each, construct the case-control dataset deterministically using the provided random seeds and distributional specifications. In all cases include an intercept, so $\\mathbf{x}_i = (1, x_{i1}, x_{i2})^\\top$ and $p = 3$. For case-control data, set $y_i = 1$ for cases and $y_i = 0$ for controls.\n\nTest Case A (balanced, typical):\n- Data generation seed: $314159$.\n- Number of cases: $50$; number of controls: $50$.\n- Covariate $x_{1}$ (binary “exposure”): for cases $x_{1} \\sim \\operatorname{Bernoulli}(0.6)$; for controls $x_{1} \\sim \\operatorname{Bernoulli}(0.3)$.\n- Covariate $x_{2}$ (continuous “age $z$-score”): for cases $x_{2} \\sim \\mathcal{N}(0.3, 1^2)$; for controls $x_{2} \\sim \\mathcal{N}(-0.3, 1^2)$.\n- Prior mean and variances: $\\boldsymbol{\\mu} = (0, 0, 0)$, $\\boldsymbol{\\sigma}^2 = (25, 9, 9)$.\n- Proposal covariance (random-walk MH): $\\operatorname{diag}(0.05^2, 0.05^2, 0.05^2)$.\n- MCMC proposal seed: $271828$.\n- Iterations: $12000$; burn-in: $6000$; thinning: $6$.\n- New covariate for posterior predictive: $\\mathbf{x}_{\\text{new}} = (1, 1, 0.5)$.\n\nTest Case B (near-separation, strong signals):\n- Data generation seed: $161803$.\n- Number of cases: $40$; number of controls: $40$.\n- Covariate $x_{1}$ (continuous “biomarker”): for cases $x_{1} \\sim \\mathcal{N}(2.5, 0.7^2)$; for controls $x_{1} \\sim \\mathcal{N}(-2.5, 0.7^2)$.\n- Covariate $x_{2}$ (binary “treatment”): for cases $x_{2} \\sim \\operatorname{Bernoulli}(0.9)$; for controls $x_{2} \\sim \\operatorname{Bernoulli}(0.1)$.\n- Prior mean and variances: $\\boldsymbol{\\mu} = (0, 0, 0)$, $\\boldsymbol{\\sigma}^2 = (25, 4, 4)$.\n- Proposal covariance (random-walk MH): $\\operatorname{diag}(0.02^2, 0.02^2, 0.02^2)$.\n- MCMC proposal seed: $141421$.\n- Iterations: $16000$; burn-in: $8000$; thinning: $8$.\n- New covariate for posterior predictive: $\\mathbf{x}_{\\text{new}} = (1, 0, 1.0)$.\n\nTest Case C (small-sample boundary):\n- Data generation seed: $123457$.\n- Number of cases: $8$; number of controls: $12$.\n- Covariate $x_{1}$ (binary “exposure”): for cases $x_{1} \\sim \\operatorname{Bernoulli}(0.5)$; for controls $x_{1} \\sim \\operatorname{Bernoulli}(0.4)$.\n- Covariate $x_{2}$ (continuous “marker”): for cases $x_{2} \\sim \\mathcal{N}(0.1, 1^2)$; for controls $x_{2} \\sim \\mathcal{N}(-0.1, 1^2)$.\n- Prior mean and variances: $\\boldsymbol{\\mu} = (0, 0, 0)$, $\\boldsymbol{\\sigma}^2 = (100, 16, 16)$.\n- Proposal covariance (random-walk MH): $\\operatorname{diag}(0.08^2, 0.08^2, 0.08^2)$.\n- MCMC proposal seed: $57721$.\n- Iterations: $10000$; burn-in: $5000$; thinning: $5$.\n- New covariate for posterior predictive: $\\mathbf{x}_{\\text{new}} = (1, 1, -0.2)$.\n\nAlgorithmic requirements:\n- Use a numerically stable expression for the log-likelihood. In particular, if $\\eta_i = \\mathbf{x}_i^\\top \\boldsymbol{\\beta}$, compute $\\log L(\\mathbf{y} \\mid \\mathbf{X}, \\boldsymbol{\\beta}) = \\sum_{i=1}^n \\left( y_i \\eta_i - \\operatorname{softplus}(\\eta_i) \\right)$, where $\\operatorname{softplus}(z) = \\log(1 + e^{z})$ computed stably.\n- Use independent normal priors for each component: $\\log \\pi(\\boldsymbol{\\beta}) = \\sum_{j=1}^p \\left( -\\frac{1}{2} \\log(2\\pi \\sigma_j^2) - \\frac{(\\beta_j - \\mu_j)^2}{2\\sigma_j^2} \\right)$.\n- Employ a symmetric multivariate normal random-walk proposal: $\\boldsymbol{\\beta}^{\\ast} = \\boldsymbol{\\beta}^{(t)} + \\mathbf{z}$ with $\\mathbf{z} \\sim \\mathcal{N}(\\mathbf{0}, \\mathbf{Q})$. The acceptance probability is $\\alpha = \\min\\left\\{1, \\exp\\left[ \\log \\pi(\\boldsymbol{\\beta}^{\\ast} \\mid \\mathbf{y}, \\mathbf{X}) - \\log \\pi(\\boldsymbol{\\beta}^{(t)} \\mid \\mathbf{y}, \\mathbf{X}) \\right] \\right\\}$, since the proposal is symmetric.\n- After sampling, compute the acceptance rate as the proportion of accepted proposals over total iterations, the posterior mean of each coefficient over the saved samples, and the posterior predictive probability $E\\left[ \\sigma(\\mathbf{x}_{\\text{new}}^\\top \\boldsymbol{\\beta}) \\mid \\mathbf{y}, \\mathbf{X} \\right]$ estimated by the sample average.\n\nFinal output format:\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets. The list must consist of, in order for Test Case A, then Test Case B, then Test Case C: acceptance rate, posterior mean of $\\beta_0$ (intercept), posterior mean of $\\beta_1$, posterior mean of $\\beta_2$, and posterior predictive probability for $\\mathbf{x}_{\\text{new}}$; then repeat the same five quantities for the next test case, and so on. For example, output of the form $[r_{A}, m_{A0}, m_{A1}, m_{A2}, p_{A}, r_{B}, m_{B0}, m_{B1}, m_{B2}, p_{B}, r_{C}, m_{C0}, m_{C1}, m_{C2}, p_{C}]$, where each symbol denotes a real number.",
            "solution": "We formulate Bayesian logistic regression for case-control data, specifying the likelihood and prior from fundamental principles, and derive the Metropolis-Hastings (MH) sampling scheme within the Markov Chain Monte Carlo (MCMC) framework.\n\nFirst, define the logistic function $\\sigma(z) = \\frac{1}{1 + e^{-z}}$ and the linear predictor $\\eta_i = \\mathbf{x}_i^\\top \\boldsymbol{\\beta}$ for each subject $i$ with covariates $\\mathbf{x}_i$ and coefficients $\\boldsymbol{\\beta}$. The Bernoulli likelihood for a single observation is $P(y_i \\mid \\eta_i) = \\sigma(\\eta_i)^{y_i} \\left(1 - \\sigma(\\eta_i)\\right)^{1 - y_i}$. With independent observations, the joint likelihood is the product over $i$. In the case-control design, $y_i$ indicates case status, but the conditional model $P(y_i \\mid \\mathbf{x}_i, \\boldsymbol{\\beta})$ retains the Bernoulli-logit form; the intercept absorbs any sampling fraction effects, and regression coefficients on covariates remain interpretable as log-odds ratios, which are central in medical evidence synthesis.\n\nFor numerical stability, avoid direct computation of $\\log \\left(1 - \\sigma(\\eta_i)\\right)$, and instead use the identity\n$$\n\\log L(\\mathbf{y} \\mid \\mathbf{X}, \\boldsymbol{\\beta}) = \\sum_{i=1}^n \\left( y_i \\eta_i - \\log\\left(1 + e^{\\eta_i}\\right) \\right) = \\sum_{i=1}^n \\left( y_i \\eta_i - \\operatorname{softplus}(\\eta_i) \\right),\n$$\nwhere the function $\\operatorname{softplus}(z) = \\log(1 + e^{z})$ should be computed with a numerically stable branching:\n$$\n\\operatorname{softplus}(z) = \n\\begin{cases}\nz + \\log(1 + e^{-z}),  z  0, \\\\\n\\log(1 + e^{z}),  z \\le 0.\n\\end{cases}\n$$\nThis avoids overflow or underflow in $e^{z}$ for large $|z|$.\n\nSpecify independent normal priors for each coefficient,\n$$\n\\pi(\\boldsymbol{\\beta}) = \\prod_{j=1}^p \\mathcal{N}(\\beta_j \\mid \\mu_j, \\sigma_j^2),\n$$\nwith log-prior\n$$\n\\log \\pi(\\boldsymbol{\\beta}) = \\sum_{j=1}^p \\left( -\\frac{1}{2} \\log(2\\pi \\sigma_j^2) - \\frac{(\\beta_j - \\mu_j)^2}{2\\sigma_j^2} \\right).\n$$\nBy Bayes’ theorem, the posterior satisfies\n$$\n\\pi(\\boldsymbol{\\beta} \\mid \\mathbf{y}, \\mathbf{X}) \\propto L(\\mathbf{y} \\mid \\mathbf{X}, \\boldsymbol{\\beta}) \\, \\pi(\\boldsymbol{\\beta}),\n$$\nthus the log-posterior is\n$$\n\\log \\pi(\\boldsymbol{\\beta} \\mid \\mathbf{y}, \\mathbf{X}) = \\sum_{i=1}^n \\left( y_i \\mathbf{x}_i^\\top \\boldsymbol{\\beta} - \\operatorname{softplus}(\\mathbf{x}_i^\\top \\boldsymbol{\\beta}) \\right) + \\sum_{j=1}^p \\left( -\\frac{1}{2} \\log(2\\pi \\sigma_j^2) - \\frac{(\\beta_j - \\mu_j)^2}{2\\sigma_j^2} \\right) + C,\n$$\nwhere $C$ is an additive constant irrelevant to ratios.\n\nTo sample from $\\pi(\\boldsymbol{\\beta} \\mid \\mathbf{y}, \\mathbf{X})$, implement the Metropolis-Hastings algorithm with a symmetric multivariate normal random-walk proposal:\n- At iteration $t$, propose $\\boldsymbol{\\beta}^{\\ast} = \\boldsymbol{\\beta}^{(t)} + \\mathbf{z}$, with $\\mathbf{z} \\sim \\mathcal{N}(\\mathbf{0}, \\mathbf{Q})$, where $\\mathbf{Q}$ is the specified proposal covariance matrix, typically diagonal for simplicity.\n- Compute the acceptance probability\n$$\n\\alpha = \\min\\left\\{1, \\exp\\left( \\log \\pi(\\boldsymbol{\\beta}^{\\ast} \\mid \\mathbf{y}, \\mathbf{X}) - \\log \\pi(\\boldsymbol{\\beta}^{(t)} \\mid \\mathbf{y}, \\mathbf{X}) \\right) \\right\\}.\n$$\nThe Hastings correction terms cancel due to proposal symmetry. Accept the proposal with probability $\\alpha$; otherwise, retain $\\boldsymbol{\\beta}^{(t)}$.\n\nInitialize at $\\boldsymbol{\\beta}^{(0)} = \\mathbf{0}$. Run for the specified number of iterations. Discard the burn-in iterations to mitigate the influence of the initial state, then thin the chain by keeping every $k$-th sample to reduce autocorrelation; although thinning is not strictly necessary in theory, it aids computational summary and ensures a manageable number of saved samples. Compute the acceptance rate as the proportion of accepted proposals over total iterations.\n\nFor posterior summaries:\n- The posterior mean of each coefficient is estimated by the sample mean over the saved draws, $\\hat{E}[\\beta_j \\mid \\mathbf{y}, \\mathbf{X}] = \\frac{1}{M} \\sum_{m=1}^M \\beta_{j}^{(m)}$.\n- The posterior predictive probability at a new covariate vector $\\mathbf{x}_{\\text{new}}$ is estimated by\n$$\n\\hat{E}\\left[ \\sigma(\\mathbf{x}_{\\text{new}}^\\top \\boldsymbol{\\beta}) \\mid \\mathbf{y}, \\mathbf{X} \\right] = \\frac{1}{M} \\sum_{m=1}^M \\sigma\\left(\\mathbf{x}_{\\text{new}}^\\top \\boldsymbol{\\beta}^{(m)}\\right),\n$$\nwhere $\\boldsymbol{\\beta}^{(m)}$ are the saved draws after burn-in and thinning.\n\nFor each test case, construct the data deterministically using the provided seeds and distributions. Specifically, with $n_{\\text{cases}}$ and $n_{\\text{controls}}$ and given covariate distributions, sample covariates independently for cases and controls using the data generation seed, set $y_i = 1$ for cases and $y_i = 0$ for controls, and stack all subjects to form $\\mathbf{X}$ with an intercept column. Use the specified prior parameters $(\\boldsymbol{\\mu}, \\boldsymbol{\\sigma}^2)$, proposal covariance $\\mathbf{Q}$, MCMC proposal seed, total iterations, burn-in, and thinning. Compute, in order, the acceptance rate, posterior mean of $\\beta_0$, posterior mean of $\\beta_1$, posterior mean of $\\beta_2$, and posterior predictive probability at the specified $\\mathbf{x}_{\\text{new}}$.\n\nFinally, aggregate the results from Test Case A, then Test Case B, then Test Case C, into a single comma-separated list enclosed in square brackets, as required. This design tests typical behavior, handling of near-separation under regularization via the prior, and small-sample robustness, reflecting realistic scenarios in medical evidence where logistic regression for case-control data is prevalent, and Bayesian regularization stabilizes inference in challenging settings.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef softplus(x):\n    # Numerically stable softplus\n    # softplus(x) = log(1 + exp(x))\n    return np.where(x > 0, x + np.log1p(np.exp(-x)), np.log1p(np.exp(x)))\n\ndef sigmoid(x):\n    # Numerically stable logistic function\n    # If x >= 0: 1/(1+exp(-x)) ; else: exp(x)/(1+exp(x))\n    return np.where(x >= 0, 1.0 / (1.0 + np.exp(-x)), np.exp(x) / (1.0 + np.exp(x)))\n\ndef log_posterior(beta, X, y, mu, sigma2):\n    # beta: (p,)\n    # X: (n, p), y: (n,)\n    eta = X @ beta\n    ll = np.sum(y * eta - softplus(eta))  # stable log-likelihood\n    # Independent normal priors\n    lp = -0.5 * np.sum(np.log(2.0 * np.pi * sigma2)) - 0.5 * np.sum(((beta - mu) ** 2) / sigma2)\n    return ll + lp\n\ndef metropolis_hastings(initial_beta, X, y, mu, sigma2, proposal_cov, n_iter, rng):\n    p = initial_beta.shape[0]\n    beta = initial_beta.copy()\n    samples = np.zeros((n_iter, p))\n    accept_count = 0\n    current_logpost = log_posterior(beta, X, y, mu, sigma2)\n    # Cholesky of proposal covariance for efficient sampling\n    chol = np.linalg.cholesky(proposal_cov)\n    for t in range(n_iter):\n        z = rng.normal(size=p)\n        proposal = beta + chol @ z\n        proposal_logpost = log_posterior(proposal, X, y, mu, sigma2)\n        log_alpha = proposal_logpost - current_logpost\n        if np.log(rng.uniform())  log_alpha:\n            beta = proposal\n            current_logpost = proposal_logpost\n            accept_count += 1\n        samples[t, :] = beta\n    return samples, accept_count\n\ndef generate_case_control(seed, n_cases, n_controls, dist_cases, dist_controls):\n    \"\"\"\n    dist_cases/controls: dict with keys 'x1', 'x2' specifying distributions:\n      For Bernoulli: ('bern', p)\n      For Normal: ('norm', mu, sigma)\n    Returns X (n,3) with intercept, y (n,)\n    \"\"\"\n    rng = np.random.default_rng(seed)\n    # Cases\n    if dist_cases['x1'][0] == 'bern':\n        x1_cases = rng.binomial(1, dist_cases['x1'][1], size=n_cases).astype(float)\n    else:\n        x1_cases = rng.normal(dist_cases['x1'][1], dist_cases['x1'][2], size=n_cases)\n    if dist_cases['x2'][0] == 'bern':\n        x2_cases = rng.binomial(1, dist_cases['x2'][1], size=n_cases).astype(float)\n    else:\n        x2_cases = rng.normal(dist_cases['x2'][1], dist_cases['x2'][2], size=n_cases)\n    y_cases = np.ones(n_cases, dtype=float)\n    # Controls\n    if dist_controls['x1'][0] == 'bern':\n        x1_controls = rng.binomial(1, dist_controls['x1'][1], size=n_controls).astype(float)\n    else:\n        x1_controls = rng.normal(dist_controls['x1'][1], dist_controls['x1'][2], size=n_controls)\n    if dist_controls['x2'][0] == 'bern':\n        x2_controls = rng.binomial(1, dist_controls['x2'][1], size=n_controls).astype(float)\n    else:\n        x2_controls = rng.normal(dist_controls['x2'][1], dist_controls['x2'][2], size=n_controls)\n    y_controls = np.zeros(n_controls, dtype=float)\n    # Stack\n    x1 = np.concatenate([x1_cases, x1_controls])\n    x2 = np.concatenate([x2_cases, x2_controls])\n    y = np.concatenate([y_cases, y_controls])\n    intercept = np.ones_like(y)\n    X = np.column_stack([intercept, x1, x2])\n    return X, y\n\ndef posterior_predictive_prob(samples, x_new):\n    # samples: (m, p)\n    # x_new: (p,)\n    eta = samples @ x_new\n    probs = sigmoid(eta)\n    return float(np.mean(probs))\n\ndef summarize_chain(samples, burn_in, thin):\n    # Return thinned samples after burn-in\n    post = samples[burn_in:]\n    if thin > 1:\n        post = post[::thin]\n    return post\n\ndef run_test_case(X, y, mu, sigma2, prop_cov, n_iter, burn_in, thin, mcmc_seed, x_new):\n    rng = np.random.default_rng(mcmc_seed)\n    initial_beta = np.zeros(X.shape[1], dtype=float)\n    samples, accept_count = metropolis_hastings(initial_beta, X, y, mu, sigma2, prop_cov, n_iter, rng)\n    post = summarize_chain(samples, burn_in, thin)\n    accept_rate = accept_count / n_iter\n    beta_mean = np.mean(post, axis=0)\n    p_pred = posterior_predictive_prob(post, x_new)\n    return accept_rate, beta_mean, p_pred\n\ndef solve():\n    # Define the test cases from the problem statement.\n    # Test Case A\n    X_A, y_A = generate_case_control(\n        seed=314159,\n        n_cases=50, n_controls=50,\n        dist_cases={'x1': ('bern', 0.6), 'x2': ('norm', 0.3, 1.0)},\n        dist_controls={'x1': ('bern', 0.3), 'x2': ('norm', -0.3, 1.0)}\n    )\n    mu_A = np.array([0.0, 0.0, 0.0])\n    sigma2_A = np.array([25.0, 9.0, 9.0])\n    prop_cov_A = np.diag([0.05**2, 0.05**2, 0.05**2])\n    n_iter_A, burn_A, thin_A = 12000, 6000, 6\n    mcmc_seed_A = 271828\n    x_new_A = np.array([1.0, 1.0, 0.5])\n\n    # Test Case B\n    X_B, y_B = generate_case_control(\n        seed=161803,\n        n_cases=40, n_controls=40,\n        dist_cases={'x1': ('norm', 2.5, 0.7), 'x2': ('bern', 0.9)},\n        dist_controls={'x1': ('norm', -2.5, 0.7), 'x2': ('bern', 0.1)}\n    )\n    mu_B = np.array([0.0, 0.0, 0.0])\n    sigma2_B = np.array([25.0, 4.0, 4.0])\n    prop_cov_B = np.diag([0.02**2, 0.02**2, 0.02**2])\n    n_iter_B, burn_B, thin_B = 16000, 8000, 8\n    mcmc_seed_B = 141421\n    x_new_B = np.array([1.0, 0.0, 1.0])\n\n    # Test Case C\n    X_C, y_C = generate_case_control(\n        seed=123457,\n        n_cases=8, n_controls=12,\n        dist_cases={'x1': ('bern', 0.5), 'x2': ('norm', 0.1, 1.0)},\n        dist_controls={'x1': ('bern', 0.4), 'x2': ('norm', -0.1, 1.0)}\n    )\n    mu_C = np.array([0.0, 0.0, 0.0])\n    sigma2_C = np.array([100.0, 16.0, 16.0])\n    prop_cov_C = np.diag([0.08**2, 0.08**2, 0.08**2])\n    n_iter_C, burn_C, thin_C = 10000, 5000, 5\n    mcmc_seed_C = 57721\n    x_new_C = np.array([1.0, 1.0, -0.2])\n\n    results = []\n\n    # Run A\n    acc_A, beta_mean_A, p_pred_A = run_test_case(\n        X_A, y_A, mu_A, sigma2_A, prop_cov_A, n_iter_A, burn_A, thin_A, mcmc_seed_A, x_new_A\n    )\n    results.extend([acc_A, beta_mean_A[0], beta_mean_A[1], beta_mean_A[2], p_pred_A])\n\n    # Run B\n    acc_B, beta_mean_B, p_pred_B = run_test_case(\n        X_B, y_B, mu_B, sigma2_B, prop_cov_B, n_iter_B, burn_B, thin_B, mcmc_seed_B, x_new_B\n    )\n    results.extend([acc_B, beta_mean_B[0], beta_mean_B[1], beta_mean_B[2], p_pred_B])\n\n    # Run C\n    acc_C, beta_mean_C, p_pred_C = run_test_case(\n        X_C, y_C, mu_C, sigma2_C, prop_cov_C, n_iter_C, burn_C, thin_C, mcmc_seed_C, x_new_C\n    )\n    results.extend([acc_C, beta_mean_C[0], beta_mean_C[1], beta_mean_C[2], p_pred_C])\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        }
    ]
}