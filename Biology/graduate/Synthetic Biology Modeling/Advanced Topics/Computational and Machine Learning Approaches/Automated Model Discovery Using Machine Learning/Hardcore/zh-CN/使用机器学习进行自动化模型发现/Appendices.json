{
    "hands_on_practices": [
        {
            "introduction": "自动化模型发现过程通常会产生大量候选模型，如何从中选出最佳模型是一个核心挑战。贝叶斯模型证据（Bayesian model evidence）为此提供了一个基本原则，它能够在评估模型对数据的拟合优度与模型复杂度之间进行权衡，这正是奥卡姆剃刀原理的体现。这项练习  将指导你通过拉普拉斯近似（Laplace approximation）推导模型证据的计算方法，并通过计算“奥卡姆因子”（Occam factor），你将定量地理解贝叶斯推断如何惩罚过于复杂的模型，这是建立稳健科学模型的基石。",
            "id": "3906825",
            "problem": "在一个用于合成生物学的自动化模型发现流程中，贝叶斯模型证据被用来对基于质量作用动力学的生物化学反应网络的候选动力学模型进行排序。考虑一个单个基因产物浓度 $x(t)$ 的候选模型，该模型由常微分方程 $dx/dt = k_1 - k_2 x$ 描述，其中参数向量为 $k = [k_1, k_2]^{\\top}$，$k_1$ 是生成速率，$k_2$ 是降解速率。设 $y = \\{y_i\\}_{i=1}^{N}$ 是在时间点 $\\{t_i\\}_{i=1}^{N}$ 对 $x(t)$ 的带噪声的观测值，其观测噪声为独立的、方差为 $\\sigma^2$ 的高斯噪声。该自动化模型发现任务在高斯先验 $p(k \\mid \\mathcal{M}) = \\mathcal{N}(\\mu_0, \\Sigma_0)$ 下评估参数的边际似然（模型证据） $p(y \\mid \\mathcal{M})$。\n\n使用贝叶斯定理和在最大后验估计 $k^{\\ast}$ 附近的对数后验密度的二阶泰勒展开，推导模型证据 $p(y \\mid \\mathcal{M})$ 的拉普拉斯近似，并用对数似然、对数先验以及在 $k^{\\ast}$ 处的负对数后验的海森矩阵来表示。从此推导中，分离出作为从先验到后验的参数空间体积收缩而惩罚模型复杂度的奥卡姆因子。将此奥卡姆因子完全用从局部高斯近似中获得的先验协方差 $\\Sigma_0$ 和后验协方差 $\\Sigma_{\\text{post}}$ 来表示。\n\n然后，对于一个使用 $d = 2$ 个参数的流程的具体实例，假设先验协方差和在 $k^{\\ast}$ 处的负对数似然海森矩阵（从设计和噪声模型中计算得出）由下式给出：\n$$\n\\Sigma_0 = \\begin{pmatrix} 0.25  0 \\\\ 0  0.04 \\end{pmatrix}, \n\\qquad\nH_{\\text{LL}} = \\begin{pmatrix} 400  -120 \\\\ -120  50 \\end{pmatrix}.\n$$\n假设后验负对数曲率满足 $H_{\\text{post}} = H_{\\text{LL}} + \\Sigma_0^{-1}$，且局部高斯近似的协方差为 $\\Sigma_{\\text{post}} = H_{\\text{post}}^{-1}$，根据你推导出的定义计算奥卡姆因子。将你的最终答案表示为一个无量纲的实数，并四舍五入到四位有效数字。",
            "solution": "该问题要求完成两个主要任务：首先，推导贝叶斯模型证据的拉普拉斯近似，并分离出代表参数空间体积收缩的奥卡姆因子；其次，为一个具体的数值实例计算该奥卡姆因子的值。\n\n### 第 1 部分：拉普拉斯近似和奥卡姆因子的推导\n\n贝叶斯模型证据，或称边际似然 $p(y \\mid \\mathcal{M})$，是通过在整个参数空间上对数据 $y$ 和参数 $k$ 的联合概率进行边缘化来定义的：\n$$p(y \\mid \\mathcal{M}) = \\int p(y, k \\mid \\mathcal{M}) dk = \\int p(y \\mid k, \\mathcal{M}) p(k \\mid \\mathcal{M}) dk$$\n其中 $k \\in \\mathbb{R}^d$ 是维度为 $d$ 的参数向量。\n\n为了评估该积分，我们采用拉普拉斯近似。我们首先定义一个“能量”函数 $E(k)$ 作为被积函数的负对数：\n$$E(k) = -\\ln[p(y \\mid k, \\mathcal{M}) p(k \\mid \\mathcal{M})] = -\\ln p(y \\mid k, \\mathcal{M}) - \\ln p(k \\mid \\mathcal{M})$$\n注意，$E(k)$ 在相差一个加性常数的情况下是负对数后验概率。证据积分可以重写为：\n$$p(y \\mid \\mathcal{M}) = \\int \\exp(-E(k)) dk$$\n拉普拉斯近似基于 $E(k)$ 在其最小值附近的二阶泰勒展开。$E(k)$ 的最小值对应于后验概率的最大值，即最大后验 (MAP) 估计，记为 $k^{\\ast}$。在这一点上，$E(k)$ 的梯度为零：$\\nabla_k E(k) |_{k=k^{\\ast}} = 0$。\n\n$E(k)$ 在 $k^{\\ast}$ 附近的泰勒展开为：\n$$E(k) \\approx E(k^{\\ast}) + (k - k^{\\ast})^{\\top} (\\nabla_k E(k) |_{k=k^{\\ast}}) + \\frac{1}{2} (k - k^{\\ast})^{\\top} (H_{\\text{post}}) (k - k^{\\ast})$$\n其中 $H_{\\text{post}}$ 是 $E(k)$ 在 $k^{\\ast}$ 处求值的海森矩阵：\n$$H_{\\text{post}} = \\nabla_k^2 E(k) |_{k=k^{\\ast}}$$\n如问题所述，该海森矩阵是负对数后验在其最大值处的曲率。由于在 $k^{\\ast}$ 处的梯度为零，展开式简化为：\n$$E(k) \\approx E(k^{\\ast}) + \\frac{1}{2} (k - k^{\\ast})^{\\top} H_{\\text{post}} (k - k^{\\ast})$$\n将此近似代回证据积分中：\n$$p(y \\mid \\mathcal{M}) \\approx \\int \\exp\\left(-E(k^{\\ast}) - \\frac{1}{2} (k - k^{\\ast})^{\\top} H_{\\text{post}} (k - k^{\\ast})\\right) dk$$\n$$p(y \\mid \\mathcal{M}) \\approx \\exp(-E(k^{\\ast})) \\int \\exp\\left(-\\frac{1}{2} (k - k^{\\ast})^{\\top} H_{\\text{post}} (k - k^{\\ast})\\right) dk$$\n该积分为标准的多维高斯积分。被积函数与均值为 $k^{\\ast}$、协方差矩阵为 $\\Sigma_{\\text{post}} = H_{\\text{post}}^{-1}$ 的高斯概率密度函数成正比。该积分的值由下式给出：\n$$\\int \\exp\\left(-\\frac{1}{2} (k - k^{\\ast})^{\\top} H_{\\text{post}} (k - k^{\\ast})\\right) dk = (2\\pi)^{d/2} |\\det(H_{\\text{post}})|^{-1/2}$$\n代入此结果，我们得到模型证据的拉普拉斯近似：\n$$p(y \\mid \\mathcal{M}) \\approx \\exp(-E(k^{\\ast})) (2\\pi)^{d/2} |\\det(H_{\\text{post}})|^{-1/2}$$\n现在，我们展开 $\\exp(-E(k^{\\ast}))$ 项：\n$$\\exp(-E(k^{\\ast})) = \\exp(-\\ln p(y \\mid k^{\\ast}, \\mathcal{M}) - \\ln p(k^{\\ast} \\mid \\mathcal{M})) = p(y \\mid k^{\\ast}, \\mathcal{M}) p(k^{\\ast} \\mid \\mathcal{M})$$\n因此，证据为：\n$$p(y \\mid \\mathcal{M}) \\approx p(y \\mid k^{\\ast}, \\mathcal{M}) p(k^{\\ast} \\mid \\mathcal{M}) (2\\pi)^{d/2} |\\det(H_{\\text{post}})|^{-1/2}$$\n项 $p(y \\mid k^{\\ast}, \\mathcal{M})$ 是最佳拟合似然，它衡量模型解释数据的好坏程度。剩余的项构成了惩罚模型复杂度的奥卡姆因子。\n问题要求分离出代表“从先验到后验的参数空间体积收缩”的奥卡姆因子。这被解释为后验概率分布和先验概率分布的特征体积之比。对于高斯分布，此体积与协方差矩阵行列式的平方根成正比。\n\n后验分布被局部近似为高斯分布 $\\mathcal{N}(k^{\\ast}, \\Sigma_{\\text{post}})$，其中 $\\Sigma_{\\text{post}} = H_{\\text{post}}^{-1}$。其特征体积与 $|\\det(\\Sigma_{\\text{post}})|^{1/2}$ 成正比。先验分布给定为高斯分布 $\\mathcal{N}(\\mu_0, \\Sigma_0)$，因此其特征体积与 $|\\det(\\Sigma_0)|^{1/2}$ 成正比。\n\n代表体积收缩的奥卡姆因子，我们称之为 $O_{\\text{vol}}$，是这些体积的比率：\n$$O_{\\text{vol}} = \\frac{\\text{后验体积}}{\\text{先验体积}} \\propto \\frac{|\\det(\\Sigma_{\\text{post}})|^{1/2}}{|\\det(\\Sigma_0)|^{1/2}} = \\sqrt{\\frac{\\det(\\Sigma_{\\text{post}})}{\\det(\\Sigma_0)}}$$\n如题目所要求，该表达式完全用先验协方差 $\\Sigma_0$ 和后验协方差 $\\Sigma_{\\text{post}}$ 来表示奥卡姆因子。\n\n### 第 2 部分：数值计算\n\n对于一个 $d=2$ 参数问题，我们给定以下值：\n- 先验协方差：$\\Sigma_0 = \\begin{pmatrix} 0.25  0 \\\\ 0  0.04 \\end{pmatrix}$\n- 在 $k^{\\ast}$ 处的负对数似然海森矩阵：$H_{\\text{LL}} = \\begin{pmatrix} 400  -120 \\\\ -120  50 \\end{pmatrix}$\n- 后验曲率：$H_{\\text{post}} = H_{\\text{LL}} + \\Sigma_0^{-1}$\n- 后验协方差：$\\Sigma_{\\text{post}} = H_{\\text{post}}^{-1}$\n\n我们需要计算 $O_{\\text{vol}} = \\sqrt{\\frac{\\det(\\Sigma_{\\text{post}})}{\\det(\\Sigma_0)}}$。\n使用性质 $\\det(A^{-1}) = (\\det(A))^{-1}$，我们可以写出 $\\det(\\Sigma_{\\text{post}}) = (\\det(H_{\\text{post}}))^{-1}$。奥卡姆因子变为：\n$$O_{\\text{vol}} = \\sqrt{\\frac{1}{\\det(H_{\\text{post}}) \\det(\\Sigma_0)}} = \\frac{1}{\\sqrt{\\det(H_{\\text{post}}) \\det(\\Sigma_0)}}$$\n这种形式在计算上更直接。\n\n首先，我们计算先验协方差矩阵 $\\Sigma_0$ 的行列式：\n$$\\det(\\Sigma_0) = (0.25) \\times (0.04) = 0.01$$\n\n接下来，我们求先验协方差矩阵 $\\Sigma_0$ 的逆矩阵 $\\Sigma_0^{-1}$。由于 $\\Sigma_0$ 是对角矩阵，其逆矩阵是对角元素倒数构成的矩阵：\n$$\\Sigma_0^{-1} = \\begin{pmatrix} 1/0.25  0 \\\\ 0  1/0.04 \\end{pmatrix} = \\begin{pmatrix} 4  0 \\\\ 0  25 \\end{pmatrix}$$\n\n现在，我们计算后验曲率矩阵 $H_{\\text{post}}$：\n$$H_{\\text{post}} = H_{\\text{LL}} + \\Sigma_0^{-1} = \\begin{pmatrix} 400  -120 \\\\ -120  50 \\end{pmatrix} + \\begin{pmatrix} 4  0 \\\\ 0  25 \\end{pmatrix} = \\begin{pmatrix} 404  -120 \\\\ -120  75 \\end{pmatrix}$$\n\n然后我们计算 $H_{\\text{post}}$ 的行列式：\n$$\\det(H_{\\text{post}}) = (404 \\times 75) - (-120 \\times -120) = 30300 - 14400 = 15900$$\n\n最后，我们将这些行列式代入奥卡姆因子的表达式中：\n$$O_{\\text{vol}} = \\frac{1}{\\sqrt{\\det(H_{\\text{post}}) \\det(\\Sigma_0)}} = \\frac{1}{\\sqrt{15900 \\times 0.01}} = \\frac{1}{\\sqrt{159}}$$\n现在我们计算数值：\n$$O_{\\text{vol}} = \\frac{1}{\\sqrt{159}} \\approx \\frac{1}{12.60952021} \\approx 0.07930501...$$\n将结果四舍五入到四位有效数字，得到 $0.07931$。",
            "answer": "$$\\boxed{0.07931}$$"
        },
        {
            "introduction": "即使一个模型能够很好地拟合数据，但如果其参数没有被数据充分约束，那么这个模型也可能是不可靠的，这就是所谓的“可辨识性”（identifiability）问题。剖面似然（profile likelihood）是一种强大的统计工具，它通过检验似然函数在某个参数维度上的形状来诊断该参数的可辨识性。在这项练习  中，你将为一个基因调控模型计算剖面似然，并观察在一个糟糕的实验设计下剖面曲线如何变得平坦，从而学会将数据质量与参数不确定性直接联系起来，并领会到设计能覆盖关键动态范围的实验是何等重要。",
            "id": "3906800",
            "problem": "给定一个基因调控情景，该情景由一个基于热力学结合平衡的希尔（Hill）激活函数建模。令 $I$ 表示诱导剂浓度（单位为 $\\mu$M），$y$ 表示测得的表达水平（单位为无量纲的相对荧光单位），$n$ 表示希尔系数。表达的经典希尔激活模型为\n$$\ny(I;\\beta_0,\\beta,K,n) \\;=\\; \\beta_0 \\;+\\; \\beta \\,\\frac{I^n}{K^n + I^n},\n$$\n其中 $\\beta_0 \\ge 0$ 是基础表达水平，$\\beta \\ge 0$ 是最大可诱导振幅，$K > 0$ 是半激活浓度。假设存在加性高斯（Gaussian）测量噪声，这与正态模型下的最大似然估计（MLE）一致，即对于在浓度 $I$ 下的每次测量 $y_{\\text{obs}}$，\n$$\ny_{\\text{obs}} \\;=\\; y(I;\\beta_0,\\beta,K,n) \\;+\\; \\varepsilon,\\quad \\varepsilon \\sim \\mathcal{N}(0,\\sigma^2),\n$$\n其中噪声标准差 $\\sigma$ 已知。对于数据集 $\\{(I_i,y_{\\text{obs},i})\\}_{i=1}^{N}$，在独立高斯误差的假设下，忽略加性常数后，对数似然函数与负的残差平方和（RSS）成正比，\n$$\n\\ell(\\beta_0,\\beta,K,n) \\;=\\; -\\frac{1}{2\\sigma^2}\\sum_{i=1}^{N}\\left[y_{\\text{obs},i} - y(I_i;\\beta_0,\\beta,K,n)\\right]^2.\n$$\n希尔系数 $n$ 的剖面对数似然函数定义为\n$$\n\\ell_{\\text{prof}}(n) \\;=\\; \\max_{\\beta_0 \\ge 0,\\, \\beta \\ge 0,\\, K > 0}\\; \\ell(\\beta_0,\\beta,K,n),\n$$\n该方法通过对每个固定的 $n$ 值在讨厌参数（nuisance parameters）上进行最大化来消除它们。在使用机器学习（ML）进行自动化模型发现时，这种剖面分析可以指导可识别性分析并为实验设计选择提供信息：在一个很宽的 $n$ 值范围内，平坦的 $\\ell_{\\text{prof}}(n)$ 曲线表明在当前数据和设计下，$n$ 是不可识别的。\n\n您的任务是实现一个完整的程序，对于每个给定的测试用例，该程序在一系列 $n$ 值的网格上计算归一化的剖面对数似然函数 $\\ell_{\\text{prof}}(n)$，并判断该剖面是否表现出指示不可识别性的平坦区域。请使用以下基于原则的规则：\n\n1. 对于指定网格上的每个固定 $n$ 值，通过最小化残差平方和来对 $(\\beta_0,\\beta,K)$ 进行最大似然估计，同时遵守约束条件 $\\beta_0 \\ge 0$、$\\beta \\ge 0$ 和 $K > 0$。将此最小化过程解释为在已知 $\\sigma$ 的高斯噪声下的最大似然估计。\n\n2. 计算剖面 $\\ell_{\\text{prof}}(n)$ 并通过减去其最大值进行归一化，使其峰值为 $0$：\n$$\n\\tilde{\\ell}_{\\text{prof}}(n) \\;=\\; \\ell_{\\text{prof}}(n) - \\max_{n}\\ell_{\\text{prof}}(n).\n$$\n\n3. 通过两个互补的度量来量化平坦度：\n   - 峰值周围的二次曲率宽度：在最大化值 $\\hat{n}$ 的一个小邻域内，对 $\\tilde{\\ell}_{\\text{prof}}(n)$ 拟合一个二次模型以获得曲率 $a$（即 $(n-\\hat{n})^2$ 项的系数）。使用单参数似然比近似，定义 $95\\%$ 置信区间的下降水平 $d = 1.92$，并估计在该下降水平上的全宽度为\n   $$\n   w \\;=\\; 2\\sqrt{\\frac{d}{|a|}}\\quad\\text{if }a  0,\\;\\text{and }w=+\\infty\\text{ if }a \\ge 0.\n   $$\n   - 全局下降幅度：计算 $\\Delta \\;=\\; \\left|\\min_{n}\\tilde{\\ell}_{\\text{prof}}(n)\\right|$。\n\n4. 如果 $w > 1.5$ 或 $\\Delta  0.8$，则将希尔系数 $n$ 分类为不可识别。否则，将其分类为可识别。为每个测试用例返回一个布尔值：$True$ 表示不可识别，$False$ 表示可识别。\n\n程序必须使用从 $0.5$ 到 $5.0$、步长为 $0.05$ 的 $n$ 值网格来实现上述过程，尊重 $I$ 的单位 $\\mu$M 并将 $y$ 视为无量纲。所有优化必须在允许的运行时环境中进行，并遵守对库的限制。\n\n测试套件：\n使用以下四个综合测试用例（所有用例均由您的程序内部使用固定的随机种子生成，以确保可复现性）：\n\n- 案例 1（设计良好，低噪声；预期为可识别）：\n  - 真实参数：$\\beta_0 = 0.1$，$\\beta = 1.0$， $K = 10.0$，$n_{\\text{true}} = 2.0$。\n  - 浓度 $I$ (单位 $\\mu$M)：$N=20$ 个值，从 $0.1$ 到 $100.0$ 对数间隔分布。\n  - 噪声标准差：$\\sigma = 0.02$。\n\n- 案例 2（仅饱和区设计，低噪声；预期为不可识别）：\n  - 真实参数：$\\beta_0 = 0.1$，$\\beta = 1.0$， $K = 10.0$，$n_{\\text{true}} = 2.0$。\n  - 浓度 $I$ (单位 $\\mu$M)：$N=10$ 个值，从 $100.0$ 到 $200.0$ 线性间隔分布。\n  - 噪声标准差：$\\sigma = 0.02$。\n\n- 案例 3（仅亚阈值区设计，低噪声；预期为不可识别）：\n  - 真实参数：$\\beta_0 = 0.1$，$\\beta = 1.0$， $K = 10.0$，$n_{\\text{true}} = 2.0$。\n  - 浓度 $I$ (单位 $\\mu$M)：$N=10$ 个值，从 $0.01$ 到 $0.20$ 线性间隔分布。\n  - 噪声标准差：$\\sigma = 0.02$。\n\n- 案例 4（设计良好但高噪声；预期为不可识别）：\n  - 真实参数：$\\beta_0 = 0.1$，$\\beta = 1.0$， $K = 10.0$，$n_{\\text{true}} = 2.0$。\n  - 浓度 $I$ (单位 $\\mu$M)：$N=8$ 个值，从 $0.1$ 到 $100.0$ 对数间隔分布。\n  - 噪声标准差：$\\sigma = 0.20$。\n\n您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表（例如，$[result_1,result_2,result_3,result_4]$），其中每个 $result_i$ 是一个布尔值，指示在指定分类规则下，相应案例的希尔系数 $n$ 是否为不可识别。不应打印任何额外文本。",
            "solution": "问题陈述经过了仔细验证，被确定为科学上合理、定义明确且客观。它在合成生物学建模和自动化模型发现领域提出了一个形式化且可验证的任务。因此，我们可以着手提供一个完整的解决方案。\n\n问题的核心是从实验数据中评估希尔系数 $n$ 的可识别性。如果现有数据足以将其值约束在一个狭窄的范围内，则该参数被认为是可识别的。剖面对数似然函数为此评估提供了一个严谨的统计工具。一个尖锐的剖面峰表示高可识别性，而在很宽的参数值范围内的平坦剖面则表示不可识别性。该任务要求实现一个算法来计算和分析不同实验情景下的该剖面。\n\n解决方案分为四个主要阶段：\n1.  为每个测试用例生成合成实验数据。\n2.  在一系列 $n$ 值的网格上计算剖面对数似然函数 $\\ell_{\\text{prof}}(n)$。\n3.  分析归一化剖面 $\\tilde{\\ell}_{\\text{prof}}(n)$，使用两个度量来量化其平坦度。\n4.  基于定量阈值将 $n$ 分类为可识别或不可识别。\n\n**1. 合成数据生成**\n\n对于每个测试用例，我们首先生成模拟实验测量的合成数据。真实的底层过程由希尔激活函数描述：\n$$\ny(I;\\beta_0,\\beta,K,n) \\;=\\; \\beta_0 \\;+\\; \\beta \\,\\frac{I^n}{K^n + I^n}\n$$\n其中 $I$ 是诱导剂浓度，$\\beta_0$ 是基础表达，$\\beta$ 是可诱导振幅，$K$ 是半激活浓度，$n$ 是希尔系数。\n\n对于一组诱导剂浓度 $\\{I_i\\}_{i=1}^{N}$，使用每个案例提供的真实参数值计算出真实的表达水平 $\\{y_{\\text{true},i}\\}_{i=1}^{N}$。通过向真实值添加独立同分布的高斯噪声来模拟实验测量值 $y_{\\text{obs},i}$：\n$$\ny_{\\text{obs},i} \\;=\\; y(I_i;\\beta_{0,\\text{true}},\\beta_{\\text{true}},K_{\\text{true}},n_{\\text{true}}) \\;+\\; \\varepsilon_i,\\quad \\text{where } \\varepsilon_i \\sim \\mathcal{N}(0,\\sigma^2)\n$$\n每个案例的噪声标准差 $\\sigma$ 都是已知的。所有数据生成都使用固定的随机种子执行，以确保可复现性。\n\n**2. 剖面对数似然计算**\n\n$n$ 的剖面对数似然函数，记为 $\\ell_{\\text{prof}}(n)$，是通过对每个固定的 $n$ 值在讨厌参数 $(\\beta_0, \\beta, K)$ 上最大化对数似然函数来找到的。假设独立高斯噪声，最大化对数似然函数等同于最小化残差平方和（RSS）：\n$$\n\\text{RSS}(\\beta_0,\\beta,K) \\;=\\; \\sum_{i=1}^{N}\\left[y_{\\text{obs},i} - y(I_i;\\beta_0,\\beta,K,n)\\right]^2\n$$\n因此，对于预定义网格上（从 $0.5$ 到 $5.0$）的每个 $n$，我们求解以下约束优化问题：\n$$\n\\text{RSS}_{\\min}(n) \\;=\\; \\min_{\\beta_0 \\ge 0,\\, \\beta \\ge 0,\\, K  0} \\text{RSS}(\\beta_0,\\beta,K)\n$$\n这是一个非线性最小二乘问题。我们采用 `L-BFGS-B` 算法，该算法可通过 `scipy.optimize.minimize` 使用，非常适合此类问题，因为它可以处理参数所需的箱式约束（即下界）：$\\beta_0 \\ge 0$、$\\beta \\ge 0$ 和 $K  0$。为保证数值稳定性，对 $K$ 的约束实现为 $K \\ge \\epsilon$，其中 $\\epsilon$ 是一个很小的正数。\n\n一旦网格中的每个 $n$ 的 $\\text{RSS}_{\\min}(n)$ 被找到，相应的剖面对数似然值计算如下：\n$$\n\\ell_{\\text{prof}}(n) \\;=\\; -\\frac{\\text{RSS}_{\\min}(n)}{2\\sigma^2}\n$$\n\n**3. 剖面分析与可识别性分类**\n\n为了便于在不同数据集和模型之间进行比较，通过减去其最大值来对剖面进行归一化：\n$$\n\\tilde{\\ell}_{\\text{prof}}(n) \\;=\\; \\ell_{\\text{prof}}(n) - \\max_{n'}\\ell_{\\text{prof}}(n')\n$$\n这个归一化剖面的峰值在 $0$ 处，对应于希尔系数的最大似然估计值 $\\hat{n}$。然后使用两个度量来量化此剖面的平坦度：\n\n-   **二次曲率宽度 ($w$)**：剖面在其峰值 $\\hat{n}$ 附近的形状可以通过一个二次函数 $p(n) = a(n-\\hat{n})^2 + b(n-\\hat{n}) + c$ 来近似。曲率 $a$ 是二次项的系数。这可以通过将一个二阶多项式拟合到 $\\tilde{\\ell}_{\\text{prof}}(n)$ 峰值周围的一个小邻域点集来获得。基于似然比理论，可以从该曲率估计一个置信区间。在下降 $d = 1.92$（对应于单个参数的 95% 置信区间）处的剖面全宽度由下式给出：\n    $$\n    w \\;=\\; \\begin{cases} 2\\sqrt{d/|a|}  \\text{if } a  0 \\\\ +\\infty  \\text{if } a \\ge 0 \\end{cases}\n    $$\n    在最大值处的向上曲率（$a \\ge 0$）意味着一个极其平坦或性状不良的剖面，表示不可识别性，这通过无限宽度来体现。\n\n-   **全局下降幅度 ($\\Delta$)**：该度量捕捉了在整个评估的 $n$ 范围内对数似然的总下降量。它被定义为归一化剖面最小值的绝对值：\n    $$\n    \\Delta \\;=\\; \\left|\\min_{n}\\tilde{\\ell}_{\\text{prof}}(n)\\right|\n    $$\n    一个小的 $\\Delta$ 值表明，即使远离最优值 $\\hat{n}$，其他 $n$ 值也几乎同样合理，这是不可识别性的一个标志。\n\n最后，如果剖面根据指定的阈值过宽或过浅，希尔系数 $n$ 就被分类为不可识别：\n$$\n\\text{如果 } (w > 1.5) \\text{ 或 } (\\Delta  0.8) \\text{ 则为不可识别}\n$$\n对于不可识别的情况返回布尔值 `True`，否则返回 `False`。\n\n**4. 实现**\n\n所述算法在 Python 中实现，利用 `numpy` 进行高效的数值计算，并使用 `scipy.optimize.minimize` 进行剖面似然计算核心的约束非线性优化。一个主函数遍历四个指定的测试用例，每个用例都由一组真实参数和实验设计（浓度范围和采样）定义。对于每个案例，它生成数据，计算剖面，对其进行分析，并确定可识别性，将最终的布尔结果附加到列表中。程序最后以指定格式打印此列表。这种系统化的方法将统计可识别性分析的原理直接转化为具体的计算工作流程。",
            "answer": "```python\nimport numpy as np\nfrom scipy.optimize import minimize\n\ndef solve():\n    \"\"\"\n    Main function to solve the identifiability problem for all test cases.\n    \"\"\"\n    # Set a single fixed random seed for reproducibility across all cases.\n    np.random.seed(42)\n\n    # Define the four test cases as specified in the problem statement.\n    test_cases = [\n        {\n            \"name\": \"Case 1: Well-designed, low noise\",\n            \"true_params\": (0.1, 1.0, 10.0, 2.0), # beta0, beta, K, n\n            \"I_config\": {\"type\": \"log\", \"N\": 20, \"start\": 0.1, \"end\": 100.0},\n            \"sigma\": 0.02\n        },\n        {\n            \"name\": \"Case 2: Saturated-only, low noise\",\n            \"true_params\": (0.1, 1.0, 10.0, 2.0),\n            \"I_config\": {\"type\": \"lin\", \"N\": 10, \"start\": 100.0, \"end\": 200.0},\n            \"sigma\": 0.02\n        },\n        {\n            \"name\": \"Case 3: Subthreshold-only, low noise\",\n            \"true_params\": (0.1, 1.0, 10.0, 2.0),\n            \"I_config\": {\"type\": \"lin\", \"N\": 10, \"start\": 0.01, \"end\": 0.20},\n            \"sigma\": 0.02\n        },\n        {\n            \"name\": \"Case 4: Well-designed, high noise\",\n            \"true_params\": (0.1, 1.0, 10.0, 2.0),\n            \"I_config\": {\"type\": \"log\", \"N\": 8, \"start\": 0.1, \"end\": 100.0},\n            \"sigma\": 0.20\n        }\n    ]\n\n    results = []\n    for case in test_cases:\n        is_non_identifiable = analyze_case(case)\n        results.append(is_non_identifiable)\n\n    # Print the final results in the required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\ndef hill_function(params, I, n):\n    \"\"\"Calculates the Hill activation function response.\"\"\"\n    beta0, beta, K = params\n    # Use numerically stable form: 1 / ( (K/I)^n + 1 )\n    # Handle potential division by zero if I can be 0, though problem constraints avoid this.\n    with np.errstate(divide='ignore', invalid='ignore'):\n        term = 1.0 / (1.0 + (K / I)**n)\n    # If I is very small, (K/I)^n can be inf, and term becomes 0, which is correct.\n    term[np.isinf(I)] = 1.0 # If I is infinite, term is 1.\n    term[I == 0] = 0.0 # If I is zero, term is 0.\n    return beta0 + beta * term\n\n\ndef rss_objective(params, I, y_obs, n):\n    \"\"\"Calculates the Residual Sum of Squares (RSS) for the Hill model.\"\"\"\n    y_model = hill_function(params, I, n)\n    return np.sum((y_obs - y_model)**2)\n\n\ndef analyze_case(case_spec):\n    \"\"\"\n    Performs the full identifiability analysis for a single test case.\n    \"\"\"\n    # 1. Generate synthetic data\n    beta0_true, beta_true, K_true, n_true = case_spec[\"true_params\"]\n    I_config = case_spec[\"I_config\"]\n    sigma = case_spec[\"sigma\"]\n\n    if I_config[\"type\"] == 'log':\n        I = np.logspace(np.log10(I_config[\"start\"]), np.log10(I_config[\"end\"]), I_config[\"N\"])\n    else: # 'lin'\n        I = np.linspace(I_config[\"start\"], I_config[\"end\"], I_config[\"N\"])\n\n    y_true = hill_function((beta0_true, beta_true, K_true), I, n_true)\n    noise = np.random.normal(0, sigma, size=I_config[\"N\"])\n    y_obs = y_true + noise\n\n    # 2. Compute profile log-likelihood\n    n_grid = np.arange(0.5, 5.0 + 1e-9, 0.05)\n    l_prof = np.zeros_like(n_grid)\n    \n    # Heuristic initial guess for optimizer\n    beta0_guess = np.min(y_obs) if np.min(y_obs)  0 else 1e-3\n    beta_guess = np.max(y_obs) - beta0_guess if (np.max(y_obs) - beta0_guess)  0 else 0.1\n    mid_y_range = beta0_guess + 0.5 * beta_guess\n    k_guess_idx = np.argmin(np.abs(y_obs - mid_y_range))\n    k_guess = I[k_guess_idx]\n    x0 = [beta0_guess, beta_guess, k_guess]\n\n    bounds = [(0, None), (0, None), (1e-9, None)]\n\n    for i, n_val in enumerate(n_grid):\n        opt_result = minimize(\n            rss_objective,\n            x0,\n            args=(I, y_obs, n_val),\n            bounds=bounds,\n            method='L-BFGS-B'\n        )\n        min_rss = opt_result.fun\n        l_prof[i] = -min_rss / (2 * sigma**2)\n\n    # 3. Analyze the profile\n    if np.all(np.isinf(l_prof)) or np.all(np.isnan(l_prof)):\n        return True # Profile computation failed, indicates extreme non-identifiability\n\n    l_prof_norm = l_prof - np.max(l_prof)\n\n    # Metric 1: Global drop magnitude\n    delta = np.abs(np.min(l_prof_norm))\n\n    # Metric 2: Quadratic-curvature width\n    idx_max = np.argmax(l_prof_norm)\n    \n    # Define neighborhood for quadratic fit, handling edges\n    width_pts = 3\n    start_idx = max(0, idx_max - width_pts)\n    end_idx = min(len(n_grid), idx_max + width_pts + 1)\n    \n    if (end_idx - start_idx)  3:\n        # Not enough points for a quadratic fit, implies a pathological profile (e.g., max at edge)\n        w = np.inf\n    else:\n        n_hood = n_grid[start_idx:end_idx]\n        l_prof_hood = l_prof_norm[start_idx:end_idx]\n        \n        # Fit a 2nd-degree polynomial: a*n^2 + b*n + c\n        coeffs = np.polyfit(n_hood, l_prof_hood, 2)\n        a = coeffs[0]\n\n        d = 1.92\n        if a = -1e-9: # Curvature is non-negative (or very close to zero)\n            w = np.inf\n        else:\n            w = 2 * np.sqrt(d / np.abs(a))\n\n    # 4. Classify based on thresholds\n    is_non_identifiable = (w  1.5) or (delta  0.8)\n    return is_non_identifiable\n\nif __name__ == '__main__':\n    solve()\n```"
        },
        {
            "introduction": "如果我们通过分析发现模型中的某个参数是不可辨识的，下一步该怎么做？一个有效的策略是设计一个更好的实验来收集更有信息量的数据。最优实验设计（Optimal Experimental Design, OED），特别是利用费雪信息矩阵（Fisher Information Matrix, FIM）的方法，使我们能够通过计算来确定哪种实验输入（例如刺激信号）对于精确估计模型参数最为有效。这项高级练习  挑战你从被动地分析现有数据转向主动地设计新实验，你将使用基于费雪信息的标准来优化输入刺激信号，从而学习如何数学化地实现“获取最大信息量”这一目标，以解决参数模糊性的问题。",
            "id": "3906793",
            "problem": "在合成生物学中，自动化模型发现通常需要选择信息丰富的输入刺激，以便从带噪声的时间序列数据中估计潜在的生物物理参数。考虑一个最小的、基于机理的转录-翻译模块，其被建模为一个由标量输入刺激驱动的一阶线性系统。动态状态 $x(t)$（可观测的报告基因水平）遵循常微分方程 $dx/dt = -k_2 x(t) + k_1 u(t)$，初始条件为零，其中 $k_1$ 和 $k_2$ 是未知的正参数，$u(t)$ 是一个可以开启和关闭的外部控制的输入刺激。测量值 $y_i$ 在离散时间 $t_i = i \\Delta t$（$i = 0,1,\\dots,N-1$）记录，带有独立的加性高斯测量噪声，其均值为零，方差为 $\\sigma^2$。只有报告基因 $y_i = x(t_i)$ 被观测到。在标准刺激下，有序对 $(k_1,k_2)$ 的可辨识性可能很差，但比率 $\\phi = k_1/k_2$ 是主要关注的。\n\n从线性系统定义、 $x(t)$ 的卷积表示以及独立高斯噪声的性质出发，为比率 $\\phi$ 推导一个基于费雪信息的标量目标函数。使用以下基本事实作为起点：(i) 线性时不变系统的叠加和卷积，(ii) 对于具有加性独立高斯噪声的模型，费雪信息矩阵 (FIM) 为 $F = \\sigma^{-2} S^\\top S$，其中 $S$ 是灵敏度矩阵，其条目是模型输出关于参数的偏导数，以及 (iii) delta 方法意味着对于标量变换 $\\phi = g(\\theta)$，其中 $\\theta = (k_1,k_2)$，$\\phi$ 的费雪信息为 $I_\\phi = \\nabla_\\theta g(\\theta)^\\top F \\nabla_\\theta g(\\theta)$。你不能假设任何预设的刺激；相反，你必须在一个受约束的族内通过计算优化输入模式以最大化 $I_\\phi$。\n\n假设存在以下实验设计空间：$u(t)$ 被约束为振幅为 $u_{\\max}$、持续时间为 $L \\Delta t$ 的单个连续矩形脉冲，从某个网格索引 $s \\in \\{0,1,\\dots,N-L\\}$ 开始，其中 $L$ 从一个有限的允许集合 $\\mathcal{L} \\subset \\{0,1,\\dots,N\\}$ 中选择。如果 $L=0$，则输入恒为零。对于给定的 $(k_1,k_2,\\Delta t,N,\\sigma,u_{\\max},\\mathcal{L})$，你的任务是搜索所有可行的脉冲长度 $L \\in \\mathcal{L}$ 和起始索引 $s$，以找到使比率 $\\phi = k_1/k_2$ 的费雪信息 $I_\\phi$ 最大化的输入。你必须使用与离散采样网格一致的黎曼和近似，完全按照上述基于费雪信息的标准来计算 $I_\\phi$。\n\n你的程序必须为每个测试用例实现以下步骤：\n- 为 $i=0,\\dots,N-1$ 构建采样时间 $t_i = i \\Delta t$。\n- 对于一个由 $(L,s)$ 和振幅 $u_{\\max}$ 表征的候选脉冲，构建离散输入序列 $u_j$，$j=0,\\dots,N-1$，其中当 $j \\in \\{s,\\dots,s+L-1\\}$ 时 $u_j = u_{\\max}$，否则 $u_j = 0$（如果 $L=0$，则对所有 $j$，$u_j=0$）。\n- 使用卷积表示和黎曼和计算每个采样时间的灵敏度：\n  - $s_{i,1} = \\frac{\\partial x(t_i)}{\\partial k_1} \\approx \\sum_{j=0}^{i} u_j \\exp\\!\\left(-k_2 (t_i - t_j)\\right) \\Delta t$。\n  - $s_{i,2} = \\frac{\\partial x(t_i)}{\\partial k_2} \\approx -k_1 \\sum_{j=0}^{i} (t_i - t_j) u_j \\exp\\!\\left(-k_2 (t_i - t_j)\\right) \\Delta t$。\n- 构成灵敏度矩阵 $S \\in \\mathbb{R}^{N \\times 2}$，其列为 $s_{\\cdot,1}$ 和 $s_{\\cdot,2}$，然后计算费雪信息矩阵 $F = \\sigma^{-2} S^\\top S$。\n- 对于 $\\phi = k_1/k_2$，计算 $\\nabla_\\theta g(\\theta) = \\left[\\frac{\\partial \\phi}{\\partial k_1}, \\frac{\\partial \\phi}{\\partial k_2}\\right]^\\top = \\left[\\frac{1}{k_2}, -\\frac{k_1}{k_2^2}\\right]^\\top$，然后计算 $I_\\phi = \\nabla_\\theta g(\\theta)^\\top F \\nabla_\\theta g(\\theta)$。\n- 返回所有允许的脉冲设计中最大的 $I_\\phi$。\n\n测试套件：\n对于每个案例，搜索整个允许的设计族，并报告找到的单个最大 $I_\\phi$ 值。整个程序的最终输出要求是单行，包含一个浮点数列表，每个测试用例一个，四舍五入到六位小数，用方括号括起来并用逗号分隔（例如，“[1.234000,0.000000]”）。\n\n- 案例 1 (正常路径):\n  - $k_1 = 2.0$, $k_2 = 0.8$, $\\Delta t = 0.5$, $N = 20$, $\\sigma = 0.1$, $u_{\\max} = 1.0$, $\\mathcal{L} = \\{2,4,6\\}$。\n- 案例 2 (边界情况，不允许输入):\n  - $k_1 = 1.2$, $k_2 = 0.6$, $\\Delta t = 0.5$, $N = 20$, $\\sigma = 0.1$, $u_{\\max} = 1.0$, $\\mathcal{L} = \\{0\\}$。\n- 案例 3 (快速衰减边缘情况):\n  - $k_1 = 1.5$, $k_2 = 3.0$, $\\Delta t = 0.2$, $N = 30$, $\\sigma = 0.2$, $u_{\\max} = 1.0$, $\\mathcal{L} = \\{3,6\\}$。\n- 案例 4 (高噪声，更长时间范围):\n  - $k_1 = 1.0$, $k_2 = 1.0$, $\\Delta t = 0.5$, $N = 25$, $\\sigma = 1.0$, $u_{\\max} = 1.0$, $\\mathcal{L} = \\{5,10\\}$。\n\n最终输出格式：\n你的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表。列表中的每个条目是对应测试用例的最大 $I_\\phi$ 值，按上述案例顺序排列，并四舍五入到六位小数。不应打印其他任何输出。",
            "solution": "用户提供的问题陈述已经过严格评估，并被确定为**有效**。\n\n### 问题验证\n\n**第1步：提取的已知条件**\n\n- **动力学系统**：一阶线性常微分方程(ODE) $dx/dt = -k_2 x(t) + k_1 u(t)$，初始条件为 $x(0) = 0$。\n- **参数**：未知的正参数 $k_1$ 和 $k_2$。\n- **输入刺激**：$u(t)$ 是一个外部控制的输入。\n- **测量模型**：$y_i = x(t_i) + \\epsilon_i$，其中测量在离散时间 $t_i = i \\Delta t$（$i = 0,1,\\dots,N-1$）进行。\n- **噪声模型**：测量噪声 $\\epsilon_i$ 是独立同分布(i.i.d.)的高斯噪声，均值为零，方差为 $\\sigma^2$。\n- **感兴趣的参数**：比率 $\\phi = k_1/k_2$。\n- **实验设计空间**：\n    - $u(t)$ 是一个单个连续的矩形脉冲。\n    - 振幅：$u_{\\max}$。\n    - 持续时间：$L \\Delta t$，其中长度参数 $L$ 从一个有限集合 $\\mathcal{L} \\subset \\{0,1,\\dots,N\\}$ 中选择。如果 $L=0$，$u(t)=0$。\n    - 起始索引：$s \\in \\{0,1,\\dots,N-L\\}$。\n- **数学工具与公式**：\n    - **费雪信息矩阵(FIM)**：$F = \\sigma^{-2} S^\\top S$，其中 $S$ 是灵敏度矩阵。\n    - **灵敏度矩阵条目($S_{i,j}$)**：$S_{ik} = \\frac{\\partial x(t_i)}{\\partial \\theta_k}$，对于 $\\theta = (k_1, k_2)$。\n    - **灵敏度近似（黎曼和）**：\n        - $s_{i,1} = \\frac{\\partial x(t_i)}{\\partial k_1} \\approx \\sum_{j=0}^{i} u_j \\exp\\!\\left(-k_2 (t_i - t_j)\\right) \\Delta t$。\n        - $s_{i,2} = \\frac{\\partial x(t_i)}{\\partial k_2} \\approx -k_1 \\sum_{j=0}^{i} (t_i - t_j) u_j \\exp\\!\\left(-k_2 (t_i - t_j)\\right) \\Delta t$。\n        - 其中 $u_j$ 是在时间 $t_j$ 的输入刺激值。\n    - **变换后参数的信息（Delta方法）**：$I_\\phi = \\nabla_\\theta g(\\theta)^\\top F \\nabla_\\theta g(\\theta)$，对于 $\\phi = g(\\theta)$。\n    - **变换的梯度**：对于 $\\phi = k_1/k_2$，$\\nabla_\\theta g(\\theta) = \\left[\\frac{1}{k_2}, -\\frac{k_1}{k_2^2}\\right]^\\top$。\n- **任务**：对于给定的参数集，找到使 $I_\\phi$ 最大化的输入脉冲设计 $(L,s)$。\n\n**第2步：使用提取的已知条件进行验证**\n\n该问题是**有效**的。\n- **具有科学依据**：该问题建立在系统理论（线性ODE、卷积）、统计推断（费雪信息）和数值方法（黎曼和）的基础原则之上。该模型是简单生化过程（如转录和翻译）的标准表示，这是合成生物学中的一个常见主题。\n- **适定的**：该问题定义了一个清晰的、标量目标函数($I_\\phi$)，该函数在一个有限的、明确定义的实验设计搜索空间上进行最大化。这种结构保证了解（一个最大值）的存在。\n- **目标**：问题使用精确的数学和科学语言陈述，没有主观性或模糊性。\n- **自洽且一致**：为每个测试用例提供了所有必需的参数、方程和约束。数学公式内部一致，并源自标准原则。灵敏度的离散近似被明确给出，消除了计算中的任何模糊性。\n\n**第3步：结论与行动**\n\n该问题是有效的。将提供一个完整的解决方案。\n\n### 求解推导与算法策略\n\n目标是从一个受约束的函数族中找到一个最优的输入刺激 $u(t)$，以最大化参数比率 $\\phi = k_1/k_2$ 的费雪信息 $I_\\phi$。输入刺激是由长度 $L$ 和起始索引 $s$ 表征的矩形脉冲。\n\n变换后参数 $\\phi$ 的费雪信息由delta方法给出：\n$$\nI_\\phi = \\nabla_\\theta g(\\theta)^\\top F \\nabla_\\theta g(\\theta)\n$$\n这里，$\\theta = (k_1, k_2)$ 是模型参数的向量，$g(\\theta)=k_1/k_2$ 是标量变换。此表达式的组成部分是：\n\n1.  **变换的梯度，$\\nabla_\\theta g(\\theta)$**：\n    $\\phi$ 关于 $k_1$ 和 $k_2$ 的偏导数是：\n    $$\n    \\frac{\\partial \\phi}{\\partial k_1} = \\frac{1}{k_2}\n    $$\n    $$\n    \\frac{\\partial \\phi}{\\partial k_2} = -\\frac{k_1}{k_2^2}\n    $$\n    因此，梯度向量是 $\\nabla_\\theta g(\\theta) = \\begin{bmatrix} 1/k_2  -k_1/k_2^2 \\end{bmatrix}^\\top$。对于任何给定的测试用例，$k_1$ 和 $k_2$ 的值是已知的，因此这个向量是一个常数。\n\n2.  **费雪信息矩阵，F**：\n    对于具有加性i.i.d.高斯噪声的模型，参数 $\\theta$ 的FIM是：\n    $$\n    F = \\frac{1}{\\sigma^2} S^\\top S\n    $$\n    项 $\\sigma^2$ 是噪声方差，对每个测试用例都是已知常数。矩阵 $S$ 是灵敏度矩阵，它捕捉了模型输出如何随参数变化。其条目是 $S_{ik} = \\frac{\\partial x(t_i)}{\\partial \\theta_k}$。\n\n3.  **灵敏度矩阵，S**：\n    灵敏度矩阵 $S$ 是一个 $N \\times 2$ 的矩阵，第一列包含关于 $k_1$ 的灵敏度，第二列包含关于 $k_2$ 的灵敏度，这些都在 $N$ 个采样时间的每一个上进行评估。\n    $$\n    S = \\begin{bmatrix}\n    \\frac{\\partial x(t_0)}{\\partial k_1}  \\frac{\\partial x(t_0)}{\\partial k_2} \\\\\n    \\frac{\\partial x(t_1)}{\\partial k_1}  \\frac{\\partial x(t_1)}{\\partial k_2} \\\\\n    \\vdots  \\vdots \\\\\n    \\frac{\\partial x(t_{N-1})}{\\partial k_1}  \\frac{\\partial x(t_{N-1})}{\\partial k_2}\n    \\end{bmatrix}\n    $$\n    关键的洞察是，灵敏度矩阵 $S$ 是 $I_\\phi$ 表达式中唯一依赖于输入刺激 $u(t)$ 的部分。因此，我们的优化问题简化为找到使涉及 $S^\\top S$ 的二次型尽可能大的输入 $u(t)$（即脉冲 $(L,s)$）。\n\n问题提供了灵敏度值的明确的黎曼和近似：\n-   $s_{i,1} = \\frac{\\partial x(t_i)}{\\partial k_1} \\approx \\Delta t \\sum_{j=0}^{i} u_j e^{-k_2 (t_i - t_j)}$\n-   $s_{i,2} = \\frac{\\partial x(t_i)}{\\partial k_2} \\approx -k_1 \\Delta t \\sum_{j=0}^{i} (t_i - t_j) u_j e^{-k_2 (t_i - t_j)}$\n\n这些求和必须对每个时间点 $i \\in \\{0, \\dots, N-1\\}$ 进行计算。\n\n### 计算搜索过程\n\n最优设计通过系统地搜索整个允许的输入脉冲的离散空间来找到。每个测试用例的算法如下：\n\n1.  初始化一个变量 `max_I_phi` 为 $0.0$，因为信息是非负的。$L=0$ 的情况（零输入）产生 $I_\\phi = 0$。\n2.  为 $i=0, \\dots, N-1$ 定义采样时间 $t_i = i \\Delta t$。\n3.  遍历每个允许的脉冲长度 $L \\in \\mathcal{L}$。\n4.  对于每个 $L  0$，遍历所有可能的起始索引 $s \\in \\{0, 1, \\dots, N-L\\}$。\n5.  对于每个候选设计 $(L,s)$：\n    a. 构建离散输入向量 $u \\in \\mathbb{R}^N$。对于 $j \\in \\{s, \\dots, s+L-1\\}$，设置 $u_j = u_{\\max}$，否则 $u_j = 0$。\n    b. 计算 $N \\times 2$ 的灵敏度矩阵 $S$。这需要两个嵌套循环：一个外层循环用于时间索引 $i$ 从 $0$ 到 $N-1$，一个内层循环用于求和索引 $j$ 从 $0$ 到 $i$。在循环内部，根据它们的公式计算 $s_{i,1}$ 和 $s_{i,2}$ 的项。\n    c. 计算 $2 \\times 2$ 矩阵 $S^\\top S$。\n    d. 计算FIM $F = \\sigma^{-2} S^\\top S$。\n    e. 计算梯度向量 $\\nabla_\\theta g(\\theta)$。\n    f. 计算标量费雪信息 $I_\\phi = (\\nabla_\\theta g(\\theta))^\\top F (\\nabla_\\theta g(\\theta))$。\n    g. 如果新计算的 $I_\\phi$ 更大，则更新 `max_I_phi`：`max_I_phi = max(max_I_phi, I_phi)`。\n6.  在评估完所有 $(L,s)$ 对之后，`max_I_phi` 持有在给定实验约束下可实现的最大信息。该值作为该测试用例的结果存储。\n\n对问题中指定的每个测试用例实施此过程，并按要求格式化最终结果。",
            "answer": "```python\nimport numpy as np\n\ndef calculate_max_fisher_information(k1, k2, dt, N, sigma, u_max, L_set):\n    \"\"\"\n    Computes the maximum Fisher information for the ratio phi = k1/k2 by searching\n    over a space of rectangular pulse experimental designs.\n\n    Args:\n        k1 (float): Parameter k1.\n        k2 (float): Parameter k2.\n        dt (float): Time step delta_t.\n        N (int): Number of time points.\n        sigma (float): Standard deviation of measurement noise.\n        u_max (float): Amplitude of the input pulse.\n        L_set (set): Set of allowed pulse lengths L (in grid units).\n\n    Returns:\n        float: The maximum Fisher information I_phi found.\n    \"\"\"\n    t = np.arange(N) * dt\n    max_I_phi = 0.0\n\n    # The gradient of phi = k1/k2 w.r.t. theta = (k1, k2) is constant for a given case.\n    # grad_g = [d(phi)/dk1, d(phi)/dk2] = [1/k2, -k1/k2^2]\n    grad_g = np.array([1 / k2, -k1 / (k2**2)])\n\n    # Handle the L=0 case separately. If L=0, u is always zero, so S=0, F=0, I_phi=0.\n    # Since max_I_phi is initialized to 0.0, this case is implicitly handled.\n    if 0 in L_set and len(L_set) == 1:\n        return 0.0\n        \n    for L in L_set:\n        if L == 0:\n            continue\n        \n        # Iterate over all possible start times for a pulse of length L\n        for s in range(N - L + 1):\n            # 1. Construct the input signal u for the current design (L, s)\n            u = np.zeros(N)\n            u[s : s + L] = u_max\n\n            # 2. Compute the sensitivity matrix S\n            S = np.zeros((N, 2))\n            for i in range(N):\n                sum1 = 0.0  # For sensitivity wrt k1\n                sum2 = 0.0  # For sensitivity wrt k2\n                \n                # The summation is from j=0 to i, as specified.\n                for j in range(i + 1):\n                    if u[j] > 0:\n                        time_diff = t[i] - t[j]\n                        exp_term = np.exp(-k2 * time_diff)\n                        \n                        # From problem: s_i1 = sum(u_j * exp(...) * dt)\n                        sum1 += u[j] * exp_term\n                        \n                        # From problem: s_i2 = -k1 * sum((t_i-t_j) * u_j * exp(...) * dt)\n                        sum2 += (time_diff * u[j] * exp_term)\n\n                S[i, 0] = sum1 * dt\n                S[i, 1] = -k1 * sum2 * dt\n\n            # 3. Compute the Fisher Information Matrix (FIM) for theta=(k1, k2)\n            # F = (1/sigma^2) * S^T * S\n            F = (1 / sigma**2) * (S.T @ S)\n\n            # 4. Compute Fisher information for phi\n            # I_phi = grad_g^T * F * grad_g\n            I_phi = grad_g.T @ F @ grad_g\n            \n            # 5. Update the maximum I_phi found\n            if I_phi > max_I_phi:\n                max_I_phi = I_phi\n                \n    return max_I_phi\n\ndef solve():\n    \"\"\"\n    Main function to run all test cases and print the final output.\n    \"\"\"\n    test_cases = [\n        # Case 1: happy path\n        {'k1': 2.0, 'k2': 0.8, 'dt': 0.5, 'N': 20, 'sigma': 0.1, 'u_max': 1.0, 'L_set': {2, 4, 6}},\n        # Case 2: boundary, no input allowed\n        {'k1': 1.2, 'k2': 0.6, 'dt': 0.5, 'N': 20, 'sigma': 0.1, 'u_max': 1.0, 'L_set': {0}},\n        # Case 3: fast decay edge case\n        {'k1': 1.5, 'k2': 3.0, 'dt': 0.2, 'N': 30, 'sigma': 0.2, 'u_max': 1.0, 'L_set': {3, 6}},\n        # Case 4: high noise, longer horizon\n        {'k1': 1.0, 'k2': 1.0, 'dt': 0.5, 'N': 25, 'sigma': 1.0, 'u_max': 1.0, 'L_set': {5, 10}},\n    ]\n\n    results = []\n    for params in test_cases:\n        max_I_phi = calculate_max_fisher_information(**params)\n        results.append(max_I_phi)\n\n    # Format the final output string exactly as required.\n    output_str = f\"[{','.join([f'{r:.6f}' for r in results])}]\"\n    print(output_str)\n\nsolve()\n```"
        }
    ]
}