{
    "hands_on_practices": [
        {
            "introduction": "Before transcriptomics data can be integrated into mechanistic models, which often operate in terms of absolute molecular counts, raw sequencing reads must be converted into these meaningful biological units. This exercise guides you through the fundamental process of absolute quantification using spike-in controls, a widely used experimental strategy . By deriving the relationship between read counts and molecule numbers, you will master a core ratiometric technique essential for accurately parameterizing biological models.",
            "id": "3924226",
            "problem": "A single-cell ribonucleic acid sequencing (RNA-seq) experiment is performed to parameterize a mechanistic gene expression model in synthetic biology by converting sequencing counts into absolute molecules per cell. External RNA Controls Consortium (ERCC) spike-in transcripts are added at a known absolute abundance prior to cell lysis. Assume the following foundational measurement model: sequencing reads arise from random sampling of complementary deoxyribonucleic acid (cDNA) molecules generated from messenger ribonucleic acid (mRNA) and spike-in templates, and, in expectation, the number of reads mapping to any transcript is proportional to the number of its input molecules multiplied by the total library size.\n\nLet $L$ denote the total number of uniquely mapped reads in the library, $C_{g}$ the uniquely mapped reads to gene $g$, $C_{s}$ the uniquely mapped reads to a particular ERCC spike-in species $s$, and $M_{s}$ the true number of molecules of spike-in species $s$ contributed per cell. Assume a common linear factor of proportionality across endogenous mRNA and the chosen spike-in, encompassing reverse transcription efficiency, amplification efficiency, and mapping probability, and assume that $L$ is known.\n\nStarting from the proportional sampling premise and core definitions above, derive an expression for the molecules per cell of gene $g$, denoted $M_{g}$, in terms of $C_{g}$, $C_{s}$, $M_{s}$, and $L$, and eliminate any nuisance constants so that $M_{g}$ is expressed only in terms of $C_{g}$, $C_{s}$, and $M_{s}$.\n\nThen, for a single cell with observed $L = 2.80 \\times 10^{7}$, $C_{g} = 13{,}720$, $C_{s} = 22{,}740$, and a known $M_{s} = 1{,}300$ molecules per cell, compute $M_{g}$ as a real number. Round your final answer to four significant figures. Express your answer as molecules per cell with no units in your final numerical value.",
            "solution": "The problem requires the derivation of an expression for the number of messenger ribonucleic acid (mRNA) molecules of a gene, $M_{g}$, based on a single-cell ribonucleic acid sequencing (RNA-seq) experiment that uses External RNA Controls Consortium (ERCC) spike-in controls for absolute quantification. Subsequently, a numerical value for $M_{g}$ is to be computed based on provided data.\n\nFirst, I will validate the problem statement.\n\n### Step 1: Extract Givens\n- $L$: total number of uniquely mapped reads in the library.\n- $C_{g}$: uniquely mapped reads to gene $g$.\n- $C_{s}$: uniquely mapped reads to a particular ERCC spike-in species $s$.\n- $M_{s}$: true number of molecules of spike-in species $s$ contributed per cell.\n- $M_{g}$: molecules per cell of gene $g$.\n- Premise: \"...in expectation, the number of reads mapping to any transcript is proportional to the number of its input molecules multiplied by the total library size.\"\n- Assumption: \"a common linear factor of proportionality across endogenous mRNA and the chosen spike-in\".\n- Numerical values for a single cell: $L = 2.80 \\times 10^{7}$, $C_{g} = 13{,}720$, $C_{s} = 22{,}740$, and $M_{s} = 1{,}300$.\n- Required task: Derive an expression for $M_{g}$ in terms of $C_{g}$, $C_{s}$, and $M_{s}$, and then compute its numerical value, rounded to four significant figures.\n\n### Step 2: Validate Using Extracted Givens\n- **Scientifically Grounded:** The problem describes a valid and common methodology in quantitative biology and synthetic biology modeling, specifically the use of spike-in standards for absolute quantification of transcripts from sequencing data. The underlying principle of proportional sampling is a cornerstone of RNA-seq analysis.\n- **Well-Posed:** The problem is well-posed. It provides a clear set of definitions and a specific, albeit simplified, measurement model. The objectives are explicit: derive an expression and then compute a numerical value. The information provided is sufficient to achieve these objectives.\n- **Objective:** The language is technical, precise, and free of subjective or ambiguous terminology.\n- **Incomplete or Contradictory Setup:** The problem is self-contained. While the premise that read counts are proportional to molecule counts *multiplied by* the total library size ($C \\propto M \\cdot L$) is an unconventional formulation (a more standard model is that the read fraction is proportional to the molecule fraction, $C/L \\propto M/M_{total}$, or simply $C \\propto M$), it constitutes a a self-consistent mathematical model defined within the problem statement itself. The presence of the variable $L$, which is ultimately eliminated from the final expression, is a common feature in physics and engineering problems designed to test understanding of scaling relationships. The problem is not contradictory.\n\n### Step 3: Verdict and Action\nThe problem is valid. I will proceed with the solution.\n\nThe foundational measurement model, as stated in the problem, is that the expected number of reads for a given transcript, $\\mathbb{E}[C]$, is proportional to the number of its input molecules, $M$, and the total library size, $L$. This can be expressed mathematically as:\n$$ \\mathbb{E}[C] = k \\cdot M \\cdot L $$\nwhere $k$ is a constant of proportionality. This constant $k$ is assumed to be common for both the endogenous gene $g$ and the ERCC spike-in species $s$. For the purpose of estimation, we equate the observed read counts, $C_{g}$ and $C_{s}$, with their expectations.\n\nFor the gene of interest, $g$, we have:\n$$ C_{g} = k \\cdot M_{g} \\cdot L \\quad (1) $$\n\nFor the ERCC spike-in species, $s$, we have:\n$$ C_{s} = k \\cdot M_{s} \\cdot L \\quad (2) $$\n\nThe problem asks for an expression for $M_{g}$. Our strategy will be to eliminate the unknown nuisance constant $k$ and any other non-essential variables. We can take the ratio of equation $(1)$ to equation $(2)$:\n$$ \\frac{C_{g}}{C_{s}} = \\frac{k \\cdot M_{g} \\cdot L}{k \\cdot M_{s} \\cdot L} $$\nThe terms $k$ and $L$ cancel out, which simplifies the expression significantly. This cancellation confirms that under this model, the total library size $L$ is not needed for the relative quantification that leads to absolute numbers via the spike-in standard.\n$$ \\frac{C_{g}}{C_{s}} = \\frac{M_{g}}{M_{s}} $$\nNow, we can solve for $M_{g}$ by rearranging the equation:\n$$ M_{g} = M_{s} \\cdot \\frac{C_{g}}{C_{s}} $$\nThis is the derived expression for the number of molecules of gene $g$, expressed solely in terms of the directly measurable quantities $C_{g}$ and $C_{s}$, and the known quantity $M_{s}$.\n\nNow, we will compute the numerical value for $M_{g}$ using the provided data:\n- $C_{g} = 13720$\n- $C_{s} = 22740$\n- $M_{s} = 1300$\n\nSubstituting these values into our derived formula:\n$$ M_{g} = 1300 \\cdot \\frac{13720}{22740} $$\n$$ M_{g} = \\frac{1300 \\cdot 13720}{22740} = \\frac{17836000}{22740} $$\n$$ M_{g} \\approx 784.340369... $$\n\nThe problem requires the answer to be rounded to four significant figures. The first four significant figures are $7$, $8$, $4$, and $3$. The fifth digit is $4$, which is less than $5$, so we round down.\n$$ M_{g} \\approx 784.3 $$\nThis value represents the estimated number of molecules of gene $g$ per cell.",
            "answer": "$$\\boxed{784.3}$$"
        },
        {
            "introduction": "Once transcript abundances are quantified, comparing them across conditions requires robust statistical models, where the choice of framework can significantly influence the results. This practice challenges you to implement and compare two distinct and powerful approaches for differential expression analysis: one based on compositional data theory and another on the Negative Binomial distribution that explicitly models library size . This hands-on comparison will build your intuition for how modeling assumptions shape data interpretation, a critical skill for any modeler using omics data.",
            "id": "3924184",
            "problem": "You are given discrete sequencing read count matrices that represent transcript abundances across genes and samples in a two-condition experiment, together with the per-sample library sizes. The task is to compute differential expression effect sizes for each gene using a log-ratio approach derived from compositional data principles and to contrast them with effect sizes obtained from a Negative Binomial (NB) model under varying library sizes. Then, for each test case, summarize the contrast using well-defined quantitative metrics.\n\nFundamental base and assumptions:\n- Sequencing read counts arise from sampling of underlying molecular abundances, and at moderate to high counts exhibit overdispersion consistent with a Negative Binomial model. Let the count for gene $g$ in sample $s$ be $y_{gs} \\in \\mathbb{N}_0$. Let the library size of sample $s$ be $L_s \\in \\mathbb{R}_+$. Let the condition label be $c_s \\in \\{0,1\\}$, with $c_s = 0$ denoting condition $A$ and $c_s = 1$ denoting condition $B$.\n- Compositionality means that only ratios are identifiable; log-ratio transformations are appropriate for relative abundances. The centered log-ratio transformation uses the geometric mean of counts across genes within each sample as a reference.\n- In the NB framework, expected counts satisfy $\\mathbb{E}[y_{gs}] = \\mu_{gs} = L_s \\, q_{g,c_s}$, where $q_{g,c} \\in \\mathbb{R}_+$ is the per-library-size mean rate for gene $g$ in condition $c$. Dispersion is captured by $\\mathrm{Var}(y_{gs}) = \\mu_{gs} + \\phi_g \\mu_{gs}^2$ with gene-specific dispersion $\\phi_g \\ge 0$. The maximum likelihood estimator of $q_{g,c}$ under independent samples is the ratio of aggregated counts to aggregated library sizes.\n\nYour program must, for each test case, do the following:\n1. Compute log-ratio effect sizes using the centered log-ratio approach.\n   - Choose a small pseudocount $k \\in \\mathbb{R}_+$ to avoid undefined logarithms at zeros. For each sample $s$, define the per-sample centered log-ratio for gene $g$ as\n     $$ r_{gs} = \\log\\left(y_{gs} + k\\right) - \\frac{1}{G} \\sum_{g'=1}^{G} \\log\\left(y_{g's} + k\\right), $$\n     where $G$ is the number of genes. The differential expression effect size for gene $g$ is the difference in condition means:\n     $$ d_g = \\frac{1}{S_B} \\sum_{s: c_s = 1} r_{gs} - \\frac{1}{S_A} \\sum_{s: c_s = 0} r_{gs}, $$\n     where $S_A$ and $S_B$ are the numbers of samples in conditions $A$ and $B$, respectively. All logarithms are natural logarithms.\n2. Compute Negative Binomial-based effect sizes by estimating per-condition mean rates.\n   - Using the aggregated counts and library sizes, define\n     $$ \\hat{q}_{g,A} = \\frac{\\sum_{s: c_s = 0} y_{gs} + \\kappa}{\\sum_{s: c_s = 0} L_s}, \\quad \\hat{q}_{g,B} = \\frac{\\sum_{s: c_s = 1} y_{gs} + \\kappa}{\\sum_{s: c_s = 1} L_s}, $$\n     where $\\kappa \\in \\mathbb{R}_+$ is a stabilization pseudocount. The NB-based differential expression effect size is the log-rate ratio:\n     $$ e_g = \\log\\left( \\frac{\\hat{q}_{g,B}}{\\hat{q}_{g,A}} \\right). $$\n3. Quantify the contrast between the two sets of effect sizes $\\{d_g\\}$ and $\\{e_g\\}$ across genes using:\n   - The Spearman rank correlation coefficient $\\rho$ between $\\{d_g\\}$ and $\\{e_g\\}$.\n   - The maximum absolute difference\n     $$ \\Delta_{\\max} = \\max_{g} \\left| d_g - e_g \\right|. $$\n   - The fraction of sign agreement, defined using the sign function $\\mathrm{sgn}(x)$ that equals $-1$ if $x < 0$, $0$ if $x = 0$, and $+1$ if $x > 0$:\n     $$ f_{\\mathrm{agree}} = \\frac{1}{G} \\sum_{g=1}^{G} \\mathbf{1}\\left[ \\mathrm{sgn}(d_g) = \\mathrm{sgn}(e_g) \\right], $$\n     where $\\mathbf{1}[\\cdot]$ is the indicator function. Report $f_{\\mathrm{agree}}$ as a decimal in $[0,1]$.\n\nTest suite:\nYou must process the following three independent test cases. In all cases, the condition labels are $c = [0,0,1,1]$ corresponding to samples $[A_1,A_2,B_1,B_2]$, and use pseudocounts $k = \\kappa = 0.5$.\n\n- Test Case $1$ (\"balanced library sizes\"):\n  - Library sizes $L = [\\,10000,\\,10000,\\,10000,\\,10000\\,]$.\n  - Counts matrix $Y$ with genes as rows and samples as columns:\n    $$ Y = \\begin{bmatrix}\n    100 & 100 & 200 & 200 \\\\\n    250 & 250 & 120 & 120 \\\\\n    150 & 150 & 150 & 150 \\\\\n    5 & 5 & 20 & 20\n    \\end{bmatrix}. $$\n\n- Test Case $2$ (\"imbalanced library sizes\"):\n  - Library sizes $L = [\\,5000,\\,20000,\\,8000,\\,35000\\,]$.\n  - Counts matrix $Y$:\n    $$ Y = \\begin{bmatrix}\n    50 & 200 & 160 & 700 \\\\\n    125 & 500 & 96 & 420 \\\\\n    75 & 300 & 120 & 525 \\\\\n    3 & 10 & 16 & 70\n    \\end{bmatrix}. $$\n\n- Test Case $3$ (\"zero-inflated edge case\"):\n  - Library sizes $L = [\\,6000,\\,4000,\\,5000,\\,7000\\,]$.\n  - Counts matrix $Y$:\n    $$ Y = \\begin{bmatrix}\n    60 & 40 & 50 & 70 \\\\\n    120 & 80 & 25 & 35 \\\\\n    0 & 0 & 8 & 11 \\\\\n    6 & 4 & 0 & 0\n    \\end{bmatrix}. $$\n\nFinal output specification:\n- For each test case, produce a list $[\\,\\rho,\\,\\Delta_{\\max},\\,f_{\\mathrm{agree}}\\,]$, where $\\rho$ is the Spearman correlation coefficient, $\\Delta_{\\max}$ is the maximum absolute difference, and $f_{\\mathrm{agree}}$ is the fraction of sign agreement. Express all three quantities as decimal floats. There are no physical units or angle units involved.\n- Your program should produce a single line of output containing the results for the three test cases as a comma-separated list enclosed in square brackets, with each test case represented by its own bracketed list, for example, $[\\, [\\,\\rho_1,\\,\\Delta_{\\max,1},\\,f_{\\mathrm{agree},1}\\,], [\\,\\rho_2,\\,\\Delta_{\\max,2},\\,f_{\\mathrm{agree},2}\\,], [\\,\\rho_3,\\,\\Delta_{\\max,3},\\,f_{\\mathrm{agree},3}\\,] \\,]$.",
            "solution": "The problem is assessed to be valid. It is scientifically grounded in the common bioinformatics task of differential expression analysis, comparing two standard-yet-distinct methodologies. The problem is well-posed, providing all necessary mathematical definitions and data to compute a unique, verifiable numerical result. The language is objective and the setup is self-contained and consistent.\n\nThe task is to compare two methods for calculating differential expression effect sizes from RNA sequencing count data: a centered log-ratio (CLR) approach derived from compositional data analysis, and a Negative Binomial (NB) model-based approach. The comparison will be performed on three distinct test cases designed to highlight the differences between the methods under varying library size conditions and data sparsity. The contrast will be quantified using Spearman correlation, maximum absolute difference, and the fraction of sign agreement.\n\nLet us denote the count matrix by $Y \\in \\mathbb{N}_0^{G \\times S}$, where $G$ is the number of genes and $S$ is the number of samples. The count for gene $g$ in sample $s$ is $y_{gs}$. The library sizes are given by the vector $L \\in \\mathbb{R}_+^S$, and condition labels by $c \\in \\{0, 1\\}^S$. For all test cases, $c = [\\,0, 0, 1, 1\\,]$, so samples $1$ and $2$ belong to condition A ($c_s=0$) and samples $3$ and $4$ to condition B ($c_s=1$). The number of samples in condition A is $S_A=2$ and in condition B is $S_B=2$. The pseudocounts are fixed at $k=0.5$ and $\\kappa=0.5$.\n\n### Step 1: Centered Log-Ratio (CLR) Effect Sizes ($d_g$)\n\nThe CLR approach treats the count data for each sample as a composition, where only the relative proportions of genes matter. To handle zeros and apply logarithms, a pseudocount $k$ is added to all counts. The data is then transformed using the centered log-ratio, which normalizes the log-transformed counts of a gene by subtracting the average log-count across all genes within the same sample. This makes the data independent of the sample's total count or library size, focusing purely on internal composition.\n\nFor each sample $s$, the vector of CLR-transformed values $\\{r_{gs}\\}_{g=1}^G$ is computed.\nFirst, a pseudocount $k$ is added and the natural logarithm is taken: $Y'_{gs} = \\log(y_{gs} + k)$.\nThen, the per-sample geometric mean of the pseudo-counted values is computed in the log domain, which is equivalent to the arithmetic mean of the log-transformed values:\n$$ \\bar{Y}'_s = \\frac{1}{G} \\sum_{g'=1}^{G} \\log(y_{g's} + k) $$\nThe CLR value for gene $g$ in sample $s$ is the deviation from this per-sample mean:\n$$ r_{gs} = \\log(y_{gs} + k) - \\bar{Y}'_s $$\nThe differential expression effect size $d_g$ for gene $g$ is the difference between the average CLR value in condition B and the average in condition A:\n$$ d_g = \\left(\\frac{1}{S_B} \\sum_{s: c_s = 1} r_{gs}\\right) - \\left(\\frac{1}{S_A} \\sum_{s: c_s = 0} r_{gs}\\right) $$\nThis calculation is performed for each gene $g=1, \\dots, G$.\n\n### Step 2: Negative Binomial (NB) Based Effect Sizes ($e_g$)\n\nThe NB approach explicitly models the library size $L_s$ as a scaling factor for an underlying mean rate $q_{g,c}$ specific to each gene and condition. The expected count is $\\mathbb{E}[y_{gs}] = L_s \\, q_{g,c_s}$. This model assumes that differences in library size are the primary driver of count differences for non-differentially expressed genes.\n\nThe mean rates for each condition, $\\hat{q}_{g,A}$ and $\\hat{q}_{g,B}$, are estimated by pooling data across replicates. The estimator is the ratio of the total counts for a gene to the total library sizes for all samples in that condition. A small pseudocount $\\kappa$ is added to the total counts to stabilize estimates, particularly when total counts are low or zero.\n$$ \\hat{q}_{g,A} = \\frac{\\left(\\sum_{s: c_s = 0} y_{gs}\\right) + \\kappa}{\\sum_{s: c_s = 0} L_s}, \\quad \\hat{q}_{g,B} = \\frac{\\left(\\sum_{s: c_s = 1} y_{gs}\\right) + \\kappa}{\\sum_{s: c_s = 1} L_s} $$\nThe NB-based effect size $e_g$ is the natural logarithm of the fold change between these estimated rates:\n$$ e_g = \\log\\left( \\frac{\\hat{q}_{g,B}}{\\hat{q}_{g,A}} \\right) = \\log(\\hat{q}_{g,B}) - \\log(\\hat{q}_{g,A}) $$\nThis calculation is performed for each gene $g=1, \\dots, G$. This effect size is commonly referred to as a log-fold change (LFC).\n\n### Step 3: Contrast Quantification\n\nThe programmatic task is to compute the two vectors of effect sizes, $\\{d_g\\}_{g=1}^G$ and $\\{e_g\\}_{g=1}^G$, and then quantify their relationship using three metrics:\n\n1.  **Spearman Rank Correlation ($\\rho$)**: This non-parametric correlation coefficient measures the strength and direction of the monotonic relationship between the two sets of effect sizes. It assesses whether the two methods tend to rank genes in a similar order of differential expression. A value of $\\rho = 1$ indicates perfect monotonic agreement, $\\rho = -1$ indicates perfect inverse monotonic agreement, and $\\rho = 0$ indicates no monotonic relationship. It is computed on the ranks of the data, making it robust to outliers and non-linear relationships.\n\n2.  **Maximum Absolute Difference ($\\Delta_{\\max}$)**: This metric quantifies the worst-case disagreement between the two methods in terms of the magnitude of the effect size. It is defined as:\n    $$ \\Delta_{\\max} = \\max_{g} \\left| d_g - e_g \\right| $$\n    A small $\\Delta_{\\max}$ indicates that the effect sizes are numerically close across all genes, while a large value signals at least one gene for which the methods produce substantially different quantitative results.\n\n3.  **Fraction of Sign Agreement ($f_{\\mathrm{agree}}$)**: This metric measures how often the two methods agree on the direction of differential expression (i.e., up-regulated, down-regulated, or unchanged). It is computed as:\n    $$ f_{\\mathrm{agree}} = \\frac{1}{G} \\sum_{g=1}^{G} \\mathbf{1}\\left[ \\mathrm{sgn}(d_g) = \\mathrm{sgn}(e_g) \\right] $$\n    where $\\mathrm{sgn}(\\cdot)$ is the sign function. A value of $f_{\\mathrm{agree}} = 1$ means the methods never disagree on whether a gene's expression has increased, decreased, or remained unchanged between conditions.\n\nThe procedure will be applied to each of the three test cases, and the resulting list of $[\\,\\rho, \\Delta_{\\max}, f_{\\mathrm{agree}}\\,]$ for each case will be aggregated into the final output. The test cases are designed to probe the methods' behavior under balanced library sizes (Case $1$), imbalanced library sizes where within-condition composition is constant (Case $2$), and sparse data with zeros (Case $3$), which can challenge the assumptions of both methods and the role of pseudocounts.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.stats import spearmanr\n\ndef solve():\n    \"\"\"\n    Solves the differential expression comparison problem for the given test cases.\n    \"\"\"\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        {\n            \"name\": \"balanced library sizes\",\n            \"Y\": np.array([\n                [100, 100, 200, 200],\n                [250, 250, 120, 120],\n                [150, 150, 150, 150],\n                [5, 5, 20, 20]\n            ]),\n            \"L\": np.array([10000, 10000, 10000, 10000]),\n        },\n        {\n            \"name\": \"imbalanced library sizes\",\n            \"Y\": np.array([\n                [50, 200, 160, 700],\n                [125, 500, 96, 420],\n                [75, 300, 120, 525],\n                [3, 10, 16, 70]\n            ]),\n            \"L\": np.array([5000, 20000, 8000, 35000]),\n        },\n        {\n            \"name\": \"zero-inflated edge case\",\n            \"Y\": np.array([\n                [60, 40, 50, 70],\n                [120, 80, 25, 35],\n                [0, 0, 8, 11],\n                [6, 4, 0, 0]\n            ]),\n            \"L\": np.array([6000, 4000, 5000, 7000]),\n        },\n    ]\n\n    # Global parameters\n    conditions = np.array([0, 0, 1, 1])\n    pseudocount_k = 0.5\n    pseudocount_kappa = 0.5\n\n    all_results = []\n\n    for case in test_cases:\n        Y = case[\"Y\"]\n        L = case[\"L\"]\n        G, S = Y.shape\n\n        # Identify samples for each condition\n        is_cond_A = (conditions == 0)\n        is_cond_B = (conditions == 1)\n        S_A = np.sum(is_cond_A)\n        S_B = np.sum(is_cond_B)\n\n        # 1. Compute log-ratio effect sizes (d_g)\n        Y_plus_k = Y + pseudocount_k\n        log_Y_plus_k = np.log(Y_plus_k)\n        \n        # Per-sample geometric mean of log-counts\n        geom_mean_log = np.mean(log_Y_plus_k, axis=0)\n        \n        # Centered log-ratio matrix r_gs\n        r_gs = log_Y_plus_k - geom_mean_log\n        \n        # Mean r_gs per condition\n        mean_r_A = np.mean(r_gs[:, is_cond_A], axis=1)\n        mean_r_B = np.mean(r_gs[:, is_cond_B], axis=1)\n        \n        d_g = mean_r_B - mean_r_A\n\n        # 2. Compute Negative Binomial-based effect sizes (e_g)\n        # Sum counts and library sizes per condition\n        sum_Y_A = np.sum(Y[:, is_cond_A], axis=1)\n        sum_L_A = np.sum(L[is_cond_A])\n        \n        sum_Y_B = np.sum(Y[:, is_cond_B], axis=1)\n        sum_L_B = np.sum(L[is_cond_B])\n\n        # Estimate per-condition mean rates\n        q_g_A = (sum_Y_A + pseudocount_kappa) / sum_L_A\n        q_g_B = (sum_Y_B + pseudocount_kappa) / sum_L_B\n\n        # NB-based effect size\n        e_g = np.log(q_g_B / q_g_A)\n        \n        # 3. Quantify the contrast\n        # Spearman correlation\n        # If variance is zero, spearmanr returns nan. For this problem context,\n        # if all effect sizes are identical, their ranks are tied, implying perfect correlation.\n        if np.all(d_g == d_g[0]) and np.all(e_g == e_g[0]):\n            rho = 1.0\n        else:\n            rho, _ = spearmanr(d_g, e_g)\n            # Handle potential NaN if one vector is constant\n            if np.isnan(rho):\n                rho = 1.0 if (np.var(d_g) == 0 and np.var(e_g) == 0) else 0.0\n\n        # Maximum absolute difference\n        delta_max = np.max(np.abs(d_g - e_g))\n        \n        # Fraction of sign agreement\n        sign_d = np.sign(d_g)\n        sign_e = np.sign(e_g)\n        f_agree = np.mean(sign_d == sign_e)\n\n        # Store results for this case\n        case_results = [rho, delta_max, f_agree]\n        all_results.append(case_results)\n\n    # Final print statement in the exact required format.\n    # The format requires string representation of the inner lists.\n    results_str = [f\"[{r[0]},{r[1]},{r[2]}]\" for r in all_results]\n    print(f\"[{','.join(results_str)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "A sophisticated model does not treat all data as equal; it accounts for the quality and uncertainty inherent in the measurements. This advanced problem demonstrates how to propagate uncertainty from low-level data quality metrics—specifically, alignment quality from sequencing—into the parameter estimates of a mechanistic model using a Bayesian framework . By calculating the posterior variance of a transcription rate parameter, $k_t$, you will learn how to make your models more robust and your parameter estimates more credible by formally integrating data reliability.",
            "id": "3924210",
            "problem": "A synthetic biology model integrates transcriptome-level observations into a mechanistic ordinary differential equation for gene expression. Under steady state of transcription and degradation, the messenger ribonucleic acid (mRNA) abundance for a gene is modeled by $x = k_{t}/d$, where $x$ is the steady-state mRNA abundance in molecules, $k_{t}$ is the transcription rate in molecules per minute, and $d$ is the first-order degradation rate in per minute. An RNA sequencing (RNA-seq) assay provides aligned reads to this gene with alignment quality summaries derived from the Sequence Alignment/Map specification, including Mapping Quality (MAPQ). The mapping quality score $Q$ is defined such that the probability of an incorrect alignment is $P_{\\mathrm{wrong}} = 10^{-Q/10}$.\n\nAssume the following:\n- The total number of reads aligned to the gene is $N = 3000$.\n- The average per-base mismatch rate across aligned reads is $m = 0.02$.\n- The average Mapping Quality (MAPQ) score is $Q = 25$, so $P_{\\mathrm{wrong}} = 10^{-Q/10}$.\n- Treat the effective information content of a read as reduced multiplicatively by mismatch and incorrect-mapping probabilities, with a reliability weight $w = (1 - m)\\,(1 - P_{\\mathrm{wrong}})$. The effective number of reliable reads is $N_{\\mathrm{eff}} = wN$.\n- Counts are modeled as Poisson, and the expression estimator $\\hat{x}$ (in molecules) is obtained by a fixed conversion factor $\\phi = 2$ counts per molecule, so that the measurement variance can be approximated by $\\sigma^{2} = N_{\\mathrm{eff}}/\\phi^{2}$ via a Poisson-to-Normal approximation.\n- The degradation rate is known and equal to $d = 0.05\\,\\mathrm{min}^{-1}$.\n- The transcription rate parameter has a Gaussian prior $k_{t} \\sim \\mathcal{N}(\\mu_{0}, \\tau_{0}^{2})$ with $\\mu_{0} = 50$ molecules per minute and $\\tau_{0}^{2} = 100\\,(\\mathrm{molecules\\, per\\, minute})^{2}$.\n- The observation model is $\\hat{x} \\sim \\mathcal{N}(x, \\sigma^{2})$ with $x = k_{t}/d$.\n\nFrom first principles, use the above definitions and assumptions to derive the posterior variance of $k_{t}$ under the Gaussian prior and Gaussian likelihood implied by the linear mapping $x = k_{t}/d$ and the measurement error variance $\\sigma^{2}$ determined by the alignment quality metrics. Compute the numerical value of the posterior variance and express your final answer in $(\\mathrm{molecules\\, per\\, minute})^{2}$. Round your answer to four significant figures.",
            "solution": "The problem requires the derivation of the posterior variance of the transcription rate parameter, $k_t$, using a Bayesian framework. The solution involves combining a Gaussian prior with a Gaussian likelihood derived from the experimental observation.\n\nFirst, let us establish the statistical model. The parameter of interest is the transcription rate, $k_t$. The prior belief about this parameter is given as a Gaussian distribution:\n$$k_{t} \\sim \\mathcal{N}(\\mu_{0}, \\tau_{0}^{2})$$\nwhere the prior mean is $\\mu_{0} = 50$ molecules per minute and the prior variance is $\\tau_{0}^{2} = 100\\,(\\mathrm{molecules/min})^{2}$. The prior probability density function is therefore:\n$$p(k_t) = \\frac{1}{\\sqrt{2\\pi\\tau_{0}^{2}}} \\exp\\left(-\\frac{(k_t - \\mu_0)^2}{2\\tau_0^2}\\right)$$\n\nThe experimental observation is an estimate of the mRNA abundance, $\\hat{x}$. The observation model is given as a Gaussian distribution centered on the true steady-state abundance, $x$:\n$$\\hat{x} \\sim \\mathcal{N}(x, \\sigma^{2})$$\nThe true abundance $x$ is related to the transcription rate $k_t$ and degradation rate $d$ by the steady-state equation $x = k_t/d$. Substituting this into the observation model, we obtain the distribution of $\\hat{x}$ conditional on $k_t$:\n$$\\hat{x} | k_t \\sim \\mathcal{N}(k_t/d, \\sigma^{2})$$\nThe likelihood function, $L(k_t; \\hat{x})$, is the probability of observing $\\hat{x}$ for a given value of $k_t$. This is given by the probability density function of the above distribution, but viewed as a function of $k_t$:\n$$p(\\hat{x} | k_t) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}} \\exp\\left(-\\frac{(\\hat{x} - k_t/d)^2}{2\\sigma^2}\\right)$$\n\nAccording to Bayes' theorem, the posterior distribution of $k_t$ is proportional to the product of the prior distribution and the likelihood function:\n$$p(k_t | \\hat{x}) \\propto p(\\hat{x} | k_t) p(k_t)$$\nSubstituting the expressions for the prior and likelihood:\n$$p(k_t | \\hat{x}) \\propto \\exp\\left(-\\frac{(\\hat{x} - k_t/d)^2}{2\\sigma^2}\\right) \\exp\\left(-\\frac{(k_t - \\mu_0)^2}{2\\tau_0^2}\\right)$$\nSince the product of two Gaussian functions is another Gaussian function (unnormalized), the posterior distribution for $k_t$ will also be Gaussian, which we can write as $p(k_t | \\hat{x}) = \\mathcal{N}(k_t | \\mu_{\\text{post}}, \\tau_{\\text{post}}^2)$.\n\nTo find the posterior variance, $\\tau_{\\text{post}}^2$, it is most convenient to work with precisions (inverse variances). The precision of a Gaussian distribution $\\mathcal{N}(\\mu, \\sigma^2)$ is $1/\\sigma^2$. The posterior precision is the sum of the prior precision and the precision of the likelihood.\nThe prior precision is clearly $1/\\tau_0^2$. To find the precision from the likelihood, we must rewrite the likelihood's exponent as a quadratic function of $k_t$:\n$$-\\frac{(\\hat{x} - k_t/d)^2}{2\\sigma^2} = -\\frac{(1/d)^2(d\\hat{x} - k_t)^2}{2\\sigma^2} = -\\frac{(k_t - d\\hat{x})^2}{2d^2\\sigma^2}$$\nThis form reveals that the likelihood, as a function of $k_t$, corresponds to a Gaussian distribution centered at $d\\hat{x}$ with a variance of $d^2\\sigma^2$. Thus, the precision contributed by the likelihood is $1/(d^2\\sigma^2)$.\n\nThe posterior precision, $1/\\tau_{\\text{post}}^2$, is the sum of the prior and likelihood precisions:\n$$\\frac{1}{\\tau_{\\text{post}}^2} = \\frac{1}{\\tau_0^2} + \\frac{1}{d^2\\sigma^2}$$\nFrom this, the posterior variance is:\n$$\\tau_{\\text{post}}^2 = \\left(\\frac{1}{\\tau_0^2} + \\frac{1}{d^2\\sigma^2}\\right)^{-1}$$\n\nNext, we must calculate the value of the measurement variance, $\\sigma^2$, from the provided alignment quality metrics.\nGiven values are: total reads $N = 3000$, average Mapping Quality $Q = 25$, and average per-base mismatch rate $m = 0.02$.\nThe probability of an incorrect alignment is $P_{\\mathrm{wrong}} = 10^{-Q/10}$.\n$$P_{\\mathrm{wrong}} = 10^{-25/10} = 10^{-2.5}$$\nThe reliability weight $w$ is defined as $w = (1 - m)(1 - P_{\\mathrm{wrong}})$.\n$$w = (1 - 0.02)(1 - 10^{-2.5}) = 0.98 \\times (1 - 10^{-2.5})$$\nThe effective number of reliable reads is $N_{\\mathrm{eff}} = wN$.\n$$N_{\\mathrm{eff}} = (0.98 \\times (1 - 10^{-2.5})) \\times 3000$$\nThe measurement variance $\\sigma^2$ is given by $\\sigma^2 = N_{\\mathrm{eff}}/\\phi^2$, with the conversion factor $\\phi = 2$.\n$$\\sigma^2 = \\frac{0.98 \\times (1 - 10^{-2.5}) \\times 3000}{2^2} = 0.98 \\times (1 - 10^{-2.5}) \\times 750$$\nLet's compute the numerical value for $\\sigma^2$:\n$10^{-2.5} \\approx 0.00316228$\n$1 - 10^{-2.5} \\approx 0.99683772$\n$w \\approx 0.98 \\times 0.99683772 \\approx 0.97690097$\n$N_{\\mathrm{eff}} \\approx 0.97690097 \\times 3000 \\approx 2930.7029$\n$$\\sigma^2 = \\frac{N_{\\mathrm{eff}}}{4} \\approx \\frac{2930.7029}{4} \\approx 732.6757\\,(\\mathrm{molecules})^2$$\n\nNow we have all the components to calculate the posterior variance $\\tau_{\\text{post}}^2$. The given values for the prior and the model are $\\tau_0^2 = 100\\,(\\mathrm{molecules/min})^2$ and $d = 0.05\\,\\mathrm{min}^{-1}$.\nSubstituting into the formula for the posterior variance:\n$$\\tau_{\\text{post}}^2 = \\left(\\frac{1}{100} + \\frac{1}{(0.05)^2 \\times \\sigma^2}\\right)^{-1}$$\nFirst, compute the denominator term for the likelihood's contribution:\n$$d^2\\sigma^2 = (0.05)^2 \\times 732.6757 = 0.0025 \\times 732.6757 \\approx 1.831689\\,(\\mathrm{molecules/min})^2$$\nNow, substitute this into the expression for $\\tau_{\\text{post}}^2$:\n$$\\tau_{\\text{post}}^2 = \\left(\\frac{1}{100} + \\frac{1}{1.831689}\\right)^{-1}$$\n$$\\tau_{\\text{post}}^2 = (0.01 + 0.545945)^{-1}$$\n$$\\tau_{\\text{post}}^2 = (0.555945)^{-1} \\approx 1.798730\\,(\\mathrm{molecules/min})^2$$\n\nRounding the final result to four significant figures, as requested, we get:\n$$\\tau_{\\text{post}}^2 \\approx 1.799\\,(\\mathrm{molecules\\, per\\, minute})^{2}$$\nThis value represents the updated variance (a measure of uncertainty) of the transcription rate parameter $k_t$ after incorporating the RNA-seq measurement, which provides much more information than the prior alone, resulting in a significant reduction in variance from the prior value of $100$ to the posterior value of approximately $1.8$.",
            "answer": "$$\\boxed{1.799}$$"
        }
    ]
}