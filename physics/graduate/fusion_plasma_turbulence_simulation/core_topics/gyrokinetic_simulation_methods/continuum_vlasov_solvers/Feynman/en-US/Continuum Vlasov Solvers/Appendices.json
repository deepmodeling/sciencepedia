{
    "hands_on_practices": [
        {
            "introduction": "A fundamental property of a particle distribution function, $f$, is that it must be non-negative. However, high-order numerical schemes used in continuum Vlasov solvers to achieve accuracy can violate this physical constraint, producing unphysical negative values, especially near sharp gradients. This exercise provides a hands-on test bed to explore this challenge by implementing and evaluating a positivity-preserving limiter, a critical algorithm that intelligently blends high-accuracy and stable low-order methods to ensure physical realism without sacrificing excessive accuracy .",
            "id": "4184958",
            "problem": "Consider the one-dimensional, velocity-space form of the Vlasov equation for a species with a constant acceleration due to a uniform electric field, which in a spatially homogeneous setting reduces to the linear advection equation in velocity space, namely $ \\partial_t f + a \\, \\partial_v f = 0 $, where $ f(v,t) $ is the distribution function, $ v $ is the velocity variable, and $ a $ is the constant advection speed in $ v $-space. In the continuum (Eulerian) setting, semi-Lagrangian updates along characteristics are widely used to avoid restrictive time-step constraints, but high-order polynomial interpolation during characteristic tracing may introduce negative undershoots when $ f(v,t) $ has sharp gradients or discontinuities. Such violations of non-negativity are unphysical in distribution functions and must be controlled by limiters that preserve positivity while attempting to retain accuracy.\n\nYour task is to construct a scientifically sound test that challenges positivity under strong $ v $-space advection and to algorithmically evaluate a positivity-preserving limiter. The test is defined on a periodic velocity domain $ v \\in [v_{\\min}, v_{\\max}) $ with $ v_{\\min} = -6 $, $ v_{\\max} = 6 $, resolved by a uniform grid of $ N = 256 $ points with spacing $ \\Delta v = (v_{\\max} - v_{\\min})/N $. The initial condition is a composite, strictly non-negative distribution designed to have sharp features:\n- A top-hat component of amplitude $ A_1 = 1 $ centered at $ v_c = 0 $ with half-width $ w = 1 $, i.e., $ f_{\\text{hat}}(v) = A_1 $ for $ |v - v_c| \\le w $ and $ f_{\\text{hat}}(v) = 0 $ otherwise.\n- A narrow Gaussian bump $ f_{\\text{bump}}(v) = A_2 \\exp\\!\\big(-\\tfrac{(v - v_b)^2}{2 \\sigma_b^2}\\big) $ with $ A_2 = 0.5 $, $ v_b = 2.7 $, and $ \\sigma_b = 0.06 $.\nThe full initial condition is $ f_0(v) = f_{\\text{hat}}(v) + f_{\\text{bump}}(v) $, which is continuous except for the top-hat edges at $ v = \\pm 1 $.\n\nUse a semi-Lagrangian characteristic update for a single time step $ \\Delta t $: the exact solution after one step is the shifted function $ f(v, \\Delta t) = f_0(v - a \\Delta t) $. Implement two numerical update variants mapping $ f_0 $ to $ f^{n+1} $ at the grid nodes by interpolating $ f^n $ to the characteristic feet:\n- A high-order cubic (four-point) Catmull–Rom interpolation for $ f_{\\text{HO}}(v_i) $ that may overshoot and produce $ f_{\\text{HO}}(v_i) < 0 $ at sharp features.\n- A low-order linear interpolation for $ f_{\\text{LO}}(v_i) $ that is monotone between adjacent grid values and preserves non-negativity provided both endpoints are non-negative.\n\nDesign and evaluate a positivity-preserving limiter constructed as a convex combination between the high-order and low-order updates to ensure $ f(v_i) \\ge \\varepsilon $ with $ \\varepsilon = 10^{-14} $ while deviating minimally from $ f_{\\text{HO}} $. That is, for each grid point, select a convex weight in $ [0,1] $ that blends $ f_{\\text{HO}} $ and $ f_{\\text{LO}} $ only when necessary to enforce non-negativity. The evaluation must quantify:\n- The minimum value $ \\min_i f^{n+1}_i $,\n- The absolute mass error $ \\big|\\sum_i f^{n+1}_i \\Delta v - \\sum_i f^n_i \\Delta v \\big| $,\n- The relative $ L^1 $ error $ \\frac{\\sum_i | f^{n+1}_i - f_{\\text{exact}}(v_i) | \\Delta v}{\\sum_i | f_{\\text{exact}}(v_i) | \\Delta v} $,\nwith $ f_{\\text{exact}}(v) = f_0(v - a \\Delta t) $. All quantities are dimensionless.\n\nImplement the above in a single program that carries out one time step for each test case in the following test suite:\n- Case $ 1 $ (happy path near the stability boundary): $ a = 5 $, choose $ \\Delta t $ such that the characteristic shift equals $ 0.9 \\, \\Delta v $, i.e., $ a \\Delta t = 0.9 \\, \\Delta v $.\n- Case $ 2 $ (strong advection across multiple cells): $ a = 5 $, choose $ \\Delta t $ such that the shift equals $ 3.7 \\, \\Delta v $, i.e., $ a \\Delta t = 3.7 \\, \\Delta v $.\n- Case $ 3 $ (very strong advection with substantial wrap-around): $ a = 17 $, choose $ \\Delta t $ such that the shift equals $ 15.3 \\, \\Delta v $, i.e., $ a \\Delta t = 15.3 \\, \\Delta v $.\n\nFor each case, compute the three metrics above for the un-limited high-order update and for the positivity-limited update. Your program should produce a single line of output containing all results aggregated as a comma-separated list enclosed in square brackets, in the order:\n$ [ \\min_{\\text{no}}, \\min_{\\text{lim}}, \\text{massErr}_{\\text{no}}, \\text{massErr}_{\\text{lim}}, L^1_{\\text{no}}, L^1_{\\text{lim}}, \\ldots ] $\nfor the three cases concatenated sequentially. All outputs must be floating-point numbers without units, using the dimensionless normalization defined above.",
            "solution": "The problem statement has been critically examined and is determined to be **valid**. It presents a well-posed, scientifically grounded numerical experiment that is directly relevant to the field of computational plasma physics, specifically concerning continuum Vlasov solvers. All parameters, methods, and evaluation criteria are defined with sufficient precision to permit a unique and verifiable solution.\n\nThe core of the problem is to solve the one-dimensional linear advection equation in velocity space,\n$$\n\\partial_t f + a \\, \\partial_v f = 0\n$$\nwhere $f(v, t)$ is the particle distribution function, $v$ is velocity, $t$ is time, and $a$ is a constant acceleration. This equation describes the evolution of a spatially homogeneous plasma under a uniform electric field. The domain is periodic in velocity, $v \\in [v_{\\min}, v_{\\max})$.\n\nThe exact solution to this equation can be found using the method of characteristics. The characteristic curves are lines in the $(v,t)$-plane defined by $\\frac{dv}{dt} = a$, which integrate to $v(t) = v_0 + at$. Along these characteristics, the distribution function is constant: $f(v(t), t) = f(v_0, 0)$. Thus, the exact solution at time $\\Delta t$ is a simple rigid shift of the initial profile $f_0(v)$:\n$$\nf(v, \\Delta t) = f_0(v - a \\Delta t)\n$$\n\nThe numerical task involves implementing a semi-Lagrangian scheme on a uniform grid $v_i = v_{\\min} + i \\Delta v$ for $i=0, \\dots, N-1$, where $\\Delta v = (v_{\\max} - v_{\\min})/N$. At each time step, the new values $f_i^{n+1}$ on the grid are computed by tracing the characteristics backward in time by one step, $\\Delta t$, from each grid point $v_i$. The new value is the value of the distribution at the previous time, $f^n$, evaluated at the characteristic foot, $v_i - a \\Delta t$.\n$$\nf_i^{n+1} = f^n(v_i - a \\Delta t)\n$$\nSince the foot $v_p = v_i - a \\Delta t$ does not generally coincide with a grid point, its value must be obtained by interpolating the known grid values $\\{f_j^n\\}$. The periodic boundary conditions are handled by wrapping the coordinate of any characteristic foot that falls outside $[v_{\\min}, v_{\\max})$ back into the domain.\n\nWe will implement and compare two interpolation schemes:\n1.  **Low-Order (LO) Linear Interpolation**: For a point $v_p$ between grid nodes $v_j$ and $v_{j+1}$, the value is a weighted average: $f_{\\text{LO}}(v_p) = (1-\\alpha)f_j + \\alpha f_{j+1}$, where $\\alpha = (v_p - v_j)/\\Delta v$. This scheme is inherently positivity-preserving if the original data points $f_j$ and $f_{j+1}$ are non-negative, as $\\alpha \\in [0,1]$.\n2.  **High-Order (HO) Catmull–Rom Interpolation**: This is a four-point cubic interpolation scheme that offers higher accuracy but is not guaranteed to be monotone. It can introduce spurious oscillations (overshoots and undershoots) near sharp gradients, potentially leading to unphysical negative values for $f$. For a point $v_p$ between $v_j$ and $v_{j+1}$ with fractional distance $\\alpha$, the interpolated value is given by the polynomial:\n    $$\n    f_{\\text{HO}}(v_p) = c_3 \\alpha^3 + c_2 \\alpha^2 + c_1 \\alpha + c_0\n    $$\n    where the coefficients are functions of the four grid values $f_{j-1}, f_j, f_{j+1}, f_{j+2}$:\n    $c_0 = f_j$, $c_1 = \\frac{1}{2}(-f_{j-1} + f_{j+1})$, $c_2 = f_{j-1} - \\frac{5}{2}f_j + 2f_{j+1} - \\frac{1}{2}f_{j+2}$, and $c_3 = -\\frac{1}{2}f_{j-1} + \\frac{3}{2}f_j - \\frac{3}{2}f_{j+1} + \\frac{1}{2}f_{j+2}$.\n\nTo rectify the non-negativity violation of the high-order scheme, a positivity-preserving limiter is designed. The limiter constructs a new solution, $f_{\\text{lim}}$, as a convex combination of the high-order and low-order solutions, $f_{\\text{HO}}$ and $f_{\\text{LO}}$. The goal is to enforce $f_{\\text{lim}, i} \\ge \\varepsilon$ at every grid point $v_i$, where $\\varepsilon = 10^{-14}$ is a small positive floor, while deviating minimally from the more accurate $f_{\\text{HO}, i}$.\n\nThe algorithmic logic for the limiter at each grid point $v_i$ is as follows:\n1.  Compute both $f_{\\text{HO}, i}$ and $f_{\\text{LO}, i}$.\n2.  If $f_{\\text{HO}, i} \\ge \\varepsilon$, no correction is needed. We retain the high-order result: $f_{\\text{lim}, i} = f_{\\text{HO}, i}$.\n3.  If $f_{\\text{HO}, i} < \\varepsilon$, a correction is necessary. We must find a value on the line segment between $f_{\\text{LO}, i}$ and $f_{\\text{HO}, i}$ that satisfies the positivity constraint and is closest to $f_{\\text{HO}, i}$.\n    - If $f_{\\text{LO}, i} \\ge \\varepsilon$, a range of valid convex combinations exists. The minimal correction that satisfies the constraint sets the limited value to be exactly the floor: $f_{\\text{lim}, i} = \\varepsilon$. This corresponds to finding the minimal blend of $f_{\\text{LO}}$ required to lift the negative $f_{\\text{HO}}$ value up to $\\varepsilon$.\n    - If $f_{\\text{LO}, i} < \\varepsilon$, even the \"safe\" low-order scheme fails to meet the threshold. In this case, no convex combination of $f_{\\text{HO}, i}$ and $f_{\\text{LO}, i}$ can be greater than or equal to $\\varepsilon$ (assuming $f_{\\text{HO}, i} \\le f_{\\text{LO}, i}$ or that $f_{HO}$ represents an undershoot). The most reasonable action is to accept the monotone, low-order result as a fallback: $f_{\\text{lim}, i} = f_{\\text{LO}, i}$.\n\nThis procedure defines the final limited solution $f_{\\text{lim}}$. The performance of the unlimited high-order scheme and the limited scheme will be evaluated using three metrics, calculated after a single time step from the initial condition $f_0(v)$:\n1.  **Minimum value**: $\\min_i f_i^{n+1}$. This directly tests the positivity-preserving property.\n2.  **Absolute mass error**: $|\\sum_i f_i^{n+1} \\Delta v - \\sum_i f_i^n \\Delta v|$. The exact advection conserves mass ($\\int f dv$), so this metric quantifies the numerical scheme's conservation property.\n3.  **Relative $L^1$ error**: $\\frac{\\sum_i |f_i^{n+1} - f_{\\text{exact}}(v_i)| \\Delta v}{\\sum_i |f_{\\text{exact}}(v_i)| \\Delta v}$. This measures the accuracy of the numerical solution against the known exact solution, $f_{\\text{exact}}(v) = f_0(v - a \\Delta t)$.\n\nThe following program implements this entire procedure for the three specified test cases, computing and reporting the six requested quantities for each case.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Implements and evaluates a positivity-preserving limiter for a semi-Lagrangian\n    Vlasov solver in 1D velocity space.\n    \"\"\"\n\n    # --- Problem Constants and Grid Setup ---\n    V_MIN = -6.0\n    V_MAX = 6.0\n    N = 256\n    EPSILON = 1e-14\n    DV = (V_MAX - V_MIN) / N\n    V_GRID = np.linspace(V_MIN, V_MAX, N, endpoint=False)\n\n    def initial_condition(v: np.ndarray) -> np.ndarray:\n        \"\"\"Computes the initial distribution function f_0(v).\"\"\"\n        # Top-hat component\n        A1 = 1.0\n        vc = 0.0\n        w = 1.0\n        f_hat = np.where(np.abs(v - vc) <= w, A1, 0.0)\n\n        # Gaussian bump component\n        A2 = 0.5\n        vb = 2.7\n        sigma_b = 0.06\n        f_bump = A2 * np.exp(-(v - vb)**2 / (2 * sigma_b**2))\n\n        return f_hat + f_bump\n\n    def linear_interp_advect(f_n: np.ndarray, shift_val: float) -> np.ndarray:\n        \"\"\"Advects f_n using semi-Lagrangian scheme with linear interpolation.\"\"\"\n        feet_v = V_GRID - shift_val\n        # Normalize coordinates to grid index units and handle periodicity\n        feet_s = ((feet_v - V_MIN) / DV) % N\n        \n        j0 = np.floor(feet_s).astype(int)\n        alpha = feet_s - j0\n        j1 = (j0 + 1) % N\n        \n        f_next = (1.0 - alpha) * f_n[j0] + alpha * f_n[j1]\n        return f_next\n\n    def catmull_rom_interp_advect(f_n: np.ndarray, shift_val: float) -> np.ndarray:\n        \"\"\"Advects f_n using semi-Lagrangian scheme with Catmull-Rom interpolation.\"\"\"\n        feet_v = V_GRID - shift_val\n        # Normalize coordinates to grid index units and handle periodicity\n        feet_s = ((feet_v - V_MIN) / DV) % N\n\n        j1 = np.floor(feet_s).astype(int)\n        alpha = feet_s - j1\n\n        # Get the 4 required points with periodic boundaries\n        j0 = (j1 - 1 + N) % N\n        j2 = (j1 + 1) % N\n        j3 = (j1 + 2) % N\n\n        p0, p1, p2, p3 = f_n[j0], f_n[j1], f_n[j2], f_n[j3]\n\n        # Catmull-Rom polynomial evaluation\n        alpha2 = alpha * alpha\n        alpha3 = alpha2 * alpha\n        \n        c0 = p1\n        c1 = 0.5 * (-p0 + p2)\n        c2 = p0 - 2.5 * p1 + 2.0 * p2 - 0.5 * p3\n        c3 = -0.5 * p0 + 1.5 * p1 - 1.5 * p2 + 0.5 * p3\n        \n        f_next = c3*alpha3 + c2*alpha2 + c1*alpha + c0\n        return f_next\n        \n    def apply_positivity_limiter(f_ho: np.ndarray, f_lo: np.ndarray) -> np.ndarray:\n        \"\"\"Applies a positivity-preserving limiter to the high-order solution.\"\"\"\n        f_lim = np.copy(f_ho)\n        \n        # Identify points where the high-order solution violates positivity\n        needs_limiting = f_ho < EPSILON\n        \n        if np.any(needs_limiting):\n            # For points needing a fix, check the low-order solution\n            f_lo_at_limited_pts = f_lo[needs_limiting]\n            \n            # If f_lo is also below threshold, fallback to f_lo.\n            # Otherwise, blend just enough to reach the epsilon floor.\n            limiter_values = np.where(f_lo_at_limited_pts < EPSILON, f_lo_at_limited_pts, EPSILON)\n            f_lim[needs_limiting] = limiter_values\n\n        return f_lim\n\n    # --- Test Case Execution ---\n    test_cases = [\n        (5.0, 0.9),    # Case 1\n        (5.0, 3.7),    # Case 2\n        (17.0, 15.3),  # Case 3\n    ]\n\n    results = []\n\n    # Initial condition and its mass\n    f0 = initial_condition(V_GRID)\n    mass0 = np.sum(f0) * DV\n\n    for a, shift_in_dv in test_cases:\n        shift_val = shift_in_dv * DV\n\n        # Calculate exact solution at t=dt for error comparison\n        f_exact = initial_condition(V_GRID - shift_val)\n        l1_norm_exact = np.sum(np.abs(f_exact)) * DV\n        # Prevent division by zero if f_exact is identically zero\n        if l1_norm_exact == 0:\n            l1_norm_exact = 1.0\n\n        # 1. High-order (unlimited) solution\n        f_ho = catmull_rom_interp_advect(f0, shift_val)\n\n        # 2. Low-order solution (for the limiter)\n        f_lo = linear_interp_advect(f0, shift_val)\n\n        # 3. Limited solution\n        f_lim = apply_positivity_limiter(f_ho, f_lo)\n        \n        # --- Metrics for High-Order (no limiter) Solution ---\n        min_ho = np.min(f_ho)\n        mass_ho = np.sum(f_ho) * DV\n        mass_err_ho = np.abs(mass_ho - mass0)\n        l1_err_ho = np.sum(np.abs(f_ho - f_exact)) * DV / l1_norm_exact\n\n        # --- Metrics for Limited Solution ---\n        min_lim = np.min(f_lim)\n        mass_lim = np.sum(f_lim) * DV\n        mass_err_lim = np.abs(mass_lim - mass0)\n        l1_err_lim = np.sum(np.abs(f_lim - f_exact)) * DV / l1_norm_exact\n        \n        results.extend([min_ho, min_lim, mass_err_ho, mass_err_lim, l1_err_ho, l1_err_lim])\n\n    # Final print statement in the exact required format\n    print(f\"[{','.join(f'{x:.12f}' for x in results)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "Pseudo-spectral methods, which use Fast Fourier Transforms to compute spatial derivatives, are prized for their high accuracy in Vlasov simulations. Their weakness, however, lies in the evaluation of nonlinear terms, such as the $E \\frac{\\partial f}{\\partial v}$ term, where the product in real space leads to a convolution in Fourier space. This can create \"aliasing\" errors, where high-frequency numerical noise contaminates the solution and can lead to unphysical energy pileup and instability. This practice guides you through setting up a Vlasov-Poisson simulation to diagnose this aliasing effect and test common de-aliasing strategies, such as the two-thirds rule and spectral filtering .",
            "id": "4184892",
            "problem": "Consider the collisionless one-dimensional Vlasov–Poisson system for a single species in dimensionless form with periodic spatial domain and sufficiently large velocity interval so that boundary effects are negligible. The distribution function $f(x,v,t)$ evolves according to\n$$\n\\frac{\\partial f}{\\partial t} + v \\frac{\\partial f}{\\partial x} + E(x,t) \\frac{\\partial f}{\\partial v} = 0,\n$$\nand the electric field $E(x,t)$ obeys Poisson's equation\n$$\n\\frac{\\partial E}{\\partial x} = \\rho(x,t) - 1,\n$$\nwhere the charge density $ \\rho(x,t) $ is given by\n$$\n\\rho(x,t) = \\int_{-\\infty}^{\\infty} f(x,v,t) \\, dv,\n$$\nand the background density is normalized to $1$. The spatial domain is $x \\in [0,2\\pi)$ with periodic boundary conditions, and the velocity domain is truncated to $v \\in [-V,V]$ for some sufficiently large $V$ such that $f(x,v,t)$ is negligible near $v=\\pm V$.\n\nIn a continuum (Eulerian) Vlasov solver that evaluates nonlinear terms pseudo-spectrally in the spatial coordinate, the pointwise product in physical space between a spatially varying field and another spatially varying quantity represents a convolution of their Fourier transforms. When the numerical representation is truncated to a finite set of Fourier modes, this convolution can generate Fourier components beyond the maximum resolved wavenumber, which then alias back into the resolved band. This aliasing can manifest as an unphysical energy pileup in high-wavenumber modes and can degrade conservation of invariants such as the total mass\n$$\nM(t) = \\int_0^{2\\pi} \\int_{-V}^{V} f(x,v,t) \\, dv \\, dx,\n$$\nand the squared $L^2$ norm\n$$\n\\|f(t)\\|_2^2 = \\int_0^{2\\pi} \\int_{-V}^{V} f(x,v,t)^2 \\, dv \\, dx.\n$$\n\nYour task is to construct a numerical test that isolates aliasing-induced energy pileup in the spatial spectrum of $f$ and to evaluate filtering strategies designed to mitigate aliasing while preserving conservation and spectral fidelity. Use the following requirements:\n\n1. Derive the computational method from the above Vlasov–Poisson equations without invoking any external shortcut formulas. Spatial derivatives and convolutions must be handled with Fast Fourier Transforms (FFT) in $x$ using a Fourier–Galerkin approach for linear terms. The nonlinear term $E(x,t) \\frac{\\partial f}{\\partial v}$ must be formed in physical space after appropriate spectral processing to control aliasing where applicable.\n\n2. Define the initial condition as a Maxwellian in $v$ with small-amplitude spatial modulation:\n$$\nf(x,v,0) = \\frac{1}{\\sqrt{2\\pi}} \\exp\\left(-\\frac{v^2}{2}\\right) \\left[ 1 + a \\cos(k_0 x) + b \\cos(k_1 x) \\right],\n$$\nwhere $a$ and $b$ are small dimensionless amplitudes. Choose $k_0$ and $k_1$ to excite interactions near the upper part of the resolved spectrum based on the grid size. The Maxwellian amplitude guarantees that $\\int f \\, dv = 1$ at $t=0$ to machine precision in the continuum limit.\n\n3. Compute $E(x,t)$ from $ \\rho(x,t) = \\int f \\, dv $ using Fourier methods: set $E_k = -i \\rho_k / k$ for nonzero $k$ and $E_{k=0}=0$ in the spatial Fourier series, where $k$ denotes the Fourier wavenumber and $i$ is the imaginary unit. Then transform back to physical space $E(x,t)$.\n\n4. Time-advance $f$ using an explicit method derived from the Vlasov equation. You must compute:\n- The spatial derivative $\\frac{\\partial f}{\\partial x}$ using FFTs in $x$.\n- The velocity derivative $\\frac{\\partial f}{\\partial v}$ using a consistent finite difference scheme in $v$ over the truncated interval, with grid spacing $\\Delta v$.\n\n5. Implement and compare the following three strategies for handling aliasing:\n- Strategy A (none): No anti-aliasing. Multiply $E(x,t)$ by $\\frac{\\partial f}{\\partial v}$ in physical space and proceed.\n- Strategy B (two_thirds): Apply the two-thirds de-aliasing rule in $x$ to both factors and to the updated $f$. Specifically, before forming the product, project the spatial Fourier coefficients of $E(x,t)$ and $\\frac{\\partial f}{\\partial v}(x,v,t)$ onto the band $|k| \\leq \\frac{2}{3} k_{\\max}$, with $k_{\\max}$ the largest resolved wavenumber. After updating $f$, project $f$ similarly in $x$ to enforce the bandwidth restriction.\n- Strategy C (exp): Apply a smooth exponential spectral filter in $x$ to the Fourier coefficients of $E(x,t)$, $\\frac{\\partial f}{\\partial v}(x,v,t)$, and to the updated $f$, of the form\n$$\n\\phi(k) = \\exp\\left( -\\alpha \\left( \\frac{|k|}{k_{\\max}} \\right)^p \\right),\n$$\nwith fixed positive $\\alpha$ and even integer $p$ that strongly damps only the highest wavenumbers.\n\n6. Quantify aliasing-induced energy pileup and conservation errors. For each strategy, compute over a fixed number of time steps:\n- The relative mass error $(M(T)-M(0))/M(0)$ at final time $T$.\n- The relative squared $L^2$ norm error $(\\|f(T)\\|_2^2 - \\|f(0)\\|_2^2)/\\|f(0)\\|_2^2$.\n- The change in the fraction of spatial spectral energy contained in the upper quartile of resolved wavenumbers, defined as\n$$\n\\Delta \\eta = \\eta(T) - \\eta(0), \\quad \\eta(t) = \\frac{\\sum_{|k| \\geq 0.75 k_{\\max}} \\left( \\int_{-V}^{V} | \\hat{f}(k,v,t) |^2 \\, dv \\right)}{\\sum_{|k| \\leq k_{\\max}} \\left( \\int_{-V}^{V} | \\hat{f}(k,v,t) |^2 \\, dv \\right)},\n$$\nwhere $\\hat{f}(k,v,t)$ denotes the spatial Fourier transform of $f(x,v,t)$.\n\n7. Work in dimensionless units. You must specify and use the domain length $L=2\\pi$, choose $V$ so that $f$ is negligible at the velocity boundaries, and choose time step size $\\Delta t$ consistent with the advective Courant–Friedrichs–Lewy (CFL) conditions implied by the linear advection terms.\n\n8. To ensure the test isolates aliasing, choose $k_0$ and $k_1$ dependent on the spatial grid size to excite near-maximum resolved modes for each case. Use the following test suite of parameter values:\n- Case 1 (general): $N_x=32$, $N_v=64$, $V=6$, $a=0.05$, $b=0.04$, Strategy A (\"none\"), $\\Delta t$ set to the minimum of $0.1 \\Delta x / V$ and $0.1 \\Delta v / \\|E(x,0)\\|_{\\infty}$, number of steps $N_t=300$.\n- Case 2 (filtered two-thirds): Same as Case 1 but Strategy B (\"two_thirds\").\n- Case 3 (filtered exponential): Same as Case 1 but Strategy C (\"exp\") with $\\alpha=36$, $p=36$.\n- Case 4 (coarse boundary): $N_x=16$, $N_v=64$, $V=6$, $a=0.05$, $b=0.04$, Strategy A (\"none\"), $\\Delta t$ as above, $N_t=300$.\n- Case 5 (high-resolution): $N_x=128$, $N_v=64$, $V=6$, $a=0.05$, $b=0.04$, Strategy A (\"none\"), $\\Delta t$ as above, $N_t=300$.\n\nIn each case, define $k_0 = \\lfloor N_x / 4 \\rfloor$ and $k_1 = \\lfloor N_x / 3 \\rfloor$ so that the initial modulation injects spectral content into upper bands.\n\nYour program should produce a single line of output containing the results of all five test cases as a comma-separated list enclosed in square brackets. Each test case result must itself be a list of three floats of the form $[m\\_err, l2\\_err, \\Delta \\eta]$ in the order described above. For example, an output line with two hypothetical cases would look like: \"[[0.0,0.0,0.0],[0.001,-0.002,0.05]]\".",
            "solution": "The problem requires the construction of a numerical simulation based on the one-dimensional Vlasov-Poisson system to investigate the effects of aliasing in a pseudo-spectral an Eulerian solver. We will compare three strategies for handling the nonlinear term: no anti-aliasing, the two-thirds de-aliasing rule, and a smooth exponential spectral filter.\n\nThe Vlasov-Poisson system is given by:\n$$\n\\frac{\\partial f}{\\partial t} + v \\frac{\\partial f}{\\partial x} + E(x,t) \\frac{\\partial f}{\\partial v} = 0\n$$\n$$\n\\frac{\\partial E}{\\partial x} = \\rho(x,t) - 1, \\quad \\text{where} \\quad \\rho(x,t) = \\int_{-\\infty}^{\\infty} f(x,v,t) \\, dv\n$$\nThe spatial domain is $x \\in [0, 2\\pi)$ with periodic boundary conditions, and the velocity domain is truncated to $v \\in [-V, V]$.\n\nWe first discretize the phase space. The spatial domain is discretized into $N_x$ grid points $x_j = j \\Delta x$ for $j = 0, \\dots, N_x-1$, with grid spacing $\\Delta x = 2\\pi/N_x$. The velocity domain is discretized into $N_v$ grid points $v_l = -V + l \\Delta v$ for $l = 0, \\dots, N_v-1$, with $\\Delta v = 2V/(N_v-1)$ using an inclusive grid, or a similar convention. Let's use `numpy.linspace` which results in $\\Delta v = 2V / (N_v-1)$. The distribution function is represented on this grid as $f_{j,l}(t) \\approx f(x_j, v_l, t)$.\n\nThe Vlasov equation is advanced in time using an explicit Forward Euler scheme:\n$$\nf^{n+1}_{j,l} = f^n_{j,l} + \\Delta t \\left( -v_l \\left(\\frac{\\partial f}{\\partial x}\\right)^n_{j,l} - E^n_j \\left(\\frac{\\partial f}{\\partial v}\\right)^n_{j,l} \\right)\n$$\nwhere $\\Delta t$ is the time step, and the superscript $n$ denotes the time level $t_n = n \\Delta t$.\n\nThe terms on the right-hand side are computed as follows:\n\nThe spatial advection term, $v \\frac{\\partial f}{\\partial x}$, is handled spectrally. For each velocity slice $v_l$, we compute the spatial Fourier transform of $f(x, v_l, t)$, denoted $\\hat{f}(k, v_l, t)$. The Fourier transform of the spatial derivative is then $i k \\hat{f}(k, v_l, t)$, where $k$ are the integer wavenumbers. An inverse Fourier transform then yields $\\frac{\\partial f}{\\partial x}$ in physical space. This corresponds to the specified Fourier-Galerkin approach for the linear term.\n\nThe velocity advection term, $E \\frac{\\partial f}{\\partial v}$, is the nonlinear term responsible for aliasing. It is computed in several steps:\n1.  **Electric Field Calculation**: The electric field $E(x,t)$ is determined from the distribution function $f(x,v,t)$.\n    - The charge density is computed by numerical integration over velocity: $\\rho(x_j, t) = \\sum_{l=0}^{N_v-1} f(x_j, v_l, t) \\Delta v$.\n    - Poisson's equation $\\frac{\\partial E}{\\partial x} = \\rho - 1$ is solved in Fourier space. Let $\\hat{\\rho}(k,t)$ be the spatial Fourier transform of $\\rho(x,t)$. The equation becomes $i k \\hat{E}(k,t) = \\hat{\\rho}(k,t) - \\hat{1}(k,t)$. Since $\\hat{1}(k,t)$ is non-zero only for $k=0$, we have for $k \\neq 0$:\n      $$\n      \\hat{E}(k,t) = \\frac{\\hat{\\rho}(k,t)}{ik} = -i \\frac{\\hat{\\rho}(k,t)}{k}\n      $$\n      For charge neutrality, the total charge perturbation $\\int (\\rho-1) dx$ is zero, implying $\\hat{\\rho}(k=0) - N_x = 0$. This ensures consistency. The $k=0$ mode of the electric field $\\hat{E}(k=0,t)$ is set to $0$, corresponding to zero average electric field.\n    - The physical-space field $E(x,t)$ is recovered by an inverse Fourier transform of $\\hat{E}(k,t)$.\n\n2.  **Velocity Derivative**: The velocity derivative $\\frac{\\partial f}{\\partial v}$ is computed using a finite difference scheme. We use a second-order accurate central difference for interior points and first-order accurate one-sided differences at the boundaries $v = \\pm V$:\n    $$\n    \\left(\\frac{\\partial f}{\\partial v}\\right)_{j,l} =\n    \\begin{cases}\n    (f_{j,1} - f_{j,0}) / \\Delta v & \\text{if } l=0 \\\\\n    (f_{j,l+1} - f_{j,l-1}) / (2 \\Delta v) & \\text{if } 0 < l < N_v-1 \\\\\n    (f_{j,N_v-1} - f_{j,N_v-2}) / \\Delta v & \\text{if } l=N_v-1\n    \\end{cases}\n    $$\n\n3.  **Nonlinear Product and Aliasing Control**: The product $E(x,t) \\frac{\\partial f}{\\partial v}(x,v,t)$ is formed. This is where aliasing occurs and where control strategies are applied.\n    - **Strategy A (None)**: The product is computed directly in physical space: $(E \\frac{\\partial f}{\\partial v})_{j,l} = E_j (\\frac{\\partial f}{\\partial v})_{j,l}$.\n    - **Strategy B (Two-Thirds Rule)**: To prevent aliasing, the Fourier spectra of both factors, $E(x,t)$ and $\\frac{\\partial f}{\\partial v}(x,v,t)$, are truncated before multiplication. Let $k_{\\max} = N_x/2$ be the maximum representable wavenumber magnitude. The Fourier coefficients $\\hat{E}(k)$ and $\\widehat{\\frac{\\partial f}{\\partial v}}(k,v_l)$ are set to zero for all wavenumbers $|k| > \\lfloor \\frac{2}{3} k_{\\max} \\rfloor = \\lfloor N_x/3 \\rfloor$. The filtered fields are then transformed back to physical space, and their product is computed. After the full time-step update, the new distribution function $f^{n+1}$ is also filtered in Fourier space using the same truncation rule.\n    - **Strategy C (Exponential Filter)**: Instead of a sharp cutoff, a smooth exponential filter is applied in Fourier space to the coefficients of $E$, $\\frac{\\partial f}{\\partial v}$, and the updated $f^{n+1}$. The filter has the form $\\phi(k) = \\exp\\left( -\\alpha \\left( \\frac{|k|}{k_{\\max}} \\right)^p \\right)$, where $\\alpha$ and $p$ are parameters controlling the filter's strength and steepness. This damps high-wavenumber modes while having minimal effect on low-wavenumber modes.\n\nThe initial condition is set to:\n$$\nf(x,v,0) = \\frac{1}{\\sqrt{2\\pi}} \\exp\\left(-\\frac{v^2}{2}\\right) \\left[ 1 + a \\cos(k_0 x) + b \\cos(k_1 x) \\right]\n$$\nwith $k_0 = \\lfloor N_x / 4 \\rfloor$ and $k_1 = \\lfloor N_x / 3 \\rfloor$. These choices for wavenumbers are designed to generate nonlinear interactions that produce modes $k_0+k_1$ which are higher than the Nyquist frequency $k_{Nyq} = N_x/2$, thus directly exciting aliasing.\n\nThe time step $\\Delta t$ is fixed based on the Courant-Friedrichs-Lewy (CFL) conditions for the spatial and velocity advection at $t=0$:\n$$\n\\Delta t = \\min \\left( 0.1 \\frac{\\Delta x}{V}, 0.1 \\frac{\\Delta v}{\\|E(x,0)\\|_{\\infty}} \\right)\n$$\nwhere $\\|E(x,0)\\|_{\\infty}$ is the maximum absolute value of the initial electric field.\n\nTo quantify the performance of each strategy, we compute three metrics:\n1.  **Relative mass error**: $\\frac{M(T)-M(0)}{M(0)}$, where $M(t) = \\iint f \\, dx dv$.\n2.  **Relative squared $L^2$ norm error**: $\\frac{\\|f(T)\\|_2^2 - \\|f(0)\\|_2^2}{\\|f(0)\\|_2^2}$, where $\\|f(t)\\|_2^2 = \\iint f^2 \\, dx dv$. While the mass is a strict invariant of the Vlasov equation, the $L^2$ norm is also conserved, a property known as Liouville's theorem in the continuum limit.\n3.  **High-wavenumber energy pileup**: $\\Delta \\eta = \\eta(T) - \\eta(0)$, where $\\eta(t)$ is the fraction of spectral energy in the upper quartile of wavenumbers, defined as:\n    $$\n    \\eta(t) = \\frac{\\sum_{|k| \\geq 0.75 k_{\\max}} \\left( \\int | \\hat{f}(k,v,t) |^2 \\, dv \\right)}{\\sum_{\\text{all }k} \\left( \\int | \\hat{f}(k,v,t) |^2 \\, dv \\right)}\n    $$\nThese diagnostics are computed at the initial time $t=0$ and the final time $t=T=N_t \\Delta t$. The numerical evaluation of these integrals is performed using simple summation over the discrete grid, weighted by the grid cell size $\\Delta x \\Delta v$.",
            "answer": "```python\nimport numpy as np\n\ndef run_simulation(Nx, Nv, V_max, a, b, strategy, strategy_params, Nt):\n    \"\"\"\n    Runs a 1D-1V Vlasov-Poisson simulation for a given set of parameters.\n    \"\"\"\n    # 1. Discretization and Grids\n    L = 2 * np.pi\n    x = np.linspace(0, L, Nx, endpoint=False)\n    v = np.linspace(-V_max, V_max, Nv)\n    dx = x[1] - x[0]\n    dv = v[1] - v[0]\n\n    # Wavenumbers for spatial Fourier transforms\n    k_int = np.fft.fftfreq(Nx, d=1.0/Nx)\n    k_phys = np.fft.fftfreq(Nx, d=dx) * 2 * np.pi\n    k_phys[0] = 1e-12 # Avoid division by zero, though handled later\n    kmax = Nx / 2\n\n    k0 = int(np.floor(Nx / 4))\n    k1 = int(np.floor(Nx / 3))\n\n    # 2. Initial Condition\n    xx, vv = np.meshgrid(x, v, indexing='ij')\n    f0 = (1.0 / np.sqrt(2 * np.pi) * np.exp(-vv**2 / 2.0) *\n          (1.0 + a * np.cos(k0 * xx) + b * np.cos(k1 * xx)))\n    f = f0.copy()\n\n    # 3. Time Step Calculation from CFL conditions\n    rho0 = np.sum(f0, axis=1) * dv\n    rho_hat0 = np.fft.fft(rho0 - 1.0)\n    E_hat0 = np.zeros_like(rho_hat0, dtype=complex)\n    k_nonzero_mask = k_int != 0\n    E_hat0[k_nonzero_mask] = -1j * rho_hat0[k_nonzero_mask] / k_int[k_nonzero_mask]\n    E0 = np.fft.ifft(E_hat0).real\n    Emax0 = np.max(np.abs(E0)) if np.max(np.abs(E0)) > 0 else 1.0\n\n    dt = min(0.1 * dx / V_max, 0.1 * dv / Emax0)\n\n    # 4. Initial Diagnostics\n    def calculate_eta(f_dist, k_vec, k_max, delta_v):\n        f_hat = np.fft.fft(f_dist, axis=0)\n        f_hat_power_v_int = np.sum(np.abs(f_hat)**2, axis=1) * delta_v\n        \n        # Denominator is total power\n        total_power = np.sum(f_hat_power_v_int)\n        if total_power == 0:\n            return 0.0\n\n        # Numerator is power in upper quartile of wavenumbers\n        upper_quartile_mask = np.abs(k_vec) >= 0.75 * k_max\n        upper_quartile_power = np.sum(f_hat_power_v_int[upper_quartile_mask])\n        \n        return upper_quartile_power / total_power\n\n    M0 = np.sum(f0) * dx * dv\n    L2_0 = np.sum(f0**2) * dx * dv\n    eta0 = calculate_eta(f0, k_int, kmax, dv)\n\n    # 5. Setup for Aliasing Strategies\n    filter_k = None\n    k_trunc = 0\n    if strategy == 'two_thirds':\n        k_trunc = int(np.floor(Nx / 3))\n    elif strategy == 'exp':\n        alpha = strategy_params['alpha']\n        p = strategy_params['p']\n        filter_k = np.exp(-alpha * (np.abs(k_int) / kmax)**p)\n    \n    # helper for v-derivative\n    def get_dfdv(f_dist, delta_v):\n        dfdv = np.zeros_like(f_dist)\n        dfdv[:, 1:-1] = (f_dist[:, 2:] - f_dist[:, :-2]) / (2 * delta_v)\n        dfdv[:, 0] = (f_dist[:, 1] - f_dist[:, 0]) / delta_v\n        dfdv[:, -1] = (f_dist[:, -1] - f_dist[:, -2]) / delta_v\n        return dfdv\n\n    # 6. Time Evolution Loop\n    for _ in range(Nt):\n        # Calculate spatial advection term: -v * df/dx\n        f_hat = np.fft.fft(f, axis=0)\n        dfdx_hat = 1j * k_int[:, np.newaxis] * f_hat\n        dfdx = np.fft.ifft(dfdx_hat, axis=0)\n        advection_term = -v[np.newaxis, :] * dfdx\n\n        # Calculate velocity advection term: -E * df/dv\n        rho = np.sum(f, axis=1) * dv\n        rho_hat = np.fft.fft(rho - 1.0)\n        E_hat = np.zeros_like(rho_hat, dtype=complex)\n        E_hat[k_nonzero_mask] = -1j * rho_hat[k_nonzero_mask] / k_int[k_nonzero_mask]\n        \n        dfdv = get_dfdv(f, dv)\n\n        if strategy == 'none':\n            E_phys = np.fft.ifft(E_hat)\n            nonlinear_term = -E_phys[:, np.newaxis] * dfdv\n        else: # Strategies with filtering\n            dfdv_hat = np.fft.fft(dfdv, axis=0)\n            if strategy == 'two_thirds':\n                mask = np.abs(k_int) > k_trunc\n                E_hat[mask] = 0\n                dfdv_hat[mask, :] = 0\n            elif strategy == 'exp':\n                E_hat *= filter_k\n                dfdv_hat *= filter_k[:, np.newaxis]\n\n            E_phys_filt = np.fft.ifft(E_hat)\n            dfdv_filt = np.fft.ifft(dfdv_hat, axis=0)\n            nonlinear_term = -E_phys_filt[:, np.newaxis] * dfdv_filt\n\n        # Update f using Forward Euler\n        f_new = f + dt * (advection_term + nonlinear_term)\n        f = f_new.real\n        \n        # Post-step filtering for strategies B and C\n        if strategy == 'two_thirds':\n            f_hat_new = np.fft.fft(f, axis=0)\n            mask = np.abs(k_int) > k_trunc\n            f_hat_new[mask, :] = 0\n            f = np.fft.ifft(f_hat_new, axis=0).real\n        elif strategy == 'exp':\n            f_hat_new = np.fft.fft(f, axis=0)\n            f_hat_new *= filter_k[:, np.newaxis]\n            f = np.fft.ifft(f_hat_new, axis=0).real\n\n    # 7. Final Diagnostics and Error Calculation\n    M_T = np.sum(f) * dx * dv\n    L2_T = np.sum(f**2) * dx * dv\n    eta_T = calculate_eta(f, k_int, kmax, dv)\n\n    m_err = (M_T - M0) / M0\n    l2_err = (L2_T - L2_0) / L2_0\n    delta_eta = eta_T - eta0\n\n    return [m_err, l2_err, delta_eta]\n\ndef solve():\n    test_cases = [\n        # Case 1: (Nx=32, Nv=64, V=6, a=0.05, b=0.04, \"none\", {}, 300)\n        {'Nx': 32, 'Nv': 64, 'V_max': 6, 'a': 0.05, 'b': 0.04,\n         'strategy': 'none', 'strategy_params': {}, 'Nt': 300},\n        # Case 2: (Nx=32, Strategy=\"two_thirds\")\n        {'Nx': 32, 'Nv': 64, 'V_max': 6, 'a': 0.05, 'b': 0.04,\n         'strategy': 'two_thirds', 'strategy_params': {}, 'Nt': 300},\n        # Case 3: (Nx=32, Strategy=\"exp\")\n        {'Nx': 32, 'Nv': 64, 'V_max': 6, 'a': 0.05, 'b': 0.04,\n         'strategy': 'exp', 'strategy_params': {'alpha': 36, 'p': 36}, 'Nt': 300},\n        # Case 4: (Nx=16, Strategy=\"none\")\n        {'Nx': 16, 'Nv': 64, 'V_max': 6, 'a': 0.05, 'b': 0.04,\n         'strategy': 'none', 'strategy_params': {}, 'Nt': 300},\n        # Case 5: (Nx=128, Strategy=\"none\")\n        {'Nx': 128, 'Nv': 64, 'V_max': 6, 'a': 0.05, 'b': 0.04,\n         'strategy': 'none', 'strategy_params': {}, 'Nt': 300},\n    ]\n\n    results = []\n    for params in test_cases:\n        result = run_simulation(**params)\n        results.append(result)\n\n    # Format output as specified: [[r1,r2,r3],[...],...]\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "To simulate plasmas in realistic devices like tokamaks, solvers must move beyond simple Cartesian grids to curvilinear coordinate systems that align with complex magnetic fields. A naive implementation of the Vlasov equation in a new coordinate system can introduce significant \"metric-induced\" errors by failing to properly account for the geometry's local stretching and shearing, encapsulated by the Jacobian. This practice isolates this crucial geometric effect, allowing you to demonstrate how a formally correct, conservative formulation preserves physical invariants, while a naive one generates spurious sources and sinks—a vital lesson for developing robust, general-geometry codes .",
            "id": "4185000",
            "problem": "You are asked to design and implement a coordinate-invariance test that isolates metric-induced errors in continuum (Eulerian) Vlasov solvers by comparing the same physical advection problem in Cartesian and in a simple field-aligned curvilinear coordinate system. The goal is to demonstrate that, for an incompressible Hamiltonian flow underlying the collisionless Vlasov dynamics, a correct conservative formulation in general coordinates preserves a uniform distribution function, while an implementation that neglects metric factors generates a spurious residual. Your program must compute and report a scalar diagnostic for several test cases.\n\nStart from the following fundamental base:\n- The collisionless Vlasov equation for a passive distribution function $f$ on a phase-space domain with flow $\\boldsymbol{a}$ is the conservative transport equation $\\partial f / \\partial t + \\nabla \\cdot (\\boldsymbol{a} f) = 0$, where $\\nabla \\cdot \\boldsymbol{a} = 0$ for incompressible Hamiltonian flow.\n- In general curvilinear coordinates $u^i$, the divergence of a physical vector field with contravariant components $a^i$ and Jacobian $J$ that maps $u^i$-space volume to physical volume is given by $\\nabla \\cdot \\boldsymbol{a} = \\dfrac{1}{J} \\partial_i (J a^i)$.\n\nConsider a two-dimensional configuration-space analog that isolates metric effects without invoking self-consistent fields. Let $(x,y)$ denote Cartesian coordinates and $(\\xi,\\eta)$ denote field-aligned coordinates connected by the smooth, strictly monotone mapping\n$$\nx(\\xi,\\eta) = \\xi,\\qquad y(\\xi,\\eta) = h(\\xi)\\,\\eta,\n$$\nwith\n$$\nh(\\xi) = 1 + \\alpha \\cos\\left(\\dfrac{2\\pi}{L_x}\\,\\xi\\right),\\qquad 0 \\le \\alpha &lt; 1,\\quad L_x &gt; 0.\n$$\nAssume periodic boundary conditions in both directions, $\\xi \\in [0,L_x)$ and $\\eta \\in [0,L_y)$. The Jacobian determinant (metric volume factor) of this mapping is $J(\\xi,\\eta) = h(\\xi)$. Let the physical advection velocity be uniform and constant in Cartesian coordinates,\n$$\n\\boldsymbol{U} = (U_x, U_y),\n$$\nso that the physical flow is incompressible, $\\nabla \\cdot \\boldsymbol{U} = 0$. For a uniform initial distribution $f_0$, the exact right-hand side residual $R = -\\nabla \\cdot (\\boldsymbol{U} f_0)$ must be identically zero in any coordinate system when the divergence is formulated correctly.\n\nDefine three discrete residual fields on a uniform grid of size $N_x \\times N_y$ in $(\\xi,\\eta)$-space, using second-order centered finite differences with periodic boundary conditions:\n- $R_{\\mathrm{cart}}$: the residual computed in Cartesian coordinates on the same uniform computational grid (interpreted directly as $(x,y)$) for the constant flux $\\boldsymbol{U} f_0$.\n- $R_{\\mathrm{curv,correct}}$: the residual computed in curvilinear coordinates using the conservative divergence with the correct metric factor and contravariant components,\n$$\nR_{\\mathrm{curv,correct}}(\\xi,\\eta) = -\\dfrac{1}{J(\\xi,\\eta)}\\left[ \\partial_\\xi\\left(J(\\xi,\\eta)\\,a^\\xi(\\xi,\\eta)\\,f_0\\right) + \\partial_\\eta\\left(J(\\xi,\\eta)\\,a^\\eta(\\xi,\\eta)\\,f_0\\right) \\right].\n$$\nHere $\\boldsymbol{a} = (a^\\xi,a^\\eta)$ are the contravariant components of $\\boldsymbol{U}$ in the $(\\xi,\\eta)$ basis defined by the mapping above.\n- $R_{\\mathrm{curv,naive}}$: the residual computed in curvilinear coordinates by a naive divergence that ignores the metric factor,\n$$\nR_{\\mathrm{curv,naive}}(\\xi,\\eta) = -\\left[\\partial_\\xi a^\\xi(\\xi,\\eta) + \\partial_\\eta a^\\eta(\\xi,\\eta)\\right] f_0.\n$$\n\nThe test that isolates metric-induced errors is to compare the root-mean-square (RMS) amplitude of $R_{\\mathrm{curv,naive}}$ against the vanishing values of $R_{\\mathrm{cart}}$ and $R_{\\mathrm{curv,correct}}$ for the same physical setup. A nonzero RMS of $R_{\\mathrm{curv,naive}}$ in cases with nontrivial metric variation or nonzero $U_x$ indicates purely metric-induced error. This comparison demonstrates the necessity of the Jacobian-weighted divergence in continuum (Eulerian) Vlasov solvers written in curvilinear coordinates.\n\nYour tasks:\n1. Derive the contravariant components $a^\\xi(\\xi,\\eta)$ and $a^\\eta(\\xi,\\eta)$ of the constant Cartesian velocity $\\boldsymbol{U}$ in the $(\\xi,\\eta)$ coordinate basis induced by the mapping above.\n2. Implement second-order centered finite-difference approximations for $\\partial_\\xi$ and $\\partial_\\eta$ with periodic boundary conditions on a uniform computational grid $(\\xi_i,\\eta_j)$, $i=0,\\dots,N_x-1$, $j=0,\\dots,N_y-1$ with spacings $\\Delta \\xi = L_x/N_x$ and $\\Delta \\eta = L_y/N_y$.\n3. For each test case, compute the RMS of $R_{\\mathrm{curv,naive}}$ over the grid, defined as\n$$\n\\mathrm{RMS}(R) = \\left( \\dfrac{1}{N_x N_y} \\sum_{i=0}^{N_x-1} \\sum_{j=0}^{N_y-1} R(\\xi_i,\\eta_j)^2 \\right)^{1/2}.\n$$\nYou may take $f_0=1$ without loss of generality.\n\nTest suite:\nProvide results for the following parameter sets $(\\alpha, N_x, N_y, U_x, U_y, L_x, L_y)$:\n- Case A (happy path): $(0.3, 64, 64, 1.0, 0.5, 2\\pi, 2\\pi)$.\n- Case B (boundary, no metric variation): $(0.0, 32, 32, 1.0, 0.0, 2\\pi, 2\\pi)$.\n- Case C (edge, flow aligned with $\\eta$ so $U_x = 0$): $(0.3, 48, 96, 0.0, 1.0, 2\\pi, 2\\pi)$.\n- Case D (edge, anisotropic grid and strong variation): $(0.5, 16, 128, 1.0, 0.0, 2\\pi, 2\\pi)$.\n- Case E (refined resolution): $(0.3, 128, 128, 1.0, 0.5, 2\\pi, 2\\pi)$.\n\nFinal output format:\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, with one floating-point number per test case in the same order as above, representing $\\mathrm{RMS}(R_{\\mathrm{curv,naive}})$ for each case, for example, \"[0.123,0.0,0.0,0.456,0.078]\". All quantities are nondimensional; no physical units are required. Angles, where present, are in radians. Percentages must not be used.",
            "solution": "The problem requires the design and implementation of a coordinate-invariance test for a continuum Vlasov solver. This test is designed to isolate and quantify numerical errors that arise from neglecting metric tensor components in a curvilinear coordinate system. The core of the task is to compute a scalar diagnostic, the root-mean-square (RMS) of a \"naively\" computed residual, for a simple incompressible flow field.\n\nThe analysis proceeds in three main steps:\n1.  Derivation of the contravariant components of the advection velocity in the specified curvilinear coordinate system.\n2.  Specification of the numerical algorithm to compute the residual field using finite differences.\n3.  Calculation of the RMS diagnostic for the provided test cases.\n\n### 1. Derivation of Contravariant Velocity Components\n\nWe are given a transformation from a curvilinear coordinate system $(\\xi, \\eta)$ to a Cartesian system $(x,y)$:\n$$\nx(\\xi,\\eta) = \\xi\n$$\n$$\ny(\\xi,\\eta) = h(\\xi)\\,\\eta\n$$\nwhere $h(\\xi) = 1 + \\alpha \\cos\\left(\\frac{2\\pi}{L_x}\\xi\\right)$.\n\nThe Cartesian velocity components $(U_x, U_y) = (\\dot{x}, \\dot{y})$ are related to the time derivatives of the curvilinear coordinates $(\\dot{\\xi}, \\dot{\\eta})$ by the chain rule:\n$$\n\\begin{pmatrix} \\dot{x} \\\\ \\dot{y} \\end{pmatrix} = \\begin{pmatrix} \\frac{\\partial x}{\\partial \\xi} & \\frac{\\partial x}{\\partial \\eta} \\\\ \\frac{\\partial y}{\\partial \\xi} & \\frac{\\partial y}{\\partial \\eta} \\end{pmatrix} \\begin{pmatrix} \\dot{\\xi} \\\\ \\dot{\\eta} \\end{pmatrix}\n$$\nThe contravariant components of the velocity vector are, by definition, $a^\\xi = \\dot{\\xi}$ and $a^\\eta = \\dot{\\eta}$. The matrix in the equation above is the Jacobian matrix of the transformation, $\\mathbf{J}_{map}$. We must compute its components:\n$$\n\\frac{\\partial x}{\\partial \\xi} = 1\n$$\n$$\n\\frac{\\partial x}{\\partial \\eta} = 0\n$$\n$$\n\\frac{\\partial y}{\\partial \\xi} = \\frac{dh}{d\\xi}\\eta = h'(\\xi)\\eta\n$$\n$$\n\\frac{\\partial y}{\\partial \\eta} = h(\\xi)\n$$\nSubstituting these into the matrix equation:\n$$\n\\begin{pmatrix} U_x \\\\ U_y \\end{pmatrix} = \\begin{pmatrix} 1 & 0 \\\\ h'(\\xi)\\eta & h(\\xi) \\end{pmatrix} \\begin{pmatrix} a^\\xi \\\\ a^\\eta \\end{pmatrix}\n$$\nTo find the contravariant components $(a^\\xi, a^\\eta)$, we invert the Jacobian matrix:\n$$\n\\mathbf{J}_{map}^{-1} = \\frac{1}{\\det(\\mathbf{J}_{map})} \\begin{pmatrix} h(\\xi) & 0 \\\\ -h'(\\xi)\\eta & 1 \\end{pmatrix} = \\frac{1}{h(\\xi)} \\begin{pmatrix} h(\\xi) & 0 \\\\ -h'(\\xi)\\eta & 1 \\end{pmatrix} = \\begin{pmatrix} 1 & 0 \\\\ -\\frac{h'(\\xi)\\eta}{h(\\xi)} & \\frac{1}{h(\\xi)} \\end{pmatrix}\n$$\nNote that the determinant, $\\det(\\mathbf{J}_{map}) = h(\\xi)$, is the Jacobian $J$ of the coordinate transformation, as given in the problem statement.\n\nNow, we solve for the contravariant components:\n$$\n\\begin{pmatrix} a^\\xi \\\\ a^\\eta \\end{pmatrix} = \\mathbf{J}_{map}^{-1} \\begin{pmatrix} U_x \\\\ U_y \\end{pmatrix} = \\begin{pmatrix} 1 & 0 \\\\ -\\frac{h'(\\xi)\\eta}{h(\\xi)} & \\frac{1}{h(\\xi)} \\end{pmatrix} \\begin{pmatrix} U_x \\\\ U_y \\end{pmatrix}\n$$\nThis matrix multiplication yields the explicit expressions for the contravariant velocity components:\n$$\na^\\xi(\\xi, \\eta) = U_x\n$$\n$$\na^\\eta(\\xi, \\eta) = -\\frac{h'(\\xi)\\eta}{h(\\xi)}U_x + \\frac{1}{h(\\xi)}U_y = \\frac{U_y - U_x h'(\\xi)\\eta}{h(\\xi)}\n$$\nwhere $h'(\\xi) = \\frac{dh}{d\\xi} = -\\alpha \\frac{2\\pi}{L_x} \\sin\\left(\\frac{2\\pi}{L_x}\\xi\\right)$. These expressions are essential for calculating the residual.\n\n### 2. Discretization and Residual Calculation\n\nThe problem asks to compute the \"naive\" residual, which ignores metric factors. For a uniform distribution $f_0=1$, this is:\n$$\nR_{\\mathrm{curv,naive}}(\\xi,\\eta) = -\\left(\\frac{\\partial a^\\xi}{\\partial \\xi} + \\frac{\\partial a^\\eta}{\\partial \\eta}\\right)\n$$\nWe evaluate this on a uniform computational grid $(\\xi_i, \\eta_j)$ where $\\xi_i = i \\Delta\\xi$ for $i=0,\\dots,N_x-1$ and $\\eta_j = j \\Delta\\eta$ for $j=0,\\dots,N_y-1$, with grid spacings $\\Delta\\xi = L_x/N_x$ and $\\Delta\\eta = L_y/N_y$.\n\nThe partial derivatives are approximated using second-order centered finite differences with periodic boundary conditions. For a generic grid function $F_{i,j} = F(\\xi_i, \\eta_j)$:\n$$\n\\left(\\frac{\\partial F}{\\partial \\xi}\\right)_{i,j} \\approx \\frac{F_{i+1,j} - F_{i-1,j}}{2\\Delta\\xi}\n$$\n$$\n\\left(\\frac{\\partial F}{\\partial \\eta}\\right)_{i,j} \\approx \\frac{F_{i,j+1} - F_{i,j-1}}{2\\Delta\\eta}\n$$\nPeriodicity implies that $F_{N_x, j} = F_{0, j}$, $F_{-1, j} = F_{N_x-1, j}$, and similarly for the $j$ index.\n\nLet's apply these operators to our contravariant components $a^\\xi$ and $a^\\eta$.\nFirst, for $\\partial a^\\xi / \\partial \\xi$:\nSince $a^\\xi(\\xi, \\eta) = U_x$ is a constant, its derivative with respect to any variable is analytically zero. The centered difference operator also gives zero exactly:\n$$\n\\frac{\\partial a^\\xi}{\\partial \\xi} \\approx \\frac{U_x - U_x}{2\\Delta\\xi} = 0\n$$\nNext, for $\\partial a^\\eta / \\partial \\eta$:\nThe component $a^\\eta$ is a linear function of $\\eta$. The centered difference operator is exact for polynomials of degree up to $2$, so it will be exact here.\n$$\n\\left(\\frac{\\partial a^\\eta}{\\partial \\eta}\\right)_{i,j} \\approx \\frac{a^\\eta(\\xi_i, \\eta_{j+1}) - a^\\eta(\\xi_i, \\eta_{j-1})}{2\\Delta\\eta} = \\frac{1}{2\\Delta\\eta} \\left[ \\frac{U_y - U_x h'(\\xi_i)\\eta_{j+1}}{h(\\xi_i)} - \\frac{U_y - U_x h'(\\xi_i)\\eta_{j-1}}{h(\\xi_i)} \\right]\n$$\n$$\n= \\frac{-U_x h'(\\xi_i)}{2\\Delta\\eta h(\\xi_i)} (\\eta_{j+1} - \\eta_{j-1}) = \\frac{-U_x h'(\\xi_i)}{2\\Delta\\eta h(\\xi_i)} (2\\Delta\\eta) = -\\frac{U_x h'(\\xi_i)}{h(\\xi_i)}\n$$\nThe numerical derivative is identical to the analytical derivative $\\frac{\\partial}{\\partial \\eta} \\left(\\frac{U_y}{h(\\xi)} - \\frac{U_x h'(\\xi) \\eta}{h(\\xi)}\\right) = -\\frac{U_x h'(\\xi)}{h(\\xi)}$.\n\nCombining these results, the numerically computed residual at each grid point is:\n$$\nR_{\\mathrm{curv,naive}}(\\xi_i, \\eta_j) = -\\left(0 - \\frac{U_x h'(\\xi_i)}{h(\\xi_i)}\\right) = \\frac{U_x h'(\\xi_i)}{h(\\xi_i)}\n$$\nThis expression shows that the residual is independent of $\\eta$ and is non-zero if and only if $U_x \\neq 0$ and $h'(\\xi_i) \\neq 0$. The latter is true if $\\alpha \\neq 0$ and $\\sin\\left(\\frac{2\\pi}{L_x}\\xi_i\\right) \\neq 0$. This residual is a direct consequence of neglecting the metric Jacobian $J=h(\\xi)$ inside the divergence operator, confirming the premise of the problem.\n\n### 3. RMS Diagnostic Calculation\n\nThe final task is to compute the RMS value of the residual field over the entire grid:\n$$\n\\mathrm{RMS}(R_{\\mathrm{curv,naive}}) = \\left( \\frac{1}{N_x N_y} \\sum_{i=0}^{N_x-1} \\sum_{j=0}^{N_y-1} \\left(R_{\\mathrm{curv,naive}}(\\xi_i, \\eta_j)\\right)^2 \\right)^{1/2}\n$$\nSince the residual $R_{\\mathrm{curv,naive}}(\\xi_i, \\eta_j)$ only depends on the index $i$, we can simplify the double summation:\n$$\n\\mathrm{RMS}(R_{\\mathrm{curv,naive}}) = \\left( \\frac{1}{N_x N_y} \\sum_{j=0}^{N_y-1} \\sum_{i=0}^{N_x-1} \\left(\\frac{U_x h'(\\xi_i)}{h(\\xi_i)}\\right)^2 \\right)^{1/2} = \\left( \\frac{N_y}{N_x N_y} \\sum_{i=0}^{N_x-1} \\left(\\frac{U_x h'(\\xi_i)}{h(\\xi_i)}\\right)^2 \\right)^{1/2}\n$$\n$$\n\\mathrm{RMS}(R_{\\mathrm{curv,naive}}) = \\left( \\frac{1}{N_x} \\sum_{i=0}^{N_x-1} \\left(\\frac{U_x h'(\\xi_i)}{h(\\xi_i)}\\right)^2 \\right)^{1/2}\n$$\nThis final expression is implemented for each test case. The implementation will follow the numerical differentiation steps as required, although we have shown it simplifies to this analytical form. The code calculates the array of residual values `R_naive` on the 2D grid and then computes its RMS value directly.",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the coordinate-invariance test problem for continuum Vlasov solvers.\n    \n    This function calculates the RMS of a naively computed residual for several\n    test cases to demonstrate metric-induced errors in a curvilinear \n    coordinate system.\n    \"\"\"\n\n    test_cases = [\n        # Case A: (alpha, Nx, Ny, Ux, Uy, Lx, Ly) - Happy path\n        (0.3, 64, 64, 1.0, 0.5, 2 * np.pi, 2 * np.pi),\n        # Case B: alpha=0, no metric variation\n        (0.0, 32, 32, 1.0, 0.0, 2 * np.pi, 2 * np.pi),\n        # Case C: Ux=0, flow aligned with eta-coordinate\n        (0.3, 48, 96, 0.0, 1.0, 2 * np.pi, 2 * np.pi),\n        # Case D: Anisotropic grid, strong metric variation\n        (0.5, 16, 128, 1.0, 0.0, 2 * np.pi, 2 * np.pi),\n        # Case E: Refined resolution of Case A\n        (0.3, 128, 128, 1.0, 0.5, 2 * np.pi, 2 * np.pi),\n    ]\n\n    results = []\n    \n    for case in test_cases:\n        alpha, Nx, Ny, Ux, Uy, Lx, Ly = case\n        \n        f0 = 1.0\n\n        # 1. Set up the computational grid in (xi, eta) space.\n        # Grid points are cell centers for a finite volume interpretation,\n        # but the problem implies a node-based grid up to L_x, L_y (exclusive).\n        #linspace endpoint=False creates an array of N points from start to stop-step.\n        xi_1d = np.linspace(0, Lx, Nx, endpoint=False)\n        eta_1d = np.linspace(0, Ly, Ny, endpoint=False)\n        xi_grid, eta_grid = np.meshgrid(xi_1d, eta_1d)\n\n        # Grid spacings\n        D_xi = Lx / Nx\n        D_eta = Ly / Ny\n\n        # 2. Calculate metric-related functions h(xi) and h'(xi).\n        # These are functions of xi only, but we broadcast them to the full grid size.\n        k = (2 * np.pi) / Lx\n        h_grid = 1.0 + alpha * np.cos(k * xi_grid)\n        h_prime_grid = -alpha * k * np.sin(k * xi_grid)\n\n        # 3. Derive the contravariant components of the velocity field.\n        # These components, a^xi and a^eta, are defined on the (xi, eta) grid.\n        # a_xi is constant.\n        a_xi_grid = Ux * np.ones_like(xi_grid)\n        \n        # a_eta depends on xi and eta.\n        # To avoid division by zero if h_grid should ever be zero (prevented by alpha < 1).\n        with np.errstate(divide='raise', invalid='raise'):\n             a_eta_grid = (Uy - Ux * h_prime_grid * eta_grid) / h_grid\n\n        # 4. Compute partial derivatives using 2nd-order centered differences\n        # with periodic boundary conditions.\n        # np.roll provides an efficient way to implement periodic shifts.\n        # axis=1 corresponds to xi (columns), axis=0 corresponds to eta (rows).\n        \n        # d(a_xi)/d_xi\n        d_xi_a_xi = (np.roll(a_xi_grid, -1, axis=1) - np.roll(a_xi_grid, 1, axis=1)) / (2 * D_xi)\n        \n        # d(a_eta)/d_eta\n        d_eta_a_eta = (np.roll(a_eta_grid, -1, axis=0) - np.roll(a_eta_grid, 1, axis=0)) / (2 * D_eta)\n\n        # 5. Compute the naive residual field, R_curv_naive.\n        # R_naive = - (d(a^xi)/d_xi + d(a^eta)/d_eta) * f0\n        R_naive = -(d_xi_a_xi + d_eta_a_eta) * f0\n\n        # 6. Calculate the Root-Mean-Square (RMS) of the residual field.\n        rms_val = np.sqrt(np.mean(R_naive**2))\n        results.append(rms_val)\n\n    # Format the final output string as required.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        }
    ]
}