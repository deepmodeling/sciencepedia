{
    "hands_on_practices": [
        {
            "introduction": "Understanding random dopant fluctuations (RDF) begins with grasping how the discrete, random nature of individual dopant atoms translates into macroscopic variability. This first practice invites you to derive the fluctuation in the built-in potential of a simple p-n junction, starting from the Poisson statistics of dopant counts . By applying first-order error propagation, you will forge a direct link between the microscopic cause (dopant number variance) and the observable effect (voltage variance), a cornerstone skill in variability analysis.",
            "id": "3769009",
            "problem": "An abrupt, planar, uniformly doped silicon $p$-$n$ junction of cross-sectional area $A$ has nominal acceptor and donor densities $N_{A}$ and $N_{D}$, respectively. The built-in potential is given by $V_{bi} = (k T/q)\\,\\ln\\!\\big(N_{A} N_{D}/n_{i}^{2}\\big)$, where $k$ is the Boltzmann constant, $T$ is the absolute temperature, $q$ is the elementary charge, and $n_{i}$ is the intrinsic carrier density. Due to random dopant fluctuations (RDF), the realized acceptor and donor densities in the neighborhood of the metallurgical junction are random and can be modeled as coarse-grained estimators $\\hat{N}_{A}$ and $\\hat{N}_{D}$ formed by counting dopant atoms inside two effective sampling volumes $V_{A}$ (on the $p$-side) and $V_{D}$ (on the $n$-side), respectively, and dividing by those volumes. Assume the dopant atoms on each side form independent spatial Poisson point processes with intensities $N_{A}$ and $N_{D}$, so that the acceptor and donor counts $X_{A}$ and $X_{D}$ satisfy $X_{A} \\sim \\mathrm{Poisson}(N_{A} V_{A})$ and $X_{D} \\sim \\mathrm{Poisson}(N_{D} V_{D})$, with $\\hat{N}_{A} = X_{A}/V_{A}$ and $\\hat{N}_{D} = X_{D}/V_{D}$.\n\nStarting from the definition of $V_{bi}$ above, use first principles of error propagation from the underlying Poisson statistics to derive a leading-order expression for the standard deviation $\\sigma_{V_{bi}}$ of the random built-in potential $\\hat{V}_{bi} = (k T/q)\\,\\ln\\!\\big(\\hat{N}_{A}\\hat{N}_{D}/n_{i}^{2}\\big)$ in terms of $k$, $T$, $q$, $N_{A}$, $N_{D}$, $V_{A}$, and $V_{D}$. Clearly state and justify any approximations you make.\n\nThen, briefly analyze the regime where $N_{A} V_{A}$ or $N_{D} V_{D}$ is small enough that zero-count events are plausible, and explain how the nonlinearity of the logarithm affects both the validity of the linear propagation and the qualitative behavior of $\\hat{V}_{bi}$ in that regime. Your analysis should be based on fundamental properties of the Poisson distribution and the smoothness (or lack thereof) of the logarithm at zero, and should indicate at least one mathematically consistent regularization or correction strategy.\n\nProvide your final answer as a single closed-form analytic expression for $\\sigma_{V_{bi}}$ in terms of the specified symbols only. Do not substitute numerical values, and do not include units in the final expression.",
            "solution": "The built-in potential is defined by\n$$\nV_{bi} = \\frac{k T}{q}\\,\\ln\\!\\left(\\frac{N_{A} N_{D}}{n_{i}^{2}}\\right).\n$$\nRandom dopant fluctuations induce randomness in the coarse-grained estimates $\\hat{N}_{A}$ and $\\hat{N}_{D}$, and hence in\n$$\n\\hat{V}_{bi} = \\frac{k T}{q}\\,\\ln\\!\\left(\\frac{\\hat{N}_{A} \\hat{N}_{D}}{n_{i}^{2}}\\right) = \\frac{k T}{q}\\,\\big(\\ln \\hat{N}_{A} + \\ln \\hat{N}_{D} - 2 \\ln n_{i}\\big).\n$$\nWe model the dopants as independent spatial Poisson point processes of intensities $N_{A}$ and $N_{D}$. Therefore, the counts in the effective sampling volumes $V_{A}$ and $V_{D}$ satisfy\n$$\nX_{A} \\sim \\mathrm{Poisson}(\\lambda_{A}), \\quad \\lambda_{A} = N_{A} V_{A}, \\qquad\nX_{D} \\sim \\mathrm{Poisson}(\\lambda_{D}), \\quad \\lambda_{D} = N_{D} V_{D},\n$$\nand the coarse-grained density estimators are\n$$\n\\hat{N}_{A} = \\frac{X_{A}}{V_{A}}, \\qquad \\hat{N}_{D} = \\frac{X_{D}}{V_{D}}.\n$$\nFor large enough $\\lambda_{A}$ and $\\lambda_{D}$, $\\hat{N}_{A}$ and $\\hat{N}_{D}$ concentrate near $N_{A}$ and $N_{D}$, respectively. We may approximate the variance of $\\hat{V}_{bi}$ by first-order (delta-method) propagation around the means $(N_{A}, N_{D})$. Define\n$$\nf(N_{A}, N_{D}) = \\frac{k T}{q}\\,\\ln\\!\\left(\\frac{N_{A} N_{D}}{n_{i}^{2}}\\right) = \\frac{k T}{q}\\,(\\ln N_{A} + \\ln N_{D} - 2 \\ln n_{i}).\n$$\nThe gradient of $f$ with respect to $(N_{A}, N_{D})$ is\n$$\n\\nabla f(N_{A}, N_{D}) = \\left(\\frac{\\partial f}{\\partial N_{A}}, \\frac{\\partial f}{\\partial N_{D}}\\right) = \\left(\\frac{k T}{q}\\,\\frac{1}{N_{A}}, \\frac{k T}{q}\\,\\frac{1}{N_{D}}\\right).\n$$\nUnder the Poisson model,\n$$\n\\mathrm{var}(\\hat{N}_{A}) = \\mathrm{var}\\!\\left(\\frac{X_{A}}{V_{A}}\\right) = \\frac{\\mathrm{var}(X_{A})}{V_{A}^{2}} = \\frac{\\lambda_{A}}{V_{A}^{2}} = \\frac{N_{A}}{V_{A}}, \\qquad\n\\mathrm{var}(\\hat{N}_{D}) = \\frac{N_{D}}{V_{D}},\n$$\nand, due to independence of the $p$-side and $n$-side processes, $\\mathrm{cov}(\\hat{N}_{A}, \\hat{N}_{D}) = 0$. The covariance matrix of $(\\hat{N}_{A}, \\hat{N}_{D})$ is therefore\n$$\n\\Sigma = \\begin{pmatrix}\n\\frac{N_{A}}{V_{A}} & 0 \\\\\n0 & \\frac{N_{D}}{V_{D}}\n\\end{pmatrix}.\n$$\nThe delta-method (first-order Taylor) approximation to the variance of $\\hat{V}_{bi}$ is\n$$\n\\mathrm{var}(\\hat{V}_{bi}) \\approx \\nabla f^{\\top}\\, \\Sigma \\, \\nabla f = \\left(\\frac{k T}{q}\\right)^{2}\\left(\\frac{1}{N_{A}^{2}}\\,\\frac{N_{A}}{V_{A}} + \\frac{1}{N_{D}^{2}}\\,\\frac{N_{D}}{V_{D}}\\right) = \\left(\\frac{k T}{q}\\right)^{2}\\left(\\frac{1}{N_{A} V_{A}} + \\frac{1}{N_{D} V_{D}}\\right).\n$$\nThus, the leading-order standard deviation is\n$$\n\\sigma_{V_{bi}} \\approx \\frac{k T}{q}\\,\\sqrt{\\frac{1}{N_{A} V_{A}} + \\frac{1}{N_{D} V_{D}}}.\n$$\n\nDiscussion of nonlinearity and zero-count events. The logarithm is not defined at zero, whereas the Poisson distribution assigns nonzero probability to zero counts:\n$$\n\\Pr[X_{A} = 0] = \\exp(-N_{A} V_{A}), \\qquad \\Pr[X_{D} = 0] = \\exp(-N_{D} V_{D}).\n$$\nWhen $N_{A} V_{A}$ or $N_{D} V_{D}$ is small, these probabilities are not negligible, and the mapping $(\\hat{N}_{A}, \\hat{N}_{D}) \\mapsto \\hat{V}_{bi}$ becomes highly nonlinear with a hard singularity. In this regime:\n- The linear (delta-method) propagation fails because it implicitly assumes a smooth mapping in a neighborhood where the random variables remain in the interior of the domain. Zero counts place mass at the boundary where $\\ln$ is undefined, invalidating the linear approximation.\n- Even conditioning on positive counts, the curvature of $\\ln(\\cdot)$ induces higher-order corrections. A second-order Taylor expansion of $\\ln \\hat{N}$ about its mean shows that, for $X \\sim \\mathrm{Poisson}(\\lambda)$ with large $\\lambda$, $\\mathbb{E}[\\ln X] \\approx \\ln \\lambda - \\frac{1}{2 \\lambda} + \\mathcal{O}(\\lambda^{-2})$ and $\\mathrm{var}(\\ln X) \\approx \\lambda^{-1} + \\mathcal{O}(\\lambda^{-2})$, indicating bias and variance corrections of order $\\lambda^{-1}$ and $\\lambda^{-2}$, respectively. Translating to densities, $\\lambda = N V$.\n- A mathematically consistent regularization is to define a pseudo-count, e.g., replace $X$ by $X + \\alpha$ with a small $\\alpha > 0$ (such as $\\alpha = 1$), so that $\\ln(\\hat{N})$ is always defined. This shifts the effective intensity to $\\lambda + \\alpha$ and regularizes the singularity at zero at the cost of an explicit, controllable bias. Alternatively, one can condition on $X>0$ and work with the conditional distribution, replacing expectations by $\\mathbb{E}[\\cdot \\mid X>0]$, which removes the singularity but modifies both mean and variance.\n\nImportantly, in all such regularizations, the leading-order variance contribution for large $N V$ remains $\\sim 1/(N V)$, which is exactly the term captured by the derived expression. The breakdown occurs when $N_{A} V_{A}$ or $N_{D} V_{D}$ is not large, where higher-order terms and zero-count handling dominate and the simple square-root law underestimates the true variability and fails to describe the heavy tail introduced by possible near-zero realizations of $\\hat{N}$.",
            "answer": "$$\\boxed{\\frac{k T}{q}\\,\\sqrt{\\frac{1}{N_{A} V_{A}} + \\frac{1}{N_{D} V_{D}}}}$$"
        },
        {
            "introduction": "Having established how RDF impacts individual devices, we now address a critical circuit design challenge: how to best allocate a fixed area budget to minimize overall variability in a multi-transistor circuit. This exercise uses Pelgrom's law and device sensitivities to frame the task as a convex optimization problem . Solving it provides a powerful, systematic method for trading off area among different devices, demonstrating that the most sensitive components demand the largest share of resources to ensure circuit robustness.",
            "id": "3769078",
            "problem": "A multistage metal–oxide–semiconductor (MOS) amplifier is dominated by random dopant fluctuation induced threshold voltage variations. Consider a set of $N=5$ transistors, indexed by $i\\in\\{1,2,3,4,5\\}$, whose threshold voltage perturbations are independent and identically distributed according to Pelgrom’s mismatch law. Let $a_i=W_iL_i$ denote the allocated device area for transistor $i$. The standard deviation of threshold mismatch for each device follows Pelgrom’s law, $\\sigma_{\\Delta V_{T,i}}=A_{VT}/\\sqrt{a_i}$, where the Pelgrom area coefficient is $A_{VT}=3.0\\,\\mathrm{mV}\\cdot\\mu\\mathrm{m}$. A first-order linearization of the circuit’s output-referred offset $y$ with respect to the threshold perturbations yields $y\\approx\\sum_{i=1}^{5}s_i\\,\\Delta V_{T,i}$, where the given small-signal sensitivities are $s_1=1.5$, $s_2=1.5$, $s_3=0.5$, $s_4=1.0$, and $s_5=1.0$ (dimensionless). Assume the $\\Delta V_{T,i}$ are independent zero-mean Gaussian random variables.\n\nYou are tasked with allocating areas $\\{a_i\\}_{i=1}^{5}$ to minimize the output offset variance under a fixed total area budget. The total available area is $A_{\\mathrm{tot}}=110\\,\\mu\\mathrm{m}^2$, and you must satisfy $\\sum_{i=1}^{5}a_i=A_{\\mathrm{tot}}$ with $a_i>0$ for all $i$. Starting from the fundamental facts that (i) Pelgrom’s law links mismatch variance inversely to area and (ii) for independent zero-mean perturbations the output variance equals the sum of sensitivity-weighted input variances, perform the following:\n\n- Formulate the optimization problem to minimize the output variance in terms of the variables $a_i$ and the given constants.\n- Establish the convexity of the objective in the feasible region $\\{a_i>0,\\sum a_i=A_{\\mathrm{tot}}\\}$.\n- Solve the optimization problem using first principles (e.g., the method of Lagrange multipliers or Karush–Kuhn–Tucker conditions) to obtain the optimal $a_i^{\\star}$ in closed form in terms of the given parameters.\n- Evaluate the optimal numerical values for $a_i^{\\star}$ using the provided data.\n\nReport your final answer as a single row vector $\\bigl[a_1^{\\star},\\,a_2^{\\star},\\,a_3^{\\star},\\,a_4^{\\star},\\,a_5^{\\star}\\bigr]$ in $\\mu\\mathrm{m}^2$. Round each entry to three significant figures. Do not include units in the final boxed vector; express the entries in $\\mu\\mathrm{m}^2$ as instructed here.",
            "solution": "The problem requires finding the optimal allocation of device areas $\\{a_i\\}_{i=1}^{5}$ to minimize the output offset variance of a multistage MOS amplifier, subject to a total area constraint. The analysis will proceed by first formulating the optimization problem, then establishing its convexity, solving it using the method of Lagrange multipliers, and finally evaluating the numerical solution.\n\n**1. Formulation of the Optimization Problem**\n\nThe output-referred offset, $y$, is given as a linear combination of the threshold voltage perturbations, $\\Delta V_{T,i}$:\n$$y \\approx \\sum_{i=1}^{N} s_i \\Delta V_{T,i}$$\nwhere $N=5$ is the number of transistors and $s_i$ are the respective sensitivities. The problem states that the perturbations $\\Delta V_{T,i}$ are independent, zero-mean Gaussian random variables. The variance of the output offset, $\\sigma_y^2$, is given by:\n$$\\sigma_y^2 = \\mathrm{Var}(y) = \\mathrm{Var}\\left(\\sum_{i=1}^{N} s_i \\Delta V_{T,i}\\right)$$\nDue to the independence of the $\\Delta V_{T,i}$ variables, the variance of the sum is the sum of the variances:\n$$\\sigma_y^2 = \\sum_{i=1}^{N} \\mathrm{Var}(s_i \\Delta V_{T,i})$$\nUsing the variance property $\\mathrm{Var}(c X) = c^2 \\mathrm{Var}(X)$, where $c$ is a constant, we have:\n$$\\sigma_y^2 = \\sum_{i=1}^{N} s_i^2 \\mathrm{Var}(\\Delta V_{T,i})$$\nThe variance of the threshold voltage perturbation for device $i$, $\\mathrm{Var}(\\Delta V_{T,i})$, is the square of its standard deviation, $\\sigma_{\\Delta V_{T,i}}^2$. Pelgrom's law provides the standard deviation as $\\sigma_{\\Delta V_{T,i}} = A_{VT} / \\sqrt{a_i}$, where $a_i$ is the device area and $A_{VT}$ is the Pelgrom area coefficient. Thus, the variance is:\n$$\\mathrm{Var}(\\Delta V_{T,i}) = \\sigma_{\\Delta V_{T,i}}^2 = \\left(\\frac{A_{VT}}{\\sqrt{a_i}}\\right)^2 = \\frac{A_{VT}^2}{a_i}$$\nSubstituting this expression back into the equation for $\\sigma_y^2$, we obtain the objective function to be minimized:\n$$\\sigma_y^2(a_1, \\dots, a_N) = \\sum_{i=1}^{N} s_i^2 \\frac{A_{VT}^2}{a_i} = A_{VT}^2 \\sum_{i=1}^{N} \\frac{s_i^2}{a_i}$$\nSince $A_{VT}$ is a given positive constant, minimizing $\\sigma_y^2$ is equivalent to minimizing the function $F(a_1, \\dots, a_N)$:\n$$F(a_1, \\dots, a_N) = \\sum_{i=1}^{N} \\frac{s_i^2}{a_i}$$\nThis minimization is subject to the constraints on the device areas:\n1.  Total area constraint: $\\sum_{i=1}^{N} a_i = A_{\\mathrm{tot}}$\n2.  Positivity constraint: $a_i > 0$ for all $i \\in \\{1, \\dots, N\\}$\n\nThe complete optimization problem is:\n$$\\text{Minimize} \\quad F(\\mathbf{a}) = \\sum_{i=1}^{N} \\frac{s_i^2}{a_i}$$\n$$\\text{subject to} \\quad \\sum_{i=1}^{N} a_i = A_{\\mathrm{tot}} \\quad \\text{and} \\quad a_i > 0 \\quad \\forall i$$\n\n**2. Convexity of the Problem**\n\nTo establish that this is a convex optimization problem, we must show that both the objective function and the feasible set are convex.\nThe feasible set is defined by the constraints. The constraint $\\sum_{i=1}^{N} a_i = A_{\\mathrm{tot}}$ defines an affine hyperplane in $\\mathbb{R}^N$. The constraints $a_i > 0$ define an open convex set (the positive orthant). The intersection of an affine set and a convex set is convex. Therefore, the feasible region is a convex set.\n\nThe objective function is $F(\\mathbf{a}) = \\sum_{i=1}^{N} f_i(a_i)$, where $f_i(a_i) = s_i^2/a_i$. A function is convex if its second derivative is non-negative. For each term $f_i(a_i)$:\n$$\\frac{d f_i}{d a_i} = -\\frac{s_i^2}{a_i^2}$$\n$$\\frac{d^2 f_i}{d a_i^2} = \\frac{2 s_i^2}{a_i^3}$$\nIn the feasible region, $a_i > 0$. Since $s_i^2 \\ge 0$, the second derivative $\\frac{d^2 f_i}{d a_i^2}$ is non-negative for all $i$. Thus, each function $f_i(a_i)$ is convex on the domain $a_i > 0$. The sum of convex functions is also convex, so the objective function $F(\\mathbf{a})$ is convex.\n\nSince we are minimizing a convex function over a convex set, any local minimum found is a global minimum.\n\n**3. Solving the Optimization Problem**\n\nWe use the method of Lagrange multipliers to solve this constrained optimization problem. The Lagrangian function $\\mathcal{L}$ is constructed by combining the objective function and the equality constraint:\n$$\\mathcal{L}(\\mathbf{a}, \\lambda) = F(\\mathbf{a}) - \\lambda \\left(\\sum_{i=1}^{N} a_i - A_{\\mathrm{tot}}\\right) = \\sum_{i=1}^{N} \\frac{s_i^2}{a_i} - \\lambda \\left(\\sum_{i=1}^{N} a_i - A_{\\mathrm{tot}}\\right)$$\nThe optimal solution must satisfy the Karush-Kuhn-Tucker (KKT) conditions. We find the stationary points by setting the gradient of the Lagrangian with respect to $\\mathbf{a}$ and $\\lambda$ to zero. For each $j \\in \\{1, \\dots, N\\}$:\n$$\\frac{\\partial \\mathcal{L}}{\\partial a_j} = -\\frac{s_j^2}{a_j^2} - \\lambda = 0$$\nThis implies:\n$$-\\frac{s_j^2}{a_j^2} = \\lambda \\implies a_j^2 = -\\frac{s_j^2}{\\lambda}$$\nSince $a_j > 0$ and $s_j^2 \\ge 0$, we must have $\\lambda < 0$. We can solve for $a_j$:\n$$a_j = \\sqrt{-\\frac{s_j^2}{\\lambda}} = \\frac{|s_j|}{\\sqrt{-\\lambda}}$$\nThe given sensitivities $s_j$ are positive, so $|s_j| = s_j$.\n$$a_j = \\frac{s_j}{\\sqrt{-\\lambda}}$$\nNow we use the total area constraint $\\sum_{j=1}^{N} a_j = A_{\\mathrm{tot}}$ to find the value of the Lagrange multiplier $\\lambda$:\n$$\\sum_{j=1}^{N} \\frac{s_j}{\\sqrt{-\\lambda}} = A_{\\mathrm{tot}}$$\nFactoring out the term with $\\lambda$:\n$$\\frac{1}{\\sqrt{-\\lambda}} \\sum_{j=1}^{N} s_j = A_{\\mathrm{tot}}$$\n$$\\frac{1}{\\sqrt{-\\lambda}} = \\frac{A_{\\mathrm{tot}}}{\\sum_{k=1}^{N} s_k}$$\nSubstituting this expression back into the equation for $a_j$:\n$$a_j^{\\star} = s_j \\left(\\frac{1}{\\sqrt{-\\lambda}}\\right) = s_j \\frac{A_{\\mathrm{tot}}}{\\sum_{k=1}^{N} s_k}$$\nThis expression gives the optimal area allocation $a_j^{\\star}$ for each transistor. This result shows that the total area $A_{\\mathrm{tot}}$ should be partitioned among the transistors in direct proportion to their sensitivities $s_j$. Since all $s_j > 0$ and $A_{\\mathrm{tot}} > 0$, the condition $a_j^{\\star} > 0$ is satisfied.\n\n**4. Numerical Evaluation**\n\nWe now substitute the given numerical values into the derived formula.\nThe number of transistors is $N=5$.\nThe total area is $A_{\\mathrm{tot}} = 110\\,\\mu\\mathrm{m}^2$.\nThe sensitivities are $s_1=1.5$, $s_2=1.5$, $s_3=0.5$, $s_4=1.0$, and $s_5=1.0$.\n\nFirst, we compute the sum of the sensitivities:\n$$\\sum_{k=1}^{5} s_k = 1.5 + 1.5 + 0.5 + 1.0 + 1.0 = 5.5$$\nNow we can calculate the optimal area for each transistor:\n$$a_1^{\\star} = A_{\\mathrm{tot}} \\frac{s_1}{\\sum s_k} = 110\\,\\mu\\mathrm{m}^2 \\times \\frac{1.5}{5.5} = 110 \\times \\frac{3}{11}\\,\\mu\\mathrm{m}^2 = 30\\,\\mu\\mathrm{m}^2$$\n$$a_2^{\\star} = A_{\\mathrm{tot}} \\frac{s_2}{\\sum s_k} = 110\\,\\mu\\mathrm{m}^2 \\times \\frac{1.5}{5.5} = 110 \\times \\frac{3}{11}\\,\\mu\\mathrm{m}^2 = 30\\,\\mu\\mathrm{m}^2$$\n$$a_3^{\\star} = A_{\\mathrm{tot}} \\frac{s_3}{\\sum s_k} = 110\\,\\mu\\mathrm{m}^2 \\times \\frac{0.5}{5.5} = 110 \\times \\frac{1}{11}\\,\\mu\\mathrm{m}^2 = 10\\,\\mu\\mathrm{m}^2$$\n$$a_4^{\\star} = A_{\\mathrm{tot}} \\frac{s_4}{\\sum s_k} = 110\\,\\mu\\mathrm{m}^2 \\times \\frac{1.0}{5.5} = 110 \\times \\frac{2}{11}\\,\\mu\\mathrm{m}^2 = 20\\,\\mu\\mathrm{m}^2$$\n$$a_5^{\\star} = A_{\\mathrm{tot}} \\frac{s_5}{\\sum s_k} = 110\\,\\mu\\mathrm{m}^2 \\times \\frac{1.0}{5.5} = 110 \\times \\frac{2}{11}\\,\\mu\\mathrm{m}^2 = 20\\,\\mu\\mathrm{m}^2$$\nThe problem requires rounding to three significant figures. The calculated integer values are expressed with one decimal place to meet this requirement.\nThe optimal areas are:\n$a_1^{\\star} = 30.0\\,\\mu\\mathrm{m}^2$\n$a_2^{\\star} = 30.0\\,\\mu\\mathrm{m}^2$\n$a_3^{\\star} = 10.0\\,\\mu\\mathrm{m}^2$\n$a_4^{\\star} = 20.0\\,\\mu\\mathrm{m}^2$\n$a_5^{\\star} = 20.0\\,\\mu\\mathrm{m}^2$\n\nThe final answer is a row vector of these values.",
            "answer": "$$\n\\boxed{\n[30.0 \\quad 30.0 \\quad 10.0 \\quad 20.0 \\quad 20.0]\n}\n$$"
        },
        {
            "introduction": "In advanced technology nodes, Random Dopant Fluctuations (RDF) coexist with other variability sources, such as Metal Gate Granularity (MGG). This final practice teaches a crucial skill for device modelers and characterization engineers: how to experimentally separate these confounding effects. You will discover that different physical mechanisms leave distinct 'fingerprints' on the drain current variance as a function of bias voltage . By deriving these signatures and formulating a diagnostic metric, you will learn to design measurements that can isolate and quantify the contribution of RDF to total device variability.",
            "id": "3769089",
            "problem": "Consider a short-channel Metal-Oxide-Semiconductor Field-Effect Transistor (MOSFET) whose device-to-device variability arises from two independent microscopic sources: Random Dopant Fluctuations (RDF) in the channel and Metal Gate Granularity (MGG) in the gate electrode. Treat each source as producing zero-mean random perturbations to long-channel parameters with the following physically motivated signatures:\n- RDF induces a random threshold voltage shift $\\delta V_{T}^{R}$ and a random drain-induced barrier lowering (DIBL) factor perturbation $\\delta \\lambda^{R}$ via stochastic variations in depletion charge and electrostatic coupling. Assume $\\delta V_{T}^{R}$ and $\\delta \\lambda^{R}$ are independent of Metal Gate Granularity and have variances $\\sigma_{R}^{2}$ and $\\sigma_{\\lambda}^{2}$, respectively.\n- MGG induces a random effective metal work function shift that maps to a threshold voltage shift $\\delta V_{T}^{M}$ with variance $\\sigma_{M}^{2}$ but negligibly perturbs the DIBL factor, so $\\delta \\lambda^{M} \\approx 0$.\n\nAssume that RDF and MGG are statistically independent, so the total threshold perturbation is $\\delta V_{T}=\\delta V_{T}^{R}+\\delta V_{T}^{M}$ with variance $\\sigma_{V_{T}}^{2}=\\sigma_{R}^{2}+\\sigma_{M}^{2}$, and the total DIBL perturbation is $\\delta \\lambda=\\delta \\lambda^{R}$ with variance $\\sigma_{\\lambda}^{2}$. Let $U_{T}=k_{B}T/q$ denote the thermal voltage and $n$ the subthreshold slope factor.\n\nModel the drain current $I_{D}$ in the two bias regimes using well-tested compact expressions:\n- Weak inversion (subthreshold): $I_{D}=I_{S}\\exp\\!\\left(\\frac{V_{G}-V_{T}-\\lambda V_{D}}{nU_{T}}\\right)$, where $I_{S}$ is a device constant that does not depend on $\\delta V_{T}$ or $\\delta \\lambda$.\n- Strong inversion, linear region with small drain bias: $I_{D}\\approx K\\left(V_{G}-V_{T}-\\lambda V_{D}\\right)V_{D}$, where $K=\\mu C_{\\mathrm{ox}}\\frac{W}{L}$ is the transconductance prefactor determined by mobility $\\mu$, oxide capacitance per unit area $C_{\\mathrm{ox}}$, width $W$, and length $L$.\n\nTreat the random perturbations as small and use first-order propagation of uncertainty to obtain ensemble variability signatures. Then:\n1. Derive the bias dependence of the ensemble variance of $\\ln I_{D}$ in weak inversion, $\\mathrm{Var}[\\ln I_{D}](V_{G},V_{D})$, in terms of $\\sigma_{V_{T}}^{2}$, $\\sigma_{\\lambda}^{2}$, $n$, $U_{T}$, and $V_{D}$.\n2. Derive the bias dependence of the ensemble variance of the relative linear-region current $\\delta I_{D}/I_{D}$ in strong inversion for fixed $V_{G}$ and variable $V_{D}$, in terms of $\\sigma_{V_{T}}^{2}$, $\\sigma_{\\lambda}^{2}$, and the overdrive $V_{G}-V_{T}-\\lambda V_{D}$.\n3. Using the weak inversion result, propose a two-point diagnostic that separates the RDF signature (through $\\sigma_{\\lambda}^{2}$) from the overall threshold variability (through $\\sigma_{V_{T}}^{2}$) by measuring $\\mathrm{Var}[\\ln I_{D}]$ at a fixed $V_{G}$ and two distinct drain biases $V_{D1}$ and $V_{D2}$. Let $\\mathcal{S}_{1}=\\mathrm{Var}[\\ln I_{D}](V_{G},V_{D1})$ and $\\mathcal{S}_{2}=\\mathrm{Var}[\\ln I_{D}](V_{G},V_{D2})$ be the measured ensemble variances. Define the dimensionless RDF-separation metric $S$ as the ratio between the $V_{D}^{2}$ slope and the zero-drain-bias intercept of the weak inversion $\\mathrm{Var}[\\ln I_{D}]$ vs. $V_{D}^{2}$ characteristic. \n\nProvide the final analytic expression for $S$ solely in terms of $V_{D1}$, $V_{D2}$, $\\mathcal{S}_{1}$, and $\\mathcal{S}_{2}$. Your expression must not depend on any unmeasured or device-specific constants. The answer must be a single closed-form analytic expression. No numerical evaluation is required.",
            "solution": "The solution proceeds by first deriving the expressions requested in tasks $1$ and $2$, and then using the result of task $1$ to solve task $3$.\n\n**1. Derivation of $\\mathrm{Var}[\\ln I_{D}]$ in Weak Inversion**\n\nIn the weak inversion regime, the drain current $I_D$ is given by:\n$$I_{D}=I_{S}\\exp\\!\\left(\\frac{V_{G}-V_{T}-\\lambda V_{D}}{nU_{T}}\\right)$$\nTaking the natural logarithm of this expression yields:\n$$\\ln I_{D} = \\ln I_{S} + \\frac{V_{G}-V_{T}-\\lambda V_{D}}{nU_{T}}$$\nThe parameters $V_{T}$ and $\\lambda$ are random variables with mean values $\\langle V_{T} \\rangle$ and $\\langle \\lambda \\rangle$ and small, zero-mean perturbations $\\delta V_{T}$ and $\\delta \\lambda$, respectively, such that $V_{T} = \\langle V_{T} \\rangle + \\delta V_{T}$ and $\\lambda = \\langle \\lambda \\rangle + \\delta \\lambda$.\nThe perturbation in $\\ln I_{D}$ to first order is:\n$$\\delta(\\ln I_{D}) = \\ln I_{D} - \\langle \\ln I_{D} \\rangle \\approx \\frac{\\partial(\\ln I_{D})}{\\partial V_{T}}\\delta V_{T} + \\frac{\\partial(\\ln I_{D})}{\\partial \\lambda}\\delta \\lambda$$\nThe partial derivatives are:\n$$\\frac{\\partial(\\ln I_{D})}{\\partial V_{T}} = -\\frac{1}{nU_{T}}$$\n$$\\frac{\\partial(\\ln I_{D})}{\\partial \\lambda} = -\\frac{V_{D}}{nU_{T}}$$\nThus, the perturbation is:\n$$\\delta(\\ln I_{D}) \\approx -\\frac{1}{nU_{T}}\\delta V_{T} - \\frac{V_{D}}{nU_{T}}\\delta \\lambda = -\\frac{1}{nU_{T}}(\\delta V_{T} + V_{D}\\delta \\lambda)$$\nThe variance of $\\ln I_{D}$ is the expectation of the square of its perturbation, since the perturbations are zero-mean:\n$$\\mathrm{Var}[\\ln I_{D}] = \\mathrm{E}[(\\delta(\\ln I_{D}))^{2}] = \\mathrm{E}\\left[ \\left(-\\frac{1}{nU_{T}}(\\delta V_{T} + V_{D}\\delta \\lambda)\\right)^{2} \\right]$$\n$$\\mathrm{Var}[\\ln I_{D}] = \\frac{1}{(nU_{T})^{2}} \\mathrm{E}[(\\delta V_{T} + V_{D}\\delta \\lambda)^{2}] = \\frac{1}{(nU_{T})^{2}} \\mathrm{E}[\\delta V_{T}^{2} + 2V_{D}\\delta V_{T}\\delta \\lambda + V_{D}^{2}\\delta \\lambda^{2}]$$\nUsing the linearity of expectation:\n$$\\mathrm{Var}[\\ln I_{D}] = \\frac{1}{(nU_{T})^{2}} (\\mathrm{E}[\\delta V_{T}^{2}] + 2V_{D}\\mathrm{E}[\\delta V_{T}\\delta \\lambda] + V_{D}^{2}\\mathrm{E}[\\delta \\lambda^{2}])$$\nThe term $\\mathrm{E}[\\delta V_{T}^{2}]$ is the variance of the total threshold voltage shift, $\\sigma_{V_{T}}^{2}$. The term $\\mathrm{E}[\\delta \\lambda^{2}]$ is the variance of the DIBL factor, $\\sigma_{\\lambda}^{2}$. The covariance term is $\\mathrm{E}[\\delta V_{T}\\delta \\lambda] = \\mathrm{E}[(\\delta V_{T}^{R}+\\delta V_{T}^{M})(\\delta \\lambda^{R})]$ since $\\delta\\lambda = \\delta\\lambda^{R}$. This expands to $\\mathrm{E}[\\delta V_{T}^{R}\\delta \\lambda^{R}] + \\mathrm{E}[\\delta V_{T}^{M}\\delta \\lambda^{R}]$. As MGG and RDF are independent, $\\mathrm{E}[\\delta V_{T}^{M}\\delta \\lambda^{R}] = \\mathrm{E}[\\delta V_{T}^{M}]\\mathrm{E}[\\delta \\lambda^{R}] = 0 \\times 0 = 0$. The problem does not provide a correlation coefficient between $\\delta V_{T}^{R}$ and $\\delta \\lambda^{R}$. In the context of such separation problems, if not specified, this correlation is assumed to be zero for analytical tractability. Hence, we assume $\\mathrm{E}[\\delta V_{T}\\delta \\lambda] = 0$.\nThe expression for the variance simplifies to:\n$$\\mathrm{Var}[\\ln I_{D}](V_{D}) = \\frac{1}{(nU_{T})^{2}} (\\sigma_{V_{T}}^{2} + \\sigma_{\\lambda}^{2}V_{D}^{2})$$\nThis completes the first task.\n\n**2. Derivation of $\\mathrm{Var}[\\delta I_{D}/I_{D}]$ in Strong Inversion (Linear)**\n\nFor the linear region in strong inversion, the current is $I_{D} \\approx K(V_{G}-V_{T}-\\lambda V_{D})V_{D}$. Let $I_{D,0}$ be the mean current, corresponding to mean values $\\langle V_{T} \\rangle$ and $\\langle \\lambda \\rangle$.\nThe first-order perturbation $\\delta I_{D}$ is:\n$$\\delta I_{D} \\approx \\frac{\\partial I_{D}}{\\partial V_{T}}\\delta V_{T} + \\frac{\\partial I_{D}}{\\partial \\lambda}\\delta \\lambda$$\nThe partial derivatives are:\n$$\\frac{\\partial I_{D}}{\\partial V_{T}} = -KV_{D}$$\n$$\\frac{\\partial I_{D}}{\\partial \\lambda} = -KV_{D}^{2}$$\nThe relative current perturbation is $\\delta I_{D} / I_{D,0}$:\n$$\\frac{\\delta I_{D}}{I_{D,0}} \\approx \\frac{-KV_{D}\\delta V_{T} - KV_{D}^{2}\\delta \\lambda}{K(V_{G}-\\langle V_{T} \\rangle - \\langle \\lambda \\rangle V_{D})V_{D}} = -\\frac{\\delta V_{T} + V_{D}\\delta \\lambda}{V_{G}-\\langle V_{T} \\rangle - \\langle \\lambda \\rangle V_{D}}$$\nThe denominator is the effective gate overdrive voltage. The variance of this relative perturbation is:\n$$\\mathrm{Var}\\left[\\frac{\\delta I_{D}}{I_{D}}\\right] = \\mathrm{E}\\left[\\left( \\frac{\\delta I_{D}}{I_{D,0}} \\right)^{2}\\right] = \\frac{1}{(V_{G}-\\langle V_{T} \\rangle - \\langle \\lambda \\rangle V_{D})^{2}} \\mathrm{E}[(\\delta V_{T} + V_{D}\\delta \\lambda)^{2}]$$\nUsing the same reasoning as for the weak inversion case (uncorrelated $\\delta V_T$ and $\\delta \\lambda$):\n$$\\mathrm{Var}\\left[\\frac{\\delta I_{D}}{I_{D}}\\right] = \\frac{\\sigma_{V_{T}}^{2} + \\sigma_{\\lambda}^{2}V_{D}^{2}}{(V_{G}-\\langle V_{T} \\rangle - \\langle \\lambda \\rangle V_{D})^{2}}$$\nThis completes the second task.\n\n**3. Separation of RDF Signature using the Two-Point Diagnostic**\n\nFrom task $1$, the variance of $\\ln I_{D}$ in weak inversion is a linear function of $V_{D}^{2}$:\n$$\\mathrm{Var}[\\ln I_{D}] = A + B V_{D}^{2}$$\nwhere the intercept $A$ and slope $B$ are given by:\n$$A = \\frac{\\sigma_{V_{T}}^{2}}{(nU_{T})^{2}}$$\n$$B = \\frac{\\sigma_{\\lambda}^{2}}{(nU_{T})^{2}}$$\nThe problem defines the RDF-separation metric $S$ as the ratio of the slope $B$ to the intercept $A$ of this linear relationship:\n$$S = \\frac{B}{A} = \\frac{\\sigma_{\\lambda}^{2} / (nU_{T})^{2}}{\\sigma_{V_{T}}^{2} / (nU_{T})^{2}} = \\frac{\\sigma_{\\lambda}^{2}}{\\sigma_{V_{T}}^{2}}$$\nWe are given two measurements of the variance at two distinct drain biases, $V_{D1}$ and $V_{D2}$:\n$$\\mathcal{S}_{1} = \\mathrm{Var}[\\ln I_{D}](V_{D1}) = A + B V_{D1}^{2}$$\n$$\\mathcal{S}_{2} = \\mathrm{Var}[\\ln I_{D}](V_{D2}) = A + B V_{D2}^{2}$$\nThis is a system of two linear equations for the two unknowns, $A$ and $B$. To solve for $A$ and $B$, we first subtract the first equation from the second to find $B$:\n$$\\mathcal{S}_{2} - \\mathcal{S}_{1} = (A + B V_{D2}^{2}) - (A + B V_{D1}^{2}) = B(V_{D2}^{2} - V_{D1}^{2})$$\n$$B = \\frac{\\mathcal{S}_{2} - \\mathcal{S}_{1}}{V_{D2}^{2} - V_{D1}^{2}}$$\nNext, we solve for $A$ by substituting this expression for $B$ into the first equation:\n$$A = \\mathcal{S}_{1} - B V_{D1}^{2} = \\mathcal{S}_{1} - \\left(\\frac{\\mathcal{S}_{2} - \\mathcal{S}_{1}}{V_{D2}^{2} - V_{D1}^{2}}\\right)V_{D1}^{2}$$\nTo simplify $A$, we find a common denominator:\n$$A = \\frac{\\mathcal{S}_{1}(V_{D2}^{2} - V_{D1}^{2}) - (\\mathcal{S}_{2} - \\mathcal{S}_{1})V_{D1}^{2}}{V_{D2}^{2} - V_{D1}^{2}} = \\frac{\\mathcal{S}_{1}V_{D2}^{2} - \\mathcal{S}_{1}V_{D1}^{2} - \\mathcal{S}_{2}V_{D1}^{2} + \\mathcal{S}_{1}V_{D1}^{2}}{V_{D2}^{2} - V_{D1}^{2}}$$\n$$A = \\frac{\\mathcal{S}_{1}V_{D2}^{2} - \\mathcal{S}_{2}V_{D1}^{2}}{V_{D2}^{2} - V_{D1}^{2}}$$\nFinally, we compute the desired metric $S = B/A$:\n$$S = \\frac{\\frac{\\mathcal{S}_{2} - \\mathcal{S}_{1}}{V_{D2}^{2} - V_{D1}^{2}}}{\\frac{\\mathcal{S}_{1}V_{D2}^{2} - \\mathcal{S}_{2}V_{D1}^{2}}{V_{D2}^{2} - V_{D1}^{2}}}$$\nThe common denominator $(V_{D2}^{2} - V_{D1}^{2})$ cancels, as $V_{D1} \\neq V_{D2}$, yielding the final expression for $S$:\n$$S = \\frac{\\mathcal{S}_{2} - \\mathcal{S}_{1}}{\\mathcal{S}_{1}V_{D2}^{2} - \\mathcal{S}_{2}V_{D1}^{2}}$$\nThis expression depends only on the measured quantities $\\mathcal{S}_{1}$, $\\mathcal{S}_{2}$ and the corresponding biases $V_{D1}$, $V_{D2}$, as required.",
            "answer": "$$\\boxed{\\frac{\\mathcal{S}_{2} - \\mathcal{S}_{1}}{\\mathcal{S}_{1}V_{D2}^{2} - \\mathcal{S}_{2}V_{D1}^{2}}}$$"
        }
    ]
}