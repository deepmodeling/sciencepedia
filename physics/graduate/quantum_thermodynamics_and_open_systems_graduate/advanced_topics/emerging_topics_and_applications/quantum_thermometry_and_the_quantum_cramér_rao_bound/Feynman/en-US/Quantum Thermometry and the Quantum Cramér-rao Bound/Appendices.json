{
    "hands_on_practices": [
        {
            "introduction": "To build our understanding of quantum thermometry, we begin with the simplest possible probe: a single two-level system, or qubit. By calculating the Quantum Fisher Information for a qubit in thermal equilibrium, we can determine its ultimate temperature sensitivity as dictated by the Quantum Cramér-Rao Bound. This foundational exercise  not only provides a concrete benchmark for precision but also illustrates the direct relationship between a system's energy spectrum and its metrological potential.",
            "id": "3781759",
            "problem": "Consider a two-level quantum probe with Hamiltonian $H = (\\Delta/2)\\,\\sigma_{z}$, where $\\Delta>0$ is the energy gap and $\\sigma_{z}$ is the Pauli-$z$ operator. The probe is weakly coupled to a large thermal reservoir at an unknown temperature $T$, so that, before each measurement, the probe is prepared in the canonical Gibbs state $\\rho(T) = \\exp(-\\beta H)/Z$ with $\\beta = 1/(k_{B} T)$ and $Z = \\mathrm{Tr}[\\exp(-\\beta H)]$. You employ the following protocol for quantum thermometry: prepare $n$ independent and identically distributed probes in $\\rho(T)$ and perform projective measurements in the energy eigenbasis $\\{|e\\rangle, |g\\rangle\\}$ of $H$, recording the outcomes.\n\nUsing only foundational definitions from quantum statistical mechanics and the general parameter-estimation framework (in particular, the definition of the canonical ensemble, the definition of Fisher information, and the Quantum Cramér-Rao Bound (QCRB) stating that for any unbiased estimator $\\hat{T}$ one has $\\mathrm{Var}(\\hat{T}) \\ge 1/[n F_{Q}(T)]$, where $F_{Q}(T)$ is the Quantum Fisher Information), derive the closed-form analytic expression for the QCRB $\\mathrm{Var}(\\hat{T})$ under this protocol as a function of $\\Delta$, $k_{B}$, $T$, and $n$. You may use that for a Gibbs state diagonal in the measurement basis, the optimal projective energy measurement achieves the Quantum Fisher Information.\n\nAdditionally, suppose you have a fixed total interrogation-time budget $\\mathcal{R}$ and the probe relaxes towards $\\rho(T)$ with a rate $\\gamma$ (so that equilibration on each run requires a preparation time on the order of $1/\\gamma$). Discuss, without computing new formulas, how this resource constraint should be allocated across the number of probes $n$ and per-probe preparation time to minimize the QCRB, explaining the scaling logic that follows from your derived bound.\n\nExpress the final lower bound on $\\mathrm{Var}(\\hat{T})$ as a single closed-form analytic expression. If you were to report a numerical value, it should be given in Kelvin squared. No rounding is required in this problem.",
            "solution": "The problem is first validated against the specified criteria.\n\n### Problem Validation\n\n**Step 1: Extract Givens**\n- Probe Hamiltonian: $H = (\\Delta/2)\\,\\sigma_{z}$, with $\\Delta > 0$.\n- Probe state: Canonical Gibbs state $\\rho(T) = \\exp(-\\beta H)/Z$.\n- Inverse temperature: $\\beta = 1/(k_{B} T)$.\n- Partition function: $Z = \\mathrm{Tr}[\\exp(-\\beta H)]$.\n- Measurement protocol: For each of $n$ independent and identically distributed (i.i.d.) probes, perform projective measurements in the energy eigenbasis $\\{|e\\rangle, |g\\rangle\\}$.\n- Parameter estimation framework: Quantum Cramér-Rao Bound (QCRB) for an unbiased estimator $\\hat{T}$ is $\\mathrm{Var}(\\hat{T}) \\ge 1/[n F_{Q}(T)]$, where $F_{Q}(T)$ is the Quantum Fisher Information.\n- Key assumption: For a Gibbs state diagonal in the measurement basis, the optimal projective energy measurement achieves the Quantum Fisher Information.\n- First objective: Derive the closed-form analytic expression for the QCRB on $\\mathrm{Var}(\\hat{T})$ as a function of $\\Delta$, $k_{B}$, $T$, and $n$.\n- Second objective: Discuss the optimal allocation of a total interrogation time $\\mathcal{R}$ between the number of probes $n$ and per-probe preparation time, given a relaxation rate $\\gamma$.\n\n**Step 2: Validate Using Extracted Givens**\n- **Scientifically Grounded:** The problem is firmly rooted in the standard theoretical framework of quantum thermodynamics and quantum metrology. The use of a two-level system as a quantum probe, the canonical Gibbs ensemble, and the Quantum Cramér-Rao bound are all well-established concepts. The setup is a canonical model for quantum thermometry.\n- **Well-Posed:** The problem is well-posed. It provides all necessary information—the Hamiltonian, the state, the measurement scheme, and the relevant theoretical bounds—to derive a unique analytical expression for the thermometric precision. The objectives are stated clearly.\n- **Objective:** The language is formal, precise, and devoid of subjective or ambiguous terminology.\n\nThe problem does not exhibit any of the invalidity flaws:\n1.  **Scientific or Factual Unsoundness:** None. The physics is standard and correct.\n2.  **Non-Formalizable or Irrelevant:** None. The problem is a formal and central topic in quantum sensing.\n3.  **Incomplete or Contradictory Setup:** None. The information is self-contained and sufficient for the derivation. The provided information that the energy measurement is optimal is a crucial simplifying step, but it is a known result for this specific scenario and does not introduce a contradiction.\n4.  **Unrealistic or Infeasible:** None. The model is an idealized but physically relevant representation of a quantum thermometer.\n5.  **Ill-Posed or Poorly Structured:** None. A unique, stable solution exists and is derivable from the premises.\n6.  **Pseudo-Profound, Trivial, or Tautological:** None. The problem requires a standard but substantive derivation involving concepts from quantum statistical mechanics and estimation theory.\n7.  **Outside Scientific Verifiability:** None. The results are mathematically verifiable.\n\n**Step 3: Verdict and Action**\nThe problem is deemed **valid**. A full solution will be provided.\n\n### Solution Derivation\n\nThe first step is to characterize the quantum system. The Hamiltonian is $H = (\\Delta/2)\\,\\sigma_{z}$. In the standard basis where $\\sigma_z$ is diagonal, the energy eigenstates are the ground state $|g\\rangle$ and the excited state $|e\\rangle$, with corresponding energy eigenvalues $E_g = -\\Delta/2$ and $E_e = +\\Delta/2$. The energy gap is $E_e - E_g = \\Delta$.\n\nThe probe is in a thermal Gibbs state $\\rho(T) = \\exp(-\\beta H)/Z$ at inverse temperature $\\beta = 1/(k_B T)$. The partition function $Z$ is calculated by summing over the energy eigenvalues:\n$$Z = \\mathrm{Tr}[\\exp(-\\beta H)] = \\exp(-\\beta E_e) + \\exp(-\\beta E_g) = \\exp\\left(-\\frac{\\beta \\Delta}{2}\\right) + \\exp\\left(\\frac{\\beta \\Delta}{2}\\right) = 2 \\cosh\\left(\\frac{\\beta \\Delta}{2}\\right)$$\nThe diagonal elements of the density matrix $\\rho(T)$ give the probabilities of finding the probe in the energy eigenstates upon measurement. These probabilities are:\n$$p_e(T) = \\frac{\\exp(-\\beta E_e)}{Z} = \\frac{\\exp(-\\beta \\Delta/2)}{2 \\cosh(\\beta \\Delta/2)}$$\n$$p_g(T) = \\frac{\\exp(-\\beta E_g)}{Z} = \\frac{\\exp(+\\beta \\Delta/2)}{2 \\cosh(\\beta \\Delta/2)}$$\nNote that $p_e(T) + p_g(T) = 1$.\n\nThe problem states that for this system, the Quantum Fisher Information (QFI), $F_Q(T)$, is equal to the classical Fisher information (CFI), $F_C(T)$, obtained from the probabilities of the energy measurement outcomes. The CFI for a parameter $T$ derived from a set of probabilities $\\{p_i(T)\\}$ is given by the general formula:\n$$F_C(T) = \\sum_i \\frac{1}{p_i(T)} \\left(\\frac{\\partial p_i(T)}{\\partial T}\\right)^2$$\nFor our two-outcome measurement (outcomes $e$ and $g$), this becomes:\n$$F_Q(T) = F_C(T) = \\frac{1}{p_e(T)}\\left(\\frac{\\partial p_e(T)}{\\partial T}\\right)^2 + \\frac{1}{p_g(T)}\\left(\\frac{\\partial p_g(T)}{\\partial T}\\right)^2$$\nSince $p_e(T) + p_g(T) = 1$, we have $\\frac{\\partial p_e(T)}{\\partial T} = - \\frac{\\partial p_g(T)}{\\partial T}$. Substituting this into the expression for $F_C(T)$ yields a more compact form:\n$$F_C(T) = \\left(\\frac{\\partial p_e(T)}{\\partial T}\\right)^2 \\left(\\frac{1}{p_e(T)} + \\frac{1}{p_g(T)}\\right) = \\frac{1}{p_e(T)p_g(T)}\\left(\\frac{\\partial p_e(T)}{\\partial T}\\right)^2$$\nTo compute this, we first find the derivative of $p_e(T)$ with respect to $T$. It is computationally more convenient to use the chain rule with $\\beta = 1/(k_B T)$: $\\frac{\\partial}{\\partial T} = \\frac{\\partial \\beta}{\\partial T} \\frac{\\partial}{\\partial \\beta} = -\\frac{1}{k_B T^2} \\frac{\\partial}{\\partial \\beta}$.\n\nLet's first express $p_e$ in a simpler form for differentiation:\n$$p_e(\\beta) = \\frac{\\exp(-\\beta \\Delta/2)}{\\exp(-\\beta \\Delta/2) + \\exp(\\beta \\Delta/2)} = \\frac{1}{1 + \\exp(\\beta \\Delta)}$$\nNow, we differentiate with respect to $\\beta$:\n$$\\frac{\\partial p_e}{\\partial \\beta} = \\frac{\\partial}{\\partial \\beta} \\left(1 + \\exp(\\beta\\Delta)\\right)^{-1} = -1 \\cdot \\left(1 + \\exp(\\beta\\Delta)\\right)^{-2} \\cdot \\left(\\Delta \\exp(\\beta\\Delta)\\right) = -\\frac{\\Delta \\exp(\\beta\\Delta)}{\\left(1 + \\exp(\\beta\\Delta)\\right)^2}$$\nNext, we determine the term $p_e p_g$:\n$$p_e p_g = \\frac{1}{1 + \\exp(\\beta\\Delta)} \\cdot \\left(1 - \\frac{1}{1 + \\exp(\\beta\\Delta)}\\right) = \\frac{1}{1 + \\exp(\\beta\\Delta)} \\cdot \\frac{\\exp(\\beta\\Delta)}{1 + \\exp(\\beta\\Delta)} = \\frac{\\exp(\\beta\\Delta)}{\\left(1 + \\exp(\\beta\\Delta)\\right)^2}$$\nComparing these two expressions, we see that $\\frac{\\partial p_e}{\\partial \\beta} = -\\Delta \\cdot (p_e p_g)$.\nNow we can compute $\\frac{\\partial p_e}{\\partial T}$:\n$$\\frac{\\partial p_e}{\\partial T} = -\\frac{1}{k_B T^2}\\frac{\\partial p_e}{\\partial \\beta} = -\\frac{1}{k_B T^2} (-\\Delta \\cdot p_e p_g) = \\frac{\\Delta}{k_B T^2} p_e p_g$$\nSubstituting this into the expression for $F_C(T)$:\n$$F_Q(T) = F_C(T) = \\frac{1}{p_e p_g} \\left(\\frac{\\Delta}{k_B T^2} p_e p_g\\right)^2 = \\frac{(\\Delta p_e p_g)^2}{(k_B T^2)^2 (p_e p_g)} = \\frac{\\Delta^2}{(k_B T^2)^2} p_e p_g$$\nTo get the final expression, we substitute the form for $p_e p_g$ in terms of hyperbolic functions:\n$$p_e p_g = \\frac{1}{2 \\cosh(\\beta\\Delta/2)} \\frac{\\exp(-\\beta\\Delta/2) \\exp(\\beta\\Delta/2)}{2 \\cosh(\\beta\\Delta/2)} = \\frac{1}{4 \\cosh^2(\\beta\\Delta/2)} = \\frac{1}{4} \\text{sech}^2\\left(\\frac{\\beta\\Delta}{2}\\right)$$\nThus, the Quantum Fisher Information is:\n$$F_Q(T) = \\frac{\\Delta^2}{(k_B T^2)^2} \\frac{1}{4} \\text{sech}^2\\left(\\frac{\\beta\\Delta}{2}\\right) = \\frac{\\Delta^2}{4 k_B^2 T^4} \\text{sech}^2\\left(\\frac{\\Delta}{2 k_B T}\\right)$$\nThe Quantum Cramér-Rao Bound states that the variance of any unbiased estimator $\\hat{T}$ is bounded by $\\mathrm{Var}(\\hat{T}) \\ge \\frac{1}{n F_Q(T)}$. The lower bound, which represents the ultimate precision achievable, is therefore:\n$$\\mathrm{Var}(\\hat{T})_{\\text{QCRB}} = \\frac{1}{n F_Q(T)} = \\frac{1}{n} \\left( \\frac{\\Delta^2}{4 k_B^2 T^4} \\text{sech}^2\\left(\\frac{\\Delta}{2 k_B T}\\right) \\right)^{-1} = \\frac{4 k_B^2 T^4}{n \\Delta^2} \\cosh^2\\left(\\frac{\\Delta}{2 k_B T}\\right)$$\n\n### Resource Allocation Discussion\n\nThe second part of the problem asks for a qualitative discussion on resource allocation. We have a fixed total interrogation time $\\mathcal{R}$. The thermometry protocol consists of $n$ repetitions, with each repetition requiring a preparation time $t_p$ for the probe to thermalize. Thus, the total time is constrained by $\\mathcal{R} = n t_p$.\n\nThe precision of the temperature estimation is limited by the QCRB, which we denote as $\\delta T^2 \\equiv \\mathrm{Var}(\\hat{T})_{\\text{QCRB}}$. From our derivation, $\\delta T^2 \\propto \\frac{1}{n F_Q}$. Using the time constraint $n = \\mathcal{R}/t_p$, we can express the uncertainty bound as:\n$$\\delta T^2 \\propto \\frac{t_p}{\\mathcal{R} F_Q}$$\nTo minimize the uncertainty $\\delta T^2$ for a fixed total time $\\mathcal{R}$, we must minimize the quantity $\\frac{t_p}{F_Q}$.\n\nA crucial point is that the Quantum Fisher Information $F_Q$ is not constant but depends on the preparation time $t_p$. The probe thermalizes towards the Gibbs state $\\rho(T)$ with a characteristic rate $\\gamma$. If we start from a fiducial state (e.g., the ground state $|g\\rangle$) that is independent of temperature, its initial Fisher information is zero. As the probe evolves for a time $t_p$, its state $\\rho(t_p)$ becomes increasingly sensitive to the bath temperature $T$, and thus $F_Q(t_p)$ increases from $F_Q(0)=0$ and asymptotically approaches the maximum value $F_{Q,\\text{Gibbs}}$ (which we calculated in the first part) for $t_p \\gg 1/\\gamma$.\n\nWe must therefore analyze the \"cost function\" $C(t_p) = t_p / F_Q(t_p)$ to find the optimal preparation time $t_{p, \\text{opt}}$.\n1.  For very short preparation times ($t_p \\to 0$): $F_Q(t_p)$ also goes to zero. The rate of approach depends on the dynamics, but it is generally faster than linear (e.g., $F_Q(t_p) \\propto t_p^2$ for short times). Thus, the cost function $C(t_p) \\sim t_p / (a t_p^2) = 1/(a t_p)$ diverges. This means using a very large number of very short-duration measurements is highly inefficient.\n2.  For very long preparation times ($t_p \\to \\infty$): The Fisher information saturates at its maximum value, $F_Q(t_p) \\to F_{Q,\\text{Gibbs}}$, which is a constant. In this regime, the cost function becomes $C(t_p) \\approx t_p / F_{Q,\\text{Gibbs}}$, which grows linearly with $t_p$. This means waiting for an excessively long time for each measurement is also inefficient, as the gain in information becomes negligible while the time cost continues to increase.\n\nSince the cost function $C(t_p)$ is large for both very small and very large $t_p$, there must exist an optimal, finite preparation time $t_{p, \\text{opt}}$ that minimizes it. This optimal time represents the most efficient trade-off between acquiring information (letting $F_Q(t_p)$ grow) and the time cost per measurement ($t_p$). This optimal time is necessarily on the order of the thermalization timescale of the system, i.e., $t_{p, \\text{opt}} \\sim 1/\\gamma$.\n\nTherefore, the optimal strategy for allocating the total time $\\mathcal{R}$ is not to maximize $n$ at the expense of equilibration, nor to ensure perfect equilibration for a few measurements. Instead, the strategy is:\n1.  Identify the optimal single-probe preparation time $t_{p, \\text{opt}}$ which minimizes the ratio $t_p / F_Q(t_p)$. This time will be of order $1/\\gamma$.\n2.  Allocate this optimal time $t_{p, \\text{opt}}$ to each of the $n$ experimental runs.\n3.  The number of runs is then determined by the total resource budget: $n = \\mathcal{R} / t_{p, \\text{opt}}$. This allocation minimizes the final uncertainty on the temperature estimate.",
            "answer": "$$\n\\boxed{\\frac{4 k_B^2 T^4}{n \\Delta^2} \\cosh^2\\left(\\frac{\\Delta}{2 k_B T}\\right)}\n$$"
        },
        {
            "introduction": "Having established a baseline with a simple qubit, we now explore how to engineer a more sensitive probe. This practice explores the non-trivial role of degeneracy in the probe's Hamiltonian, a common feature in more complex quantum systems. By analyzing how the multiplicity $g$ of an excited state affects the Quantum Fisher Information , you will uncover how degeneracy can be a powerful resource for tuning a thermometer's sensitivity and optimizing its performance in specific temperature regimes.",
            "id": "3781746",
            "problem": "Consider a quantum system used as a temperature probe with Hamiltonian $\\hat{H}$ having a unique non-degenerate ground state $\\lvert 0 \\rangle$ of energy $0$ and a degenerate excited manifold $\\{ \\lvert e_m \\rangle \\}_{m=1}^{g}$ of energy $\\Delta > 0$ with multiplicity $g \\in \\mathbb{N}$. Thus, $\\hat{H} = \\Delta \\sum_{m=1}^{g} \\lvert e_m \\rangle \\langle e_m \\rvert$. The system is in thermal equilibrium with a heat bath at absolute temperature $T > 0$, and its state is the Gibbs state $\\hat{\\rho}_{T} = \\exp(-\\beta \\hat{H})/Z$, where $\\beta = 1/(k_{B} T)$ and $Z = \\mathrm{Tr}[\\exp(-\\beta \\hat{H})]$ is the partition function. You are tasked with estimating $T$ from measurements on $\\hat{\\rho}_{T}$. Starting strictly from the definitions of the Gibbs state and the Quantum Fisher Information (QFI), where the QFI with respect to $T$ is defined via the symmetric logarithmic derivative $\\hat{L}_{T}$ by $\\partial_{T} \\hat{\\rho}_{T} = (\\hat{\\rho}_{T} \\hat{L}_{T} + \\hat{L}_{T} \\hat{\\rho}_{T})/2$ and $F_{Q}(T) = \\mathrm{Tr}[\\hat{\\rho}_{T} \\hat{L}_{T}^{2}]$, derive a closed-form expression for $F_{Q}(T)$ in terms of $\\Delta$, $g$, $k_{B}$, and $T$. In your derivation, carefully account for the degeneracy of the excited manifold and its effect on the energy statistics of $\\hat{\\rho}_{T}$. Then, briefly explain how the multiplicity $g$ modifies the energy variance that governs the temperature sensitivity. Provide the final result as a single exact analytic expression in terms of $\\Delta$, $g$, $k_{B}$, and $T$. Do not approximate, and do not include units in the final expression.",
            "solution": "The problem is first validated against the specified criteria.\n\n### Problem Validation\n\n**Step 1: Extract Givens**\n- **System**: A quantum probe for temperature estimation.\n- **Hamiltonian**: $\\hat{H} = \\Delta \\sum_{m=1}^{g} \\lvert e_m \\rangle \\langle e_m \\rvert$.\n- **Energy Spectrum**: Non-degenerate ground state $\\lvert 0 \\rangle$ with energy $0$. Degenerate excited manifold $\\{ \\lvert e_m \\rangle \\}_{m=1}^{g}$ with energy $\\Delta > 0$ and multiplicity $g \\in \\mathbb{N}$.\n- **Thermal State**: The system is in a Gibbs state $\\hat{\\rho}_{T} = \\exp(-\\beta \\hat{H})/Z$ at temperature $T > 0$.\n- **Definitions**: $\\beta = 1/(k_{B} T)$, $Z = \\mathrm{Tr}[\\exp(-\\beta \\hat{H})]$.\n- **Quantum Fisher Information (QFI)**: $F_{Q}(T) = \\mathrm{Tr}[\\hat{\\rho}_{T} \\hat{L}_{T}^{2}]$, where the Symmetric Logarithmic Derivative (SLD) $\\hat{L}_{T}$ is defined by $\\partial_{T} \\hat{\\rho}_{T} = (\\hat{\\rho}_{T} \\hat{L}_{T} + \\hat{L}_{T} \\hat{\\rho}_{T})/2$.\n- **Task**: Derive a closed-form expression for $F_{Q}(T)$ in terms of $\\Delta$, $g$, $k_{B}$, and $T$. Explain the effect of $g$ on the energy variance.\n\n**Step 2: Validate Using Extracted Givens**\n- **Scientifically Grounded**: The problem is set within the standard framework of quantum statistical mechanics and quantum metrology. All concepts, including the Gibbs state, Hamiltonian of a multi-level system, and Quantum Fisher Information, are well-established. This is a standard model in quantum thermometry.\n- **Well-Posed**: The problem is clearly defined with all necessary variables ($\\Delta$, $g$, $T$, $k_B$) and definitions. The objective is to derive a specific analytical expression, and a unique solution exists.\n- **Objective**: The problem is stated using precise, formal language, free of any subjective or ambiguous terms.\n- **Conclusion**: The problem does not violate any of the specified invalidity criteria. It is scientifically sound, well-posed, objective, and formalizable.\n\n**Step 3: Verdict and Action**\nThe problem is **valid**. A full solution will be provided.\n\n### Derivation of the Quantum Fisher Information\n\nThe derivation proceeds by first calculating the partition function, then the density operator, and subsequently the energy variance of the system, which for a thermal state is directly related to the Quantum Fisher Information (QFI).\n\nThe Hamiltonian $\\hat{H}$ has two distinct energy eigenvalues: $E_0 = 0$ with multiplicity $1$, and $E_1 = \\Delta$ with multiplicity $g$. The Hilbert space is spanned by the orthonormal basis $\\{ \\lvert 0 \\rangle, \\lvert e_1 \\rangle, \\dots, \\lvert e_g \\rangle \\}$.\n\n$1$. **Partition Function $Z$**:\nThe partition function $Z$ is the trace of the Boltzmann factor $\\exp(-\\beta \\hat{H})$. In the energy eigenbasis, this is the sum of the Boltzmann factors for each state:\n$$Z = \\mathrm{Tr}[\\exp(-\\beta \\hat{H})] = \\langle 0 \\rvert \\exp(-\\beta \\hat{H}) \\lvert 0 \\rangle + \\sum_{m=1}^{g} \\langle e_m \\rvert \\exp(-\\beta \\hat{H}) \\lvert e_m \\rangle$$\n$$Z = \\exp(-\\beta E_0) + g \\exp(-\\beta E_1) = \\exp(0) + g \\exp(-\\beta \\Delta)$$\n$$Z = 1 + g \\exp(-\\beta \\Delta)$$\nwhere $\\beta = 1/(k_B T)$.\n\n$2$. **Gibbs State $\\hat{\\rho}_T$**:\nThe density operator for the Gibbs state is:\n$$\\hat{\\rho}_T = \\frac{1}{Z} \\exp(-\\beta \\hat{H})$$\nIn the energy eigenbasis, this is a diagonal operator:\n$$\\hat{\\rho}_T = \\frac{1}{Z} \\left( \\exp(-\\beta E_0) \\lvert 0 \\rangle \\langle 0 \\rvert + \\exp(-\\beta E_1) \\sum_{m=1}^{g} \\lvert e_m \\rangle \\langle e_m \\rvert \\right)$$\n$$\\hat{\\rho}_T = \\frac{1}{1 + g \\exp(-\\beta \\Delta)} \\left( \\lvert 0 \\rangle \\langle 0 \\rvert + \\exp(-\\beta \\Delta) \\sum_{m=1}^{g} \\lvert e_m \\rangle \\langle e_m \\rvert \\right)$$\nThe probability of finding the system in the ground state is $P_0 = \\frac{1}{Z}$. The total probability of finding it in the excited manifold is $P_1 = \\frac{g \\exp(-\\beta \\Delta)}{Z}$. Note that $P_0 + P_1 = 1$.\n\n$3$. **QFI and Energy Variance**:\nFor a thermal state $\\hat{\\rho}_\\beta = \\exp(-\\beta \\hat{H})/Z$, the derivative with respect to $\\beta$ is $\\partial_\\beta \\hat{\\rho}_\\beta = (\\langle \\hat{H} \\rangle - \\hat{H})\\hat{\\rho}_\\beta$. Since $\\hat{H}$ and $\\hat{\\rho}_\\beta$ are diagonal in the same basis, they commute. The equation for the SLD with respect to $\\beta$, $\\partial_\\beta \\hat{\\rho}_\\beta = (\\hat{\\rho}_\\beta \\hat{L}_\\beta + \\hat{L}_\\beta \\hat{\\rho}_\\beta)/2$, simplifies to $\\partial_\\beta \\hat{\\rho}_\\beta = \\hat{\\rho}_\\beta \\hat{L}_\\beta$. This gives $\\hat{L}_\\beta = \\langle \\hat{H} \\rangle - \\hat{H}$.\nThe QFI with respect to $\\beta$ is then:\n$F_Q(\\beta) = \\mathrm{Tr}[\\hat{\\rho}_\\beta \\hat{L}_\\beta^2] = \\mathrm{Tr}[\\hat{\\rho}_\\beta (\\langle \\hat{H} \\rangle - \\hat{H})^2] = \\langle (\\hat{H} - \\langle \\hat{H} \\rangle)^2 \\rangle = (\\Delta H)^2$.\nThus, the QFI for $\\beta$ is simply the variance of the Hamiltonian. We can calculate this from $\\langle \\hat{H} \\rangle$ and $\\langle \\hat{H}^2 \\rangle$.\n\n$4$. **Calculation of Energy Variance $(\\Delta H)^2$**:\nFirst, we find the expectation value of the Hamiltonian, $\\langle \\hat{H} \\rangle$:\n$$\\langle \\hat{H} \\rangle = \\mathrm{Tr}[\\hat{\\rho}_T \\hat{H}] = P_0 E_0 + P_1 E_1 = \\frac{1}{Z}(0) + \\frac{g \\exp(-\\beta \\Delta)}{Z}(\\Delta) = \\frac{g \\Delta \\exp(-\\beta \\Delta)}{1 + g \\exp(-\\beta \\Delta)}$$\nNext, we find the expectation value of $\\hat{H}^2$. Since $\\hat{H} = \\Delta \\hat{P}_e$ where $\\hat{P}_e = \\sum_{m=1}^{g} \\lvert e_m \\rangle \\langle e_m \\rvert$ is a projection operator, we have $\\hat{P}_e^2 = \\hat{P}_e$. Therefore, $\\hat{H}^2 = \\Delta^2 \\hat{P}_e$.\n$$\\langle \\hat{H}^2 \\rangle = \\mathrm{Tr}[\\hat{\\rho}_T \\hat{H}^2] = \\Delta^2 \\mathrm{Tr}[\\hat{\\rho}_T \\hat{P}_e] = \\Delta^2 \\frac{g \\exp(-\\beta \\Delta)}{Z} = \\frac{g \\Delta^2 \\exp(-\\beta \\Delta)}{1 + g \\exp(-\\beta \\Delta)}$$\nThe variance is $(\\Delta H)^2 = \\langle \\hat{H}^2 \\rangle - \\langle \\hat{H} \\rangle^2$:\n$$(\\Delta H)^2 = \\frac{g \\Delta^2 \\exp(-\\beta \\Delta)}{Z} - \\left( \\frac{g \\Delta \\exp(-\\beta \\Delta)}{Z} \\right)^2$$\n$$(\\Delta H)^2 = \\frac{g \\Delta^2 \\exp(-\\beta \\Delta) Z - (g \\Delta \\exp(-\\beta \\Delta))^2}{Z^2}$$\n$$(\\Delta H)^2 = \\frac{g \\Delta^2 \\exp(-\\beta \\Delta) (1 + g \\exp(-\\beta \\Delta)) - g^2 \\Delta^2 \\exp(-2\\beta \\Delta)}{Z^2}$$\n$$(\\Delta H)^2 = \\frac{g \\Delta^2 \\exp(-\\beta \\Delta) + g^2 \\Delta^2 \\exp(-2\\beta \\Delta) - g^2 \\Delta^2 \\exp(-2\\beta \\Delta)}{Z^2}$$\n$$(\\Delta H)^2 = \\frac{g \\Delta^2 \\exp(-\\beta \\Delta)}{Z^2} = \\frac{g \\Delta^2 \\exp(-\\beta \\Delta)}{(1 + g \\exp(-\\beta \\Delta))^2}$$\nSo, $F_Q(\\beta) = (\\Delta H)^2 = \\frac{g \\Delta^2 \\exp(-\\beta \\Delta)}{(1 + g \\exp(-\\beta \\Delta))^2}$.\n\n$5$. **Conversion to $F_Q(T)$**:\nThe QFI with respect to temperature $T$ is related to the QFI with respect to $\\beta$ by the chain rule:\n$$F_Q(T) = F_Q(\\beta) \\left( \\frac{d\\beta}{dT} \\right)^2$$\nThe derivative is:\n$$\\frac{d\\beta}{dT} = \\frac{d}{dT}\\left(\\frac{1}{k_B T}\\right) = -\\frac{1}{k_B T^2}$$\nSo, its square is:\n$$\\left( \\frac{d\\beta}{dT} \\right)^2 = \\frac{1}{k_B^2 T^4}$$\nSubstituting this and the expression for $F_Q(\\beta)$ gives the final result for $F_Q(T)$:\n$$F_Q(T) = \\frac{g \\Delta^2 \\exp(-\\beta \\Delta)}{(1 + g \\exp(-\\beta \\Delta))^2} \\frac{1}{k_B^2 T^4}$$\nReplacing $\\beta$ with $1/(k_B T)$:\n$$F_Q(T) = \\frac{\\Delta^2}{k_B^2 T^4} \\frac{g \\exp\\left(-\\frac{\\Delta}{k_B T}\\right)}{\\left(1 + g \\exp\\left(-\\frac{\\Delta}{k_B T}\\right)\\right)^2}$$\n\n### Effect of Multiplicity $g$\n\nThe precision of temperature estimation is fundamentally limited by the quantum Cramér-Rao bound, $\\delta T \\ge 1/\\sqrt{N F_Q(T)}$, where $N$ is the number of measurements. A higher QFI, $F_Q(T)$, corresponds to a better potential sensitivity. As shown, $F_Q(T)$ is directly proportional to the energy variance $(\\Delta H)^2$. The multiplicity $g$ modifies this variance and, consequently, the thermometer's performance.\n\nThe energy variance $(\\Delta H)^2 = \\Delta^2 P_0 P_1$ depends on the total populations of the ground ($P_0 = 1/Z$) and excited ($P_1 = g\\exp(-\\beta \\Delta)/Z$) manifolds. The factor $g$ acts as an entropic weight, increasing the probability of occupying the excited manifold compared to a non-degenerate system at the same temperature.\n\nThis has two main consequences:\n$1$. **Shift of Optimal Temperature**: The variance $(\\Delta H)^2$, and thus the QFI, is maximized when the ground and excited manifolds are equally populated ($P_0 = P_1 = 1/2$). This occurs when $g \\exp(-\\Delta/k_B T) = 1$, which yields an optimal operating temperature of $T_{\\text{opt}} = \\frac{\\Delta}{k_B \\ln(g)}$. For a simple two-level system ($g=1$), this happens only in the limit $T \\to \\infty$. For $g>1$, the probe's maximum sensitivity is achieved at a finite temperature, which can be tuned by engineering the degeneracy $g$. A larger $g$ lowers the optimal temperature.\n\n$2$. **Enhancement of Low-Temperature Sensitivity**: At low temperatures ($k_B T \\ll \\Delta$), the excited state population is very small. The variance is approximately $(\\Delta H)^2 \\approx g \\Delta^2 \\exp(-\\Delta/k_B T)$. This shows that at a fixed low temperature, the variance and the QFI scale linearly with $g$. By increasing the degeneracy, one can significantly boost the signal and the temperature sensitivity in the low-temperature regime, where a non-degenerate probe would be highly insensitive.\n\nIn summary, degeneracy provides a crucial resource for quantum thermometry, allowing for tunable, high-precision temperature estimation at finite temperatures, especially in the low-temperature domain.",
            "answer": "$$\n\\boxed{\\frac{\\Delta^2}{k_B^2 T^4} \\frac{g \\exp\\left(-\\frac{\\Delta}{k_B T}\\right)}{\\left(1 + g \\exp\\left(-\\frac{\\Delta}{k_B T}\\right)\\right)^2}}\n$$"
        },
        {
            "introduction": "The Quantum Fisher Information sets the ultimate bound on precision, but the information actually extracted depends on the chosen measurement and any subsequent data processing. This exercise  makes this crucial distinction tangible by quantifying the precise loss in thermometric precision when high-resolution energy measurements are coarse-grained. By calculating the difference between the Fisher information before and after binning the outcomes, you will directly observe the 'data processing inequality' in action and appreciate the gap between a probe's potential and its practical performance.",
            "id": "3781732",
            "problem": "A three-level quantum system with nondegenerate energy eigenvalues $E_{0}=0$, $E_{1}=\\epsilon$, and $E_{2}=2\\epsilon$ is weakly coupled to a large thermal reservoir and reaches a stationary state described by the Gibbs density operator $\\rho(T)=\\exp(-\\beta H)/Z$, where $H$ is the Hamiltonian, $\\beta=1/(k_{B}T)$ is the inverse temperature, $k_{B}$ is the Boltzmann constant, and $Z=\\operatorname{Tr}[\\exp(-\\beta H)]$ is the partition function. Consider estimating the temperature $T$ by performing a projective measurement in the energy eigenbasis. The measurement outcomes are the energy levels with probabilities determined by the Gibbs distribution. Define the classical Fisher information (FI) for temperature $T$ as $F_{c}(T)=\\sum_{i} \\frac{(\\partial_{T} p_{i}(T))^{2}}{p_{i}(T)}$, where $p_{i}(T)$ are the temperature-dependent outcome probabilities.\n\nNow suppose that, after collecting the measurement outcomes, you apply a classical post-processing that coarsely bins the outcomes by merging the two excited levels $E_{1}$ and $E_{2}$ into a single bin, while keeping the ground level $E_{0}$ as its own bin. This creates a two-outcome distribution for the post-processed data.\n\nStarting from the fundamental definitions of the Gibbs state, the outcome probabilities, and the classical Fisher information, and using only basic rules of differentiation and algebra, derive an explicit closed-form analytic expression for the loss in classical Fisher information due to this coarse-grained post-processing, defined as the difference $\\Delta F_{c}(T)=F_{c}^{\\mathrm{full}}(T)-F_{c}^{\\mathrm{binned}}(T)$ between the FI with full-resolution energy outcomes and the FI with the post-processed two-bin outcomes. Express your final result in terms of $\\epsilon$, $k_{B}$, and $T$ only, and you may use exponentials. Use International System of Units (SI), taking energy in Joules and temperature in Kelvin. No numerical evaluation is required, and no rounding is needed. The final answer must be a single closed-form analytic expression.",
            "solution": "The system has energies $E_{0}=0$, $E_{1}=\\epsilon$, $E_{2}=2\\epsilon$, so the partition function is\n$$\nZ=1+\\exp(-\\beta \\epsilon)+\\exp(-2\\beta \\epsilon).\n$$\nIntroduce the shorthand\n$$\nx=\\exp(-\\beta \\epsilon)=\\exp\\left(-\\frac{\\epsilon}{k_{B}T}\\right),\n$$\nso that $Z=1+x+x^{2}$. The outcome probabilities for the full-resolution energy measurement are\n$$\np_{0}=\\frac{1}{Z},\\quad p_{1}=\\frac{x}{Z},\\quad p_{2}=\\frac{x^{2}}{Z}.\n$$\n\nWe first compute the classical Fisher information (FI) for the full-resolution measurement about the inverse temperature $\\beta$, and then convert to FI about $T$ via the chain rule. For a family of probability distributions $p_{i}(\\beta)$, the classical FI is\n$$\nF_{c}(\\beta)=\\sum_{i}\\frac{(\\partial_{\\beta} p_{i})^{2}}{p_{i}}.\n$$\nFor the Gibbs distribution $p_{i}(\\beta)=\\exp(-\\beta E_{i})/Z$, it is a standard identity that\n$$\n\\partial_{\\beta} \\ln p_{i}=-E_{i}+\\langle H\\rangle,\n$$\nwhere $\\langle H\\rangle=\\sum_{j}E_{j}p_{j}$ is the mean energy, so that\n$$\nF_{c}(\\beta)=\\sum_{i}p_{i}\\left(\\partial_{\\beta}\\ln p_{i}\\right)^{2}=\\sum_{i}p_{i}\\left(E_{i}-\\langle H\\rangle\\right)^{2}=\\operatorname{Var}(H).\n$$\nFor the present three-level spectrum, we compute $\\langle H\\rangle$ and $\\langle H^{2}\\rangle$:\n$$\n\\langle H\\rangle=\\epsilon p_{1}+2\\epsilon p_{2}=\\epsilon\\frac{x+2x^{2}}{Z},\n$$\n$$\n\\langle H^{2}\\rangle=\\epsilon^{2} p_{1}+4\\epsilon^{2} p_{2}=\\epsilon^{2}\\frac{x+4x^{2}}{Z}.\n$$\nTherefore\n$$\n\\operatorname{Var}(H)=\\langle H^{2}\\rangle-\\langle H\\rangle^{2}\n=\\epsilon^{2}\\left[\\frac{x+4x^{2}}{Z}-\\left(\\frac{x+2x^{2}}{Z}\\right)^{2}\\right]\n=\\epsilon^{2}\\frac{x+4x^{2}+x^{3}}{Z^{2}},\n$$\nwhere the final simplification follows from expanding the numerator:\n$$\n\\left(x+4x^{2}\\right)Z-\\left(x+2x^{2}\\right)^{2}\n=(x+4x^{2})(1+x+x^{2})-(x^{2}+4x^{3}+4x^{4})\n=x+4x^{2}+x^{3}.\n$$\n\nTo convert $F_{c}(\\beta)$ to $F_{c}(T)$, we use the chain rule. Since $\\beta=1/(k_{B}T)$,\n$$\n\\frac{\\partial \\beta}{\\partial T}=-\\frac{1}{k_{B}T^{2}},\\quad\\left(\\frac{\\partial \\beta}{\\partial T}\\right)^{2}=\\frac{1}{k_{B}^{2}T^{4}}.\n$$\nThus the classical FI for the full-resolution energy measurement with respect to $T$ is\n$$\nF_{c}^{\\mathrm{full}}(T)=F_{c}(\\beta)\\left(\\frac{\\partial \\beta}{\\partial T}\\right)^{2}\n=\\epsilon^{2}\\frac{x+4x^{2}+x^{3}}{Z^{2}}\\cdot\\frac{1}{k_{B}^{2}T^{4}}.\n$$\n\nNow consider the coarse-grained post-processing that merges $E_{1}$ and $E_{2}$ into one bin and keeps $E_{0}$ as the other bin. The two outcome probabilities are\n$$\nq_{0}=p_{0}=\\frac{1}{Z},\\quad q_{1}=p_{1}+p_{2}=\\frac{x+x^{2}}{Z}.\n$$\nFor a binary distribution $\\{q_{0},q_{1}\\}$ depending on $\\beta$, the classical FI is\n$$\nF_{c}^{\\mathrm{binned}}(\\beta)=\\frac{(\\partial_{\\beta} q_{0})^{2}}{q_{0}}+\\frac{(\\partial_{\\beta} q_{1})^{2}}{q_{1}}\n=\\frac{(\\partial_{\\beta} q_{0})^{2}}{q_{0}}+\\frac{(-\\partial_{\\beta} q_{0})^{2}}{1-q_{0}}\n=\\frac{(\\partial_{\\beta} q_{0})^{2}}{q_{0}(1-q_{0})}.\n$$\nWe compute $\\partial_{\\beta} q_{0}$:\n$$\nq_{0}=\\frac{1}{Z},\\quad \\partial_{\\beta} Z=-\\epsilon x-2\\epsilon x^{2}=-\\epsilon(x+2x^{2}),\n$$\nso\n$$\n\\partial_{\\beta} q_{0}=-\\frac{1}{Z^{2}}\\partial_{\\beta} Z\n=\\frac{\\epsilon(x+2x^{2})}{Z^{2}}.\n$$\nAlso $q_{0}(1-q_{0})=\\frac{1}{Z}\\cdot\\frac{x+x^{2}}{Z}=\\frac{x+x^{2}}{Z^{2}}$, hence\n$$\nF_{c}^{\\mathrm{binned}}(\\beta)\n=\\frac{\\epsilon^{2}(x+2x^{2})^{2}/Z^{4}}{(x+x^{2})/Z^{2}}\n=\\epsilon^{2}\\frac{(x+2x^{2})^{2}}{Z^{2}(x+x^{2})}\n=\\epsilon^{2}\\frac{x(1+2x)^{2}}{Z^{2}(1+x)}.\n$$\nConverting to FI with respect to $T$ gives\n$$\nF_{c}^{\\mathrm{binned}}(T)=F_{c}^{\\mathrm{binned}}(\\beta)\\left(\\frac{\\partial \\beta}{\\partial T}\\right)^{2}\n=\\epsilon^{2}\\frac{x(1+2x)^{2}}{Z^{2}(1+x)}\\cdot\\frac{1}{k_{B}^{2}T^{4}}.\n$$\n\nThe loss in classical FI due to binning is the difference\n$$\n\\Delta F_{c}(T)=F_{c}^{\\mathrm{full}}(T)-F_{c}^{\\mathrm{binned}}(T)\n=\\frac{\\epsilon^{2}}{k_{B}^{2}T^{4}}\\left[\\frac{x+4x^{2}+x^{3}}{Z^{2}}-\\frac{x(1+2x)^{2}}{Z^{2}(1+x)}\\right].\n$$\nPlace the two terms over a common denominator and simplify. Using $Z=1+x+x^{2}$,\n$$\n\\frac{x+4x^{2}+x^{3}}{Z^{2}}-\\frac{x(1+2x)^{2}}{Z^{2}(1+x)}\n=\\frac{(x+4x^{2}+x^{3})(1+x)-x(1+2x)^{2}}{Z^{2}(1+x)}.\n$$\nCompute the numerator:\n$$\n(x+4x^{2}+x^{3})(1+x)=x+5x^{2}+5x^{3}+x^{4},\\quad x(1+2x)^{2}=x+4x^{2}+4x^{3},\n$$\nso the difference is\n$$\nx+5x^{2}+5x^{3}+x^{4}-(x+4x^{2}+4x^{3})=x^{2}+x^{3}+x^{4}=x^{2}(1+x+x^{2})=x^{2}Z.\n$$\nTherefore\n$$\n\\Delta F_{c}(T)=\\frac{\\epsilon^{2}}{k_{B}^{2}T^{4}}\\cdot\\frac{x^{2}Z}{Z^{2}(1+x)}\n=\\frac{\\epsilon^{2}}{k_{B}^{2}T^{4}}\\cdot\\frac{x^{2}}{Z(1+x)}.\n$$\nRe-expressing $x$ and $Z$ in terms of $\\epsilon$, $k_{B}$, and $T$,\n$$\nx=\\exp\\left(-\\frac{\\epsilon}{k_{B}T}\\right),\\quad Z=1+\\exp\\left(-\\frac{\\epsilon}{k_{B}T}\\right)+\\exp\\left(-\\frac{2\\epsilon}{k_{B}T}\\right),\n$$\nthe final closed-form analytic expression for the Fisher information loss is\n$$\n\\Delta F_{c}(T)=\\frac{\\epsilon^{2}\\,\\exp\\left(-\\frac{2\\epsilon}{k_{B}T}\\right)}{k_{B}^{2}T^{4}\\left[1+\\exp\\left(-\\frac{\\epsilon}{k_{B}T}\\right)+\\exp\\left(-\\frac{2\\epsilon}{k_{B}T}\\right)\\right]\\left[1+\\exp\\left(-\\frac{\\epsilon}{k_{B}T}\\right)\\right]}.\n$$\nThis quantity is nonnegative and has units of inverse temperature squared, consistent with the information-theoretic scaling for estimating $T$. The expression is to be reported in SI units, with temperature in Kelvin and energy in Joules.",
            "answer": "$$\\boxed{\\frac{\\epsilon^{2}\\,\\exp\\left(-\\frac{2\\epsilon}{k_{B}T}\\right)}{k_{B}^{2}T^{4}\\left[1+\\exp\\left(-\\frac{\\epsilon}{k_{B}T}\\right)+\\exp\\left(-\\frac{2\\epsilon}{k_{B}T}\\right)\\right]\\left[1+\\exp\\left(-\\frac{\\epsilon}{k_{B}T}\\right)\\right]}}$$"
        }
    ]
}