{"hands_on_practices": [{"introduction": "本练习提供了一个具体、可解的有限时域马尔可夫决策过程 (MDP) 案例。它的目的是让你亲身体验动态规划的核心机制：逆向递推。通过手动计算每个时间步的最优价值函数和最优策略，你将对贝尔曼最优性原理的实际应用建立起坚实而直观的理解，为解决更复杂的控制问题打下基础。[@problem_id:2703371]", "problem": "考虑一个有限时域、时间索引的随机控制问题，该问题被建模为一个马尔可夫决策过程 (MDP)，其状态空间为 $\\mathcal{X}=\\{0,1\\}$，动作空间为 $\\mathcal{U}=\\{a,b\\}$，时域为 $N=3$，决策时刻为 $t\\in\\{0,1,2\\}$，并在 $t=3$ 时有终端成本。受控状态演化是时齐且具有马尔可夫性的：对于每个 $t$，下一状态 $x_{t+1}$ 仅取决于当前状态 $x_t$ 和所施加的控制 $u_t$。决策者旨在最小化阶段成本与终端成本之和的期望值。\n\n转移概率如下：\n- 从 $x=0$ 出发：在 $u=a$ 下，$x_{t+1}=0$ 的概率为 $\\frac{2}{3}$，$x_{t+1}=1$ 的概率为 $\\frac{1}{3}$；在 $u=b$ 下，$x_{t+1}=1$ 的概率为 $1$。\n- 从 $x=1$ 出发：在 $u=a$ 下，$x_{t+1}=0$ 的概率为 $\\frac{1}{2}$，$x_{t+1}=1$ 的概率为 $\\frac{1}{2}$；在 $u=b$ 下，$x_{t+1}=1$ 的概率为 $1$。\n\n在时刻 $t\\in\\{0,1,2\\}$，处于状态 $x$ 并采取动作 $u$ 的阶段成本是时不变的，由 $c(x,u)$ 给出，其中\n- $c(0,a)=0$, $c(0,b)=\\frac{3}{5}$，\n- $c(1,a)=\\frac{3}{2}$, $c(1,b)=0$。\n在 $t=3$ 时的终端成本为 $g(x)$，$g(0)=\\frac{7}{10}$ 且 $g(1)=0$。\n\n从有限时域MDP最优控制的基本定义（在容许策略上最小化期望总成本）和 Bellman 最优性原理出发，首先推导出刻画最优未来成本函数 $\\{V_t\\}_{t=0}^{3}$ 的反向递推关系，不要借助任何预先给出的“捷径”公式。然后，为所有状态 $x\\in\\{0,1\\}$ 显式计算值函数 $V_3$、$V_2$、$V_1$ 和 $V_0$，并确定在每个时刻 $t\\in\\{0,1,2\\}$ 和每个状态 $x\\in\\{0,1\\}$ 下的最优策略 $\\pi_t^{\\star}(x)\\in\\{a,b\\}$。最后，验证最优子结构（Bellman 最优性）。具体方法是：对于每个从 $(t,x)\\in\\{1,2\\}\\times\\{0,1\\}$ 开始的子问题，通过显式评估各种竞争动作，来检验我们所计算出的策略在该子问题中确实是最优的。\n\n设初始条件为 $x_0=0$。请将最优初始期望总成本 $V_0(x_0)$ 作为一个最简有理数报告为您的最终答案。不要四舍五入；请以精确的分数形式表示您的答案。", "solution": "首先应验证问题的科学合理性和一致性。\n\n### 步骤 1：提取已知条件\n\n- **状态空间**：$\\mathcal{X}=\\{0,1\\}$\n- **动作空间**：$\\mathcal{U}=\\{a,b\\}$\n- **时域**：$N=3$，决策时刻 $t \\in \\{0, 1, 2\\}$\n- **终端时刻**：$t=3$\n- **转移概率**，$P(x_{t+1}=y | x_t=x, u_t=u)$:\n  - 从 $x=0$ 出发：\n    - $u=a$: $P(x_{t+1}=0|0,a) = \\frac{2}{3}$, $P(x_{t+1}=1|0,a) = \\frac{1}{3}$\n    - $u=b$: $P(x_{t+1}=1|0,b) = 1$\n  - 从 $x=1$ 出发：\n    - $u=a$: $P(x_{t+1}=0|1,a) = \\frac{1}{2}$, $P(x_{t+1}=1|1,a) = \\frac{1}{2}$\n    - $u=b$: $P(x_{t+1}=1|1,b) = 1$\n- **阶段成本**，$c(x,u)$:\n  - $c(0,a)=0$, $c(0,b)=\\frac{3}{5}$\n  - $c(1,a)=\\frac{3}{2}$, $c(1,b)=0$\n- **终端成本**，$g(x)$:\n  - $g(0)=\\frac{7}{10}$, $g(1)=0$\n- **目标**：最小化期望总成本。\n- **初始条件**：$x_0=0$\n\n### 步骤 2：使用提取的已知条件进行验证\n\n- **科学依据**：该问题是一个标准的、形式完善的马尔可夫决策过程 (MDP)，是随机控制理论和运筹学的基石。所有概念均基于已确立的数学原理。\n- **适定性**：该问题是一个有限时域、有限状态、有限动作的 MDP。对于此类问题，保证存在最优策略和唯一的最优未来成本函数。\n- **目标**：问题陈述使用了精确、无歧义的数学语言。成本和概率以客观的数值形式给出。\n- **完备性**：所有必要信息（状态、动作、时域、成本、转移）均已提供。该问题是自洽的。\n- **一致性**：所提供的数据中没有内部矛盾。\n\n### 步骤 3：结论与行动\n\n问题有效。将提供解答。\n\n---\n\n目标是找到一个策略 $\\pi = (\\mu_0, \\mu_1, \\mu_2)$，其中每个 $\\mu_t: \\mathcal{X} \\to \\mathcal{U}$ 是一个决策规则，该策略能最小化期望总成本泛函 $J_{\\pi}(x_0)$：\n$$\nJ_{\\pi}(x_0) = \\mathbb{E}_{\\pi} \\left[ g(x_3) + \\sum_{t=0}^{2} c(x_t, u_t) \\mid x_0 \\right]\n$$\n其中 $u_t = \\mu_t(x_t)$。在时刻 $t$ 从状态 $x$ 出发的最优未来成本（或称值函数）定义为从时刻 $t$ 到时域终点 $N=3$ 的最小可能期望成本：\n$$\nV_t(x) = \\min_{\\mu_t, ..., \\mu_{N-1}} \\mathbb{E} \\left[ g(x_N) + \\sum_{k=t}^{N-1} c(x_k, u_k) \\mid x_t = x \\right]\n$$\n整个问题的最优成本为 $V_0(x_0)$。\n\nBellman 最优性原理指出，一个最优策略具有这样的特性：无论当前状态和控制动作是什么，余下的决策相对于当前动作所导致的状态而言，必须构成一个最优策略。该原理导出了一个关于最优未来成本函数的反向递推关系，即贝尔曼方程 (Bellman equation)。\n\n对于最后的时刻 $t=N=3$，没有更多的决策可做，因此未来成本就是终端成本：\n$$\nV_3(x) = g(x)\n$$\n对于任意时刻 $t \\in \\{0, 1, 2\\}$，如果我们处于状态 $x_t=x$ 并选择动作 $u_t=u$，我们会产生一个即时阶段成本 $c(x,u)$ 并转移到一个新状态 $x_{t+1}$。如果我们假设从时刻 $t+1$ 起遵循最优策略，那么未来的期望成本为 $\\mathbb{E}[V_{t+1}(x_{t+1}) \\mid x_t=x, u_t=u]$。为了在时刻 $t$ 做出最优行动，我们必须选择能够最小化即时成本与未来最优成本期望之和的动作 $u$。这就建立了反向递推关系：\n$$\nV_t(x) = \\min_{u \\in \\mathcal{U}} \\left\\{ c(x,u) + \\mathbb{E}[V_{t+1}(x_{t+1}) \\mid x_t=x, u_t=u] \\right\\}\n$$\n该期望是根据下一状态 $x_{t+1}$ 的概率分布计算的：\n$$\n\\mathbb{E}[V_{t+1}(x_{t+1}) \\mid x_t=x, u_t=u] = \\sum_{y \\in \\mathcal{X}} P(x_{t+1}=y \\mid x_t=x, u_t=u) V_{t+1}(y)\n$$\n在时刻 $t$ 的最优策略 $\\pi_t^{\\star}(x) = \\mu_t^{\\star}(x)$ 就是实现这个最小值的动作 $u$。我们现在应用这个递推关系，从 $t=3$ 开始反向计算到 $t=0$。\n\n**步骤 `t=3` (终端步骤)**\n未来成本是终端成本 $g(x)$：\n$V_3(0) = g(0) = \\frac{7}{10}$\n$V_3(1) = g(1) = 0$\n\n**步骤 `t=2` (反向递推)**\n我们使用 $V_3$ 为每个状态 $x \\in \\{0,1\\}$ 计算 $V_2(x)$。\n对于 $x=0$:\n$$\nV_2(0) = \\min \\left\\{\n\\begin{array}{ll}\n\\text{cost for } u=a: & c(0,a) + P(x_3=0|0,a)V_3(0) + P(x_3=1|0,a)V_3(1) \\\\\n\\text{cost for } u=b: & c(0,b) + P(x_3=0|0,b)V_3(0) + P(x_3=1|0,b)V_3(1)\n\\end{array}\n\\right.\n$$\n$$\nV_2(0) = \\min \\left\\{ 0 + \\frac{2}{3} \\cdot \\frac{7}{10} + \\frac{1}{3} \\cdot 0, \\quad \\frac{3}{5} + 0 \\cdot \\frac{7}{10} + 1 \\cdot 0 \\right\\} = \\min \\left\\{ \\frac{14}{30}, \\frac{3}{5} \\right\\} = \\min \\left\\{ \\frac{7}{15}, \\frac{9}{15} \\right\\} = \\frac{7}{15}\n$$\n当 $u=a$ 时达到最小值。因此，$V_2(0) = \\frac{7}{15}$ 且 $\\pi_2^{\\star}(0)=a$。\n\n对于 $x=1$:\n$$\nV_2(1) = \\min \\left\\{\n\\begin{array}{ll}\n\\text{cost for } u=a: & c(1,a) + P(x_3=0|1,a)V_3(0) + P(x_3=1|1,a)V_3(1) \\\\\n\\text{cost for } u=b: & c(1,b) + P(x_3=0|1,b)V_3(0) + P(x_3=1|1,b)V_3(1)\n\\end{array}\n\\right.\n$$\n$$\nV_2(1) = \\min \\left\\{ \\frac{3}{2} + \\frac{1}{2} \\cdot \\frac{7}{10} + \\frac{1}{2} \\cdot 0, \\quad 0 + 0 \\cdot \\frac{7}{10} + 1 \\cdot 0 \\right\\} = \\min \\left\\{ \\frac{3}{2} + \\frac{7}{20}, 0 \\right\\} = \\min \\left\\{ \\frac{30}{20} + \\frac{7}{20}, 0 \\right\\} = \\min \\left\\{ \\frac{37}{20}, 0 \\right\\} = 0\n$$\n当 $u=b$ 时达到最小值。因此，$V_2(1) = 0$ 且 $\\pi_2^{\\star}(1)=b$。\n\n**步骤 `t=1` (反向递推)**\n我们使用 $V_2(0)=\\frac{7}{15}$ 和 $V_2(1)=0$ 为每个状态 $x \\in \\{0,1\\}$ 计算 $V_1(x)$。\n对于 $x=0$:\n$$\nV_1(0) = \\min \\left\\{ 0 + \\frac{2}{3}V_2(0) + \\frac{1}{3}V_2(1), \\quad \\frac{3}{5} + 0 \\cdot V_2(0) + 1 \\cdot V_2(1) \\right\\}\n$$\n$$\nV_1(0) = \\min \\left\\{ \\frac{2}{3} \\cdot \\frac{7}{15} + \\frac{1}{3} \\cdot 0, \\quad \\frac{3}{5} + 0 \\right\\} = \\min \\left\\{ \\frac{14}{45}, \\frac{3}{5} \\right\\} = \\min \\left\\{ \\frac{14}{45}, \\frac{27}{45} \\right\\} = \\frac{14}{45}\n$$\n当 $u=a$ 时达到最小值。因此，$V_1(0) = \\frac{14}{45}$ 且 $\\pi_1^{\\star}(0)=a$。\n\n对于 $x=1$:\n$$\nV_1(1) = \\min \\left\\{ \\frac{3}{2} + \\frac{1}{2}V_2(0) + \\frac{1}{2}V_2(1), \\quad 0 + 0 \\cdot V_2(0) + 1 \\cdot V_2(1) \\right\\}\n$$\n$$\nV_1(1) = \\min \\left\\{ \\frac{3}{2} + \\frac{1}{2} \\cdot \\frac{7}{15} + \\frac{1}{2} \\cdot 0, \\quad 0 \\right\\} = \\min \\left\\{ \\frac{3}{2} + \\frac{7}{30}, 0 \\right\\} = \\min \\left\\{ \\frac{45}{30} + \\frac{7}{30}, 0 \\right\\} = \\min \\left\\{ \\frac{52}{30}, 0 \\right\\} = 0\n$$\n当 $u=b$ 时达到最小值。因此，$V_1(1) = 0$ 且 $\\pi_1^{\\star}(1)=b$。\n\n**步骤 `t=0` (反向递推)**\n我们使用 $V_1(0)=\\frac{14}{45}$ 和 $V_1(1)=0$ 为每个状态 $x \\in \\{0,1\\}$ 计算 $V_0(x)$。\n对于 $x=0$:\n$$\nV_0(0) = \\min \\left\\{ 0 + \\frac{2}{3}V_1(0) + \\frac{1}{3}V_1(1), \\quad \\frac{3}{5} + 0 \\cdot V_1(0) + 1 \\cdot V_1(1) \\right\\}\n$$\n$$\nV_0(0) = \\min \\left\\{ \\frac{2}{3} \\cdot \\frac{14}{45} + \\frac{1}{3} \\cdot 0, \\quad \\frac{3}{5} + 0 \\right\\} = \\min \\left\\{ \\frac{28}{135}, \\frac{3}{5} \\right\\} = \\min \\left\\{ \\frac{28}{135}, \\frac{81}{135} \\right\\} = \\frac{28}{135}\n$$\n当 $u=a$ 时达到最小值。因此，$V_0(0) = \\frac{28}{135}$ 且 $\\pi_0^{\\star}(0)=a$。\n\n为完整起见，我们计算 $V_0(1)$：\n$$\nV_0(1) = \\min \\left\\{ \\frac{3}{2} + \\frac{1}{2}V_1(0) + \\frac{1}{2}V_1(1), \\quad 0 + 0 \\cdot V_1(0) + 1 \\cdot V_1(1) \\right\\}\n$$\n$$\nV_0(1) = \\min \\left\\{ \\frac{3}{2} + \\frac{1}{2} \\cdot \\frac{14}{45} + \\frac{1}{2} \\cdot 0, \\quad 0 \\right\\} = \\min \\left\\{ \\frac{3}{2} + \\frac{7}{45}, 0 \\right\\} = \\min \\left\\{ \\frac{135}{90} + \\frac{14}{90}, 0 \\right\\} = \\min \\left\\{ \\frac{149}{90}, 0 \\right\\} = 0\n$$\n当 $u=b$ 时达到最小值。因此，$V_0(1) = 0$ 且 $\\pi_0^{\\star}(1)=b$。\n\n**最优策略总结**\n最优策略 $\\pi^{\\star} = (\\pi_0^{\\star}, \\pi_1^{\\star}, \\pi_2^{\\star})$ 为：\n- $\\pi_0^{\\star}(0) = a, \\quad \\pi_0^{\\star}(1) = b$\n- $\\pi_1^{\\star}(0) = a, \\quad \\pi_1^{\\star}(1) = b$\n- $\\pi_2^{\\star}(0) = a, \\quad \\pi_2^{\\star}(1) = b$\n\n**最优子结构验证**\n问题要求验证最优子结构。动态规划方法本身，通过其构造，就保证了这一性质。在每一步 $(t,x)$，我们通过显式地最小化当前成本与未来最优成本期望之和来计算 $V_t(x)$。这确保了为任何从时刻 $t > 0$ 开始的子问题选择的策略对该子问题都是最优的。\n例如，我们来验证对于从 $(t,x) = (2,0)$ 开始的子问题，策略 $\\pi_2^{\\star}(0)=a$ 确实是最优的。这个动作的成本是 $c(0,a) + \\mathbb{E}[V_3(x_3)|x_2=0, u_2=a] = \\frac{7}{15}$。替代动作 $u=b$ 的成本是 $c(0,b) + \\mathbb{E}[V_3(x_3)|x_2=0, u_2=b] = \\frac{3}{5}$。由于 $\\frac{7}{15} < \\frac{3}{5}$，选择 $\\pi_2^{\\star}(0)=a$ 对于从 $(2,0)$ 开始的子问题是最优的。我们对 $V_2(0)$ 的计算正是这个验证过程。同样的逻辑适用于所有其他状态和时刻。反向递推是 Bellman 最优性原理的算法实现。\n\n问题要求的是从 $x_0=0$ 出发的最优初始期望总成本。这就是值 $V_0(0)$。\n根据计算，$V_0(0) = \\frac{28}{135}$。这个分数已经是最简形式，因为 $28 = 2^2 \\cdot 7$ 且 $135 = 3^3 \\cdot 5$。", "answer": "$$\n\\boxed{\\frac{28}{135}}\n$$", "id": "2703371"}, {"introduction": "本实践练习将我们从离散系统带入连续状态最优控制问题，这更贴近于物理系统的实际情况。你将处理一个线性系统和二次型成本函数，但其中包含一个重要的实际复杂性：执行器饱和。这个练习展示了动态规划在处理此类非线性约束时的强大能力，其解将得到一个分段定义的价值函数和一个饱和最优控制律，从而让你对约束最优控制的解结构有更深刻的认识。[@problem_id:2703354]", "problem": "考虑具有执行器饱和的离散时间一维系统\n$$\nx_{k+1} \\;=\\; x_{k} + u_{k}, \\quad k \\in \\{0,1\\},\n$$\n该系统服从硬输入约束\n$$\n|u_{k}| \\;\\le\\; 1 \\quad \\text{对所有 } k.\n$$\n在长度为 $2$ 的有限时域上，性能指标是二次阶段成本之和加上一个终端成本，\n$$\nJ \\;=\\; \\sum_{k=0}^{1} \\big( x_{k}^{2} + u_{k}^{2} \\big) \\;+\\; x_{2}^{2}.\n$$\n使用 Bellman 最优性原理和动态规划 (DP)，从价值函数的定义出发，根据第一性原理推导整个时域上的 Bellman 递推关系。然后，求解第 $1$ 步的问题以得到 $V_{1}(x_{1})$ 和最优策略 $u_{1}^{\\star}(x_{1})$，并仔细处理输入饱和。接下来，求解第 $0$ 步的问题以得到 $V_{0}(x_{0})$ 和最优策略 $u_{0}^{\\star}(x_{0})$，同样与第 $1$ 步的解法一致地处理输入饱和。精确地确定在每一步中最优控制达到饱和的状态空间区域，并通过在给定问题数据下有效的凸性论证来证明您的解是全局最优的。\n\n请提供价值函数 $V_{0}(x_{0})$ 作为 $x_{0}$ 的分段解析函数的精确闭式表达式，并尽可能简化，作为您的最终答案。不要进行近似；无需四舍五入。", "solution": "问题正在进行验证。\n\n**第 1 步：提取已知条件**\n- 系统动态：$x_{k+1} = x_{k} + u_{k}$，$k \\in \\{0, 1\\}$。\n- 状态空间：$x_k \\in \\mathbb{R}$。\n- 控制输入约束：$|u_{k}| \\le 1$。\n- 时域：$N=2$。\n- 性能指标：$J = \\sum_{k=0}^{1} ( x_{k}^{2} + u_{k}^{2} ) + x_{2}^{2}$。\n这可以写作阶段成本 $L(x_k, u_k) = x_k^2 + u_k^2$ 和终端成本 $\\Phi(x_2) = x_2^2$。\n- 方法：动态规划 (DP)。\n\n**第 2 步：使用提取的已知条件进行验证**\n该问题是一个标准的有限时域离散时间最优控制问题。该系统是一个线性积分器, 成本函数是二次的（因此在控制上是严格凸的），并且控制约束定义了一个紧的凸集。该问题具有科学依据、是良态的、完全指定的和客观的。未违反任何验证标准。\n\n**结论**\n问题有效。将提供一个解。\n\n**使用动态规划推导求解**\n\n求解过程从 $k=N=2$ 到 $k=0$ 按时间向后归纳。价值函数 $V_k(x_k)$ 表示在时间 $k$ 从状态 $x_k$ 出发的最优未来成本。\n\nBellman 递推定义为：\n$$ V_k(x_k) = \\min_{|u_k| \\le 1} \\left\\{ L(x_k, u_k) + V_{k+1}(x_{k+1}) \\right\\}, \\quad k=0, 1 $$\n终端条件为：\n$$ V_2(x_2) = \\Phi(x_2) = x_2^2 $$\n\n**k=1 的步骤（最后阶段）**\n\n在阶段 $k=1$ 的价值函数为：\n$$ V_1(x_1) = \\min_{|u_1| \\le 1} \\left\\{ x_1^2 + u_1^2 + V_2(x_2) \\right\\} $$\n代入 $x_2 = x_1 + u_1$ 和 $V_2(x_2) = x_2^2$：\n$$ V_1(x_1) = \\min_{|u_1| \\le 1} \\left\\{ x_1^2 + u_1^2 + (x_1 + u_1)^2 \\right\\} $$\n设 $J_1(u_1)$ 为要最小化的量：\n$$ J_1(u_1) = x_1^2 + u_1^2 + x_1^2 + 2x_1 u_1 + u_1^2 = 2x_1^2 + 2x_1 u_1 + 2u_1^2 $$\n这是关于 $u_1$ 的严格凸二次函数。通过将导数设为零来找到无约束最小值：\n$$ \\frac{\\partial J_1}{\\partial u_1} = 2x_1 + 4u_1 = 0 \\implies u_{1,\\text{unc}} = -\\frac{1}{2}x_1 $$\n最优控制 $u_1^\\star(x_1)$ 是通过将此无约束解投影到可行集 $[-1, 1]$ 上找到的：\n$$ u_1^\\star(x_1) = \\text{sat}\\left(-\\frac{1}{2}x_1\\right) = \\begin{cases} 1 & \\text{若 } -\\frac{1}{2}x_1 > 1 \\iff x_1 < -2 \\\\ -\\frac{1}{2}x_1 & \\text{若 } -1 \\le -\\frac{1}{2}x_1 \\le 1 \\iff |x_1| \\le 2 \\\\ -1 & \\text{若 } -\\frac{1}{2}x_1 < -1 \\iff x_1 > 2 \\end{cases} $$\n当 $|x_1| \\ge 2$ 时，控制达到饱和。我们现在通过将 $u_1^\\star(x_1)$ 代入 $J_1(u_1)$ 来计算价值函数 $V_1(x_1)$，这会得到一个分段函数：\n\n1.  对于 $|x_1| \\le 2$（线性区域），$u_1^\\star = -\\frac{1}{2}x_1$：\n    $$ V_1(x_1) = 2x_1^2 + 2x_1\\left(-\\frac{1}{2}x_1\\right) + 2\\left(-\\frac{1}{2}x_1\\right)^2 = 2x_1^2 - x_1^2 + \\frac{1}{2}x_1^2 = \\frac{3}{2}x_1^2 $$\n2.  对于 $x_1 > 2$（饱和区域），$u_1^\\star = -1$：\n    $$ V_1(x_1) = 2x_1^2 + 2x_1(-1) + 2(-1)^2 = 2x_1^2 - 2x_1 + 2 $$\n3.  对于 $x_1 < -2$（饱和区域），$u_1^\\star = 1$：\n    $$ V_1(x_1) = 2x_1^2 + 2x_1(1) + 2(1)^2 = 2x_1^2 + 2x_1 + 2 $$\n\n因此，在 $k=1$ 时的价值函数是：\n$$ V_1(x_1) = \\begin{cases} 2x_1^2 + 2x_1 + 2 & \\text{若 } x_1 \\le -2 \\\\ \\frac{3}{2}x_1^2 & \\text{若 } -2 < x_1 < 2 \\\\ 2x_1^2 - 2x_1 + 2 & \\text{若 } x_1 \\ge 2 \\end{cases} $$\n这个函数是连续且凸的。它的导数是 $V_1'(x_1) = \\begin{cases} 4x_1+2 & \\text{若 } x_1 \\le -2 \\\\ 3x_1 & \\text{若 } -2 < x_1 < 2 \\\\ 4x_1-2 & \\text{若 } x_1 \\ge 2 \\end{cases}$，它是连续的。\n\n**k=0 的步骤（初始阶段）**\n\n在阶段 $k=0$ 的价值函数为：\n$$ V_0(x_0) = \\min_{|u_0| \\le 1} \\left\\{ x_0^2 + u_0^2 + V_1(x_0 + u_0) \\right\\} $$\n设 $J_0(u_0) = x_0^2 + u_0^2 + V_1(x_0 + u_0)$。函数 $V_1$ 是凸的，并且映射 $u_0 \\mapsto x_0^2+u_0^2$ 是严格凸的。因此，$J_0(u_0)$ 是关于 $u_0$ 的严格凸函数。最优控制 $u_0^\\star(x_0)$ 是唯一的最小化子。\n\n无约束最小化子 $u_{0, \\text{unc}}$ 满足 $\\frac{dJ_0}{du_0} = 0$：\n$$ 2u_0 + V_1'(x_0+u_0) = 0 $$\n最优带约束控制是 $u_0^\\star = \\text{sat}(u_{0,\\text{unc}})$。如果在 $u_0=-1$ 处导数 $\\frac{dJ_0}{du_0} \\ge 0$，则控制在 $u_0^\\star=-1$ 处饱和；如果在 $u_0=1$ 处导数 $\\frac{dJ_0}{du_0} \\le 0$，则控制在 $u_0^\\star=1$ 处饱和。\n\n- 在 $u_0^\\star = -1$ 处饱和：这发生在 $2(-1) + V_1'(x_0-1) \\ge 0 \\implies V_1'(x_0-1) \\ge 2$ 的情况下。\n  使用 $V_1'(x_1)$ 的表达式，我们发现当 $x_1 \\ge 2/3$ 时，$V_1'(x_1) \\ge 2$。因此，当 $x_0-1 \\ge 2/3$ 时，即 $x_0 \\ge 5/3$ 时，在 $u_0^\\star=-1$ 处发生饱和。\n\n- 在 $u_0^\\star = 1$ 处饱和：这发生在 $2(1) + V_1'(x_0+1) \\le 0 \\implies V_1'(x_0+1) \\le -2$ 的情况下。\n  这对于 $x_1 \\le -2/3$ 成立。因此，当 $x_0+1 \\le -2/3$ 时，即 $x_0 \\le -5/3$ 时，在 $u_0^\\star=1$ 处发生饱和。\n\n- 线性区域：对于 $|x_0| < 5/3$，控制未饱和。最优性条件基于 $x_1 = x_0+u_0$ 位于 $V_1$ 的线性区域，即 $|x_1| < 2$。\n  在这种情况下，$V_1'(x_1) = 3x_1$。最优性条件 $2u_0 + 3(x_0+u_0) = 0$ 给出 $5u_0+3x_0=0$，所以 $u_{0,\\text{unc}} = -\\frac{3}{5}x_0$。\n  对于 $|x_0| < 5/3$, $|u_{0,\\text{unc}}| = \\frac{3}{5}|x_0| < 1$，所以控制确实是未饱和的。\n  下一步的状态是 $x_1 = x_0 + u_0^\\star = x_0 - \\frac{3}{5}x_0 = \\frac{2}{5}x_0$。对于 $|x_0| < 5/3$，我们有 $|x_1| < \\frac{2}{5} \\cdot \\frac{5}{3} = 2/3 < 2$，所以 $x_1$ 确实在 $V_1$ 的二次区域内。\n\n最优策略是 $u_0^\\star(x_0) = \\text{sat}(-3x_0/5)$，更精确地说是：\n$$ u_0^\\star(x_0) = \\begin{cases} 1 & \\text{若 } x_0 \\le -5/3 \\\\ -\\frac{3}{5}x_0 & \\text{若 } |x_0| < 5/3 \\\\ -1 & \\text{若 } x_0 \\ge 5/3 \\end{cases} $$\n我们现在分段计算价值函数 $V_0(x_0)$：\n\n1.  对于 $|x_0|  5/3$（线性控制区域），$u_0^\\star = -3x_0/5$。下一个状态是 $x_1 = 2x_0/5$，它位于 $(-2,2)$ 区间内。\n    $$ V_0(x_0) = x_0^2 + \\left(-\\frac{3}{5}x_0\\right)^2 + V_1\\left(\\frac{2}{5}x_0\\right) = x_0^2 + \\frac{9}{25}x_0^2 + \\frac{3}{2}\\left(\\frac{2}{5}x_0\\right)^2 $$\n    $$ V_0(x_0) = x_0^2 + \\frac{9}{25}x_0^2 + \\frac{3}{2}\\frac{4}{25}x_0^2 = \\left(1 + \\frac{9}{25} + \\frac{6}{25}\\right)x_0^2 = \\left(\\frac{25+9+6}{25}\\right)x_0^2 = \\frac{40}{25}x_0^2 = \\frac{8}{5}x_0^2 $$\n\n2.  对于 $x_0 \\ge 5/3$（饱和控制），$u_0^\\star = -1$。下一个状态是 $x_1 = x_0-1 > 2/3$。\n    $$ V_0(x_0) = x_0^2 + (-1)^2 + V_1(x_0-1) = x_0^2 + 1 + V_1(x_0-1) $$\n    $V_1$ 的形式取决于 $x_1 = x_0-1$ 是大于还是小于 $2$。边界是 $x_0-1=2 \\implies x_0=3$。\n\n    - 对于 $5/3 \\le x_0 \\le 3$：$x_1=x_0-1 \\in [2/3, 2]$，所以 $V_1(x_1) = \\frac{3}{2}x_1^2$。\n      $$ V_0(x_0) = x_0^2 + 1 + \\frac{3}{2}(x_0-1)^2 = x_0^2 + 1 + \\frac{3}{2}(x_0^2 - 2x_0 + 1) = \\frac{5}{2}x_0^2 - 3x_0 + \\frac{5}{2} $$\n    - 对于 $x_0 > 3$：$x_1=x_0-1>2$，所以 $V_1(x_1) = 2x_1^2-2x_1+2$。\n      $$ V_0(x_0) = x_0^2 + 1 + 2(x_0-1)^2 - 2(x_0-1) + 2 = x_0^2 + 1 + 2(x_0^2-2x_0+1) - 2x_0 + 2 + 2 = 3x_0^2 - 6x_0 + 7 $$\n\n3.  对于 $x_0 \\le -5/3$（饱和控制），$u_0^\\star = 1$。通过与 $x_0>5/3$ 情况的对称性。下一个状态是 $x_1=x_0+1  -2/3$。$V_1$ 的边界是 $x_0+1=-2 \\implies x_0=-3$。\n\n    - 对于 $-3 \\le x_0 \\le -5/3$：$x_1=x_0+1 \\in [-2, -2/3]$，所以 $V_1(x_1) = \\frac{3}{2}x_1^2$。\n      $$ V_0(x_0) = x_0^2+1+\\frac{3}{2}(x_0+1)^2 = x_0^2+1+\\frac{3}{2}(x_0^2+2x_0+1) = \\frac{5}{2}x_0^2 + 3x_0 + \\frac{5}{2} $$\n    - 对于 $x_0  -3$：$x_1=x_0+1-2$，所以 $V_1(x_1) = 2x_1^2+2x_1+2$。\n      $$ V_0(x_0) = x_0^2+1+2(x_0+1)^2+2(x_0+1)+2 = x_0^2+1+2(x_0^2+2x_0+1)+2x_0+2+2 = 3x_0^2+6x_0+7 $$\n\n$V_0(x_0)$ 的最终表达式是一个由五部分组成的连续、分段解析函数。\n\n**全局最优性论证**\n\n成本函数 $J = x_0^2 + u_0^2 + (x_0+u_0)^2 + u_1^2 + (x_0+u_0+u_1)^2$ 是控制向量 $(u_0, u_1)$ 的严格凸函数，因为其 Hessian 矩阵 $H = \\begin{pmatrix} 4  2 \\\\ 2  4 \\end{pmatrix}$ 是正定的。可行控制集 $\\mathcal{U} = \\{(u_0, u_1) \\in \\mathbb{R}^2 \\mid |u_0|\\le 1, |u_1|\\le 1\\}$ 是紧的且凸的。在一个紧凸集上最小化一个严格凸函数有唯一的全局最小值。DP 算法正确地找到了这个最小值。在每个阶段 $k$，关于 $u_k$ 的最小化问题是凸的，因为阶段成本是凸的，并且价值函数 $V_{k+1}$ 是凸的（通过归纳法，从凸的终端成本 $V_2(x_2)=x_2^2$ 开始）。因此，在每一步推导出的策略对于该子问题都是最优的。根据 Bellman 最优性原理，这些最优子策略的组合产生了全局最优策略。推导出的解是唯一的且全局最优的。\n\n价值函数 $V_0(x_0)$ 的最终表达式是：\n$$ V_0(x_0) = \\begin{cases}\n3x_0^2 + 6x_0 + 7  \\text{若 } x_0 \\le -3 \\\\\n\\frac{5}{2}x_0^2 + 3x_0 + \\frac{5}{2}  \\text{若 } -3  x_0 \\le -5/3 \\\\\n\\frac{8}{5}x_0^2  \\text{若 } -5/3  x_0  5/3 \\\\\n\\frac{5}{2}x_0^2 - 3x_0 + \\frac{5}{2}  \\text{若 } 5/3 \\le x_0  3 \\\\\n3x_0^2 - 6x_0 + 7  \\text{若 } x_0 \\ge 3\n\\end{cases} $$", "answer": "$$\n\\boxed{\nV_0(x_0) = \\begin{cases}\n3x_0^2 + 6x_0 + 7  \\text{若 } x_0 \\le -3 \\\\\n\\frac{5}{2}x_0^2 + 3x_0 + \\frac{5}{2}  \\text{若 } -3  x_0 \\le -\\frac{5}{3} \\\\\n\\frac{8}{5}x_0^2  \\text{若 } -\\frac{5}{3}  x_0  \\frac{5}{3} \\\\\n\\frac{5}{2}x_0^2 - 3x_0 + \\frac{5}{2}  \\text{若 } \\frac{5}{3} \\le x_0  3 \\\\\n3x_0^2 - 6x_0 + 7  \\text{若 } x_0 \\ge 3\n\\end{cases}\n}\n$$", "id": "2703354"}, {"introduction": "本问题将介绍另一类基本的序贯决策问题：最优停止问题。在这里，核心决策不是选择采取 *何种* 行动，而是 *何时* 停止一个过程以最大化收益。你将首先推导此类问题的一般贝尔曼方程，然后将其应用于一个具体案例，学习如何通过比较立即停止的收益与继续下去的期望价值来确定最优停止区域。这个练习展示了动态规划框架在传统控制任务之外的广泛适用性。[@problem_id:2703363]", "problem": "考虑一个实值状态过程 $\\{x_{t}\\}_{t \\in \\mathbb{N}_{0}}$ 的离散时间最优停止问题，其初始条件为 $x_{0}=x \\in \\mathbb{R}$。在每个时刻 $t$，决策者选择停止并获得即时回报，或者选择继续并获得一个连续回报，并保留在下一时刻再次决策的选择权。当决策为继续时，系统根据一个时齐转移律演化。目标是最大化期望总折扣回报。假设折扣因子为 $\\gamma \\in (0,1)$，即时停止回报由可测函数 $\\psi:\\mathbb{R}\\to\\mathbb{R}$ 给出，连续回报由可测函数 $\\ell:\\mathbb{R}\\to\\mathbb{R}$ 给出，并且当选择继续时，从 $x$ 到下一状态 $x'$ 的转移服从一个条件分布，使得条件期望 $\\mathbb{E}[\\cdot \\mid x]$ 是良定义的。\n\n- 仅使用最优性原理和条件期望的塔性质，推导刻画此最优停止问题的最优值函数 $V:\\mathbb{R}\\to\\mathbb{R}$ 的动态规划方程。清晰地陈述您为证明此推导而施加的任何正则性条件。\n\n- 现在将问题特殊化为一个一维例子，其在继续时的动力学为确定性线性动力学，由 $x_{t+1}=\\lambda x_{t}$ 给出（其中 $\\lambda \\in \\mathbb{R}$ 为常数），连续回报为 $\\ell(x)=-q x^{2}$（其中 $q0$），停止回报为 $\\psi(x)=A - B x^{2}$（其中 $A0$ 且 $B0$）。假设 $\\gamma \\lambda^{2}  1$ 且 $B  \\frac{q}{1-\\gamma \\lambda^{2}}$。\n\n  使用您推导的动态规划方程，通过假设一个在动力学和回报下不变的适当函数形式，求解继续区域中的值函数。然后确定阈值 $x^{\\star}0$，使得最优停止区域为 $\\{x \\in \\mathbb{R} : |x| \\leq x^{\\star}\\}$。用 $A$、$B$、$q$、$\\gamma$ 和 $\\lambda$ 以闭式形式表示 $x^{\\star}$。\n\n- 最后，使用具体参数值 $A=3$、$B=5$、$q=1$、$\\gamma=\\frac{1}{2}$ 和 $\\lambda=\\frac{1}{2}$ 计算 $x^{\\star}$ 的值。最终答案只报告 $x^{\\star}$ 的精确值。不要四舍五入或近似。", "solution": "我们首先对问题陈述进行严格验证。\n\n### 步骤 1：提取已知条件\n问题提供了以下信息：\n- 一个实值状态过程 $\\{x_{t}\\}_{t \\in \\mathbb{N}_{0}}$ 的离散时间最优停止问题，其初始条件为 $x_{0}=x \\in \\mathbb{R}$。\n- 每个时刻 $t$ 的决策：停止或继续。\n- 折扣因子：$\\gamma \\in (0,1)$。\n- 即时停止回报函数：$\\psi:\\mathbb{R}\\to\\mathbb{R}$。\n- 连续回报函数（当继续时）：$\\ell:\\mathbb{R}\\to\\mathbb{R}$。\n- 状态转移：从 $x$ 到 $x'$ 的一个时齐条件分布，使得条件期望 $\\mathbb{E}[\\cdot \\mid x]$ 是良定义的。\n- 目标：最大化期望总折扣回报。\n- 第 1 部分任务：使用最优性原理和条件期望的塔性质，推导最优值函数 $V:\\mathbb{R}\\to\\mathbb{R}$ 的动态规划方程。\n- 第 2 部分特殊化：\n  - 确定性线性动力学：$x_{t+1}=\\lambda x_{t}$，其中 $\\lambda \\in \\mathbb{R}$。\n  - 连续回报：$\\ell(x)=-q x^{2}$，其中 $q0$。\n  - 停止回报：$\\psi(x)=A - B x^{2}$，其中 $A0$ 且 $B0$。\n  - 参数约束：$\\gamma \\lambda^{2}  1$ 且 $B  \\frac{q}{1-\\gamma \\lambda^{2}}$。\n- 第 2 部分任务：使用一个不变的函数形式求解继续区域中的值函数，并确定停止区域 $\\{x \\in \\mathbb{R} : |x| \\leq x^{\\star}\\}$ 的停止阈值 $x^{\\star}0$。\n- 第 3 部分任务：使用具体参数值 $A=3$、$B=5$、$q=1$、$\\gamma=\\frac{1}{2}$ 和 $\\lambda=\\frac{1}{2}$ 计算 $x^{\\star}$。\n\n### 步骤 2：使用提取的已知条件进行验证\n根据验证标准对问题陈述进行审查。\n- **科学上合理**：该问题是无限期、离散时间最优停止问题的标准表述，是控制论和序贯决策论中的一个基本主题。它依赖于诸如 Bellman 最优性原理、动态规划和条件期望等既定概念。它没有任何科学或数学上的谬误。\n- **适定性**：该问题是适定的。第一部分要求进行标准推导。第二部分提供了具体的函数形式和参数约束（$ \\gamma \\lambda^2  1 $, $ B  \\frac{q}{1-\\gamma \\lambda^2} $），这些正是确保值函数和停止阈值存在良定义、非平凡且唯一解所必需的条件。\n- **客观性**：问题以精确、客观的数学语言陈述。\n- **完整性**：问题是自洽的。它提供了执行所需推导和计算所必需的所有函数、参数和约束。\n- **其他缺陷**：问题没有其他缺陷。在控制论的数学背景下，它不是平凡的、比喻性的或不切实际的。\n\n### 步骤 3：结论和行动\n问题有效。我现在将提供完整的解法。\n\n### 解题推导\n\n**第 1 部分：动态规划方程的推导**\n\n令 $V(x)$ 为最优值函数，表示从状态 $x_0 = x$ 开始的最大期望总折扣回报。决策者选择一个策略，即针对每个状态和时间的一系列决策（停止或继续），以最大化该值。\n\n在任何状态 $x$，决策者可以从两个行动中选择一个：\n1.  **停止**：过程终止，决策者获得终点回报 $\\psi(x)$。总折扣回报就是 $\\psi(x)$。\n2.  **继续**：决策者获得一个即时连续回报 $\\ell(x)$。系统随后根据其转移律转移到一个新状态 $x'$。过程从 $x'$ 继续，并且根据最优性原理，后续的决策必须构成从 $x'$ 开始的问题的最优策略。从当前时刻看，所有未来回报的期望折扣值为 $\\gamma \\mathbb{E}[V(x') \\mid x]$。期望的塔性质，$\\mathbb{E}[\\mathbb{E}[Y|X]] = \\mathbb{E}[Y]$，确保了该公式在时间上的一致性。因此，继续的总期望回报为 $\\ell(x) + \\gamma \\mathbb{E}[V(x') \\mid x]$。\n\nBellman 的最优性原理指出，一个最优策略具有这样的性质：无论初始状态和初始决策是什么，余下的决策相对于由第一个决策所产生的状态而言，必须构成一个最优策略。在数学上，这意味着值函数 $V(x)$ 必须是与每个可能的初始行动相关联的值中的最大值。\n\n因此，这个最优停止问题的动态规划方程，或称贝尔曼方程，是：\n$$V(x) = \\max \\left\\{ \\psi(x), \\quad \\ell(x) + \\gamma \\mathbb{E}[V(x') \\mid x] \\right\\}$$\n该方程是关于 $V(x)$ 的一个泛函方程。为了保证该方程解 $V(x)$ 的存在性和唯一性并证明推导的合理性，需要某些正则性条件。通常，我们假设回报函数 $\\psi(x)$ 和 $\\ell(x)$是有界的，且算子 $T(f)(x) = \\max\\{\\psi(x), \\ell(x) + \\gamma \\mathbb{E}[f(x') \\mid x]\\}$ 在具有上确界范数的有界连续函数空间上是一个压缩映射。条件 $\\gamma \\in (0,1)$ 对此至关重要，它使得 $T$ 成为一个压缩映射，并根据 Banach 不动点定理，确保了值迭代收敛到一个唯一的不动点。\n\n**第 2 部分：具体例子的求解**\n\n给定以下特殊化条件：\n- 动力学： $x_{t+1} = \\lambda x_t$。这是确定性的，所以对于任何函数 $f$，有 $\\mathbb{E}[f(x_{t+1}) | x_t] = f(\\lambda x_t)$。\n- 连续回报：$\\ell(x) = -q x^2$。\n- 停止回报：$\\psi(x) = A - B x^2$。\n\n动态规划方程简化为：\n$$V(x) = \\max \\left\\{ A - Bx^2, \\quad -qx^2 + \\gamma V(\\lambda x) \\right\\}$$\n空间被划分为一个停止区域 $S$ 和一个继续区域 $C$。\n- 在停止区域 $S$ 中，$V(x) = \\psi(x) = A - Bx^2$。\n- 在继续区域 $C$ 中，$V(x) = \\ell(x) + \\gamma V(\\lambda x) = -qx^2 + \\gamma V(\\lambda x)$。\n\n问题假设在继续区域中值函数具有一个不变的函数形式。鉴于回报函数是二次形式, 我们假设继续区域中的值函数也为二次形式，即 $V_c(x) = K - Px^2$，其中 $K$ 和 $P$ 是某些常数。为了使这个猜测有效，如果 $x \\in C$，那么 $\\lambda x$ 必须也在 $C$ 中（或者形式会自适应）。让我们假设 $x=0$ 是一个停止点，因此继续区域不包含 $0$ 的一个邻域。\n\n将拟设 $V(x) = K - Px^2$ 代入继续区域的方程中：\n$$K - Px^2 = -qx^2 + \\gamma (K - P(\\lambda x)^2)$$\n$$K - Px^2 = -qx^2 + \\gamma K - \\gamma P \\lambda^2 x^2$$\n为了使该方程在继续区域中的所有 $x$ 都成立，我们必须匹配 $x$ 的各次幂的系数。\n- 匹配常数项：$K = \\gamma K \\implies K(1-\\gamma) = 0$。因为 $\\gamma \\in (0,1)$，所以我们必有 $K=0$。\n- 匹配 $x^2$ 项：$-P = -q - \\gamma P \\lambda^2 \\implies P(1 - \\gamma \\lambda^2) = q$。\n条件 $\\gamma \\lambda^2  1$ 确保了 $1 - \\gamma \\lambda^2  0$。由于 $q0$，我们可以解出 $P$：\n$$P = \\frac{q}{1 - \\gamma \\lambda^2}$$\n因此，继续区域中的值函数为 $V_c(x) = -Px^2 = -\\frac{q}{1 - \\gamma \\lambda^2}x^2$。\n\n最优策略是在停止回报至少与继续的价值一样大时停止。停止区域是 $\\{x \\in \\mathbb{R} : \\psi(x) \\geq V_c(x)\\}$。问题陈述该区域的形式为 $\\{x \\in \\mathbb{R} : |x| \\leq x^{\\star}\\}$。该区域的边界由值匹配条件 $\\psi(x) = V_c(x)$ 定义。\n$$A - Bx^2 = -\\frac{q}{1 - \\gamma \\lambda^2}x^2$$\n$$A = Bx^2 - \\frac{q}{1 - \\gamma \\lambda^2}x^2$$\n$$A = \\left( B - \\frac{q}{1 - \\gamma \\lambda^2} \\right) x^2$$\n问题给出的约束 $B  \\frac{q}{1-\\gamma \\lambda^2}$ 确保了 $x^2$ 的系数为正。令这个正系数为 $C = B - \\frac{q}{1-\\gamma \\lambda^2}$。\n$$A = C x^2 \\implies x^2 = \\frac{A}{C}$$\n阈值为 $x = \\pm \\sqrt{\\frac{A}{C}}$。由于 $x^\\star  0$，我们有：\n$$x^{\\star} = \\sqrt{\\frac{A}{B - \\frac{q}{1-\\gamma \\lambda^2}}}$$\n这就是停止阈值的闭式表达式。停止区域确实是 $|x| \\leq x^\\star$，因为对于此区间内的任何 $x$，都有 $x^2 \\leq (x^\\star)^2 = A/C$，这意味着 $Cx^2 \\leq A$，整理后可得 $\\psi(x) \\geq V_c(x)$。\n\n**第 3 部分：数值计算**\n\n我们给定的参数为：$A=3$、$B=5$、$q=1$、$\\gamma=\\frac{1}{2}$ 和 $\\lambda=\\frac{1}{2}$。\n首先，我们验证约束条件：\n- $\\gamma \\lambda^2 = \\frac{1}{2} \\left(\\frac{1}{2}\\right)^2 = \\frac{1}{2} \\cdot \\frac{1}{4} = \\frac{1}{8}$。由于 $\\frac{1}{8}  1$，第一个条件满足。\n- 我们必须检查是否 $B  \\frac{q}{1-\\gamma \\lambda^2}$。右边是 $\\frac{1}{1 - 1/8} = \\frac{1}{7/8} = \\frac{8}{7}$。条件是 $5  \\frac{8}{7}$，这是成立的，因为 $5 = \\frac{35}{7}$。\n\n现在，我们将这些值代入 $x^{\\star}$ 的表达式中：\n$$x^{\\star} = \\sqrt{\\frac{A}{B - \\frac{q}{1 - \\gamma\\lambda^2}}}$$\n$$x^{\\star} = \\sqrt{\\frac{3}{5 - \\frac{1}{1 - \\frac{1}{8}}}}$$\n$$x^{\\star} = \\sqrt{\\frac{3}{5 - \\frac{8}{7}}}$$\n$$x^{\\star} = \\sqrt{\\frac{3}{\\frac{35}{7} - \\frac{8}{7}}}$$\n$$x^{\\star} = \\sqrt{\\frac{3}{\\frac{27}{7}}}$$\n$$x^{\\star} = \\sqrt{\\frac{3 \\cdot 7}{27}} = \\sqrt{\\frac{7}{9}}$$\n$$x^{\\star} = \\frac{\\sqrt{7}}{3}$$\n\n停止阈值的精确值为 $\\frac{\\sqrt{7}}{3}$。", "answer": "$$\\boxed{\\frac{\\sqrt{7}}{3}}$$", "id": "2703363"}]}