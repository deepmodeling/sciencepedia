{"hands_on_practices": [{"introduction": "容错控制的首要任务是准确地检测和估计故障。本练习将引导您应用经典的统计学原理来解决一个实际的传感器故障估计问题 [@problem_id:2707675]。通过从最大似然估计（MLE）的第一性原理出发，您将推导出一个传感器偏置故障的最佳估计量，从而深刻理解如何在充满噪声的测量数据中提炼出关于系统健康状况的关键信息。", "problem": "考虑一种容错控制 (FTC) 架构，该架构融合冗余传感器的测量值，以在可能存在偏置故障的情况下估计对象输出。设有两台同步传感器，在以 $k \\in \\{1,\\dots,N\\}$ 为索引的离散时刻观测同一个标量对象输出。时刻 $k$ 的潜在对象输出为 $x_{k} \\in \\mathbb{R}$，其未知且可以随 $k$ 任意变化。传感器1可能存在一个常数偏置故障 $b \\in \\mathbb{R}$，而传感器2是无偏的。测量模型为\n$$\ny_{1,k} \\;=\\; x_{k} + b + v_{1,k}, \n\\qquad\ny_{2,k} \\;=\\; x_{k} + v_{2,k},\n$$\n其中 $\\{v_{1,k}\\}$ 和 $\\{v_{2,k}\\}$ 是相互独立、零均值的高斯噪声序列，其方差已知且可能时变：\n$$\nv_{1,k} \\sim \\mathcal{N}\\!\\big(0,\\;\\sigma_{1,k}^{2}\\big), \n\\qquad\nv_{2,k} \\sim \\mathcal{N}\\!\\big(0,\\;\\sigma_{2,k}^{2}\\big),\n$$\n并且在时间 $k$ 上是独立的。序列 $\\{\\sigma_{1,k}^{2}\\}_{k=1}^{N}$ 和 $\\{\\sigma_{2,k}^{2}\\}_{k=1}^{N}$ 是由传感器健康监测器提供的已知正数。未知量是偏置 $b$ 和讨厌值序列 $\\{x_{k}\\}_{k=1}^{N}$。\n\n从最大似然估计的基本原理和独立性条件下的高斯似然定义出发，推导偏置 $b$ 的最大似然估计 (MLE) 的闭式表达式，该表达式仅用观测数据 $\\{y_{1,k},y_{2,k}\\}_{k=1}^{N}$ 和已知方差 $\\{\\sigma_{1,k}^{2},\\sigma_{2,k}^{2}\\}_{k=1}^{N}$ 表示。您的推导过程应显式地消除讨厌序列 $\\{x_{k}\\}_{k=1}^{N}$，并且除了已声明的内容外，不对 $\\{x_{k}\\}_{k=1}^{N}$ 作任何先验模型的假设。\n\n将您的最终结果表示为单一的精确解析表达式。无需四舍五入，不涉及单位。", "solution": "所述问题在科学上是合理的、适定的、客观的且自洽的。这是统计估计理论应用于故障检测中的一个标准问题。它不包含任何不一致或违反科学原理之处。因此，将推导其解。\n\n目标是从测量数据集 $\\{y_{1,k}, y_{2,k}\\}_{k=1}^{N}$ 中找到常数偏置参数 $b$ 的最大似然估计 (MLE)。待估计的参数是偏置 $b$ 和未知的真实对象输出 $\\{x_k\\}_{k=1}^{N}$，后者被视为讨厌参数。设参数向量为 $\\theta = (b, x_1, x_2, \\dots, x_N)$。\n\n测量模型由下式给出：\n$$y_{1,k} = x_k + b + v_{1,k}, \\quad v_{1,k} \\sim \\mathcal{N}(0, \\sigma_{1,k}^2)$$\n$$y_{2,k} = x_k + v_{2,k}, \\quad v_{2,k} \\sim \\mathcal{N}(0, \\sigma_{2,k}^2)$$\n噪声项 $v_{1,k}$ 和 $v_{2,k}$ 相互独立，并且在时间索引 $k$ 上也是独立的。\n\n在单个时间步 $k$，以参数 $x_k$ 和 $b$ 为条件的测量向量 $(y_{1,k}, y_{2,k})$ 的概率密度函数 (PDF) 是各个高斯 PDF 的乘积，这是因为噪声源是独立的：\n$$p(y_{1,k}, y_{2,k} | x_k, b) = p(y_{1,k} | x_k, b) \\, p(y_{2,k} | x_k)$$\n$$p(y_{1,k}, y_{2,k} | x_k, b) = \\frac{1}{\\sqrt{2\\pi\\sigma_{1,k}^2}} \\exp\\left(-\\frac{(y_{1,k} - x_k - b)^2}{2\\sigma_{1,k}^2}\\right) \\cdot \\frac{1}{\\sqrt{2\\pi\\sigma_{2,k}^2}} \\exp\\left(-\\frac{(y_{2,k} - x_k)^2}{2\\sigma_{2,k}^2}\\right)$$\n\n对于整个测量序列 $Y = \\{y_{1,k}, y_{2,k}\\}_{k=1}^N$，给定参数向量 $\\theta$ 的总似然函数是每个时间步的 PDF 的乘积，这是因为时间上的独立性：\n$$L(\\theta | Y) = \\prod_{k=1}^N p(y_{1,k}, y_{2,k} | x_k, b)$$\n$$L(b, \\{x_k\\}_{k=1}^N | Y) = \\prod_{k=1}^N \\frac{1}{2\\pi\\sigma_{1,k}\\sigma_{2,k}} \\exp\\left(-\\frac{(y_{1,k} - x_k - b)^2}{2\\sigma_{1,k}^2} - \\frac{(y_{2,k} - x_k)^2}{2\\sigma_{2,k}^2}\\right)$$\n\n为了进行最大化，处理对数似然函数 $\\mathcal{L}(\\theta) = \\ln L(\\theta | Y)$ 更为方便：\n$$\\mathcal{L}(b, \\{x_k\\}_{k=1}^N) = \\sum_{k=1}^N \\left[ -\\ln(2\\pi\\sigma_{1,k}\\sigma_{2,k}) - \\frac{(y_{1,k} - x_k - b)^2}{2\\sigma_{1,k}^2} - \\frac{(y_{2,k} - x_k)^2}{2\\sigma_{2,k}^2} \\right]$$\n\n最大化对数似然等价于最小化二次项之和的负数。令该代价函数为 $J(b, \\{x_k\\}_{k=1}^N)$：\n$$J(b, \\{x_k\\}_{k=1}^N) = \\sum_{k=1}^N \\left[ \\frac{(y_{1,k} - x_k - b)^2}{\\sigma_{1,k}^2} + \\frac{(y_{2,k} - x_k)^2}{\\sigma_{2,k}^2} \\right]$$\n\n为求得 $b$ 的 MLE，我们使用剖面似然法。我们首先通过最小化 $J$ 来找到每个讨厌参数 $x_k$ 作为 $b$ 的函数的 MLE，记为 $\\hat{x}_k(b)$。由于 $J$ 是一个和式，其中每个 $x_k$ 仅出现在第 $k$ 项中，因此我们可以独立地最小化每一项。对于每个 $k \\in \\{1, \\dots, N\\}$，我们将关于 $x_k$ 的偏导数设为零：\n$$\\frac{\\partial J}{\\partial x_k} = \\frac{-2(y_{1,k} - x_k - b)( -1)}{\\sigma_{1,k}^2} + \\frac{-2(y_{2,k} - x_k)( -1)}{\\sigma_{2,k}^2} = 0$$\n$$\\frac{y_{1,k} - b - x_k}{\\sigma_{1,k}^2} + \\frac{y_{2,k} - x_k}{\\sigma_{2,k}^2} = 0$$\n求解 $x_k$：\n$$\\frac{y_{1,k} - b}{\\sigma_{1,k}^2} + \\frac{y_{2,k}}{\\sigma_{2,k}^2} = x_k \\left( \\frac{1}{\\sigma_{1,k}^2} + \\frac{1}{\\sigma_{2,k}^2} \\right)$$\n$$\\hat{x}_k(b) = \\frac{\\frac{y_{1,k} - b}{\\sigma_{1,k}^2} + \\frac{y_{2,k}}{\\sigma_{2,k}^2}}{\\frac{1}{\\sigma_{1,k}^2} + \\frac{1}{\\sigma_{2,k}^2}} = \\frac{(y_{1,k} - b)\\sigma_{2,k}^2 + y_{2,k}\\sigma_{1,k}^2}{\\sigma_{1,k}^2 + \\sigma_{2,k}^2}$$\n这个 $\\hat{x}_k(b)$ 的表达式代表了在给定 $b$ 的情况下对 $x_k$ 的最优估计。\n\n接下来，我们将 $\\hat{x}_k(b)$ 代入代价函数 $J$ 中，以获得剖面代价函数 $J_p(b) = J(b, \\{\\hat{x}_k(b)\\}_{k=1}^N)$。让我们先分析和式中单个 $k$ 的项：\n$$y_{1,k} - \\hat{x}_k(b) - b = (y_{1,k}-b) - \\frac{(y_{1,k} - b)\\sigma_{2,k}^2 + y_{2,k}\\sigma_{1,k}^2}{\\sigma_{1,k}^2 + \\sigma_{2,k}^2} = \\frac{(y_{1,k}-b)(\\sigma_{1,k}^2+\\sigma_{2,k}^2) - (y_{1,k}-b)\\sigma_{2,k}^2 - y_{2,k}\\sigma_{1,k}^2}{\\sigma_{1,k}^2 + \\sigma_{2,k}^2} = \\frac{(y_{1,k}-b-y_{2,k})\\sigma_{1,k}^2}{\\sigma_{1,k}^2 + \\sigma_{2,k}^2}$$\n$$y_{2,k} - \\hat{x}_k(b) = y_{2,k} - \\frac{(y_{1,k}-b)\\sigma_{2,k}^2 + y_{2,k}\\sigma_{1,k}^2}{\\sigma_{1,k}^2+\\sigma_{2,k}^2} = \\frac{y_{2,k}(\\sigma_{1,k}^2+\\sigma_{2,k}^2) - (y_{1,k}-b)\\sigma_{2,k}^2 - y_{2,k}\\sigma_{1,k}^2}{\\sigma_{1,k}^2+\\sigma_{2,k}^2} = \\frac{(y_{2,k} - y_{1,k}+b)\\sigma_{2,k}^2}{\\sigma_{1,k}^2 + \\sigma_{2,k}^2}$$\n\n将这些代入 $J$ 的第 $k$ 项：\n$$\\frac{1}{\\sigma_{1,k}^2}\\left(\\frac{(y_{1,k}-y_{2,k}-b)\\sigma_{1,k}^2}{\\sigma_{1,k}^2 + \\sigma_{2,k}^2}\\right)^2 + \\frac{1}{\\sigma_{2,k}^2}\\left(\\frac{(y_{2,k}-y_{1,k}+b)\\sigma_{2,k}^2}{\\sigma_{1,k}^2 + \\sigma_{2,k}^2}\\right)^2$$\n$$= \\frac{\\sigma_{1,k}^2(y_{1,k}-y_{2,k}-b)^2}{(\\sigma_{1,k}^2 + \\sigma_{2,k}^2)^2} + \\frac{\\sigma_{2,k}^2(y_{1,k}-y_{2,k}-b)^2}{(\\sigma_{1,k}^2 + \\sigma_{2,k}^2)^2} = \\frac{(\\sigma_{1,k}^2+\\sigma_{2,k}^2)(y_{1,k}-y_{2,k}-b)^2}{(\\sigma_{1,k}^2 + \\sigma_{2,k}^2)^2} = \\frac{(y_{1,k}-y_{2,k}-b)^2}{\\sigma_{1,k}^2 + \\sigma_{2,k}^2}$$\n这个简化表明，该问题等价于估计变量 $d_k = y_{1,k} - y_{2,k}$ 的均值 $b$，该变量的方差为时变的 $\\sigma_{d,k}^2 = \\sigma_{1,k}^2 + \\sigma_{2,k}^2$。\n\n因此，剖面代价函数为：\n$$J_p(b) = \\sum_{k=1}^N \\frac{(y_{1,k} - y_{2,k} - b)^2}{\\sigma_{1,k}^2 + \\sigma_{2,k}^2}$$\n\n为了求得 $b$ 的 MLE，我们通过将其关于 $b$ 的导数设为零来最小化 $J_p(b)$：\n$$\\frac{d J_p(b)}{d b} = \\sum_{k=1}^N \\frac{-2(y_{1,k} - y_{2,k} - b)}{\\sigma_{1,k}^2 + \\sigma_{2,k}^2} = 0$$\n$$\\sum_{k=1}^N \\frac{y_{1,k} - y_{2,k}}{\\sigma_{1,k}^2 + \\sigma_{2,k}^2} = \\sum_{k=1}^N \\frac{b}{\\sigma_{1,k}^2 + \\sigma_{2,k}^2}$$\n$$b \\left( \\sum_{k=1}^N \\frac{1}{\\sigma_{1,k}^2 + \\sigma_{2,k}^2} \\right) = \\sum_{k=1}^N \\frac{y_{1,k} - y_{2,k}}{\\sigma_{1,k}^2 + \\sigma_{2,k}^2}$$\n\n求解 $b$ 可得到最大似然估计 $\\hat{b}_{MLE}$ 的最终表达式：\n$$\\hat{b}_{MLE} = \\frac{\\sum_{k=1}^{N} \\frac{y_{1,k} - y_{2,k}}{\\sigma_{1,k}^2 + \\sigma_{2,k}^2}}{\\sum_{k=1}^{N} \\frac{1}{\\sigma_{1,k}^2 + \\sigma_{2,k}^2}}$$\n这是一个差值 $y_{1,k} - y_{2,k}$ 的加权平均，其中权重与该差值的方差成反比，这对于此类估计问题是一个标准且符合预期的结果。", "answer": "$$\n\\boxed{\\frac{\\sum_{k=1}^{N} \\frac{y_{1,k} - y_{2,k}}{\\sigma_{1,k}^{2} + \\sigma_{2,k}^{2}}}{\\sum_{k=1}^{N} \\frac{1}{\\sigma_{1,k}^{2} + \\sigma_{2,k}^{2}}}}\n$$", "id": "2707675"}, {"introduction": "在生成故障信号（即“残差”）之后，下一步是建立一个可靠的决策规则来判断故障是否真的发生。本练习聚焦于故障检测中的统计决策环节，要求您为一个二次型残差评估统计量设计一个检测阈值 [@problem_id:2707656]。通过推导该统计量在无故障情况下的概率分布（即卡方分布, $\\chi^2$ 分布），您将学会如何量化地平衡检测灵敏度与误报率 $\\alpha$，这是设计任何高性能诊断系统的核心权衡。", "problem": "一个奇偶空间残差生成器被用于一个传感器冗余的线性时不变系统中的故障检测。在每个离散时间索引 $k$，无故障假设下的残差向量 $r_k \\in \\mathbb{R}^2$ 被建模为一个零均值多元高斯随机向量，其协方差矩阵为 $\\Sigma_r \\in \\mathbb{R}^{2 \\times 2}$，其中\n$$\n\\Sigma_r \\;=\\; \\begin{pmatrix} 3 & 1 \\\\ 1 & 2 \\end{pmatrix}.\n$$\n一个二次决策统计量被构造为\n$$\nJ_k \\;=\\; r_k^{\\top}\\,\\Sigma_r^{-1}\\,r_k,\n$$\n并且如果 $J_k > \\gamma$，则发出警报。\n\n从多元高斯分布和高斯随机向量线性变换的基本定义出发，推导在无故障假设下 $J_k$ 的概率分布。然后，利用这个分布，确定检测阈值 $\\gamma$，使得虚警概率等于 $\\alpha = 0.05$，即，\n$$\n\\mathbb{P}\\!\\left(J_k > \\gamma \\,\\middle|\\, \\text{no fault}\\right) \\;=\\; \\alpha.\n$$\n将您计算出的 $\\gamma$ 的最终数值答案四舍五入至四位有效数字。将最终答案以单个不带单位的实数形式给出。", "solution": "问题陈述经过验证。\n\n**步骤 1：提取已知条件**\n- 在无故障假设下的残差向量为 $r_k \\in \\mathbb{R}^2$。\n- 残差向量的分布为零均值多元高斯分布：$r_k \\sim \\mathcal{N}(0, \\Sigma_r)$。\n- 协方差矩阵为 $\\Sigma_r = \\begin{pmatrix} 3 & 1 \\\\ 1 & 2 \\end{pmatrix}$。\n- 二次决策统计量为 $J_k = r_k^{\\top}\\,\\Sigma_r^{-1}\\,r_k$。\n- 如果 $J_k > \\gamma$，则宣告故障。\n- 指定的虚警概率为 $\\mathbb{P}(J_k > \\gamma \\,|\\, \\text{no fault}) = \\alpha = 0.05$。\n\n**步骤 2：使用提取的已知条件进行验证**\n该问题具有科学依据，是统计决策理论在故障检测中的一个标准应用。给定的协方差矩阵 $\\Sigma_r$ 是对称的。其行列式为 $\\det(\\Sigma_r) = (3)(2) - (1)(1) = 5 > 0$，且其对角线元素为正。因此，$\\Sigma_r$ 是一个正定矩阵，这是非退化分布的协方差矩阵的一个有效要求。该问题是适定的，因为确定 $J_k$ 的分布以及随后确定阈值 $\\gamma$ 所需的所有信息均已提供。语言客观而精确。该问题并非浅显，因为它需要关于高斯向量二次型性质的知识。该问题是有效的。\n\n**步骤 3：结论与行动**\n该问题是有效的。将提供解答。\n\n目标是首先推导统计量 $J_k = r_k^{\\top}\\Sigma_r^{-1}r_k$ 的概率分布，然后计算对应于虚警概率 $\\alpha = 0.05$ 的阈值 $\\gamma$。\n\n在无故障假设下，残差向量 $r_k$ 是一个二维多元高斯随机向量，其均值向量为 $0$，协方差矩阵为 $\\Sigma_r$。我们记为 $r_k \\sim \\mathcal{N}(0, \\Sigma_r)$。\n\n多元高斯向量的基本理论指出，高斯向量的任何线性变换结果仍为高斯向量。我们定义一个变换来标准化向量 $r_k$。由于 $\\Sigma_r$ 是一个对称正定矩阵，它可以进行 Cholesky 分解，或者更一般地，存在矩阵平方根。令 $\\Sigma_r^{-1/2}$ 为逆协方差矩阵 $\\Sigma_r^{-1}$ 的对称正定平方根。我们定义一个新的随机向量 $z_k \\in \\mathbb{R}^2$ 为：\n$$\nz_k = \\Sigma_r^{-1/2} r_k\n$$\n这是 $r_k$ 的一个线性变换。我们可以通过计算其均值和协方差矩阵来确定 $z_k$ 的分布。\n\n$z_k$ 的均值为：\n$$\n\\mathbb{E}[z_k] = \\mathbb{E}[\\Sigma_r^{-1/2} r_k] = \\Sigma_r^{-1/2} \\mathbb{E}[r_k] = \\Sigma_r^{-1/2} \\cdot 0 = 0\n$$\n$z_k$ 的协方差矩阵为：\n$$\n\\text{Cov}(z_k) = \\mathbb{E}[(z_k - \\mathbb{E}[z_k])(z_k - \\mathbb{E}[z_k])^{\\top}] = \\mathbb{E}[z_k z_k^{\\top}]\n$$\n代入 $z_k$ 的表达式：\n$$\n\\text{Cov}(z_k) = \\mathbb{E}[(\\Sigma_r^{-1/2} r_k)(\\Sigma_r^{-1/2} r_k)^{\\top}] = \\mathbb{E}[\\Sigma_r^{-1/2} r_k r_k^{\\top} (\\Sigma_r^{-1/2})^{\\top}]\n$$\n由于 $\\Sigma_r^{-1/2}$ 是一个常数矩阵且是对称的，因此 $(\\Sigma_r^{-1/2})^{\\top} = \\Sigma_r^{-1/2}$。我们可以写成：\n$$\n\\text{Cov}(z_k) = \\Sigma_r^{-1/2} \\mathbb{E}[r_k r_k^{\\top}] \\Sigma_r^{-1/2}\n$$\n根据定义，$\\mathbb{E}[r_k r_k^{\\top}]$ 是 $r_k$ 的协方差矩阵，即 $\\Sigma_r$。因此：\n$$\n\\text{Cov}(z_k) = \\Sigma_r^{-1/2} \\Sigma_r \\Sigma_r^{-1/2} = \\Sigma_r^{-1/2} (\\Sigma_r^{1/2} \\Sigma_r^{1/2}) \\Sigma_r^{-1/2} = (\\Sigma_r^{-1/2} \\Sigma_r^{1/2}) (\\Sigma_r^{1/2} \\Sigma_r^{-1/2}) = I_2 \\cdot I_2 = I_2\n$$\n其中 $I_2$ 是 $2 \\times 2$ 单位矩阵。\n因此，$z_k$ 是一个零均值、单位协方差矩阵的多元高斯向量，$z_k \\sim \\mathcal{N}(0, I_2)$。这意味着 $z_k$ 的分量，我们记为 $z_{k,1}$ 和 $z_{k,2}$，是独立同分布的标准正态随机变量，即对于 $i=1, 2$，有 $z_{k,i} \\sim \\mathcal{N}(0, 1)$。\n\n现在，我们来考察决策统计量 $J_k$：\n$$\nJ_k = r_k^{\\top}\\Sigma_r^{-1}r_k\n$$\n由于 $\\Sigma_r^{-1} = (\\Sigma_r^{-1/2})^{\\top} \\Sigma_r^{-1/2}$ (因为 $\\Sigma_r^{-1/2}$ 是对称的)，我们可以将 $J_k$ 重写为：\n$$\nJ_k = r_k^{\\top} (\\Sigma_r^{-1/2})^{\\top} \\Sigma_r^{-1/2} r_k = (\\Sigma_r^{-1/2} r_k)^{\\top} (\\Sigma_r^{-1/2} r_k) = z_k^{\\top} z_k\n$$\n展开此表达式得到：\n$$\nJ_k = \\begin{pmatrix} z_{k,1} & z_{k,2} \\end{pmatrix} \\begin{pmatrix} z_{k,1} \\\\ z_{k,2} \\end{pmatrix} = z_{k,1}^2 + z_{k,2}^2\n$$\n根据卡方($\\chi^2$)分布的基本定义，$n$ 个独立标准正态随机变量的平方和是一个自由度为 $n$ 的卡方分布随机变量。在本例中，$n=2$。\n因此，统计量 $J_k$ 服从自由度为 $2$ 的卡方分布：\n$$\nJ_k \\sim \\chi_2^2\n$$\n这就完成了问题的第一部分。\n\n对于第二部分，我们必须找到阈值 $\\gamma$，使得虚警概率为 $\\alpha = 0.05$。条件是：\n$$\n\\mathbb{P}(J_k > \\gamma) = \\alpha = 0.05\n$$\n这意味着 $\\gamma$ 是这样一个值，使得 $\\chi_2^2$ 分布的概率密度函数（PDF）从 $\\gamma$ 到无穷大的积分面积为 $0.05$。这等价于找到使累积分布函数（CDF）为 $1 - \\alpha = 0.95$ 的值 $\\gamma$。\n设 $F_{\\chi_2^2}(x)$ 为 $\\chi_2^2$ 分布的累积分布函数。我们需要求解 $F_{\\chi_2^2}(\\gamma) = 0.95$。\n\n自由度为 2 的卡方分布是一个特例，等价于一个指数分布。$\\chi_n^2$ 分布的概率密度函数为 $f(x; n) = \\frac{1}{2^{n/2}\\Gamma(n/2)} x^{n/2 - 1} \\exp(-x/2)$，对于 $x \\ge 0$。当 $n=2$ 时：\n$$\nf(x; 2) = \\frac{1}{2^{2/2}\\Gamma(2/2)} x^{2/2 - 1} \\exp(-x/2) = \\frac{1}{2\\Gamma(1)} x^0 \\exp(-x/2) = \\frac{1}{2}\\exp(-x/2)\n$$\n这是率参数 $\\lambda = 1/2$ 的指数分布的概率密度函数。该分布的累积分布函数是 $F(x) = 1 - \\exp(-\\lambda x) = 1 - \\exp(-x/2)$。\n\n我们将累积分布函数设为等于 $1-\\alpha$：\n$$\nF_{\\chi_2^2}(\\gamma) = 1 - \\exp(-\\gamma/2) = 1 - 0.05 = 0.95\n$$\n求解 $\\gamma$：\n$$\n\\exp(-\\gamma/2) = 0.05\n$$\n对两边取自然对数：\n$$\n-\\frac{\\gamma}{2} = \\ln(0.05)\n$$\n$$\n\\gamma = -2 \\ln(0.05) = 2 \\ln\\left(\\frac{1}{0.05}\\right) = 2 \\ln(20)\n$$\n现在，我们计算数值：\n$$\n\\gamma \\approx 2 \\times 2.99573227... = 5.99146454...\n$$\n四舍五入到四位有效数字，我们得到：\n$$\n\\gamma \\approx 5.991\n$$\n这就是所要求的检测阈值。", "answer": "$$\n\\boxed{5.991}\n$$", "id": "2707656"}, {"introduction": "成功检测到故障后，容错控制系统的最终目标是调整控制策略以适应故障，即故障调节。本练习将带您进入基于优化的控制分配领域，这是一种处理执行器故障的先进方法 [@problem_id:2707720]。您将学习如何将控制分配问题构建为一个二次规划（QP）问题，并通过推导其 KKT (Karush-Kuhn-Tucker) 最优性条件，来为一个遭受部分失效和饱和限制的执行器系统计算出最优的控制指令。", "problem": "考虑一个单步模型预测控制 (MPC) 框架下的容错控制分配问题，该系统有三个执行器，并受到饱和与部分故障的影响。在当前采样时刻需要跟踪的广义控制力是向量 $v \\in \\mathbb{R}^{3}$。设执行器有效性（健康）矩阵为对角矩阵 $E \\in \\mathbb{R}^{3 \\times 3}$，其中 $E_{ii} \\in [0,1]$ 表示执行器 $i$ 的有效性分数（$E_{ii} = 0$ 表示完全故障）。分配器通过求解以下严格凸二次规划问题来确定指令执行器输入 $u \\in \\mathbb{R}^{3}$：\n$$\n\\min_{u \\in \\mathbb{R}^{3}} \\;\\; \\frac{1}{2}\\,(E u - v)^{\\top} W (E u - v) \\;+\\; \\frac{1}{2}\\, u^{\\top} R u\n$$\n约束条件为箱式约束\n$$\n\\ell \\le u \\le h,\n$$\n其中 $W \\in \\mathbb{R}^{3 \\times 3}$ 和 $R \\in \\mathbb{R}^{3 \\times 3}$ 是正定对角权重矩阵，不等式被逐分量地解释，其上下界分别为 $\\ell, h \\in \\mathbb{R}^{3}$。\n\n1) 从凸二次规划、拉格朗日函数和 Karush-Kuhn-Tucker (KKT) 条件的定义出发，推导上述分配器问题的充要 KKT 最优性条件。您的推导必须是完全符号化的，并应根据问题数据 $E$、$W$、$R$、$v$、$\\ell$ 和 $h$ 明确指出驻点性条件、原始可行性、对偶可行性和互补松弛性条件。\n\n2) 使用您得到的 KKT 条件，计算以下特定数值实例的最优分配 $u^{\\star}$：\n$$\nE = \\mathrm{diag}(1,\\;0.7,\\;0), \\quad W = \\mathrm{diag}(2,\\;1,\\;3), \\quad R = \\mathrm{diag}(0.5,\\;1,\\;0.2),\n$$\n$$\nv = \\begin{pmatrix} 1.0 \\\\ -0.5 \\\\ 0.2 \\end{pmatrix}, \\quad \\ell = \\begin{pmatrix} -0.2 \\\\ -0.3 \\\\ -0.1 \\end{pmatrix}, \\quad h = \\begin{pmatrix} 0.6 \\\\ 0.1 \\\\ 0.15 \\end{pmatrix}.\n$$\n报告最优分配向量 $u^{\\star}$，将每个分量四舍五入到四位有效数字。将最终答案表示为无单位的行向量。", "solution": "所述问题是控制工程中常见的标准、良定的凸优化问题。该问题具有科学依据、内容自洽，并拥有唯一的解。我们将进行推导和计算。\n\n问题在于求解执行器指令 $u \\in \\mathbb{R}^{3}$，该指令是以下严格凸二次规划 (QP) 问题的解：\n$$\n\\min_{u \\in \\mathbb{R}^{3}} \\;\\; J(u) = \\frac{1}{2}\\,(E u - v)^{\\top} W (E u - v) \\;+\\; \\frac{1}{2}\\, u^{\\top} R u\n$$\n约束条件为逐分量约束 $\\ell \\le u \\le h$。目标函数 $J(u)$ 是严格凸的，因为其海森矩阵 $\\nabla^2_u J(u) = E^{\\top}WE + R$ 是一个正定矩阵 $R$ 和一个半正定矩阵 $E^{\\top}WE$ 的和，这使得它们的和为正定矩阵。约束集是一个非空、闭合的凸多面体（一个箱体）。在此类集合上最小化一个严格凸函数可保证存在唯一的全局最小值。因此，Karush-Kuhn-Tucker (KKT) 条件是确定最优性的充要条件。\n\n**1) KKT 条件的推导**\n\n为了推导 KKT 条件，我们首先构建拉格朗日函数。箱式约束 $\\ell \\le u \\le h$ 等价于两组不等式约束：$u - h \\le 0$ 和 $\\ell - u \\le 0$。我们引入相应的拉格朗日乘子向量 $\\mu \\in \\mathbb{R}^{3}$ 和 $\\lambda \\in \\mathbb{R}^{3}$。拉格朗日函数 $\\mathcal{L}(u, \\lambda, \\mu)$ 为：\n$$\n\\mathcal{L}(u, \\lambda, \\mu) = J(u) + \\lambda^{\\top}(\\ell - u) + \\mu^{\\top}(u - h)\n$$\n最优性的 KKT 条件如下：\n\n**a) 驻点性条件 (Stationarity):** 拉格朗日函数关于原始变量 $u$ 的梯度必须为零。\n$$\n\\nabla_u \\mathcal{L}(u, \\lambda, \\mu) = \\nabla_u J(u) - \\lambda + \\mu = 0\n$$\n首先，我们计算目标函数 $J(u)$ 的梯度：\n$$\n\\nabla_u J(u) = \\nabla_u \\left( \\frac{1}{2}(u^{\\top}E^{\\top}WEu - 2v^{\\top}WEu + v^{\\top}Wv) + \\frac{1}{2}u^{\\top}Ru \\right) = E^{\\top}WEu - E^{\\top}Wv + Ru\n$$\n因此，驻点性条件为：\n$$\n(E^{\\top}WE + R)u - E^{\\top}Wv - \\lambda + \\mu = 0\n$$\n\n**b) 原始可行性 (Primal Feasibility):** 必须满足对 $u$ 的原始约束。\n$$\n\\ell_i \\le u_i \\le h_i, \\quad \\text{for } i=1, 2, 3\n$$\n\n**c) 对偶可行性 (Dual Feasibility):** 拉格朗日乘子必须为非负。\n$$\n\\lambda_i \\ge 0, \\quad \\mu_i \\ge 0, \\quad \\text{for } i=1, 2, 3\n$$\n\n**d) 互补松弛性 (Complementary Slackness):** 每个乘子与其对应约束函数的乘积必须为零。\n$$\n\\lambda_i (\\ell_i - u_i) = 0, \\quad \\mu_i (u_i - h_i) = 0, \\quad \\text{for } i=1, 2, 3\n$$\n这意味着乘子仅在相应约束有效（即，等式成立）时才能为正。\n\n由于矩阵 $E$、$W$ 和 $R$ 都是对角矩阵，目标函数和约束对每个分量 $u_i$ 都是解耦的。总目标函数是各分量目标函数之和，$J(u) = \\sum_{i=1}^3 J_i(u_i)$，其中\n$$\nJ_i(u_i) = \\frac{1}{2} W_{ii}(E_{ii} u_i - v_i)^2 + \\frac{1}{2} R_{ii} u_i^2\n$$\n并且我们对每个 $i \\in \\{1, 2, 3\\}$ 独立地求解 $\\min J_i(u_i)$，约束条件为 $\\ell_i \\le u_i \\le h_i$。 KKT 条件可以为每个分量 $i$ 写出：\n\\begin{align*}\n\\text{驻点性条件: } & (E_{ii}^2 W_{ii} + R_{ii}) u_i - E_{ii} W_{ii} v_i - \\lambda_i + \\mu_i = 0 \\\\\n\\text{原始可行性: } & \\ell_i \\le u_i \\le h_i \\\\\n\\text{对偶可行性: } & \\lambda_i \\ge 0, \\; \\mu_i \\ge 0 \\\\\n\\text{互补松弛性: } & \\lambda_i(\\ell_i - u_i) = 0, \\; \\mu_i(u_i - h_i) = 0\n\\end{align*}\n\n**2) 最优分配的计算**\n\n我们将逐分量的 KKT 条件应用于给定的数值实例。对于每个分量 $i$，最优解 $u_i^{\\star}$ 的求解方法是：首先计算 $J_i(u_i)$ 的无约束最小值，然后将其投影到可行区间 $[\\ell_i, h_i]$ 上。无约束最小值（记为 $u_i^{\\text{unc}}$）通过设置 $\\lambda_i = 0$ 和 $\\mu_i = 0$ 从驻点性条件得出：\n$$\nu_i^{\\text{unc}} = \\frac{E_{ii} W_{ii} v_i}{E_{ii}^2 W_{ii} + R_{ii}}\n$$\n最优解则为 $u_i^{\\star} = \\max(\\ell_i, \\min(h_i, u_i^{\\text{unc}}))$。\n\n给定的数据是：\n$E = \\mathrm{diag}(1, 0.7, 0)$, $W = \\mathrm{diag}(2, 1, 3)$, $R = \\mathrm{diag}(0.5, 1, 0.2)$\n$v = \\begin{pmatrix} 1.0 \\\\ -0.5 \\\\ 0.2 \\end{pmatrix}$, $\\ell = \\begin{pmatrix} -0.2 \\\\ -0.3 \\\\ -0.1 \\end{pmatrix}$, $h = \\begin{pmatrix} 0.6 \\\\ 0.1 \\\\ 0.15 \\end{pmatrix}$。\n\n**分量 $i=1$:**\n$E_{11}=1$, $W_{11}=2$, $R_{11}=0.5$, $v_1=1.0$, $\\ell_1=-0.2$, $h_1=0.6$。\n无约束解为：\n$$\nu_1^{\\text{unc}} = \\frac{1 \\cdot 2 \\cdot 1.0}{1^2 \\cdot 2 + 0.5} = \\frac{2.0}{2.5} = 0.8\n$$\n可行区间为 $[-0.2, 0.6]$。由于 $u_1^{\\text{unc}} = 0.8 > h_1 = 0.6$，解在上界处饱和。\n$$\nu_1^{\\star} = h_1 = 0.6\n$$\n\n**分量 $i=2$:**\n$E_{22}=0.7$, $W_{22}=1$, $R_{22}=1$, $v_2=-0.5$, $\\ell_2=-0.3$, $h_2=0.1$。\n无约束解为：\n$$\nu_2^{\\text{unc}} = \\frac{0.7 \\cdot 1 \\cdot (-0.5)}{0.7^2 \\cdot 1 + 1} = \\frac{-0.35}{0.49 + 1} = \\frac{-0.35}{1.49} \\approx -0.234899...\n$$\n可行区间为 $[-0.3, 0.1]$。由于 $\\ell_2 = -0.3 < u_2^{\\text{unc}} < h_2 = 0.1$，无约束解是可行的。\n$$\nu_2^{\\star} = \\frac{-0.35}{1.49}\n$$\n\n**分量 $i=3$:**\n$E_{33}=0$, $W_{33}=3$, $R_{33}=0.2$, $v_3=0.2$, $\\ell_3=-0.1$, $h_3=0.15$。\n该执行器已完全失效。无约束解为：\n$$\nu_3^{\\text{unc}} = \\frac{0 \\cdot 3 \\cdot 0.2}{0^2 \\cdot 3 + 0.2} = \\frac{0}{0.2} = 0\n$$\n另外，注意到成本分量 $J_3(u_3)$ 为 $\\frac{1}{2}W_{33}(0 \\cdot u_3 - v_3)^2 + \\frac{1}{2}R_{33}u_3^2 = \\frac{1}{2}W_{33}v_3^2 + \\frac{1}{2}R_{33}u_3^2$。为使该成本最小化，我们必须最小化 $\\frac{1}{2}R_{33}u_3^2$（因为第一项是常数），对于 $R_{33} > 0$ 而言，这意味着使 $u_3$ 尽可能接近 $0$。可行区间为 $[-0.1, 0.15]$，其中包含 $0$。\n因此，最优解为：\n$$\nu_3^{\\star} = 0\n$$\n\n最终的最优分配向量 $u^{\\star} = (u_1^{\\star}, u_2^{\\star}, u_3^{\\star})^{\\top}$ 必须报告，并且每个分量需四舍五入到四位有效数字。\n$u_1^{\\star} = 0.6$。四舍五入到四位有效数字为 $0.6000$。\n$u_2^{\\star} = -0.35/1.49 \\approx -0.234899...$。四舍五入到四位有效数字为 $-0.2349$。\n$u_3^{\\star} = 0$。为与其他分量保持一致，表示为 $0.0000$。\n\n最终的最优分配为 $u^{\\star} = (0.6000, -0.2349, 0.0000)^{\\top}$。", "answer": "$$\n\\boxed{\\begin{pmatrix} 0.6000 & -0.2349 & 0.0000 \\end{pmatrix}}\n$$", "id": "2707720"}]}