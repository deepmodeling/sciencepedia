{"hands_on_practices": [{"introduction": "推导一个能保证稳定性的自适应律是模型参考自adaptive控制 (MRAC) 的核心。本练习将指导您使用强大的李雅普诺夫直接法，为一个简单的一阶连续系统设计参数更新法则。这个过程不仅能确保跟踪误差 $e(t)$ 收敛于零，还为您处理更复杂系统的设计奠定了坚实的基础 [@problem_id:1591800]。", "problem": "考虑一个简单化学反应器的温度 $y(t)$ 控制问题。该反应器的热力学动态由以下一阶线性微分方程描述：\n$$ \\dot{y}(t) = -a y(t) + b u(t) $$\n其中 $u(t)$ 是由加热器提供的热量速率（控制输入），$b$ 是一个已知的正常数，代表加热器的效率，$a$ 是一个未知但恒定的正参数，代表向环境的散热速率。\n\n目标是设计一个控制器，使反应器温度 $y(t)$ 渐近跟踪一个稳定参考模型的温度曲线 $y_m(t)$。该参考模型由下式给出：\n$$ \\dot{y}_m(t) = -a_m y_m(t) + b_m r(t) $$\n其中 $a_m$ 和 $b_m$ 是已知的正常数，$r(t)$ 是一个有界的参考指令信号。\n\n采用一种模型参考自适应控制 (MRAC) 策略。控制输入 $u(t)$ 的结构如下：\n$$ u(t) = \\frac{\\hat{a}(t) - a_m}{b} y(t) + \\frac{b_m}{b} r(t) $$\n此处，$\\hat{a}(t)$ 是未知参数 $a$ 的实时估计值。该控制策略的关键是找到一个*自适应律*，即一个关于 $\\dot{\\hat{a}}(t)$ 的微分方程，以保证系统的稳定性，并确保跟踪误差 $e(t) = y(t) - y_m(t)$ 收敛到零。\n\n你的任务是使用基于李雅普诺夫的设计过程来推导此自适应律。首先，推导描述跟踪误差 $e(t)$ 的微分方程。然后，使用跟踪误差 $e(t)$ 和参数估计误差 $\\tilde{a}(t) = \\hat{a}(t) - a$ 构建一个二次李雅普诺夫候选函数。最后，使用此李雅普诺夫函数推导能确保稳定性的 $\\dot{\\hat{a}}(t)$ 的更新法则。\n\n将你的最终答案表示为关于 $\\dot{\\hat{a}}(t)$ 的表达式。该表达式应使用跟踪误差 $e(t)$、对象输出 $y(t)$ 和一个正常数 $\\gamma$ 来表示，其中 $\\gamma$ 作为自适应增益，并应在你的李雅普诺夫函数中引入。", "solution": "对象为 $\\dot{y}(t)=-a y(t)+b u(t)$，参考模型为 $\\dot{y}_{m}(t)=-a_{m} y_{m}(t)+b_{m} r(t)$，其中 $a>0$, $b>0$, $a_{m}>0$, $b_{m}>0$。控制律为\n$$\nu(t)=\\frac{\\hat{a}(t)-a_{m}}{b}y(t)+\\frac{b_{m}}{b}r(t).\n$$\n将 $u(t)$ 代入对象方程可得\n$$\n\\dot{y}(t)=-a y(t)+b\\left(\\frac{\\hat{a}(t)-a_{m}}{b}y(t)+\\frac{b_{m}}{b}r(t)\\right)=-a y(t)+(\\hat{a}(t)-a_{m})y(t)+b_{m}r(t).\n$$\n因此\n$$\n\\dot{y}(t)=-(a+a_{m}-\\hat{a}(t))y(t)+b_{m}r(t).\n$$\n定义跟踪误差 $e(t)=y(t)-y_{m}(t)$。其导数为\n$$\n\\dot{e}(t)=\\dot{y}(t)-\\dot{y}_{m}(t)=\\bigl(-(a+a_{m}-\\hat{a}(t))y(t)+b_{m}r(t)\\bigr)-\\bigl(-a_{m}y_{m}(t)+b_{m}r(t)\\bigr).\n$$\n化简可得\n$$\n\\dot{e}(t)=-(a+a_{m}-\\hat{a}(t))y(t)+a_{m}y_{m}(t).\n$$\n使用 $y_{m}(t)=y(t)-e(t)$，我们得到\n$$\n\\dot{e}(t)=-(a+a_{m}-\\hat{a}(t))y(t)+a_{m}(y(t)-e(t))=-a y(t)+\\hat{a}(t)y(t)-a_{m}e(t).\n$$\n引入参数估计误差 $\\tilde{a}(t)=\\hat{a}(t)-a$。则误差动态变为\n$$\n\\dot{e}(t)=-a_{m}e(t)+\\tilde{a}(t)\\,y(t).\n$$\n\n选择李雅普诺夫候选函数\n$$\nV(t)=\\frac{1}{2}e^{2}(t)+\\frac{1}{2\\gamma}\\tilde{a}^{2}(t),\n$$\n其中 $\\gamma>0$ 是自适应增益。由于 $a$ 是常数，因此 $\\dot{\\tilde{a}}(t)=\\dot{\\hat{a}}(t)$。$V$ 沿轨迹的时间导数为\n$$\n\\dot{V}(t)=e(t)\\dot{e}(t)+\\frac{1}{\\gamma}\\tilde{a}(t)\\dot{\\tilde{a}}(t)=e(t)\\bigl(-a_{m}e(t)+\\tilde{a}(t)\\,y(t)\\bigr)+\\frac{1}{\\gamma}\\tilde{a}(t)\\dot{\\hat{a}}(t).\n$$\n因此\n$$\n\\dot{V}(t)=-a_{m}e^{2}(t)+e(t)\\tilde{a}(t)\\,y(t)+\\frac{1}{\\gamma}\\tilde{a}(t)\\dot{\\hat{a}}(t).\n$$\n为确保 $\\dot{V}(t)\\leq 0$，选择 $\\dot{\\hat{a}}(t)$ 以消除交叉项 $e(t)\\tilde{a}(t)\\,y(t)$。若选择\n$$\n\\dot{\\hat{a}}(t)=-\\gamma\\,e(t)\\,y(t)\n$$\n可得\n$$\n\\dot{V}(t)=-a_{m}e^{2}(t)\\leq 0.\n$$\n因此 $V(t)$ 是非增的，$e(t)$ 和 $\\tilde{a}(t)$ 是有界的，并且根据标准的李雅普诺夫论证（例如，使用有界信号的LaSalle或Barbalat引理），跟踪误差 $e(t)$ 渐近收敛到零。所要求的自适应律是梯度更新\n$$\n\\dot{\\hat{a}}(t)=-\\gamma\\,e(t)\\,y(t).\n$$", "answer": "$$\\boxed{-\\gamma\\,e(t)\\,y(t)}$$", "id": "1591800"}, {"introduction": "现实世界中的控制器大多以数字形式实现，因此将连续时间的设计思想转化为离散时间算法至关重要。本练习将带您进入离散时间领域，为一个一阶离散系统设计直接 MRAC 控制器。您将运用基于梯度下降的方法来更新控制器参数，这与连续时间中的方法形成了有趣的对比和补充 [@problem_id:1591827]。", "problem": "下一代通信卫星中的一个关键部件需要精确的热调节。其温度动态可以简化并由以下一阶离散时间系统建模：\n$$y_p(k+1) = a_p y_p(k) + b_p u(k)$$\n其中，$k$ 是离散时间索引，$y_p(k)$ 代表该部件相对于其标称工作点的温度偏差，$u(k)$ 是发送给热电冷却器的控制信号。系统参数 $a_p$ 和 $b_p$ 未知但为常数，分别代表热惯性和冷却器效率。根据物理原理可知 $b_p > 0$。\n\n为确保稳定且可预测的热行为，要求该部件的温度响应遵循一个指定的参考模型：\n$$y_m(k+1) = a_m y_m(k) + b_m r(k)$$\n在此模型中，$y_m(k)$ 是期望的温度偏差，$r(k)$ 是外部指令信号，$a_m$ 和 $b_m$ 是定义理想响应的已知固定参数，其中 $|a_m| < 1$ 以保证稳定性。\n\n为实现此目标，采用了一种直接模型参考自适应控制 (MRAC) 方案。其控制律形式如下：\n$$u(k) = \\theta_1(k) y_p(k) + \\theta_2(k) r(k)$$\n其中 $\\theta_1(k)$ 和 $\\theta_2(k)$ 是自适应增益。这些增益在每个时间步长根据梯度下降法进行更新，旨在最小化下一时间步长的跟踪误差平方，该误差由成本函数 $J = \\frac{1}{2}e(k+1)^2$ 定义，其中跟踪误差为 $e(k+1) = y_p(k+1) - y_m(k+1)$。更新法则由下式给出：\n$$\\theta_i(k+1) = \\theta_i(k) - \\gamma_0 \\frac{\\partial J}{\\partial \\theta_i(k)} \\quad \\text{for } i \\in \\{1, 2\\}$$\n其中 $\\gamma_0$ 是一个为正的基础自适应率。对于最终表达式，推导过程中出现的未知物理参数 $b_p$ 必须被吸收到一个新的、记为 $\\gamma$ 的单一正常数自适应增益中。\n\n推导自适应增益 $\\theta_1(k+1)$ 和 $\\theta_2(k+1)$ 的显式更新表达式。你的最终答案应以一个 $1 \\times 2$ 行矩阵的形式呈现，其中第一列包含 $\\theta_1(k+1)$ 的完整表达式，第二列包含 $\\theta_2(k+1)$ 的完整表达式。", "solution": "目标是找到控制器参数 $\\theta_1(k)$ 和 $\\theta_2(k)$ 的自适应律。该自适应基于对成本函数 $J = \\frac{1}{2}e(k+1)^2$ 的梯度下降最小化，其中 $e(k+1) = y_p(k+1) - y_m(k+1)$ 是跟踪误差。\n\n更新法则如下所示：\n$$\\theta_i(k+1) = \\theta_i(k) - \\gamma_0 \\frac{\\partial J}{\\partial \\theta_i(k)}$$\n\n首先，我们应用链式法则来计算成本函数 $J$ 对每个参数 $\\theta_i(k)$ 的偏导数：\n$$\\frac{\\partial J}{\\partial \\theta_i(k)} = \\frac{\\partial}{\\partial \\theta_i(k)} \\left( \\frac{1}{2} e(k+1)^2 \\right) = e(k+1) \\frac{\\partial e(k+1)}{\\partial \\theta_i(k)}$$\n\n接下来，我们需要求出灵敏度导数，它描述了误差 $e(k+1)$ 相对于前一时间步长的控制器参数 $\\theta_i(k)$ 如何变化。\n误差定义为 $e(k+1) = y_p(k+1) - y_m(k+1)$。参考模型输出 $y_m(k+1)$ 由 $y_m(k+1) = a_m y_m(k) + b_m r(k)$ 生成，并且不依赖于控制器参数 $\\theta_1(k)$ 和 $\\theta_2(k)$。因此，误差的导数就是对象输出的导数：\n$$\\frac{\\partial e(k+1)}{\\partial \\theta_i(k)} = \\frac{\\partial}{\\partial \\theta_i(k)} \\left( y_p(k+1) - y_m(k+1) \\right) = \\frac{\\partial y_p(k+1)}{\\partial \\theta_i(k)}$$\n\n现在，我们计算对象输出 $y_p(k+1)$ 对每个参数的导数。对象动态由 $y_p(k+1) = a_p y_p(k) + b_p u(k)$ 给出。我们将控制律 $u(k) = \\theta_1(k) y_p(k) + \\theta_2(k) r(k)$ 代入对象方程：\n$$y_p(k+1) = a_p y_p(k) + b_p \\left( \\theta_1(k) y_p(k) + \\theta_2(k) r(k) \\right)$$\n\n我们现在可以计算关于 $\\theta_1(k)$ 和 $\\theta_2(k)$ 的偏导数。注意，在此微分中，$y_p(k)$ 和 $r(k)$ 被视为常数，因为它们是来自前一时间步长的值。\n对于 $\\theta_1(k)$：\n$$\\frac{\\partial y_p(k+1)}{\\partial \\theta_1(k)} = \\frac{\\partial}{\\partial \\theta_1(k)} \\left[ a_p y_p(k) + b_p \\theta_1(k) y_p(k) + b_p \\theta_2(k) r(k) \\right] = b_p y_p(k)$$\n对于 $\\theta_2(k)$：\n$$\\frac{\\partial y_p(k+1)}{\\partial \\theta_2(k)} = \\frac{\\partial}{\\partial \\theta_2(k)} \\left[ a_p y_p(k) + b_p \\theta_1(k) y_p(k) + b_p \\theta_2(k) r(k) \\right] = b_p r(k)$$\n\n现在我们将这些灵敏度导数代回到 $\\frac{\\partial J}{\\partial \\theta_i(k)}$ 的表达式中：\n$$\\frac{\\partial J}{\\partial \\theta_1(k)} = e(k+1) \\frac{\\partial y_p(k+1)}{\\partial \\theta_1(k)} = e(k+1) b_p y_p(k)$$\n$$\\frac{\\partial J}{\\partial \\theta_2(k)} = e(k+1) \\frac{\\partial y_p(k+1)}{\\partial \\theta_2(k)} = e(k+1) b_p r(k)$$\n\n最后，我们将这些梯度代入给定的更新法则 $\\theta_i(k+1) = \\theta_i(k) - \\gamma_0 \\frac{\\partial J}{\\partial \\theta_i(k)}$：\n对于 $\\theta_1(k+1)$:\n$$\\theta_1(k+1) = \\theta_1(k) - \\gamma_0 \\left( e(k+1) b_p y_p(k) \\right)$$\n对于 $\\theta_2(k+1)$:\n$$\\theta_2(k+1) = \\theta_2(k) - \\gamma_0 \\left( e(k+1) b_p r(k) \\right)$$\n\n问题指出，未知常数 $b_p$ 必须被吸收到一个单一的自适应增益 $\\gamma$ 中。我们定义一个新的增益 $\\gamma = \\gamma_0 b_p$。由于 $\\gamma_0 > 0$ 且已知 $b_p > 0$，合并后的自适应增益 $\\gamma$ 也为正。\n\n最终的自适应律为：\n$$\\theta_1(k+1) = \\theta_1(k) - \\gamma e(k+1) y_p(k)$$\n$$\\theta_2(k+1) = \\theta_2(k) - \\gamma e(k+1) r(k)$$\n\n这些表达式为自适应增益提供了显式的更新法则。误差 $e(k+1)$ 在每个步骤中使用测量的对象输出 $y_p(k+1)$ 和计算的模型输出 $y_m(k+1)$ 来计算。然后使用此误差以及来自前一步骤的信号值 $y_p(k)$ 和 $r(k)$ 来更新增益。\n\n答案应以一个 $1 \\times 2$ 的行矩阵形式呈现。第一个元素是 $\\theta_1(k+1)$ 的表达式，第二个元素是 $\\theta_2(k+1)$ 的表达式。", "answer": "$$\\boxed{\\begin{pmatrix} \\theta_1(k) - \\gamma e(k+1) y_p(k) & \\theta_2(k) - \\gamma e(k+1) r(k) \\end{pmatrix}}$$", "id": "1591827"}, {"introduction": "许多 MRAC 方案的稳定性证明依赖于一个关键的系统属性——严格正实性 (Strictly Positive Real, SPR)。本练习将视角从控制器设计转向系统分析，要求您编写程序来验证 SPR 条件。您将通过求解线性矩阵不等式 (Linear Matrix Inequalities, LMI) 这一现代计算工具，来判断一个系统是否满足基于卡尔曼-雅库波维奇-波波夫 (Kalman-Yakubovich-Popov) 引理的 SPR 条件，从而将抽象的理论与可执行的算法联系起来 [@problem_id:2725781]。", "problem": "考虑由矩阵 $A \\in \\mathbb{R}^{2 \\times 2}$、$B \\in \\mathbb{R}^{2 \\times 1}$ 和 $C \\in \\mathbb{R}^{1 \\times 2}$ 定义的单输入单输出线性时不变状态空间系统，其输入为 $u \\in \\mathbb{R}$，状态为 $x \\in \\mathbb{R}^{2}$，输出为 $y \\in \\mathbb{R}$。其传递函数为 $G(s) = C (s I - A)^{-1} B$。一个有理函数 $G(s)$ 是严格正实（SPR）的，如果它是实有理的，在 $\\operatorname{Re}(s) \\ge 0$ 内没有极点，并且对于所有 $\\omega \\in \\mathbb{R}$ 满足 $\\operatorname{Re}[G(j \\omega)] > 0$。在模型参考自适应控制（MRAC）中，一种标准方法是通过与 Kalman-Yakubovich-Popov 引理一致的 Lyapunov 不等式来验证严格正实性，即寻找一个对称正定矩阵 $P \\in \\mathbb{R}^{2 \\times 2}$ 满足以下约束条件：\n- $P = P^\\top$，\n- $P B = C^\\top$，\n- $A^\\top P + P A \\prec 0$（严格负定），\n- $C B > 0$。\n\n当存在这样的矩阵 $P$ 时，函数 $V(x) = \\tfrac{1}{2} x^\\top P x$ 是一个存储函数，它展示了具有严格裕度的无源性，这意味着 $G(s)$ 是严格正实的。这种存储函数的解释在自适应控制的 Lyapunov 分析中至关重要。\n\n任务：编写一个程序，对于每个给定的三元组 $(A,B,C)$，判断是否存在一个对称正定矩阵 $P$ 满足 $P B = C^\\top$、$A^\\top P + P A \\prec 0$ 和 $C B > 0$。你的程序必须为每个测试用例返回一个布尔值：如果存在这样的 $P$，则返回 $\\,\\text{True}\\,$，否则返回 $\\,\\text{False}\\,$。搜索过程应以数学上合理且数值上鲁棒的方式执行，并且不得依赖任何外部用户输入。\n\n你的程序必须为以下参数值测试套件实现决策逻辑（所有条目均为实数且维度一致）：\n- 测试用例 $1$（正常路径，Hurwitz 矩阵 $A$ 和可行约束）：\n  - $A = \\begin{bmatrix} -1 & 0 \\\\ 0 & -1 \\end{bmatrix}$，\n  - $B = \\begin{bmatrix} 1 \\\\ 2 \\end{bmatrix}$，\n  - $C = \\begin{bmatrix} 3 & 3.5 \\end{bmatrix}$。\n- 测试用例 $2$（违反 $C B > 0$）：\n  - $A = \\begin{bmatrix} -1 & 0 \\\\ 0 & -1 \\end{bmatrix}$，\n  - $B = \\begin{bmatrix} 1 \\\\ 2 \\end{bmatrix}$，\n  - $C = \\begin{bmatrix} -3 & -3.5 \\end{bmatrix}$。\n- 测试用例 $3$（不稳定的矩阵 $A$）：\n  - $A = \\begin{bmatrix} 0.2 & 0 \\\\ 0 & -1 \\end{bmatrix}$，\n  - $B = \\begin{bmatrix} 1 \\\\ 2 \\end{bmatrix}$，\n  - $C = \\begin{bmatrix} 3 & 3.5 \\end{bmatrix}$。\n- 测试用例 $4$（具有零特征值的临界稳定矩阵 $A$）：\n  - $A = \\begin{bmatrix} 0 & 0 \\\\ 0 & -1 \\end{bmatrix}$，\n  - $B = \\begin{bmatrix} 1 \\\\ 2 \\end{bmatrix}$，\n  - $C = \\begin{bmatrix} 3 & 3.5 \\end{bmatrix}$。\n- 测试用例 $5$（具有不同参数的正常路径）：\n  - $A = \\begin{bmatrix} -2 & 0 \\\\ 0 & -2 \\end{bmatrix}$，\n  - $B = \\begin{bmatrix} 2 \\\\ -1 \\end{bmatrix}$，\n  - $C = \\begin{bmatrix} 1.8 & -0.4 \\end{bmatrix}$。\n\n你必须在程序逻辑中强制执行的重要细节和约束：\n- $P$ 必须是对称正定的。\n- 用于检查严格不等式的候选矩阵 $P$ 必须精确满足等式 $P B = C^\\top$。\n- 严格矩阵不等式 $A^\\top P + P A \\prec 0$ 必须通过验证其特征值均为严格负数来确认。\n- 标量不等式 $C B > 0$ 必须直接验证。\n- 用于判断定性的所有数值阈值必须有明确的理由并被一致地实现。\n\n最终输出格式：\n- 你的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表（例如 $[result_1,result_2,\\dots]$），其中每个 $result_i$ 为 $\\text{True}$ 或 $\\text{False}$。\n- 此问题不涉及角度或物理单位。\n- 你的程序必须是完全确定性和自包含的，无需用户输入，并且必须计算并输出上述五个测试用例的结果，结果需按给定顺序排列在单行列表中。", "solution": "所述问题是有效的。它在科学上基于控制理论中的 Lyapunov 稳定性理论和 Kalman-Yakubovich-Popov (KYP) 引理的原理，该引理为系统传递函数是严格正实（SPR）提供了条件。该问题是适定的、客观的，并包含得出确定性解所需的所有必要信息。\n\n任务是对于一个由矩阵 $(A, B, C)$ 定义的给定单输入单输出（SISO）线性时不变（LTI）系统，判断是否存在一个对称正定矩阵 $P$ 满足一组条件。这些条件是：\n1.  $P = P^\\top$（对称性）\n2.  $P \\succ 0$（正定性）\n3.  $C B > 0$\n4.  $P B = C^\\top$\n5.  $A^\\top P + P A \\prec 0$（负定性）\n\n让我们系统地分析这些条件。\n\n首先，对于存在一个满足 $A^\\top P + P A \\prec 0$ 的正定矩阵 $P$，一个关键的必要条件是矩阵 $A$ 必须是 Hurwitz 矩阵。如果一个矩阵的所有特征值的实部都严格为负，则该矩阵是 Hurwitz 矩阵。让我们用反证法来证明这一点。假设存在矩阵 $A$ 的一个特征向量 $v$，其对应的特征值为 $\\lambda$，满足 $\\operatorname{Re}(\\lambda) \\ge 0$。那么 $Av = \\lambda v$。如果 $A^\\top P + P A$ 是负定的，那么必然有 $v^* (A^\\top P + P A) v < 0$。计算这个表达式可得：\n$$v^* (A^\\top P + P A) v = (Av)^* P v + v^* P (Av) = (\\lambda v)^* P v + v^* P (\\lambda v) = \\bar{\\lambda} v^* P v + \\lambda v^* P v$$\n$$= (\\bar{\\lambda} + \\lambda) v^* P v = 2 \\operatorname{Re}(\\lambda) v^* P v$$\n由于 $P$ 被要求是正定的，所以 $v^* P v > 0$。根据我们的假设 $\\operatorname{Re}(\\lambda) \\ge 0$，整个表达式 $2 \\operatorname{Re}(\\lambda) v^* P v$ 必须大于或等于 $0$。这与 $v^* (A^\\top P + P A) v < 0$ 的要求相矛盾。因此，矩阵 $A$ 必须是 Hurwitz 矩阵。这提供了一个简单的初始检查。\n\n其次，标量条件 $C B > 0$ 是一个直接而简单的计算。如果不满足此条件，则不存在解。\n\n如果这两个必要条件都满足，我们继续寻找是否存在一个满足其余约束的矩阵 $P$。矩阵 $P$ 是一个对称的 $2 \\times 2$ 矩阵，因此可以写成：\n$$P = \\begin{bmatrix} p_{11} & p_{12} \\\\ p_{12} & p_{22} \\end{bmatrix}$$\n这个矩阵有三个未知元素：$p_{11}$、$p_{12}$ 和 $p_{22}$。约束 $P B = C^\\top$ 为这三个未知数提供了两个线性方程组成的方程组：\n$$\\begin{bmatrix} p_{11} & p_{12} \\\\ p_{12} & p_{22} \\end{bmatrix} \\begin{bmatrix} b_1 \\\\ b_2 \\end{bmatrix} = \\begin{bmatrix} c_1 \\\\ c_2 \\end{bmatrix}$$\n展开为：\n$$p_{11} b_1 + p_{12} b_2 = c_1$$\n$$p_{12} b_1 + p_{22} b_2 = c_2$$\n在任何有意义的控制问题（或给定的测试用例）中，$B$ 都不是零向量，因此该方程组是欠定的。这意味着如果存在解，则存在一个单参数解族。我们可以用一个自由参数（我们称之为 $\\alpha$）来表示 $P$ 的元素。例如，如果 $b_1 \\neq 0$ 且 $b_2 \\neq 0$，我们可以设 $p_{12} = \\alpha$ 并求解 $p_{11}$ 和 $p_{22}$：\n$$p_{11}(\\alpha) = \\frac{c_1 - \\alpha b_2}{b_1}$$\n$$p_{22}(\\alpha) = \\frac{c_2 - \\alpha b_1}{b_2}$$\n如果 $B$ 的某个分量为零，我们会选择一个不同的自由参数，但原理保持不变。矩阵 $P(\\alpha)$ 现在是 $\\alpha$ 的线性函数。\n\n问题现在简化为寻找是否存在一个实数 $\\alpha$，使得 $P(\\alpha)$ 满足两个矩阵不等式：\n1.  $P(\\alpha) \\succ 0$\n2.  $Q(\\alpha) = A^\\top P(\\alpha) + P(\\alpha) A \\prec 0$\n\n对于一个 $2 \\times 2$ 的对称矩阵 $M = \\begin{bmatrix} m_{11} & m_{12} \\\\ m_{12} & m_{22} \\end{bmatrix}$，正定性（$M \\succ 0$）等价于 $m_{11} > 0$ 和 $\\det(M) > 0$。负定性（$M \\prec 0$）等价于 $m_{11} < 0$ 和 $\\det(M) > 0$。\n\n将此应用于 $P(\\alpha)$：\n-   $p_{11}(\\alpha) > 0$：这是一个关于 $\\alpha$ 的线性不等式。\n-   $\\det(P(\\alpha)) > 0$：如详细推导所示，代入 $p_{ij}(\\alpha)$ 的表达式得出 $\\det(P(\\alpha)) = \\frac{c_1c_2 - \\alpha(CB)}{b_1b_2}$。这也是一个关于 $\\alpha$ 的线性不等式。\n这两个线性不等式为 $\\alpha$ 定义了一个开区间 $(\\alpha_{\\min,P}, \\alpha_{\\max,P})$。\n\n将此应用于 $Q(\\alpha)$：\n$Q(\\alpha)$ 的元素是 $\\alpha$ 的线性函数，因为 $P(\\alpha)$ 是 $\\alpha$ 的线性函数。设 $Q(\\alpha) = \\begin{bmatrix} q_{11}(\\alpha) & q_{12}(\\alpha) \\\\ q_{12}(\\alpha) & q_{22}(\\alpha) \\end{bmatrix}$。\n-   $q_{11}(\\alpha) < 0$：这是一个关于 $\\alpha$ 的线性不等式。\n-   $\\det(Q(\\alpha)) > 0$：由于 $q_{ij}(\\alpha)$ 是线性的，$\\det(Q(\\alpha)) = q_{11}(\\alpha)q_{22}(\\alpha) - q_{12}(\\alpha)^2$ 是一个关于 $\\alpha$ 的二次函数，记为 $f(\\alpha) = k_2\\alpha^2 + k_1\\alpha + k_0$。我们需要 $f(\\alpha) > 0$。\n\n最后一步是确定是否存在一个 $\\alpha$ 同时满足所有这些不等式。首先，我们求出所有线性不等式的交集，得到一个开区间 $(\\alpha_{\\min}, \\alpha_{\\max})$。如果这个区间是空的（即 $\\alpha_{\\min} \\ge \\alpha_{\\max}$），则不存在解。否则，我们必须检查这个区间是否与二次不等式 $f(\\alpha) > 0$ 的解集有非空交集。这是一个对二次多项式 $f(\\alpha)$ 的根和符号的标准分析。\n\n总体算法如下：\n1.  验证 $A$ 是 Hurwitz 矩阵。如果不是，则答案为 False。\n2.  验证 $C B > 0$。如果不是，则答案为 False。\n3.  基于约束 $P B = C^\\top$，用单个变量 $\\alpha$ 来参数化 $P$。\n4.  从 $P(\\alpha) \\succ 0$ 和 $Q(\\alpha) \\prec 0$ 的条件（即 $q_{11}(\\alpha) < 0$）中推导出关于 $\\alpha$ 的线性不等式集。求出它们的交集，即区间 $(\\alpha_{\\min}, \\alpha_{\\max})$。如果此区间为空，则返回 False。\n5.  推导出二次不等式 $\\det(Q(\\alpha)) > 0$。\n6.  解析地确定二次不等式的解集是否与区间 $(\\alpha_{\\min}, \\alpha_{\\max})$ 有非空交集。如果有，则存在有效的 $P$，返回 True。否则，返回 False。所有比较都必须使用数值容差。", "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the problem for the given test cases.\n    \"\"\"\n    test_cases = [\n        # Test case 1\n        {'A': np.array([[-1., 0.], [0., -1.]]),\n         'B': np.array([[1.], [2.]]),\n         'C': np.array([[3., 3.5]])},\n        # Test case 2\n        {'A': np.array([[-1., 0.], [0., -1.]]),\n         'B': np.array([[1.], [2.]]),\n         'C': np.array([[-3., -3.5]])},\n        # Test case 3\n        {'A': np.array([[0.2, 0.], [0., -1.]]),\n         'B': np.array([[1.], [2.]]),\n         'C': np.array([[3., 3.5]])},\n        # Test case 4\n        {'A': np.array([[0., 0.], [0., -1.]]),\n         'B': np.array([[1.], [2.]]),\n         'C': np.array([[3., 3.5]])},\n        # Test case 5\n        {'A': np.array([[-2., 0.], [0., -2.]]),\n         'B': np.array([[2.], [-1.]]),\n         'C': np.array([[1.8, -0.4]])}\n    ]\n\n    results = [_check_spr_conditions(**case) for case in test_cases]\n    print(f\"[{','.join(map(str, results))}]\")\n\ndef _check_spr_conditions(A, B, C):\n    \"\"\"\n    Checks if a symmetric positive definite P exists for the given (A, B, C).\n    \"\"\"\n    TOL = 1e-9\n\n    # Condition 1: A must be Hurwitz (all eigenvalues have negative real parts)\n    eigs_A = np.linalg.eigvals(A)\n    if np.max(np.real(eigs_A)) >= -TOL:\n        return False\n\n    # Condition 2: CB > 0\n    if (C @ B)[0, 0] <= TOL:\n        return False\n\n    # Parameterize P using PB = C^T. Let P = [p11, p12; p12, p22].\n    # The elements p_ij are expressed as linear functions of a free parameter 'alpha'.\n    # p_ij(alpha) = m_ij * alpha + c_ij\n    b1, b2 = B[0, 0], B[1, 0]\n    c1, c2 = C[0, 0], C[0, 1]\n    \n    p_coeffs = {} # Stores (m, c) for each p_ij\n\n    if abs(b1) > TOL:\n        if abs(b2) > TOL: # General case, let p12 be the free parameter\n            p_coeffs['p12'] = (1.0, 0.0)\n            # p11 = (c1 - alpha * b2) / b1\n            p_coeffs['p11'] = (-b2 / b1, c1 / b1)\n            # p22 = (c2 - alpha * b1) / b2\n            p_coeffs['p22'] = (-b1 / b2, c2 / b2)\n        else: # b2 is zero, let p22 be the free parameter\n            p_coeffs['p22'] = (1.0, 0.0)\n            p_coeffs['p11'] = (0.0, c1 / b1)\n            p_coeffs['p12'] = (0.0, c2 / b1)\n    else: # b1 is zero, so b2 must be non-zero, let p11 be the free parameter\n        p_coeffs['p11'] = (1.0, 0.0)\n        p_coeffs['p12'] = (0.0, c1 / b2)\n        p_coeffs['p22'] = (0.0, c2 / b2)\n\n    p11_m, p11_c = p_coeffs['p11']\n    p12_m, p12_c = p_coeffs['p12']\n    p22_m, p22_c = p_coeffs['p22']\n\n    # Aggregate linear inequalities to find the feasible interval for alpha\n    alpha_min, alpha_max = -np.inf, np.inf\n\n    # Helper function to update the interval [alpha_min, alpha_max]\n    def update_interval(m, c, is_gt):\n        nonlocal alpha_min, alpha_max\n        # m*alpha + c > 0 if is_gt, else m*alpha + c < 0\n        if abs(m) < TOL:\n            return c > TOL if is_gt else c < -TOL\n        \n        root = -c / m\n        if is_gt: # m*alpha > -c\n            if m > 0: alpha_min = max(alpha_min, root)\n            else: alpha_max = min(alpha_max, root)\n        else: # m*alpha < -c\n            if m > 0: alpha_max = min(alpha_max, root)\n            else: alpha_min = max(alpha_min, root)\n        return True\n\n    # From P > 0: p11 > 0\n    if not update_interval(p11_m, p11_c, is_gt=True): return False\n\n    # From P > 0: det(P) > 0. This is linear in alpha.\n    det_P_m = p11_m * p22_c + p11_c * p22_m - 2 * p12_m * p12_c\n    det_P_c = p11_c * p22_c - p12_c**2\n    if not update_interval(det_P_m, det_P_c, is_gt=True): return False\n\n    # From Q = A'P + PA < 0.\n    a11, a12, a21, a22 = A[0,0], A[0,1], A[1,0], A[1,1]\n    \n    # Coefficients for q_ij(alpha) = m * alpha + c\n    q11_m = 2 * (a11 * p11_m + a21 * p12_m)\n    q11_c = 2 * (a11 * p11_c + a21 * p12_c)\n    q22_m = 2 * (a12 * p12_m + a22 * p22_m)\n    q22_c = 2 * (a12 * p12_c + a22 * p22_c)\n    q12_m = a11 * p12_m + a12 * p11_m + a21 * p22_m + a22 * p12_m\n    q12_c = a11 * p12_c + a12 * p11_c + a21 * p22_c + a22 * p12_c\n\n    # From Q < 0: q11 < 0\n    if not update_interval(q11_m, q11_c, is_gt=False): return False\n\n    # Check if a consistent interval for linear constraints exists\n    if alpha_min >= alpha_max - TOL:\n        return False\n        \n    # From Q < 0: det(Q) > 0. This is a quadratic inequality.\n    # f(alpha) = k2*alpha^2 + k1*alpha + k0 > 0\n    k2 = q11_m * q22_m - q12_m**2\n    k1 = q11_m * q22_c + q11_c * q22_m - 2 * q12_m * q12_c\n    k0 = q11_c * q22_c - q12_c**2\n\n    if abs(k2) < TOL: # Linear or constant case for det(Q)\n        dummy_m, dummy_c = k1, k0\n        if abs(dummy_m) < TOL:\n            return dummy_c > TOL\n        \n        root = -dummy_c / dummy_m\n        if dummy_m > 0: # alpha > root\n            return max(alpha_min, root) < alpha_max - TOL\n        else: # alpha < root\n            return alpha_min < min(alpha_max, root) - TOL\n    else: # Quadratic case\n        delta = k1**2 - 4 * k2 * k0\n        if delta < -TOL:\n            return k2 > 0\n        else:\n            delta = max(0, delta) # Handle small negative delta from precision loss\n            sqrt_delta = np.sqrt(delta)\n            r1 = (-k1 - sqrt_delta) / (2 * k2)\n            r2 = (-k1 + sqrt_delta) / (2 * k2)\n            if r1 > r2: r1, r2 = r2, r1\n            \n            if k2 > 0: # f > 0 outside roots\n                overlap1 = alpha_min < min(alpha_max, r1) - TOL\n                overlap2 = max(alpha_min, r2) < alpha_max - TOL\n                return overlap1 or overlap2\n            else: # f > 0 between roots\n                intersect_min = max(alpha_min, r1)\n                intersect_max = min(alpha_max, r2)\n                return intersect_min < intersect_max - TOL\n\nif __name__ == '__main__':\n    solve()\n```", "id": "2725781"}]}