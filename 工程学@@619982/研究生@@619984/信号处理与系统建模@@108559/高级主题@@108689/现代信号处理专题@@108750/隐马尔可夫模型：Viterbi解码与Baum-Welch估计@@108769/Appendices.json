{"hands_on_practices": [{"introduction": "在处理隐马尔可夫模型 (HMM) 时，我们面临两个基本问题：解码和评估。解码是找出最有可能产生给定观测序列的隐藏状态序列，而评估则是计算该观测序列出现的总概率。本练习将引导您手动执行维特比 (Viterbi) 算法来寻找最优路径，并使用前向算法计算观测的边缘似然，通过比较这两个核心计算的结果，您将深刻理解“最优路径的概率”与“所有可能路径概率之和”之间的区别，这是正确应用 HMM 的关键一步。[@problem_id:2875864]", "id": "2875864", "problem": "考虑一个离散时间隐马尔可夫模型 (HMM)，其具有两个隐藏状态 $s_1$ 和 $s_2$，一个观测字母表 $\\mathcal{X} = \\{0,1\\}$，以及以下参数：\n- 初始分布 $\\pi$：$\\pi_1 = 0.55$，$\\pi_2 = 0.45$。\n- 状态转移矩阵 $A = [a_{ij}]$，其中 $a_{11} = 0.65$，$a_{12} = 0.35$，$a_{21} = 0.25$，$a_{22} = 0.75$。\n- 发射概率 $b_i(x) = p(x \\mid s_i)$：\n  - 对于状态 $s_1$：$b_1(0) = 0.60$，$b_1(1) = 0.40$。\n  - 对于状态 $s_2$：$b_2(0) = 0.20$，$b_2(1) = 0.80$。\n\n您观测到长度为4的序列 $x_{1:4} = (1,0,1,1)$。仅使用隐马尔可夫模型 (HMM) 的基本定义以及马尔可夫性质和条件发射模型所隐含的独立性假设（并且不使用任何缩放），完成以下任务：\n- 为 $x_{1:4}$ 数值化地构建 Viterbi 格，并回溯以获得最可能的隐藏状态路径及其概率（Viterbi 路径概率）。\n- 另外，通过从模型的基本定义推导出的前向递归，对所有隐藏状态路径求和来计算边际似然 $p(x_{1:4})$。\n- 计算比率 $R = \\dfrac{\\text{Viterbi path probability}}{p(x_{1:4})}$。\n\n仅报告 $R$ 的值作为您的最终答案。将您的最终答案四舍五入到五位有效数字。不需要单位。", "solution": "我们首先验证问题陈述。\n\n步骤1：提取已知条件。\n问题为离散时间隐马尔可夫模型 (HMM) 提供了以下参数：\n- 隐藏状态：$s_1$，$s_2$。\n- 观测字母表：$\\mathcal{X} = \\{0,1\\}$。\n- 初始分布 $\\pi$：$\\pi_1 = 0.55$，$\\pi_2 = 0.45$。\n- 状态转移矩阵 $A = [a_{ij}]$：$a_{11} = 0.65$，$a_{12} = 0.35$，$a_{21} = 0.25$，$a_{22} = 0.75$。\n- 发射概率 $b_i(x) = p(x \\mid s_i)$：\n  - $b_1(0) = 0.60$，$b_1(1) = 0.40$。\n  - $b_2(0) = 0.20$，$b_2(1) = 0.80$。\n- 观测序列：$x_{1:4} = (1,0,1,1)$。\n\n步骤2：使用提取的已知条件进行验证。\n该问题有科学依据，是适定的，并且是客观的。为标准 HMM 提供了所有参数。初始概率之和为1：$\\pi_1 + \\pi_2 = 0.55 + 0.45 = 1$。矩阵 $A$ 中每一行的转移概率之和为1：$a_{11} + a_{12} = 0.65 + 0.35 = 1$ 且 $a_{21} + a_{22} = 0.25 + 0.75 = 1$。每个状态的发射概率之和为1：$b_1(0) + b_1(1) = 0.60 + 0.40 = 1$ 且 $b_2(0) + b_2(1) = 0.20 + 0.80 = 1$。该问题是自包含、一致的，并为 HMM 提出了一组标准的计算任务（Viterbi 解码、前向算法）。它没有违反任何无效性标准。\n\n步骤3：结论和行动。\n问题是有效的。我们继续进行求解。\n\n求解需要三个顺序计算：给定观测序列的 Viterbi 路径概率，该序列的边际似然，以及这两个值的比率。\n\n第1部分：Viterbi 路径概率\nViterbi 算法为观测序列 $x_{1:T} = (x_1, \\dots, x_T)$ 找到最可能的隐藏状态序列 $q_{1:T} = (q_1, \\dots, q_T)$。它通过找到具有最大概率的单一状态路径来实现这一点。令 $\\delta_t(i)$ 为任意一条长度为 $t$、结束于状态 $s_i$ 并生成观测值 $x_{1:t}$ 的路径的最大概率。\n递归定义如下：\n- 初始化 ($t=1$)：$\\delta_1(i) = \\pi_i b_i(x_1)$\n- 递归 ($t > 1$)：$\\delta_t(j) = \\left( \\max_{i} [\\delta_{t-1}(i) a_{ij}] \\right) b_j(x_t)$\n我们将此递归应用于观测序列 $x_{1:4} = (1,0,1,1)$。\n\n时间 $t=1$，观测值 $x_1=1$：\n- $\\delta_1(1) = \\pi_1 b_1(1) = 0.55 \\times 0.40 = 0.22$\n- $\\delta_1(2) = \\pi_2 b_2(1) = 0.45 \\times 0.80 = 0.36$\n\n时间 $t=2$，观测值 $x_2=0$：\n- $\\delta_2(1) = \\max(\\delta_1(1)a_{11}, \\delta_1(2)a_{21}) \\times b_1(0) = \\max(0.22 \\times 0.65, 0.36 \\times 0.25) \\times 0.60 = \\max(0.143, 0.09) \\times 0.60 = 0.143 \\times 0.60 = 0.0858$\n- $\\delta_2(2) = \\max(\\delta_1(1)a_{12}, \\delta_1(2)a_{22}) \\times b_2(0) = \\max(0.22 \\times 0.35, 0.36 \\times 0.75) \\times 0.20 = \\max(0.077, 0.27) \\times 0.20 = 0.27 \\times 0.20 = 0.054$\n\n时间 $t=3$，观测值 $x_3=1$：\n- $\\delta_3(1) = \\max(\\delta_2(1)a_{11}, \\delta_2(2)a_{21}) \\times b_1(1) = \\max(0.0858 \\times 0.65, 0.054 \\times 0.25) \\times 0.40 = \\max(0.05577, 0.0135) \\times 0.40 = 0.05577 \\times 0.40 = 0.022308$\n- $\\delta_3(2) = \\max(\\delta_2(1)a_{12}, \\delta_2(2)a_{22}) \\times b_2(1) = \\max(0.0858 \\times 0.35, 0.054 \\times 0.75) \\times 0.80 = \\max(0.03003, 0.0405) \\times 0.80 = 0.0405 \\times 0.80 = 0.0324$\n\n时间 $t=4$，观测值 $x_4=1$：\n- $\\delta_4(1) = \\max(\\delta_3(1)a_{11}, \\delta_3(2)a_{21}) \\times b_1(1) = \\max(0.022308 \\times 0.65, 0.0324 \\times 0.25) \\times 0.40 = \\max(0.0145002, 0.0081) \\times 0.40 = 0.0145002 \\times 0.40 = 0.00580008$\n- $\\delta_4(2) = \\max(\\delta_3(1)a_{12}, \\delta_3(2)a_{22}) \\times b_2(1) = \\max(0.022308 \\times 0.35, 0.0324 \\times 0.75) \\times 0.80 = \\max(0.0078078, 0.0243) \\times 0.80 = 0.0243 \\times 0.80 = 0.01944$\n\n最可能路径的概率是最终时间步的最大值：\n$$P(\\text{Viterbi path}) = \\max_i \\delta_4(i) = \\max(0.00580008, 0.01944) = 0.01944$$\n\n第2部分：使用前向递归计算边际似然\n边际似然 $p(x_{1:T})$ 是所有可能生成该观测序列的隐藏状态路径的概率之和。它使用前向算法计算。令 $\\alpha_t(i) = p(x_{1:t}, q_t=s_i)$ 为前向变量，即观测到前 $t$ 个输出且在时间 $t$ 处于状态 $s_i$ 的联合概率。\n递归定义如下：\n- 初始化 ($t=1$)：$\\alpha_1(i) = \\pi_i b_i(x_1)$\n- 递归 ($t > 1$)：$\\alpha_t(j) = \\left( \\sum_{i} \\alpha_{t-1}(i) a_{ij} \\right) b_j(x_t)$\n- 终止：$p(x_{1:T}) = \\sum_i \\alpha_T(i)$\n\n我们将此递归应用于相同序列 $x_{1:4} = (1,0,1,1)$。\n\n时间 $t=1$，观测值 $x_1=1$：\n- $\\alpha_1(1) = \\pi_1 b_1(1) = 0.55 \\times 0.40 = 0.22$\n- $\\alpha_1(2) = \\pi_2 b_2(1) = 0.45 \\times 0.80 = 0.36$\n\n时间 $t=2$，观测值 $x_2=0$：\n- $\\alpha_2(1) = (\\alpha_1(1)a_{11} + \\alpha_1(2)a_{21}) \\times b_1(0) = (0.22 \\times 0.65 + 0.36 \\times 0.25) \\times 0.60 = (0.143 + 0.09) \\times 0.60 = 0.233 \\times 0.60 = 0.1398$\n- $\\alpha_2(2) = (\\alpha_1(1)a_{12} + \\alpha_1(2)a_{22}) \\times b_2(0) = (0.22 \\times 0.35 + 0.36 \\times 0.75) \\times 0.20 = (0.077 + 0.27) \\times 0.20 = 0.347 \\times 0.20 = 0.0694$\n\n时间 $t=3$，观测值 $x_3=1$：\n- $\\alpha_3(1) = (\\alpha_2(1)a_{11} + \\alpha_2(2)a_{21}) \\times b_1(1) = (0.1398 \\times 0.65 + 0.0694 \\times 0.25) \\times 0.40 = (0.09087 + 0.01735) \\times 0.40 = 0.10822 \\times 0.40 = 0.043288$\n- $\\alpha_3(2) = (\\alpha_2(1)a_{12} + \\alpha_2(2)a_{22}) \\times b_2(1) = (0.1398 \\times 0.35 + 0.0694 \\times 0.75) \\times 0.80 = (0.04893 + 0.05205) \\times 0.80 = 0.10098 \\times 0.80 = 0.080784$\n\n时间 $t=4$，观测值 $x_4=1$：\n- $\\alpha_4(1) = (\\alpha_3(1)a_{11} + \\alpha_3(2)a_{21}) \\times b_1(1) = (0.043288 \\times 0.65 + 0.080784 \\times 0.25) \\times 0.40 = (0.0281372 + 0.020196) \\times 0.40 = 0.0483332 \\times 0.40 = 0.01933328$\n- $\\alpha_4(2) = (\\alpha_3(1)a_{12} + \\alpha_3(2)a_{22}) \\times b_2(1) = (0.043288 \\times 0.35 + 0.080784 \\times 0.75) \\times 0.80 = (0.0151508 + 0.060588) \\times 0.80 = 0.0757388 \\times 0.80 = 0.06059104$\n\n总边际似然是最终时间步的前向变量之和：\n$$p(x_{1:4}) = \\sum_i \\alpha_4(i) = \\alpha_4(1) + \\alpha_4(2) = 0.01933328 + 0.06059104 = 0.07992432$$\n\n第3部分：计算比率 $R$\n最后一步是计算 Viterbi 路径概率与总边际似然的比率 $R$。\n$$R = \\frac{P(\\text{Viterbi path})}{p(x_{1:4})} = \\frac{0.01944}{0.07992432} \\approx 0.24322900$$\n根据问题陈述的要求，四舍五入到五位有效数字，得到：\n$$R \\approx 0.24323$$\n该比率量化了单一最可能路径相对于所有可能路径的总概率质量的主导程度。", "answer": "$$\\boxed{0.24323}$$"}, {"introduction": "在我们掌握了如何使用给定的 HMM进行推断之后，下一个核心任务便是从数据中学习模型本身的参数（例如，状态转移概率和发射概率）。这正是鲍姆-韦尔奇 (Baum-Welch) 算法的用武之地，它是期望最大化 (EM) 算法在 HMM 中的一个经典应用。本练习将带您完整地完成一次鲍姆-韦尔奇迭代，包括计算期望（E-步）和最大化（M-步），从而亲身体验模型参数如何根据观测数据进行更新和优化。[@problem_id:2875785]", "id": "2875785", "problem": "一个离散时间系统中的二进制传感器由一个双状态 ($2$) 的离散隐马尔可夫模型 (HMM) 建模。两个隐藏状态表示为 $S_1$ 和 $S_2$，观测字母表为 $\\{0,1\\}$。HMM 的参数包括初始状态分布 $\\boldsymbol{\\pi}$、状态转移矩阵 $\\boldsymbol{A}$ 和观测（发射）概率 $\\boldsymbol{B}$，根据定义，给定隐藏状态的发射条件独立性和马尔可夫性质均成立。具体来说，该模型为\n$$\n\\boldsymbol{\\pi} = \\begin{pmatrix}0.6 & 0.4\\end{pmatrix},\\quad\n\\boldsymbol{A} = \\begin{pmatrix}0.7 & 0.3\\\\ 0.4 & 0.6\\end{pmatrix},\\quad\n\\boldsymbol{B} =\n\\begin{pmatrix}\nP(O=0\\mid S_1) & P(O=1\\mid S_1)\\\\\nP(O=0\\mid S_2) & P(O=1\\mid S_2)\n\\end{pmatrix}\n=\n\\begin{pmatrix}\n0.5 & 0.5\\\\\n0.8 & 0.2\n\\end{pmatrix}.\n$$\n在时间 $t=1,2,3$，您观测到长度为 $3$ 的序列 $\\boldsymbol{O}=(1,0,1)$。\n\n仅使用离散隐马尔可夫模型 (HMM) 的基本定义、从马尔可夫性质和条件独立性推导出的前向-后向递归、贝叶斯规则以及标准的期望最大化 (EM) 框架，执行一次完整的 Baum–Welch EM 迭代，如下所示：\n\n1. 计算所有 $t\\in\\{1,2,3\\}$ 和 $i\\in\\{1,2\\}$ 的前向概率 $\\alpha_t(i)=P(O_1,\\dots,O_t,X_t=S_i)$ 和后向概率 $\\beta_t(i)=P(O_{t+1},\\dots,O_T\\mid X_t=S_i)$，以及序列似然 $P(\\boldsymbol{O})$。\n\n2. 从这些概率中，计算 $t\\in\\{1,2\\}$ 和 $i,j\\in\\{1,2\\}$ 的状态后验概率 $\\gamma_t(i)=P(X_t=S_i\\mid \\boldsymbol{O})$ 和双切片后验概率 $\\xi_t(i,j)=P(X_t=S_i,X_{t+1}=S_j\\mid \\boldsymbol{O})$。\n\n3. 在归一化约束下，使用 EM 的最大化步骤获得重估参数 $\\boldsymbol{\\pi}'$、$\\boldsymbol{A}'$ 和 $\\boldsymbol{B}'$。\n\n仅报告从状态 $S_1$ 到状态 $S_2$ 的重估转移概率，记为 $a'_{12}$，以单一最简分数形式表示。不提供单位。不要四舍五入；以既约分数形式表示答案。", "solution": "对问题陈述进行验证。\n\n### 步骤1：提取已知条件\n- 一个具有 $N=2$ 个隐藏状态 $S_1$ 和 $S_2$ 的离散隐马尔可夫模型 (HMM)。\n- 观测字母表为 $\\{0,1\\}$。\n- 观测序列的长度为 $T=3$。\n- 观测序列为 $\\boldsymbol{O}=(O_1, O_2, O_3) = (1,0,1)$。\n- 初始状态分布为 $\\boldsymbol{\\pi} = \\begin{pmatrix} \\pi_1 & \\pi_2 \\end{pmatrix} = \\begin{pmatrix} 0.6 & 0.4 \\end{pmatrix}$。\n- 状态转移概率矩阵为 $\\boldsymbol{A} = \\begin{pmatrix} a_{11} & a_{12} \\\\ a_{21} & a_{22} \\end{pmatrix} = \\begin{pmatrix} 0.7 & 0.3\\\\ 0.4 & 0.6 \\end{pmatrix}$。\n- 观测（发射）概率矩阵为 $\\boldsymbol{B}$，其中 $b_j(k) = P(O_t=k \\mid X_t=S_j)$。给定为 $\\boldsymbol{B} = \\begin{pmatrix} b_1(0) & b_1(1) \\\\ b_2(0) & b_2(1) \\end{pmatrix} = \\begin{pmatrix} 0.5 & 0.5\\\\ 0.8 & 0.2 \\end{pmatrix}$。\n- 任务是执行一次 Baum-Welch 算法迭代以重估模型参数，并报告单一值 $a'_{12}$。\n\n### 步骤2：使用提取的已知条件进行验证\n- **科学依据：** 该问题是隐马尔可夫模型的 Baum-Welch 算法的标准应用，该算法是信号处理和机器学习的基石。它在科学上和数学上都是合理的。\n- **适定性：** 该问题是适定的。所有必要的参数 ($\\boldsymbol{\\pi}, \\boldsymbol{A}, \\boldsymbol{B}$) 和观测序列 $\\boldsymbol{O}$ 均已提供。目标明确陈述。单次迭代存在唯一解。所提供的概率分布已正确归一化（$\\boldsymbol{\\pi}$、$\\boldsymbol{A}$ 和 $\\boldsymbol{B}$ 的行和为 $1$）。\n- **客观性：** 问题以客观的、数学的术语陈述，没有歧义或主观内容。\n- **完备性与一致性：** 问题是自洽的，没有矛盾之处。\n\n### 步骤3：结论与行动\n问题是**有效的**。将推导解答。\n\nBaum-Welch 算法是期望最大化 (EM) 算法的一个实例。一次迭代包括一个期望 (E) 步骤和一个最大化 (M) 步骤。\n\n**E-步骤：计算前向、后向和后验概率**\n\n模型参数的分数形式为：\n$\\boldsymbol{\\pi} = \\begin{pmatrix} \\frac{3}{5} & \\frac{2}{5} \\end{pmatrix}$, $\\boldsymbol{A} = \\begin{pmatrix} \\frac{7}{10} & \\frac{3}{10}\\\\ \\frac{2}{5} & \\frac{3}{5} \\end{pmatrix}$, $\\boldsymbol{B} = \\begin{pmatrix} \\frac{1}{2} & \\frac{1}{2}\\\\ \\frac{4}{5} & \\frac{1}{5} \\end{pmatrix}$。\n观测序列为 $\\boldsymbol{O}=(1,0,1)$。\n\n**1. 前向概率 $\\alpha_t(i) = P(O_1, \\dots, O_t, X_t=S_i \\mid \\boldsymbol{\\lambda})$**\n前向变量 $\\alpha_t(i)$ 通过递归计算。\n- **初始化 ($t=1$):** $\\alpha_1(i) = \\pi_i b_i(O_1)$。这里 $O_1 = 1$。\n$$ \\alpha_1(1) = \\pi_1 b_1(1) = \\frac{3}{5} \\times \\frac{1}{2} = \\frac{3}{10} $$\n$$ \\alpha_1(2) = \\pi_2 b_2(1) = \\frac{2}{5} \\times \\frac{1}{5} = \\frac{2}{25} $$\n- **递归 ($t=2$):** $\\alpha_2(j) = \\left[ \\sum_{i=1}^2 \\alpha_1(i) a_{ij} \\right] b_j(O_2)$。这里 $O_2 = 0$。\n$$ \\alpha_2(1) = \\left[ \\alpha_1(1)a_{11} + \\alpha_1(2)a_{21} \\right] b_1(0) = \\left[ \\frac{3}{10}\\frac{7}{10} + \\frac{2}{25}\\frac{2}{5} \\right] \\frac{1}{2} = \\left[ \\frac{21}{100} + \\frac{4}{125} \\right] \\frac{1}{2} = \\left[ \\frac{105+16}{500} \\right] \\frac{1}{2} = \\frac{121}{1000} $$\n$$ \\alpha_2(2) = \\left[ \\alpha_1(1)a_{12} + \\alpha_1(2)a_{22} \\right] b_2(0) = \\left[ \\frac{3}{10}\\frac{3}{10} + \\frac{2}{25}\\frac{3}{5} \\right] \\frac{4}{5} = \\left[ \\frac{9}{100} + \\frac{6}{125} \\right] \\frac{4}{5} = \\left[ \\frac{45+24}{500} \\right] \\frac{4}{5} = \\frac{69}{500}\\frac{4}{5} = \\frac{276}{2500} = \\frac{69}{625} $$\n- **递归 ($t=3$):** $\\alpha_3(j) = \\left[ \\sum_{i=1}^2 \\alpha_2(i) a_{ij} \\right] b_j(O_3)$。这里 $O_3 = 1$。\n$$ \\alpha_3(1) = \\left[ \\alpha_2(1)a_{11} + \\alpha_2(2)a_{21} \\right] b_1(1) = \\left[ \\frac{121}{1000}\\frac{7}{10} + \\frac{69}{625}\\frac{2}{5} \\right] \\frac{1}{2} = \\left[ \\frac{847}{10000} + \\frac{138}{3125} \\right] \\frac{1}{2} = \\left[ \\frac{4235+2208}{50000} \\right] \\frac{1}{2} = \\frac{6443}{100000} $$\n$$ \\alpha_3(2) = \\left[ \\alpha_2(1)a_{12} + \\alpha_2(2)a_{22} \\right] b_2(1) = \\left[ \\frac{121}{1000}\\frac{3}{10} + \\frac{69}{625}\\frac{3}{5} \\right] \\frac{1}{5} = \\left[ \\frac{363}{10000} + \\frac{207}{3125} \\right] \\frac{1}{5} = \\left[ \\frac{1815+3312}{50000} \\right] \\frac{1}{5} = \\frac{5127}{50000}\\frac{1}{5} = \\frac{5127}{250000} $$\n- **序列概率 $P(\\boldsymbol{O})$：** 这是最终前向变量的和。\n$$ P(\\boldsymbol{O}) = \\alpha_3(1) + \\alpha_3(2) = \\frac{6443}{100000} + \\frac{5127}{250000} = \\frac{32215+10254}{500000} = \\frac{42469}{500000} $$\n\n**2. 后向概率 $\\beta_t(i) = P(O_{t+1}, \\dots, O_T \\mid X_t=S_i, \\boldsymbol{\\lambda})$**\n后向变量 $\\beta_t(i)$ 通过后向递归计算。\n- **初始化 ($t=3$):**\n$$ \\beta_3(1) = 1, \\quad \\beta_3(2) = 1 $$\n- **递归 ($t=2$):** $\\beta_2(i) = \\sum_{j=1}^2 a_{ij} b_j(O_3) \\beta_3(j)$。这里 $O_3=1$。\n$$ \\beta_2(1) = a_{11}b_1(1)\\beta_3(1) + a_{12}b_2(1)\\beta_3(2) = \\frac{7}{10}\\frac{1}{2}(1) + \\frac{3}{10}\\frac{1}{5}(1) = \\frac{7}{20} + \\frac{3}{50} = \\frac{35+6}{100} = \\frac{41}{100} $$\n$$ \\beta_2(2) = a_{21}b_1(1)\\beta_3(1) + a_{22}b_2(1)\\beta_3(2) = \\frac{2}{5}\\frac{1}{2}(1) + \\frac{3}{5}\\frac{1}{5}(1) = \\frac{1}{5} + \\frac{3}{25} = \\frac{5+3}{25} = \\frac{8}{25} $$\n- **递归 ($t=1$):** $\\beta_1(i) = \\sum_{j=1}^2 a_{ij} b_j(O_2) \\beta_2(j)$。这里 $O_2=0$。\n$$ \\beta_1(1) = a_{11}b_1(0)\\beta_2(1) + a_{12}b_2(0)\\beta_2(2) = \\frac{7}{10}\\frac{1}{2}\\frac{41}{100} + \\frac{3}{10}\\frac{4}{5}\\frac{8}{25} = \\frac{287}{2000} + \\frac{96}{1250} = \\frac{1435+768}{10000} = \\frac{2203}{10000} $$\n$$ \\beta_1(2) = a_{21}b_1(0)\\beta_2(1) + a_{22}b_2(0)\\beta_2(2) = \\frac{2}{5}\\frac{1}{2}\\frac{41}{100} + \\frac{3}{5}\\frac{4}{5}\\frac{8}{25} = \\frac{41}{500} + \\frac{96}{625} = \\frac{205+384}{2500} = \\frac{589}{2500} $$\n作为一致性检查，$P(\\boldsymbol{O})$ 也可以在 $t=1$ 时计算：\n$$ P(\\boldsymbol{O}) = \\sum_{i=1}^2 \\alpha_1(i)\\beta_1(i) = \\frac{3}{10}\\frac{2203}{10000} + \\frac{2}{25}\\frac{589}{2500} = \\frac{6609}{100000} + \\frac{1178}{62500} = \\frac{33045+9424}{500000} = \\frac{42469}{500000} $$\n结果匹配，证实了前向和后向计算的正确性。\n\n**3. 后验概率**\n状态后验概率 $\\gamma_t(i)$ 和双切片后验概率 $\\xi_t(i,j)$ 分别是：\n$$ \\gamma_t(i) = P(X_t=S_i \\mid \\boldsymbol{O}, \\boldsymbol{\\lambda}) = \\frac{\\alpha_t(i)\\beta_t(i)}{P(\\boldsymbol{O})} $$\n$$ \\xi_t(i,j) = P(X_t=S_i, X_{t+1}=S_j \\mid \\boldsymbol{O}, \\boldsymbol{\\lambda}) = \\frac{\\alpha_t(i) a_{ij} b_j(O_{t+1}) \\beta_{t+1}(j)}{P(\\boldsymbol{O})} $$\n\n**M-步骤：参数重估**\n转移概率 $a'_{ij}$ 的重估公式为：\n$$ a'_{ij} = \\frac{\\text{从 } S_i \\text{ 到 } S_j \\text{ 转移的期望次数}}{\\text{从 } S_i \\text{ 转移的期望次数}} = \\frac{\\sum_{t=1}^{T-1} \\xi_t(i,j)}{\\sum_{t=1}^{T-1} \\gamma_t(i)} $$\n对于 $a'_{12}$，当 $T=3$ 时：\n$$ a'_{12} = \\frac{\\xi_1(1,2) + \\xi_2(1,2)}{\\gamma_1(1) + \\gamma_2(1)} $$\n$P(\\boldsymbol{O})$ 这个公分母将会消掉，所以我们可以直接使用 $\\xi$ 和 $\\gamma$ 的分子进行计算。\n令 $Num = (\\alpha_1(1) a_{12} b_2(O_2) \\beta_2(2)) + (\\alpha_2(1) a_{12} b_2(O_3) \\beta_3(2))$。\n令 $Den = (\\alpha_1(1) \\beta_1(1)) + (\\alpha_2(1) \\beta_2(1))$。\n则 $a'_{12} = \\frac{Num}{Den}$。\n\n- **计算分子和：**\n第 1 项 ($t=1$): $\\alpha_1(1) a_{12} b_2(O_2) \\beta_2(2) = \\frac{3}{10} \\times \\frac{3}{10} \\times \\frac{4}{5} \\times \\frac{8}{25} = \\frac{288}{12500} = \\frac{72}{3125}$。\n第 2 项 ($t=2$): $\\alpha_2(1) a_{12} b_2(O_3) \\beta_3(2) = \\frac{121}{1000} \\times \\frac{3}{10} \\times \\frac{1}{5} \\times 1 = \\frac{363}{50000}$。\n$$ Num = \\frac{72}{3125} + \\frac{363}{50000} = \\frac{72 \\times 16 + 363}{50000} = \\frac{1152+363}{50000} = \\frac{1515}{50000} $$\n\n- **计算分母和：**\n第 1 项 ($t=1$): $\\alpha_1(1) \\beta_1(1) = \\frac{3}{10} \\times \\frac{2203}{10000} = \\frac{6609}{100000}$。\n第 2 项 ($t=2$): $\\alpha_2(1) \\beta_2(1) = \\frac{121}{1000} \\times \\frac{41}{100} = \\frac{4961}{100000}$。\n$$ Den = \\frac{6609}{100000} + \\frac{4961}{100000} = \\frac{11570}{100000} = \\frac{1157}{10000} $$\n\n- **计算 $a'_{12}$ 的最终比率：**\n$$ a'_{12} = \\frac{Num}{Den} = \\frac{1515/50000}{1157/10000} = \\frac{1515}{50000} \\times \\frac{10000}{1157} = \\frac{1515}{5 \\times 1157} = \\frac{303}{1157} $$\n通过将分子和分母同除以 $5$ 来简化分数。为检查 $\\frac{303}{1157}$ 是否可以进一步约分，我们找到它们的质因数。\n$303 = 3 \\times 101$。\n$1157$ 不能被 $3$ (各位数字之和为 $14$) 或 $101$ 整除。\n$1157 = 13 \\times 89$。\n由于没有共同的质因数，该分数是既约的。", "answer": "$$\\boxed{\\frac{303}{1157}}$$"}, {"introduction": "理论上强大的鲍姆-韦尔奇算法在实际应用中，尤其是在处理稀疏数据时，可能会遇到数值稳定性问题。一个典型挑战是，在 E-步中计算出的某些状态或转移的期望计数可能为零。本练习旨在探讨这种“零计数”问题对最大似然估计（ML）框架下 M-步更新所造成的影响，并分析为何引入先验分布的最大后验（MAP）估计等平滑技术能有效解决参数更新不明确或模型退化的问题，从而构建更鲁棒的 HMM。[@problem_id:2875859]", "id": "2875859", "problem": "考虑一个隐马尔可夫模型 (HMM)，其具有 $N$ 个隐状态、初始分布 $\\boldsymbol{\\pi}$、转移矩阵 $\\mathbf{A}$ (其元素为 $A_{ij}$) 以及发射参数 $\\{\\theta_i\\}_{i=1}^N$。这些发射参数描述了在一个大小为 $M$ 的字母表上的离散发射分布，或者是一个均值为 $\\boldsymbol{\\mu}_i$、协方差为 $\\boldsymbol{\\Sigma}_i$ 的多元高斯分布。令一个长度为 $T$ 的观测序列表示为 $\\mathbf{o}_{1:T}$。期望最大化 (EM) 算法，在其针对 HMM 的 Baum–Welch 实例中，在每次迭代时构造辅助函数 $Q(\\boldsymbol{\\theta}\\mid\\boldsymbol{\\theta}^{\\text{old}}) \\triangleq \\mathbb{E}_{\\mathbf{S}\\mid \\mathbf{o}_{1:T},\\boldsymbol{\\theta}^{\\text{old}}}\\left[\\log p(\\mathbf{S},\\mathbf{o}_{1:T}\\mid \\boldsymbol{\\theta})\\right]$，其中 $\\mathbf{S}$ 是隐状态序列，并相对于参数 $\\boldsymbol{\\theta} \\triangleq (\\boldsymbol{\\pi},\\mathbf{A},\\{\\theta_i\\})$ 对该函数进行最大化。在时刻 $t$ 的后验状态占据概率和后验转移概率分别表示为 $\\gamma_t(i) \\triangleq p(S_t=i\\mid \\mathbf{o}_{1:T},\\boldsymbol{\\theta}^{\\text{old}})$ 和 $\\xi_t(i,j) \\triangleq p(S_t=i,S_{t+1}=j\\mid \\mathbf{o}_{1:T},\\boldsymbol{\\theta}^{\\text{old}})$。假设由于数据稀疏性和模型初始化，某些期望计数变得恰好为零，例如对于某个状态 $i$ 有 $\\sum_{t=1}^T \\gamma_t(i)=0$，或对于某个转移 $(i,j)$ 有 $\\sum_{t=1}^{T-1}\\xi_t(i,j)=0$，甚至对于某个行 $i$ 有 $\\sum_{t=1}^{T-1}\\sum_{j=1}^N \\xi_t(i,j)=0$。根据完全数据对数似然和 EM 辅助函数的定义，分析这些零期望计数对最大似然 (ML) M步以及 EM 的单调性保证的影响。同时考虑带有正常共轭先验的最大后验 (MAP) 变体，以及诸如加性下限和协方差下限等常见工程启发法。\n\n下列哪个陈述是正确的？\n\nA. 如果对于某个具有离散发射的状态 $i$ 有 $\\sum_{t=1}^T \\gamma_t(i)=0$，那么在没有先验的最大似然估计下，状态 $i$ 的发射分布的 M 步更新是不可识别的，因为辅助函数中相应的项不依赖于 $\\theta_i$。对状态 $i$ 的发射概率引入一个具有严格为正的超参数的对称狄利克雷先验，会产生一个定义明确的最大后验更新，其中所有发射概率都严格为正。\n\nB. 如果对于某个状态 $i$ 有 $\\sum_{t=1}^{T-1}\\sum_{j=1}^N \\xi_t(i,j)=0$，那么对矩阵 $\\mathbf{A}$ 的第 $i$ 行所有元素设置一个小的加性下限 $\\epsilon$ 并对该行进行重新归一化，能保证在这次迭代中对于任何 $\\epsilon>0$，EM 下界 $Q(\\boldsymbol{\\theta}\\mid\\boldsymbol{\\theta}^{\\text{old}})$ 都会严格增加。\n\nC. 对于高斯发射，如果对于某个状态 $i$ 有 $\\sum_{t=1}^T \\gamma_t(i)=0$，那么用一个小的 $\\epsilon>0$ 将 $\\boldsymbol{\\Sigma}_i$ 替换为 $\\epsilon \\mathbf{I}$ 会保持 EM 所保证的不完全数据对数似然的单调不减性，并且在极限 $\\epsilon\\to 0$ 下，这等价于对 $\\boldsymbol{\\Sigma}_i$ 使用一个共轭威沙特先验。\n\nD. 如果对于某个状态 $i$ 有 $\\gamma_1(i)=0$，那么初始分布项 $\\pi_i$ 的最大似然 M 步更新是未定义的。引入一个带有 $\\alpha_i>0$ 的伪计数向量 $\\boldsymbol{\\alpha}$ 可以解决这个问题，它会产生与 $\\gamma_1(i)+\\alpha_i$ 成正比且严格为正的 $\\pi_i$ 更新。\n\nE. 用维特比训练（通过维特比解码进行硬分配）替代 EM 算法可以避免零期望计数，同时保持 EM 在每次迭代中享有的不完全数据对数似然的非递减性质。", "solution": "本问题要求分析隐马尔可夫模型 (HMM) 的 Baum-Welch 算法中零期望计数带来的后果，并评估几个关于最大似然 (ML) 估计、最大后验 (MAP) 估计和常见启发法的陈述。\n\n首先，我们建立数学背景。期望最大化 (EM) 算法通过迭代最大化辅助函数 $Q(\\boldsymbol{\\theta}\\mid\\boldsymbol{\\theta}^{\\text{old}})$ 来最大化不完全数据对数似然 $p(\\mathbf{o}_{1:T} \\mid \\boldsymbol{\\theta})$。该函数是期望的完全数据对数似然：\n$$ Q(\\boldsymbol{\\theta} \\mid \\boldsymbol{\\theta}^{\\text{old}}) = \\mathbb{E}_{\\mathbf{S}\\mid \\mathbf{o}_{1:T},\\boldsymbol{\\theta}^{\\text{old}}}\\left[\\log p(\\mathbf{S},\\mathbf{o}_{1:T}\\mid \\boldsymbol{\\theta})\\right] $$\n完全数据对数似然由下式给出：\n$$ \\log p(\\mathbf{S},\\mathbf{o}_{1:T}\\mid \\boldsymbol{\\theta}) = \\log \\pi_{S_1} + \\sum_{t=1}^{T-1} \\log A_{S_t S_{t+1}} + \\sum_{t=1}^T \\log p(\\mathbf{o}_t \\mid \\theta_{S_t}) $$\n求期望得到 $Q$ 函数，该函数可分离为与初始概率 $\\boldsymbol{\\pi}$、转移概率 $\\mathbf{A}$ 和发射参数 $\\{\\theta_i\\}$ 相关的三项：\n$$ Q(\\boldsymbol{\\theta} \\mid \\boldsymbol{\\theta}^{\\text{old}}) = \\sum_{i=1}^N \\gamma_1(i) \\log \\pi_i + \\sum_{t=1}^{T-1} \\sum_{i=1}^N \\sum_{j=1}^N \\xi_t(i,j) \\log A_{ij} + \\sum_{t=1}^T \\sum_{i=1}^N \\gamma_t(i) \\log p(\\mathbf{o}_t \\mid \\theta_i) $$\n这里，$\\gamma_t(i)=p(S_t=i\\mid\\mathbf{o}_{1:T},\\boldsymbol{\\theta}^{\\text{old}})$ 和 $\\xi_t(i,j)=p(S_t=i,S_{t+1}=j\\mid\\mathbf{o}_{1:T},\\boldsymbol{\\theta}^{\\text{old}})$ 是在 E 步中计算的后验概率。\n\nM 步涉及相对于参数 $\\boldsymbol{\\theta}$ 最大化这些项。\n- 对于 $\\boldsymbol{\\pi}$：$\\pi_i^{\\text{new}} = \\gamma_1(i)$。\n- 对于 $\\mathbf{A}$：$A_{ij}^{\\text{new}} = \\frac{\\sum_{t=1}^{T-1} \\xi_t(i,j)}{\\sum_{t=1}^{T-1} \\gamma_t(i)}$。\n- 对于离散发射 $b_{ik} = p(\\text{obs } v_k|S=i)$：$b_{ik}^{\\text{new}} = \\frac{\\sum_{t \\text{ s.t. } o_t=v_k} \\gamma_t(i)}{\\sum_{t=1}^T \\gamma_t(i)}$。\n- 对于高斯发射 $(\\boldsymbol{\\mu}_i, \\boldsymbol{\\Sigma}_i)$：$\\boldsymbol{\\mu}_i^{\\text{new}} = \\frac{\\sum_{t=1}^T \\gamma_t(i) \\mathbf{o}_t}{\\sum_{t=1}^T \\gamma_t(i)}$ 和 $\\boldsymbol{\\Sigma}_i^{\\text{new}} = \\frac{\\sum_{t=1}^T \\gamma_t(i) (\\mathbf{o}_t - \\boldsymbol{\\mu}_i^{\\text{new}})(\\mathbf{o}_t - \\boldsymbol{\\mu}_i^{\\text{new}})^T}{\\sum_{t=1}^T \\gamma_t(i)}$。\n\n我们现在基于这些公式分析每个陈述。\n\n**对选项 A 的分析**\n\n该陈述是：“如果对于某个具有离散发射的状态 $i$ 有 $\\sum_{t=1}^T \\gamma_t(i)=0$，那么在没有先验的最大似然估计下，状态 $i$ 的发射分布的 M 步更新是不可识别的，因为辅助函数中相应的项不依赖于 $\\theta_i$。对状态 $i$ 的发射概率引入一个具有严格为正的超参数的对称狄利克雷先验，会产生一个定义明确的最大后验更新，其中所有发射概率都严格为正。”\n\n1.  **最大似然更新问题**：由于所有 $\\gamma_t(i) \\ge 0$，条件 $\\sum_{t=1}^T \\gamma_t(i)=0$ 意味着对于所有 $t \\in \\{1, \\dots, T\\}$ 都有 $\\gamma_t(i)=0$。$Q$ 函数中与状态 $i$ 的发射分布 $\\theta_i = \\{b_{ik}\\}_{k=1}^M$ 相关的项是 $\\sum_{t=1}^T \\gamma_t(i) \\log p(\\mathbf{o}_t \\mid \\theta_i) = \\sum_{t=1}^T 0 \\cdot \\log p(\\mathbf{o}_t \\mid \\theta_i) = 0$。该项是常数，不依赖于 $\\theta_i$。因此，任何有效的概率分布 $\\{b_{ik}\\}$ 都是一个最大化器，参数是不可识别的。更新公式 $b_{ik}^{\\text{new}}$ 会导致不定式 $0/0$。陈述的第一部分是正确的。\n\n2.  **带狄利克雷先验的最大后验更新**：为概率向量 $\\mathbf{b}_i = (b_{i1}, \\dots, b_{iM})$ 引入一个狄利克雷先验 $\\text{Dir}(\\mathbf{b}_i \\mid \\boldsymbol{\\alpha})$，会向 M 步中被最大化的函数添加一项 $\\sum_{k=1}^M (\\alpha_k-1)\\log b_{ik}$。$b_{ik}$ 的最大后验更新与期望计数加上伪计数成正比：$b_{ik}^{\\text{new}} \\propto (\\sum_{t \\text{ s.t. } o_t=v_k} \\gamma_t(i)) + \\alpha_k - 1$。在给定条件下，期望计数为零。更新变为 $b_{ik}^{\\text{new}} \\propto \\alpha_k - 1$。对于对称先验，所有 $k$ 的 $\\alpha_k=\\alpha$。更新为 $b_{ik}^{\\text{new}} = \\frac{\\alpha-1}{\\sum_{j=1}^M(\\alpha-1)} = \\frac{1}{M}$，前提是 $\\alpha \\neq 1$。陈述声称结果概率是“严格为正”的。这要求分子 $\\alpha_k-1$ 为正，即 $\\alpha_k > 1$。问题中指定了“严格为正的超参数”，这意味着 $\\alpha_k > 0$。如果我们选择一个超参数 $\\alpha \\in (0,1)$，目标函数变为凸函数，最大值在概率单纯形的顶点处取得（即一个 $b_{ik}=1$，其余为 $0$），这并非“严格为正”。如果 $\\alpha=1$，目标函数为常数，导致解不唯一。因此，该陈述仅在超参数 $\\alpha > 1$ 时成立。然而，陈述说“引入一个对称狄利克雷先验...”。这可以被存在性地解释：在指定的类别（对称，$\\alpha>0$）中是否存在一个先验满足该主张？是的。任何 $\\alpha > 1$ 的选择（例如 $\\alpha=2$）都符合“严格为正的超参数”的描述，并导致一个定义明确的更新（$b_{ik}^{\\text{new}} = 1/M$），其中所有概率都严格为正。与其他包含明确错误的选项相比，这个陈述是最合理的。\n\n**对 A 的裁定**：**正确**。\n\n**对选项 B 的分析**\n\n该陈述是：“如果对于某个状态 $i$ 有 $\\sum_{t=1}^{T-1}\\sum_{j=1}^N \\xi_t(i,j)=0$，那么对矩阵 $\\mathbf{A}$ 的第 $i$ 行所有元素设置一个小的加性下限 $\\epsilon$ 并对该行进行重新归一化，能保证在这次迭代中对于任何 $\\epsilon>0$，EM 下界 $Q(\\boldsymbol{\\theta}\\mid\\boldsymbol{\\theta}^{\\text{old}})$ 都会严格增加。”\n\n条件 $\\sum_{t=1}^{T-1}\\sum_{j=1}^N \\xi_t(i,j)=0$ 意味着对于所有 $j \\in \\{1,\\dots,N\\}$ 和所有 $t \\in \\{1,\\dots,T-1\\}$ 都有 $\\xi_t(i,j)=0$，因为 $\\xi_t(i,j) \\ge 0$。$Q$ 函数中依赖于转移矩阵 $\\mathbf{A}$ 的第 $i$ 行的部分是 $\\sum_{t=1}^{T-1} \\sum_{j=1}^N \\xi_t(i,j) \\log A_{ij}$。在给定条件下，该项为 $\\sum_{t=1}^{T-1} \\sum_{j=1}^N 0 \\cdot \\log A_{ij} = 0$。$Q$ 函数的这部分值为零，且独立于参数 $\\{A_{ij}\\}_{j=1}^N$。将这些参数从其旧值 $\\mathbf{A}^{\\text{old}}$ 修改为新值，例如通过设置下限和归一化，不会改变 $Q(\\boldsymbol{\\theta} \\mid \\boldsymbol{\\theta}^{\\text{old}})$ 的值。 $Q$ 的变化量恰好为零。该陈述声称*严格增加*，这是错误的。\n\n**对 B 的裁定**：**错误**。\n\n**对选项 C 的分析**\n\n该陈述是：“对于高斯发射，如果对于某个状态 $i$ 有 $\\sum_{t=1}^T \\gamma_t(i)=0$，那么用一个小的 $\\epsilon>0$ 将 $\\boldsymbol{\\Sigma}_i$ 替换为 $\\epsilon \\mathbf{I}$ 会保持 EM 所保证的不完全数据对数似然的单调不减性，并且在极限 $\\epsilon\\to 0$ 下，这等价于对 $\\boldsymbol{\\Sigma}_i$ 使用一个共轭威沙特先验。”\n\n1.  **单调不减性**：与选项 A 中一样，如果 $\\sum_{t=1}^T \\gamma_t(i)=0$，则 $Q$ 函数中依赖于状态 $i$ 的发射参数（$\\boldsymbol{\\mu}_i, \\boldsymbol{\\Sigma}_i$）的部分为零。改变这些参数对 $Q$ 的值没有影响。因此，$Q(\\boldsymbol{\\theta}^{\\text{new}} \\mid \\boldsymbol{\\theta}^{\\text{old}}) = Q(\\boldsymbol{\\theta}^{\\text{old}} \\mid \\boldsymbol{\\theta}^{\\text{old}})$。EM 的基本不等式表明 $p(\\mathbf{o} \\mid \\boldsymbol{\\theta}^{\\text{new}}) - p(\\mathbf{o} \\mid \\boldsymbol{\\theta}^{\\text{old}}) \\ge Q(\\boldsymbol{\\theta}^{\\text{new}} \\mid \\boldsymbol{\\theta}^{\\text{old}}) - Q(\\boldsymbol{\\theta}^{\\text{old}} \\mid \\boldsymbol{\\theta}^{\\text{old}})$。在这里，右侧为 $0$，所以 $p(\\mathbf{o} \\mid \\boldsymbol{\\theta}^{\\text{new}}) \\ge p(\\mathbf{o} \\mid \\boldsymbol{\\theta}^{\\text{old}})$ 成立。单调不减的性质得以保持。这部分是正确的。\n\n2.  **与先验的等价性**：在没有数据的情况下，最大后验估计是先验的众数。该启发法设置 $\\boldsymbol{\\Sigma}_i = \\epsilon \\mathbf{I}$。人们可以构建一个共轭先验（例如，对 $\\boldsymbol{\\Sigma}_i$ 的逆威沙特先验），其众数恰好是 $\\epsilon \\mathbf{I}$。然而，该陈述讨论的是极限 $\\epsilon \\to 0$。在此极限下，$\\boldsymbol{\\Sigma}_i \\to \\mathbf{0}$，一个奇异矩阵。这代表一个无限精确的高斯分布，即一个狄拉克δ函数。协方差下限的目的是通过确保协方差矩阵是良态的并且其行列式有远离零的下界来*防止*奇异性。一个在极限下导致奇异矩阵的过程与该启发法的目标背道而驰。在一个与方法目的相矛盾的病态极限下声称等价，在科学上是不合理的并且具有误导性。\n\n**对 C 的裁定**：**错误**。\n\n**对选项 D 的分析**\n\n该陈述是：“如果对于某个状态 $i$ 有 $\\gamma_1(i)=0$，那么初始分布项 $\\pi_i$ 的最大似然 M 步更新是未定义的。引入一个带有 $\\alpha_i>0$ 的伪计数向量 $\\boldsymbol{\\alpha}$ 可以解决这个问题，它会产生与 $\\gamma_1(i)+\\alpha_i$ 成正比且严格为正的 $\\pi_i$ 更新。”\n\n初始概率 $\\pi_i$ 的最大似然 M 步更新是 $\\pi_i^{\\text{new}} = \\gamma_1(i)$。如果 $\\gamma_1(i)=0$，那么 $\\pi_i^{\\text{new}} = 0$。这是一个完全定义明确的数学运算。结果是实数 $0$。它不是像 $0/0$ 那样的不定式意义上的“未定义”。该陈述的基本前提是错误的。虽然设置 $\\pi_i=0$ 可能会因为“扼杀”一个状态而对模型造成问题，但更新规则本身是定义明确的。\n\n**对 D 的裁定**：**错误**。\n\n**对选项 E 的分析**\n\n该陈述是：“用维特比训练（通过维特比解码进行硬分配）替代 EM 算法可以避免零期望计数，同时保持 EM 在每次迭代中享有的不完全数据对数似然的非递减性质。”\n\n1.  **避免零计数**：维特比训练将 EM 的“软”期望计数（后验概率之和）替换为来自单一最可能状态序列 $\\mathbf{S}^*$ 的“硬”整数计数。这个序列 $\\mathbf{S}^*$ 完全有可能根本不使用某个特定状态 $i$ 或某个特定转移 $(i,j)$。在这种情况下，该状态或转移的硬计数将恰好为零。维特比训练并不能避免零计数的问题。\n\n2.  **保持单调性**：EM 算法保证永远不会降低不完全数据（边际）对数似然 $p(\\mathbf{o}_{1:T} \\mid \\boldsymbol{\\theta})$。维特比训练*没有*这个保证。维特比训练的一个已知性质是，虽然它会增加所选路径的完全数据对数似然 $p(\\mathbf{S}^*, \\mathbf{o}_{1:T} \\mid \\boldsymbol{\\theta})$，但边际对数似然 $p(\\mathbf{o}_{1:T} \\mid \\boldsymbol{\\theta})$ 可能会减小。\n\n此陈述中的两个主张都是错误的。\n\n**对 E 的裁定**：**错误**。", "answer": "$$\\boxed{A}$$"}]}