{"hands_on_practices": [{"introduction": "我们从一个基础问题开始我们的动手实践之旅：为一个一阶自回归（AR(1)）过程设计一个单步线性预测器。这个练习至关重要，因为它要求您直接从统计定义出发，推导维纳-霍夫方程的各个组成部分 [@problem_id:2888998]。通过解决这个最简单的案例，您将为正交性原理以及它如何导出最优滤波器建立坚实的直觉。", "problem": "考虑一个由一阶自回归递推 $x[n] = a\\,x[n-1] + w[n]$ 定义的广义平稳、零均值的离散时间随机过程，其中 $|a| < 1$，且 $w[n]$ 是一个零均值、方差为 $\\sigma_{w}^{2}$ 的白随机过程，并与所有 $k \\leq n-1$ 的 $\\{x[k]\\}$ 不相关。你需要基于单个回归量 $x[n-1]$，为 $x[n]$ 设计一个因果、M=1阶的线性最小均方误差（LMMSE）单步预测器。也就是说，考虑估计器 $\\hat{x}[n] = h\\,x[n-1]$，并对标量系数 $h$ 最小化 $\\mathbb{E}\\{(x[n]-\\hat{x}[n])^{2}\\}$。\n\n仅从自相关、互相关、平稳性的定义以及给定的自回归模型出发，执行以下操作：\n\n- 以 $a$ 和 $\\sigma_{w}^{2}$ 为参数，用闭式形式推导标量输入自相关矩阵 $R$（对于 $M=1$，该矩阵为 $1 \\times 1$）。\n- 求解 $M=1$ 时的 Wiener–Hopf 范式方程，以 $a$ 和 $\\sigma_{w}^{2}$ 为参数，明确地以闭式形式求得最优系数 $h$。\n\n将你的最终答案表示为一个单行矩阵，其两个元素按顺序分别为标量 $R$ 和最优标量 $h$。不需要数值近似；请提供精确的闭式表达式。", "solution": "所给出的问题是优化线性估计理论中的一个标准练习，其设置是合理的、有科学依据的且内部一致的。这是一个有效的问题。我们将着手进行解答。\n\n目标是找到单步线性预测器 $\\hat{x}[n] = h\\,x[n-1]$ 的最优标量系数 $h$，以最小化均方误差（MSE），其定义为 $J(h) = \\mathbb{E}\\{(x[n]-\\hat{x}[n])^{2}\\}$。过程 $x[n]$ 是一个一阶自回归（AR(1)）过程，由 $x[n] = a\\,x[n-1] + w[n]$ 给出，其中 $|a| < 1$，并且 $w[n]$ 是零均值白噪声，其方差为 $\\sigma_{w}^{2}$，与过程 $x[k]$ 的过去值（对于 $k \\le n-1$）不相关。\n\n最优滤波器系数可以通过求解 Wiener-Hopf 范式方程 $R\\mathbf{h} = \\mathbf{p}$ 得到。对于指定的问题，我们有一个单抽头预测器，因此阶数 $M=1$。因此，滤波器系数向量 $\\mathbf{h}$ 是一个标量 $h$，输入自相关矩阵 $R$ 是一个 $1 \\times 1$ 矩阵（一个标量），互相关向量 $\\mathbf{p}$ 也是一个标量 $p$。\n\n因此，标量 Wiener-Hopf 方程为 $Rh=p$。\n\n首先，我们必须推导标量自相关矩阵 $R$ 的表达式。对于输入为 $x[n-1]$ 的 $M=1$ 阶预测器，$R$ 定义为：\n$$R = \\mathbb{E}\\{x[n-1]x[n-1]\\} = \\mathbb{E}\\{x[n-1]^2\\}$$\n由于给定过程 $x[n]$ 是广义平稳的（WSS），其自相关函数 $r_{xx}[k] = \\mathbb{E}\\{x[n]x[n-k]\\}$ 与 $n$ 无关，仅取决于时延 $k$。过程的方差是恒定的，因此 $\\mathbb{E}\\{x[n-1]^2\\} = \\mathbb{E}\\{x[n]^2\\} = r_{xx}[0]$。我们来求 $r_{xx}[0]$。\n从过程的定义出发：\n$$x[n] = a\\,x[n-1] + w[n]$$\n我们计算方差：\n$$r_{xx}[0] = \\mathbb{E}\\{x[n]^2\\} = \\mathbb{E}\\{[a\\,x[n-1] + w[n]]^2\\}$$\n$$r_{xx}[0] = \\mathbb{E}\\{a^2 x[n-1]^2 + 2a\\,x[n-1]w[n] + w[n]^2\\}$$\n利用期望算子的线性性质：\n$$r_{xx}[0] = a^2 \\mathbb{E}\\{x[n-1]^2\\} + 2a\\,\\mathbb{E}\\{x[n-1]w[n]\\} + \\mathbb{E}\\{w[n]^2\\}$$\n我们现在使用给定的性质：\n$1$. 平稳性意味着 $\\mathbb{E}\\{x[n-1]^2\\} = r_{xx}[0]$。\n$2$. 噪声方差为 $\\mathbb{E}\\{w[n]^2\\} = \\sigma_w^2$。\n$3$. 噪声 $w[n]$ 与 $k \\le n-1$ 的 $x[k]$ 不相关，这意味着 $\\mathbb{E}\\{x[n-1]w[n]\\} = 0$。\n\n将这些代入 $r_{xx}[0]$ 的方程中：\n$$r_{xx}[0] = a^2 r_{xx}[0] + 2a(0) + \\sigma_w^2$$\n$$r_{xx}[0](1 - a^2) = \\sigma_w^2$$\n因为 $|a| < 1$，我们知道 $1-a^2 \\neq 0$，所以我们可以解出 $r_{xx}[0]$：\n$$r_{xx}[0] = \\frac{\\sigma_w^2}{1 - a^2}$$\n这就是标量自相关矩阵 $R$ 的表达式。\n$$R = r_{xx}[0] = \\frac{\\sigma_w^2}{1 - a^2}$$\n\n接下来，我们推导标量互相关 $p$ 的表达式。它被定义为期望信号 $x[n]$ 和滤波器输入 $x[n-1]$ 之间的相关性。\n$$p = \\mathbb{E}\\{x[n]x[n-1]\\}$$\n根据广义平稳过程的自相关函数定义，这就是 $r_{xx}[1]$。我们计算这个值：\n$$p = r_{xx}[1] = \\mathbb{E}\\{x[n]x[n-1]\\} = \\mathbb{E}\\{[a\\,x[n-1] + w[n]]x[n-1]\\}$$\n$$p = \\mathbb{E}\\{a\\,x[n-1]^2 + w[n]x[n-1]\\}$$\n根据期望的线性性质：\n$$p = a\\,\\mathbb{E}\\{x[n-1]^2\\} + \\mathbb{E}\\{w[n]x[n-1]\\}$$\n使用与之前相同的性质：$\\mathbb{E}\\{x[n-1]^2\\} = r_{xx}[0]$ 且 $\\mathbb{E}\\{w[n]x[n-1]\\} = 0$。\n$$p = a\\,r_{xx}[0] + 0 = a\\,r_{xx}[0]$$\n代入 $r_{xx}[0]$ 的表达式：\n$$p = a \\left(\\frac{\\sigma_w^2}{1 - a^2}\\right)$$\n\n最后，我们求解标量 Wiener-Hopf 方程 $Rh = p$ 以得到最优系数 $h$：\n$$\\left(\\frac{\\sigma_w^2}{1 - a^2}\\right) h = a \\left(\\frac{\\sigma_w^2}{1 - a^2}\\right)$$\n假设一个非平凡过程，其中 $\\sigma_w^2 > 0$，我们可以将等式两边同时除以非零量 $\\frac{\\sigma_w^2}{1 - a^2}$。这得出：\n$$h = a$$\n这个结果是正确且直观的。对于一个 AR(1) 过程，基于前一个样本的最佳线性预测器使用了已知的自回归系数。\n\n问题要求将标量 $R$ 和最优标量 $h$ 报告为一个单行矩阵。\n第一个元素是 $R = \\frac{\\sigma_{w}^{2}}{1 - a^{2}}$。\n第二个元素是 $h = a$。", "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n\\frac{\\sigma_{w}^{2}}{1 - a^{2}} & a\n\\end{pmatrix}\n}\n$$", "id": "2888998"}, {"introduction": "在掌握了基础知识之后，接下来的练习要求您设计一个二阶维纳滤波器。在这里，我们从简单的预测问题扩展到一个更普遍的、涉及两个不同随机过程的估计问题 [@problem_id:2888953]。这个实践将巩固您对以完整矩阵形式构建和求解维纳-霍夫方程的理解，为您处理更高阶滤波器设计提供关键经验。", "problem": "考虑两个联合宽平稳、零均值、实值的离散时间随机过程 $x[n]$ 和 $d[n]$。您需要根据 $x[n]$ 的最近两个样本，即 $x[n]$ 和 $x[n-1]$，来构成 $d[n]$ 的最佳线性均方估计，即\n$$\n\\hat{d}[n] = h_{0}\\,x[n] + h_{1}\\,x[n-1],\n$$\n其中 $h_{0}$ 和 $h_{1}$ 是待确定的实数滤波器系数。令 $M=2$ 表示有限冲激响应滤波器中的抽头数。输入自相关和期望-输入互相关由下式指定：\n$$\nR_{xx}[\\tau] = \\alpha^{|\\tau|}, \\quad R_{dx}[\\tau] = \\beta\\,\\alpha^{|\\tau|},\n$$\n对所有整数延迟 $\\tau$ 成立，其中 $\\alpha \\in (-1,1)$ 且 $\\beta \\in \\mathbb{R}$。假设在这些条件下，由正交原理产生的正规方程是适定的。\n\n从均方误差和最佳线性估计的正交原理的定义出发，推导出用自相关和互相关函数表示最优系数的方程组。然后，利用给定的 $R_{xx}[\\tau]$ 和 $R_{dx}[\\tau]$，构建输入向量 $[x[n],\\,x[n-1]]^{\\top}$ 的 $2 \\times 2$ 自相关矩阵 $R$，以及 $[x[n],\\,x[n-1]]^{\\top}$ 和 $d[n]$ 之间的 $2 \\times 1$ 互相关向量 $p$，并求解得到的线性方程组以获得最优系数向量 $h = [h_{0},\\,h_{1}]^{\\top}$。\n\n将最终答案表示为单个行向量 $\\begin{pmatrix} h_{0} & h_{1} \\end{pmatrix}$。不需要进行数值近似或舍入。", "solution": "在尝试求解之前，对所述问题进行验证。\n\n步骤1：提取已知条件\n- 给定两个联合宽平稳（WSS）、零均值、实值的离散时间随机过程 $x[n]$ 和 $d[n]$。\n- $d[n]$ 的线性估计形式为 $\\hat{d}[n] = h_{0}\\,x[n] + h_{1}\\,x[n-1]$。\n- 滤波器抽头数为 $M=2$。系数 $h_{0}$ 和 $h_{1}$ 是实数。\n- 输入自相关函数为 $R_{xx}[\\tau] = E[x[n+\\tau]x[n]] = \\alpha^{|\\tau|}$。\n- 期望-输入互相关函数为 $R_{dx}[\\tau] = E[d[n+\\tau]x[n]] = \\beta\\,\\alpha^{|\\tau|}$。\n- 参数约束为 $\\alpha \\in (-1,1)$ 和 $\\beta \\in \\mathbb{R}$。\n- 给定正规方程是适定的。\n\n步骤2：使用提取的已知条件进行验证\n- **科学依据：**该问题是数字信号处理中维纳滤波理论的一个标准应用。自相关函数 $R_{xx}[\\tau] = \\alpha^{|\\tau|}$ 且 $|\\alpha| < 1$ 对应于一个稳定的1阶自回归过程，这是时间序列分析中的一个基本模型。该问题的构建基于最小均方误差原理，这是最优估计的基石。该问题是合理的。\n- **适定性：** 问题假设正规方程是适定的。我们可以验证这一点。自相关矩阵 $R$ 是由 $R_{xx}[\\tau]$ 构成的托普利茨矩阵。对于 $M=2$，其行列式为 $R_{xx}[0]^2 - R_{xx}[1]^2 = (\\alpha^0)^2 - (\\alpha^1)^2 = 1 - \\alpha^2$。由于 $\\alpha \\in (-1,1)$，所以 $\\alpha^2 < 1$，行列式 $1 - \\alpha^2$ 严格为正。因此，该矩阵是正定的和可逆的，保证了唯一解的存在。该问题是适定的。\n- **客观性：** 问题使用精确的数学语言和定义陈述，没有任何主观性或歧义。\n\n步骤3：结论与行动\n该问题有效。我们继续推导解答。\n\n目标是找到最优滤波器系数 $h_0$ 和 $h_1$，以最小化定义为 $J$ 的均方误差（MSE）。\n$$\nJ = E[(d[n] - \\hat{d}[n])^2]\n$$\n代入估计 $\\hat{d}[n]$ 的表达式：\n$$\nJ(h_0, h_1) = E\\left[\\left(d[n] - \\left(h_0 x[n] + h_1 x[n-1]\\right)\\right)^2\\right]\n$$\n根据正交原理，当且仅当误差信号 $e[n] = d[n] - \\hat{d}[n]$ 与用于构成估计的每个输入样本正交时，均方误差 $J$ 最小。这给出了一个由两个线性方程组成的方程组：\n$$\nE[e[n]\\,x[n]] = 0\n$$\n$$\nE[e[n]\\,x[n-1]] = 0\n$$\n将 $e[n]$ 的表达式代入这两个方程，得到：\n$$\nE[(d[n] - h_0 x[n] - h_1 x[n-1]) x[n]] = 0\n$$\n$$\nE[(d[n] - h_0 x[n] - h_1 x[n-1]) x[n-1]] = 0\n$$\n根据期望算子的线性性质，我们展开这些方程：\n$$\nE[d[n]x[n]] - h_0 E[x[n]x[n]] - h_1 E[x[n-1]x[n]] = 0\n$$\n$$\nE[d[n]x[n-1]] - h_0 E[x[n]x[n-1]] - h_1 E[x[n-1]x[n-1]] = 0\n$$\n这些方程可以用给定的自相关和互相关函数表示。我们使用定义 $R_{dx}[\\tau] = E[d[n]x[n-\\tau]]$ 和 $R_{xx}[\\tau] = E[x[n]x[n-\\tau]]$。注意，对于实数宽平稳过程，$R_{xx}[\\tau] = R_{xx}[-\\tau]$。\n方程组变为：\n$$\nR_{dx}[0] - h_0 R_{xx}[0] - h_1 R_{xx}[-1] = 0\n$$\n$$\nR_{dx}[1] - h_0 R_{xx}[1] - h_1 R_{xx}[0] = 0\n$$\n重新整理，将未知系数 $h_0$ 和 $h_1$ 放在一边，我们得到正规方程，也称为离散时间情况下的维纳-霍夫方程：\n$$\nh_0 R_{xx}[0] + h_1 R_{xx}[1] = R_{dx}[0]\n$$\n$$\nh_0 R_{xx}[1] + h_1 R_{xx}[0] = R_{dx}[1]\n$$\n这个线性方程组可以写成矩阵形式 $R h = p$，其中 $h = [h_0, h_1]^{\\top}$ 是最优系数向量，$R$ 是输入向量 $[x[n], x[n-1]]^{\\top}$ 的 $2 \\times 2$ 自相关矩阵，$p$ 是期望信号 $d[n]$ 和输入向量之间的 $2 \\times 1$ 互相关向量。\n$R$ 的元素由 $R_{ij} = E[x[n-i]x[n-j]] = R_{xx}[j-i]$ 给出，其中 $i,j \\in \\{0, 1\\}$。\n$$\nR = \\begin{pmatrix} R_{xx}[0] & R_{xx}[1] \\\\ R_{xx}[-1] & R_{xx}[0] \\end{pmatrix} = \\begin{pmatrix} R_{xx}[0] & R_{xx}[1] \\\\ R_{xx}[1] & R_{xx}[0] \\end{pmatrix}\n$$\n$p$ 的元素由 $p_i = E[d[n]x[n-i]] = R_{dx}[i]$ 给出，其中 $i \\in \\{0, 1\\}$。\n$$\np = \\begin{pmatrix} R_{dx}[0] \\\\ R_{dx}[1] \\end{pmatrix}\n$$\n现在，我们代入指定的相关函数 $R_{xx}[\\tau] = \\alpha^{|\\tau|}$ 和 $R_{dx}[\\tau] = \\beta\\alpha^{|\\tau|}$：\n$$\nR = \\begin{pmatrix} \\alpha^{|0|} & \\alpha^{|1|} \\\\ \\alpha^{|1|} & \\alpha^{|0|} \\end{pmatrix} = \\begin{pmatrix} 1 & \\alpha \\\\ \\alpha & 1 \\end{pmatrix}\n$$\n$$\np = \\begin{pmatrix} \\beta\\alpha^{|0|} \\\\ \\beta\\alpha^{|1|} \\end{pmatrix} = \\begin{pmatrix} \\beta \\\\ \\beta\\alpha \\end{pmatrix}\n$$\n待求解的线性方程组是：\n$$\n\\begin{pmatrix} 1 & \\alpha \\\\ \\alpha & 1 \\end{pmatrix} \\begin{pmatrix} h_0 \\\\ h_1 \\end{pmatrix} = \\begin{pmatrix} \\beta \\\\ \\beta\\alpha \\end{pmatrix}\n$$\n系数向量 $h$ 的解由 $h = R^{-1} p$ 给出。首先，我们计算矩阵 $R$ 的逆。 $R$ 的行列式是 $\\det(R) = (1)(1) - (\\alpha)(\\alpha) = 1 - \\alpha^2$。\n$$\nR^{-1} = \\frac{1}{\\det(R)} \\begin{pmatrix} 1 & -\\alpha \\\\ -\\alpha & 1 \\end{pmatrix} = \\frac{1}{1-\\alpha^2} \\begin{pmatrix} 1 & -\\alpha \\\\ -\\alpha & 1 \\end{pmatrix}\n$$\n现在，我们将 $R^{-1}$ 乘以 $p$ 来求 $h$：\n$$\n\\begin{pmatrix} h_0 \\\\ h_1 \\end{pmatrix} = \\frac{1}{1-\\alpha^2} \\begin{pmatrix} 1 & -\\alpha \\\\ -\\alpha & 1 \\end{pmatrix} \\begin{pmatrix} \\beta \\\\ \\beta\\alpha \\end{pmatrix}\n$$\n$$\n\\begin{pmatrix} h_0 \\\\ h_1 \\end{pmatrix} = \\frac{\\beta}{1-\\alpha^2} \\begin{pmatrix} 1 & -\\alpha \\\\ -\\alpha & 1 \\end{pmatrix} \\begin{pmatrix} 1 \\\\ \\alpha \\end{pmatrix}\n$$\n我们进行矩阵-向量乘法：\n$$\n\\begin{pmatrix} h_0 \\\\ h_1 \\end{pmatrix} = \\frac{\\beta}{1-\\alpha^2} \\begin{pmatrix} (1)(1) + (-\\alpha)(\\alpha) \\\\ (-\\alpha)(1) + (1)(\\alpha) \\end{pmatrix} = \\frac{\\beta}{1-\\alpha^2} \\begin{pmatrix} 1-\\alpha^2 \\\\ -\\alpha + \\alpha \\end{pmatrix} = \\frac{\\beta}{1-\\alpha^2} \\begin{pmatrix} 1-\\alpha^2 \\\\ 0 \\end{pmatrix}\n$$\n这可以简化为：\n$$\n\\begin{pmatrix} h_0 \\\\ h_1 \\end{pmatrix} = \\begin{pmatrix} \\beta \\\\ 0 \\end{pmatrix}\n$$\n因此，最优滤波器系数为 $h_0 = \\beta$ 和 $h_1 = 0$。得到的最优估计为 $\\hat{d}[n] = \\beta x[n]$。这个结果是特定关系 $R_{dx}[\\tau] = \\beta R_{xx}[\\tau]$ 的一个推论，该关系意味着 $d[n]$ 中与过程 $x[n]$ 相关的分量只是一个缩放版本，即 $\\beta x[n]$。因此，从逻辑上讲，最优线性滤波器简化为对最近的输入样本 $x[n]$ 的简单缩放，而没有来自过去样本（如 $x[n-1]$）的贡献。\n\n最终答案要求以行向量 $\\begin{pmatrix} h_0 & h_1 \\end{pmatrix}$ 的形式表示。", "answer": "$$\n\\boxed{\\begin{pmatrix} \\beta & 0 \\end{pmatrix}}\n$$", "id": "2888953"}, {"introduction": "我们最后的实践聚焦于一个关键的现实世界挑战：数值不稳定性。该问题引入了对角加载（Tikhonov regularization）的概念，作为一种改善自相关矩阵条件数的方法 [@problem_id:2888981]。通过求解正则化滤波器并分析其均方误差（Mean Squared Error, MSE），您将对基本的偏差-方差权衡获得直接的洞察，这是现代信号处理和机器学习的基石。", "problem": "考虑一个零均值、宽平稳 (WSS) 标量过程 $x(n)$，它由一阶自回归模型 $x(n) = a\\,x(n-1) + u(n)$ 生成，其中 $|a|<1$ 且 $u(n)$ 是一个与 $x(n-1)$ 无关的零均值白过程。假设 $x(n)$ 已经过归一化，使得 $\\mathbb{E}\\{x(n)^2\\} = 1$。对于此模型，自相关为 $r_{k} = \\mathbb{E}\\{x(n)x(n-k)\\} = a^{|k|}$。\n\n您观察二维回归量 $x(n) = [x(n),\\,x(n-1)]^{\\top}$，并希望使用一个二抽头滤波器 $w \\in \\mathbb{R}^{2}$ 来线性估计期望信号 $d(n) = x(n-1)$，该滤波器可以最小化均方误差 (MSE)，其中 MSE 定义为 $J(w) = \\mathbb{E}\\{(d(n) - w^{\\top}x(n))^{2}\\}$。从正交性原理以及自相关矩阵和互相关向量的定义出发，可以使用由 $r_{k}$ 导出的托普利兹 (Toeplitz) 矩阵结构来构建未正则化的正规方程。\n\n为改善数值条件，您应用了对角加载（一种预处理形式），加载参数为 $\\lambda>0$，得到修正后的系统 $(R + \\lambda I) w_{\\lambda} = p$，其中 $R$ 是 $x(n)$ 的 $2\\times 2$ 托普利兹 (Toeplitz) 自相关矩阵，$p$ 是 $x(n)$ 和 $d(n)$ 之间的 $2\\times 1$ 互相关向量。\n\n任务：\n1. 仅使用 WSS 过程的性质和正交性原理，用 $a$ 符号化地构建 $R$ 和 $p$，并写出对角加载系统 $(R + \\lambda I) w_{\\lambda} = p$（对于 $\\lambda>0$）。\n2. 求解 $w_{\\lambda}$，使其作为 $a$ 和 $\\lambda$ 的函数。\n3. 从定义 $J(w) = \\mathbb{E}\\{(d(n) - w^{\\top}x(n))^{2}\\}$ 出发，且不使用任何快捷公式，推导对角加载 MSE $J(\\lambda) \\triangleq J(w_{\\lambda})$ 的闭式表达式，用 $a$ 和 $\\lambda$ 表示。将您的结果简化为关于 $a$ 和 $\\lambda$ 的单个有理表达式。\n\n根据您的表达式，简要解释对角加载如何修正托普利兹 (Toeplitz) 系统并影响最优性和 MSE。您的最终答案必须是 $J(\\lambda)$ 关于 $a$ 和 $\\lambda$ 的单个简化解析表达式。无需数值四舍五入，也无需单位。", "solution": "所提出的问题具有科学依据，是适定的，并包含唯一解所需的所有信息。这是最优线性估计理论中的一个标准练习。其中 $x(n)$ 被用来同时表示一个标量过程和一个向量回归量的轻微符号歧义可以通过上下文解决。为清晰起见，回归向量将表示为 $\\mathbf{x}(n) = [x(n), x(n-1)]^{\\top}$。我们继续进行解答。\n\n问题要求完成三个任务，然后进行简要解释。\n\n任务1：构建对角加载系统。\n\n自相关矩阵 $R$ 定义为 $R = \\mathbb{E}\\{\\mathbf{x}(n)\\mathbf{x}(n)^{\\top}\\}$。回归向量为 $\\mathbf{x}(n) = \\begin{pmatrix} x(n) \\\\ x(n-1) \\end{pmatrix}$。\n$$\nR = \\mathbb{E}\\left\\{ \\begin{pmatrix} x(n) \\\\ x(n-1) \\end{pmatrix} \\begin{pmatrix} x(n) & x(n-1) \\end{pmatrix} \\right\\} = \\mathbb{E}\\left\\{ \\begin{pmatrix} x(n)^2 & x(n)x(n-1) \\\\ x(n-1)x(n) & x(n-1)^2 \\end{pmatrix} \\right\\}\n$$\n通过对每个元素取期望，并使用宽平稳 (WSS) 属性和给定的自相关函数 $r_{k} = \\mathbb{E}\\{x(m)x(m-k)\\} = a^{|k|}$，以及归一化条件 $r_0 = \\mathbb{E}\\{x(n)^2\\}=1$：\n$$\nR = \\begin{pmatrix} \\mathbb{E}\\{x(n)^2\\} & \\mathbb{E}\\{x(n)x(n-1)\\} \\\\ \\mathbb{E}\\{x(n-1)x(n)\\} & \\mathbb{E}\\{x(n-1)^2\\} \\end{pmatrix} = \\begin{pmatrix} r_0 & r_1 \\\\ r_1 & r_0 \\end{pmatrix} = \\begin{pmatrix} 1 & a \\\\ a & 1 \\end{pmatrix}\n$$\n互相关向量 $p$ 定义为 $p = \\mathbb{E}\\{\\mathbf{x}(n)d(n)\\}$，其中期望信号为 $d(n) = x(n-1)$。\n$$\np = \\mathbb{E}\\left\\{ \\begin{pmatrix} x(n) \\\\ x(n-1) \\end{pmatrix} x(n-1) \\right\\} = \\begin{pmatrix} \\mathbb{E}\\{x(n)x(n-1)\\} \\\\ \\mathbb{E}\\{x(n-1)^2\\} \\end{pmatrix} = \\begin{pmatrix} r_1 \\\\ r_0 \\end{pmatrix} = \\begin{pmatrix} a \\\\ 1 \\end{pmatrix}\n$$\n因此，对角加载系统 $(R + \\lambda I) w_{\\lambda} = p$ 为：\n$$\n\\left( \\begin{pmatrix} 1 & a \\\\ a & 1 \\end{pmatrix} + \\lambda \\begin{pmatrix} 1 & 0 \\\\ 0 & 1 \\end{pmatrix} \\right) w_{\\lambda} = \\begin{pmatrix} a \\\\ 1 \\end{pmatrix}\n$$\n$$\n\\begin{pmatrix} 1+\\lambda & a \\\\ a & 1+\\lambda \\end{pmatrix} w_{\\lambda} = \\begin{pmatrix} a \\\\ 1 \\end{pmatrix}\n$$\n\n任务2：求解 $w_{\\lambda}$。\n\n为了求得 $w_{\\lambda}$，我们必须对矩阵 $(R+\\lambda I)$ 求逆。设此矩阵为 $A = \\begin{pmatrix} 1+\\lambda & a \\\\ a & 1+\\lambda \\end{pmatrix}$。\n其行列式为 $\\det(A) = (1+\\lambda)^2 - a^2$。其逆矩阵为 $A^{-1} = \\frac{1}{(1+\\lambda)^2 - a^2} \\begin{pmatrix} 1+\\lambda & -a \\\\ -a & 1+\\lambda \\end{pmatrix}$。\n解为 $w_{\\lambda} = A^{-1}p$：\n$$\nw_{\\lambda} = \\frac{1}{(1+\\lambda)^2 - a^2} \\begin{pmatrix} 1+\\lambda & -a \\\\ -a & 1+\\lambda \\end{pmatrix} \\begin{pmatrix} a \\\\ 1 \\end{pmatrix} = \\frac{1}{(1+\\lambda)^2 - a^2} \\begin{pmatrix} a(1+\\lambda) - a \\\\ -a^2 + (1+\\lambda) \\end{pmatrix}\n$$\n$$\nw_{\\lambda} = \\frac{1}{(1+\\lambda)^2 - a^2} \\begin{pmatrix} a\\lambda \\\\ 1 - a^2 + \\lambda \\end{pmatrix}\n$$\n\n任务3：推导 MSE $J(\\lambda)$ 的闭式表达式。\n\nMSE 由 $J(w) = \\mathbb{E}\\{(d(n) - w^{\\top}\\mathbf{x}(n))^{2}\\}$ 给出。展开此式可得一般二次型：\n$$\nJ(w) = \\mathbb{E}\\{d(n)^2\\} - 2w^{\\top}\\mathbb{E}\\{\\mathbf{x}(n)d(n)\\} + w^{\\top}\\mathbb{E}\\{\\mathbf{x}(n)\\mathbf{x}(n)^{\\top}\\}w = \\sigma_d^2 - 2w^{\\top}p + w^{\\top}Rw\n$$\n这里，$\\sigma_d^2 = \\mathbb{E}\\{d(n)^2\\} = \\mathbb{E}\\{x(n-1)^2\\} = r_0 = 1$。\n最优的未正则化维纳 (Wiener) 滤波器解 $w_o$ 最小化 $J(w)$，由 $Rw_o=p$ 给出。最小 MSE 为 $J_{min} = J(w_o) = \\sigma_d^2 - p^{\\top}w_o$。\n在这个问题中，最优解通过在 $w_{\\lambda}$ 的表达式中设置 $\\lambda=0$ 得到：\n$$\nw_o = w_{\\lambda=0} = \\frac{1}{1-a^2} \\begin{pmatrix} 0 \\\\ 1-a^2 \\end{pmatrix} = \\begin{pmatrix} 0 \\\\ 1 \\end{pmatrix}\n$$\n这是一个直观的结果，因为从 $[x(n), x(n-1)]^{\\top}$ 估计 $d(n)=x(n-1)$ 可以通过选择第二个分量来完美实现。最小 MSE 为：\n$$\nJ_{min} = J(w_o) = 1 - p^{\\top}w_o = 1 - \\begin{pmatrix} a & 1 \\end{pmatrix} \\begin{pmatrix} 0 \\\\ 1 \\end{pmatrix} = 1 - 1 = 0\n$$\n正则化解 $w_{\\lambda}$ 的 MSE 是 $J(\\lambda) = J(w_\\lambda)$。这可以表示为最小 MSE 和由于滤波器失配导致的超额 MSE 项之和：\n$J(\\lambda) = J_{min} + (w_{\\lambda}-w_o)^{\\top}R(w_{\\lambda}-w_o)$。由于 $J_{min}=0$：\n$$\nJ(\\lambda) = (w_{\\lambda}-w_o)^{\\top}R(w_{\\lambda}-w_o)\n$$\n首先，我们求滤波器失配向量 $w_{\\lambda}-w_o$：\n$$\nw_{\\lambda}-w_o = \\frac{1}{(1+\\lambda)^2-a^2} \\begin{pmatrix} a\\lambda \\\\ 1 - a^2 + \\lambda \\end{pmatrix} - \\begin{pmatrix} 0 \\\\ 1 \\end{pmatrix} = \\begin{pmatrix} \\frac{a\\lambda}{(1+\\lambda)^2-a^2} \\\\ \\frac{1-a^2+\\lambda - ((1+\\lambda)^2-a^2)}{(1+\\lambda)^2-a^2} \\end{pmatrix}\n$$\n第二个分量可简化为 $\\frac{1-a^2+\\lambda - (1+2\\lambda+\\lambda^2-a^2)}{(1+\\lambda)^2-a^2} = \\frac{-\\lambda-\\lambda^2}{(1+\\lambda)^2-a^2} = \\frac{-\\lambda(1+\\lambda)}{(1+\\lambda)^2-a^2}$。\n因此，失配向量是：\n$$\nw_{\\lambda}-w_o = \\frac{\\lambda}{(1+\\lambda)^2-a^2} \\begin{pmatrix} a \\\\ -(1+\\lambda) \\end{pmatrix}\n$$\n现在我们计算二次型。令 $D = (1+\\lambda)^2-a^2$。\n$$\nJ(\\lambda) = \\left(\\frac{\\lambda}{D}\\right)^2 \\begin{pmatrix} a & -(1+\\lambda) \\end{pmatrix} \\begin{pmatrix} 1 & a \\\\ a & 1 \\end{pmatrix} \\begin{pmatrix} a \\\\ -(1+\\lambda) \\end{pmatrix}\n$$\n矩阵乘积为：\n$$\n\\begin{pmatrix} a & -(1+\\lambda) \\end{pmatrix} \\begin{pmatrix} 1 & a \\\\ a & 1 \\end{pmatrix} \\begin{pmatrix} a \\\\ -(1+\\lambda) \\end{pmatrix} = \\begin{pmatrix} a-a(1+\\lambda) & a^2-(1+\\lambda) \\end{pmatrix} \\begin{pmatrix} a \\\\ -(1+\\lambda) \\end{pmatrix}\n$$\n$$\n= \\begin{pmatrix} -a\\lambda & a^2-1-\\lambda \\end{pmatrix} \\begin{pmatrix} a \\\\ -(1+\\lambda) \\end{pmatrix} = -a^2\\lambda - (a^2-1-\\lambda)(1+\\lambda)\n$$\n$$\n= -a^2\\lambda - (a^2(1+\\lambda) - (1+\\lambda)^2) = -a^2\\lambda - a^2 - a^2\\lambda + (1+\\lambda)^2\n$$\n$$\n= (1+\\lambda)^2 - a^2 - 2a^2\\lambda\n$$\n将此代回 $J(\\lambda)$ 的表达式中：\n$$\nJ(\\lambda) = \\left(\\frac{\\lambda}{D}\\right)^2 (D - 2a^2\\lambda) = \\frac{\\lambda^2(D - 2a^2\\lambda)}{D^2}\n$$\n用 $D$ 的定义替换，我们得到最终的简化有理表达式：\n$$\nJ(\\lambda) = \\frac{\\lambda^2((1+\\lambda)^2 - a^2 - 2a^2\\lambda)}{((1+\\lambda)^2 - a^2)^2}\n$$\n分子可以重写为 $\\lambda^2((1+\\lambda)^2 - a^2(1+2\\lambda))$。\n\n效果解释：\n对角加载通过将正常数 $\\lambda$ 加到自相关矩阵 $R$ 的对角元素上，来修正正规方程。这个操作，$R \\to R+\\lambda I$，将矩阵的特征值增加了 $\\lambda$。如果 $R$ 是病态的（即具有很大的条件数，当 $|a| \\to 1$ 时会发生这种情况），这种平移会使矩阵 $R+\\lambda I$ 的条件更好，从而提高 $w_{\\lambda}$ 解的数值稳定性。\n\n这种稳定性是以牺牲最优性为代价的。得到的滤波器 $w_{\\lambda}$ 并不是原始均方误差 $J(w)$ 的最小化器，而是正则化代价函数 $J(w) + \\lambda\\|w\\|^2$ 的最小化器。这给估计引入了偏差。因此，对于任何 $\\lambda>0$，使用正则化滤波器所达到的 MSE $J(\\lambda)$ 严格大于可能的最小 MSE $J_{min}=0$。从推导的表达式可以看出，当 $\\lambda > 0$ 时 $J(\\lambda) > 0$，且当 $\\lambda \\to 0$ 时 $J(\\lambda) \\to 0$。这说明了正则化中基本的偏差-方差权衡：人们接受一个更高的（有偏的）MSE，以换取一个范数更小、更稳定的解，这在实践中可以提高泛化性能。", "answer": "$$\n\\boxed{\\frac{\\lambda^2 ( (1+\\lambda)^2 - a^2(1+2\\lambda) )}{((1+\\lambda)^2 - a^2)^2}}\n$$", "id": "2888981"}]}