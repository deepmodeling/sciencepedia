{"hands_on_practices": [{"introduction": "在深入研究自适应算法之前，理解其理论上的“黄金标准”——维纳滤波器至关重要。该练习将演示当信号的完整统计信息（即自相关矩阵 $R$ 和互相关向量 $p$）已知时，如何直接计算出最优的滤波器权重。这个最优解为任何自适应滤波器的性能设定了基准 [@problem_id:2850046]。", "problem": "设计一个双抽头线性均衡器，用以最小化一个零均值期望标量信号 $d(n)$ 与一个线性估计 $\\hat{d}(n)=\\mathbf{w}^{\\top}\\mathbf{x}(n)$ 之间的均方误差。该线性估计由一个零均值、联合广义平稳的二维输入 $\\mathbf{x}(n)\\in\\mathbb{R}^{2}$ 构成。设输入自相关矩阵为 $R=\\mathbb{E}\\{\\mathbf{x}(n)\\mathbf{x}^{\\top}(n)\\}$，互相关向量为 $\\mathbf{p}=\\mathbb{E}\\{\\mathbf{x}(n)d(n)\\}$。假设已从数据的二阶统计量中得到 $R=\\begin{bmatrix}2&1\\\\1&2\\end{bmatrix}$ 和 $\\mathbf{p}=\\begin{bmatrix}1\\\\0\\end{bmatrix}$，且期望信号方差为 $\\sigma_{d}^{2}=\\mathbb{E}\\{d^{2}(n)\\}=1$。\n\n从基于二阶矩和正交原理的最小均方误差公式出发，确定：\n\n1. 最小化 $\\mathbb{E}\\{(d(n)-\\mathbf{w}^{\\top}\\mathbf{x}(n))^{2}\\}$ 的最优维纳解 $\\mathbf{w}_{o}\\in\\mathbb{R}^{2}$。\n\n2. 在 $\\mathbf{w}_{o}$ 处达到的最小均方误差 $J_{\\min}$。\n\n请精确表示最终数值，无需四舍五入。答案必须以精确有理数的形式给出。", "solution": "所给出的问题是统计信号处理中关于维纳滤波器推导的一个标准练习。该问题具有科学依据，提法正确，并包含了完整解答所需的所有信息。因此，它是有效的。我们继续进行推导。\n\n目标是找到最小化均方误差（MSE）$J(\\mathbf{w})$的权重向量$\\mathbf{w}$。MSE定义为期望信号$d(n)$与其估计值$\\hat{d}(n)$之间误差平方的期望值。\n估计值是输入向量$\\mathbf{x}(n)$的线性组合，由$\\hat{d}(n) = \\mathbf{w}^{\\top}\\mathbf{x}(n)$给出。误差信号为$e(n) = d(n) - \\hat{d}(n) = d(n) - \\mathbf{w}^{\\top}\\mathbf{x}(n)$。\n\nMSE代价函数$J(\\mathbf{w})$为：\n$$J(\\mathbf{w}) = \\mathbb{E}\\{e^2(n)\\} = \\mathbb{E}\\{(d(n) - \\mathbf{w}^{\\top}\\mathbf{x}(n))^2\\}$$\n展开平方项，我们得到：\n$$J(\\mathbf{w}) = \\mathbb{E}\\{d^2(n) - 2d(n)\\mathbf{w}^{\\top}\\mathbf{x}(n) + (\\mathbf{w}^{\\top}\\mathbf{x}(n))(\\mathbf{x}^{\\top}(n)\\mathbf{w})\\}$$\n利用期望算子的线性性质，上式变为：\n$$J(\\mathbf{w}) = \\mathbb{E}\\{d^2(n)\\} - 2\\mathbb{E}\\{d(n)\\mathbf{w}^{\\top}\\mathbf{x}(n)\\} + \\mathbb{E}\\{\\mathbf{w}^{\\top}\\mathbf{x}(n)\\mathbf{x}^{\\top}(n)\\mathbf{w}\\}$$\n由于$\\mathbf{w}$是一个确定性系数向量，可以将其移出期望运算：\n$$J(\\mathbf{w}) = \\mathbb{E}\\{d^2(n)\\} - 2\\mathbf{w}^{\\top}\\mathbb{E}\\{\\mathbf{x}(n)d(n)\\} + \\mathbf{w}^{\\top}\\mathbb{E}\\{\\mathbf{x}(n)\\mathbf{x}^{\\top}(n)\\}\\mathbf{w}$$\n我们已知以下二阶统计量：\n期望信号的方差：$\\sigma_d^2 = \\mathbb{E}\\{d^2(n)\\} = 1$。\n输入与期望信号之间的互相关向量：$\\mathbf{p} = \\mathbb{E}\\{\\mathbf{x}(n)d(n)\\} = \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix}$。\n输入向量的自相关矩阵：$R = \\mathbb{E}\\{\\mathbf{x}(n)\\mathbf{x}^{\\top}(n)\\} = \\begin{pmatrix} 2 & 1 \\\\ 1 & 2 \\end{pmatrix}$。\n\n将这些量代入$J(\\mathbf{w})$的表达式，得到性能曲面：\n$$J(\\mathbf{w}) = \\sigma_d^2 - 2\\mathbf{w}^{\\top}\\mathbf{p} + \\mathbf{w}^{\\top}R\\mathbf{w}$$\n为了找到最小化该二次函数的最优权重向量$\\mathbf{w}_o$，我们必须计算$J(\\mathbf{w})$关于$\\mathbf{w}$的梯度，并将其设为零向量。\n$$\\nabla_{\\mathbf{w}} J(\\mathbf{w}) = \\frac{\\mathrm{d}}{\\mathrm{d}\\mathbf{w}} (\\sigma_d^2 - 2\\mathbf{w}^{\\top}\\mathbf{p} + \\mathbf{w}^{\\top}R\\mathbf{w}) = -2\\mathbf{p} + 2R\\mathbf{w}$$\n对最优向量$\\mathbf{w}_o$将梯度设为零：\n$$-2\\mathbf{p} + 2R\\mathbf{w}_o = \\mathbf{0}$$\n这就得到了维纳-霍夫方程（Wiener-Hopf equation）：\n$$R\\mathbf{w}_o = \\mathbf{p}$$\n最优维纳解$\\mathbf{w}_o$通过求解该线性方程组得到：\n$$\\mathbf{w}_o = R^{-1}\\mathbf{p}$$\n首先，我们计算自相关矩阵$R$的逆矩阵。$R$的行列式为：\n$$\\det(R) = (2)(2) - (1)(1) = 4 - 1 = 3$$\n由于$\\det(R) \\neq 0$，逆矩阵存在。对于一个$2 \\times 2$矩阵$\\begin{pmatrix} a & b \\\\ c & d \\end{pmatrix}$，其逆矩阵为$\\frac{1}{ad-bc}\\begin{pmatrix} d & -b \\\\ -c & a \\end{pmatrix}$。\n$$R^{-1} = \\frac{1}{3}\\begin{pmatrix} 2 & -1 \\\\ -1 & 2 \\end{pmatrix} = \\begin{pmatrix} \\frac{2}{3} & -\\frac{1}{3} \\\\ -\\frac{1}{3} & \\frac{2}{3} \\end{pmatrix}$$\n现在，我们可以计算$\\mathbf{w}_o$：\n$$\\mathbf{w}_o = R^{-1}\\mathbf{p} = \\begin{pmatrix} \\frac{2}{3} & -\\frac{1}{3} \\\\ -\\frac{1}{3} & \\frac{2}{3} \\end{pmatrix} \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix} = \\begin{pmatrix} (\\frac{2}{3})(1) + (-\\frac{1}{3})(0) \\\\ (-\\frac{1}{3})(1) + (\\frac{2}{3})(0) \\end{pmatrix} = \\begin{pmatrix} \\frac{2}{3} \\\\ -\\frac{1}{3} \\end{pmatrix}$$\n这就是滤波器抽头的最优维纳解。\n\n接下来，我们确定最小均方误差$J_{\\min}$，即代价函数在$\\mathbf{w} = \\mathbf{w}_o$处的值：\n$$J_{\\min} = J(\\mathbf{w}_o) = \\sigma_d^2 - 2\\mathbf{w}_o^{\\top}\\mathbf{p} + \\mathbf{w}_o^{\\top}R\\mathbf{w}_o$$\n使用维纳-霍夫方程$R\\mathbf{w}_o = \\mathbf{p}$，我们可以将$\\mathbf{p}$代入$J_{\\min}$的表达式中：\n$$J_{\\min} = \\sigma_d^2 - 2\\mathbf{w}_o^{\\top}(R\\mathbf{w}_o) + \\mathbf{w}_o^{\\top}R\\mathbf{w}_o = \\sigma_d^2 - \\mathbf{w}_o^{\\top}R\\mathbf{w}_o$$\n或者，更直接地，将$\\mathbf{w}_o^{\\top}R = \\mathbf{p}^{\\top}$代入$J_{\\min}$的表达式中：\n$$J_{\\min} = \\sigma_d^2 - \\mathbf{p}^{\\top}\\mathbf{w}_o - \\mathbf{w}_o^{\\top}\\mathbf{p} + \\mathbf{p}^{\\top}\\mathbf{w}_o= \\sigma_d^2 - \\mathbf{w}_o^{\\top}\\mathbf{p}$$\n这是最小均方误差最常用且最简化的表达式。使用我们已有的值：\n$\\sigma_d^2 = 1$，$\\mathbf{w}_o = \\begin{pmatrix} \\frac{2}{3} \\\\ -\\frac{1}{3} \\end{pmatrix}$，及$\\mathbf{p} = \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix}$。\n$$\\mathbf{w}_o^{\\top}\\mathbf{p} = \\begin{pmatrix} \\frac{2}{3} & -\\frac{1}{3} \\end{pmatrix} \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix} = (\\frac{2}{3})(1) + (-\\frac{1}{3})(0) = \\frac{2}{3}$$\n因此，最小均方误差为：\n$$J_{\\min} = \\sigma_d^2 - \\mathbf{w}_o^{\\top}\\mathbf{p} = 1 - \\frac{2}{3} = \\frac{1}{3}$$\n最优维纳滤波器为$\\mathbf{w}_o = \\begin{pmatrix} \\frac{2}{3} \\\\ -\\frac{1}{3} \\end{pmatrix}$，最小均方误差为$J_{\\min} = \\frac{1}{3}$。", "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n\\frac{2}{3} & -\\frac{1}{3} & \\frac{1}{3}\n\\end{pmatrix}\n}\n$$", "id": "2850046"}, {"introduction": "在现实世界的应用中，我们通常无法获得计算维纳滤波器所需的精确统计信息。这个练习将介绍一种强大的替代方法——最小均方 (LMS) 算法，它仅利用当前的输入数据和误差信号，通过迭代的方式逼近最优解。通过执行单步更新，我们将掌握 LMS 算法的基本工作机制 [@problem_id:2850033]。", "problem": "一个基带通信接收机使用一个$2$抽头的有限脉冲响应自适应均衡器来减轻码间串扰。在离散时间 $n=0$ 时，均衡器的输入回归向量为 $x_0=\\begin{bmatrix}1\\\\-1\\end{bmatrix}$，期望符号为 $d_0=1$，当前系数向量为 $w_0=\\begin{bmatrix}0\\\\0\\end{bmatrix}$。该均衡器从 $w_0$ 开始，对瞬时平方误差代价函数 $J_0(w)=\\tfrac{1}{2}\\left(d_0 - x_0^{\\top}w\\right)^{2}$ 执行一步随机梯度下降，步长为 $\\mu=0.1$。定义时间 $0$ 时的先验误差为 $e^{\\text{ap}}(0)=d_0 - x_0^{\\top}w_0$，后验误差为 $e^{\\text{po}}(0)=d_0 - x_0^{\\top}w_1$，其中 $w_1$ 是经过单次梯度下降步骤后的系数向量。\n\n仅使用应用于 $J_0(w)$ 的梯度下降原理和给定数据，计算更新后的系数向量 $w_1$ 和后验误差 $e^{\\text{po}}(0)$。请将您的最终答案以单行矩阵的形式给出，其中包含三个条目，顺序为 $\\big(w_{1,1},\\,w_{1,2},\\,e^{\\text{po}}(0)\\big)$。无需进行四舍五入。", "solution": "问题陈述为随机梯度下降(SGD)算法的应用提供了一个完整且适定的场景，特别是其在自适应信号处理中作为标准的最小均方(LMS)变体。该问题在科学上是合理的，并且为求得唯一解提供了所有必要的数据。因此，该问题是有效的。\n\n任务是从离散时间 $n=0$ 时的初始向量 $w_0$ 开始，对自适应均衡器的系数向量 $w$ 执行一步更新。该更新基于最小化瞬时平方误差代价函数 $J_0(w)$：\n$$J_0(w) = \\frac{1}{2}(d_0 - x_0^{\\top}w)^{2}$$\n梯度下降更新的通用公式为：\n$$w_1 = w_0 - \\mu \\nabla_w J_0(w) \\bigg|_{w=w_0}$$\n其中 $\\mu$ 是步长，$\\nabla_w J_0(w)$ 是代价函数关于向量 $w$ 的梯度。\n\n首先，我们必须推导代价函数的梯度。设时间 $n=0$ 时的瞬时误差是 $w$ 的函数，定义为 $e_0(w) = d_0 - x_0^{\\top}w$。则代价函数为 $J_0(w) = \\frac{1}{2}e_0(w)^2$。使用向量微分的链式法则：\n$$\\nabla_w J_0(w) = \\frac{\\partial J_0}{\\partial e_0} \\nabla_w e_0(w)$$\n各个导数分别为：\n$$\\frac{\\partial J_0}{\\partial e_0} = e_0(w)$$\n$$\\nabla_w e_0(w) = \\nabla_w (d_0 - x_0^{\\top}w) = -x_0$$\n结合这些，我们得到梯度：\n$$\\nabla_w J_0(w) = e_0(w)(-x_0) = -(d_0 - x_0^{\\top}w)x_0$$\n必须在当前系数向量 $w_0$ 处计算梯度：\n$$\\nabla_w J_0(w_0) = -(d_0 - x_0^{\\top}w_0)x_0$$\n问题中将 $d_0 - x_0^{\\top}w_0$ 项定义为先验误差 $e^{\\text{ap}}(0)$。因此，梯度更新项为：\n$$\\nabla_w J_0(w_0) = -e^{\\text{ap}}(0) x_0$$\n将此代回梯度下降公式，得到此问题的特定更新规则，即LMS更新方程：\n$$w_1 = w_0 - \\mu (-e^{\\text{ap}}(0) x_0) = w_0 + \\mu e^{\\text{ap}}(0) x_0$$\n\n我们已知以下值：\n-   期望符号：$d_0 = 1$\n-   输入回归向量：$x_0 = \\begin{bmatrix} 1 \\\\ -1 \\end{bmatrix}$\n-   初始系数向量：$w_0 = \\begin{bmatrix} 0 \\\\ 0 \\end{bmatrix}$\n-   步长：$\\mu = 0.1$\n\n第一步是计算先验误差 $e^{\\text{ap}}(0)$：\n$$e^{\\text{ap}}(0) = d_0 - x_0^{\\top}w_0 = 1 - \\begin{bmatrix} 1 & -1 \\end{bmatrix}\\begin{bmatrix} 0 \\\\ 0 \\end{bmatrix} = 1 - (1 \\cdot 0 + (-1) \\cdot 0) = 1 - 0 = 1$$\n接下来，我们计算更新后的系数向量 $w_1$：\n$$w_1 = w_0 + \\mu e^{\\text{ap}}(0)x_0 = \\begin{bmatrix} 0 \\\\ 0 \\end{bmatrix} + (0.1)(1)\\begin{bmatrix} 1 \\\\ -1 \\end{bmatrix} = \\begin{bmatrix} 0 \\\\ 0 \\end{bmatrix} + \\begin{bmatrix} 0.1 \\\\ -0.1 \\end{bmatrix} = \\begin{bmatrix} 0.1 \\\\ -0.1 \\end{bmatrix}$$\n因此，更新后向量的分量为 $w_{1,1} = 0.1$ 和 $w_{1,2} = -0.1$。\n\n最后，我们计算后验误差 $e^{\\text{po}}(0)$，这是使用更新后的系数向量 $w_1$ 计算的误差：\n$$e^{\\text{po}}(0) = d_0 - x_0^{\\top}w_1$$\n代入已知值和计算出的值：\n$$e^{\\text{po}}(0) = 1 - \\begin{bmatrix} 1 & -1 \\end{bmatrix}\\begin{bmatrix} 0.1 \\\\ -0.1 \\end{bmatrix} = 1 - (1 \\cdot 0.1 + (-1) \\cdot (-0.1)) = 1 - (0.1 + 0.1) = 1 - 0.2 = 0.8$$\n所需的量为 $w_{1,1}=0.1$、$w_{1,2}=-0.1$ 和 $e^{\\text{po}}(0)=0.8$。这些量将以单行矩阵的形式呈现。", "answer": "$$\\boxed{\\begin{pmatrix} 0.1 & -0.1 & 0.8 \\end{pmatrix}}$$", "id": "2850033"}, {"introduction": "基本 LMS 算法的性能可能对输入信号的功率水平很敏感，这在某些应用中是一个缺点。本练习将探讨归一化最小均方 (NLMS) 算法，这是对 LMS 的一项重要改进，它在每一步都会动态调整学习率。该练习将演示如何执行一次 NLMS 更新，并突显其在实际应用中的鲁棒性优势 [@problem_id:2850035]。", "problem": "一个双抽头自适应滤波器被用作单通道传感场景中噪声消除的简化模型。在时间索引 $n$ 时，滤波器权重向量为 $w(n) \\in \\mathbb{R}^{2}$，输入回归量为 $x(n) \\in \\mathbb{R}^{2}$，期望信号为 $d(n) \\in \\mathbb{R}$。在时间 $n$ 的目标是最小化瞬时平方误差，定义为 $J(n) = \\tfrac{1}{2} e^{2}(n)$，其中 $e(n) = d(n) - w^{\\top}(n) x(n)$。从这个目标和关于 $w$ 的梯度 $\\nabla_{w} J(n)$ 出发，最小均方 (LMS) 方法执行一个梯度步长。归一化最小均方 (NLMS) 方法通过瞬时输入功率对此步长进行重新缩放，使其对输入幅度不变，并带有一个小的正常数正则化项以避免除以零。\n\n给定初始权重向量 $w(0) = [0, 0]^{\\top}$，步长 $\\mu = 1$，正则化项 $\\delta = 10^{-3}$，输入 $x(0) = [3, 4]^{\\top}$，以及期望响应 $d(0) = 5$，从 $J(n)$ 及其梯度的定义出发，执行一次归一化最小均方 (NLMS) 算法的更新，并计算：\n- 更新后的系数向量 $w(1)$，以及\n- 得到的后验瞬时误差 $e^{+}(0) \\equiv d(0) - w^{\\top}(1)\\,x(0)$。\n\n将您的最终答案表示为一个单行矩阵，其中按顺序包含 $w(1)$ 的两个分量，后跟 $e^{+}(0)$。无需四舍五入；请提供精确表达式。", "solution": "首先对问题陈述进行验证。\n\n**步骤 1：提取已知条件**\n- **模型：** 双抽头自适应滤波器\n- **权重向量：** $w(n) \\in \\mathbb{R}^{2}$\n- **输入回归量：** $x(n) \\in \\mathbb{R}^{2}$\n- **期望信号：** $d(n) \\in \\mathbb{R}$\n- **目标函数：** $J(n) = \\frac{1}{2} e^{2}(n)$\n- **误差信号：** $e(n) = d(n) - w^{\\top}(n) x(n)$\n- **算法：** 归一化最小均方 (NLMS)\n- **初始权重向量：** $w(0) = [0, 0]^{\\top}$\n- **步长：** $\\mu = 1$\n- **正则化项：** $\\delta = 10^{-3}$\n- **$n=0$ 时的输入：** $x(0) = [3, 4]^{\\top}$\n- **$n=0$ 时的期望响应：** $d(0) = 5$\n- **要求输出：** $w(1)$ 和 $e^{+}(0) \\equiv d(0) - w^{\\top}(1)\\,x(0)$\n\n**步骤 2：使用提取的已知条件进行验证**\n该问题具有科学依据，因为它涉及标准的 NLMS 算法，这是自适应信号处理中的一个基本课题。这是一个适定问题，为求得唯一解提供了所有必要的参数和初始条件。语言客观而精确。数据一致且完整。因此，该问题是有效的。\n\n**步骤 3：结论与行动**\n该问题有效。将提供解答。\n\n目标是执行一次归一化最小均方 (NLMS) 算法的更新，以找到更新后的权重向量 $w(1)$ 和后验误差 $e^{+}(0)$。\n\n在时间 $n$ 的瞬时代价函数是平方误差：\n$$J(n) = \\frac{1}{2} e^{2}(n) = \\frac{1}{2} (d(n) - w^{\\top}(n) x(n))^{2}$$\nNLMS 算法是随机梯度下降的一种形式。第一步是计算代价函数 $J(n)$ 相对于权重向量 $w(n)$ 的梯度。使用链式法则：\n$$\\nabla_{w} J(n) = \\frac{\\partial J(n)}{\\partial w(n)} = \\frac{\\partial J(n)}{\\partial e(n)} \\frac{\\partial e(n)}{\\partial w(n)}$$\n导数是：\n$$\\frac{\\partial J(n)}{\\partial e(n)} = e(n)$$\n$$\\frac{\\partial e(n)}{\\partial w(n)} = \\frac{\\partial}{\\partial w(n)} (d(n) - w^{\\top}(n) x(n)) = -x(n)$$\n因此，梯度是：\n$$\\nabla_{w} J(n) = -e(n) x(n)$$\n通用的随机梯度下降更新规则是 $w(n+1) = w(n) - \\alpha \\nabla_{w} J(n)$，其中 $\\alpha$ 是一个步长参数。对于 NLMS 算法，其更新规则具体定义为：\n$$w(n+1) = w(n) - \\left( \\frac{\\mu}{\\delta + \\|x(n)\\|^{2}} \\right) \\nabla_{w} J(n)$$\n代入梯度的表达式，我们得到 NLMS 的更新方程：\n$$w(n+1) = w(n) + \\frac{\\mu}{\\delta + \\|x(n)\\|^{2}} e(n) x(n)$$\n其中 $\\|x(n)\\|^{2} = x^{\\top}(n) x(n)$ 是输入向量的欧几里得范数的平方（瞬时功率）。\n\n我们被要求计算 $n=0$ 时的更新。给定的值为：\n$w(0) = \\begin{pmatrix} 0 \\\\ 0 \\end{pmatrix}$，$x(0) = \\begin{pmatrix} 3 \\\\ 4 \\end{pmatrix}$，$d(0) = 5$，$\\mu = 1$，以及 $\\delta = 10^{-3}$。\n\n首先，我们计算在时间 $n=0$ 时的先验误差：\n$$e(0) = d(0) - w^{\\top}(0) x(0) = 5 - \\begin{pmatrix} 0 & 0 \\end{pmatrix} \\begin{pmatrix} 3 \\\\ 4 \\end{pmatrix} = 5 - 0 = 5$$\n接下来，我们计算输入向量 $x(0)$ 的范数平方：\n$$\\|x(0)\\|^{2} = x^{\\top}(0) x(0) = 3^{2} + 4^{2} = 9 + 16 = 25$$\n现在我们可以计算更新后的权重向量 $w(1)$：\n$$w(1) = w(0) + \\frac{\\mu}{\\delta + \\|x(0)\\|^{2}} e(0) x(0)$$\n$$w(1) = \\begin{pmatrix} 0 \\\\ 0 \\end{pmatrix} + \\frac{1}{10^{-3} + 25} (5) \\begin{pmatrix} 3 \\\\ 4 \\end{pmatrix}$$\n项 $\\delta + \\|x(0)\\|^2$ 是 $25.001$，即 $\\frac{25001}{1000}$。更新的系数是：\n$$\\frac{5}{25.001} = \\frac{5}{25001/1000} = \\frac{5000}{25001}$$\n所以，更新后的权重向量是：\n$$w(1) = \\frac{5000}{25001} \\begin{pmatrix} 3 \\\\ 4 \\end{pmatrix} = \\begin{pmatrix} \\frac{15000}{25001} \\\\ \\frac{20000}{25001} \\end{pmatrix}$$\n更新后权重向量的分量是 $w_{1}(1) = \\frac{15000}{25001}$ 和 $w_{2}(1) = \\frac{20000}{25001}$。\n\n最后，我们计算后验误差 $e^{+}(0)$：\n$$e^{+}(0) = d(0) - w^{\\top}(1) x(0)$$\n$$e^{+}(0) = 5 - \\begin{pmatrix} \\frac{15000}{25001} & \\frac{20000}{25001} \\end{pmatrix} \\begin{pmatrix} 3 \\\\ 4 \\end{pmatrix}$$\n$$e^{+}(0) = 5 - \\left( \\frac{15000 \\cdot 3 + 20000 \\cdot 4}{25001} \\right)$$\n$$e^{+}(0) = 5 - \\left( \\frac{45000 + 80000}{25001} \\right) = 5 - \\frac{125000}{25001}$$\n$$e^{+}(0) = \\frac{5 \\cdot 25001 - 125000}{25001} = \\frac{125005 - 125000}{25001} = \\frac{5}{25001}$$\n\n要求的输出是 $w(1)$ 的两个分量和 $e^{+}(0)$ 的值。", "answer": "$$\\boxed{\\begin{pmatrix} \\frac{15000}{25001} & \\frac{20000}{25001} & \\frac{5}{25001} \\end{pmatrix}}$$", "id": "2850035"}]}