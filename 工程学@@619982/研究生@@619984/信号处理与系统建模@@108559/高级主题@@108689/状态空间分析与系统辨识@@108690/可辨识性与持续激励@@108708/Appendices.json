{"hands_on_practices": [{"introduction": "我们将通过挑战一个常见的直觉来开始我们的动手实践：更强的输入信号是否总是有利于系统辨识？本练习 [@problem_id:2876722] 证明，仅有信号能量是不够的，信号的谱丰富性至关重要。通过分析一个简单的高能量正弦输入，您将从数学上揭示为何它对于阶数大于二的系统不满足持续激励条件，从而提供一个关于不可辨识场景的坚实范例。", "problem": "考虑一个单输入单输出的离散时间有限脉冲响应系统，其阶数 $n \\geq 3$ 已知，但系数未知。设时间 $k$ 的回归量为向量 $\\varphi_{k} \\in \\mathbb{R}^{n}$，定义为 $\\varphi_{k} = \\big[u(k), u(k-1), \\dots, u(k-n+1)\\big]^{\\top}$。如果存在常数 $\\alpha > 0$ 和一个整数 $N_{0} \\geq n$，使得对于所有整数 $t$，有限时域回归格拉姆矩阵 $G_{t} = \\sum_{k=t}^{t+N_{0}-1} \\varphi_{k} \\varphi_{k}^{\\top}$ 满足 $G_{t} \\succeq \\alpha I_{n}$（其中 $I_{n}$ 是 $n \\times n$ 的单位矩阵），则称序列 $\\{u(k)\\}$ 是n阶持续激励（PE）的。评估此性质的一种等效方法是通过渐近时间平均相关矩阵 $R = \\lim_{N \\to \\infty} \\frac{1}{N} \\sum_{k=0}^{N-1} \\varphi_{k} \\varphi_{k}^{\\top}$，其中 $R$ 的正定性是n阶持续激励的必要条件。\n\n给定一个形式为 $u(k) = A \\cos(\\omega k)$ 的输入序列，其中 $A > 0$ 且频率 $\\omega \\in (0, \\pi)$ 是固定的。这类输入允许通过增加 $A$ 使每样本平均输入能量 $\\lim_{N \\to \\infty} \\frac{1}{N} \\sum_{k=0}^{N-1} u(k)^{2}$ 变得任意大，从而满足任何仅取决于总能量或平均能量的预定能量最大化目标。\n\n仅使用上述定义和基本三角恒等式，计算与此输入相关的矩阵 $R$ 的最小特征值 $\\lambda_{\\min}$ 的精确值，作为 $A$、$n$ 和 $\\omega$ 的函数。您的最终答案必须是单一的闭式表达式。无需四舍五入，也不涉及单位。此计算将建立一个反例，证明仅最大化输入能量并不能保证n阶（$n \\geq 3$）持续激励，并突显了输入信号具备频谱丰富度的必要性。", "solution": "该问题已经过验证，被认定是有效的。它具有科学依据，提法得当，且解决问题所需的所有定义均已提供。我现在将开始解答。\n\n渐近时间平均相关矩阵 $R$ 定义为\n$$R = \\lim_{N \\to \\infty} \\frac{1}{N} \\sum_{k=0}^{N-1} \\varphi_{k} \\varphi_{k}^{\\top}$$\n其中 $\\varphi_{k} = \\big[u(k), u(k-1), \\dots, u(k-n+1)\\big]^{\\top}$ 是维度为 $n$ 的回归向量。矩阵 $R$ 是一个 $n \\times n$ 矩阵，其元素（记为 $R_{ij}$，$i, j \\in \\{1, 2, \\dots, n\\}$）由下式给出\n$$R_{ij} = \\lim_{N \\to \\infty} \\frac{1}{N} \\sum_{k=0}^{N-1} u(k-i+1) u(k-j+1)$$\n输入序列由 $u(k) = A \\cos(\\omega k)$ 给出, 其中 $A > 0$ 且 $\\omega \\in (0, \\pi)$。将此代入 $R_{ij}$ 的表达式中：\n$$R_{ij} = \\lim_{N \\to \\infty} \\frac{1}{N} \\sum_{k=0}^{N-1} \\left[ A \\cos(\\omega(k-i+1)) \\right] \\left[ A \\cos(\\omega(k-j+1)) \\right]$$\n$$R_{ij} = A^2 \\lim_{N \\to \\infty} \\frac{1}{N} \\sum_{k=0}^{N-1} \\cos(\\omega k - \\omega(i-1)) \\cos(\\omega k - \\omega(j-1))$$\n我们使用积化和差三角恒等式 $\\cos(X)\\cos(Y) = \\frac{1}{2}[\\cos(X-Y) + \\cos(X+Y)]$。\n令 $X = \\omega k - \\omega(i-1)$ 且 $Y = \\omega k - \\omega(j-1)$。那么，\n$$X-Y = \\omega(j-1) - \\omega(i-1) = \\omega(j-i)$$\n$$X+Y = 2\\omega k - \\omega(i-1) - \\omega(j-1) = 2\\omega k - \\omega(i+j-2)$$\n$R_{ij}$ 的表达式变为\n$$R_{ij} = A^2 \\lim_{N \\to \\infty} \\frac{1}{2N} \\sum_{k=0}^{N-1} \\left[ \\cos(\\omega(j-i)) + \\cos(2\\omega k - \\omega(i+j-2)) \\right]$$\n我们可以将和的极限分解为极限的和：\n$$R_{ij} = \\frac{A^2}{2} \\left[ \\lim_{N \\to \\infty} \\frac{1}{N} \\sum_{k=0}^{N-1} \\cos(\\omega(j-i)) + \\lim_{N \\to \\infty} \\frac{1}{N} \\sum_{k=0}^{N-1} \\cos(2\\omega k - \\omega(i+j-2)) \\right]$$\n第一项 $\\cos(\\omega(j-i))$ 是一个关于求和索引 $k$ 的常数。其时间平均值就是该常数本身。\n对于第二项，我们必须评估一个正弦函数的时间平均值。对于任何非零且不是 $2\\pi$ 倍数的频率 $\\nu$，其时间平均值为零：$\\lim_{N \\to \\infty} \\frac{1}{N} \\sum_{k=0}^{N-1} \\cos(\\nu k + \\phi) = 0$。在我们的例子中，频率是 $2\\omega$。因为 $\\omega \\in (0, \\pi)$，我们有 $2\\omega \\in (0, 2\\pi)$。因此，该频率不是 $2\\pi$ 的倍数，所以极限为零。\n$$ \\lim_{N \\to \\infty} \\frac{1}{N} \\sum_{k=0}^{N-1} \\cos(2\\omega k - \\omega(i+j-2)) = 0$$\n因此，矩阵 $R$ 的元素为\n$$R_{ij} = \\frac{A^2}{2} \\cos(\\omega(j-i))$$\n现在，我们必须分析矩阵 $R$ 的结构。我们可以使用余弦差角公式 $\\cos(a-b) = \\cos(a)\\cos(b) + \\sin(a)\\sin(b)$ 来表示 $R_{ij}$：\n$$R_{ij} = \\frac{A^2}{2} \\left[ \\cos(\\omega(i-1)) \\cos(\\omega(j-1)) + \\sin(\\omega(i-1)) \\sin(\\omega(j-1)) \\right]$$\n这揭示了矩阵 $R$ 可以写成两个外积之和。我们定义两个向量 $c, s \\in \\mathbb{R}^n$：\n$$c = \\begin{pmatrix} \\cos(0\\omega) \\\\ \\cos(1\\omega) \\\\ \\vdots \\\\ \\cos((n-1)\\omega) \\end{pmatrix} = \\begin{pmatrix} 1 \\\\ \\cos(\\omega) \\\\ \\vdots \\\\ \\cos((n-1)\\omega) \\end{pmatrix}$$\n$$s = \\begin{pmatrix} \\sin(0\\omega) \\\\ \\sin(1\\omega) \\\\ \\vdots \\\\ \\sin((n-1)\\omega) \\end{pmatrix} = \\begin{pmatrix} 0 \\\\ \\sin(\\omega) \\\\ \\vdots \\\\ \\sin((n-1)\\omega) \\end{pmatrix}$$\n那么，矩阵 $R$ 可以表示为\n$$R = \\frac{A^2}{2} \\left( c c^{\\top} + s s^{\\top} \\right)$$\n矩阵 $R$ 是两个秩为1的矩阵 $c c^{\\top}$ 和 $s s^{\\top}$ 的线性组合。矩阵和的秩小于或等于它们秩的和。因此，$\\mathrm{rank}(R) \\le \\mathrm{rank}(c c^{\\top}) + \\mathrm{rank}(s s^{\\top})$。因为 $A>0$，向量 $c$ 和 $s$ 都是非零向量，所以 $\\mathrm{rank}(c c^{\\top})=1$ 且 $\\mathrm{rank}(s s^{\\top})=1$。这意味着 $\\mathrm{rank}(R) \\le 2$。\n\n为确定确切的秩，我们检查向量 $c$ 和 $s$ 是否线性无关。考虑一个线性组合 $\\alpha c + \\beta s = 0$。这个向量方程意味着一组 $n$ 个标量方程：\n$$\\alpha \\cos(k\\omega) + \\beta \\sin(k\\omega) = 0 \\quad \\text{for } k = 0, 1, \\dots, n-1$$\n当 $k=0$ 时，方程变为 $\\alpha \\cos(0) + \\beta \\sin(0) = \\alpha \\cdot 1 + \\beta \\cdot 0 = \\alpha = 0$。\n将 $\\alpha=0$ 代入 $k=1$ 的方程，我们得到 $\\beta \\sin(\\omega) = 0$。由于 $\\omega \\in (0, \\pi)$，$\\sin(\\omega) \\ne 0$，这意味着 $\\beta=0$。\n因此，唯一的解是 $\\alpha=\\beta=0$，这证明了向量 $c$ 和 $s$ 是线性无关的。$R$ 的列空间由 $c$ 和 $s$ 张成，所以 $\\mathrm{rank}(R) = 2$。\n\n给定系统阶数 $n \\ge 3$。根据秩-零度定理，对于一个 $n \\times n$ 矩阵 $R$，我们有 $\\mathrm{rank}(R) + \\mathrm{nullity}(R) = n$。\n当 $\\mathrm{rank}(R)=2$ 时，$R$ 的零度是 $n-2$。\n因为 $n \\ge 3$，零度 $n-2 \\ge 1$。零度至少为1意味着存在至少一个非零向量 $v$ 使得 $Rv=0v$。根据定义，这意味着 $\\lambda=0$ 是 $R$ 的一个特征值。\n\n此外，矩阵 $R$ 是一个格拉姆型矩阵，由半正定矩阵 $\\varphi_k \\varphi_k^{\\top}$ 的和的极限构成。因此，$R$ 本身必须是半正定的。一个半正定矩阵的所有特征值都必须是非负的。\n我们已经确定了 $0$ 是 $R$ 的一个特征值，并且 $R$ 的所有特征值都大于或等于 $0$。因此，$R$ 的最小特征值 $\\lambda_{\\min}$ 必须是 $0$。这个结果对于任何 $A > 0$ 和任何 $\\omega \\in (0, \\pi)$，在给定 $n \\ge 3$ 的情况下都成立。", "answer": "$$\\boxed{0}$$", "id": "2876722"}, {"introduction": "在单输入案例的基础上，我们现在来研究多输入多输出（MIMO）系统中的一个常见陷阱。当我们所用的各个输入通道虽然自身都具有激励性，但它们之间并非相互独立时，会发生什么？这项实践 [@problem_id:2876761] 揭示了通道间的相关性会如何灾难性地破坏系统的可辨识性。您将构建一个其中一个输入是另一个输入的延迟版本的场景，并证明这种线性依赖关系使得区分单个输入各自所产生的影响变得不可能，从而阐明MIMO实验设计中的一个关键原则。", "problem": "考虑一个双输入单输出离散时间线性时不变有限脉冲响应系统，每个输入通道的阶数为 $n=2$。设未知参数矢量为 $\\theta \\in \\mathbb{R}^{4}$，它是由每个输入通道的二抽头系数堆叠而成。在时间 $k$ 的标准最小二乘回归量为\n$$\n\\varphi(k) \\triangleq \\begin{pmatrix} u_{1}(k) \\\\ u_{1}(k-1) \\\\ u_{2}(k) \\\\ u_{2}(k-1) \\end{pmatrix} \\in \\mathbb{R}^{4}.\n$$\n对于一个有限时域 $N \\geq 3$，定义数据格拉姆矩阵（信息矩阵）\n$$\nR_{N} \\triangleq \\sum_{k=2}^{N} \\varphi(k) \\varphi(k)^{\\top} \\in \\mathbb{R}^{4 \\times 4}.\n$$\n如果由回归量 $\\psi(k) \\triangleq \\begin{pmatrix} u(k) \\\\ u(k-1) \\end{pmatrix}$ 构成的 $2 \\times 2$ 格拉姆矩阵在足够长的窗口上是正定的，或者等价地，如果其渐近时间平均格拉姆矩阵是正定的，则称标量输入序列 $u(k)$ 是2阶持续激励（PE）的。在一个窗口上通过最小二乘法实现 $\\theta$ 的可辨识性，要求 $R_{N}$ 是正定的。\n\n现在考虑以下构造的输入对。固定两个不可通约的频率 $\\omega_{1}, \\omega_{2} \\in (0,\\pi)$，例如 $\\omega_{1}=\\pi/\\sqrt{2}$ 和 $\\omega_{2}=\\pi/\\sqrt{3}$。令\n$$\nu_{1}(k) \\triangleq \\sin(\\omega_{1} k) + \\sin(\\omega_{2} k), \\qquad u_{2}(k) \\triangleq u_{1}(k-1), \\quad \\text{对所有整数 } k.\n$$\n任务：\n- 仅使用线性时不变系统和最小二乘回归的基本定义和性质，论证为什么每个标量通道 $u_{1}$ 和 $u_{2}$，当各自使用其自身的2阶回归量 $\\psi_{i}(k) \\triangleq \\begin{pmatrix} u_{i}(k) \\\\ u_{i}(k-1) \\end{pmatrix}$ 单独考虑时，是2阶持续激励的。\n- 解释为什么尽管每个通道都具有单独的持续激励性，但联合回归量 $\\varphi(k)$ 却不是4阶持续激励的，并根据数据中的线性相关性来描述由此导致的 $\\theta$ 可辨识性的丧失。\n- 对于上述输入对，计算行列式 $\\det(R_{N})$ 作为 $N$ 的函数。请将最终答案表示为一个无单位的精确值。无需四舍五入。", "solution": "该问题提法恰当且科学上无误。我们按顺序处理每个任务，进行求解。\n\n首先，我们必须确定单个输入通道 $u_{1}(k)$ 和 $u_{2}(k)$ 是2阶持续激励（PE）的。根据定义，如果一个信号 $u(k)$ 的渐近时间平均格拉姆矩阵是正定的，则该信号是n阶PE的。对于标量信号 $u_i(k)$ 和阶数 $n=2$，回归量为 $\\psi_{i}(k) = \\begin{pmatrix} u_{i}(k) & u_{i}(k-1) \\end{pmatrix}^{\\top}$，我们必须分析矩阵 $M_{i} = \\lim_{N \\to \\infty} \\frac{1}{N} \\sum_{k=1}^{N} \\psi_{i}(k) \\psi_{i}(k)^{\\top}$ 的正定性。\n\n对于第一个通道，$u_{1}(k) = \\sin(\\omega_{1} k) + \\sin(\\omega_{2} k)$。矩阵 $M_1$ 由下式给出：\n$$\nM_{1} = \\lim_{N \\to \\infty} \\frac{1}{N} \\sum_{k=1}^{N} \\begin{pmatrix} u_{1}(k)^{2} & u_{1}(k) u_{1}(k-1) \\\\ u_{1}(k) u_{1}(k-1) & u_{1}(k-1)^{2} \\end{pmatrix}\n$$\n矩阵的元素是信号在延迟为 $0$ 和 $1$ 时的自相关值。对于由具有不可通约频率的正弦波组成的准周期信号，不同频率项的交叉乘积的时间平均值为零。$\\sin^{2}(\\omega k + \\phi)$ 的时间平均值为 $\\frac{1}{2}$。因此，自相关函数 $r_{1}(\\tau) = \\lim_{N \\to \\infty} \\frac{1}{N} \\sum_{k=1}^{N} u_{1}(k) u_{1}(k+\\tau)$ 为：\n$$\nr_{1}(\\tau) = \\frac{1}{2} \\cos(\\omega_{1} \\tau) + \\frac{1}{2} \\cos(\\omega_{2} \\tau)\n$$\n因此矩阵 $M_1$ 为：\n$$\nM_{1} = \\begin{pmatrix} r_{1}(0) & r_{1}(1) \\\\ r_{1}(1) & r_{1}(0) \\end{pmatrix} = \\begin{pmatrix} 1 & \\frac{1}{2}(\\cos(\\omega_{1}) + \\cos(\\omega_{2})) \\\\ \\frac{1}{2}(\\cos(\\omega_{1}) + \\cos(\\omega_{2})) & 1 \\end{pmatrix}\n$$\n为使 $M_1$ 是正定的，其所有主子式必须为正。第一个主子式为 $1 > 0$。第二个主子式是其行列式，$\\det(M_{1}) = 1 - \\frac{1}{4}(\\cos(\\omega_{1}) + \\cos(\\omega_{2}))^{2}$。因为 $\\omega_{1}, \\omega_{2} \\in (0, \\pi)$，我们有 $|\\cos(\\omega_{i})| < 1$。根据三角不等式， $|\\cos(\\omega_{1}) + \\cos(\\omega_{2})| < 2$，这意味着 $(\\cos(\\omega_{1}) + \\cos(\\omega_{2}))^{2} < 4$。因此，$\\det(M_{1}) > 1 - \\frac{4}{4} = 0$。由于 $M_1$ 是对称的且主子式为正，所以它是正定的。因此，$u_{1}(k)$ 是2阶PE的。对于第二个通道，$u_{2}(k) = u_{1}(k-1)$。这仅仅是 $u_{1}(k)$ 的一个时间平移。平稳或循环平稳过程的自相关函数对于信号的时间平移是不变的。因此，对于 $u_2(k)$ 的渐近格拉姆矩阵 $M_2$ 与 $M_1$ 相同，即 $M_2 = M_1$。由于 $M_1$ 是正定的，所以 $M_2$ 也是正定的，因此 $u_2(k)$ 也是2阶PE的。\n\n第二，我们分析为什么联合回归量 $\\varphi(k)$ 不是4阶持续激励的。回归量定义为 $\\varphi(k) = \\begin{pmatrix} u_{1}(k) & u_{1}(k-1) & u_{2}(k) & u_{2}(k-1) \\end{pmatrix}^{\\top}$。关键条件是两个输入信号之间的线性关系：对所有 $k$ 都有 $u_{2}(k) = u_{1}(k-1)$。我们将此代入回归量的定义中：\n$$\n\\varphi(k) = \\begin{pmatrix} u_{1}(k) \\\\ u_{1}(k-1) \\\\ u_{1}(k-1) \\\\ u_{1}(k-2) \\end{pmatrix}\n$$\n立即可以看出，对于所有 $k$，矢量 $\\varphi(k)$ 的第二个和第三个分量是相同的。这在回归量矢量的分量之间引入了线性相关性。具体来说，令 $c = \\begin{pmatrix} 0 & 1 & -1 & 0 \\end{pmatrix}^{\\top}$。那么对于任意时刻 $k$，内积 $c^{\\top} \\varphi(k)$ 为：\n$$\nc^{\\top} \\varphi(k) = 0 \\cdot u_{1}(k) + 1 \\cdot u_{1}(k-1) - 1 \\cdot u_{1}(k-1) + 0 \\cdot u_{1}(k-2) = 0\n$$\n因此，信息矩阵 $R_{N} = \\sum_{k=2}^{N} \\varphi(k) \\varphi(k)^{\\top}$ 是奇异的。为证明这一点，我们将 $R_N$ 乘以非零矢量 $c$：\n$$\nR_{N} c = \\left( \\sum_{k=2}^{N} \\varphi(k) \\varphi(k)^{\\top} \\right) c = \\sum_{k=2}^{N} \\varphi(k) (\\varphi(k)^{\\top} c) = \\sum_{k=2}^{N} \\varphi(k) (c^{\\top} \\varphi(k))^{\\top} = \\sum_{k=2}^{N} \\varphi(k) \\cdot 0 = 0\n$$\n由于在 $R_N$ 的零空间中存在一个非零矢量 $c$，因此对于任意 $N \\geq 2$，矩阵 $R_N$ 都是奇异的。奇异矩阵不可能是正定的，因此联合回归量不是4阶PE的。这种奇异性导致了可辨识性的丧失。系统模型为 $y(k) = \\varphi(k)^{\\top} \\theta$。考虑一个替代参数矢量 $\\theta' = \\theta + \\alpha c$，其中 $\\alpha$ 为任意非零标量。由 $\\theta'$ 产生的系统输出为 $\\varphi(k)^{\\top} \\theta' = \\varphi(k)^{\\top} (\\theta + \\alpha c) = \\varphi(k)^{\\top} \\theta + \\alpha \\varphi(k)^{\\top} c = \\varphi(k)^{\\top} \\theta$。输出是相同的，这意味着数据无法用于区分 $\\theta$ 和 $\\theta'$。将 $\\theta$ 写为 $\\theta = \\begin{pmatrix} \\theta_{11} & \\theta_{12} & \\theta_{21} & \\theta_{22} \\end{pmatrix}^{\\top}$，不可辨识的参数形式为 $\\theta' = \\begin{pmatrix} \\theta_{11} & \\theta_{12} + \\alpha & \\theta_{21} - \\alpha & \\theta_{22} \\end{pmatrix}^{\\top}$。这表明只有和 $\\theta_{12} + \\theta_{21}$ 是可辨识的，而单个参数 $\\theta_{12}$ 和 $\\theta_{21}$ 则不可辨识。\n\n第三，我们要计算 $R_N$ 的行列式。信息矩阵由 $R_{N} = \\sum_{k=2}^{N} \\varphi(k) \\varphi(k)^{\\top}$ 给出。其第 $(i,j)$ 个元素是 $(R_{N})_{ij} = \\sum_{k=2}^{N} \\varphi_{i}(k) \\varphi_{j}(k)$，其中 $\\varphi_{i}(k)$ 是 $\\varphi(k)$ 的第 $i$ 个分量。如前所述，$\\varphi_{2}(k) = u_{1}(k-1)$ 且 $\\varphi_{3}(k) = u_{2}(k) = u_{1}(k-1)$。因此，对于所有 $k$，都有 $\\varphi_{2}(k) = \\varphi_{3}(k)$。\n让我们来考察矩阵 $R_N$ 的第二行和第三行。\n第二行的第 $j$ 个元素是 $(R_{N})_{2j} = \\sum_{k=2}^{N} \\varphi_{2}(k) \\varphi_{j}(k)$。\n第三行的第 $j$ 个元素是 $(R_{N})_{3j} = \\sum_{k=2}^{N} \\varphi_{3}(k) \\varphi_{j}(k)$。\n由于 $\\varphi_{2}(k) = \\varphi_{3}(k)$，可以轻易得出对于所有的 $j \\in \\{1, 2, 3, 4\\}$，都有 $(R_{N})_{2j} = (R_{N})_{3j}$。\n这意味着矩阵 $R_N$ 的第二行与第三行完全相同。行列式的一个基本性质是，如果一个方阵有两行（或两列）相同，其行列式为零。这对于任何 $N \\geq 2$ 的值都成立。因此，$R_N$ 的行列式恒为零，与 $N$ 无关。", "answer": "$$\n\\boxed{0}\n$$", "id": "2876761"}, {"introduction": "我们最后的实践将从理论原则转向数值计算的实际问题。即使我们拥有一个理论上完美的输入信号，我们对模型表示的选择也可能决定可辨识性的成败。本练习 [@problem_id:2876779] 将引导您编写一段仿真代码，以揭示病态的基函数（如高阶单项式）会如何导致持续激励性质的数值损失。通过实现并比较不同的缓解策略，如数据缩放和基函数正交化，您将获得构建稳健可靠的系统辨识程序的宝贵实践技能。", "problem": "给定一个线性回归设置，其中回归量向量 $\\phi(t) \\in \\mathbb{R}^{p+1}$ 由标量输入 $x(t) \\in \\mathbb{R}$ 的确定性基函数构成。模型 $y(t) = \\phi(t)^{\\top}\\theta + w(t)$ 中参数向量 $\\theta \\in \\mathbb{R}^{p+1}$ 的可辨识性取决于回归矩阵 $\\Phi \\in \\mathbb{R}^{N \\times (p+1)}$ 的性质，该矩阵的行是 $\\phi(t)^{\\top}$，其中 $N$ 是样本数量，$w(t)$ 是一个加性误差。在长度为 $N$ 的数据窗口上，$p+1$ 阶的持续激励 (Persistency of Excitation, PE) 这一常用概念用格拉姆矩阵 $G = \\sum_{t=1}^{N} \\phi(t)\\phi(t)^{\\top} = \\Phi^{\\top}\\Phi \\in \\mathbb{R}^{(p+1)\\times (p+1)}$ 来表示：存在一个常数 $\\alpha > 0$ 使得 $G \\succeq \\alpha I_{p+1}$。当此条件成立时，模型在该窗口上是可辨识的。然而，即使 $G$ 理论上是满秩的，数值舍入误差和病态问题也可能导致其在浮点运算中实际上是奇异的，从而破坏了实际的 PE。\n\n你的任务是构建一个案例，在该案例中，数值舍入误差对高阶多项式回归量有效地破坏了持续激励（PE），并实施缩放和正交化策略来缓解此问题。你的推理和实现应基于以下基本原理：\n- 回归矩阵 $\\Phi$ 的列由确定性基函数在输入 $\\{x(t)\\}_{t=1}^{N}$ 上的求值给出。\n- 格拉姆矩阵为 $G = \\Phi^{\\top}\\Phi$。\n- 窗口上的持续激励（PE）的特征是，最小特征值 $\\lambda_{\\min}(G)$ 相对于一个正基准值，能够保持显著大于零。\n- 有限精度运算可能导致病态基（例如在 $[0,1]$ 上的高阶单项式）出现严重的数值秩损失。\n\n程序要求：\n1. 使用输入 $x(t)$ 构建最高到 $p$ 次的单项式回归量，即 $\\phi(t) = [1, x(t), x(t)^{2}, \\dots, x(t)^{p}]^{\\top}$，并通过堆叠这些行向量来形成 $\\Phi$。\n2. 实现以下基构建策略：\n   - 在 $[0,1]$ 上的原始单项式（无缩放）。\n   - 缩放后的单项式：通过仿射变换 $z(t) = 2x(t) - 1$ 将输入映射到 $[-1,1]$，然后将 $\\Phi$ 的每一列归一化为单位欧几里得范数。\n   - 通过瘦（简化）$QR$ 分解进行标准正交化：当 $N \\geq p+1$ 时，用其具有标准正交列的 $Q$ 因子替换 $\\Phi$。\n3. 对于任何构建的 $\\Phi$，计算：\n   - 格拉姆矩阵 $G = \\Phi^{\\top}\\Phi$。\n   - 最小和最大特征值 $\\lambda_{\\min}(G)$ 和 $\\lambda_{\\max}(G)$。\n   - 谱条件数 $\\kappa(G) = \\lambda_{\\max}(G) / \\lambda_{\\min}(G)$，如果 $\\lambda_{\\min}(G)$ 在数值上为 0，则使用一个较大的有限占位符，如 $10^{308}$。\n   - 通过奇异值分解计算 $\\Phi$ 的数值秩，使用的阈值为 $\\tau_{\\mathrm{rank}} = \\max(N,p+1)\\,\\varepsilon\\,\\sigma_{\\max}$，其中 $\\varepsilon$ 是机器精度，$\\sigma_{\\max}$ 是 $\\Phi$ 的最大奇异值。\n   - 两项 PE 检查：\n     - 相对 PE 检查：如果 $\\lambda_{\\min}(G)/\\lambda_{\\max}(G) \\geq \\tau_{\\mathrm{rel}}$（其中 $\\tau_{\\mathrm{rel}} = 10^{-8}$），则声明 $\\mathrm{PE}_{\\mathrm{rel}}$ 为真。\n     - 尺度不变的绝对 PE 代理指标：如果 $\\lambda_{\\min}(G) \\geq \\tau_{\\mathrm{abs}} \\cdot \\mathrm{tr}(G)/(p+1)$（其中 $\\tau_{\\mathrm{abs}} = 10^{-8}$），则声明 $\\mathrm{PE}_{\\mathrm{abs}}$ 为真。\n4. 全程使用双精度运算。\n\n测试套件：\n在 $[0,1]$ 上使用具有 $N$ 个样本的等间距输入 $x(t)$。对于每种情况，按此顺序报告一个包含五个项目的列表：$[\\lambda_{\\min}(G), \\kappa(G), \\text{rank}(\\Phi), \\mathrm{PE}_{\\mathrm{rel}}, \\mathrm{PE}_{\\mathrm{abs}}]$。\n- 情况 A（高阶原始单项式；舍入误差破坏 PE）：$N = 60$，$p = 25$，方法 = 在 $[0,1]$ 上的原始单项式。\n- 情况 B（高阶缩放单项式；缓解病态问题）：$N = 60$，$p = 25$，方法 = 通过 $z = 2x-1$ 和列归一化进行缩放的单项式。\n- 情况 C（高阶，$QR$ 标准正交化；缓解病态问题）：$N = 60$，$p = 25$，方法 = 原始单项式矩阵的简化 $QR$ 分解得到的 $Q$ 矩阵。\n- 情况 D（理想情况，低阶原始单项式）：$N = 60$，$p = 5$，方法 = 在 $[0,1]$ 上的原始单项式。\n- 情况 E（边界情况，维度导致的激励不足；结构性非 PE）：$N = 10$，$p = 25$，方法 = 在 $[0,1]$ 上的原始单项式。\n\n最终输出格式：\n你的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表，列表中的每个元素是按 A、B、C、D、E 顺序排列的测试案例的五项列表。例如，输出必须如下所示：\n[[a11,a12,a13,a14,a15],[a21,a22,a23,a24,a25],[a31,a32,a33,a34,a35],[a41,a42,a43,a44,a45],[a51,a52,a53,a54,a55]]\n其中 $a_{ij}$ 是如上定义的浮点数、整数或布尔值。本问题不涉及单位。本问题不使用角度。百分比（若有）必须表示为小数，而不是使用百分号。", "solution": "所呈现的问题陈述是数值分析在系统辨识中应用的一个有效且适定的练习。它具有科学依据、客观，并包含了继续进行所需的所有必要信息。任务是展示高阶多项式回归量中持续激励（PE）的数值损失现象，并实现和评估标准的缓解技术。\n\n问题的核心在于回归矩阵 $\\Phi \\in \\mathbb{R}^{N \\times (p+1)}$ 及其相关的格拉姆矩阵 $G = \\Phi^{\\top}\\Phi \\in \\mathbb{R}^{(p+1)\\times (p+1)}$ 的性质。对于由 $y(t) = \\phi(t)^{\\top}\\theta + w(t)$ 描述的线性回归模型，参数向量 $\\theta \\in \\mathbb{R}^{p+1}$ 能否通过一组 $N$ 次测量进行辨识，当且仅当格拉姆矩阵 $G$ 是可逆的，或者等价地，是正定的 ($G \\succ 0$)。这个条件被称为持续激励（PE）。在数值上，通过验证 $G$ 的最小特征值（记为 $\\lambda_{\\min}(G)$）是否显著大于零来评估。\n\n格拉姆矩阵的条件数 $\\kappa(G) = \\lambda_{\\max}(G)/\\lambda_{\\min}(G)$ 提供了一个衡量其接近奇异性程度的指标。一个非常大的条件数表明该矩阵是病态的，并且在数值上接近奇异。对于任何满列秩的矩阵 $\\Phi$，其格拉姆矩阵的条件数与其自身的条件数相关，关系为 $\\kappa(G) = (\\kappa(\\Phi))^2$。因此，$\\Phi$ 中的任何病态性都会在 $G$ 中被放大。\n\n下面是与测试案例相对应的分步分析。\n\n**情况 A：高阶原始单项式 ($N=60, p=25$)**\n\n回归量向量使用区间 $[0,1]$ 上的原始单项式基构建：\n$$ \\phi(t) = [1, x(t), x(t)^2, \\dots, x(t)^{25}]^{\\top} $$\n其中输入 $\\{x(t)\\}_{t=1}^{60}$ 在 $[0,1]$ 上等距分布。对于大的幂次 $p$，函数 $x^p$ 和 $x^{p-1}$ 在此区间上变得几乎无法区分。例如，当 $x=0.95$ 时，$x^{25} \\approx 0.277$ 且 $x^{24} \\approx 0.292$。当 $x$ 趋近于 $1$ 时，这些函数变得更加相似。这导致回归矩阵 $\\Phi$ 的列变得近线性相关。这样的矩阵与臭名昭著的病态希尔伯特矩阵有关。\n\n因此，$\\Phi$ 是严重病态的。在有限精度运算（本例中为双精度）中，计算出的格拉姆矩阵 $G = \\Phi^{\\top}\\Phi$ 变为数值上奇异的。这意味着其最小特征值 $\\lambda_{\\min}(G)$ 将被计算为零或一个与机器精度同数量级的数，这在功能上等效于零。$\\Phi$ 的数值秩将被发现小于参数数量 $p+1=26$。依赖于 $\\lambda_{\\min}(G)$ 显著为正的 PE 检查将会失败。这表明，即使基理论上是满秩的，由于数值误差，也导致了实际可辨识性的损失。\n\n**情况 B：缩放后的单项式 ($N=60, p=25$)**\n\n为缓解情况 A 中观察到的病态问题，本案例采用了两种策略。首先，通过变换 $z(t) = 2x(t)-1$ 将输入区间 $[0,1]$ 仿射映射到 $[-1,1]$。现在的单项式基函数是 $z(t)$ 的幂，即 $\\{z(t)^k\\}_{k=0}^{p}$。这些函数在 $[-1,1]$ 上比 $x(t)$ 的幂在 $[0,1]$ 上更具区分度。其次，更重要的是，将得到的回归矩阵 $\\Phi$ 的每一列都归一化为单位欧几里得范数。\n\n这种列归一化平衡了基函数的尺度。在原始单项式情况下，第一列（对应 $x^0=1$）的范数为 $\\sqrt{N}$，而最后一列（对应 $x^{25}$）的范数则小得多。列范数的这种极端差异是病态的主要来源。通过强制所有列 $j$ 满足 $\\|\\Phi_{:,j}\\|_2 = 1$，我们创建了一个条件数更好的矩阵 $\\Phi$。因此，新的格拉姆矩阵 $G = \\Phi^{\\top}\\Phi$ 的条件数将大幅减小。其最小特征值 $\\lambda_{\\min}(G)$ 将稳健为正，并与零有很好的分离，从而满足 PE 检查。\n\n**情况 C：标准正交基 ($N=60, p=25$)**\n\n确保良好条件的最有效方法是使用标准正交基。如果回归矩阵 $\\Phi_{\\text{new}}$ 的列是标准正交的，那么格拉姆矩阵就是单位矩阵，$G_{\\text{new}} = \\Phi_{\\text{new}}^{\\top}\\Phi_{\\text{new}} = I_{p+1}$。对于单位矩阵，所有特征值都为 1，因此 $\\lambda_{\\min}(G) = \\lambda_{\\max}(G) = 1$，条件数 $\\kappa(G) = 1$，这是最佳的。\n\n这种理想状态可以通过对情况 A 中原始的、病态的单项式矩阵执行瘦（或简化）$QR$ 分解来实现，即 $\\Phi_{\\text{raw}} = QR$。这里，$Q \\in \\mathbb{R}^{N \\times (p+1)}$ 是一个具有标准正交列的矩阵，$R \\in \\mathbb{R}^{(p+1) \\times (p+1)}$ 是一个上三角矩阵。通过用 $Q$ 替换回归矩阵，我们处理的是一个条件完美的系统。最终得到的 $\\lambda_{\\min}(G)$ 将精确为 $1.0$（在浮点精度范围内），从而轻易地通过两项 PE 检查。此方法完全解决了数值病态问题。\n\n**情况 D：低阶原始单项式 ($N=60, p=5$)**\n\n这个案例作为一个“理想情况”的基线。当多项式阶数较低（$p=5$）时，单项式基函数 $\\{1, x, x^2, x^3, x^4, x^5\\}$ 在 $[0,1]$ 上足够可区分。回归矩阵 $\\Phi$ 的列不是近线性相关的。因此，$\\Phi$ 和格拉姆矩阵 $G$ 都是条件良好的。最小特征值 $\\lambda_{\\min}(G)$ 会很小，但能稳定地保持在零以上，并且无需任何缩放或正交化即可通过 PE 检查。这突显出该问题是高阶多项式特有的。\n\n**情况 E：数据不足 ($N=10, p=25$)**\n\n这个案例展示了结构性而非数值性的 PE 缺乏。我们试图从仅 $N=10$ 个数据点中辨识 $p+1 = 26$ 个参数。回归矩阵 $\\Phi$ 的维度是 $10 \\times 26$。任何矩阵的秩都不能超过其维度的最小值，因此 $\\text{rank}(\\Phi) \\leq \\min(10, 26) = 10$。由于秩小于列数（$10 < 26$），根据定义，$\\Phi$ 的列是线性相关的。\n\n格拉姆矩阵 $G = \\Phi^{\\top}\\Phi$ 是一个 $26 \\times 26$ 的矩阵，其秩等于 $\\Phi$ 的秩。由于 $\\text{rank}(G) = 10 < 26$，$G$ 是奇异的。奇异矩阵必须至少有一个零特征值；在本例中，它将至少有 $26 - 10 = 16$ 个零特征值。因此，$\\lambda_{\\min}(G) = 0$。这不是一个数值假象，而是一个欠定问题的根本后果。无论使用何种基，PE 条件在结构上都无法满足。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.linalg import qr\n\ndef analyze_pe(N, p, method):\n    \"\"\"\n    Analyzes Persistency of Excitation for a given regressor construction.\n\n    Args:\n        N (int): Number of samples.\n        p (int): Polynomial degree.\n        method (str): Basis construction method ('raw', 'scaled', 'qr').\n\n    Returns:\n        list: A list containing [lambda_min(G), kappa(G), rank(Phi), PE_rel, PE_abs].\n    \"\"\"\n    p_plus_1 = p + 1\n    x = np.linspace(0.0, 1.0, N, dtype=np.float64)\n\n    # 1. Construct the regressor matrix Phi\n    if method in ['raw', 'qr']:\n        # The problem defines phi(t) = [1, x(t), ..., x(t)^p]^T.\n        # np.vander with increasing=True produces rows [x^0, x^1, ...], which is correct.\n        Phi = np.vander(x, N=p_plus_1, increasing=True)\n    elif method == 'scaled':\n        z = 2.0 * x - 1.0\n        Phi = np.vander(z, N=p_plus_1, increasing=True)\n        # Normalize columns to unit Euclidean norm\n        col_norms = np.linalg.norm(Phi, axis=0)\n        # Prevent division by zero if a column is all zeros\n        non_zero_norms = np.where(col_norms == 0, 1.0, col_norms)\n        Phi = Phi / non_zero_norms\n    else:\n        raise ValueError(f\"Unknown method: {method}\")\n\n    # For the QR method, replace Phi with its Q factor from a thin QR decomposition\n    if method == 'qr':\n        if N >= p_plus_1:\n            Q, _ = qr(Phi, mode='economic')\n            Phi = Q\n        # If N  p+1, Phi is structurally rank-deficient. We analyze it as is,\n        # since QR is meant as a mitigation for ill-conditioning, not structural deficiency.\n        # This branch is not hit by the specified test cases for 'qr'.\n\n    # 2. Compute the Gram matrix G and its eigenvalues\n    G = Phi.T @ Phi\n\n    try:\n        # eigvalsh is preferred for symmetric matrices for speed and stability\n        eigvals = np.linalg.eigvalsh(G)\n    except np.linalg.LinAlgError:\n        # Fallback if G isn't perfectly symmetric due to numerical artifacts\n        eigvals = np.linalg.eigvals(G)\n        eigvals = np.real(eigvals)\n\n    lambda_min = np.min(eigvals)\n    lambda_max = np.max(eigvals)\n\n    # Correct for small negative eigenvalues from floating-point errors\n    lambda_min = max(0.0, lambda_min)\n\n    # 3. Compute condition number of G\n    # Use a large placeholder if lambda_min is effectively zero.\n    if lambda_min  1e-16:\n        kappa_G = 1.0e308\n    else:\n        kappa_G = lambda_max / lambda_min\n    \n    # For structural rank deficiency, lambda_min is theoretically C.\n    if N  p_plus_1:\n         lambda_min = 0.0\n         kappa_G = 1.0e308\n\n    # 4. Compute numerical rank of Phi\n    _U, s, _Vh = np.linalg.svd(Phi)\n    sigma_max = np.max(s) if s.size > 0 else 0.0\n    eps = np.finfo(np.float64).eps\n    rank_threshold = max(N, p_plus_1) * eps * sigma_max\n    num_rank = np.sum(s > rank_threshold)\n\n    # 5. Perform PE checks\n    tau_rel = 1e-8\n    tau_abs = 1e-8\n    \n    # Relative PE check\n    pe_rel = (lambda_min / lambda_max) >= tau_rel if lambda_max > 0 else (lambda_min >= 0.0)\n    \n    # Scale-invariant absolute PE proxy\n    trace_G = np.trace(G)\n    pe_abs = (lambda_min >= tau_abs * trace_G / p_plus_1) if p_plus_1 > 0 else False\n\n    return [lambda_min, kappa_G, int(num_rank), pe_rel, pe_abs]\n\ndef solve():\n    \"\"\"\n    Main function to run test cases and print results.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # Case A: High-order, raw monomials\n        {'N': 60, 'p': 25, 'method': 'raw'},\n        # Case B: High-order, scaled monomials\n        {'N': 60, 'p': 25, 'method': 'scaled'},\n        # Case C: High-order, orthonormalized by QR\n        {'N': 60, 'p': 25, 'method': 'qr'},\n        # Case D: Low-order, raw monomials\n        {'N': 60, 'p': 5, 'method': 'raw'},\n        # Case E: Insufficient data samples\n        {'N': 10, 'p': 25, 'method': 'raw'},\n    ]\n\n    results = []\n    for case in test_cases:\n        result = analyze_pe(N=case['N'], p=case['p'], method=case['method'])\n        results.append(result)\n\n    # Format the final output string exactly as required, without extra spaces.\n    # This involves manually building the string representation of the list of lists.\n    outer_list_str = []\n    for res_list in results:\n        inner_list_str = [str(item) for item in res_list]\n        outer_list_str.append(f\"[{','.join(inner_list_str)}]\")\n    \n    final_output = f\"[{','.join(outer_list_str)}]\"\n    print(final_output)\n\nsolve()\n```", "id": "2876779"}]}