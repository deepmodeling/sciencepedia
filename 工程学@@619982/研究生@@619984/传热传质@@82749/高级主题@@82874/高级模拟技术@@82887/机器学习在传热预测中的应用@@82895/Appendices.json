{"hands_on_practices": [{"introduction": "在机器学习中，一个核心挑战是模型的泛化能力——即模型在未见过的、但与训练数据来自同一分布的数据上的表现。在科学和工程应用中，这通常意味着模型需要跨越不同的物理尺度和参数进行准确预测。本实践将引导您探索一种源自物理学的强大技术——无量纲化，它通过揭示问题的内在尺度不变性，极大地简化了学习任务。通过分析一个经典瞬态热传导问题，您将亲身体会到，如何通过变量变换将一个看似依赖于多个物理参数的复杂问题族，转化为一个单一、普适的无量纲问题，从而为训练一个具有广泛泛化能力的机器学习模型奠定基础 [@problem_id:2502955]。", "problem": "一个实验室正在构建一个机器学习（ML）代理模型，用于预测一维瞬态热传导。热传导发生于均质杆中，在不同实验中，这些杆的长度、材料和初始温差各不相同。对于每根长度为$L$、热扩散系数为常数$\\alpha$的杆，其温度$T(x,t)$的演化遵循能量守恒和傅里叶定律，且两端始终保持在环境温度$T_{\\infty}$。初始温度是均匀的$T_{\\infty}+\\Delta T$，其中$\\Delta T>0$在不同杆件中可能不同。现有两种训练流程被用来构建一个将时空坐标映射到温度的神经网络（NN）。\n\n流程$\\mathsf{Dim}$：训练一个神经网络来近似有量纲解$T(x,t)$，将$(x,t,L,\\alpha,T_{\\infty},\\Delta T)$作为输入并预测$T$。\n\n流程$\\mathsf{ND}$：首先变换为无量纲变量$T^{*}=(T-T_{\\infty})/\\Delta T$，$x^{*}=x/L$，$t^{*}=\\alpha t/L^{2}$，然后使用来自具有不同$L$、$\\alpha$、$T_{\\infty}$和$\\Delta T$的杆件的汇集数据，训练一个神经网络来近似$T^{*}(x^{*},t^{*})$。在推理时，通过$T=T_{\\infty}+\\Delta T\\,T^{*}$进行逆向映射。\n\n从第一性原理出发，解释无量纲化如何改变解对物理参数的控制性依赖关系，以及这对机器学习中的跨尺度泛化能力意味着什么。对于这个热传导问题，哪个陈述最能概括$(T^{*},x^{*},t^{*})$变换对参数数量和跨尺度泛化能力的影响？\n\nA. 通过将$T^{*}$、$x^{*}$和$t^{*}$代入具有狄利克雷边界条件的能量方程和傅里叶定律，偏微分方程（PDE）及其与数据一致的初始和边界条件中对$L$、$\\alpha$、$T_{\\infty}$和$\\Delta T$的参数依赖性被消除，从而产生一个唯一的通用无量纲解$T^{*}(x^{*},t^{*})$；因此，一个在汇集的$(x^{*},t^{*})\\mapsto T^{*}$数据上训练的神经网络可以泛化到不同的$L$和$\\alpha$，而有量纲的预测值可以通过逆向缩放得到。\n\nB. 无量纲化仅仅是将输入和输出归一化到0和1之间，并没有改变独立控制参数的数量；因此，对于每个不同的$L$和$\\alpha$仍然需要一个单独的神经网络，跨尺度泛化能力没有改善。\n\nC. 因为无量纲化消除了$L$和$\\alpha$在控制方程中的影响，所以无法恢复有量纲的温度$T$；因此，可解释性和转换回物理单位的能力受到了影响。\n\nD. 对于一个足够大的神经网络，显式的无量纲化是不必要的，因为网络会自动学习到正确的缩放关系；因此，使用$(T^{*},x^{*},t^{*})$并不会减少有效参数数量或改善泛化能力。\n\nE. 即使两端不是保持在$T_{\\infty}$，而是经历与传热系数为$h$的对流，同样的$(T^{*},x^{*},t^{*})$变换总是能消除所有参数依赖性，使得无量纲问题保持无参数状态；因此，一个在$T^{*}(x^{*},t^{*})$上训练的神经网络将能够在没有附加特征的情况下泛化到变化的$h$。", "solution": "首先必须验证问题陈述的科学性和逻辑一致性。\n\n该问题描述了一个均质杆中的一维瞬态热传导。其控制偏微分方程（PDE）源于能量守恒原理结合傅里叶热传导定律。对于热扩散系数$\\alpha$为常数的材料，这就是热方程：\n$$\n\\frac{\\partial T}{\\partial t} = \\alpha \\frac{\\partial^2 T}{\\partial x^2}\n$$\n该方程定义在空间域 $x \\in [0, L]$ 和时间 $t \\ge 0$ 上。\n\n边界条件（BCs）给出为杆的两端在所有时间内都保持在环境温度$T_{\\infty}$。这指定了狄利克雷边界条件：\n$$\nT(0, t) = T_{\\infty} \\quad \\text{for } t \\ge 0\n$$\n$$\nT(L, t) = T_{\\infty} \\quad \\text{for } t \\ge 0\n$$\n\n初始条件（IC）是在环境温度之上有一个均匀的温差$\\Delta T$：\n$$\nT(x, 0) = T_{\\infty} + \\Delta T \\quad \\text{for } x \\in (0, L)\n$$\n\n问题的参数是杆长$L$、热扩散系数$\\alpha$、环境温度$T_{\\infty}$和初始温差$\\Delta T > 0$。解是温度场$T(x, t)$，它依赖于这四个参数。\n\n问题提出使用以下变量进行无量纲化：\n$$\nT^{*} = \\frac{T - T_{\\infty}}{\\Delta T}, \\quad x^{*} = \\frac{x}{L}, \\quad t^{*} = \\frac{\\alpha t}{L^2}\n$$\n量$t^{*}$也被称为傅里叶数，$Fo$。\n\n问题陈述是科学合理的、适定的和客观的。它描述了热传导理论中的一个经典问题，具有明确的物理、几何和条件。该无量纲化方案是这类问题的标准方案。问题有效。我们可以继续解答。\n\n任务的核心是将有量纲的控制方程及其相关条件转换为无量纲形式，以分析其对参数依赖性的影响。我们使用链式法则来变换偏导数。\n\n首先，我们用$T^{*}$表示$T$：$T(x,t) = T_{\\infty} + \\Delta T \\, T^{*}(x^{*}, t^{*})$。\n\n时间导数是：\n$$\n\\frac{\\partial T}{\\partial t} = \\Delta T \\frac{\\partial T^{*}}{\\partial t} = \\Delta T \\left(\\frac{\\partial T^{*}}{\\partial t^{*}} \\frac{\\partial t^{*}}{\\partial t}\\right) = \\Delta T \\left(\\frac{\\partial T^{*}}{\\partial t^{*}} \\frac{\\alpha}{L^2}\\right) = \\frac{\\alpha \\Delta T}{L^2} \\frac{\\partial T^{*}}{\\partial t^{*}}\n$$\n\n空间导数是：\n$$\n\\frac{\\partial T}{\\partial x} = \\Delta T \\frac{\\partial T^{*}}{\\partial x} = \\Delta T \\left(\\frac{\\partial T^{*}}{\\partial x^{*}} \\frac{\\partial x^{*}}{\\partial x}\\right) = \\Delta T \\left(\\frac{\\partial T^{*}}{\\partial x^{*}} \\frac{1}{L}\\right) = \\frac{\\Delta T}{L} \\frac{\\partial T^{*}}{\\partial x^{*}}\n$$\n$$\n\\frac{\\partial^2 T}{\\partial x^2} = \\frac{\\partial}{\\partial x}\\left(\\frac{\\Delta T}{L} \\frac{\\partial T^{*}}{\\partial x^{*}}\\right) = \\frac{\\Delta T}{L} \\left(\\frac{\\partial^2 T^{*}}{\\partial (x^{*})^2} \\frac{\\partial x^{*}}{\\partial x}\\right) = \\frac{\\Delta T}{L^2} \\frac{\\partial^2 T^{*}}{\\partial (x^{*})^2}\n$$\n\n将这些代入原始热方程：\n$$\n\\frac{\\alpha \\Delta T}{L^2} \\frac{\\partial T^{*}}{\\partial t^{*}} = \\alpha \\left(\\frac{\\Delta T}{L^2} \\frac{\\partial^2 T^{*}}{\\partial (x^{*})^2}\\right)\n$$\n由于$\\alpha > 0$，$\\Delta T > 0$，且$L > 0$，我们可以将等式两边同除以$\\frac{\\alpha \\Delta T}{L^2}$，得到无量纲热方程：\n$$\n\\frac{\\partial T^{*}}{\\partial t^{*}} = \\frac{\\partial^2 T^{*}}{\\partial (x^{*})^2}\n$$\n\n接下来，我们变换边界条件和初始条件。\n空间域$x \\in [0, L]$变为$x^{*} \\in [0, 1]$。\n时间域$t \\in [0, \\infty)$变为$t^{*} \\in [0, \\infty)$。\n\n对于$x=0$处的边界条件，我们有$x^{*}=0$。\n$$\nT^{*}(0, t^{*}) = \\frac{T(0, t) - T_{\\infty}}{\\Delta T} = \\frac{T_{\\infty} - T_{\\infty}}{\\Delta T} = 0\n$$\n\n对于$x=L$处的边界条件，我们有$x^{*}=1$。\n$$\nT^{*}(1, t^{*}) = \\frac{T(L, t) - T_{\\infty}}{\\Delta T} = \\frac{T_{\\infty} - T_{\\infty}}{\\Delta T} = 0\n$$\n\n对于$t=0$处的初始条件，我们有$t^{*}=0$。\n$$\nT^{*}(x^{*}, 0) = \\frac{T(x, 0) - T_{\\infty}}{\\Delta T} = \\frac{(T_{\\infty} + \\Delta T) - T_{\\infty}}{\\Delta T} = 1\n$$\n\n完整的无量纲问题是：\n求解在$x^{*} \\in [0, 1]$和$t^{*} \\ge 0$范围内的$T^{*}(x^{*}, t^{*})$，使得：\n$$\n\\frac{\\partial T^{*}}{\\partial t^{*}} = \\frac{\\partial^2 T^{*}}{\\partial (x^{*})^2}\n$$\n边界条件为：$T^{*}(0, t^{*}) = 0$，$T^{*}(1, t^{*}) = 0$，初始条件为：$T^{*}(x^{*}, 0) = 1$。\n\n这种无量纲表述完全不含原始的物理参数$L$、$\\alpha$、$T_{\\infty}$和$\\Delta T$。这意味着解$T^{*}(x^{*}, t^{*})$是一个单一的、通用的函数。这个问题的任何物理实现，无论$L, \\alpha, T_{\\infty}, \\Delta T$的具体值如何，都映射到这同一个无量纲问题。\n\n从机器学习的角度来看，这是一个意义深远的简化。\n流程$\\mathsf{Dim}$需要一个神经网络来学习一个6变量的函数：$T(x, t, L, \\alpha, T_{\\infty}, \\Delta T)$。神经网络必须在内部发现由物理定律决定的复杂缩放关系。\n流程$\\mathsf{ND}$需要一个神经网络来学习一个仅有2个变量的函数：$T^{*}(x^{*}, t^{*})$。来自物理参数差异巨大的实验数据都可以被转换到无量纲空间并汇集起来，用于训练一个关于这个通用函数的单一模型。这极大地降低了学习任务的复杂性，提高了数据效率，并确保了在物理模型有效的所有尺度和参数上实现完美的泛化。有量纲的答案可以通过逆变换$T(x,t) = T_{\\infty} + \\Delta T \\, T^{*}(\\frac{x}{L}, \\frac{\\alpha t}{L^2})$轻易地恢复。\n\n现在我们评估给定的选项。\n\nA. 通过将$T^{*}$、$x^{*}$和$t^{*}$代入具有狄利克雷边界条件的能量方程和傅里叶定律，偏微分方程（PDE）及其与数据一致的初始和边界条件中对$L$、$\\alpha$、$T_{\\infty}$和$\\Delta T$的参数依赖性被消除，从而产生一个唯一的通用无量纲解$T^{*}(x^{*},t^{*})$；因此，一个在汇集的$(x^{*},t^{*})\\mapsto T^{*}$数据上训练的神经网络可以泛化到不同的$L$和$\\alpha$，而有量纲的预测值可以通过逆向缩放得到。\n这个陈述是我们推导过程的精确而完整的总结。无量纲化消除了PDE系统中的所有参数，得到了一个通用的解。这使得数据可以被汇集，并保证了在无量纲空间中训练的ML模型具有泛化能力。通过逆向缩放进行恢复的说法也是正确的。**正确**。\n\nB. 无量纲化仅仅是将输入和输出归一化到0和1之间，并没有改变独立控制参数的数量；因此，对于每个不同的$L$和$\\alpha$仍然需要一个单独的神经网络，跨尺度泛化能力没有改善。\n这个陈述有根本性的错误。虽然归一化是一个附带效果（例如，$T^{*}$初始为1并衰减至0），但其主要成就是减少了参数空间。我们的推导明确表明，无量纲PDE系统中的控制参数数量从四个减少到零。因此，需要单独神经网络的结论是错误的。**不正确**。\n\nC. 因为无量纲化消除了$L$和$\\alpha$在控制方程中的影响，所以无法恢复有量纲的温度$T$；因此，可解释性和转换回物理单位的能力受到了影响。\n这个陈述显然是错误的。该变换是代数的并且完全可逆。如上所示，$T(x,t) = T_{\\infty} + \\Delta T \\, T^{*}(x/L, \\alpha t/L^2)$。给定通用解$T^{*}$和特定案例的参数，物理温度$T$可以唯一且容易地确定。这个过程非但没有损害可解释性，反而通过将普适行为与特定案例的缩放分离开来，增强了可解释性。**不正确**。\n\nD. 对于一个足够大的神经网络，显式的无量纲化是不必要的，因为网络会自动学习到正确的缩放关系；因此，使用$(T^{*},x^{*},t^{*})$并不会减少有效参数数量或改善泛化能力。\n这反映了对神经网络作为通用近似器能力的一种天真信念，忽略了训练和数据需求的实际情况。虽然一个足够大的网络理论上可以近似多变量的有量纲函数，但从稀疏数据中学习其中内嵌的复杂物理缩放定律是一项异常困难的任务，通常会导致较差的泛化能力。将已知的物理知识（例如通过无量纲化得到的缩放定律）嵌入模型，是高效且稳健的科学机器学习的基石。它提供了一种强大的归纳偏置，极大地提高了样本效率和泛化能力。关于有效参数数量没有减少的说法是错误的；学习问题从一个$6 \\rightarrow 1$的映射简化为一个$2 \\rightarrow 1$的映射。**不正确**。\n\nE. 即使两端不是保持在$T_{\\infty}$，而是经历与传热系数为$h$的对流，同样的$(T^{*},x^{*},t^{*})$变换总是能消除所有参数依赖性，使得无量纲问题保持无参数状态；因此，一个在$T^{*}(x^{*},t^{*})$上训练的神经网络将能够在没有附加特征的情况下泛化到变化的$h$。\n这个陈述对一个不同的物理场景做出了一个强有力的断言，必须进行验证。在$x=L$处的对流边界条件的形式为$-k \\frac{\\partial T}{\\partial x}\\big|_{x=L} = h [T(L,t) - T_{\\infty}]$，其中$k$是热导率。代入无量纲变量并使用$k = \\alpha \\rho c_p$：\n$$\n-k \\left(\\frac{\\Delta T}{L} \\frac{\\partial T^{*}}{\\partial x^{*}}\\bigg|_{x^{*}=1}\\right) = h [\\Delta T \\cdot T^{*}(1, t^{*})]\n$$\n$$\n- \\frac{\\partial T^{*}}{\\partial x^{*}}\\bigg|_{x^{*}=1} = \\frac{hL}{k} T^{*}(1, t^{*})\n$$\n无量纲数群$\\frac{hL}{k}$是毕渥数（Biot number），$Bi$。得到的无量纲边界条件是$- \\frac{\\partial T^{*}}{\\partial x^{*}}\\big|_{x^{*}=1} = Bi \\cdot T^{*}(1, t^{*})$。因此，无量纲问题现在依赖于毕渥数。所以，关于问题保持无参数的说法是错误的。为了泛化到不同的$h$值，神经网络需要将$Bi$作为输入。**不正确**。", "answer": "$$\\boxed{A}$$", "id": "2502955"}, {"introduction": "在上一节实践的基础上，我们继续探讨如何将物理知识更深入地融入模型。一个优秀的科学机器学习模型不仅应在数据上表现准确，更应遵守其所描述系统的基本物理定律。本实践聚焦于学习材料的热力学性质（焓），并展示了两种嵌入物理约束的关键技术。您将学习如何通过精心设计模型结构（例如，确保比热容 $c_{p}$ 始终为非负）来硬性施加物理约束，以及如何通过在损失函数中添加惩罚项，来软性地引导模型满足已知的物理测量值 [@problem_id:2502951]。", "problem": "一个数据驱动的传热模型正在被开发，用于使用机器学习（ML）来预测恒压下单相流体的随温度变化的焓。该模型旨在建立从温度到焓的映射关系，并基于焓的测量数据进行训练，同时利用热力学一致性来正则化拟合过程。\n\n从以下定义出发：在恒定压力下，微分焓满足 $dh = c_{p}(T)\\,dT$，微分熵满足 $ds = \\frac{c_{p}(T)}{T}\\,dT$。在温度区间 $[T_{\\min},T_{\\max}]$ （其中 $T_{\\min} > 0$）上，一个物理上合理的焓，其对应的热容应为非负且可积，并且熵为有限值且随温度升高而增加。\n\n给定 $M$ 个焓测量值 $\\{(T_{i},\\hat{h}_{i})\\}_{i=1}^{M}$，每个值都以基准温度 $T_{r}\\in[T_{\\min},T_{\\max}]$ 作为参考，因此真实焓满足 $h(T_{r})=0$。学习器不直接预测 $h(T)$；而是预测一个参数化热容\n$$\nc_{p,\\theta}(T) = \\big(a + b\\,T + c\\,T^{2}\\big)^{2},\n$$\n其参数为 $\\theta = (a,b,c)$，并通过以下方式定义预测焓\n$$\nh_{\\theta}(T) = \\int_{T_{r}}^{T} c_{p,\\theta}(\\tau)\\,d\\tau.\n$$\n为了嵌入除单调性以外的更深层次的热力学一致性，我们使用一个已知的量热参考值：位于 $[T_{\\min},T_{\\max}]$ 区间内的两个校准温度 $T_{a}$ 和 $T_{b}$ 之间的焓差满足 $h(T_{b})-h(T_{a})=\\Delta h_{\\mathrm{ref}}$。学习目标函数在经验风险的基础上增加了一个罚项，以强制施加此焓差约束：\n$$\n\\mathcal{J}(a,b,c) = \\frac{1}{M}\\sum_{i=1}^{M}\\Big(h_{\\theta}(T_{i})-\\hat{h}_{i}\\Big)^{2} \\;+\\; \\mu\\,\\Big(h_{\\theta}(T_{b})-h_{\\theta}(T_{a})-\\Delta h_{\\mathrm{ref}}\\Big)^{2},\n$$\n其中 $\\mu>0$ 是给定的罚项权重。\n\n任务：\n- 根据上述基本定义，陈述在恒定压力下，确保 $h(T)$ 和 $s(T)$ 物理上合理的关于 $c_{p}(T)$ 和温度域的充分条件。\n- 证明所选的参数化形式 $c_{p,\\theta}(T) = \\big(a + b\\,T + c\\,T^{2}\\big)^{2}$ 在区间 $[T_{\\min},T_{\\max}]$ (其中 $T_{\\min}>0$) 上满足这些条件。\n- 计算 $h_{\\theta}(T)$ 的闭式解，然后推导出 $\\mathcal{J}(a,b,c)$ 的显式解析表达式，该表达式应以 $(a,b,c)$、$\\{(T_{i},\\hat{h}_{i})\\}_{i=1}^{M}$、$T_{r}$、$T_{a}$、$T_{b}$、$\\Delta h_{\\mathrm{ref}}$ 和 $\\mu$ 表示。\n\n请以单个 $\\mathcal{J}(a,b,c)$ 的闭式表达式提供最终答案。所有温度单位必须为 $\\text{K}$，焓单位必须为 $\\text{kJ}\\,\\text{kg}^{-1}$。最终损失函数的单位应表示为 $(\\text{kJ}\\,\\text{kg}^{-1})^{2}$。无需进行数值代入，也无需进行四舍五入。最终答案必须是单个解析表达式。", "solution": "本问题是一个定义明确的练习，其内容是应用基本热力学原理来为一个机器学习模型构建正则化目标函数。该问题科学严谨，逻辑自洽，并包含了所有必要信息。我们将对其进行系统性的求解。\n\n任务是为一个数据驱动的焓模型推导出学习目标函数 $\\mathcal{J}(a,b,c)$ 的显式解析形式。这将分三个阶段完成：首先，形式化物理约束；其次，验证所提出的模型是否满足这些约束；第三，直接计算目标函数。\n\n首先，我们讨论在温度范围 $[T_{\\min}, T_{\\max}]$（其中 $T_{\\min} > 0$）内，针对恒压下单相流体的焓 $h(T)$ 和熵 $s(T)$，一个物理上合理的热力学模型需要满足的条件。分析从所提供的基本吉布斯关系式开始：\n$$\ndh = c_{p}(T)\\,dT\n$$\n$$\nds = \\frac{c_{p}(T)}{T}\\,dT\n$$\n为了让这些关系式描述一个物理上合理的系统，比热容 $c_{p}(T)$ 必须满足某些条件。\n1.  **热力学稳定性**：热容必须为非负值，即 $c_{p}(T) \\ge 0$。如果热容为负，热量就可能自发地从系统的较冷部分传递到较热部分，这违反了热力学第二定律。此条件确保了局部热稳定性。\n2.  **熵增**：一个闭合系统的熵必须是其内能的非递减函数。在恒定压力下，对于单相物质，这意味着熵必须是温度的非递减函数。根据熵变的关系式，熵随温度的变化率为 $\\frac{ds}{dT} = \\frac{c_{p}(T)}{T}$。由于在给定域内绝对温度 $T$（单位为开尔文）是严格为正的（$T \\ge T_{\\min} > 0$），因此条件 $\\frac{ds}{dT} \\ge 0$ 等价于 $c_{p}(T) \\ge 0$。问题要求熵增加，这对应于严格不等式 $c_p(T) > 0$。模型应至少满足非负性约束。\n3.  **可积性与有限性**：为了通过积分良好地定义焓 $h(T)$ 和熵 $s(T)$，函数 $c_{p}(T)$ 和 $\\frac{c_{p}(T)}{T}$ 都必须在定义域上可积。一个充分条件是 $c_{p}(T)$ 在闭合有界区间 $[T_{\\min}, T_{\\max}]$ 上是连续的。连续性保证了可积性。条件 $T_{\\min} > 0$ 至关重要，它确保了被积函数 $\\frac{c_{p}(T)}{T}$ 在 $T=0$ 处没有奇点，从而保证了熵积分为有限值。\n\n总而言之，在区间 $[T_{\\min}, T_{\\max}]$（其中 $T_{\\min} > 0$）上，一个物理上合理的模型的充分条件是 $c_{p}(T)$ 是一个连续的非负函数。\n\n其次，我们验证所提出的参数化热容模型 $c_{p,\\theta}(T) = \\big(a + bT + cT^{2}\\big)^{2}$ 是否满足这些条件。其参数为 $\\theta = (a, b, c)$。\n1.  函数 $P(T) = a + bT + cT^{2}$ 是关于温度 $T$ 的多项式。多项式对所有实数 $T$ 都是连续的。函数 $c_{p,\\theta}(T)$ 是 $P(T)$ 的平方，而连续函数的复合函数也是连续的。因此，$c_{p,\\theta}(T)$ 在任何区间上都是连续的，包括 $[T_{\\min}, T_{\\max}]$。\n2.  对于实值参数 $a$，$b$，$c$ 和实数温度 $T$，$P(T)$ 的值是一个实数。任何实数的平方都是非负的。因此，对于所有 $T$，$c_{p,\\theta}(T) = (P(T))^{2} \\ge 0$。这种结构形式从结构上保证了非负性约束，这是物理合理性的一个关键要求。\n\n因此，该模型形式是有效的。\n\n第三，我们推导目标函数 $\\mathcal{J}(a,b,c)$ 的闭式表达式。这需要计算预测焓 $h_{\\theta}(T)$。我们首先展开 $c_{p,\\theta}(T)$ 的表达式：\n$$\nc_{p,\\theta}(\\tau) = \\big(a + b\\tau + c\\tau^{2}\\big)^{2} = a^{2} + b^{2}\\tau^{2} + c^{2}\\tau^{4} + 2ab\\tau + 2ac\\tau^{2} + 2bc\\tau^{3}\n$$\n按 $\\tau$ 的幂次进行分组：\n$$\nc_{p,\\theta}(\\tau) = a^{2} + (2ab)\\tau + (b^{2}+2ac)\\tau^{2} + (2bc)\\tau^{3} + c^{2}\\tau^{4}\n$$\n预测焓 $h_{\\theta}(T)$ 定义为 $c_{p,\\theta}(\\tau)$ 从参考温度 $T_{r}$到 $T$ 的积分：\n$$\nh_{\\theta}(T) = \\int_{T_{r}}^{T} c_{p,\\theta}(\\tau)\\,d\\tau = \\int_{T_{r}}^{T} \\left( a^{2} + 2ab\\tau + (b^{2}+2ac)\\tau^{2} + 2bc\\tau^{3} + c^{2}\\tau^{4} \\right) d\\tau\n$$\n为了计算这个积分，我们求其原函数，记为 $H(\\tau)$：\n$$\nH(\\tau) = a^{2}\\tau + ab\\tau^{2} + \\frac{b^{2}+2ac}{3}\\tau^{3} + \\frac{bc}{2}\\tau^{4} + \\frac{c^{2}}{5}\\tau^{5}\n$$\n于是定积分为 $h_{\\theta}(T) = H(T) - H(T_{r})$。展开此式可得：\n$$\nh_{\\theta}(T) = \\left( a^{2}T + abT^{2} + \\frac{b^{2}+2ac}{3}T^{3} + \\frac{bc}{2}T^{4} + \\frac{c^{2}}{5}T^{5} \\right) - \\left( a^{2}T_{r} + abT_{r}^{2} + \\frac{b^{2}+2ac}{3}T_{r}^{3} + \\frac{bc}{2}T_{r}^{4} + \\frac{c^{2}}{5}T_{r}^{5} \\right)\n$$\n此式可按参数乘积重新组合：\n$$\nh_{\\theta}(T) = a^{2}(T - T_{r}) + ab(T^{2} - T_{r}^{2}) + \\frac{2ac}{3}(T^{3} - T_{r}^{3}) + \\frac{b^{2}}{3}(T^{3} - T_{r}^{3}) + \\frac{bc}{2}(T^{4} - T_{r}^{4}) + \\frac{c^{2}}{5}(T^{5} - T_{r}^{5})\n$$\n目标函数 $\\mathcal{J}(a,b,c)$ 有两部分。第一部分是关于数据点 $\\{(T_{i},\\hat{h}_{i})\\}$ 的均方误差：\n$$\n\\text{Term 1} = \\frac{1}{M}\\sum_{i=1}^{M}\\Big(h_{\\theta}(T_{i})-\\hat{h}_{i}\\Big)^{2}\n$$\n第二部分是强制施加量热约束的罚项：\n$$\n\\text{Term 2} = \\mu\\,\\Big(h_{\\theta}(T_{b})-h_{\\theta}(T_{a})-\\Delta h_{\\mathrm{ref}}\\Big)^{2}\n$$\n对于罚项，焓差为：\n$$\nh_{\\theta}(T_{b}) - h_{\\theta}(T_{a}) = (H(T_{b}) - H(T_{r})) - (H(T_{a}) - H(T_{r})) = H(T_{b}) - H(T_{a})\n$$\n这得到：\n$$\nh_{\\theta}(T_{b})-h_{\\theta}(T_{a}) = a^{2}(T_{b}- T_{a}) + ab(T_{b}^{2} - T_{a}^{2}) + \\frac{2ac}{3}(T_{b}^{3} - T_{a}^{3}) + \\frac{b^{2}}{3}(T_{b}^{3} - T_{a}^{3}) + \\frac{bc}{2}(T_{b}^{4} - T_{a}^{4}) + \\frac{c^{2}}{5}(T_{b}^{5} - T_{a}^{5})\n$$\n将这些表达式代入目标函数，即可得到最终的显式形式。\n\n$\\mathcal{J}(a,b,c)$ 的完整表达式为：\n$$\n\\mathcal{J}(a,b,c) = \\frac{1}{M}\\sum_{i=1}^{M}\\left( a^{2}(T_{i}-T_{r}) + ab(T_{i}^{2}-T_{r}^{2}) + \\frac{2ac}{3}(T_{i}^{3}-T_{r}^{3}) + \\frac{b^{2}}{3}(T_{i}^{3}-T_{r}^{3}) + \\frac{bc}{2}(T_{i}^{4}-T_{r}^{4}) + \\frac{c^{2}}{5}(T_{i}^{5}-T_{r}^{5}) - \\hat{h}_{i} \\right)^{2} \\\\\n+ \\mu \\left( a^{2}(T_{b}-T_{a}) + ab(T_{b}^{2}-T_{a}^{2}) + \\frac{2ac}{3}(T_{b}^{3}-T_{a}^{3}) + \\frac{b^{2}}{3}(T_{b}^{3}-T_{a}^{3}) + \\frac{bc}{2}(T_{b}^{4}-T_{a}^{4}) + \\frac{c^{2}}{5}(T_{b}^{5}-T_{a}^{5}) - \\Delta h_{\\mathrm{ref}} \\right)^{2}\n$$\n这就是所要求的结果。", "answer": "$$\n\\boxed{\\mathcal{J}(a,b,c) = \\frac{1}{M}\\sum_{i=1}^{M}\\left( a^{2}(T_{i}-T_{r}) + ab(T_{i}^{2}-T_{r}^{2}) + \\frac{2ac}{3}(T_{i}^{3}-T_{r}^{3}) + \\frac{b^{2}}{3}(T_{i}^{3}-T_{r}^{3}) + \\frac{bc}{2}(T_{i}^{4}-T_{r}^{4}) + \\frac{c^{2}}{5}(T_{i}^{5}-T_{r}^{5}) - \\hat{h}_{i} \\right)^{2} + \\mu \\left( a^{2}(T_{b}-T_{a}) + ab(T_{b}^{2}-T_{a}^{2}) + \\frac{2ac}{3}(T_{b}^{3}-T_{a}^{3}) + \\frac{b^{2}}{3}(T_{b}^{3}-T_{a}^{3}) + \\frac{bc}{2}(T_{b}^{4}-T_{a}^{4}) + \\frac{c^{2}}{5}(T_{b}^{5}-T_{a}^{5}) - \\Delta h_{\\mathrm{ref}} \\right)^{2}}\n$$", "id": "2502951"}]}