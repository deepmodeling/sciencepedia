{"hands_on_practices": [{"introduction": "要真正掌握线性二次调节器（LQR）框架，从基础开始至关重要。第一个练习将问题简化为一维系统，让您可以直接将系统参数（$a, b$）和LQR权重（$q, r$）与最终的闭环性能（由系统极点 $s$ 表示）联系起来 [@problem_id:1589492]。通过求解标量代数Riccati方程，您将亲手体验LQR的核心数学机制，并建立对这些参数如何相互作用的直观理解。", "problem": "考虑一个简化的一维模型，用于描述在磁约束系统中，一个粒子偏离其不稳定平衡点的位移 $x(t)$。该偏离的动力学由以下线性微分方程描述：\n$$\n\\dot{x}(t) = ax(t) + bu(t)\n$$\n其中 $u(t)$ 是施加到电磁铁上的控制输入电压。参数 $a$ 和 $b$ 是正常数，分别代表系统的固有不稳定性和控制输入的有效性。\n\n为了将粒子稳定在平衡点（$x=0$），我们设计了一个反馈控制器。控制器的行为通过使用线性二次调节器（LQR）方法优化一个性能准则来确定。这涉及到在无限时间域上最小化一个代价泛函 $J$，其定义如下：\n$$\nJ = \\int_{0}^{\\infty} \\left(q x(t)^2 + r u(t)^2\\right) dt\n$$\n此处，$q$ 和 $r$ 是正常数，分别对状态偏差和控制力施加惩罚。\n\n最优LQR控制律是一种形式为 $u(t) = -Kx(t)$ 的状态反馈控制器，其中 $K$ 是一个常数增益。应用该控制器将系统动力学修改为一个稳定的一阶闭环系统 $\\dot{x}(t) = s x(t)$。您的任务是根据物理和代价参数 $a、b、q$ 和 $r$ 来确定闭环系统的极点 $s$ 的位置。", "solution": "我们从线性系统 $\\dot{x}(t) = a x(t) + b u(t)$ 和代价 $J = \\int_{0}^{\\infty} \\left(q x(t)^{2} + r u(t)^{2}\\right) dt$ 开始，其中 $a>0$，$b>0$，$q>0$ 且 $r>0$。连续时间LQR最优控制律为 $u(t) = -K x(t)$，其中 $K = R^{-1} B^{T} P$，$P$ 是以下代数Riccati方程的唯一半正定稳定解：\n$$\nA^{T} P + P A - P B R^{-1} B^{T} P + Q = 0.\n$$\n在标量情况下，$A=a$，$B=b$，$Q=q$ 且 $R=r$，因此Riccati方程变为\n$$\n2 a P - \\frac{b^{2}}{r} P^{2} + q = 0.\n$$\n在 $u=-Kx$ 控制下的闭环系统为 $\\dot{x} = (a - bK) x$，因此其唯一的极点是\n$$\ns = a - b K = a - \\frac{b^{2}}{r} P.\n$$\n为了用 $a、b、q$ 和 $r$ 直接表示 $s$，我们将 $P = \\frac{r}{b^{2}}(a - s)$ 代入Riccati方程：\n$$\n2 a \\left(\\frac{r}{b^{2}}(a - s)\\right) - \\frac{b^{2}}{r} \\left(\\frac{r}{b^{2}}(a - s)\\right)^{2} + q = 0,\n$$\n化简后得到：\n$$\n\\frac{2 a r}{b^{2}}(a - s) - \\frac{r}{b^{2}}(a - s)^{2} + q = 0.\n$$\n两边乘以 $\\frac{b^{2}}{r}$ 得到：\n$$\n2 a (a - s) - (a - s)^{2} + \\frac{q b^{2}}{r} = 0.\n$$\n令 $y = a - s$，我们得到二次方程：\n$$\ny^{2} - 2 a y - \\frac{q b^{2}}{r} = 0.\n$$\n解出 $y$ 得：\n$$\ny = a \\pm \\sqrt{a^{2} + \\frac{q b^{2}}{r}}.\n$$\n由于对于稳定解，$P = \\frac{r}{b^{2}} y$ 必须为非负值，且 $a>0$，我们选择正分支 $y = a + \\sqrt{a^{2} + \\frac{q b^{2}}{r}}$。因此，\n$$\ns = a - y = a - \\left(a + \\sqrt{a^{2} + \\frac{q b^{2}}{r}}\\right) = - \\sqrt{a^{2} + \\frac{q b^{2}}{r}}.\n$$\n这是一个负实数极点，确保了闭环系统的稳定性。", "answer": "$$\\boxed{-\\sqrt{a^{2}+\\frac{q b^{2}}{r}}}$$", "id": "1589492"}, {"introduction": "控制设计的一项关键技能是调整参数以实现期望的行为。本练习探讨了控制努力权重 $R$ 与系统稳定性之间的直观关系 [@problem_id:1589454]。通过分析当您使控制动作的“代价”变得极其昂贵（$R \\to \\infty$）时系统的行为，您将发现LQR调参的一个基本原则，并理解控制器如何回归到系统的自然动态。", "problem": "考虑一个标量、线性时不变（LTI）系统，其状态空间方程描述为：\n$$\n\\dot{x}(t) = A x(t) + B u(t)\n$$\n其中 $x(t)$ 是状态，$u(t)$ 是控制输入，$A$ 和 $B$ 是非零实数标量常数。已知该系统是开环稳定的。\n\n使用线性二次调节器（LQR）框架设计了一个形式为 $u(t) = -Kx(t)$ 的状态反馈控制器。选择控制器增益 $K$ 以最小化无限时域二次型代价函数：\n$$\nJ = \\int_{0}^{\\infty} \\left( Q x(t)^2 + R u(t)^2 \\right) dt\n$$\n其中 $Q$ 和 $R$ 是正常数标量加权因子（$Q > 0, R > 0$）。该设计得到一个闭环系统 $\\dot{x}(t) = (A - BK)x(t)$。\n\n确定当控制加权参数 $R$ 趋于无穷大时，该闭环系统单个极点的渐近位置。用系统参数 $A$ 表示你的答案。", "solution": "我们处理的是标量连续时间LQR问题，其动态方程为 $\\dot{x}(t) = A x(t) + B u(t)$，状态反馈为 $u(t) = -K x(t)$，旨在最小化\n$$\nJ = \\int_{0}^{\\infty} \\left( Q x(t)^{2} + R u(t)^{2} \\right) dt,\n$$\n其中 $Q>0$ 且 $R>0$。最优增益为 $K = R^{-1} B P$，其中 $P$ 是代数 Riccati 方程的解\n$$\nA^{T} P + P A - P B R^{-1} B^{T} P + Q = 0.\n$$\n对于标量情况，$A^{T} = A$ 且 $B^{T} = B$，因此代数 Riccati 方程（ARE）变为\n$$\n2 A P - \\frac{B^{2}}{R} P^{2} + Q = 0.\n$$\n闭环极点为\n$$\n\\lambda(R) = A - B K = A - \\frac{B^{2}}{R} P.\n$$\n当 $R \\to \\infty$ 时，我们分析代数 Riccati 方程。由于 $R^{-1} \\to 0$，含有 $R^{-1}$ 的项在极限情况下消失，任何极限点 $P_{\\infty}$ 都必须满足 Lyapunov 方程\n$$\n2 A P_{\\infty} + Q = 0.\n$$\n求解可得\n$$\nP_{\\infty} = -\\frac{Q}{2 A}.\n$$\n因为系统是开环稳定的，所以 $A<0$，因此 $P_{\\infty}>0$ 并且是有限的。所以，\n$$\n\\lim_{R \\to \\infty} K = \\lim_{R \\to \\infty} \\frac{B}{R} P = 0,\n$$\n闭环极点趋向于\n$$\n\\lim_{R \\to \\infty} \\lambda(R) = A - \\lim_{R \\to \\infty} \\frac{B^{2}}{R} P = A.\n$$\n因此，当 $R \\to \\infty$ 时，单个闭环极点的渐近位置是 $A$。", "answer": "$$\\boxed{A}$$", "id": "1589454"}, {"introduction": "到目前为止，我们都是从成本函数出发设计控制器。但是，如果我们已经有一个表现良好的控制器，并希望理解它所优化的性能标准，该怎么办呢？这个高级练习介绍了逆LQR问题，这是现代控制理论中的一个强大概念 [@problem_id:1589483]。您将从一个给定的稳定化增益 $k$ 出发，反向推导出其对应的状态权重矩阵 $Q$ 族，从而深入了解一个控制器是如何隐式地平衡状态调节和控制努力的。", "problem": "考虑一个可控的二阶线性时不变（LTI）系统，其状态空间方程为 $\\dot{x}(t) = Ax(t) + bu(t)$，其中状态为 $x(t) \\in \\mathbb{R}^2$，控制输入为标量 $u(t) \\in \\mathbb{R}$。系统矩阵由符号参数 $\\alpha, \\beta, \\gamma$ 给出：\n$$\nA = \\begin{pmatrix} 0 & 1 \\\\ \\alpha & \\beta \\end{pmatrix}, \\quad b = \\begin{pmatrix} 0 \\\\ \\gamma \\end{pmatrix}\n$$\n设计了一个形式为 $u(t) = -kx(t)$ 的状态反馈控制器，其增益为已知的行向量 $k = \\begin{pmatrix} k_1 & k_2 \\end{pmatrix}$。已知该增益可以稳定系统，这意味着闭环矩阵 $A_{cl} = A - bk$ 是 Hurwitz 矩阵。\n\n我们希望确定该控制器对于一个具有成本函数 $J = \\int_{0}^{\\infty} (x^T Q x + u^2) dt$ 的线性二次调节器（LQR）问题是否是最优的。注意，控制加权“矩阵”是标量 $R=1$。状态加权矩阵 $Q$ 是对称半正定的，但是未知的。\n\n对于一个给定的稳定增益 $k$ 和一个固定的 $R$，通常不存在一个唯一的矩阵 $Q$ 使得 $k$ 成为最优 LQR 增益。相反，存在一个此类矩阵族。对于给定的系统，这个 $Q$ 的解族可以由单个标量变量参数化。\n\n您的任务是找到状态加权矩阵 $Q$ 的一个通用表达式。用给定的符号常量 $\\alpha, \\beta, \\gamma, k_1, k_2$ 以及参数 $p_{11}$ 来表示您的答案。$p_{11}$ 代表对称正定矩阵 $P$ 的第一行第一列的元素，该矩阵 $P$ 是相应的代数 Riccati 方程的唯一解。", "solution": "我们考虑成本为 $J=\\int_{0}^{\\infty}(x^{T}Qx+u^{2})\\,dt$ 且 $R=1$ 的连续时间 LQR 问题。代数 Riccati 方程（ARE）为\n$$\nA^{T}P+PA-Pbb^{T}P+Q=0,\n$$\n且最优增益为\n$$\nk=R^{-1}b^{T}P=b^{T}P.\n$$\n设 $P=\\begin{pmatrix}p_{11}&p_{12}\\\\ p_{12}&p_{22}\\end{pmatrix}$ 且 $P=P^{T}\\succ 0$。使用 $b=\\begin{pmatrix}0\\\\ \\gamma\\end{pmatrix}$，我们计算可得\n$$\nk=b^{T}P=\\begin{pmatrix}0&\\gamma\\end{pmatrix}\\begin{pmatrix}p_{11}&p_{12}\\\\ p_{12}&p_{22}\\end{pmatrix}=\\begin{pmatrix}\\gamma p_{12}&\\gamma p_{22}\\end{pmatrix}.\n$$\n将其与给定的稳定增益 $k=\\begin{pmatrix}k_{1}&k_{2}\\end{pmatrix}$ 相等，可得\n$$\np_{12}=\\frac{k_{1}}{\\gamma},\\qquad p_{22}=\\frac{k_{2}}{\\gamma},\n$$\n因此 $p_{11}$ 仍然是一个自由参数（记为 $p_{11}$）。接下来，从 ARE 我们得到\n$$\nQ=-A^{T}P-PA+Pbb^{T}P.\n$$\n使用 $A=\\begin{pmatrix}0&1\\\\ \\alpha&\\beta\\end{pmatrix}$ 和 $A^{T}=\\begin{pmatrix}0&\\alpha\\\\ 1&\\beta\\end{pmatrix}$，计算\n$$\nA^{T}P=\\begin{pmatrix}\\alpha p_{12}&\\alpha p_{22}\\\\ p_{11}+\\beta p_{12}&p_{12}+\\beta p_{22}\\end{pmatrix},\\qquad\nPA=\\begin{pmatrix}\\alpha p_{12}&p_{11}+\\beta p_{12}\\\\ \\alpha p_{22}&p_{12}+\\beta p_{22}\\end{pmatrix},\n$$\n所以\n$$\nA^{T}P+PA=\\begin{pmatrix}\n2\\alpha p_{12} & p_{11}+\\beta p_{12}+\\alpha p_{22}\\\\\np_{11}+\\beta p_{12}+\\alpha p_{22} & 2(p_{12}+\\beta p_{22})\n\\end{pmatrix}.\n$$\n此外，\n$$\nPbb^{T}P=(Pb)(b^{T}P)=(Pb)\\,k=\\begin{pmatrix}\\gamma p_{12}\\\\ \\gamma p_{22}\\end{pmatrix}\\begin{pmatrix}k_{1}&k_{2}\\end{pmatrix}\n=\\begin{pmatrix}k_{1}^{2}&k_{1}k_{2}\\\\ k_{1}k_{2}&k_{2}^{2}\\end{pmatrix},\n$$\n因为 $\\gamma p_{12}=k_{1}$ 且 $\\gamma p_{22}=k_{2}$。代入 $p_{12}=\\frac{k_{1}}{\\gamma}$ 和 $p_{22}=\\frac{k_{2}}{\\gamma}$ 可得\n$$\nA^{T}P+PA=\\begin{pmatrix}\n\\frac{2\\alpha k_{1}}{\\gamma} & p_{11}+\\frac{\\alpha k_{2}+\\beta k_{1}}{\\gamma}\\\\\np_{11}+\\frac{\\alpha k_{2}+\\beta k_{1}}{\\gamma} & \\frac{2(k_{1}+\\beta k_{2})}{\\gamma}\n\\end{pmatrix}.\n$$\n因此，\n$$\nQ=Pbb^{T}P-(A^{T}P+PA)=\\begin{pmatrix}\nk_{1}^{2}-\\frac{2\\alpha k_{1}}{\\gamma} & k_{1}k_{2}-p_{11}-\\frac{\\alpha k_{2}+\\beta k_{1}}{\\gamma}\\\\\nk_{1}k_{2}-p_{11}-\\frac{\\alpha k_{2}+\\beta k_{1}}{\\gamma} & k_{2}^{2}-\\frac{2(k_{1}+\\beta k_{2})}{\\gamma}\n\\end{pmatrix}.\n$$\n这就是我们所求的、由 $p_{11}$ 参数化的状态加权矩阵 $Q$ 的单参数族。对于这个矩阵族中的任意矩阵 $Q$，给定的稳定增益 $k$ 在 $R=1$ 的情况下都是最优的 LQR 反馈。", "answer": "$$\\boxed{\\begin{pmatrix}\nk_{1}^{2}-\\frac{2\\alpha k_{1}}{\\gamma} & k_{1}k_{2}-p_{11}-\\frac{\\alpha k_{2}+\\beta k_{1}}{\\gamma}\\\\\nk_{1}k_{2}-p_{11}-\\frac{\\alpha k_{2}+\\beta k_{1}}{\\gamma} & k_{2}^{2}-\\frac{2\\left(k_{1}+\\beta k_{2}\\right)}{\\gamma}\n\\end{pmatrix}}$$", "id": "1589483"}]}