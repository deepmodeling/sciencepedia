{"hands_on_practices": [{"introduction": "Before a Graph Neural Network can learn from a biological system, we must first translate the complex web of interactions into a language computers understand. This fundamental step involves choosing a data structure to represent the network's nodes and edges. This first practice exercise [@problem_id:1436682] focuses on this crucial translation, asking you to represent a simple metabolic pathway using two of the most common formats: the adjacency matrix and the edge list. Mastering this conversion is the essential starting point for applying GNNs to any biological network.", "problem": "In systems biology, metabolic pathways are often modeled as graphs to be analyzed by machine learning algorithms like Graph Neural Networks (GNNs). Consider a simple hypothetical metabolic pathway involving four metabolites: M1, M2, M3, and M4. The biochemical reactions in this pathway, which define the connections in our graph, are as follows:\n\n1.  Metabolite M1 is a substrate that is converted into Metabolite M2.\n2.  Metabolite M2 is a substrate that can be converted into Metabolite M3.\n3.  Metabolite M2 can also be converted into Metabolite M4 via a separate reaction.\n\nThese reactions can be represented as a directed graph where an edge from node $u$ to node $v$ signifies that metabolite $u$ is a substrate for a reaction that produces metabolite $v$. For processing by a GNN, this graph must be converted into a numerical format. Two common formats are the adjacency matrix and the edge list.\n\nLet the metabolites be indexed as nodes in the following order: M1=1, M2=2, M3=3, M4=4. The adjacency matrix, $A$, is a square matrix where the entry $A_{ij}$ is 1 if there is a directed edge from node $i$ to node $j$, and 0 otherwise. The edge list is a list of pairs, where each pair `[source, target]` represents a directed edge.\n\nGiven the pathway described, which of the following options correctly provides both the adjacency matrix and the edge list representation of the graph?\n\nA.\nAdjacency Matrix:\n$$\n\\begin{pmatrix} 0 & 1 & 0 & 0 \\\\ 0 & 0 & 1 & 1 \\\\ 0 & 0 & 0 & 0 \\\\ 0 & 0 & 0 & 0 \\end{pmatrix}\n$$\nEdge List: `[[1, 2], [2, 3], [2, 4]]`\n\nB.\nAdjacency Matrix:\n$$\n\\begin{pmatrix} 0 & 1 & 0 & 0 \\\\ 1 & 0 & 1 & 1 \\\\ 0 & 1 & 0 & 0 \\\\ 0 & 1 & 0 & 0 \\end{pmatrix}\n$$\nEdge List: `[[1, 2], [2, 1], [2, 3], [3, 2], [2, 4], [4, 2]]`\n\nC.\nAdjacency Matrix:\n$$\n\\begin{pmatrix} 0 & 1 & 0 & 0 \\\\ 0 & 0 & 1 & 0 \\\\ 0 & 0 & 0 & 0 \\\\ 0 & 0 & 0 & 0 \\end{pmatrix}\n$$\nEdge List: `[[1, 2], [2, 3]]`\n\nD.\nAdjacency Matrix:\n$$\n\\begin{pmatrix} 0 & 0 & 0 & 0 \\\\ 1 & 0 & 0 & 0 \\\\ 0 & 1 & 0 & 0 \\\\ 0 & 1 & 0 & 0 \\end{pmatrix}\n$$\nEdge List: `[[2, 1], [3, 2], [4, 2]]`", "solution": "The pathway defines directed reactions: M1 to M2, M2 to M3, and M2 to M4. With node indices M1=1, M2=2, M3=3, M4=4, the directed edges implied by the reactions are $(1,2)$, $(2,3)$, and $(2,4)$.\n\nBy definition of the adjacency matrix $A$, $A_{ij}=1$ if there is a directed edge from node $i$ to node $j$, and $A_{ij}=0$ otherwise. Therefore, the only nonzero entries are $A_{12}=1$, $A_{23}=1$, and $A_{24}=1$, with all other entries equal to $0$. This yields\n$$\nA=\\begin{pmatrix}\n0 & 1 & 0 & 0\\\\\n0 & 0 & 1 & 1\\\\\n0 & 0 & 0 & 0\\\\\n0 & 0 & 0 & 0\n\\end{pmatrix}.\n$$\nThe edge list is the set of directed pairs recording the same edges, namely $[[1,2],[2,3],[2,4]]$.\n\nComparing with the options:\n- Option A has exactly this adjacency matrix and edge list, so it is correct.\n- Option B includes additional reverse edges $(2,1)$, $(3,2)$, and $(4,2)$ that are not present, so it is incorrect.\n- Option C omits the edge $(2,4)$, so it is incomplete and incorrect.\n- Option D reverses the direction of all edges, so it is incorrect.\n\nThus, the correct choice is A.", "answer": "$$\\boxed{A}$$", "id": "1436682"}, {"introduction": "At the heart of every GNN is the message-passing mechanism, where nodes communicate with and update each other based on their connections. This exercise [@problem_id:1436694] demystifies this process by guiding you through a single, concrete computational step. You will calculate how a protein's feature vector, representing its biological properties, is updated by aggregating information from its immediate neighbors in a protein-protein interaction network. This calculation is the fundamental building block upon which deep graph learning is built.", "problem": "In the field of systems biology, Graph Neural Networks (GNNs) are powerful tools for learning from data structured as networks, such as protein-protein interaction (PPI) networks. Consider a simple GNN model designed to update the features of proteins based on their connections.\n\nWe are focused on a small part of a PPI network involving a central protein, Protein V, which interacts with two neighboring proteins, Protein U1 and Protein U2. Each protein is described by a 2-dimensional feature vector. The first element of the vector represents the protein's normalized expression level, and the second element represents its mitochondrial localization score.\n\nThe initial feature vectors are given as:\n- Protein V: $h_V = \\begin{pmatrix}0.1 & 0.9\\end{pmatrix}$\n- Protein U1: $h_{U1} = \\begin{pmatrix}0.2 & 0.3\\end{pmatrix}$\n- Protein U2: $h_{U2} = \\begin{pmatrix}0.6 & 0.1\\end{pmatrix}$\n\nThe GNN performs an update to find a new feature vector for Protein V, denoted as $h'_V$, in a single message-passing step. This process involves two stages:\n\n1.  **Aggregation:** An aggregated neighbor vector, $h_{N(V)}$, is created by taking the element-wise sum of the feature vectors of all of Protein V's neighbors.\n2.  **Update:** The new feature vector $h'_V$ is calculated by adding the aggregated neighbor vector $h_{N(V)}$ to Protein V's original feature vector $h_V$, and then applying an element-wise Rectified Linear Unit (ReLU) activation function to the result. The ReLU function is defined as $\\operatorname{ReLU}(x) = \\max(0, x)$ for each component of the vector.\n\nCalculate the updated feature vector $h'_V$ for Protein V.", "solution": "We are given initial feature vectors for three proteins:\n$$\nh_{V}=\\begin{pmatrix}0.1 & 0.9\\end{pmatrix},\\quad\nh_{U1}=\\begin{pmatrix}0.2 & 0.3\\end{pmatrix},\\quad\nh_{U2}=\\begin{pmatrix}0.6 & 0.1\\end{pmatrix}.\n$$\nAggregation step: the aggregated neighbor vector is the element-wise sum of neighbor features,\n$$\nh_{N(V)}=h_{U1}+h_{U2}\n=\\begin{pmatrix}0.2 & 0.3\\end{pmatrix}+\\begin{pmatrix}0.6 & 0.1\\end{pmatrix}\n=\\begin{pmatrix}0.8 & 0.4\\end{pmatrix}.\n$$\nUpdate step: apply the element-wise ReLU to the sum of $h_{V}$ and $h_{N(V)}$,\n$$\nh'_{V}=\\operatorname{ReLU}\\!\\big(h_{V}+h_{N(V)}\\big)\n=\\operatorname{ReLU}\\!\\left(\\begin{pmatrix}0.1 & 0.9\\end{pmatrix}+\\begin{pmatrix}0.8 & 0.4\\end{pmatrix}\\right)\n=\\operatorname{ReLU}\\!\\begin{pmatrix}0.9 & 1.3\\end{pmatrix}.\n$$\nSince each component is positive, $\\operatorname{ReLU}(x)=x$ for both components, hence\n$$\nh'_{V}=\\begin{pmatrix}0.9 & 1.3\\end{pmatrix}.\n$$", "answer": "$$\\boxed{\\begin{pmatrix}0.9 & 1.3\\end{pmatrix}}$$", "id": "1436694"}, {"introduction": "While a single message-passing step updates a node based on its direct neighbors, the real power of GNNs emerges when we stack multiple layers. This allows information to propagate further, enabling a node to 'see' and incorporate information from a wider network environment. This final exercise [@problem_id:1436705] simulates this multi-layer process, allowing you to trace how a signal travels through a simple signaling pathway. By tracking the feature values step-by-step, you will gain an intuitive understanding of how a GNN builds sophisticated node representations that capture multi-hop neighborhood information.", "problem": "In the study of systems biology, protein signaling pathways are often modeled as graphs, where proteins are nodes and their interactions are edges. We can use a Graph Neural Network (GNN) to learn representations of these proteins that capture information about their local network environment.\n\nConsider a simplified linear signaling pathway consisting of four proteins: A, B, C, and D. This can be represented as an undirected graph where the nodes are the proteins and the edges represent interactions: (A, B), (B, C), and (C, D).\n\nInitially, each protein has a scalar feature value, representing a particular biochemical property. Let the initial feature values at layer $k=0$ be denoted by $h^{(0)}$. In our pathway, a signal originates at protein A, so its initial feature value is $h_A^{(0)} = w$, while the other proteins are in a basal state with zero feature value: $h_B^{(0)} = 0$, $h_C^{(0)} = 0$, and $h_D^{(0)} = 0$.\n\nThe GNN updates the feature value of each protein at each layer. The update rule for any protein (node) $v$ at the next layer, $k+1$, is a function of its own feature value and the feature values of its immediate neighbors from the current layer, $k$. Specifically, the new feature value is the average of the feature values of the node itself and its neighbors. Mathematically, the update rule is:\n$$h_v^{(k+1)} = \\frac{1}{|\\mathcal{N}(v)| + 1} \\left( h_v^{(k)} + \\sum_{u \\in \\mathcal{N}(v)} h_u^{(k)} \\right)$$\nwhere $\\mathcal{N}(v)$ is the set of neighbors of node $v$, and $|\\mathcal{N}(v)|$ is the number of neighbors.\n\nCalculate the feature value of protein D, $h_D$, after the network has processed the information for exactly three GNN layers (i.e., find $h_D^{(3)}$). Express your answer as a symbolic expression in terms of $w$.", "solution": "We model the undirected path graph A-B-C-D with neighbor sets $\\mathcal{N}(A)=\\{B\\}$, $\\mathcal{N}(B)=\\{A,C\\}$, $\\mathcal{N}(C)=\\{B,D\\}$, and $\\mathcal{N}(D)=\\{C\\}$. The layer-wise update rule is\n$$\nh_v^{(k+1)}=\\frac{1}{|\\mathcal{N}(v)|+1}\\left(h_v^{(k)}+\\sum_{u\\in\\mathcal{N}(v)}h_u^{(k)}\\right),\n$$\nwhich for each node becomes\n$$\nh_A^{(k+1)}=\\frac{h_A^{(k)}+h_B^{(k)}}{2},\\quad\nh_B^{(k+1)}=\\frac{h_B^{(k)}+h_A^{(k)}+h_C^{(k)}}{3},\\quad\nh_C^{(k+1)}=\\frac{h_C^{(k)}+h_B^{(k)}+h_D^{(k)}}{3},\\quad\nh_D^{(k+1)}=\\frac{h_D^{(k)}+h_C^{(k)}}{2}.\n$$\nWith initial features\n$$\nh_A^{(0)}=w,\\quad h_B^{(0)}=0,\\quad h_C^{(0)}=0,\\quad h_D^{(0)}=0,\n$$\nwe compute layer by layer.\n\nAt $k=1$:\n$$\nh_A^{(1)}=\\frac{w+0}{2}=\\frac{w}{2},\\quad\nh_B^{(1)}=\\frac{0+w+0}{3}=\\frac{w}{3},\\quad\nh_C^{(1)}=\\frac{0+0+0}{3}=0,\\quad\nh_D^{(1)}=\\frac{0+0}{2}=0.\n$$\n\nAt $k=2$:\n$$\nh_A^{(2)}=\\frac{\\frac{w}{2}+\\frac{w}{3}}{2}=\\frac{5w}{12},\\quad\nh_B^{(2)}=\\frac{\\frac{w}{3}+\\frac{w}{2}+0}{3}=\\frac{5w}{18},\\quad\nh_C^{(2)}=\\frac{0+\\frac{w}{3}+0}{3}=\\frac{w}{9},\\quad\nh_D^{(2)}=\\frac{0+0}{2}=0.\n$$\n\nAt $k=3$:\n$$\nh_A^{(3)}=\\frac{\\frac{5w}{12}+\\frac{5w}{18}}{2}=\\frac{25w}{72},\\quad\nh_B^{(3)}=\\frac{\\frac{5w}{18}+\\frac{5w}{12}+\\frac{w}{9}}{3}=\\frac{29w}{108},\\quad\nh_C^{(3)}=\\frac{\\frac{w}{9}+\\frac{5w}{18}+0}{3}=\\frac{7w}{54},\\quad\nh_D^{(3)}=\\frac{0+\\frac{w}{9}}{2}=\\frac{w}{18}.\n$$\n\nTherefore, the feature value at protein D after three layers is $h_D^{(3)}=\\frac{w}{18}$.", "answer": "$$\\boxed{\\frac{w}{18}}$$", "id": "1436705"}]}