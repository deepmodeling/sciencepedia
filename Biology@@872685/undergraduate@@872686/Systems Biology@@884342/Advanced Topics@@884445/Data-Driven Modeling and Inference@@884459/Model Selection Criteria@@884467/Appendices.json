{"hands_on_practices": [{"introduction": "At the heart of scientific modeling lies a fundamental trade-off: we want models that are complex enough to capture the essential features of the data, but simple enough to be understandable and generalizable. This is the principle of parsimony, or Occam's razor. This exercise [@problem_id:1447591] provides a classic scenario in systems biology where you must use the Bayesian Information Criterion (BIC) to adjudicate between a simpler and a more complex model of bacterial growth. By working through it, you'll gain hands-on experience in applying a formal method to balance model fit with complexity, a core skill for any modeler.", "problem": "A systems biologist is investigating the population dynamics of a specific strain of bacteria in response to a fluctuating nutrient environment. Two competing mathematical models, Model A and Model B, are proposed to describe the bacterial growth. The biologist performs an experiment and collects a time-series dataset consisting of $n=200$ measurements of the bacterial population density.\n\nModel A is a simpler model with $k_A = 3$ adjustable parameters. After fitting this model to the experimental data, the maximum value of the natural logarithm of the likelihood function is found to be $\\ln(\\mathcal{L}_A) = -180.5$.\n\nModel B is a more complex model that incorporates additional dynamics, involving a total of $k_B = 5$ adjustable parameters. Fitting this model to the same dataset yields a maximum natural log-likelihood of $\\ln(\\mathcal{L}_B) = -177.0$.\n\nTo decide which model is better supported by the data while penalizing for complexity, the researcher uses the Bayesian Information Criterion (BIC). The BIC is calculated using the formula:\n$$BIC = k \\ln(n) - 2 \\ln(\\mathcal{L})$$\nwhere $k$ is the number of parameters in the model, $n$ is the number of data points, and $\\ln(\\mathcal{L})$ is the maximum natural log-likelihood. A model with a lower BIC score is considered a better fit to the data.\n\nTo quantify the evidence of one model over the other, calculate the difference $\\Delta BIC = BIC_{B} - BIC_{A}$. Express your answer for $\\Delta BIC$ as a real number rounded to three significant figures.", "solution": "The Bayesian Information Criterion for a model with parameter count $k$, sample size $n$, and maximum log-likelihood $\\ln(\\mathcal{L})$ is\n$$\nBIC = k \\ln(n) - 2 \\ln(\\mathcal{L}).\n$$\nFor Model A with $k_{A} = 3$, $n = 200$, and $\\ln(\\mathcal{L}_{A}) = -180.5$,\n$$\nBIC_{A} = 3 \\ln(200) - 2(-180.5) = 3 \\ln(200) + 361.\n$$\nFor Model B with $k_{B} = 5$, $n = 200$, and $\\ln(\\mathcal{L}_{B}) = -177.0$,\n$$\nBIC_{B} = 5 \\ln(200) - 2(-177.0) = 5 \\ln(200) + 354.\n$$\nThe difference is\n$$\n\\Delta BIC = BIC_{B} - BIC_{A} = \\left(5 \\ln(200) + 354\\right) - \\left(3 \\ln(200) + 361\\right) = 2 \\ln(200) - 7.\n$$\nCompute $\\ln(200)$ numerically:\n$$\n\\ln(200) = \\ln(2) + 2 \\ln(10) \\approx 0.6931471806 + 2 \\times 2.302585093 \\approx 5.298317367.\n$$\nTherefore,\n$$\n\\Delta BIC \\approx 2 \\times 5.298317367 - 7 = 10.596634734 - 7 = 3.596634734.\n$$\nRounding to three significant figures gives $3.60$.", "answer": "$$\\boxed{3.60}$$", "id": "1447591"}, {"introduction": "As you delve deeper into statistical modeling, you may encounter situations where different methods seem to give conflicting advice. For instance, a hypothesis test might suggest a parameter is not statistically significant, yet a model including that parameter is strongly preferred by a selection criterion like BIC. This exercise [@problem_id:1447569] presents exactly such a scenario, forcing a reconciliation between the world of null hypothesis testing and information-theoretic model selection. It illuminates the crucial difference between asking \"is this parameter's effect non-zero?\" and \"does including this parameter lead to a better overall model for prediction and explanation?\"", "problem": "A systems biologist is modeling a genetic autoregulatory circuit where a protein P is believed to repress its own synthesis. Two competing models are proposed to explain the dynamics of protein concentration measured at $n=150$ discrete time points.\n\nModel 1 (M1) is a simple model of constitutive gene expression and protein degradation. It has $k_1 = 2$ parameters: a production rate and a degradation rate. After fitting this model to the experimental data, the maximized log-likelihood is found to be $\\ln(L_1) = -125.8$.\n\nModel 2 (M2) is a more complex model that includes an additional parameter, $\\kappa$, representing the strength of the negative feedback loop. This model has $k_2 = 3$ parameters in total. Fitting Model 2 yields a maximized log-likelihood of $\\ln(L_2) = -122.1$. However, a subsequent statistical analysis of Model 2 reveals that the 95% confidence interval for the feedback parameter $\\kappa$ is $[-0.11, 2.54]$, which includes zero.\n\nTo resolve which model is better supported by the data, you decide to compare them using the Bayesian Information Criterion (BIC), which is defined as $\\text{BIC} = k \\ln(n) - 2\\ln(L)$, where $k$ is the number of estimated parameters in the model, $n$ is the number of data points, and $\\ln(L)$ is the maximized log-likelihood for the model. A model with a lower BIC score is considered preferable.\n\nCalculate the difference $\\Delta \\text{BIC} = \\text{BIC}_1 - \\text{BIC}_2$. A positive value indicates that Model 2 is preferred over Model 1. Report your answer rounded to three significant figures.", "solution": "We compare models using the Bayesian Information Criterion defined by $\\text{BIC} = k \\ln(n) - 2 \\ln(L)$. The difference is\n$$\n\\Delta \\text{BIC} = \\text{BIC}_{1} - \\text{BIC}_{2} = \\left(k_{1} \\ln(n) - 2 \\ln(L_{1})\\right) - \\left(k_{2} \\ln(n) - 2 \\ln(L_{2})\\right).\n$$\nCollecting terms gives\n$$\n\\Delta \\text{BIC} = (k_{1} - k_{2}) \\ln(n) - 2 \\left(\\ln(L_{1}) - \\ln(L_{2})\\right).\n$$\nSubstitute $k_{1} = 2$, $k_{2} = 3$, $n = 150$, $\\ln(L_{1}) = -125.8$, and $\\ln(L_{2}) = -122.1$:\n$$\n\\Delta \\text{BIC} = (2 - 3)\\ln(150) - 2\\left((-125.8) - (-122.1)\\right) = -\\ln(150) - 2(-3.7) = -\\ln(150) + 7.4.\n$$\nUsing $\\ln(150) \\approx 5.010635294$, we obtain\n$$\n\\Delta \\text{BIC} \\approx 7.4 - 5.010635294 = 2.389364706.\n$$\nRounding to three significant figures gives $2.39$. Since this is positive, Model 2 is preferred over Model 1.", "answer": "$$\\boxed{2.39}$$", "id": "1447569"}, {"introduction": "The power of model selection criteria like AIC and BIC comes with an important condition: the comparison must be fair. These criteria are based on comparing model likelihoods, which measure how probable the observed data are given the model. This exercise [@problem_id:1447532] highlights a critical and common pitfall where this fairness principle is violated. By analyzing two modeling approaches—one on raw data and one on log-transformed data—you will uncover why directly comparing their BIC scores is statistically invalid, reinforcing the essential lesson that models can only be compared if their likelihoods are calculated for the exact same data on the same scale.", "problem": "A researcher in systems biology is studying the degradation of a fluorescent protein in a cell culture. They collect fluorescence intensity data, $y_i$, at a series of time points, $t_i$, where $i=1, \\dots, n$. The researcher proposes a simple exponential decay model for this process. However, they are unsure whether to fit the model to the raw fluorescence data or to the natural logarithm of the data.\n\nLet's define the two approaches:\n- **Model A**: Fits the function $f_A(t, a, b) = a \\exp(-bt)$ directly to the raw data, $y_i$. The model assumes that the observed data points $y_i$ are samples from a normal distribution with mean $f_A(t_i, a, b)$ and a constant variance $\\sigma_A^2$.\n- **Model B**: Fits the linear function $f_B(t, c, d) = c - dt$ to the log-transformed data, $z_i = \\ln(y_i)$. This is equivalent to fitting the model $y(t) = \\exp(c - dt)$, which has the same form as Model A. This model assumes that the transformed data points $z_i$ are samples from a normal distribution with mean $f_B(t_i, c, d)$ and a constant variance $\\sigma_B^2$.\n\nAfter performing both fits, the researcher calculates the Bayesian Information Criterion (BIC) for each model, defined as $BIC = k \\ln(n) - 2 \\ln(\\hat{L})$, where $k$ is the number of estimated parameters, $n$ is the number of data points, and $\\hat{L}$ is the maximized value of the likelihood function. They find that the BIC for Model B is significantly lower (indicating a better fit according to the criterion) than the BIC for Model A. They conclude that fitting the model to the log-transformed data is the superior approach for this dataset.\n\nWhich of the following statements provides the most fundamental and statistically rigorous reason why the researcher's direct comparison of the two BIC values is invalid?\n\nA. The BIC is only valid for models where the errors are known to be perfectly normally distributed, and the logarithmic transformation of the data may have distorted a previously normal error distribution.\n\nB. The logarithmic transformation changes the scale of the dependent variable, which artificially and unfairly deflates the residual sum of squares, thus leading to an invalidly small BIC value for Model B.\n\nC. The models are not nested within each other, and BIC can only be used to compare nested models.\n\nD. The likelihoods, $\\hat{L}_A$ and $\\hat{L}_B$, are calculated with respect to different probability density functions (one for the variable $Y$ and one for the variable $Z = \\ln(Y)$) and are therefore not on a comparable scale.\n\nE. The number of parameters, $k$, is different between the two models because Model B includes an implicit transformation parameter, which is not accounted for in the BIC calculation.", "solution": "Let the observed data be $y_{1},\\dots,y_{n}$ at times $t_{1},\\dots,t_{n}$, with $z_{i}=\\ln(y_{i})$ for all $i$.\n\nUnder Model A, the observation model on the original scale is\n$$\nY_{i}\\mid a,b,\\sigma_{A}^{2} \\sim \\mathcal{N}\\!\\left(\\mu_{i},\\sigma_{A}^{2}\\right),\\quad \\mu_{i}=a\\exp(-b t_{i}),\n$$\nso the log-likelihood for the observed $y_{1:n}$ is\n$$\n\\ell_{A}(a,b,\\sigma_{A}^{2})\n= -\\frac{n}{2}\\ln(2\\pi) - n\\ln(\\sigma_{A}) - \\frac{1}{2\\sigma_{A}^{2}} \\sum_{i=1}^{n} \\left(y_{i}-a\\exp(-b t_{i})\\right)^{2}.\n$$\n\nUnder Model B as fitted on the log scale, the model is\n$$\nZ_{i}=\\ln(Y_{i}) \\mid c,d,\\sigma_{B}^{2} \\sim \\mathcal{N}\\!\\left(\\eta_{i},\\sigma_{B}^{2}\\right),\\quad \\eta_{i}=c-d t_{i}.\n$$\nThe log-likelihood for the transformed data $z_{1:n}$ is\n$$\n\\ell_{B,Z}(c,d,\\sigma_{B}^{2})\n= -\\frac{n}{2}\\ln(2\\pi) - n\\ln(\\sigma_{B}) - \\frac{1}{2\\sigma_{B}^{2}} \\sum_{i=1}^{n} \\left(\\ln y_{i} - (c - d t_{i})\\right)^{2}.\n$$\n\nHowever, BIC is derived from an asymptotic approximation to the log marginal likelihood for the observed data. To compare models on the same footing, both likelihoods must be written for the same observed variable. The likelihood for $Y$ implied by Model B is obtained by change of variables. Since $z=\\ln y$ is monotone with inverse $y=\\exp z$ and Jacobian $\\left|\\frac{dy}{dz}\\right|=y$, the implied density for $Y$ under Model B is\n$$\np_{Y|B}(y_{i}\\mid c,d,\\sigma_{B}^{2})\n= p_{Z|B}(\\ln y_{i}\\mid c,d,\\sigma_{B}^{2}) \\cdot \\frac{1}{y_{i}}\n= \\frac{1}{y_{i}\\,\\sigma_{B}\\sqrt{2\\pi}} \\exp\\!\\left(-\\frac{(\\ln y_{i}-(c-d t_{i}))^{2}}{2\\sigma_{B}^{2}}\\right),\n$$\nfor $y_{i}0$. Therefore, the log-likelihood for the observed $y_{1:n}$ under Model B is\n$$\n\\ell_{B,Y}(c,d,\\sigma_{B}^{2})\n= \\ell_{B,Z}(c,d,\\sigma_{B}^{2}) - \\sum_{i=1}^{n} \\ln y_{i}.\n$$\nThe term $-\\sum_{i=1}^{n}\\ln y_{i}$ is the log-Jacobian and depends only on the data and the transformation, not on $(c,d,\\sigma_{B}^{2})$.\n\nThe BIC used for model comparison is $BIC = k \\ln(n) - 2 \\ln(\\hat{L})$, where $\\hat{L}$ is the maximized likelihood for the observed data under the model. Thus, the correct BIC for Model B, comparable to Model A, must use $\\hat{L}$ computed for $Y$, namely\n$$\nBIC_{B,\\text{correct}} \\;=\\; k_{B}\\ln(n) - 2\\ln \\hat{L}_{B}(Y)\n\\;=\\; k_{B}\\ln(n) - 2\\left(\\ln \\hat{L}_{B}(Z) - \\sum_{i=1}^{n}\\ln y_{i}\\right)\n\\;=\\; \\bigl(k_{B}\\ln(n) - 2\\ln \\hat{L}_{B}(Z)\\bigr) + 2\\sum_{i=1}^{n}\\ln y_{i}.\n$$\nIf the researcher instead directly compares $BIC_{A}$, computed from $\\ln \\hat{L}_{A}(Y)$, to $BIC_{B}$ computed from $\\ln \\hat{L}_{B}(Z)$, they are comparing likelihoods defined on different sample spaces and with different base measures. The missing log-Jacobian term means the two BIC values are not on a common scale. The rigorous requirement is to compare models using likelihoods for the same observed variable; equivalently, to include the Jacobian so that both BIC values are computed from $\\ln \\hat{L}$ for $Y$.\n\nTherefore, the most fundamental and statistically rigorous reason the direct comparison is invalid is that the likelihoods are computed with respect to different probability density functions (one for $Y$, one for $Z=\\ln Y$), and thus are not directly comparable without the change-of-variables adjustment. This corresponds to option D. For completeness: BIC can compare non-nested models, so C is false; normality is a modeling assumption within each model and does not invalidate BIC per se, so A is false; claims about residual sum of squares scaling (B) are not the fundamental issue when using likelihood-based criteria; and there is no extra parameter for the log transformation in Model B, so E is false.", "answer": "$$\\boxed{D}$$", "id": "1447532"}]}