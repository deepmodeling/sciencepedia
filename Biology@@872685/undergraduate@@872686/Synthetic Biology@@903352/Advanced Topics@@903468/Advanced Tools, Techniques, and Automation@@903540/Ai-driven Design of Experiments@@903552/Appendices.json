{"hands_on_practices": [{"introduction": "The first step in any engineering design process, especially one driven by AI, is to comprehend the scale of the challenge. This practice explores the concept of the \"design space\"—the total set of all possible solutions. By calculating the number of potential protein variants, you will gain a tangible appreciation for why brute-force screening is infeasible for most biological systems and why intelligent search algorithms are indispensable [@problem_id:2018103].", "problem": "A synthetic biology startup is using an Artificial Intelligence (AI) platform to engineer a novel fluorescent protein for bio-imaging applications. The starting point is a wild-type protein consisting of a single chain of 100 amino acids. The AI model predicts that the protein's fluorescence can be maximized by introducing exactly two point mutations. A point mutation is defined as changing the amino acid at a single position to any of the other standard amino acids. Assuming there are 20 standard proteinogenic amino acids, calculate the total size of the design space that the AI must explore. This corresponds to the total number of unique protein variants that have exactly two amino acids different from the wild-type sequence.", "solution": "We must count all protein variants that differ from the wild-type at exactly two positions.\n\n- There are $100$ positions in the sequence. Choosing exactly two distinct positions to mutate is a combinations problem, since the order of the two positions does not matter. By the combinations formula, the number of ways to choose these positions is\n$$\n\\binom{100}{2}.\n$$\n\n- For each chosen position, the original amino acid must be changed to a different one. With $20$ standard amino acids, there are $20-1=19$ possible replacements at each position. The choices at the two positions are independent, giving\n$$\n19 \\times 19 = 19^{2}\n$$\nsubstitution choices for a fixed pair of positions.\n\n- By the multiplication principle of counting, the total number of variants with exactly two mutations is\n$$\nN=\\binom{100}{2} \\times 19^{2}.\n$$", "answer": "$$\\boxed{\\binom{100}{2}\\times 19^{2}}$$", "id": "2018103"}, {"introduction": "An AI needs a clear, quantitative goal to guide its search through a vast design space. This exercise demonstrates how to translate a multi-faceted biological objective, such as maximizing protein production while minimizing cost, into a mathematical \"utility function\". Formulating such functions is a critical skill in AI-driven design, as it provides the compass that directs the optimization process toward economically and scientifically valuable outcomes [@problem_id:2018121].", "problem": "In a modern bio-foundry, an Artificial Intelligence (AI) agent is tasked with optimizing the production of a therapeutic protein. The synthesis of this protein in a bacterial culture is induced by a specific chemical, and the final protein yield, $Y$, is known to follow a saturation model as a function of the inducer's concentration, $[I]$. This relationship is described by the equation:\n$$Y([I]) = \\frac{Y_{\\text{max}} [I]}{K + [I]}$$\nwhere $Y_{\\text{max}}$ is the maximum possible protein yield and $K$ is the saturation constant, representing the inducer concentration at which the yield is half of its maximum.\n\nThe inducer is expensive, and its cost is directly proportional to the concentration used. To balance the benefit of high yield against the cost of the inducer, the AI uses a utility function, $U([I])$, which it aims to maximize:\n$$U([I]) = Y([I]) - \\lambda [I]$$\nHere, $\\lambda$ is a positive constant that represents the marginal cost of the inducer, normalized into the same units as the yield. Assume that the system parameters are such that $\\frac{Y_{\\text{max}}}{\\lambda} > K$, which ensures that using a non-zero amount of inducer is beneficial.\n\nYour task is to determine the optimal inducer concentration, $[I]_{\\text{opt}}$, that the AI should select to maximize this utility function. Provide your answer as a single symbolic expression in terms of $Y_{\\text{max}}$, $K$, and $\\lambda$.", "solution": "We are to maximize the utility $U([I]) = Y([I]) - \\lambda [I]$ with respect to $[I] \\ge 0$, where $Y([I]) = \\dfrac{Y_{\\text{max}}[I]}{K + [I]}$ and $\\lambda > 0$, $K > 0$, $Y_{\\text{max}} > 0$. Since $U$ is differentiable for $[I] > -K$ and the feasible domain is $[I] \\ge 0$, we use first-order optimality and verify the second-order condition.\n\nFirst compute the derivative of $Y([I])$ using the quotient rule. Let $g([I]) = Y_{\\text{max}}[I]$ and $h([I]) = K + [I]$. Then $g'([I]) = Y_{\\text{max}}$ and $h'([I]) = 1$, and the quotient rule gives\n$$\n\\frac{dY}{d[I]} = \\frac{g'([I])h([I]) - g([I])h'([I])}{h([I])^{2}} = \\frac{Y_{\\text{max}}(K + [I]) - Y_{\\text{max}}[I]}{(K + [I])^{2}} = \\frac{Y_{\\text{max}}K}{(K + [I])^{2}}.\n$$\nTherefore,\n$$\n\\frac{dU}{d[I]} = \\frac{dY}{d[I]} - \\lambda = \\frac{Y_{\\text{max}}K}{(K + [I])^{2}} - \\lambda.\n$$\nSet the derivative to zero to obtain the first-order condition:\n$$\n\\frac{Y_{\\text{max}}K}{(K + [I])^{2}} - \\lambda = 0 \\quad \\Longrightarrow \\quad (K + [I])^{2} = \\frac{Y_{\\text{max}}K}{\\lambda}.\n$$\nTaking the positive square root (since $K + [I] > 0$ for $[I] \\ge 0$),\n$$\nK + [I] = \\sqrt{\\frac{Y_{\\text{max}}K}{\\lambda}} \\quad \\Longrightarrow \\quad [I]_{\\text{opt}} = \\sqrt{\\frac{Y_{\\text{max}}K}{\\lambda}} - K.\n$$\nTo confirm this is a maximum, compute the second derivative:\n$$\n\\frac{d^{2}U}{d[I]^{2}} = \\frac{d}{d[I]}\\left(\\frac{Y_{\\text{max}}K}{(K + [I])^{2}}\\right) = -\\frac{2Y_{\\text{max}}K}{(K + [I])^{3}} < 0 \\quad \\text{for} \\quad [I] \\ge 0,\n$$\nwhich ensures $U$ is strictly concave in $[I]$ and the critical point is a global maximum on its domain unless it lies outside $[I] \\ge 0$. The assumption $\\dfrac{Y_{\\text{max}}}{\\lambda} > K$ implies\n$$\n\\frac{Y_{\\text{max}}K}{\\lambda} > K^{2} \\quad \\Longrightarrow \\quad \\sqrt{\\frac{Y_{\\text{max}}K}{\\lambda}} > K \\quad \\Longrightarrow \\quad [I]_{\\text{opt}} > 0,\n$$\nso the optimal solution is interior and feasible. Therefore, the optimal inducer concentration is\n$$\n[I]_{\\text{opt}} = \\sqrt{\\frac{Y_{\\text{max}}K}{\\lambda}} - K.\n$$", "answer": "$$\\boxed{\\sqrt{\\frac{Y_{\\text{max}}K}{\\lambda}}-K}$$", "id": "2018121"}, {"introduction": "Building a predictive model is only half the battle; we must also rigorously prove its worth. This practice addresses the vital, yet often overlooked, step of model validation. It reveals a common and critical pitfall where a model shows high accuracy on a test set but is unable to generalize its predictions to truly novel sequences. Mastering this concept is essential for distinguishing between a model that has genuinely learned underlying biological principles and one that has simply memorized its training data [@problem_id:2018108].", "problem": "A synthetic biology research team is developing an Artificial Intelligence (AI) model to predict the catalytic efficiency of a specific enzyme family. Their goal is to use this model to screen for novel, high-activity enzyme variants for industrial applications. They assemble a dataset of 1,000 known enzyme sequences and their experimentally measured activities. They partition this data by randomly selecting 800 sequences for a training set, which is used to teach the model, and the remaining 200 sequences for a test set, which is used to evaluate the model's performance.\n\nAfter training, the model achieves an impressive 98% prediction accuracy on the test set. However, a closer analysis reveals that every protein in the test set shares at least 99% amino acid sequence identity with at least one protein in the training set. Given this information, which of the following statements describes the most fundamental flaw in the team's validation strategy?\n\nA. The model's predictive power on genuinely novel enzymes is likely to be significantly overestimated because the test set does not adequately assess the model's ability to generalize.\n\nB. The model is severely overfitted, meaning it has learned the noise in the training data rather than the true relationship between sequence and activity.\n\nC. The high sequence similarity indicates that the 2% error rate is solely due to random measurement errors in the lab, not model inaccuracies.\n\nD. The computational cost of training was inefficiently high due to the redundancy between the training and test sets.\n\nE. The dataset of 1,000 enzymes is too small to build any meaningful AI model for enzyme function, regardless of how it is partitioned.", "solution": "We formalize the setup to analyze the validation strategy and its assumptions.\n\n1. Define the dataset and partitions:\n- Let the full dataset be $\\mathcal{D}=\\{(x_{i},y_{i})\\}_{i=1}^{1000}$ where $x_{i}$ is an enzyme sequence and $y_{i}$ is its measured activity.\n- The training set is $\\mathcal{D}_{\\mathrm{train}}$ with $|\\mathcal{D}_{\\mathrm{train}}|=800$ and the test set is $\\mathcal{D}_{\\mathrm{test}}$ with $|\\mathcal{D}_{\\mathrm{test}}|=200$.\n- The model is a function $f:\\mathcal{X}\\to\\mathcal{Y}$ trained on $\\mathcal{D}_{\\mathrm{train}}$ and evaluated on $\\mathcal{D}_{\\mathrm{test}}$.\n\n2. Define the evaluation metric:\n- The reported test accuracy is $0.98$ on $\\mathcal{D}_{\\mathrm{test}}$, i.e., the empirical accuracy $\\hat{A}_{\\mathrm{test}}=\\frac{1}{|\\mathcal{D}_{\\mathrm{test}}|}\\sum_{(x,y)\\in\\mathcal{D}_{\\mathrm{test}}}\\mathbf{1}\\{f(x)=y\\}=0.98$ (or an analogous metric for regression thresholded as accuracy).\n\n3. State the key similarity condition:\n- For every $x\\in\\mathcal{D}_{\\mathrm{test}}$, there exists $x'\\in\\mathcal{D}_{\\mathrm{train}}$ such that the sequence identity satisfies $I(x,x')\\geq 0.99$, where $I:\\mathcal{X}\\times\\mathcal{X}\\to[0,1]$ denotes pairwise sequence identity.\n\n4. State the principle of proper validation:\n- Valid estimation of generalization requires that the test set approximate the target deployment distribution. If the scientific goal is prediction for genuinely novel enzymes, define the target distribution as sequences $x$ such that for all $x'\\in\\mathcal{D}_{\\mathrm{train}}$, $I(x,x')\\leq \\tau$ for some threshold $\\tau$ with $\\tau\\ll 0.99$ (e.g., a remote homolog regime).\n- The independence assumption requires that test examples are not trivially derivable from training examples; high redundancy violates the notion of an independent test.\n\n5. Analyze the consequence of high sequence identity:\n- Under $I(x,x')\\geq 0.99$, $x$ and $x'$ differ at at most a small fraction of positions. Thus, $f$ can achieve high accuracy by effectively memorizing or interpolating local neighborhoods in sequence space, without learning the broader, causal mapping from sequence to activity across diverse scaffolds.\n- Therefore, $\\hat{A}_{\\mathrm{test}}$ estimates performance on near-duplicates of training sequences, not on genuinely novel sequences. Formally, if $\\mathcal{X}_{\\mathrm{near}}=\\{x:\\exists x'\\in\\mathcal{D}_{\\mathrm{train}}\\ \\text{with}\\ I(x,x')\\geq 0.99\\}$ and $\\mathcal{X}_{\\mathrm{novel}}=\\{x:\\forall x'\\in\\mathcal{D}_{\\mathrm{train}},\\ I(x,x')\\leq \\tau\\}$ with $\\tau\\ll 0.99$, then the reported $\\hat{A}_{\\mathrm{test}}$ estimates performance on $\\mathcal{X}_{\\mathrm{near}}$ while the scientific goal concerns $\\mathcal{X}_{\\mathrm{novel}}$.\n\n6. Evaluate the options:\n- Option A states that the model’s predictive power on genuinely novel enzymes is likely overestimated because the test does not assess generalization. This follows directly from the mismatch between $\\mathcal{X}_{\\mathrm{near}}$ and $\\mathcal{X}_{\\mathrm{novel}}$ and the violation of independence due to high redundancy. Hence, A identifies the fundamental flaw in the validation strategy.\n- Option B (severe overfitting) is not necessarily implied. High performance on near-duplicates can arise from memorization or local interpolation without necessarily overfitting noise; the flaw is the non-representative test, not proven overfitting.\n- Option C incorrectly attributes the residual error solely to measurement noise; model inaccuracies cannot be ruled out from the given information.\n- Option D concerns computational cost, which is not the fundamental validation flaw; redundancy affects validity more than cost.\n- Option E makes an absolute claim about dataset size that is unsupported; meaningful models can be trained with 1,000 examples depending on complexity and validation protocol.\n\n7. Conclusion:\n- The most fundamental flaw is the non-independent, highly redundant test set that fails to measure generalization to novel sequences, making A the correct choice.", "answer": "$$\\boxed{A}$$", "id": "2018108"}]}