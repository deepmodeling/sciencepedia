{"hands_on_practices": [{"introduction": "A fundamental task in environmental science is to untangle complex causal webs to determine if an exposure truly causes an outcome. Directed Acyclic Graphs (DAGs) provide a rigorous, visual language for mapping out causal assumptions and identifying confounding variables that can create spurious associations. This exercise [@problem_id:2488829] demonstrates how to use this framework to structure an environmental health question, identify the necessary adjustments for a valid causal estimate, and analytically derive the bias that arises from a naive analysis that ignores confounding.", "problem": "An environmental epidemiology team aims to estimate the total causal effect of long-term ambient air pollution exposure on cardiovascular outcomes. To keep the inquiry grounded in environmental science rather than environmentalism, the team frames the question in terms of empirically identifiable causal relationships among measured variables, not in terms of advocacy. Let the variables be: air pollution exposure $A$, socioeconomic status $S$, smoking intensity $M$, and a cardiovascular outcome $Y$.\n\nUsing core definitions of causal graphs and standard causal reasoning, proceed as follows:\n\n1) Propose a plausible Directed Acyclic Graph (DAG) structure among $A$, $S$, $M$, and $Y$ that reflects the following domain-justified qualitative statements without contradicting known biology or social determinants: socioeconomic status $S$ affects residential location and thus air pollution exposure $A$; $S$ also affects smoking intensity $M$ and baseline cardiovascular risk $Y$ through multiple pathways; smoking $M$ affects $Y$; air pollution $A$ affects $Y$; and $A$ does not directly cause changes in $M$ over the long term. Do not introduce cycles or colliders beyond those implied by these statements.\n\n2) Using only fundamental causal graph principles, identify a minimal sufficient adjustment set for estimating the total causal effect of $A$ on $Y$.\n\n3) Now assume a linear Structural Causal Model (SCM) consistent with your DAG, with jointly independent, mean-zero disturbances:\n$$\nS \\sim \\mathcal{N}(0,\\sigma_S^2), \\quad A \\,=\\, \\gamma_S S + \\varepsilon_A, \\quad M \\,=\\, \\delta_S S + \\varepsilon_M, \\quad Y \\,=\\, \\beta_A A + \\beta_M M + \\beta_S S + \\varepsilon_Y,\n$$\nwhere $\\varepsilon_A$, $\\varepsilon_M$, and $\\varepsilon_Y$ are mutually independent of each other and of $S$, each with finite variance, and all expectations are finite.\n\nLet $\\theta_{\\text{naive}}$ be the ordinary least squares (OLS; Ordinary Least Squares) slope from regressing $Y$ on $A$ alone, and let $\\theta_{\\text{adj}}$ be the OLS partial slope on $A$ from regressing $Y$ on $A$ and $S$ (do not include $M$ in the adjustment set). Starting from the laws of covariance and the definition of the OLS slope, derive a closed-form analytic expression for the difference $\\theta_{\\text{naive}} - \\theta_{\\text{adj}}$ in terms of the structural parameters $\\beta_A$, $\\beta_M$, $\\beta_S$, $\\gamma_S$, $\\delta_S$, $\\sigma_S^2$, and the variance of $\\varepsilon_A$, denoted $\\sigma_A^2$.\n\nReport only the simplified expression for $\\theta_{\\text{naive}} - \\theta_{\\text{adj}}$ as your final answer. No numerical approximation is required, and no units are needed.", "solution": "The problem as stated is scientifically grounded, well-posed, and objective. It employs standard, formalizable methods from causal inference and statistics—specifically, Directed Acyclic Graphs (DAGs) and linear Structural Causal Models (SCMs)—to address a valid question in environmental epidemiology. The premises are internally consistent, and the required information is sufficient for a unique solution. The problem is therefore valid, and we proceed to the solution.\n\nThe problem is structured in three parts. We will address them in sequence.\n\nPart $1$: Construction of the Directed Acyclic Graph (DAG)\n\nThe problem provides the following qualitative relationships between the variables: air pollution exposure ($A$), socioeconomic status ($S$), smoking intensity ($M$), and a cardiovascular outcome ($Y$).\n1. Socioeconomic status $S$ affects air pollution exposure $A$: $S \\to A$.\n2. Socioeconomic status $S$ affects smoking intensity $M$: $S \\to M$.\n3. Socioeconomic status $S$ affects cardiovascular outcome $Y$: $S \\to Y$.\n4. Smoking intensity $M$ affects cardiovascular outcome $Y$: $M \\to Y$.\n5. Air pollution exposure $A$ affects cardiovascular outcome $Y$: $A \\to Y$.\n6. Air pollution exposure $A$ does not directly cause smoking intensity $M$. There is no edge $A \\to M$.\n\nBased on these directed relationships, the variable $S$ is a common cause of $A$, $M$, and $Y$. The variables $A$ and $M$ are mediators of the effect of $S$ on $Y$, but they also have their own direct causal paths to $Y$. The resulting DAG has arrows from $S$ pointing to $A$, $M$, and $Y$; an arrow from $A$ to $Y$; and an arrow from $M$ to $Y$.\n\nPart $2$: Identification of a Minimal Sufficient Adjustment Set\n\nThe objective is to estimate the total causal effect of $A$ on $Y$, which corresponds to the path $A \\to Y$. To achieve this, we must block all non-causal \"back-door\" paths between $A$ and $Y$. A back-door path is a path from $A$ to $Y$ that starts with an arrow pointing into $A$.\n\nIn the constructed DAG, we identify the following paths from $A$ to $Y$:\n- The direct causal path: $A \\to Y$.\n- A back-door path through the confounder $S$: $A \\leftarrow S \\to Y$.\n- Another back-door path involving $S$ and $M$: $A \\leftarrow S \\to M \\to Y$.\n\nTo estimate the causal effect of $A$ on $Y$, we must block all back-door paths while leaving all causal paths open. According to the back-door criterion, a set of variables $Z$ is a sufficient adjustment set if:\n1. No variable in $Z$ is a descendant of $A$.\n2. $Z$ blocks every back-door path between $A$ and $Y$.\n\nBoth identified back-door paths, $A \\leftarrow S \\to Y$ and $A \\leftarrow S \\to M \\to Y$, contain the variable $S$. Conditioning on $S$ blocks both of these paths. The variable $S$ is not a descendant of $A$. Therefore, the set $\\{S\\}$ satisfies the back-door criterion and is a sufficient adjustment set.\n\nTo determine if $\\{S\\}$ is a minimal sufficient adjustment set, we must confirm that no proper subset of $\\{S\\}$ is also sufficient. The only proper subset is the empty set $\\emptyset$, which leaves both back-door paths open. Thus, conditioning on $S$ is necessary. The set $\\{S\\}$ is therefore a minimal sufficient adjustment set.\n\nPart $3$: Derivation of the Difference $\\theta_{\\text{naive}} - \\theta_{\\text{adj}}$\n\nWe are given the linear Structural Causal Model (SCM):\n$$\nS \\sim \\mathcal{N}(0,\\sigma_S^2), \\quad A = \\gamma_S S + \\varepsilon_A, \\quad M = \\delta_S S + \\varepsilon_M, \\quad Y = \\beta_A A + \\beta_M M + \\beta_S S + \\varepsilon_Y\n$$\nThe error terms $\\varepsilon_A$, $\\varepsilon_M$, $\\varepsilon_Y$, and the variable $S$ are mutually independent, with zero mean and finite variances. We denote $\\text{Var}(\\varepsilon_A) = \\sigma_A^2$.\n\nThe naive estimator, $\\theta_{\\text{naive}}$, is the ordinary least squares (OLS) slope from regressing $Y$ on $A$ alone. It is given by:\n$$\n\\theta_{\\text{naive}} = \\frac{\\text{Cov}(Y,A)}{\\text{Var}(A)}\n$$\nThe adjusted estimator, $\\theta_{\\text{adj}}$, is the OLS partial slope on $A$ from regressing $Y$ on $A$ and $S$. To find this, we first express $Y$ in terms of $A$ and $S$ and an error term that is uncorrelated with $A$ and $S$. We substitute the equation for $M$ into the equation for $Y$:\n$$\nY = \\beta_A A + \\beta_M (\\delta_S S + \\varepsilon_M) + \\beta_S S + \\varepsilon_Y\n$$\n$$\nY = \\beta_A A + (\\beta_M \\delta_S + \\beta_S)S + (\\beta_M \\varepsilon_M + \\varepsilon_Y)\n$$\nThis is a linear model for $Y$ in terms of $A$ and $S$. The new error term is $u = \\beta_M \\varepsilon_M + \\varepsilon_Y$. We must check if the regressors $A$ and $S$ are uncorrelated with $u$.\n$$\n\\text{Cov}(A, u) = \\text{Cov}(\\gamma_S S + \\varepsilon_A, \\beta_M \\varepsilon_M + \\varepsilon_Y) = 0\n$$\n$$\n\\text{Cov}(S, u) = \\text{Cov}(S, \\beta_M \\varepsilon_M + \\varepsilon_Y) = 0\n$$\nBoth covariances are zero due to the mutual independence of $S$, $\\varepsilon_A$, $\\varepsilon_M$, and $\\varepsilon_Y$. Since the regressors are uncorrelated with the error term, the OLS estimator for the coefficient of $A$ will be an unbiased and consistent estimator of the true parameter $\\beta_A$. Therefore:\n$$\n\\theta_{\\text{adj}} = \\beta_A\n$$\nNow we compute $\\theta_{\\text{naive}}$. We need $\\text{Var}(A)$ and $\\text{Cov}(Y,A)$. First, we compute the necessary variances and covariances from the SCM.\n$$\n\\text{Var}(S) = \\sigma_S^2\n$$\n$$\n\\text{Var}(A) = \\text{Var}(\\gamma_S S + \\varepsilon_A) = \\gamma_S^2 \\text{Var}(S) + \\text{Var}(\\varepsilon_A) = \\gamma_S^2 \\sigma_S^2 + \\sigma_A^2\n$$\nThe covariance between the confounder $S$ and exposure $A$ is:\n$$\n\\text{Cov}(S,A) = \\text{Cov}(S, \\gamma_S S + \\varepsilon_A) = \\gamma_S \\text{Var}(S) = \\gamma_S \\sigma_S^2\n$$\nThe covariance between smoking $M$ and exposure $A$ is:\n$$\n\\text{Cov}(M,A) = \\text{Cov}(\\delta_S S + \\varepsilon_M, \\gamma_S S + \\varepsilon_A) = \\delta_S \\gamma_S \\text{Var}(S) = \\delta_S \\gamma_S \\sigma_S^2\n$$\nNow, we compute the covariance between the outcome $Y$ and exposure $A$:\n$$\n\\text{Cov}(Y,A) = \\text{Cov}(\\beta_A A + \\beta_M M + \\beta_S S + \\varepsilon_Y, A)\n$$\n$$\n= \\beta_A \\text{Var}(A) + \\beta_M \\text{Cov}(M,A) + \\beta_S \\text{Cov}(S,A) + \\text{Cov}(\\varepsilon_Y, A)\n$$\nSince $\\text{Cov}(\\varepsilon_Y, A) = \\text{Cov}(\\varepsilon_Y, \\gamma_S S + \\varepsilon_A)=0$, we substitute the previously derived terms:\n$$\n\\text{Cov}(Y,A) = \\beta_A (\\gamma_S^2 \\sigma_S^2 + \\sigma_A^2) + \\beta_M (\\delta_S \\gamma_S \\sigma_S^2) + \\beta_S (\\gamma_S \\sigma_S^2)\n$$\nNow we can compute $\\theta_{\\text{naive}}$:\n$$\n\\theta_{\\text{naive}} = \\frac{\\text{Cov}(Y,A)}{\\text{Var}(A)} = \\frac{\\beta_A (\\gamma_S^2 \\sigma_S^2 + \\sigma_A^2) + \\beta_M \\delta_S \\gamma_S \\sigma_S^2 + \\beta_S \\gamma_S \\sigma_S^2}{\\gamma_S^2 \\sigma_S^2 + \\sigma_A^2}\n$$\n$$\n\\theta_{\\text{naive}} = \\beta_A + \\frac{\\gamma_S \\sigma_S^2 (\\beta_M \\delta_S + \\beta_S)}{\\gamma_S^2 \\sigma_S^2 + \\sigma_A^2}\n$$\nThe required difference is $\\theta_{\\text{naive}} - \\theta_{\\text{adj}}$. Since $\\theta_{\\text{adj}} = \\beta_A$, this difference is the omitted variable bias term:\n$$\n\\theta_{\\text{naive}} - \\theta_{\\text{adj}} = \\left( \\beta_A + \\frac{\\gamma_S \\sigma_S^2 (\\beta_M \\delta_S + \\beta_S)}{\\gamma_S^2 \\sigma_S^2 + \\sigma_A^2} \\right) - \\beta_A\n$$\n$$\n\\theta_{\\text{naive}} - \\theta_{\\text{adj}} = \\frac{\\gamma_S \\sigma_S^2 (\\beta_M \\delta_S + \\beta_S)}{\\gamma_S^2 \\sigma_S^2 + \\sigma_A^2}\n$$\nThis is the final simplified expression. It quantifies the bias introduced by not adjusting for the confounder $S$. The bias is a product of the effect of the confounder path on the outcome (the $\\beta_M \\delta_S + \\beta_S$ term) and the association between the confounder and the exposure (related to the other terms).", "answer": "$$\n\\boxed{\\frac{\\gamma_S \\sigma_S^2 (\\beta_M \\delta_S + \\beta_S)}{\\gamma_S^2 \\sigma_S^2 + \\sigma_A^2}}\n$$", "id": "2488829"}, {"introduction": "Environmental science provides a quantitative foundation for the sustainable management of natural resources, distinguishing it from purely value-based conservation arguments. A classic example is the concept of Maximum Sustainable Yield ($MSY$), which is not an arbitrary goal but a quantity derived directly from mathematical models of population dynamics. In this practice [@problem_id:2488860], you will derive the $MSY$ for a fishery and, crucially, analyze how uncertainty in the underlying biological parameters propagates to the final management advice, highlighting how science formally incorporates and communicates the limits of its predictive power.", "problem": "A single-species fish stock of biomass $B(t)$ in a closed region is modeled by density-regulated growth with an intrinsic rate of increase $r$ and carrying capacity $K$, consistent with a logistic state equation from population ecology. In the absence of harvesting, the net biomass increment over a small interval is the surplus production, which is defined as the difference between births plus growth and natural mortality, and under logistic dynamics is a function of $B(t)$, $r$, and $K$. In fisheries environmental science, a scientifically grounded harvesting policy is to set a constant catch rate equal to the long-run surplus production at a positive equilibrium biomass. This defines the Maximum Sustainable Yield (MSY), which is the highest constant harvest that can be maintained indefinitely under the assumed population dynamics. This scientific quantity is distinct from normative environmentalism, which may advocate targets below MSY for precautionary or ethical reasons; here, focus strictly on the scientific derivation.\n\nStarting from the logistic growth framework and the definition of surplus production under equilibrium (where harvest equals net production), perform the following:\n\n1. Derive the surplus production model $Y(B)$ as a function of biomass $B$ under equilibrium harvesting, and determine the biomass $B^{\\ast}$ that maximizes $Y(B)$ over the biologically feasible interval. Use this to obtain the Maximum Sustainable Yield as a function of $r$ and $K$.\n\n2. To analyze sensitivity to parameter uncertainty in an environmental science context, suppose the true parameters $r$ and $K$ are random with small relative uncertainties. Let $\\operatorname{E}[r]=r$, $\\operatorname{E}[K]=K$, define coefficients of variation $c_{r}=\\operatorname{sd}(r)/r$ and $c_{K}=\\operatorname{sd}(K)/K$, and let $\\rho$ denote the correlation between $r$ and $K$. Using a first-order delta-method approximation (linear error propagation), derive a closed-form expression for the coefficient of variation of MSY, denoted $\\mathrm{CV}_{\\mathrm{MSY}}=\\operatorname{sd}(\\mathrm{MSY})/\\operatorname{E}[\\mathrm{MSY}]$, in terms of $c_{r}$, $c_{K}$, and $\\rho$.\n\nReport, as your final answer, the single analytic expression for $\\mathrm{CV}_{\\mathrm{MSY}}$ you obtain in step $2$. No numerical evaluation is required, and no units are needed because $\\mathrm{CV}_{\\mathrm{MSY}}$ is dimensionless. Do not round; provide the exact symbolic form.", "solution": "The problem statement has been subjected to rigorous validation and is deemed scientifically grounded, well-posed, and objective. It represents a standard exercise in quantitative population ecology and resource management, combining the deterministic derivation of Maximum Sustainable Yield (MSY) from the logistic model with a statistical uncertainty analysis using the delta method. The premises are sound and all necessary information for a unique solution is provided. We will proceed with the derivation.\n\nThe dynamics of the fish stock biomass, $B(t)$, are described by the logistic equation:\n$$\n\\frac{dB}{dt} = rB\\left(1 - \\frac{B}{K}\\right)\n$$\nHere, $r$ is the intrinsic rate of population increase and $K$ is the carrying capacity. The term on the right-hand side is the surplus production, which is the net biomass growth available for harvest.\n\nStep 1: Derivation of the Maximum Sustainable Yield (MSY).\n\nA sustainable harvest or yield, which we denote as a function of biomass $Y(B)$, is a harvest rate that is exactly matched by the population's surplus production. At such a rate, the biomass level remains at equilibrium. Thus, the sustainable yield at biomass $B$ is:\n$$\nY(B) = rB\\left(1 - \\frac{B}{K}\\right) = rB - \\frac{r}{K}B^2\n$$\nTo find the Maximum Sustainable Yield (MSY), we must find the biomass level, $B^{\\ast}$, that maximizes this function $Y(B)$. This is accomplished by finding the critical point of $Y(B)$ through differentiation with respect to $B$ and setting the result to zero.\n$$\n\\frac{dY}{dB} = \\frac{d}{dB}\\left(rB - \\frac{r}{K}B^2\\right) = r - \\frac{2rB}{K}\n$$\nSetting the derivative to zero to find the optimal biomass $B^{\\ast}$:\n$$\nr - \\frac{2rB^{\\ast}}{K} = 0\n$$\nAssuming $r > 0$, we can solve for $B^{\\ast}$:\n$$\n\\frac{2rB^{\\ast}}{K} = r \\implies B^{\\ast} = \\frac{K}{2}\n$$\nTo confirm this is a maximum, we examine the second derivative:\n$$\n\\frac{d^2Y}{dB^2} = -\\frac{2r}{K}\n$$\nSince $r > 0$ and $K > 0$, the second derivative is negative, which confirms that $B^{\\ast} = K/2$ yields a maximum.\n\nThe MSY is the yield evaluated at this optimal biomass, $Y(B^{\\ast})$:\n$$\n\\mathrm{MSY} = Y\\left(\\frac{K}{2}\\right) = r\\left(\\frac{K}{2}\\right)\\left(1 - \\frac{K/2}{K}\\right) = r\\left(\\frac{K}{2}\\right)\\left(1 - \\frac{1}{2}\\right) = r\\left(\\frac{K}{2}\\right)\\left(\\frac{1}{2}\\right) = \\frac{rK}{4}\n$$\nThis gives the MSY as a function of the model parameters $r$ and $K$.\n\nStep 2: Derivation of the Coefficient of Variation of MSY.\n\nWe now treat $r$ and $K$ as random variables with means $\\operatorname{E}[r]$ and $\\operatorname{E}[K]$ (denoted simply as $r$ and $K$ per the problem's convention), standard deviations $\\sigma_r$ and $\\sigma_K$, and correlation $\\rho$. We have the function $\\mathrm{MSY} = f(r, K) = \\frac{rK}{4}$. We will use the first-order delta method (the formula for propagation of uncertainty) to approximate the variance of MSY.\nThe general formula for the variance of a function $f(x_1, x_2)$ is:\n$$\n\\operatorname{Var}(f) \\approx \\left(\\frac{\\partial f}{\\partial x_1}\\right)^2 \\operatorname{Var}(x_1) + \\left(\\frac{\\partial f}{\\partial x_2}\\right)^2 \\operatorname{Var}(x_2) + 2\\left(\\frac{\\partial f}{\\partial x_1}\\right)\\left(\\frac{\\partial f}{\\partial x_2}\\right)\\operatorname{Cov}(x_1, x_2)\n$$\nwhere derivatives are evaluated at the mean values.\n\nFirst, we compute the partial derivatives of $\\mathrm{MSY}$ with respect to $r$ and $K$:\n$$\n\\frac{\\partial(\\mathrm{MSY})}{\\partial r} = \\frac{\\partial}{\\partial r}\\left(\\frac{rK}{4}\\right) = \\frac{K}{4}\n$$\n$$\n\\frac{\\partial(\\mathrm{MSY})}{\\partial K} = \\frac{\\partial}{\\partial K}\\left(\\frac{rK}{4}\\right) = \\frac{r}{4}\n$$\nSubstituting these into the variance formula, with $\\operatorname{Var}(r) = \\sigma_{r}^{2}$, $\\operatorname{Var}(K) = \\sigma_{K}^{2}$, and $\\operatorname{Cov}(r, K) = \\rho \\sigma_r \\sigma_K$:\n$$\n\\operatorname{Var}(\\mathrm{MSY}) \\approx \\left(\\frac{K}{4}\\right)^2 \\sigma_{r}^{2} + \\left(\\frac{r}{4}\\right)^2 \\sigma_{K}^{2} + 2\\left(\\frac{K}{4}\\right)\\left(\\frac{r}{4}\\right)\\rho \\sigma_r \\sigma_K\n$$\n$$\n\\operatorname{Var}(\\mathrm{MSY}) \\approx \\frac{K^2 \\sigma_{r}^{2}}{16} + \\frac{r^2 \\sigma_{K}^{2}}{16} + \\frac{2rK \\rho \\sigma_r \\sigma_K}{16}\n$$\nThe problem asks for the coefficient of variation, $\\mathrm{CV}_{\\mathrm{MSY}} = \\operatorname{sd}(\\mathrm{MSY}) / \\operatorname{E}[\\mathrm{MSY}]$. It is more direct to work with the squared coefficient of variation, or relative variance: $\\mathrm{CV}_{\\mathrm{MSY}}^{2} = \\operatorname{Var}(\\mathrm{MSY}) / (\\operatorname{E}[\\mathrm{MSY}])^2$.\n\nThe first-order approximation for the expected value of MSY is $\\operatorname{E}[\\mathrm{MSY}] \\approx f(\\operatorname{E}[r], \\operatorname{E}[K]) = \\frac{rK}{4}$.\nNow we compute $\\mathrm{CV}_{\\mathrm{MSY}}^{2}$:\n$$\n\\mathrm{CV}_{\\mathrm{MSY}}^{2} \\approx \\frac{\\frac{1}{16}(K^2 \\sigma_{r}^{2} + r^2 \\sigma_{K}^{2} + 2rK \\rho \\sigma_r \\sigma_K)}{\\left(\\frac{rK}{4}\\right)^2} = \\frac{\\frac{1}{16}(K^2 \\sigma_{r}^{2} + r^2 \\sigma_{K}^{2} + 2rK \\rho \\sigma_r \\sigma_K)}{\\frac{r^2 K^2}{16}}\n$$\n$$\n\\mathrm{CV}_{\\mathrm{MSY}}^{2} \\approx \\frac{K^2 \\sigma_{r}^{2} + r^2 \\sigma_{K}^{2} + 2rK \\rho \\sigma_r \\sigma_K}{r^2 K^2}\n$$\nDividing each term in the numerator by the denominator:\n$$\n\\mathrm{CV}_{\\mathrm{MSY}}^{2} \\approx \\frac{K^2 \\sigma_{r}^{2}}{r^2 K^2} + \\frac{r^2 \\sigma_{K}^{2}}{r^2 K^2} + \\frac{2rK \\rho \\sigma_r \\sigma_K}{r^2 K^2} = \\left(\\frac{\\sigma_r}{r}\\right)^2 + \\left(\\frac{\\sigma_K}{K}\\right)^2 + 2\\rho\\left(\\frac{\\sigma_r}{r}\\right)\\left(\\frac{\\sigma_K}{K}\\right)\n$$\nThe problem provides the definitions for the coefficients of variation of the parameters: $c_r = \\sigma_r/r$ and $c_K = \\sigma_K/K$. Substituting these into the expression:\n$$\n\\mathrm{CV}_{\\mathrm{MSY}}^{2} \\approx c_{r}^{2} + c_{K}^{2} + 2\\rho c_r c_K\n$$\nFinally, taking the square root gives the coefficient of variation of MSY:\n$$\n\\mathrm{CV}_{\\mathrm{MSY}} \\approx \\sqrt{c_{r}^{2} + c_{K}^{2} + 2\\rho c_r c_K}\n$$\nThis is the required closed-form expression.", "answer": "$$\n\\boxed{\\sqrt{c_{r}^{2} + c_{K}^{2} + 2 \\rho c_{r} c_{K}}}\n$$", "id": "2488860"}, {"introduction": "Raw data from the field are often a noisy and biased reflection of the ecological reality we wish to understand. For instance, failing to detect a species during a survey does not necessarily mean it is absent. This computational exercise [@problem_id:2488903] challenges you to move beyond naive interpretations of data by implementing a hierarchical statistical model, a cornerstone of modern quantitative ecology, to properly estimate a population trend while accounting for imperfect detection. By contrasting the rigorous model's output with a simplistic \"connect-the-dots\" approach, you will see how scientific methods are essential for generating reliable evidence and avoiding potentially misleading conclusions.", "problem": "Environmental science seeks to infer state variables from data while accounting for observation error, whereas environmentalism often communicates simplified metrics that may ignore known biases. Consider the task of estimating a multi-season site-occupancy trend for a species monitored with repeated detection/non-detection surveys, where imperfect detection is present. You are to implement a program that estimates the occupancy trend using a hierarchical occupancy model and compares it to a naive change metric that ignores imperfect detection—an advocacy-style statistic.\n\nModeling framework to be used (foundational base):\n- Latent occupancy: For site $i$ in season $t$, the latent true occupancy state $z_{it}$ is a Bernoulli random variable with success probability $\\psi_t$, written as $z_{it} \\sim \\mathrm{Bernoulli}(\\psi_t)$, for $i \\in \\{1,\\dots,S\\}$ and $t \\in \\{1,\\dots,T\\}$.\n- Detection model: Conditional on $z_{it} = 1$, each replicate survey $j \\in \\{1,\\dots,J_{it}\\}$ yields a detection $y_{itj} \\sim \\mathrm{Bernoulli}(p)$, independent across replicates, with constant detection probability $p$ across seasons and sites. If $z_{it} = 0$, then $y_{itj} = 0$ almost surely.\n- Temporal trend in occupancy: The occupancy probability follows a logistic trend,\n$$\n\\mathrm{logit}(\\psi_t) = \\alpha + \\beta \\cdot (t-1),\n$$\nwith $\\alpha \\in \\mathbb{R}$ and $\\beta \\in \\mathbb{R}$, and where $\\mathrm{logit}(x) = \\log\\left(\\frac{x}{1-x}\\right)$.\n\nEstimation principle:\n- Use Maximum Likelihood Estimation (MLE) to estimate $(\\alpha,\\beta,p)$ by marginalizing over the latent $z_{it}$. Derive the site-season observation model from the above generative process, and maximize the joint likelihood across all sites and seasons.\n\nRequired outputs for each test case:\n1. The hierarchical trend change as a decimal: compute\n$$\n\\Delta_{\\mathrm{hier}} = \\frac{\\psi_T - \\psi_1}{\\psi_1},\n$$\nusing the MLEs for $(\\alpha,\\beta)$ via $\\psi_t = \\mathrm{logit}^{-1}(\\alpha + \\beta \\cdot (t-1))$.\n2. The naive change as a decimal that ignores imperfect detection: for each season $t$, compute the proportion of sites with at least one detection, call this $d_t$. Then\n$$\n\\Delta_{\\mathrm{naive}} = \\frac{d_T - d_1}{d_1}.\n$$\n3. The difference between the naive and hierarchical changes:\n$$\n\\Delta_{\\mathrm{diff}} = \\Delta_{\\mathrm{naive}} - \\Delta_{\\mathrm{hier}}.\n$$\n\nAll three outputs per test case must be expressed as decimal numbers, rounded to exactly $3$ decimal places.\n\nAngle units are not involved. No physical units are required. Percent changes must be returned as decimals, not as percentages.\n\nTest suite to implement and evaluate:\nEach test case is a list of sites, where each site is a list over seasons, and each season holds a list of replicate detections $0/1$. There are $3$ seasons in every test case. Replicate counts $J_{it}$ may vary by test case and season.\n\n- Test case A (moderate decline signal, moderate detection; $S=12$ sites, $T=3$ seasons, $J_{it}=3$ replicates per season):\n  [\n    [[1,0,1],[1,0,0],[0,1,0]],\n    [[0,1,1],[0,0,1],[0,0,1]],\n    [[1,1,1],[1,0,1],[0,0,1]],\n    [[0,0,1],[0,0,0],[0,0,0]],\n    [[0,1,0],[0,0,0],[0,0,0]],\n    [[1,0,0],[0,0,0],[0,0,0]],\n    [[1,1,0],[0,1,0],[0,1,0]],\n    [[0,0,0],[0,0,1],[0,0,0]],\n    [[0,0,0],[1,0,0],[0,0,1]],\n    [[1,0,0],[1,0,0],[0,0,0]],\n    [[0,0,0],[0,0,0],[0,0,0]],\n    [[0,1,0],[0,0,0],[0,0,0]]\n  ]\n\n- Test case B (approximately stable occupancy with low detection; $S=10$ sites, $T=3$ seasons, $J_{it}=4$ replicates per season):\n  [\n    [[1,0,0,0],[0,1,0,0],[0,0,1,0]],\n    [[0,0,0,0],[0,0,0,0],[0,0,0,0]],\n    [[0,1,0,0],[0,0,1,0],[0,0,0,1]],\n    [[1,1,0,0],[0,0,0,0],[0,1,0,0]],\n    [[0,0,0,0],[0,0,0,0],[0,0,0,0]],\n    [[0,1,1,0],[0,0,0,0],[0,0,1,0]],\n    [[0,0,0,0],[1,0,0,0],[0,0,0,0]],\n    [[0,1,0,0],[0,1,0,0],[0,0,0,0]],\n    [[0,0,0,0],[0,0,1,0],[0,0,0,0]],\n    [[1,0,0,0],[0,0,0,0],[0,0,0,0]]\n  ]\n\n- Test case C (strong increase signal with high detection; $S=8$ sites, $T=3$ seasons, $J_{it}=2$ replicates per season):\n  [\n    [[0,0],[0,1],[1,1]],\n    [[0,0],[0,1],[1,1]],\n    [[1,1],[1,1],[1,1]],\n    [[0,0],[0,0],[1,0]],\n    [[0,0],[0,1],[1,1]],\n    [[1,0],[1,1],[1,1]],\n    [[0,0],[0,0],[0,0]],\n    [[0,1],[1,1],[1,1]]\n  ]\n\nYour task:\n- Implement a complete program that, for each of the above three test cases, fits the specified hierarchical occupancy model via Maximum Likelihood Estimation, computes $\\Delta_{\\mathrm{hier}}$, $\\Delta_{\\mathrm{naive}}$, and $\\Delta_{\\mathrm{diff}}$, and rounds each to exactly $3$ decimal places.\n- Your program must produce a single line of output containing all results in a flat, comma-separated list enclosed in square brackets. The required order is:\n  [\n    $\\Delta_{\\mathrm{hier}}^{(A)}$,\n    $\\Delta_{\\mathrm{naive}}^{(A)}$,\n    $\\Delta_{\\mathrm{diff}}^{(A)}$,\n    $\\Delta_{\\mathrm{hier}}^{(B)}$,\n    $\\Delta_{\\mathrm{naive}}^{(B)}$,\n    $\\Delta_{\\mathrm{diff}}^{(B)}$,\n    $\\Delta_{\\mathrm{hier}}^{(C)}$,\n    $\\Delta_{\\mathrm{naive}}^{(C)}$,\n    $\\Delta_{\\mathrm{diff}}^{(C)}$\n  ]\nFor example, your output must look like a single line with the pattern \"[x1,x2,x3,x4,x5,x6,x7,x8,x9]\" where each $x_k$ is a decimal rounded to exactly $3$ places.\n\nImplementation constraints:\n- The program must be self-contained, require no input, and use Maximum Likelihood Estimation with numerically stable likelihood computation consistent with the model definitions above. Use the logistic function for both $\\psi_t$ and $p$ via unconstrained parameters.\n- Express all final numeric results as decimals with exactly $3$ digits after the decimal point.", "solution": "The problem statement is evaluated as valid. It is scientifically grounded in established principles of statistical ecology, specifically hierarchical modeling for species occupancy. The problem is well-posed, providing a complete description of the data, the generative model, the estimation principle (Maximum Likelihood Estimation), and the precise output metrics required. The language is objective and formal. All necessary data and constraints are provided, rendering the problem self-contained and solvable.\n\nThe task is to estimate an ecological trend under imperfect detection and compare a rigorous model-based estimate with a naive estimate that ignores this complexity. This requires the derivation and maximization of a likelihood function for a hierarchical occupancy model.\n\nThe model parameters to be estimated are $\\boldsymbol{\\theta} = (\\alpha, \\beta, p)$, where $\\alpha$ and $\\beta$ define the temporal trend in occupancy probability $\\psi_t$, and $p$ is the detection probability.\nThe occupancy probability for season $t \\in \\{1, \\dots, T\\}$ is given by the logistic model:\n$$ \\psi_t = \\frac{1}{1 + \\exp(-(\\alpha + \\beta(t-1)))} $$\nThe latent (unobserved) true occupancy state for site $i \\in \\{1, \\dots, S\\}$ in season $t$, denoted $z_{it}$, is a Bernoulli random variable:\n$$ z_{it} \\sim \\mathrm{Bernoulli}(\\psi_t) $$\nThe observed data consist of $J_{it}$ replicate surveys at site $i$ in season $t$. The outcome of each survey, $y_{itj}$, is a detection ($1$) or non-detection ($0$). Conditional on the site being occupied ($z_{it}=1$), each survey is an independent Bernoulli trial with success probability $p$:\n$$ y_{itj} | z_{it}=1 \\sim \\mathrm{Bernoulli}(p) $$\nIf the site is unoccupied ($z_{it}=0$), no detections are possible, so $y_{itj}=0$.\n\nTo perform Maximum Likelihood Estimation, we must first construct the likelihood of the observed data by marginalizing over the latent states $z_{it}$. Let the data for site $i$ in season $t$ be summarized by the number of detections, $k_{it} = \\sum_{j=1}^{J_{it}} y_{itj}$, out of $J_{it}$ surveys.\n\nThe likelihood contribution $L_{it}$ for a single site-season observation depends on whether detections occurred:\n\nCase 1: At least one detection ($k_{it} > 0$).\nIf one or more detections are observed, the site must have been occupied ($z_{it}=1$). The probability of this observation is the probability of the site being occupied, multiplied by the probability of the specific detection history given occupancy.\n$$ L_{it}(k_{it}>0) = P(z_{it}=1) \\cdot P(\\text{data}_{it} | z_{it}=1) = \\psi_t \\cdot p^{k_{it}} (1-p)^{J_{it}-k_{it}} $$\n\nCase 2: No detections ($k_{it} = 0$).\nThis can occur in two mutually exclusive ways: either the site was occupied but the species was not detected in any of the $J_{it}$ surveys, or the site was unoccupied.\n$$ L_{it}(k_{it}=0) = P(z_{it}=1) \\cdot P(k_{it}=0 | z_{it}=1) + P(z_{it}=0) \\cdot P(k_{it}=0 | z_{it}=0) $$\n$$ L_{it}(k_{it}=0) = \\psi_t \\cdot (1-p)^{J_{it}} + (1-\\psi_t) \\cdot 1 $$\n\nThe total likelihood is the product of these individual likelihoods over all sites and seasons, assuming independence:\n$$ L(\\alpha, \\beta, p) = \\prod_{i=1}^{S} \\prod_{t=1}^{T} L_{it} $$\nFor numerical optimization, we work with the negative log-likelihood (NLL). Let $D_1 = \\{(i, t) | k_{it} > 0\\}$ and $D_0 = \\{(i, t) | k_{it} = 0\\}$.\n$$ \\mathrm{NLL}(\\alpha, \\beta, p) = - \\log L = - \\sum_{(i,t) \\in D_1} \\left[ \\log(\\psi_t) + k_{it}\\log(p) + (J_{it}-k_{it})\\log(1-p) \\right] - \\sum_{(i,t) \\in D_0} \\log\\left( \\psi_t (1-p)^{J_{it}} + 1-\\psi_t \\right) $$\nTo ensure numerical stability and facilitate unconstrained optimization, the parameters $(\\alpha, \\beta, p)$ are reparameterized. We can optimize over $(\\alpha, \\beta, \\text{logit}(p))$, where $\\text{logit}(p) = \\log(p/(1-p))$. The NLL is minimized with respect to these unconstrained parameters using a numerical optimization algorithm, such as the Broyden–Fletcher–Goldfarb–Shanno (BFGS) algorithm, available in `scipy.optimize.minimize`.\n\nUpon finding the Maximum Likelihood Estimates $(\\hat{\\alpha}, \\hat{\\beta}, \\hat{p})$, the required quantities are calculated:\n1.  Hierarchical relative change, $\\Delta_{\\mathrm{hier}}$:\n    $$ \\hat{\\psi}_1 = \\frac{1}{1 + \\exp(-\\hat{\\alpha})} $$\n    $$ \\hat{\\psi}_T = \\frac{1}{1 + \\exp(-(\\hat{\\alpha} + \\hat{\\beta}(T-1)))} $$\n    $$ \\Delta_{\\mathrm{hier}} = \\frac{\\hat{\\psi}_T - \\hat{\\psi}_1}{\\hat{\\psi}_1} $$\n2.  Naive relative change, $\\Delta_{\\mathrm{naive}}$:\n    For each season $t$, the proportion of sites with at least one detection is $d_t = \\frac{1}{S} \\sum_{i=1}^{S} \\mathbb{I}(k_{it}>0)$, where $\\mathbb{I}(\\cdot)$ is the indicator function.\n    $$ \\Delta_{\\mathrm{naive}} = \\frac{d_T - d_1}{d_1} $$\n3.  Difference, $\\Delta_{\\mathrm{diff}}$:\n    $$ \\Delta_{\\mathrm{diff}} = \\Delta_{\\mathrm{naive}} - \\Delta_{\\mathrm{hier}} $$\nThese calculations are performed for each test case provided.", "answer": "```python\nimport numpy as np\nfrom scipy.optimize import minimize\n\ndef solve():\n    \"\"\"\n    Main function to solve the occupancy modeling problem for all test cases.\n    \"\"\"\n    test_cases = {\n        'A': [\n            [[1,0,1],[1,0,0],[0,1,0]],\n            [[0,1,1],[0,0,1],[0,0,1]],\n            [[1,1,1],[1,0,1],[0,0,1]],\n            [[0,0,1],[0,0,0],[0,0,0]],\n            [[0,1,0],[0,0,0],[0,0,0]],\n            [[1,0,0],[0,0,0],[0,0,0]],\n            [[1,1,0],[0,1,0],[0,1,0]],\n            [[0,0,0],[0,0,1],[0,0,0]],\n            [[0,0,0],[1,0,0],[0,0,1]],\n            [[1,0,0],[1,0,0],[0,0,0]],\n            [[0,0,0],[0,0,0],[0,0,0]],\n            [[0,1,0],[0,0,0],[0,0,0]]\n        ],\n        'B': [\n            [[1,0,0,0],[0,1,0,0],[0,0,1,0]],\n            [[0,0,0,0],[0,0,0,0],[0,0,0,0]],\n            [[0,1,0,0],[0,0,1,0],[0,0,0,1]],\n            [[1,1,0,0],[0,0,0,0],[0,1,0,0]],\n            [[0,0,0,0],[0,0,0,0],[0,0,0,0]],\n            [[0,1,1,0],[0,0,0,0],[0,0,1,0]],\n            [[0,0,0,0],[1,0,0,0],[0,0,0,0]],\n            [[0,1,0,0],[0,1,0,0],[0,0,0,0]],\n            [[0,0,0,0],[0,0,1,0],[0,0,0,0]],\n            [[1,0,0,0],[0,0,0,0],[0,0,0,0]]\n        ],\n        'C': [\n            [[0,0],[0,1],[1,1]],\n            [[0,0],[0,1],[1,1]],\n            [[1,1],[1,1],[1,1]],\n            [[0,0],[0,0],[1,0]],\n            [[0,0],[0,1],[1,1]],\n            [[1,0],[1,1],[1,1]],\n            [[0,0],[0,0],[0,0]],\n            [[0,1],[1,1],[1,1]]\n        ]\n    }\n\n    all_results = []\n    \n    for case_data in [test_cases['A'], test_cases['B'], test_cases['C']]:\n        # Perform calculations for one test case\n        S = len(case_data)\n        T = len(case_data[0]) if S > 0 else 0\n\n        # Pre-process data into summary statistics (k_it, J_it)\n        summary_data = []\n        for i in range(S):\n            site_summary = []\n            for t in range(T):\n                detections = case_data[i][t]\n                k_it = sum(detections)\n                J_it = len(detections)\n                site_summary.append((k_it, J_it))\n            summary_data.append(site_summary)\n\n        # Numerically stable logistic function\n        def logistic(x):\n            return 1.0 / (1.0 + np.exp(-x))\n\n        # Numerically stable log-sum-exp for log(exp(a) + exp(b))\n        def log_sum_exp(a, b):\n            if a > b:\n                return a + np.log(1.0 + np.exp(b - a))\n            else:\n                return b + np.log(1.0 + np.exp(a - b))\n\n        # Negative log-likelihood function\n        def nll(params):\n            alpha, beta, logit_p = params\n            \n            # Using stable forms for log(p) and log(1-p)\n            log_p = -np.log(1.0 + np.exp(-logit_p))\n            log_1_minus_p = -np.log(1.0 + np.exp(logit_p))\n            if np.isinf(log_p) or np.isinf(log_1_minus_p): return np.inf\n\n            total_log_likelihood = 0.0\n\n            for t_idx in range(T):\n                t = t_idx + 1\n                logit_psi = alpha + beta * (t - 1.0)\n                \n                log_psi_t = -np.log(1.0 + np.exp(-logit_psi))\n                log_1_minus_psi_t = -np.log(1.0 + np.exp(logit_psi))\n                if np.isinf(log_psi_t) or np.isinf(log_1_minus_psi_t): return np.inf\n\n                for i in range(S):\n                    k_it, J_it = summary_data[i][t_idx]\n                    \n                    if k_it > 0:\n                        term = log_psi_t + k_it * log_p + (J_it - k_it) * log_1_minus_p\n                        total_log_likelihood += term\n                    else:\n                        term1 = log_1_minus_psi_t\n                        term2 = log_psi_t + J_it * log_1_minus_p\n                        total_log_likelihood += log_sum_exp(term1, term2)\n            \n            return -total_log_likelihood\n\n        # Find Maximum Likelihood Estimates\n        initial_params = np.array([0.0, 0.0, 0.0]) # alpha, beta, logit(p)\n        result = minimize(nll, initial_params, method='BFGS')\n        alpha_mle, beta_mle, logit_p_mle = result.x\n\n        # 1. Calculate hierarchical change\n        psi_1 = logistic(alpha_mle)\n        psi_T = logistic(alpha_mle + beta_mle * (T - 1))\n        \n        delta_hier = (psi_T - psi_1) / psi_1 if psi_1 != 0 else np.inf\n\n        # 2. Calculate naive change\n        d = np.zeros(T)\n        for t_idx in range(T):\n            detected_sites_count = sum(1 for i in range(S) if summary_data[i][t_idx][0] > 0)\n            d[t_idx] = detected_sites_count / S\n        \n        d_1 = d[0]\n        d_T = d[-1]\n        \n        delta_naive = (d_T - d_1) / d_1 if d_1 != 0 else np.inf\n\n        # 3. Calculate the difference\n        delta_diff = delta_naive - delta_hier\n        \n        # Append rounded results\n        all_results.append(f\"{delta_hier:.3f}\")\n        all_results.append(f\"{delta_naive:.3f}\")\n        all_results.append(f\"{delta_diff:.3f}\")\n        \n    # Print the final formatted output\n    print(f\"[{','.join(all_results)}]\")\n\nsolve()\n```", "id": "2488903"}]}