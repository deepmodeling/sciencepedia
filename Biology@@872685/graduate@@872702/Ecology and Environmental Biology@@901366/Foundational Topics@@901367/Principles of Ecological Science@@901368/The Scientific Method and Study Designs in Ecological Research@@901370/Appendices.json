{"hands_on_practices": [{"introduction": "A cornerstone of sound experimental design is ensuring true replication, yet a common pitfall in ecological research is pseudoreplication—mistaking subsamples for genuine independent replicates. This error can lead to drastically inflated confidence in your results and erroneous conclusions. This practice problem [@problem_id:2538657] challenges you to deconstruct a multi-level experimental setup to identify the correct unit of analysis, a fundamental skill for designing and interpreting any ecological experiment.", "problem": "A laboratory microcosm experiment tests the effect of temperature on per-capita metabolic rate of a small aquatic invertebrate. There are $3$ temperature treatments: $12$, $18$, and $24$ degrees Celsius. To implement treatments, the laboratory maintains, for each temperature, $2$ independent water baths, each with its own thermostat and recirculating loop. Within each water bath, $4$ aerated tanks are placed on the same rack and plumbed exclusively to that bath. Each tank contains $8$ individuals drawn at random from a large, well-mixed stock population. Each individual’s oxygen-consumption rate is measured $3$ times on consecutive days with calibrated respirometry. Temperature is controlled only at the water-bath level; all tanks plumbed to the same bath share the same recirculating water and ambient microclimate. No other blocking factors are present. Assume no mortality, no missing data, and that all measurement errors are independent and identically distributed within their appropriate level of the design hierarchy.\n\nThe investigators plan to test whether mean metabolic rate differs among temperatures using a fixed-effect one-way analysis of variance (ANOVA). Starting from core definitions of experimental units, replication, and degrees of freedom, determine the appropriate unit of analysis that avoids pseudoreplication in this design, and compute the denominator degrees of freedom for the $F$-test of the temperature effect under a design-based analysis that respects the randomization.\n\nProvide your final answer as the denominator degrees of freedom for the temperature effect $F$-test (an integer). No rounding is required.", "solution": "The problem requires the determination of the appropriate unit of analysis and the corresponding denominator degrees of freedom for an $F$-test of a treatment effect in a hierarchical experimental design. The solution demands a strict application of the definitions of an experimental unit and replication to avoid the statistical fallacy of pseudoreplication.\n\nFirst, we must define the central concepts. An **experimental unit** is the smallest division of the experimental material to which a treatment is independently applied. True **replication** consists of applying a treatment to multiple, independent experimental units. **Pseudoreplication** occurs when one treats subsamples or repeated measurements from a single experimental unit as if they were independent replicates. The denominator degrees of freedom in an Analysis of Variance ($ANOVA$) for a treatment effect must be based on the number of true experimental units, not the number of subsamples or measurements.\n\nLet us dissect the hierarchical structure of the experiment as described.\nThe treatment factor is temperature, with $a=3$ levels: $12^\\circ\\text{C}$, $18^\\circ\\text{C}$, and $24^\\circ\\text{C}$.\n\nThe highest level of the experimental structure below the treatment is the **water bath**. The problem states that \"for each temperature, [there are] $2$ independent water baths, each with its own thermostat and recirculating loop.\" This statement is critical. The application of a specific temperature is controlled at the level of the water bath. Because each bath has its own thermostat, the assignment of a temperature to one bath is physically and statistically independent of the assignment to any other bath. Therefore, the **water bath is the experimental unit**.\nThe number of true replicates per temperature treatment is $n=2$.\nThe total number of experimental units in the entire experiment is the number of treatments multiplied by the number of replicates per treatment: $N = a \\times n = 3 \\times 2 = 6$.\n\nThe subsequent levels in the design hierarchy are subsamples within these experimental units.\n- **Tanks**: Within each water bath, there are $k=4$ tanks. These tanks \"share the same recirculating water and ambient microclimate.\" Consequently, the observations from tanks within the same water bath are not independent. They are subject to the same random error associated with that specific water bath's temperature regulation and water chemistry. These tanks are **subsamples** or **observational units**, not experimental units.\n- **Individuals**: Within each tank, there are $m=8$ individuals. These individuals are also subsamples, nested within tanks. Their metabolic rates are not independent because they share the common environment of the tank and, by extension, the water bath.\n- **Measurements**: Each individual is measured $p=3$ times. These are **repeated measures** on the same individual and are also not independent replicates of the temperature effect.\n\nA one-way $ANOVA$ tests the hypothesis that the means of the treatment groups are equal. The $F$-statistic for this test is the ratio of the mean square for the treatment to the mean square for the error:\n$$ F = \\frac{\\text{MS}_{\\text{Treatment}}}{\\text{MS}_{\\text{Error}}} $$\nThe $\\text{MS}_{\\text{Treatment}}$ quantifies the variation *among* the mean metabolic rates of the $a=3$ temperature groups. Its degrees of freedom are $\\text{df}_{\\text{Treatment}} = a - 1 = 3 - 1 = 2$.\nThe $\\text{MS}_{\\text{Error}}$ must quantify the random variation *among the true experimental units* within each treatment group. This is the variation among the water baths. The degrees of freedom for this error term, which become the denominator degrees of freedom for the $F$-test, are calculated based on the total number of experimental units ($N$) and the number of treatment groups ($a$).\n\nThe denominator degrees of freedom are given by:\n$$ \\text{df}_{\\text{Error}} = N - a $$\nIn this design, the total number of experimental units (water baths) is $N=6$, and the number of treatment groups (temperatures) is $a=3$.\nTherefore, the denominator degrees of freedom for the $F$-test of the temperature effect are:\n$$ \\text{df}_{\\text{Error}} = 6 - 3 = 3 $$\nAny analysis that uses the total number of tanks ($24$), individuals ($192$), or measurements ($576$) to calculate the error degrees of freedom (e.g., $24-3=21$, $192-3=189$, or $576-3=573$) would commit the error of pseudoreplication, leading to an invalid inflation of statistical power and a high probability of a Type I error. The correct analysis respects the randomization, which occurred at the level of the water bath. The appropriate error term for the temperature effect is the variation observed among the $n=2$ water baths within each of the $a=3$ temperatures.", "answer": "$$\\boxed{3}$$", "id": "2538657"}, {"introduction": "Once you have a valid experimental design, the next critical question is: \"How many samples do I need?\" An underpowered study wastes resources by having little chance of detecting a true effect, while an overpowered one is also wasteful. This exercise [@problem_id:2538634] walks you through a foundational derivation of the required sample size, directly linking the concepts of significance ($\\alpha$), power ($1-\\beta$), and effect size ($\\delta$) to the practicalities of study planning.", "problem": "An ecologist is planning a randomized, parallel-group field experiment to compare the mean invertebrate biomass between a restored habitat and an unrestored control. Let the restored group have mean $\\mu_{T}$ and the control group have mean $\\mu_{C}$. Assume independent observations, a common and known variance $\\sigma^{2}$ across groups, and equal allocation with $n$ observations per group. The investigator will conduct a $2$-sided hypothesis test of $H_{0}:\\mu_{T}-\\mu_{C}=0$ at significance level $\\alpha$, targeting power $1-\\beta$ to detect a standardized effect size $\\delta$, defined by $\\delta=(\\mu_{T}-\\mu_{C})/\\sigma$. \n\nUsing only first principles that are appropriate for planning in ecological study design—namely, the Central Limit Theorem (CLT), the definition of Type I and Type II errors, and the large-sample normal approximation to the two-sample $t$-statistic—derive the per-group sample size $n$ (not rounded to an integer) required to achieve the specified $\\alpha$, $\\beta$, and $\\delta$ under a $2$-sided test with equal group sizes. \n\nYour derivation must:\n- Start from the distribution of the difference in sample means and the definition of the test statistic under $H_{0}$ and under the alternative.\n- Use the standard normal cumulative distribution function $\\Phi(\\cdot)$ and its quantile function $\\Phi^{-1}(\\cdot)$ to express the rejection threshold for level $\\alpha$ and the noncentral mean under the alternative that corresponds to power $1-\\beta$.\n- Solve explicitly for $n$ in closed form as a function of $\\alpha$, $\\beta$, and $\\delta$.\n\nReport your final answer as a single closed-form analytic expression in terms of $\\Phi^{-1}(\\cdot)$. Do not apply any ceiling or rounding; a numerical evaluation is not required. The sample size is unitless, so no units are needed.", "solution": "The problem statement is scientifically sound, well-posed, objective, and contains all necessary information for a rigorous derivation. It presents a standard task in statistical power analysis. Therefore, the problem is valid, and we proceed with the solution.\n\nWe are tasked to derive the per-group sample size, denoted by $n$, for a two-sample study. The objective is to compare two means, $\\mu_{T}$ for the treatment group and $\\mu_{C}$ for the control group.\n\nLet $\\bar{X}_{T}$ and $\\bar{X}_{C}$ be the sample means obtained from the treatment and control groups, respectively, each of size $n$. The observations are independent, and the population variance $\\sigma^{2}$ is common and assumed to be known. Based on the Central Limit Theorem (CLT), for a sufficiently large sample size $n$, the distributions of the sample means are approximated by the normal distribution:\n$$ \\bar{X}_{T} \\sim \\mathcal{N}\\left(\\mu_{T}, \\frac{\\sigma^{2}}{n}\\right) $$\n$$ \\bar{X}_{C} \\sim \\mathcal{N}\\left(\\mu_{C}, \\frac{\\sigma^{2}}{n}\\right) $$\nDue to the independence of the two groups, the distribution of the difference in sample means, $\\bar{X}_{T} - \\bar{X}_{C}$, is also normal. The expected value and variance of this difference are:\n$$ E[\\bar{X}_{T} - \\bar{X}_{C}] = E[\\bar{X}_{T}] - E[\\bar{X}_{C}] = \\mu_{T} - \\mu_{C} $$\n$$ \\text{Var}(\\bar{X}_{T} - \\bar{X}_{C}) = \\text{Var}(\\bar{X}_{T}) + \\text{Var}(\\bar{X}_{C}) = \\frac{\\sigma^{2}}{n} + \\frac{\\sigma^{2}}{n} = \\frac{2\\sigma^{2}}{n} $$\nThus, the sampling distribution of the difference in means is:\n$$ (\\bar{X}_{T} - \\bar{X}_{C}) \\sim \\mathcal{N}\\left(\\mu_{T} - \\mu_{C}, \\frac{2\\sigma^{2}}{n}\\right) $$\nThe test statistic for the hypothesis test is the standardized difference in sample means. We define the test statistic $Z$ as:\n$$ Z = \\frac{(\\bar{X}_{T} - \\bar{X}_{C}) - (\\mu_{T} - \\mu_{C})}{\\sqrt{\\frac{2\\sigma^{2}}{n}}} $$\nUnder the null hypothesis, $H_{0}: \\mu_{T} - \\mu_{C} = 0$, the statistic simplifies to:\n$$ Z_{0} = \\frac{\\bar{X}_{T} - \\bar{X}_{C}}{\\sigma\\sqrt{\\frac{2}{n}}} $$\nUnder $H_{0}$, $Z_{0}$ follows a standard normal distribution, $Z_{0} \\sim \\mathcal{N}(0, 1)$.\n\nFor a $2$-sided test at a significance level of $\\alpha$, we reject $H_{0}$ if the absolute value of the observed test statistic, $|Z_{0}|$, exceeds the critical value. This critical value is the upper $\\alpha/2$ quantile of the standard normal distribution. Using the standard normal cumulative distribution function $\\Phi(\\cdot)$ and its inverse (the quantile function) $\\Phi^{-1}(\\cdot)$, the critical value is $\\Phi^{-1}(1 - \\alpha/2)$.\nThe rejection rule is: Reject $H_{0}$ if $|Z_{0}|  \\Phi^{-1}(1 - \\alpha/2)$.\n\nNext, we consider the power of the test, $1 - \\beta$. This is the probability of correctly rejecting $H_{0}$ when the alternative hypothesis, $H_{A}$, is true. The problem specifies a standardized effect size $\\delta = (\\mu_{T} - \\mu_{C})/\\sigma$ that we wish to detect. We consider a specific alternative hypothesis where the true difference is $\\mu_{T} - \\mu_{C} = \\Delta$, so $\\delta = \\Delta/\\sigma$.\nThe power is the probability of the test statistic falling into the rejection region, conditional on $H_{A}$ being true. For a $2$-sided test, power is $P(|Z_{0}|  \\Phi^{-1}(1 - \\alpha/2) | \\mu_{T} - \\mu_{C} = \\Delta)$.\nIn typical power calculations for a two-sided test, we assume without loss of generality that $\\Delta  0$. In this case, the probability of rejecting in the lower tail becomes negligible for reasonable power. The power is dominated by the probability of rejecting in the upper tail.\n$$ 1 - \\beta \\approx P\\left(Z_{0}  \\Phi^{-1}(1 - \\alpha/2) | \\mu_{T} - \\mu_{C} = \\Delta\\right) $$\n$$ 1 - \\beta \\approx P\\left(\\frac{\\bar{X}_{T} - \\bar{X}_{C}}{\\sigma\\sqrt{\\frac{2}{n}}}  \\Phi^{-1}(1 - \\alpha/2) | \\mu_{T} - \\mu_{C} = \\Delta\\right) $$\nTo evaluate this probability, we must standardize the random variable $\\bar{X}_{T} - \\bar{X}_{C}$ under the alternative hypothesis, where its mean is $\\Delta$. We subtract the mean $\\Delta$ and divide by the standard deviation $\\sigma\\sqrt{2/n}$:\n$$ 1 - \\beta \\approx P\\left( \\frac{(\\bar{X}_{T} - \\bar{X}_{C}) - \\Delta}{\\sigma\\sqrt{\\frac{2}{n}}}  \\frac{\\sigma\\sqrt{\\frac{2}{n}}\\Phi^{-1}(1 - \\alpha/2) - \\Delta}{\\sigma\\sqrt{\\frac{2}{n}}} \\right) $$\nThe term on the left inside the probability is a standard normal random variable. Let's call it $Z_{A}$.\n$$ 1 - \\beta \\approx P\\left( Z_{A}  \\Phi^{-1}(1 - \\alpha/2) - \\frac{\\Delta}{\\sigma\\sqrt{\\frac{2}{n}}} \\right) $$\nThe probability that a standard normal variable $Z_{A}$ exceeds some value $c$ is $1 - \\Phi(c)$. For this probability to be equal to $1-\\beta$, the value $c$ must be the quantile $\\Phi^{-1}(\\beta)$.\n$$ \\Phi^{-1}(\\beta) = \\Phi^{-1}(1 - \\alpha/2) - \\frac{\\Delta}{\\sigma\\sqrt{\\frac{2}{n}}} $$\nUsing the symmetry of the normal distribution, $\\Phi^{-1}(\\beta) = -\\Phi^{-1}(1 - \\beta)$. Substituting this and the definition of the standardized effect size $\\delta = \\Delta/\\sigma$:\n$$ -\\Phi^{-1}(1 - \\beta) = \\Phi^{-1}(1 - \\alpha/2) - \\frac{\\delta \\sigma}{\\sigma\\sqrt{\\frac{2}{n}}} $$\n$$ -\\Phi^{-1}(1 - \\beta) = \\Phi^{-1}(1 - \\alpha/2) - \\delta\\sqrt{\\frac{n}{2}} $$\nNow, we must solve for the sample size $n$.\n$$ \\delta\\sqrt{\\frac{n}{2}} = \\Phi^{-1}(1 - \\frac{\\alpha}{2}) + \\Phi^{-1}(1 - \\beta) $$\n$$ \\sqrt{n} = \\frac{\\sqrt{2}}{\\delta} \\left( \\Phi^{-1}(1 - \\frac{\\alpha}{2}) + \\Phi^{-1}(1 - \\beta) \\right) $$\nSquaring both sides yields the final closed-form expression for the per-group sample size $n$:\n$$ n = \\frac{2}{\\delta^{2}} \\left( \\Phi^{-1}(1 - \\frac{\\alpha}{2}) + \\Phi^{-1}(1 - \\beta) \\right)^{2} $$\nThis expression provides the required sample size per group as a function of the desired Type I error rate $\\alpha$, Type II error rate $\\beta$, and standardized effect size $\\delta$.", "answer": "$$ \\boxed{ \\frac{2}{\\delta^2} \\left( \\Phi^{-1}\\left(1 - \\frac{\\alpha}{2}\\right) + \\Phi^{-1}(1 - \\beta) \\right)^{2} } $$", "id": "2538634"}, {"introduction": "Ecological data are frequently hierarchical, with observations nested within plots, sites, or regions. This exercise [@problem_id:2538629] moves beyond simple designs to address the practical challenge of optimizing studies that involve such structured data. By deriving the variance of a key parameter in a linear mixed model and optimizing the sampling design under a budget constraint, you will learn how to strategically allocate resources between different levels of your study—a crucial skill for maximizing the statistical power and precision of complex ecological research.", "problem": "Ecologists are studying how microclimate modulates understory plant growth across multiple forest stands. The response for individual $i$ in stand $j$ is modeled as a linear mixed model with a fixed slope and a stand-specific random intercept,\n$$\ny_{ij} = \\beta_0 + \\beta_1 x_{ij} + b_{0j} + \\epsilon_{ij},\n$$\nwhere $b_{0j} \\sim \\mathcal{N}(0,\\sigma_b^2)$ are independent across stands and $\\epsilon_{ij} \\sim \\mathcal{N}(0,\\sigma_e^2)$ are independent across individuals and independent of $b_{0j}$. The study uses a balanced design with $J$ stands and $n$ individuals per stand. The design of the predictor $x_{ij}$ is controlled as follows: within each stand $j$, the sample mean $\\bar{x}_j$ and the within-stand sample variance $v_w$ are fixed by design, and across stands the variance of stand means $\\bar{x}_j$ is fixed to $v_b$, with the grand mean of $x_{ij}$ equal to zero. That is, for each stand $j$, $\\sum_{i=1}^{n} (x_{ij}-\\bar{x}_j)^2 = n\\,v_w$, and across stands $\\frac{1}{J}\\sum_{j=1}^{J} \\bar{x}_j^2 = v_b$, with $\\sum_{j=1}^{J} \\bar{x}_j = 0$.\n\nAssume $J \\geq 2$, $n \\geq 2$, and that $\\sigma_b^2  0$, $\\sigma_e^2  0$, $v_w  0$, $v_b  0$.\n\nTasks:\n- Derive from first principles an exact expression for $\\operatorname{Var}(\\hat{\\beta}_1)$, where $\\hat{\\beta}_1$ is the best linear unbiased estimator of $\\beta_1$ under the Gaussian linear mixed model assumptions, in terms of $J$, $n$, $v_w$, $v_b$, $\\sigma_e^2$, and $\\sigma_b^2$.\n- Suppose the total budget is fixed at $C$, with a stand-initiation cost $c_0  0$ per stand and a per-individual measurement cost $c_1  0$, so that $J = C/(c_0 + c_1 n)$. Holding $C$ fixed and all other quantities as constants, determine the within-stand sample size $n$ that minimizes $\\operatorname{Var}(\\hat{\\beta}_1)$. Assume parameters satisfy conditions ensuring an interior optimum exists. Use the specific parameter values $\\sigma_e^2 = 4$, $\\sigma_b^2 = 1$, $v_w = 1$, $v_b = 1$, $c_0 = 1$, and $c_1 = 1$ to compute the optimal $n$. Round your final numerical answer to four significant figures.\n- Briefly justify, in your derivation, how the design choices in $J$ and $n$ control the precision of $\\hat{\\beta}_1$, and explain qualitatively how increasing $J$ and $n$ affects the precision for estimating the random intercept variance $\\sigma_b^2$ under this balanced design.\n\nFor your final response, report only the optimal $n$ as requested above, in a single numeric value rounded to four significant figures and without units.", "solution": "The problem as stated is scientifically grounded, well-posed, and objective. It presents a standard, albeit detailed, problem in the statistical design of ecological studies using linear mixed models. All required parameters and constraints are provided, and there are no internal contradictions or violations of mathematical or scientific principles. The problem is valid and a solution will be derived.\n\nThe model for the response $y_{ij}$ of individual $i$ in stand $j$ is given by:\n$$\ny_{ij} = \\beta_0 + \\beta_1 x_{ij} + b_{0j} + \\epsilon_{ij}\n$$\nwhere $b_{0j} \\sim \\mathcal{N}(0, \\sigma_b^2)$ and $\\epsilon_{ij} \\sim \\mathcal{N}(0, \\sigma_e^2)$ are independent random variables.\nIn matrix notation for all $N = Jn$ observations, the model is $\\mathbf{y} = \\mathbf{X}\\boldsymbol{\\beta} + \\mathbf{Z}\\mathbf{b} + \\boldsymbol{\\epsilon}$. The covariance matrix of the response vector $\\mathbf{y}$ is $\\mathbf{V} = \\operatorname{Var}(\\mathbf{y}) = \\mathbf{Z}\\operatorname{Var}(\\mathbf{b})\\mathbf{Z}^T + \\operatorname{Var}(\\boldsymbol{\\epsilon}) = \\sigma_b^2 \\mathbf{Z}\\mathbf{Z}^T + \\sigma_e^2 \\mathbf{I}_{Jn}$.\nGiven the balanced design with $J$ stands and $n$ individuals per stand, the matrix $\\mathbf{Z}$ has the structure $\\mathbf{Z} = \\mathbf{I}_J \\otimes \\mathbf{1}_n$, where $\\mathbf{I}_J$ is the $J \\times J$ identity matrix and $\\mathbf{1}_n$ is an $n \\times 1$ vector of ones. This gives $\\mathbf{Z}\\mathbf{Z}^T = \\mathbf{I}_J \\otimes \\mathbf{J}_n$, where $\\mathbf{J}_n$ is the $n \\times n$ matrix of ones.\nThe covariance matrix $\\mathbf{V}$ is block-diagonal:\n$$\n\\mathbf{V} = \\sigma_b^2 (\\mathbf{I}_J \\otimes \\mathbf{J}_n) + \\sigma_e^2 (\\mathbf{I}_J \\otimes \\mathbf{I}_n) = \\mathbf{I}_J \\otimes (\\sigma_e^2 \\mathbf{I}_n + \\sigma_b^2 \\mathbf{J}_n)\n$$\nThe Best Linear Unbiased Estimator (BLUE) for $\\boldsymbol{\\beta} = [\\beta_0, \\beta_1]^T$ is the Generalized Least Squares (GLS) estimator, $\\hat{\\boldsymbol{\\beta}} = (\\mathbf{X}^T \\mathbf{V}^{-1} \\mathbf{X})^{-1} \\mathbf{X}^T \\mathbf{V}^{-1} \\mathbf{y}$, with variance-covariance matrix $\\operatorname{Var}(\\hat{\\boldsymbol{\\beta}}) = (\\mathbf{X}^T \\mathbf{V}^{-1} \\mathbf{X})^{-1}$. We need to derive the $(2,2)$ element of this matrix, which corresponds to $\\operatorname{Var}(\\hat{\\beta}_1)$.\n\nThe inverse of the covariance matrix, $\\mathbf{V}^{-1}$, is also block-diagonal: $\\mathbf{V}^{-1} = \\mathbf{I}_J \\otimes (\\sigma_e^2 \\mathbf{I}_n + \\sigma_b^2 \\mathbf{J}_n)^{-1}$. Using the Sherman-Morrison-Woodbury formula, the inverse of the block is:\n$$\n(\\sigma_e^2 \\mathbf{I}_n + \\sigma_b^2 \\mathbf{J}_n)^{-1} = \\frac{1}{\\sigma_e^2}\\mathbf{I}_n - \\frac{\\sigma_b^2}{\\sigma_e^2(\\sigma_e^2 + n\\sigma_b^2)}\\mathbf{J}_n\n$$\nLet's denote this $n \\times n$ block matrix as $\\mathbf{V}_{\\text{block}}^{-1}$. The matrix $\\mathbf{X}^T \\mathbf{V}^{-1} \\mathbf{X}$ is the Fisher information matrix for $\\boldsymbol{\\beta}$. Due to the block structure, it can be computed as a sum over the $J$ stands:\n$$\n\\mathbf{X}^T \\mathbf{V}^{-1} \\mathbf{X} = \\sum_{j=1}^{J} \\mathbf{X}_j^T \\mathbf{V}_{\\text{block}}^{-1} \\mathbf{X}_j = \\sum_{j=1}^{J} \\begin{pmatrix} \\mathbf{1}_n^T \\\\ \\mathbf{x}_j^T \\end{pmatrix} \\mathbf{V}_{\\text{block}}^{-1} \\begin{pmatrix} \\mathbf{1}_n  \\mathbf{x}_j \\end{pmatrix}\n= \\sum_{j=1}^{J} \\begin{pmatrix} \\mathbf{1}_n^T \\mathbf{V}_{\\text{block}}^{-1} \\mathbf{1}_n  \\mathbf{1}_n^T \\mathbf{V}_{\\text{block}}^{-1} \\mathbf{x}_j \\\\ \\mathbf{x}_j^T \\mathbf{V}_{\\text{block}}^{-1} \\mathbf{1}_n  \\mathbf{x}_j^T \\mathbf{V}_{\\text{block}}^{-1} \\mathbf{x}_j \\end{pmatrix}\n$$\nThe problem states that for the predictor $x_{ij}$, the grand mean is zero due to the condition $\\sum_{j=1}^{J} \\bar{x}_j = 0$. This greatly simplifies the calculation, as it makes the columns of the design matrix $\\mathbf{X}$ orthogonal with respect to the weighting matrix $\\mathbf{V}^{-1}$.\nLet's verify this. The off-diagonal element is $\\sum_j \\mathbf{1}_n^T \\mathbf{V}_{\\text{block}}^{-1} \\mathbf{x}_j$.\nFirst, $\\mathbf{1}_n^T \\mathbf{V}_{\\text{block}}^{-1} = \\mathbf{1}_n^T (\\frac{1}{\\sigma_e^2}\\mathbf{I}_n - \\frac{\\sigma_b^2}{\\sigma_e^2(\\sigma_e^2 + n\\sigma_b^2)}\\mathbf{J}_n) = \\frac{1}{\\sigma_e^2}\\mathbf{1}_n^T - \\frac{n\\sigma_b^2}{\\sigma_e^2(\\sigma_e^2 + n\\sigma_b^2)}\\mathbf{1}_n^T = \\frac{\\sigma_e^2 + n\\sigma_b^2 - n\\sigma_b^2}{\\sigma_e^2(\\sigma_e^2 + n\\sigma_b^2)}\\mathbf{1}_n^T = \\frac{1}{\\sigma_e^2 + n\\sigma_b^2}\\mathbf{1}_n^T$.\nSo, the off-diagonal element is $\\sum_j \\frac{1}{\\sigma_e^2 + n\\sigma_b^2} \\mathbf{1}_n^T \\mathbf{x}_j = \\frac{n}{\\sigma_e^2 + n\\sigma_b^2} \\sum_j \\bar{x}_j = 0$.\nThe matrix $\\mathbf{X}^T \\mathbf{V}^{-1} \\mathbf{X}$ is therefore diagonal. We only need to compute its $(2,2)$ element, which is $\\sum_{j=1}^{J} \\mathbf{x}_j^T \\mathbf{V}_{\\text{block}}^{-1} \\mathbf{x}_j$.\n$$\n\\mathbf{x}_j^T \\mathbf{V}_{\\text{block}}^{-1} \\mathbf{x}_j = \\mathbf{x}_j^T \\left( \\frac{1}{\\sigma_e^2}\\mathbf{I}_n - \\frac{\\sigma_b^2}{\\sigma_e^2(\\sigma_e^2 + n\\sigma_b^2)}\\mathbf{J}_n \\right) \\mathbf{x}_j = \\frac{1}{\\sigma_e^2}\\sum_{i=1}^{n}x_{ij}^2 - \\frac{\\sigma_b^2(n\\bar{x}_j)^2}{\\sigma_e^2(\\sigma_e^2 + n\\sigma_b^2)}\n$$\nUsing the identity $\\sum_i x_{ij}^2 = \\sum_i (x_{ij}-\\bar{x}_j)^2 + n\\bar{x}_j^2 = n v_w + n\\bar{x}_j^2$, we get:\n$$\n\\mathbf{x}_j^T \\mathbf{V}_{\\text{block}}^{-1} \\mathbf{x}_j = \\frac{n v_w + n\\bar{x}_j^2}{\\sigma_e^2} - \\frac{n^2\\bar{x}_j^2\\sigma_b^2}{\\sigma_e^2(\\sigma_e^2 + n\\sigma_b^2)} = \\frac{n v_w}{\\sigma_e^2} + n\\bar{x}_j^2\\left(\\frac{1}{\\sigma_e^2} - \\frac{n\\sigma_b^2}{\\sigma_e^2(\\sigma_e^2 + n\\sigma_b^2)}\\right)\n$$\n$$\n= \\frac{n v_w}{\\sigma_e^2} + n\\bar{x}_j^2\\left(\\frac{\\sigma_e^2+n\\sigma_b^2 - n\\sigma_b^2}{\\sigma_e^2(\\sigma_e^2 + n\\sigma_b^2)}\\right) = \\frac{n v_w}{\\sigma_e^2} + \\frac{n\\bar{x}_j^2}{\\sigma_e^2 + n\\sigma_b^2}\n$$\nSumming over all stands $j$:\n$$\n[\\mathbf{X}^T \\mathbf{V}^{-1} \\mathbf{X}]_{22} = \\sum_{j=1}^{J} \\left( \\frac{n v_w}{\\sigma_e^2} + \\frac{n\\bar{x}_j^2}{\\sigma_e^2 + n\\sigma_b^2} \\right) = \\frac{J n v_w}{\\sigma_e^2} + \\frac{n}{\\sigma_e^2 + n\\sigma_b^2}\\sum_{j=1}^{J}\\bar{x}_j^2\n$$\nUsing the design constraint $\\sum_j \\bar{x}_j^2 = J v_b$, this becomes:\n$$\n[\\mathbf{X}^T \\mathbf{V}^{-1} \\mathbf{X}]_{22} = \\frac{J n v_w}{\\sigma_e^2} + \\frac{J n v_b}{\\sigma_e^2 + n\\sigma_b^2}\n$$\nSince $\\mathbf{X}^T \\mathbf{V}^{-1} \\mathbf{X}$ is diagonal, $\\operatorname{Var}(\\hat{\\beta}_1)$ is the reciprocal of this term.\n$$\n\\operatorname{Var}(\\hat{\\beta}_1) = \\left( \\frac{J n v_w}{\\sigma_e^2} + \\frac{J n v_b}{\\sigma_e^2 + n\\sigma_b^2} \\right)^{-1} = \\frac{1}{Jn \\left( \\frac{v_w}{\\sigma_e^2} + \\frac{v_b}{\\sigma_e^2 + n\\sigma_b^2} \\right)}\n$$\nThis expression represents the variance of the fixed slope estimator. It is inversely proportional to the total information, which is a sum of within-stand information ($Jnv_w/\\sigma_e^2$) and between-stand information ($Jnv_b/(\\sigma_e^2 + n\\sigma_b^2)$).\n\nNext, we minimize this variance with respect to the within-stand sample size $n$, subject to the budget constraint $J = C / (c_0 + c_1 n)$. To minimize the variance, we maximize its reciprocal, the information $I(n)$:\n$$\nI(n) = \\frac{C n}{c_0 + c_1 n} \\left( \\frac{v_w}{\\sigma_e^2} + \\frac{v_b}{\\sigma_e^2 + n\\sigma_b^2} \\right)\n$$\nWe differentiate $I(n)$ with respect to $n$ and set the derivative to zero.\n$$\n\\frac{dI}{dn} = C \\left[ \\frac{d}{dn}\\left(\\frac{n}{c_0+c_1n}\\right) \\frac{v_w}{\\sigma_e^2} + \\frac{d}{dn}\\left(\\frac{n}{(c_0+c_1n)(\\sigma_e^2+n\\sigma_b^2)}\\right)v_b \\right] = 0\n$$\nThe derivatives of the components are:\n$$\n\\frac{d}{dn}\\left(\\frac{n}{c_0+c_1n}\\right) = \\frac{c_0}{(c_0+c_1n)^2}\n$$\n$$\n\\frac{d}{dn}\\left(\\frac{n}{(c_0+c_1n)(\\sigma_e^2+n\\sigma_b^2)}\\right) = \\frac{c_0\\sigma_e^2 - c_1n^2\\sigma_b^2}{((c_0+c_1n)(\\sigma_e^2+n\\sigma_b^2))^2}\n$$\nSetting $\\frac{dI}{dn}=0$ and dividing by common positive factors gives:\n$$\n\\frac{v_w}{\\sigma_e^2} \\frac{c_0}{(c_0+c_1n)^2} + \\frac{v_b(c_0\\sigma_e^2 - c_1n^2\\sigma_b^2)}{(c_0+c_1n)^2(\\sigma_e^2+n\\sigma_b^2)^2} = 0\n$$\n$$\n\\frac{v_w}{\\sigma_e^2} (\\sigma_e^2+n\\sigma_b^2)^2 + v_b(c_0\\sigma_e^2 - c_1n^2\\sigma_b^2) = 0\n$$\nExpanding and collecting terms in powers of $n$:\n$$\n\\frac{v_w}{\\sigma_e^2} ((\\sigma_e^2)^2 + 2n\\sigma_e^2\\sigma_b^2 + n^2(\\sigma_b^2)^2) + v_b c_0\\sigma_e^2 - v_b c_1 n^2\\sigma_b^2 = 0\n$$\n$$\nn^2\\left(\\frac{v_w(\\sigma_b^2)^2}{\\sigma_e^2} - v_b c_1\\sigma_b^2\\right) + n(2v_w\\sigma_b^2) + (v_w\\sigma_e^2 + v_b c_0\\sigma_e^2) = 0\n$$\nWe insert the given parameter values: $\\sigma_e^2 = 4$, $\\sigma_b^2 = 1$, $v_w = 1$, $v_b = 1$, $c_0 = 1$, and $c_1 = 1$.\n$$\nn^2\\left(\\frac{1(1)^2}{4} - 1(1)(1)\\right) + n(2(1)(1)) + (1(4) + 1(1)(4)) = 0\n$$\n$$\nn^2\\left(\\frac{1}{4} - 1\\right) + 2n + (4+4)=0\n$$\n$$\n-\\frac{3}{4}n^2 + 2n + 8 = 0\n$$\nMultiplying by $-4$ to remove the fraction and leading negative sign:\n$$\n3n^2 - 8n - 32 = 0\n$$\nThis is a quadratic equation for $n$. We use the quadratic formula, taking the positive root as $n$ must be positive:\n$$\nn = \\frac{-(-8) + \\sqrt{(-8)^2 - 4(3)(-32)}}{2(3)} = \\frac{8 + \\sqrt{64 + 384}}{6} = \\frac{8 + \\sqrt{448}}{6}\n$$\nSimplifying the radical: $\\sqrt{448} = \\sqrt{64 \\times 7} = 8\\sqrt{7}$.\n$$\nn = \\frac{8 + 8\\sqrt{7}}{6} = \\frac{4 + 4\\sqrt{7}}{3} = \\frac{4}{3}(1+\\sqrt{7})\n$$\nNumerically, this is $n \\approx 4.860965...$. Rounding to four significant figures gives $n = 4.861$.\n\nFinally, we provide the requested justifications.\nThe precision of $\\hat{\\beta}_1$ is the information $I(\\hat{\\beta}_1) = 1/\\operatorname{Var}(\\hat{\\beta}_1) = Jn(\\frac{v_w}{\\sigma_e^2} + \\frac{v_b}{\\sigma_e^2+n\\sigma_b^2})$. This precision depends on the design choices $J$ and $n$. Increasing $J$ (the number of stands) increases both the within-stand and between-stand information components linearly, thus always improving precision. Increasing $n$ (individuals per stand) also increases both components; however, its contribution to the between-stand information, $\\frac{n}{\\sigma_e^2+n\\sigma_b^2} = \\frac{1}{\\sigma_e^2/n + \\sigma_b^2}$, exhibits diminishing returns, approaching a limit of $1/\\sigma_b^2$ as $n \\to \\infty$. The budget constraint forces a trade-off between $J$ and $n$. The optimal design balances the marginal gains in information from adding another stand versus adding another individual to existing stands.\n\nThe precision of the random intercept variance estimate, $\\hat{\\sigma}_b^2$, is primarily determined by the number of stands, $J$. The parameter $\\sigma_b^2$ describes the variability *among* stands. To estimate a variance, one needs multiple data points; in this context, the estimated random effects $\\hat{b}_{0j}$ serve as these data points. A larger $J$ provides more of these points, leading to a more stable and precise estimate of their variance. The within-stand sample size $n$ plays a secondary role: larger $n$ reduces the error ($\\bar{\\epsilon}_j$) in the stand-level means $\\bar{y}_j$, allowing for a more precise estimate of each individual random effect $b_{0j}$. This \"cleans up\" the data from which $\\sigma_b^2$ is estimated. However, without a sufficient number of stands $J$, even perfectly estimated $b_{0j}$ (from infinite $n$) would yield a poor estimate of $\\sigma_b^2$. Therefore, to estimate $\\sigma_b^2$ with high precision, increasing $J$ is fundamentally more important than increasing $n$.", "answer": "$$\n\\boxed{4.861}\n$$", "id": "2538629"}]}