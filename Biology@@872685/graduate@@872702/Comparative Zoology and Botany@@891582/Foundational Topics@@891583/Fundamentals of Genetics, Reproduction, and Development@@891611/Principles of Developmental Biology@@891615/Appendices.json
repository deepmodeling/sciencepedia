{"hands_on_practices": [{"introduction": "The formation of spatial patterns in developing tissues often relies on morphogen gradients, where concentration varies with position. This first practice explores the foundational 'synthesis-diffusion-degradation' model, a cornerstone for understanding how such gradients are established. By deriving the steady-state concentration profile, you will uncover the concept of a characteristic length scale, $\\lambda = \\sqrt{D/k}$, and explore how this single parameter, emerging from molecular kinetics, constrains the physical size of biological structures that can be patterned [@problem_id:2604622].", "problem": "In both animal embryos and plant meristems, diffusible morphogens establish concentration gradients that can encode positional information for cell fate decisions. Consider a one-dimensional tissue occupying $x \\ge 0$, with a localized morphogen source at $x=0$. Assume that within the tissue the morphogen undergoes diffusion with diffusion coefficient $D$ and first-order removal (for example, by degradation or receptor-mediated uptake) with rate constant $k$. Starting from Fick’s second law with first-order loss,\n$$\n\\frac{\\partial c(x,t)}{\\partial t} \\;=\\; D\\,\\frac{\\partial^{2} c(x,t)}{\\partial x^{2}} \\;-\\; k\\,c(x,t),\n$$\nderive the steady-state concentration profile $c(x)$ for $x>0$ away from the source and, by inspecting its spatial dependence, identify the emergent characteristic length scale that governs how rapidly $c(x)$ decays with distance. Then, using this characteristic length, compute its numerical value for a peptide morphogen with $D = 9.0\\,\\mu\\mathrm{m}^{2}\\,\\mathrm{s}^{-1}$ and $k = 2.2 \\times 10^{-4}\\,\\mathrm{s}^{-1}$. \n\nIn your derivation, treat the source as localized at $x=0$ and impose the physically appropriate condition that $c(x)$ remains finite as $x \\to \\infty$. You may assume that any source-specific boundary condition at $x=0$ only fixes the amplitude of $c(x)$ and does not alter the spatial decay rate away from the source.\n\nExplain, based on your derivation, how this characteristic length constrains the spatial range over which positional information can be reliably encoded in tissues across taxa (for example, in a vertebrate limb bud versus a plant root meristem).\n\nExpress the final numerical value of the characteristic length in micrometers, and round your answer to four significant figures.", "solution": "The starting point is the governing equation for the concentration $c(x,t)$:\n$$\n\\frac{\\partial c(x,t)}{\\partial t} = D\\,\\frac{\\partial^{2} c(x,t)}{\\partial x^{2}} - k\\,c(x,t)\n$$\nTo find the steady-state concentration profile, we must impose the condition that the concentration no longer changes with time. Mathematically, this corresponds to setting the time derivative to zero: $\\frac{\\partial c}{\\partial t} = 0$. The partial differential equation thus reduces to a second-order ordinary differential equation (ODE) for the steady-state profile $c(x)$:\n$$\n0 = D\\,\\frac{d^{2} c}{d x^{2}} - k\\,c(x)\n$$\nThis equation is conventionally rearranged into the standard form for a linear homogeneous ODE with constant coefficients:\n$$\n\\frac{d^{2} c}{d x^{2}} - \\frac{k}{D}c(x) = 0\n$$\nTo solve this ODE, we propose a solution of the form $c(x) = \\exp(rx)$ and substitute it into the equation, which yields the characteristic equation for the parameter $r$:\n$$\nr^{2} - \\frac{k}{D} = 0\n$$\nThe roots of this characteristic equation are $r_{1,2} = \\pm\\sqrt{\\frac{k}{D}}$. The general solution for $c(x)$ is a linear combination of the two independent solutions corresponding to these roots:\n$$\nc(x) = A\\,\\exp\\left(\\sqrt{\\frac{k}{D}}x\\right) + B\\,\\exp\\left(-\\sqrt{\\frac{k}{D}}x\\right)\n$$\nwhere $A$ and $B$ are constants to be determined by the boundary conditions.\n\nThe problem specifies two boundary conditions. First, the concentration must remain finite as the distance from the source approaches infinity, i.e., $c(x)$ is bounded as $x \\to \\infty$. The term $A\\,\\exp\\left(\\sqrt{\\frac{k}{D}}x\\right)$ grows without bound as $x \\to \\infty$, since both $D$ and $k$ are positive physical constants. To satisfy the condition of a finite concentration, the coefficient $A$ must be zero. This simplifies the solution to:\n$$\nc(x) = B\\,\\exp\\left(-\\sqrt{\\frac{k}{D}}x\\right)\n$$\nThe second boundary condition pertains to the source at $x=0$. The problem states that this condition sets the amplitude of the concentration profile. We can define the concentration at the source as $c(0) = c_0$. Substituting $x=0$ into our solution gives $c(0) = B\\,\\exp(0) = B$. Thus, the constant $B$ is equal to the concentration at the source, $c_0$. The full steady-state concentration profile is:\n$$\nc(x) = c_0\\,\\exp\\left(-\\sqrt{\\frac{k}{D}}x\\right)\n$$\nThe problem asks to identify the characteristic length scale that governs the spatial decay. The solution shows an exponential decay with distance $x$. A generic exponential decay function is written as $f(x) = f_0 \\exp(-x/\\lambda)$, where $\\lambda$ is the characteristic length scale over which the function's value decreases by a factor of $e$. By comparing our derived solution to this generic form:\n$$\n\\exp\\left(-\\frac{x}{\\lambda}\\right) = \\exp\\left(-x\\sqrt{\\frac{k}{D}}\\right)\n$$\nwe can equate the exponents and identify the characteristic length scale, $\\lambda$:\n$$\n\\lambda = \\sqrt{\\frac{D}{k}}\n$$\nThis length scale, often called the decay length or space constant, is determined by the ratio of the diffusion coefficient to the removal rate constant. It represents the distance over which the morphogen concentration falls to $1/e$ (approximately $37\\%$) of its value at the source.\n\nNow, we compute the numerical value of $\\lambda$ using the provided parameters: $D = 9.0\\,\\mu\\mathrm{m}^{2}\\,\\mathrm{s}^{-1}$ and $k = 2.2 \\times 10^{-4}\\,\\mathrm{s}^{-1}$.\n$$\n\\lambda = \\sqrt{\\frac{9.0\\,\\mu\\mathrm{m}^{2}\\,\\mathrm{s}^{-1}}{2.2 \\times 10^{-4}\\,\\mathrm{s}^{-1}}} = \\sqrt{\\frac{9.0}{2.2 \\times 10^{-4}}}\\,\\mu\\mathrm{m}\n$$\nPerforming the calculation:\n$$\n\\lambda = \\sqrt{40909.0909...}\\,\\mu\\mathrm{m} \\approx 202.2600...\\,\\mu\\mathrm{m}\n$$\nRounding the result to four significant figures, as instructed:\n$$\n\\lambda \\approx 202.3\\,\\mu\\mathrm{m}\n$$\nFinally, the biological implication of this characteristic length must be explained. The length scale $\\lambda$ fundamentally constrains the physical size of a developing tissue that can be patterned by a simple morphogen gradient. For a gradient to encode positional information, cells at different positions must be able to distinguish different local morphogen concentrations. If the tissue to be patterned has a length $L$ that is much larger than $\\lambda$ (e.g., $L \\gg 3\\lambda$), the concentration will have decayed to negligible levels ($c < c_0 e^{-3} \\approx 0.05 c_0$) over the majority of the tissue. In this large-tissue regime, the gradient is too steep near the source and effectively flat (zero) far from the source, meaning most cells experience the same minimal concentration and thus cannot determine their position. Conversely, if the tissue is very small compared to $\\lambda$ ($L \\ll \\lambda$), the exponential function can be approximated as linear ($c(x) \\approx c_0(1-x/\\lambda)$), but the total change in concentration across the tissue is small, which may be difficult for cells to resolve above intrinsic biochemical noise.\n\nTherefore, this diffusion-degradation mechanism is most effective at patterning tissues with dimensions on the order of a few multiples of the characteristic length $\\lambda$. For the calculated value of $\\lambda \\approx 202.3\\,\\mu\\mathrm{m}$, this mechanism is well-suited for patterning fields of a few hundred micrometers, a scale common for structures like the root apical meristem in plants or insect imaginal discs. For much larger structures, such as a vertebrate limb bud which can be several millimeters long, a simple gradient with this decay length would be insufficient to specify position across the entire structure. This implies that larger organisms must employ more complex patterning strategies, such as reaction-diffusion networks that generate stable patterns (Turing patterns), sequential induction, signal relays where cells propagate the signal, or dynamic regulation of the parameters $D$ and $k$ to scale the gradient to the growing tissue size. The value of $\\lambda$ is thus a critical biophysical parameter that connects molecular properties ($D$, $k$) to macroscopic developmental outcomes (organ size and pattern).", "answer": "$$\n\\boxed{202.3}\n$$", "id": "2604622"}, {"introduction": "While morphogen gradients provide a global coordinate system, many patterns emerge from local cell-to-cell interactions. This exercise delves into lateral inhibition, a mechanism where initially equivalent cells adopt different fates through mutual repression, famously mediated by the Notch-Delta signaling pathway. You will model this process as a dynamical system, find its fixed points, and use linear stability analysis to determine whether a homogeneous state is stable or if it spontaneously breaks symmetry to create a pattern [@problem_id:2604680].", "problem": "Consider a minimal two-cell model of Notch–Delta lateral inhibition, suitable for adjacent epithelial cells in a developing tissue. Let $N_i(t)$ denote the activated Notch level in cell $i \\in \\{1,2\\}$ and $D_i(t)$ denote the Delta ligand level in cell $i$. The transcriptional and post-translational processes are represented at a coarse-grained level by ordinary differential equations based on (i) saturating trans-activation of Notch by the neighboring cell’s Delta and (ii) hyperbolic repression of Delta production by the cell’s own Notch. Assume first-order turnover (degradation or effective removal) for both $N_i$ and $D_i$. The model is\n$$\n\\frac{dN_i}{dt} \\;=\\; \\alpha_N \\,\\frac{D_j}{K_T + D_j} \\;-\\; \\beta_N \\, N_i,\\quad j \\neq i,\n$$\n$$\n\\frac{dD_i}{dt} \\;=\\; \\alpha_D \\,\\frac{1}{1 + \\frac{N_i}{K_C}} \\;-\\; \\beta_D \\, D_i,\n$$\nwhere $K_T$ and $K_C$ are positive constants setting the activation and repression scales, respectively, and $\\alpha_N,\\beta_N,\\alpha_D,\\beta_D$ are positive kinetic parameters. This formulation rests on standard biochemical kinetics assumptions: saturable ligand–receptor interaction for Notch activation and hyperbolic repression for Delta production, together with first-order turnover.\n\nAssume the following parameter values and units: $\\alpha_N = 2\\,\\text{h}^{-1}$, $\\beta_N = 1\\,\\text{h}^{-1}$, $\\alpha_D = 1\\,\\text{h}^{-1}$, $\\beta_D = 1\\,\\text{h}^{-1}$, $K_T = 1$ (arbitrary concentration units), $K_C = 1$ (same concentration units). All state variables $N_i,D_i$ are measured in the same arbitrary concentration units; time is measured in hours.\n\nTasks:\n- Using only the definitions and equations above, derive all fixed points $(N_1^{\\ast},N_2^{\\ast},D_1^{\\ast},D_2^{\\ast})$ of the two-cell system. Identify the symmetric fixed point where $N_1^{\\ast} = N_2^{\\ast}$ and $D_1^{\\ast} = D_2^{\\ast}$ explicitly.\n- Linearize the dynamics about the symmetric fixed point by computing the Jacobian matrix and its eigenvalues. Decompose the linearized dynamics into symmetric and antisymmetric perturbation modes to assess stability from first principles.\n- State whether the symmetric fixed point is stable or unstable to symmetric and antisymmetric perturbations, and report the dominant eigenvalue (the one with the largest real part) of the full Jacobian at the symmetric fixed point. Express the final growth rate in per hour. Provide your final answer as a single exact closed-form expression (no numerical rounding is required, and do not include units in the final box).", "solution": "The system of ordinary differential equations describes the dynamics of activated Notch, $N_i(t)$, and Delta, $D_i(t)$, in two interacting cells ($i=1, 2$):\n$$\n\\frac{dN_i}{dt} = \\alpha_N \\frac{D_j}{K_T + D_j} - \\beta_N N_i, \\quad j \\neq i\n$$\n$$\n\\frac{dD_i}{dt} = \\alpha_D \\frac{1}{1 + \\frac{N_i}{K_C}} - \\beta_D D_i\n$$\nThe parameter values are given as $\\alpha_N = 2\\,\\text{h}^{-1}$, $\\beta_N = 1\\,\\text{h}^{-1}$, $\\alpha_D = 1\\,\\text{h}^{-1}$, $\\beta_D = 1\\,\\text{h}^{-1}$, $K_T = 1$, and $K_C = 1$ in consistent units.\n\nFirst, we find the fixed points of the system by setting all time derivatives to zero. A fixed point $(N_1^*, N_2^*, D_1^*, D_2^*)$ must satisfy:\n$$\n\\beta_N N_i^* = \\alpha_N \\frac{D_j^*}{K_T + D_j^*}, \\quad j \\neq i\n$$\n$$\n\\beta_D D_i^* = \\alpha_D \\frac{1}{1 + \\frac{N_i^*}{K_C}}\n$$\nWe seek the symmetric fixed point, where $N_1^* = N_2^* = N^*$ and $D_1^* = D_2^* = D^*$. With the given parameters, the equations simplify to:\n$$\nN^* = \\frac{2D^*}{1+D^*} \\quad \\text{and} \\quad D^* = \\frac{1}{1+N^*}\n$$\nSubstituting the expression for $N^*$ from the first equation into the second gives:\n$$\nD^* = \\frac{1}{1 + \\frac{2D^*}{1+D^*}} = \\frac{1+D^*}{1+D^*+2D^*} = \\frac{1+D^*}{1+3D^*}\n$$\nThis leads to a quadratic equation for $D^*$: $D^*(1+3D^*) = 1+D^*$, which simplifies to $3(D^*)^2 = 1$. Since concentration must be non-negative, we take the positive root: $D^* = 1/\\sqrt{3}$. The corresponding value for $N^*$ is $N^* = 1/D^* - 1 = \\sqrt{3} - 1$.\nThe symmetric fixed point is $(\\sqrt{3}-1, \\sqrt{3}-1, 1/\\sqrt{3}, 1/\\sqrt{3})$.\n\nTo determine if asymmetric fixed points exist, we note the steady-state equations can be written as $D_2 = F(D_1)$ and $D_1 = F(D_2)$, where $F(D) = \\frac{1+D}{1+3D}$. The symmetric solution we found is a fixed point of this mapping, $D^* = F(D^*)$. Asymmetric solutions can bifurcate from the symmetric one if the feedback is sufficiently strong, specifically if $|F'(D^*)| > 1$. We calculate the derivative: $F'(D) = \\frac{1(1+3D) - 3(1+D)}{(1+3D)^2} = \\frac{-2}{(1+3D)^2}$. At the fixed point, $|F'(D^*)| = \\frac{2}{(1+3(1/\\sqrt{3}))^2} = \\frac{2}{(1+\\sqrt{3})^2} = \\frac{2}{4+2\\sqrt{3}} = \\frac{1}{2+\\sqrt{3}}  1$. Since this condition is not met, the symmetric fixed point is stable against this exchange, and no asymmetric fixed points bifurcate. Thus, the symmetric fixed point is the only non-negative solution.\n\nNext, we perform linear stability analysis around the symmetric fixed point. The state vector is $X = (N_1, D_1, N_2, D_2)^T$. The linearized system is $\\delta \\dot{X} = J \\delta X$, where $J$ is the Jacobian matrix evaluated at the fixed point.\nLet $f_N(D) = \\alpha_N \\frac{D}{K_T+D}$ and $f_D(N) = \\alpha_D \\frac{1}{1+N/K_C}$.\nThe derivatives at the fixed point are:\n$C_N = f_N'(D^*) = \\alpha_N \\frac{K_T}{(K_T+D^*)^2} = 2 \\frac{1}{(1+1/\\sqrt{3})^2} = \\frac{6}{(\\sqrt{3}+1)^2} = 3(2-\\sqrt{3})$.\n$C_D = f_D'(N^*) = -\\frac{\\alpha_D/K_C}{(1+N^*/K_C)^2} = -\\frac{1}{(1+\\sqrt{3}-1)^2} = -1/3$.\nThe Jacobian is:\n$$\nJ = \\begin{pmatrix}\n-\\beta_N  0  0  C_N \\\\\nC_D  -\\beta_D  0  0 \\\\\n0  C_N  -\\beta_N  0 \\\\\n0  0  C_D  -\\beta_D\n\\end{pmatrix}\n=\n\\begin{pmatrix}\n-1  0  0  3(2-\\sqrt{3}) \\\\\n-1/3  -1  0  0 \\\\\n0  3(2-\\sqrt{3})  -1  0 \\\\\n0  0  -1/3  -1\n\\end{pmatrix}\n$$\nThe dynamics decouple for symmetric modes ($\\delta N_S = (\\delta N_1+\\delta N_2)/2$, etc.) and antisymmetric modes ($\\delta N_A = (\\delta N_1-\\delta N_2)/2$, etc.).\nFor symmetric modes, the dynamics are governed by $J_S = \\begin{pmatrix} -\\beta_N  C_N \\\\ C_D  -\\beta_D \\end{pmatrix} = \\begin{pmatrix} -1  3(2-\\sqrt{3}) \\\\ -1/3  -1 \\end{pmatrix}$.\nThe eigenvalues $\\lambda_S$ satisfy $(\\lambda_S+1)^2 - C_N C_D = 0 \\implies (\\lambda_S+1)^2 - (3(2-\\sqrt{3}))(-1/3) = 0 \\implies (\\lambda_S+1)^2 + (2-\\sqrt{3}) = 0$.\nThis gives $\\lambda_S = -1 \\pm i\\sqrt{2-\\sqrt{3}}$. Since $\\text{Re}(\\lambda_S) = -1  0$, the symmetric fixed point is stable to symmetric perturbations.\n\nFor antisymmetric modes, the dynamics are governed by $J_A = \\begin{pmatrix} -\\beta_N  -C_N \\\\ C_D  -\\beta_D \\end{pmatrix} = \\begin{pmatrix} -1  -3(2-\\sqrt{3}) \\\\ -1/3  -1 \\end{pmatrix}$.\nThe eigenvalues $\\lambda_A$ satisfy $(\\lambda_A+1)^2 - (-C_N)C_D = 0 \\implies (\\lambda_A+1)^2 + C_N C_D = 0 \\implies (\\lambda_A+1)^2 - (2-\\sqrt{3}) = 0$.\nThis gives $\\lambda_A = -1 \\pm \\sqrt{2-\\sqrt{3}}$.\nWe can simplify the radical: $\\sqrt{2-\\sqrt{3}} = \\sqrt{\\frac{4-2\\sqrt{3}}{2}} = \\frac{\\sqrt{(\\sqrt{3}-1)^2}}{\\sqrt{2}} = \\frac{\\sqrt{3}-1}{\\sqrt{2}}$.\nSince $1  \\sqrt{3}  1+\\sqrt{2}$, we have $0  \\frac{\\sqrt{3}-1}{\\sqrt{2}}  1$. Therefore, both eigenvalues for the antisymmetric mode are negative. The symmetric fixed point is also stable to antisymmetric perturbations. Consequently, the symmetric fixed point is stable.\n\nThe dominant eigenvalue of the full system is the one with the largest (least negative) real part. The four eigenvalues are $\\{-1 \\pm i\\sqrt{2-\\sqrt{3}}, -1 \\pm \\sqrt{2-\\sqrt{3}}\\}$. The largest real part comes from the antisymmetric modes and is $\\lambda_{dom} = -1 + \\sqrt{2-\\sqrt{3}}$.\nUsing the simplified form of the radical, the dominant eigenvalue is:\n$$\n\\lambda_{dom} = -1 + \\frac{\\sqrt{3}-1}{\\sqrt{2}}\n$$\nThis is the required final expression.", "answer": "$$\\boxed{-1 + \\frac{\\sqrt{3}-1}{\\sqrt{2}}}$$", "id": "2604680"}, {"introduction": "Ultimately, developmental patterns are realized through changes in gene expression, which are controlled by cis-regulatory elements like enhancers that integrate signals from multiple transcription factors. This computational practice challenges you to act as a quantitative biologist, inferring the underlying 'logic' of an enhancer (e.g., AND vs. OR) by fitting mathematical models to synthetic gene expression data. This exercise will provide hands-on experience with model selection, a crucial skill for interpreting quantitative data and connecting signaling inputs to transcriptional outputs in modern developmental biology [@problem_id:2604658].", "problem": "You are given the task of inferring enhancer logic across a spatial developmental gradient by fitting a minimal transcription factor occupancy model to reporter intensity data. In comparative zoology and botany, conserved principles of cis-regulatory logic can often be captured by simple probabilistic models derived from quasi-equilibrium binding and independence of transcription factor binding sites. The goal is to decide whether an enhancer integrates two transcription factors according to an AND logic or an OR logic. You must implement a program that takes no input, constructs a fixed synthetic test suite of datasets, fits both candidate models to each dataset by minimizing the mean squared error, and outputs an inference for each dataset in a single line as specified below.\n\nAssumptions and minimal model:\n- Let the spatial coordinate be $x \\in [0,1]$ sampled at $N$ evenly spaced positions $\\{x_i\\}_{i=1}^N$. For each position $x_i$, there are two transcription factor concentrations $c_A(x_i)$ and $c_B(x_i)$.\n- Under quasi-equilibrium binding and independent site occupancy, the single-site binding probability for factor $A$ is modeled by a Hill function $p_A(x) = \\dfrac{c_A(x)^{n_A}}{K_A^{n_A} + c_A(x)^{n_A}}$, and analogously for factor $B$ with parameters $K_B$ and $n_B$.\n- The enhancer’s activation logic is captured by a function $F(p_A, p_B)$ that maps the single-site occupancies to an activation probability. Two hypotheses are considered:\n  - AND logic: $F_{\\mathrm{AND}}(p_A, p_B) = p_A \\cdot p_B$.\n  - OR logic: $F_{\\mathrm{OR}}(p_A, p_B) = 1 - (1 - p_A)(1 - p_B)$.\n- The reporter intensity is modeled as $y(x) \\approx b + s \\cdot F(p_A(x), p_B(x))$, where $b$ is a baseline intensity and $s$ is a scale factor.\n\nFitting objective:\n- For a given dataset consisting of $\\{(x_i, c_A(x_i), c_B(x_i), y_i)\\}_{i=1}^N$, estimate parameters $\\theta = (K_A, K_B, n_A, n_B, s, b)$ under each logic to minimize the mean squared error (MSE): \n$$\\mathrm{MSE}(\\theta) = \\dfrac{1}{N} \\sum_{i=1}^N \\left(y_i - \\left[b + s \\cdot F\\big(p_A(x_i), p_B(x_i)\\big)\\right]\\right)^2.$$\n- To enforce a minimal and identifiable parameterization, optimize $(K_A, K_B, n_A, n_B)$ with bounds $K_A \\in (0, 2]$, $K_B \\in (0, 2]$, $n_A \\in [1, 4]$, $n_B \\in [1, 4]$, and, conditional on these, estimate $(s, b)$ by ordinary least squares on the linear model $y_i \\approx b + s F_i$ with $F_i = F\\big(p_A(x_i), p_B(x_i)\\big)$.\n\nDecision rule:\n- For each dataset, fit both $F_{\\mathrm{AND}}$ and $F_{\\mathrm{OR}}$, compute the minimized $\\mathrm{MSE}_{\\mathrm{AND}}$ and $\\mathrm{MSE}_{\\mathrm{OR}}$, and output the integer $1$ if $\\mathrm{MSE}_{\\mathrm{AND}}  \\mathrm{MSE}_{\\mathrm{OR}} - \\varepsilon$, otherwise output $0$ (breaking ties or near-ties in favor of OR), where $\\varepsilon = 10^{-6}$.\n\nTest suite:\nConstruct three datasets using $N = 101$ positions $x_i$ evenly spaced on $[0,1]$. Use the same “true” parameters for all datasets unless specified: $K_A^{\\mathrm{true}} = 0.3$, $K_B^{\\mathrm{true}} = 0.35$, $n_A^{\\mathrm{true}} = 2$, $n_B^{\\mathrm{true}} = 2$, $s^{\\mathrm{true}} = 1000$, $b^{\\mathrm{true}} = 50$. For all datasets, compute $p_A(x)$ and $p_B(x)$ using the Hill form with the true parameters and then compute the true logic-specific $F$ and reporter $y(x) = b^{\\mathrm{true}} + s^{\\mathrm{true}} \\cdot F(p_A(x), p_B(x))$. Add zero-mean Gaussian noise with specified standard deviation to $y(x)$ to emulate measurement noise. All concentrations must be in arbitrary units on $[0,1]$.\n\n- Dataset $1$ (AND ground truth; “single central domain”): \n  - $c_A(x) = \\exp\\!\\left(-\\dfrac{(x - \\mu_A)^2}{2 \\sigma_A^2}\\right)$ with $\\mu_A = 0.35$, $\\sigma_A = 0.20$.\n  - $c_B(x) = \\exp\\!\\left(-\\dfrac{(x - \\mu_B)^2}{2 \\sigma_B^2}\\right)$ with $\\mu_B = 0.65$, $\\sigma_B = 0.18$.\n  - Logic for generating $y$: AND, $F = F_{\\mathrm{AND}}$.\n  - Add Gaussian noise with standard deviation $\\sigma_y = 25$.\n- Dataset $2$ (OR ground truth; “two-lobed domain”):\n  - $c_A(x) = \\exp\\!\\left(-\\dfrac{(x - \\mu_A)^2}{2 \\sigma_A^2}\\right)$ with $\\mu_A = 0.25$, $\\sigma_A = 0.22$.\n  - $c_B(x) = \\exp\\!\\left(-\\dfrac{(x - \\mu_B)^2}{2 \\sigma_B^2}\\right)$ with $\\mu_B = 0.75$, $\\sigma_B = 0.22$.\n  - Logic for generating $y$: OR, $F = F_{\\mathrm{OR}}$.\n  - Add Gaussian noise with standard deviation $\\sigma_y = 25$.\n- Dataset $3$ (OR ground truth; “A-only boundary case”):\n  - $c_A(x) = 1 - x$.\n  - $c_B(x) = 0.05$ for all $x$.\n  - Use modified true parameters $K_A^{\\mathrm{true}} = 0.25$, $K_B^{\\mathrm{true}} = 0.50$, $n_A^{\\mathrm{true}} = 2$, $n_B^{\\mathrm{true}} = 2$, $s^{\\mathrm{true}} = 900$, $b^{\\mathrm{true}} = 40$.\n  - Logic for generating $y$: OR, $F = F_{\\mathrm{OR}}$.\n  - Add Gaussian noise with standard deviation $\\sigma_y = 5$.\n\nImplementation details:\n- Use a fixed random seed so that results are deterministic. Let the seed be $0$ for generating all noise.\n- For numerical stability in computing $p(c; K, n)$, ensure denominators cannot be zero by adding a small $\\epsilon = 10^{-12}$ if needed during computation.\n- Perform bounded optimization of $(K_A, K_B, n_A, n_B)$ for each logic hypothesis; for each tentative $(K_A, K_B, n_A, n_B)$, compute $F_i$ and then estimate $(s, b)$ by least squares on $y_i \\approx b + s F_i$. Use the minimized MSE as the score for that hypothesis.\n- Use multiple initial guesses for $(K_A, K_B, n_A, n_B)$ to reduce the risk of local minima; at minimum, include initial values $(0.2, 0.2, 1.5, 1.5)$, $(0.5, 0.5, 2.5, 2.5)$, and $(1.0, 1.0, 3.5, 3.5)$.\n\nFinal output format:\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets. For each dataset in order $(1,2,3)$, output the integer $1$ if the fitted AND model attains strictly lower MSE than the fitted OR model by more than $\\varepsilon = 10^{-6}$, otherwise output $0$. For example, a valid output line would look like $[1,0,0]$.", "solution": "This problem requires distinguishing between two competing hypotheses for cis-regulatory logic—AND versus OR integration—for three synthetic datasets. This involves a computational procedure to generate the datasets and then fit both models to each, selecting the model that yields a lower Mean Squared Error (MSE).\n\nThe core of the solution is parameter estimation for each model. The full parameter set is $\\theta = (K_A, K_B, n_A, n_B, s, b)$. The problem specifies a nested optimization strategy (variable projection), where the non-linear parameters $(K_A, K_B, n_A, n_B)$ are optimized in an outer loop, and for each candidate set, the optimal linear parameters $(s, b)$ are found analytically via Ordinary Least Squares (OLS).\n\nThe procedure for a single dataset and a single logic hypothesis ($F$) is as follows:\n\n1.  **Outer Optimization**: A numerical optimization algorithm searches for the optimal non-linear parameters $\\theta_{nl}^* = (K_A^*, K_B^*, n_A^*, n_B^*)$ that minimize the MSE, constrained to the bounds $K_A, K_B \\in (0, 2]$ and $n_A, n_B \\in [1, 4]$.\n\n2.  **Inner OLS Step**: For any given set of non-linear parameters $(K_A, K_B, n_A, n_B)$, the activation probabilities $F_i = F(p_{A,i}, p_{B,i})$ are computed for all data points. The optimal linear parameters $(s, b)$ for the model $y_i = b + s \\cdot F_i$ are then found by OLS, which minimizes the sum of squared residuals. The resulting MSE is the value that the outer optimization loop seeks to minimize.\n\n3.  **Numerical Implementation**: A bounded optimization algorithm (e.g., L-BFGS-B) is used for the outer loop. To avoid local minima, the optimization is run from multiple starting points as specified. The parameter set yielding the lowest MSE across all runs is chosen as the best fit.\n\n4.  **Model Selection**: The entire procedure is performed for both the AND logic ($F_{\\mathrm{AND}}$) and the OR logic ($F_{\\mathrm{OR}}$), yielding two minimized error values, $\\mathrm{MSE}_{\\mathrm{AND}}$ and $\\mathrm{MSE}_{\\mathrm{OR}}$. The decision rule is applied: if $\\mathrm{MSE}_{\\mathrm{AND}}  \\mathrm{MSE}_{\\mathrm{OR}} - \\varepsilon$, the model is classified as AND (1); otherwise, it is classified as OR (0).\n\nThis approach is systematically applied to each of the three synthetic datasets, which are generated first using the specified \"true\" parameters and a fixed random seed for reproducibility.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.optimize import minimize\n\ndef solve():\n    \"\"\"\n    Main function to generate datasets, fit models, and determine enhancer logic.\n    \"\"\"\n    # Set the random seed for reproducible noise generation.\n    np.random.seed(0)\n\n    # Global parameters\n    N = 101\n    x = np.linspace(0, 1, N)\n    epsilon_mse = 1e-6\n\n    # Optimization settings\n    initial_guesses = [\n        (0.2, 0.2, 1.5, 1.5),\n        (0.5, 0.5, 2.5, 2.5),\n        (1.0, 1.0, 3.5, 3.5),\n    ]\n    # Bounds for K are (0, 2], we use a small positive number for the lower bound.\n    bounds = [(1e-9, 2.0), (1e-9, 2.0), (1.0, 4.0), (1.0, 4.0)]\n\n    # --- Dataset Definitions ---\n    # Common true parameters for datasets 1 and 2\n    params_true_1_2 = {'KA': 0.3, 'KB': 0.35, 'nA': 2.0, 'nB': 2.0, 's': 1000.0, 'b': 50.0}\n    # Modified true parameters for dataset 3\n    params_true_3 = {'KA': 0.25, 'KB': 0.50, 'nA': 2.0, 'nB': 2.0, 's': 900.0, 'b': 40.0}\n\n    all_datasets = [\n        {\n            'name': 'Dataset 1 (AND)',\n            'cA': np.exp(-((x - 0.35)**2) / (2 * 0.20**2)),\n            'cB': np.exp(-((x - 0.65)**2) / (2 * 0.18**2)),\n            'true_params': params_true_1_2,\n            'true_logic': 'AND',\n            'noise_std': 25.0\n        },\n        {\n            'name': 'Dataset 2 (OR)',\n            'cA': np.exp(-((x - 0.25)**2) / (2 * 0.22**2)),\n            'cB': np.exp(-((x - 0.75)**2) / (2 * 0.22**2)),\n            'true_params': params_true_1_2,\n            'true_logic': 'OR',\n            'noise_std': 25.0\n        },\n        {\n            'name': 'Dataset 3 (OR, boundary)',\n            'cA': 1.0 - x,\n            'cB': np.full_like(x, 0.05),\n            'true_params': params_true_3,\n            'true_logic': 'OR',\n            'noise_std': 5.0\n        }\n    ]\n\n    # --- Helper Functions ---\n    def hill(c, K, n):\n        \"\"\"Computes the Hill function for binding probability.\"\"\"\n        # Add a small epsilon to denominator to prevent division by zero if c and K are zero,\n        # though bounds prevent K=0.\n        c_n = c**n\n        K_n = K**n\n        return c_n / (K_n + c_n + 1e-12)\n\n    def logic_F(pA, pB, logic_type):\n        \"\"\"Computes the activation probability based on logic type.\"\"\"\n        if logic_type == 'AND':\n            return pA * pB\n        elif logic_type == 'OR':\n            return 1.0 - (1.0 - pA) * (1.0 - pB)\n        else:\n            raise ValueError(\"Unknown logic type\")\n\n    def generate_y_data(dataset_def):\n        \"\"\"Generates the reporter intensity data with noise.\"\"\"\n        p = dataset_def['true_params']\n        pA_true = hill(dataset_def['cA'], p['KA'], p['nA'])\n        pB_true = hill(dataset_def['cB'], p['KB'], p['nB'])\n        F_true = logic_F(pA_true, pB_true, dataset_def['true_logic'])\n        y_true = p['b'] + p['s'] * F_true\n        noise = np.random.normal(0, dataset_def['noise_std'], size=N)\n        return y_true + noise\n\n    def calculate_mse_for_params(params, cA, cB, y_data, logic_type):\n        \"\"\"\n        Objective function for the optimizer.\n        For a given set of non-linear parameters, it calculates the optimal\n        linear parameters (s, b) via OLS and returns the corresponding MSE.\n        \"\"\"\n        KA, KB, nA, nB = params\n        \n        pA = hill(cA, KA, nA)\n        pB = hill(cB, KB, nB)\n        \n        F_vec = logic_F(pA, pB, logic_type)\n        \n        # OLS for s and b: y = b * 1 + s * F\n        X = np.vstack([np.ones_like(F_vec), F_vec]).T\n        \n        # Using numpy.linalg.lstsq to solve for [b, s]\n        # It robustly handles the linear regression and returns sum of squared residuals\n        _, residuals, _, _ = np.linalg.lstsq(X, y_data, rcond=None)\n        \n        if residuals.size == 0:\n            # This can happen if the design matrix is singular, e.g., F_vec is constant.\n            # Predict with mean and calculate MSE.\n            y_pred = np.mean(y_data)\n            mse = np.mean((y_data - y_pred)**2)\n        else:\n            sum_sq_resid = residuals[0]\n            mse = sum_sq_resid / N\n            \n        return mse\n\n    def fit_logic_model(cA, cB, y_data, logic_type):\n        \"\"\"\n        Fits a model (AND or OR) to the data by finding the best non-linear\n        parameters that minimize MSE. Runs optimizer from multiple starting points.\n        \"\"\"\n        min_mse_found = np.inf\n        for start_point in initial_guesses:\n            result = minimize(\n                fun=calculate_mse_for_params,\n                x0=start_point,\n                args=(cA, cB, y_data, logic_type),\n                method='L-BFGS-B',\n                bounds=bounds\n            )\n            if result.fun  min_mse_found:\n                min_mse_found = result.fun\n        return min_mse_found\n\n    # --- Main Loop ---\n    results = []\n    for dataset in all_datasets:\n        y_noisy = generate_y_data(dataset)\n        \n        mse_and = fit_logic_model(dataset['cA'], dataset['cB'], y_noisy, 'AND')\n        mse_or = fit_logic_model(dataset['cA'], dataset['cB'], y_noisy, 'OR')\n        \n        # Decision rule\n        if mse_and  mse_or - epsilon_mse:\n            results.append(1)  # AND model is better\n        else:\n            results.append(0)  # OR model is better or they are too close\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "2604658"}]}