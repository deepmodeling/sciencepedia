{"hands_on_practices": [{"introduction": "Effective panel design is the bedrock of a successful mass cytometry experiment. A critical, yet often overlooked, aspect of this design is the management of 'spreading error'â€”the propagation of counting noise from a highly abundant marker into an adjacent mass channel measuring a less abundant one. This practice guides you through the calculation of this error, providing a quantitative understanding of how spillover from a bright channel degrades the signal quality of its neighbor, a crucial skill for designing panels that can accurately resolve rare or low-density cell populations.", "problem": "A mass cytometry panel is designed to quantify a low-density antigen assigned to one mass channel while a high-density co-expressed marker is assigned to the immediately adjacent mass channel. In inductively coupled plasma time-of-flight mass cytometry, signals are linear in ion counts, and spillover arises from two well-established sources: isotopic impurity and detector peak tailing into adjacent channels. Assume the following empirically characterized and scientifically standard conditions.\n\n- Detector response is linear, and ion arrival follows counting statistics. For a mean ion count $\\mu$, the variance of the counting process is $\\mu$. Empirically, overdispersion is sometimes observed; model this by a Fano factor $F$ so that the variance becomes $F \\mu$.\n- The measured raw intensities in the two channels, $Y_{A}$ and $Y_{B}$, are related to the true underlying signals $A_{\\text{true}}$ and $B_{\\text{true}}$ by a linear system that includes a small spillover from channel $B$ into channel $A$. The standard linear unmixing is applied using the known spillover fraction.\n- Measurement noise sources across channels are independent, and baseline electronic noise is negligible compared to counting noise under the conditions below.\n\nYou are given the following panel-specific and sample-specific parameters, all measured under stable acquisition conditions:\n- The high-density marker in channel $B$ has a mean raw count per event of $\\mu_{B} = 7.5 \\times 10^{4}$ ion counts per event.\n- The overdispersion factor (Fano factor) for channel $B$ is $F_{B} = 1.15$.\n- The spillover fraction from $B$ into the adjacent channel $A$ is the sum of an isotopic impurity component $s_{\\text{iso}} = 0.0022$ and a detector tailing component $s_{\\text{tail}} = 0.0013$.\n- The antigen in channel $A$ is low-density, and you should compute the expected spreading error attributable solely to channel $B$ after linear unmixing, defined as the standard deviation contribution in channel $A$ arising from the noise in channel $B$ propagated through the unmixing step. Ignore any intrinsic variance from channel $A$ itself for this calculation.\n\nUsing only the principles above, compute the expected spreading error standard deviation in channel $A$ in ion counts per event. Express the final answer in ion counts per event and round your answer to three significant figures.", "solution": "The problem requires the computation of the spreading error standard deviation in a mass cytometry channel, which arises from spillover from an adjacent, high-signal channel. This is a standard problem of error propagation in a linear system.\n\nFirst, we formalize the measurement process. Let $A_{\\text{true}}$ and $B_{\\text{true}}$ be the true, underlying ion signals for a given event in channels $A$ and $B$, respectively. The measured raw intensities, denoted by the random variables $Y_A$ and $Y_B$, are affected by spillover. Given that spillover occurs from channel $B$ into channel $A$ with a known fraction $s$, the model for the measured signals is:\n$$ Y_A = A_{\\text{true}}' + s \\cdot Y_B $$\n$$ Y_B = B_{\\text{true}}' $$\nHere, $A_{\\text{true}}'$ and $B_{\\text{true}}'$ represent the true signals plus their own intrinsic counting noise. For the clarity of propagation, let us consider the relationship between the estimators of true signals and the measured signals. The goal of linear unmixing (compensation) is to estimate the true signals from the raw measurements. Let $\\hat{A}_{\\text{true}}$ and $\\hat{B}_{\\text{true}}$ be the estimators. The unmixing process inverts the measurement model:\n$$ \\hat{B}_{\\text{true}} = Y_B $$\n$$ \\hat{A}_{\\text{true}} = Y_A - s \\cdot Y_B $$\n\nWe are asked to find the standard deviation of the error in channel $A$ that is attributable solely to the noise in channel $B$. This error propagates into the estimate $\\hat{A}_{\\text{true}}$. We begin by calculating the variance of $\\hat{A}_{\\text{true}}$.\n$$ \\text{Var}(\\hat{A}_{\\text{true}}) = \\text{Var}(Y_A - s \\cdot Y_B) $$\n\nThe problem states that measurement noise sources across channels are independent. Therefore, the covariance between $Y_A$ and $Y_B$ is zero. Using the properties of variance for independent random variables, we have:\n$$ \\text{Var}(\\hat{A}_{\\text{true}}) = \\text{Var}(Y_A) + \\text{Var}(-s \\cdot Y_B) $$\n$$ \\text{Var}(\\hat{A}_{\\text{true}}) = \\text{Var}(Y_A) + (-s)^2 \\text{Var}(Y_B) $$\n$$ \\text{Var}(\\hat{A}_{\\text{true}}) = \\text{Var}(Y_A) + s^2 \\text{Var}(Y_B) $$\n\nThe total variance of the compensated signal in channel $A$ is composed of two terms: the intrinsic variance of the measurement in channel $A$, $\\text{Var}(Y_A)$, and the variance contribution from channel $B$, $s^2 \\text{Var}(Y_B)$. The latter term is defined as the spreading error variance, $\\sigma_{\\text{spread}}^2$.\n$$ \\sigma_{\\text{spread}}^2 = s^2 \\text{Var}(Y_B) $$\n\nThe problem asks for the spreading error standard deviation, $\\sigma_{\\text{spread}}$, which is the square root of this variance.\n$$ \\sigma_{\\text{spread}} = \\sqrt{s^2 \\text{Var}(Y_B)} = |s| \\sqrt{\\text{Var}(Y_B)} $$\nSince the spillover fraction $s$ is positive, this simplifies to:\n$$ \\sigma_{\\text{spread}} = s \\cdot \\sigma_B $$\nwhere $\\sigma_B = \\sqrt{\\text{Var}(Y_B)}$ is the standard deviation of the raw signal in channel $B$.\n\nNow we must calculate the values of $s$ and $\\text{Var}(Y_B)$ from the given parameters.\n\nThe total spillover fraction $s$ is the sum of the isotopic impurity and detector tailing components:\n$$ s = s_{\\text{iso}} + s_{\\text{tail}} $$\nGiven $s_{\\text{iso}} = 0.0022$ and $s_{\\text{tail}} = 0.0013$:\n$$ s = 0.0022 + 0.0013 = 0.0035 $$\n\nThe variance of the counting process in channel $B$ is given by the model $\\text{Var}(Y_B) = F_B \\mu_B$, where $\\mu_B$ is the mean ion count and $F_B$ is the Fano factor.\nGiven $\\mu_B = 7.5 \\times 10^4$ ion counts and $F_B = 1.15$:\n$$ \\text{Var}(Y_B) = F_B \\cdot \\mu_B = 1.15 \\times (7.5 \\times 10^4) = 86250 $$\n\nNow, substitute these values back into the expression for the spreading error standard deviation:\n$$ \\sigma_{\\text{spread}} = s \\cdot \\sqrt{\\text{Var}(Y_B)} = 0.0035 \\times \\sqrt{86250} $$\nCalculating the numerical value:\n$$ \\sqrt{86250} \\approx 293.6835 $$\n$$ \\sigma_{\\text{spread}} \\approx 0.0035 \\times 293.6835 \\approx 1.02789 $$\n\nThe problem requires the final answer to be rounded to three significant figures.\n$$ \\sigma_{\\text{spread}} \\approx 1.03 $$\nThe expected spreading error standard deviation in channel $A$ due to spillover from channel $B$ is approximately $1.03$ ion counts per event.", "answer": "$$\\boxed{1.03}$$", "id": "2866257"}, {"introduction": "Once data is acquired, the first critical processing step is to correct for signal spillover, where the signal from one metal isotope leaks into adjacent mass channels. This exercise challenges you to implement a robust compensation algorithm using Non-Negative Least Squares (NNLS), which computationally 'unmixes' the raw signals based on a pre-determined spillover matrix. By applying the linear model $\\mathbf{s} = \\mathbf{A}\\mathbf{t}$, you will gain hands-on experience in converting raw, convoluted measurements into accurate estimates of true marker expression, a cornerstone of all downstream analysis.", "problem": "You are given a linear mixing model for mass cytometry (Cytometry by Time of Flight (CyTOF)) signals in which the measured intensity vector $\\mathbf{s} \\in \\mathbb{R}_{\\ge 0}^{C}$ for a single event across $C$ channels is related to the underlying true marker intensities $\\mathbf{t} \\in \\mathbb{R}_{\\ge 0}^{C}$ by the relation $\\mathbf{s} = \\mathbf{A}\\mathbf{t} + \\boldsymbol{\\eta}$, where $\\mathbf{A} \\in \\mathbb{R}^{C \\times C}$ is the spillover matrix estimated from single-stained controls (one control per channel) and $\\boldsymbol{\\eta}$ denotes measurement noise and model mismatch. The spillover matrix $\\mathbf{A}$ encodes on-diagonal primary signal and off-diagonal cross-channel contamination. For a test sample with $E$ events, the measured data are arranged as a matrix $\\mathbf{S} \\in \\mathbb{R}_{\\ge 0}^{E \\times C}$ whose $i$-th row is $\\mathbf{s}_i^\\top$.\n\nYour task is to compute compensated signals using Non-Negative Least Squares (NNLS) and quantify residual contamination per channel. Use the following principled definitions:\n\n1. For each event $i \\in \\{1,\\dots,E\\}$, estimate the compensated true signal $\\widehat{\\mathbf{t}}_i$ by solving the NNLS problem\n$$\n\\widehat{\\mathbf{t}}_i \\;=\\; \\arg\\min_{\\mathbf{t} \\in \\mathbb{R}_{\\ge 0}^{C}} \\left\\| \\mathbf{A}\\mathbf{t} - \\mathbf{s}_i \\right\\|_2^2.\n$$\n\n2. For each $i$ and channel $j \\in \\{1,\\dots,C\\}$, define the model-predicted measured signal $\\widehat{\\mathbf{s}}_i = \\mathbf{A}\\widehat{\\mathbf{t}}_i$ and the off-diagonal predicted contamination in channel $j$ as\n$$\n\\operatorname{offdiag}_{i,j} \\;=\\; \\left(\\widehat{\\mathbf{s}}_i\\right)_j \\;-\\; A_{j,j}\\, \\left(\\widehat{\\mathbf{t}}_i\\right)_j \\;=\\; \\sum_{\\substack{k=1\\\\k \\ne j}}^{C} A_{j,k}\\,\\left(\\widehat{\\mathbf{t}}_i\\right)_k.\n$$\n\n3. To quantify contamination and residuals in a numerically stable way for channels that may have zero measured intensity, define the per-event, per-channel denominators\n$$\nd_{i,j} \\;=\\; \\max\\!\\left( \\left(\\mathbf{s}_i\\right)_j, \\delta \\right),\n$$\nwith a fixed small constant $\\delta = 10^{-9}$.\n\n4. The predicted fractional contamination for event $i$ in channel $j$ is\n$$\nf^{\\mathrm{pred}}_{i,j} \\;=\\; \\frac{\\operatorname{offdiag}_{i,j}}{d_{i,j}},\n$$\nand the residual fractional error is\n$$\nf^{\\mathrm{resid}}_{i,j} \\;=\\; \\frac{\\left| \\left(\\mathbf{s}_i\\right)_j - \\left(\\widehat{\\mathbf{s}}_i\\right)_j \\right|}{d_{i,j}}.\n$$\n\n5. Aggregate across events to obtain two per-channel summaries:\n   - Mean predicted contamination per channel:\n   $$\n   \\overline{f}^{\\mathrm{pred}}_{j} \\;=\\; \\frac{1}{E}\\sum_{i=1}^{E} f^{\\mathrm{pred}}_{i,j}.\n   $$\n   - Maximum residual fractional error per channel:\n   $$\n   f^{\\mathrm{resid,max}}_{j} \\;=\\; \\max_{1 \\le i \\le E} f^{\\mathrm{resid}}_{i,j}.\n   $$\n\nImplement a program that, for each test case provided below, computes the vectors $\\left(\\overline{f}^{\\mathrm{pred}}_{j}\\right)_{j=1}^{C}$ and $\\left(f^{\\mathrm{resid,max}}_{j}\\right)_{j=1}^{C}$ using the definitions above. Use $C = 3$ channels for all cases. No physical units are required for intensities. All outputs must be rounded to $6$ decimal places.\n\nTest suite (three cases):\n\n- Case $1$ (well-conditioned spillover, noiseless sample):\n  - $C = 3$, $E = 4$.\n  - Spillover matrix\n    $$\n    \\mathbf{A}_1 = \\begin{bmatrix}\n    1.0 & 0.02 & 0.01\\\\\n    0.015 & 1.0 & 0.025\\\\\n    0.0 & 0.03 & 1.0\n    \\end{bmatrix}.\n    $$\n  - Measured sample matrix\n    $$\n    \\mathbf{S}_1 = \\begin{bmatrix}\n    1001.1 & 65.25 & 11.5\\\\\n    10.0 & 500.0 & 15.0\\\\\n    206.0 & 208.0 & 206.0\\\\\n    1.0 & 2.5 & 100.0\n    \\end{bmatrix}.\n    $$\n\n- Case $2$ (identity spillover, arbitrary signals including zeros):\n  - $C = 3$, $E = 3$.\n  - Spillover matrix\n    $$\n    \\mathbf{A}_2 = \\begin{bmatrix}\n    1.0 & 0.0 & 0.0\\\\\n    0.0 & 1.0 & 0.0\\\\\n    0.0 & 0.0 & 1.0\n    \\end{bmatrix}.\n    $$\n  - Measured sample matrix\n    $$\n    \\mathbf{S}_2 = \\begin{bmatrix}\n    10.0 & 0.0 & 0.0\\\\\n    0.0 & 20.0 & 30.0\\\\\n    5.0 & 5.0 & 5.0\n    \\end{bmatrix}.\n    $$\n\n- Case $3$ (strong cross-talk, mild additive noise):\n  - $C = 3$, $E = 4$.\n  - Spillover matrix\n    $$\n    \\mathbf{A}_3 = \\begin{bmatrix}\n    1.0 & 0.4 & 0.3\\\\\n    0.35 & 1.0 & 0.45\\\\\n    0.25 & 0.5 & 1.0\n    \\end{bmatrix}.\n    $$\n  - Noisy measured sample matrix\n    $$\n    \\mathbf{S}_3 = \\begin{bmatrix}\n    150.3 & 141.5 & 125.2\\\\\n    47.9 & 120.0 & 60.1\\\\\n    65.0 & 40.2 & 62.2\\\\\n    6.05 & 4.27 & 3.23\n    \\end{bmatrix}.\n    $$\n\nFinal output specification:\n\n- For each test case $m \\in \\{1,2,3\\}$, compute two lists:\n  - $\\left[\\overline{f}^{\\mathrm{pred}}_{1}, \\overline{f}^{\\mathrm{pred}}_{2}, \\overline{f}^{\\mathrm{pred}}_{3}\\right]$,\n  - $\\left[f^{\\mathrm{resid,max}}_{1}, f^{\\mathrm{resid,max}}_{2}, f^{\\mathrm{resid,max}}_{3}\\right]$,\n  with all entries rounded to $6$ decimal places.\n- Your program should produce a single line of output containing the results as a comma-separated list of three elements, each element itself being a two-element list as described above, and with no spaces. For example, the top-level structure must look like\n  $$\n  \\big[\\,[\\,[\\cdot,\\cdot,\\cdot],[\\cdot,\\cdot,\\cdot]\\,],\\;[\\,[\\cdot,\\cdot,\\cdot],[\\cdot,\\cdot,\\cdot]\\,],\\;[\\,[\\cdot,\\cdot,\\cdot],[\\cdot,\\cdot,\\cdot]\\,]\\,\\big]\n  $$\n  where each $\\cdot$ is a decimal rounded to $6$ places.\nUse $\\delta = 10^{-9}$ in all denominators $d_{i,j}$ as defined above. Angles are not involved. All outputs must be real-valued decimals; do not use percentages or symbols.", "solution": "The problem as stated is subjected to rigorous validation and is found to be valid. It is scientifically grounded in the principles of mass cytometry, mathematically well-posed, and provides a complete and unambiguous specification for all required computations. We shall therefore proceed to formulate the solution.\n\nThe objective is to analyze simulated mass cytometry data by first compensating for signal spillover and then quantifying both the extent of this spillover and the residual error of the model. The procedure is a sequence of well-defined analytical steps applied to each cellular event, followed by an aggregation of metrics across all events.\n\nThe foundational model is the linear mixing equation $\\mathbf{s} = \\mathbf{A}\\mathbf{t} + \\boldsymbol{\\eta}$. Here, $\\mathbf{s} \\in \\mathbb{R}_{\\ge 0}^{C}$ is the vector of measured signal intensities across $C$ channels for a single cell. The vector $\\mathbf{t} \\in \\mathbb{R}_{\\ge 0}^{C}$ represents the true, unobserved intensities of the biological markers, which are physically constrained to be non-negative. The spillover matrix $\\mathbf{A} \\in \\mathbb{R}^{C \\times C}$ is a system matrix that quantifies how signal from one channel leaks into others. Its diagonal elements $A_{j,j}$ represent the primary signal sensitivity, while its off-diagonal elements $A_{j,k}$ ($j \\ne k$) represent the cross-channel contamination. The term $\\boldsymbol{\\eta}$ accounts for measurement noise and any deviations from the ideal linear model.\n\nThe algorithmic process for analyzing a dataset of $E$ events, represented by the matrix $\\mathbf{S} \\in \\mathbb{R}_{\\ge 0}^{E \\times C}$, is comprised of the following steps:\n\n1.  **Event-wise Signal Deconvolution:** For each event $i$ (each row $\\mathbf{s}_i$ of $\\mathbf{S}$), we must estimate the true underlying signal vector $\\mathbf{t}_i$. Since true marker expression cannot be negative, we use Non-Negative Least Squares (NNLS) to solve the optimization problem:\n    $$\n    \\widehat{\\mathbf{t}}_i \\;=\\; \\arg\\min_{\\mathbf{t} \\in \\mathbb{R}_{\\ge 0}^{C}} \\left\\| \\mathbf{A}\\mathbf{t} - \\mathbf{s}_i \\right\\|_2^2.\n    $$\n    This formulation finds the best non-negative true signal vector $\\widehat{\\mathbf{t}}_i$ that, when transformed by the spillover matrix $\\mathbf{A}$, most closely reconstructs the measured signal vector $\\mathbf{s}_i$ in the Euclidean norm sense. This is the core signal compensation step.\n\n2.  **Calculation of Model-Predicted Signals and Contamination:** Once the compensated signal $\\widehat{\\mathbf{t}}_i$ is estimated, we compute the idealized measured signal that our model predicts:\n    $$\n    \\widehat{\\mathbf{s}}_i = \\mathbf{A}\\widehat{\\mathbf{t}}_i.\n    $$\n    The off-diagonal contamination in a specific channel $j$ is the portion of the predicted signal $\\left(\\widehat{\\mathbf{s}}_i\\right)_j$ that originates from true signals in other channels $k \\ne j$. It is calculated as:\n    $$\n    \\operatorname{offdiag}_{i,j} \\;=\\; \\sum_{\\substack{k=1\\\\k \\ne j}}^{C} A_{j,k}\\,\\left(\\widehat{\\mathbf{t}}_i\\right)_k.\n    $$\n\n3.  **Quantification of Fractional Contamination and Residual Error:** To make these quantities comparable across different signal magnitudes and to ensure numerical stability, they are normalized. The denominator for each channel $j$ of event $i$ is defined as $d_{i,j} = \\max\\!\\left( \\left(\\mathbf{s}_i\\right)_j, \\delta \\right)$, where $\\delta = 10^{-9}$ is a small constant to prevent division by zero.\n    -   The predicted fractional contamination is the ratio of the off-diagonal contribution to the measured signal:\n        $$\n        f^{\\mathrm{pred}}_{i,j} \\;=\\; \\frac{\\operatorname{offdiag}_{i,j}}{d_{i,j}}.\n        $$\n    -   The residual fractional error measures the discrepancy between the measured signal and the model-reconstructed signal, indicating the goodness-of-fit:\n        $$\n        f^{\\mathrm{resid}}_{i,j} \\;=\\; \\frac{\\left| \\left(\\mathbf{s}_i\\right)_j - \\left(\\widehat{\\mathbf{s}}_i\\right)_j \\right|}{d_{i,j}}.\n        $$\n    A non-zero residual can be attributed to the noise term $\\boldsymbol{\\eta}$ or fundamental inaccuracies of the linear model.\n\n4.  **Aggregation of Per-Channel Statistics:** Finally, the event-level metrics are aggregated across all $E$ events to produce two summary vectors, each of dimension $C$:\n    -   The mean predicted contamination per channel, $\\overline{f}^{\\mathrm{pred}}_{j}$, provides an average measure of the spillover impact on channel $j$ across the cell population:\n        $$\n        \\overline{f}^{\\mathrm{pred}}_{j} \\;=\\; \\frac{1}{E}\\sum_{i=1}^{E} f^{\\mathrm{pred}}_{i,j}.\n        $$\n    -   The maximum residual fractional error per channel, $f^{\\mathrm{resid,max}}_{j}$, identifies the worst-case model failure for channel $j$, which is a critical diagnostic for model performance:\n        $$\n        f^{\\mathrm{resid,max}}_{j} \\;=\\; \\max_{1 \\le i \\le E} f^{\\mathrm{resid}}_{i,j}.\n        $$\n\nThe implementation will systematically apply this entire procedure to each provided test case. It will utilize the `nnls` function from the `scipy.optimize` library for the core optimization step and `numpy` for efficient matrix and vector operations. The final results for each case, consisting of the two vectors $(\\overline{f}^{\\mathrm{pred}}_{j})_{j=1}^{C}$ and $(f^{\\mathrm{resid,max}}_{j})_{j=1}^{C}$, will be formatted as specified.", "answer": "[[[0.010476,0.027014,0.019484],[0.000000,0.000000,0.000000]],[[0.000000,0.000000,0.000000],[0.000000,0.000000,0.000000]],[[0.332306,0.395729,0.518600],[0.003923,0.007609,0.006965]]]", "id": "2866251"}, {"introduction": "The ultimate goal of many systems immunology experiments is to determine if a treatment or condition causes a significant change in the abundance of specific cell populations. This hands-on practice moves beyond basic statistical tests to introduce a powerful and robust method: the exact permutation test for paired data. You will implement a sign-flipping algorithm on arcsine-transformed proportions to generate a null distribution empirically, allowing for a rigorous assessment of treatment effects while honoring the paired experimental design common in clinical and pre-clinical studies.", "problem": "You are given paired mass cytometry by time-of-flight (CyTOF) cluster counts for donors measured under a control condition and the same donors measured under a treatment. For donor-level inference that preserves pairing, design and implement an exact permutation test based on sign-flips of within-donor differences to assess whether treatment changes cluster abundance, while controlling type I error under the null hypothesis that treatment has no effect on the mean of transformed cluster proportions across donors.\n\nFundamental base and assumptions:\n- Cluster event counts measured by mass cytometry are modeled as binomial draws conditional on the total events per sample. Specifically, for donor index $i \\in \\{1,\\dots,n\\}$ and condition $c \\in \\{\\text{control}, \\text{treatment}\\}$, let $Y_{i,c}$ be the cluster count and $N_{i,c}$ the total event count, with $Y_{i,c} \\mid N_{i,c} \\sim \\text{Binomial}(N_{i,c}, p_{i,c})$. The cluster proportion is $P_{i,c} = Y_{i,c}/N_{i,c}$.\n- Use the arcsine square root variance-stabilizing transform $g(p) = \\arcsin(\\sqrt{p})$, with angles in radians. Define within-donor transformed differences $D_i = g(P_{i,\\text{treatment}}) - g(P_{i,\\text{control}})$.\n- Under the sharp null hypothesis that treatment does not change the within-donor cluster proportion distribution, the signs of $D_i$ are exchangeable across donors. A sign-flip permutation test that enumerates all $2^n$ sign patterns on $\\{D_i\\}_{i=1}^n$ yields an exact two-sided test at level $\\alpha$ for the null hypothesis that the mean of $D_i$ is zero.\n- Define the studentized test statistic $T = \\dfrac{\\bar{D}}{S_D/\\sqrt{n}}$, where $\\bar{D}$ is the sample mean of $\\{D_i\\}$ and $S_D$ is the unbiased sample standard deviation computed with degrees-of-freedom correction $n-1$.\n\nAlgorithm to implement:\n- Given paired counts $\\{(N_{i,\\text{control}}, Y_{i,\\text{control}}, N_{i,\\text{treatment}}, Y_{i,\\text{treatment}})\\}_{i=1}^n$, compute $P_{i,c} = Y_{i,c}/N_{i,c}$, $D_i = \\arcsin(\\sqrt{P_{i,\\text{treatment}}}) - \\arcsin(\\sqrt{P_{i,\\text{control}}})$ in radians, $\\bar{D}$, $S_D$, and $T_{\\text{obs}} = \\bar{D}/(S_D/\\sqrt{n})$.\n- Enumerate all $2^n$ sign patterns $\\mathbf{s} \\in \\{-1, +1\\}^n$ to generate permuted differences $D_i^{(\\mathbf{s})} = s_i D_i$, compute $T^{(\\mathbf{s})}$ analogously for each permutation, and compute the exact two-sided permutation $p$-value $p_{\\text{perm}} = \\dfrac{1}{2^n} \\sum_{\\mathbf{s}} \\mathbf{1}\\{\\,|T^{(\\mathbf{s})}| \\ge |T_{\\text{obs}}|\\,\\}$.\n- Use a two-sided significance level $\\alpha = 0.05$ and reject when $p_{\\text{perm}} \\le \\alpha$.\n- Angle unit requirement: the arcsine function must be evaluated in radians.\n\nTest suite:\nImplement your program to run the following four independent test cases. Each case is supplied as an explicit list of donors, where each donor is a tuple $(N_{\\text{control}}, Y_{\\text{control}}, N_{\\text{treatment}}, Y_{\\text{treatment}})$.\n\n- Case A (null-like, mixed small changes, $n = 8$):\n$$\n\\text{case}_A =\n[(12000,180,13000,195),\n(9000,90,9500,105),\n(15000,300,14500,280),\n(11000,132,11500,130),\n(8000,80,8500,88),\n(10000,140,12000,168),\n(13000,169,12500,162),\n(14000,210,15000,240)].\n$$\n\n- Case B (treatment increases abundance, $n = 10$):\n$$\n\\text{case}_B =\n[(10000,100,10000,200),\n(12000,96,11000,220),\n(9000,90,9000,180),\n(15000,225,15000,450),\n(16000,128,16000,256),\n(11000,110,12000,240),\n(8000,72,8000,160),\n(20000,220,20000,440),\n(14000,140,13000,299),\n(10000,130,9000,216)].\n$$\n\n- Case C (edge with zeros and small counts, $n = 6$):\n$$\n\\text{case}_C =\n[(5000,0,5000,10),\n(6000,0,6000,0),\n(7000,7,7000,0),\n(8000,0,8000,16),\n(9000,9,9000,18),\n(10000,10,10000,8)].\n$$\n\n- Case D (small sample, consistent increases, $n = 3$):\n$$\n\\text{case}_D =\n[(10000,100,10000,180),\n(12000,60,12000,120),\n(15000,150,15000,300)].\n$$\n\nTask:\n- For each case, compute the exact two-sided permutation $p$-value as specified and return a boolean indicating whether to reject the null hypothesis at level $\\alpha = 0.05$.\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, in the order $[\\text{Case A}, \\text{Case B}, \\text{Case C}, \\text{Case D}]$, where each element is either True or False, for example, $[\\text{True},\\text{False},\\text{True},\\text{False}]$.\n\nNotes:\n- All computations must be performed in radians for trigonometric functions.\n- If $S_D = 0$, define $T = 0$ when $\\bar{D} = 0$ and define $T = \\text{sign}(\\bar{D}) \\cdot \\infty$ otherwise for the purpose of permutation comparisons.", "solution": "The problem as stated is valid. It presents a clear, self-contained, and scientifically sound task based on established principles of biostatistics. The experimental context, mass cytometry, is appropriate for the proposed data structure. The model assumptions, including the binomial distribution for cell counts and the use of an arcsine square root transformation for variance stabilization, are standard practice for analyzing proportional data. The core of the problem is the implementation of an exact permutation test, a non-parametric method that provides robust control of type I error by generating the null distribution directly from the data. The problem is well-posed, with all necessary data, parameters, and a deterministic algorithm provided, ensuring a unique and verifiable solution.\n\nWe will proceed with the solution by systematically implementing the specified algorithm. The foundation of this procedure rests on the statistical analysis of paired data, where each donor provides a pair of measurements: one under a control condition and one under a treatment condition.\n\nFirst, we formalize the initial data transformation. For each donor $i \\in \\{1, \\dots, n\\}$, we are given the total number of cells analyzed, $N_{i,c}$, and the number of cells belonging to a specific cluster, $Y_{i,c}$, for each condition $c \\in \\{\\text{control}, \\text{treatment}\\}$. The proportion of cells in the cluster is estimated as $P_{i,c} = Y_{i,c} / N_{i,c}$. These proportions are realizations of random variables, and their variance depends on the underlying true probability, which is undesirable for many statistical tests. To mitigate this, we apply the arcsine square root transformation, a standard variance-stabilizing transformation for binomial proportions. The transformed value is $g(p) = \\arcsin(\\sqrt{p})$, with the angle measured in radians. The variance of $g(P_{i,c})$ is approximately $\\frac{1}{4N_{i,c}}$, which is independent of the proportion $p_{i,c}$.\n\nThe paired nature of the experimental design is exploited by computing the within-donor difference of the transformed proportions:\n$$\nD_i = g(P_{i,\\text{treatment}}) - g(P_{i,\\text{control}}) = \\arcsin(\\sqrt{P_{i,\\text{treatment}}}) - \\arcsin(\\sqrt{P_{i,\\text{control}}})\n$$\nThe set of differences $\\{D_i\\}_{i=1}^n$ becomes the fundamental data for our test. The null hypothesis to be tested is that the treatment has no effect on cluster abundance, which implies that the mean of the distribution from which the $D_i$ are drawn is zero.\n\nThe test procedure is an exact permutation test based on sign-flipping. This method is justified by the sharp null hypothesis, which states that for any given donor, the treatment has absolutely no effect. Under this hypothesis, the labels \"control\" and \"treatment\" are interchangeable. Swapping these labels for donor $i$ would simply change the sign of the computed difference $D_i$. Therefore, under the sharp null, the sign of each $D_i$ can be considered a random outcome from a coin flip ($\\{-1, +1\\}$ with equal probability), independent across donors. This principle allows us to generate the complete null distribution of any test statistic by considering all $2^n$ possible sign combinations for the observed differences $\\{D_i\\}_{i=1}^n$.\n\nThe specified test statistic is the studentized mean of the differences, which is identical in form to a one-sample t-statistic:\n$$\nT = \\frac{\\bar{D}}{S_D / \\sqrt{n}}\n$$\nwhere $\\bar{D} = \\frac{1}{n} \\sum_{i=1}^n D_i$ is the sample mean of the differences, and $S_D = \\sqrt{\\frac{1}{n-1} \\sum_{i=1}^n (D_i - \\bar{D})^2}$ is the unbiased sample standard deviation. We first compute this statistic for the observed data, yielding $T_{\\text{obs}}$.\n\nThe core of the algorithm is the enumeration of the null distribution. We generate all $2^n$ sign vectors $\\mathbf{s} = (s_1, s_2, \\dots, s_n)$, where each $s_i \\in \\{-1, +1\\}$. For each vector $\\mathbf{s}$, we create a permuted set of differences $\\{D_i^{(\\mathbf{s})} = s_i D_i\\}_{i=1}^n$. For each such set, we compute the corresponding test statistic $T^{(\\mathbf{s})}$ using the same formula:\n$$\nT^{(\\mathbf{s})} = \\frac{\\bar{D}^{(\\mathbf{s})}}{S_D^{(\\mathbf{s})} / \\sqrt{n}}\n$$\nwhere $\\bar{D}^{(\\mathbf{s})}$ and $S_D^{(\\mathbf{s})}$ are the mean and standard deviation of the permuted differences $\\{D_i^{(\\mathbf{s})}\\}_{i=1}^n$. A special case arises if the standard deviation of a permuted set, $S_D^{(\\mathbf{s})}$, is zero. If the mean $\\bar{D}^{(\\mathbf{s})}$ is also zero, $T^{(\\mathbf{s})}$ is defined as $0$. If $\\bar{D}^{(\\mathbf{s})}$ is non-zero, $T^{(\\mathbf{s})}$ is defined as $\\text{sign}(\\bar{D}^{(\\mathbf{s})}) \\cdot \\infty$ to correctly reflect an infinitely significant deviation. The collection of the $2^n$ values of $T^{(\\mathbf{s})}$ forms the exact null distribution of the statistic.\n\nThe two-sided p-value is then calculated as the proportion of permutations for which the test statistic is at least as extreme as the observed statistic. Formally,\n$$\np_{\\text{perm}} = \\frac{1}{2^n} \\sum_{\\mathbf{s} \\in \\{-1, +1\\}^n} \\mathbf{1}\\{|T^{(\\mathbf{s})}| \\ge |T_{\\text{obs}}|\\}\n$$\nwhere $\\mathbf{1}\\{\\cdot\\}$ is the indicator function, which equals $1$ if the condition is true and $0$ otherwise.\n\nFinally, a decision is made based on a pre-defined significance level $\\alpha$. The problem specifies $\\alpha = 0.05$. If $p_{\\text{perm}} \\le 0.05$, we reject the null hypothesis and conclude there is statistically significant evidence that the treatment affects the cluster abundance. Otherwise, if $p_{\\text{perm}} > 0.05$, we fail to reject the null hypothesis. This procedure will now be implemented for each of the four test cases provided.", "answer": "[False,True,False,True]", "id": "2866321"}]}