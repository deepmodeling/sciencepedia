{"hands_on_practices": [{"introduction": "Before constructing quantitative models, it is essential to master the qualitative logic of the signaling pathway. This exercise uses a classic molecular biology thought experiment involving phospho-dead and phospho-mimetic mutants to probe your understanding of how LATS kinase activity directly controls YAP's subcellular localization. Successfully reasoning through this scenario is fundamental to interpreting a wide range of experiments in the field.", "problem": "You are studying how mechanical inputs regulate organ growth through the Hippo pathway and its effectors Yes-associated protein (YAP) and Transcriptional co-activator with PDZ-binding motif (TAZ). In epithelia, when the Hippo kinase cascade is active, Mammalian STE20-like kinases (MST) and Large Tumor Suppressor kinases (LATS1/2) phosphorylate YAP, creating binding sites for the 14-3-3 proteins that promote cytoplasmic retention and limit TEA domain (TEAD)-dependent transcription linked to proliferation. When the Hippo cascade is inactive, dephosphorylated YAP accumulates in the nucleus and co-activates TEAD, promoting growth and contributing to organ size increase.\n\nYou engineer two YAP mutants: a phospho-dead variant, YAP $S127A$ (serine to alanine at position $127$, which cannot be phosphorylated at that site), and a phospho-mimetic variant, YAP $S127D$ (serine to aspartate at position $127$, which mimics a constitutive negative charge at that site). You express either wild-type YAP, YAP $S127A$, or YAP $S127D$ at comparable levels in epithelial organoids embedded in a compliant extracellular matrix that typically enforces low cytoskeletal tension and activates Hippo signaling.\n\nUsing immunofluorescence, you quantify YAP subcellular localization and TEAD target gene expression. Based on core definitions of kinase-regulated protein phosphorylation and localization control, and accepted Hippo pathway logic connecting phosphorylation state to YAP localization and activity, which statement best predicts the localization outcomes for the mutants on a compliant matrix and correctly infers what those outcomes imply about Hippo pathway activity readouts?\n\nA. On a compliant matrix, wild-type YAP is predominantly cytoplasmic, YAP $S127A$ is predominantly nuclear, and YAP $S127D$ is predominantly cytoplasmic; thus, nuclear localization of YAP $S127A$ cannot be used to infer upstream Hippo pathway activity, whereas nuclear localization of wild-type YAP indicates Hippo pathway inactivation.\n\nB. On a compliant matrix, all three (wild-type, YAP $S127A$, and YAP $S127D$) are predominantly cytoplasmic because the matrix is soft; thus, cytoplasmic localization of YAP $S127A$ shows that Hippo signaling is inactivated.\n\nC. On a compliant matrix, YAP $S127D$ is predominantly nuclear because its negative charge exposes a nuclear localization signal, indicating that active Hippo signaling drives nuclear YAP accumulation.\n\nD. On a compliant matrix, YAP $S127A$ is predominantly cytoplasmic because it cannot be phosphorylated and therefore cannot dissociate from 14-3-3 proteins; this shows that Hippo-driven nuclear exclusion of YAP is independent of phosphorylation.\n\nE. On a compliant matrix, wild-type YAP and YAP $S127D$ are both predominantly nuclear because acidic substitutions mimic RhoA-driven actin tension; therefore, YAP localization is independent of Hippo status and cannot report pathway activity under these conditions.", "solution": "The problem statement shall first be validated for scientific soundness and logical consistency.\n\n### Step 1: Extract Givens\nThe given information is as follows:\n- The system under study is the Hippo pathway, its effectors YAP (Yes-associated protein) and TAZ (Transcriptional co-activator with PDZ-binding motif), and their role in mechanotransduction and organ size control.\n- When the Hippo kinase cascade is active, MST (Mammalian STE20-like kinases) and LATS1/2 (Large Tumor Suppressor kinases) phosphorylate YAP.\n- Phosphorylated YAP creates binding sites for 14-3-3 proteins.\n- Binding of 14-3-3 proteins to phosphorylated YAP promotes its cytoplasmic retention.\n- Cytoplasmic retention of YAP limits its co-activation of TEAD (TEA domain) transcription factors, thereby inhibiting proliferation.\n- When the Hippo cascade is inactive, YAP is dephosphorylated, accumulates in the nucleus, co-activates TEAD, and promotes growth.\n- An experimental setup uses epithelial organoids embedded in a compliant (soft) extracellular matrix.\n- A compliant matrix is stated to enforce low cytoskeletal tension and activate Hippo signaling.\n- Three variants of YAP are expressed:\n    1. Wild-type YAP (YAP WT).\n    2. A phospho-dead variant, YAP S127A, where serine at position 127 is mutated to alanine, preventing phosphorylation at this site.\n    3. A phospho-mimetic variant, YAP S127D, where serine at position 127 is mutated to aspartate, mimicking the negative charge of a phosphate group.\n- The task is to predict the subcellular localization of these YAP variants on a compliant matrix and to infer the implications for using them as reporters of Hippo pathway activity.\n\n### Step 2: Validate Using Extracted Givens\nThe problem statement is evaluated based on the established criteria.\n- **Scientifically Grounded**: The problem is firmly based on established principles of cell biology and signal transduction. The Hippo-YAP/TAZ pathway, its regulation by mechanical cues (mechanotransduction), the roles of LATS kinase, S127 phosphorylation, 14-3-3 protein binding, and nuclear-cytoplasmic shuttling are all well-documented and fundamental concepts in the field. The use of phospho-dead (S to A) and phospho-mimetic (S to D) mutants is a standard and widely accepted technique to investigate protein phosphorylation.\n- **Well-Posed**: The problem is well-posed. It provides a clear experimental context (compliant matrix), defines the key molecular players and their interactions, and asks for a specific prediction based on these established mechanisms. A unique and logical solution can be derived from the provided information.\n- **Objective**: The language is precise and unbiased. It describes biological components and mechanisms without subjectivity.\n\nThe problem statement does not exhibit any flaws such as scientific unsoundness, missing information, or ambiguity. It is a standard, textbook-level problem in molecular and cell biology.\n\n### Step 3: Verdict and Action\nThe problem statement is valid. A solution will be derived.\n\n### Derivation of Solution\n\nThe core of the problem rests on understanding the chain of events initiated by the mechanical environment.\n\n1.  **Mechanical Cue and Hippo Pathway Activity**: A compliant (soft) matrix leads to low cytoskeletal tension. The problem explicitly states this condition activates the Hippo signaling pathway. Therefore, the LATS1/2 kinases are active.\n\n2.  **LATS1/2 Kinase Action**: Active LATS1/2 kinases will phosphorylate their substrates. The key substrate here is YAP at the serine 127 (S127) site.\n\n3.  **Consequence of Phosphorylation**: Phosphorylation of YAP at S127 creates a binding motif for the 14-3-3 family of scaffolding proteins. The problem states that binding of 14-3-3 promotes cytoplasmic retention of YAP.\n\nBased on these principles, we predict the localization of each YAP variant:\n\n-   **Wild-type YAP (YAP WT)**: In the presence of active LATS1/2 kinases (due to the compliant matrix), YAP WT will be phosphorylated at S127. This phosphorylated YAP will bind to 14-3-3 proteins and consequently be retained in the cytoplasm. Therefore, YAP WT is expected to be predominantly cytoplasmic.\n\n-   **Phospho-dead YAP (YAP S127A)**: The mutation from serine (S) to alanine (A) at site 127 removes the hydroxyl group necessary for phosphorylation. Therefore, LATS1/2 kinases, even though active, cannot phosphorylate YAP S127A at this site. Without this phosphorylation, YAP S127A cannot bind 14-3-3 proteins for cytoplasmic sequestration. As nuclear import is the default state for unsequestered YAP, YAP S127A will accumulate in the nucleus. Its localization is thus independent of (and resistant to) the upstream Hippo pathway's \"off\" signal. Therefore, YAP S127A is expected to be predominantly nuclear.\n\n-   **Phospho-mimetic YAP (YAP S127D)**: The mutation from serine (S) to aspartate (D) at site 127 introduces a constitutive negative charge, which mimics the effect of a phosphate group. This variant is \"perceived\" as being permanently phosphorylated at this site. Consequently, YAP S127D will bind 14-3-3 proteins regardless of the activity state of LATS1/2 kinases. This binding will lead to its retention in the cytoplasm. Therefore, YAP S127D is expected to be predominantly cytoplasmic.\n\nSummary of Predictions on a Compliant Matrix:\n- YAP WT: Predominantly cytoplasmic\n- YAP S127A: Predominantly nuclear\n- YAP S127D: Predominantly cytoplasmic\n\nNow, we evaluate the logical implications for inferring pathway activity.\n- The localization of YAP WT is a direct readout of pathway activity. Cytoplasmic YAP WT indicates an active Hippo pathway, while nuclear YAP WT indicates an inactive Hippo pathway.\n- The localization of the mutants is fixed by their structure. YAP S127A is constitutively nuclear and YAP S127D is constitutively cytoplasmic with respect to the S127 phosphorylation site. Observing the nuclear localization of YAP S127A provides no information about the upstream kinase activity, as it would be nuclear even if LATS were active. It only confirms the mutant behaves as expected.\n\n### Evaluation of Options\n\n**A. On a compliant matrix, wild-type YAP is predominantly cytoplasmic, YAP $S127A$ is predominantly nuclear, and YAP $S127D$ is predominantly cytoplasmic; thus, nuclear localization of YAP $S127A$ cannot be used to infer upstream Hippo pathway activity, whereas nuclear localization of wild-type YAP indicates Hippo pathway inactivation.**\n- Prediction of localizations: YAP WT cytoplasmic (Correct), YAP S127A nuclear (Correct), YAP S127D cytoplasmic (Correct). This part is fully consistent with our derivation.\n- Inference about YAP S127A: The nuclear localization of YAP S127A is constitutive because it cannot be phosphorylated. Therefore, observing it in the nucleus does not report on the upstream LATS kinase activity. This statement is correct.\n- Inference about YAP WT: Nuclear localization of YAP WT occurs when it is *not* phosphorylated, which means the Hippo pathway is inactive. This statement is also a correct representation of the pathway logic.\n- Verdict: **Correct**.\n\n**B. On a compliant matrix, all three (wild-type, YAP $S127A$, and YAP $S127D$) are predominantly cytoplasmic because the matrix is soft; thus, cytoplasmic localization of YAP $S127A$ shows that Hippo signaling is inactivated.**\n- Prediction of localizations: \"all three ... are predominantly cytoplasmic\" is incorrect. YAP S127A is expected to be nuclear.\n- Inference: The inference is based on a false premise. Furthermore, the claim that cytoplasmic localization of YAP S127A would show Hippo inactivation is contradictory to the pathway's mechanism.\n- Verdict: **Incorrect**.\n\n**C. On a compliant matrix, YAP $S127D$ is predominantly nuclear because its negative charge exposes a nuclear localization signal, indicating that active Hippo signaling drives nuclear YAP accumulation.**\n- Prediction of localization: YAP S127D is predicted to be nuclear, which is incorrect. It should be cytoplasmic.\n- Mechanistic claim: The claim that the negative charge \"exposes a nuclear localization signal\" is false. The negative charge from phosphorylation (or its mimic) promotes binding to 14-3-3, which leads to cytoplasmic retention, effectively masking nuclear import.\n- Pathway conclusion: The final clause \"active Hippo signaling drives nuclear YAP accumulation\" is the opposite of the established fact.\n- Verdict: **Incorrect**.\n\n**D. On a compliant matrix, YAP $S127A$ is predominantly cytoplasmic because it cannot be phosphorylated and therefore cannot dissociate from 14-3-3 proteins; this shows that Hippo-driven nuclear exclusion of YAP is independent of phosphorylation.**\n- Prediction of a localization: YAP S127A is predicted to be cytoplasmic, which is incorrect.\n- Mechanistic claim: The reasoning \"because it cannot be phosphorylated and therefore cannot dissociate from 14-3-3 proteins\" is fundamentally flawed. YAP binds to 14-3-3 *because* it is phosphorylated. If it cannot be phosphorylated, it cannot bind in the first place.\n- Pathway conclusion: The statement \"Hippo-driven nuclear exclusion of YAP is independent of phosphorylation\" is false. This process is critically dependent on S127 phosphorylation.\n- Verdict: **Incorrect**.\n\n**E. On a compliant matrix, wild-type YAP and YAP $S127D$ are both predominantly nuclear because acidic substitutions mimic RhoA-driven actin tension; therefore, YAP localization is independent of Hippo status and cannot report pathway activity under these conditions.**\n- Prediction of a localization: Predicts YAP WT and YAP S127D are nuclear, which is incorrect. Both should be cytoplasmic under these conditions.\n- Mechanistic claim: The reasoning \"acidic substitutions mimic RhoA-driven actin tension\" is a confused analogy. Acidic substitutions (S to D) mimic phosphorylation. High RhoA activity and actin tension are associated with *stiff* matrices, which *inactivate* the Hippo pathway, leading to *dephosphorylated* and nuclear YAP. The option conflates and reverses cause and effect.\n- Verdict: **Incorrect**.\n\nBased on the analysis, option A is the only one that correctly predicts the experimental outcomes and draws the correct logical conclusions about the pathway.", "answer": "$$\\boxed{A}$$", "id": "2688222"}, {"introduction": "With a solid conceptual foundation, we can now translate the biological mechanism of mechanosensing into a mathematical framework. This practice challenges you to derive the Hill equation, a cornerstone for modeling cooperative biological phenomena, to describe the sigmoidal relationship between extracellular matrix stiffness and YAP nuclear accumulation [@problem_id:2688222]. This exercise illustrates how complex, switch-like biological behaviors can often be captured by a simple yet powerful mathematical expression.", "problem": "Yes-Associated Protein / Transcriptional co-Activator with PDZ-binding motif (YAP/TAZ) is a mechanosensitive transcriptional co-regulator whose nuclear localization increases with substrate stiffness due to cytoskeletal tension and focal adhesion maturation. Consider a coarse-grained mechanotransduction module in which a stiffness-sensing complex can exist in an inactive state or an active state that promotes nuclear import of YAP. Assume the following well-tested facts and definitions as the fundamental base: (i) equilibrium occupancy of a receptor by a ligand follows mass-action balance; (ii) cooperative activation of a complex by an input can be captured by an effective Hill-Langmuir form arising from $n$-th order binding or concerted transition; (iii) the half-activation parameter $K$ is the input value at which the active-state probability is $1/2$; and (iv) at steady state, the nuclear fraction of YAP is proportional to the active-state probability of the mechanosensor, with the proportionality set to unity by normalization of total YAP. Treat substrate Young’s modulus $E$ (in $\\mathrm{kPa}$) as the effective input to the sensor.\nStarting from these assumptions and without assuming any particular target formula, derive an expression for the steady-state nuclear fraction $N(E)$ as a function of $E$, the half-activation stiffness $K$, and the effective Hill coefficient $n$. Then, using your derived expression, compute $N$ for $E = 10$ $\\mathrm{kPa}$, $K = 8$ $\\mathrm{kPa}$, and $n = 3$. Express the final value of $N$ as a unitless decimal rounded to four significant figures.", "solution": "The problem requires the derivation of an expression for the steady-state nuclear fraction of YAP, denoted as $N(E)$, as a function of substrate Young's modulus $E$, a half-activation stiffness $K$, and a Hill coefficient $n$. The derivation must proceed from the provided assumptions.\n\nAssumption (ii) states that the cooperative activation of the stiffness-sensing complex by the input, $E$, can be described by an effective Hill-Langmuir form. The Hill-Langmuir equation models the fractional saturation or activation of a system exhibiting cooperative binding. Let $P_{\\text{active}}(E)$ be the probability that the mechanosensor is in the active state. This probability is the fractional response of the system to the input stiffness $E$. The general form of the Hill equation is:\n$$ P_{\\text{active}}(E) = \\frac{E^n}{K_{A}^n + E^n} $$\nwhere $n$ is the Hill coefficient quantifying the degree of cooperativity, and $K_{A}$ is the apparent activation constant, which corresponds to the value of the input $E$ that yields half-maximal activation.\n\nAssumption (iii) defines the parameter $K$ as the half-activation stiffness, meaning the input value $E$ at which the active-state probability is $1/2$. We must verify that our chosen form of the Hill equation is consistent with this definition. Let us set $E = K$. Then, the expression for the probability becomes:\n$$ P_{\\text{active}}(K) = \\frac{K^n}{K^n + K^n} = \\frac{K^n}{2 K^n} = \\frac{1}{2} $$\nThis is consistent with the definition of $K$ provided in the problem. Therefore, the parameter $K_{A}$ in the general Hill equation corresponds to the parameter $K$ given in the problem statement. The correct expression for the active-state probability is:\n$$ P_{\\text{active}}(E) = \\frac{E^n}{K^n + E^n} $$\n\nAssumption (iv) provides the link between the mechanosensor's state and the nuclear fraction of YAP, $N(E)$. It states that at steady state, $N(E)$ is proportional to $P_{\\text{active}}(E)$, and the proportionality constant is unity ($1$) due to normalization. Thus, we have the direct relationship:\n$$ N(E) = 1 \\cdot P_{\\text{active}}(E) $$\nSubstituting the expression for $P_{\\text{active}}(E)$, we arrive at the derived expression for the steady-state nuclear fraction of YAP:\n$$ N(E) = \\frac{E^n}{K^n + E^n} $$\n\nThe second part of the problem is to compute the value of $N$ for the specific parameters $E = 10 \\ \\mathrm{kPa}$, $K = 8 \\ \\mathrm{kPa}$, and $n = 3$. We substitute these values into the derived formula. The units of $E$ and $K$ are identical and will cancel, yielding a dimensionless result for $N$, as expected for a fraction.\n$$ N = \\frac{10^3}{8^3 + 10^3} $$\nWe proceed with the calculation of the powers:\n$$ 10^3 = 1000 $$\n$$ 8^3 = 8 \\times 8 \\times 8 = 64 \\times 8 = 512 $$\nSubstituting these values back into the expression for $N$:\n$$ N = \\frac{1000}{512 + 1000} = \\frac{1000}{1512} $$\nTo obtain the final numerical answer, we perform the division:\n$$ N \\approx 0.66137566... $$\nThe problem requires the result to be rounded to four significant figures. The fifth significant digit is $7$, which is greater than or equal to $5$, so we round up the fourth significant digit.\n$$ N \\approx 0.6614 $$\nThis is the final numerical answer.", "answer": "$$\n\\boxed{0.6614}\n$$", "id": "2688216"}, {"introduction": "A theoretical model's true utility is demonstrated when it is confronted with real experimental data, which is inevitably noisy and sparse. This capstone practice bridges theory and application, guiding you to use a Bayesian statistical approach to fit the Hill model you derived previously [@problem_id:2688216] to simulated experimental measurements. By implementing a Maximum A Posteriori (MAP) estimation algorithm, you will learn a powerful technique for extracting meaningful biological parameters, like the system's sensitivity ($K$) and cooperativity ($n$), from realistic data.", "problem": "In organ size control, Yes-associated protein (YAP) and transcriptional coactivator with PDZ-binding motif (TAZ) transduce mechanical cues from the extracellular matrix to regulate gene expression. A widely replicated observation is that the nuclear fraction of YAP/TAZ increases with substrate stiffness in a monotonic, saturating manner consistent with a Hill-type input-output relation. Consider the following generative model for independent measurements of normalized nuclear fraction.\n\nYou are given a set of independent measurements $\\{(E_i, N_i)\\}_{i=1}^m$, where $E_i$ is the substrate Young’s modulus in kilopascals ($\\mathrm{kPa}$) and $N_i$ is the measured nuclear fraction of YAP/TAZ (dimensionless, between $0$ and $1$ in the noise-free model). Assume the following model structure:\n- The deterministic input-output relation is given by a Hill form with known saturation bounds $N_{\\min} = 0$ and $N_{\\max} = 1$:\n$$\nf(E; K, n) \\equiv \\frac{E^n}{K^n + E^n},\n$$\nwhere $K$ (in $\\mathrm{kPa}$) is the stiffness at half-maximal response and $n$ (dimensionless) is the Hill coefficient.\n- The observation model is additive, independent, zero-mean Gaussian noise:\n$$\nN_i = f(E_i; K, n) + \\varepsilon_i,\\quad \\varepsilon_i \\overset{\\text{i.i.d.}}{\\sim} \\mathcal{N}(0, \\sigma^2).\n$$\n- The prior on parameters encodes positivity and scale via independent Normal priors on their logarithms:\n$$\n\\log K \\sim \\mathcal{N}(m_K, s_K^2), \\quad \\log n \\sim \\mathcal{N}(m_n, s_n^2),\n$$\nwith all logarithms being natural logarithms.\n\nTasks:\n1) Using the assumptions above and the independence of measurements, write the likelihood $p(\\{N_i\\}\\mid \\{E_i\\}, K, n, \\sigma)$ and the corresponding log-likelihood. Then combine with the priors to write the posterior density $p(K, n \\mid \\{E_i, N_i\\}, \\sigma, m_K, s_K, m_n, s_n)$ up to a proportionality constant. Finally, provide the negative log-posterior expression to be minimized for maximum a posteriori estimation.\n2) Propose an algorithm that computes the maximum a posteriori estimates $(\\hat{K}, \\hat{n})$ by minimizing the negative log-posterior with respect to $K$ and $n$. Your algorithm must enforce $K &gt; 0$ and $n &gt; 0$, and it should be numerically stable when $E$ spans orders of magnitude. State any reparameterizations you use and justify them based on the model.\n3) Implement your algorithm as a complete, runnable program that takes no input and applies the procedure to the following test suite. For each test case, produce MAP estimates for $K$ (in $\\mathrm{kPa}$) and $n$ (dimensionless), rounding each to $3$ decimal places. Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, flattened across test cases in the order given, namely $\\big[\\hat{K}_1,\\hat{n}_1,\\hat{K}_2,\\hat{n}_2,\\dots\\big]$.\n\nUse the following test suite, where each test case specifies $\\{E_i\\}$ in $\\mathrm{kPa}$, $\\{N_i\\}$ (dimensionless), $\\sigma$ (dimensionless), and prior hyperparameters $(m_K, s_K, m_n, s_n)$:\n\n- Test case $1$ (typical stiffness range, moderate noise):\n  - $E = [\\,0.5,\\,1.0,\\,2.0,\\,4.0,\\,8.0,\\,16.0\\,]$\n  - $N = [\\,0.015495,\\,0.010303,\\,0.180200,\\,0.490000,\\,0.869540,\\,0.939700\\,]$\n  - $\\sigma = 0.05$\n  - $(m_K, s_K, m_n, s_n) = (1.3862943611,\\,0.8,\\,0.6931471806,\\,0.5)$\n- Test case $2$ (broader stiffness range, higher noise):\n  - $E = [\\,0.5,\\,1.0,\\,2.0,\\,5.0,\\,10.0,\\,20.0,\\,40.0\\,]$\n  - $N = [\\,0.006700,\\,0.109400,\\,0.106600,\\,0.363300,\\,0.460000,\\,0.706900,\\,0.811100\\,]$\n  - $\\sigma = 0.10$\n  - $(m_K, s_K, m_n, s_n) = (2.0794415417,\\,0.8,\\,0.4054651081,\\,0.5)$\n- Test case $3$ (limited sub-saturating regime, low noise; potential identifiability challenge):\n  - $E = [\\,0.2,\\,0.4,\\,0.8,\\,1.6\\,]$\n  - $N = [\\,0.005100,\\,0.000597,\\,0.027970,\\,0.280700\\,]$\n  - $\\sigma = 0.03$\n  - $(m_K, s_K, m_n, s_n) = (1.0986122887,\\,0.7,\\,1.0986122887,\\,0.7)$\n\nConstraints and requirements:\n- All computations must be performed assuming $E$ and $K$ are in $\\mathrm{kPa}$ and $n$ is dimensionless.\n- Angles are not used in this problem; no angle unit is required.\n- Your final output must be a single line in the exact format described: a single Python print producing one bracketed, comma-separated list of floats rounded to $3$ decimal places, flattened across test cases as $[\\,\\hat{K}_1,\\hat{n}_1,\\hat{K}_2,\\hat{n}_2,\\hat{K}_3,\\hat{n}_3\\,]$.", "solution": "The problem statement is examined and found to be valid. It is scientifically grounded in the principles of biophysical modeling and statistical inference, and it is mathematically well-posed. All necessary components for a unique solution are provided, and there are no internal contradictions. We may therefore proceed with the derivation and implementation.\n\nThe objective is to find the maximum a posteriori (MAP) estimates for the parameters $K$ and $n$ of a Hill-type model describing YAP/TAZ nuclear localization as a function of substrate stiffness $E$. This requires the formulation and subsequent minimization of the negative log-posterior probability distribution of the parameters.\n\nThe problem is addressed in two parts as requested: first, the derivation of the objective function (the negative log-posterior), and second, the specification of a numerical algorithm to find its minimum.\n\n**1. Derivation of the Negative Log-Posterior**\n\nLet the parameters of interest be $K$ and $n$. We are given a set of $m$ independent measurements $\\{ (E_i, N_i) \\}_{i=1}^m$.\n\nThe deterministic relationship is the Hill function:\n$$\nf(E_i; K, n) = \\frac{E_i^n}{K^n + E_i^n}\n$$\n\nThe observation model assumes additive, independent, and identically distributed (i.i.d.) Gaussian noise, $\\varepsilon_i \\sim \\mathcal{N}(0, \\sigma^2)$. Thus, the likelihood of observing a single data point $N_i$ given $E_i$, $K$, $n$, and $\\sigma$ is given by the probability density function of the Normal distribution:\n$$\np(N_i \\mid E_i, K, n, \\sigma) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}} \\exp\\left( -\\frac{(N_i - f(E_i; K, n))^2}{2\\sigma^2} \\right)\n$$\nDue to the independence of measurements, the total likelihood of the dataset $\\{N_i\\}$ is the product of the individual likelihoods:\n$$\np(\\{N_i\\} \\mid \\{E_i\\}, K, n, \\sigma) = \\prod_{i=1}^m p(N_i \\mid E_i, K, n, \\sigma) = \\left(2\\pi\\sigma^2\\right)^{-m/2} \\exp\\left( -\\frac{1}{2\\sigma^2} \\sum_{i=1}^m (N_i - f(E_i; K, n))^2 \\right)\n$$\nThe corresponding log-likelihood, denoted $\\mathcal{L}_{\\text{data}}$, is:\n$$\n\\mathcal{L}_{\\text{data}} = \\log p(\\{N_i\\} \\mid \\{E_i\\}, K, n, \\sigma) = -\\frac{m}{2} \\log(2\\pi\\sigma^2) - \\frac{1}{2\\sigma^2} \\sum_{i=1}^m (N_i - f(E_i; K, n))^2\n$$\nThe priors for the parameters are specified for their logarithms: $\\log K \\sim \\mathcal{N}(m_K, s_K^2)$ and $\\log n \\sim \\mathcal{N}(m_n, s_n^2)$. The joint prior density is thus:\n$$\np(\\log K, \\log n) = p(\\log K) p(\\log n) = \\frac{1}{\\sqrt{2\\pi s_K^2}} \\exp\\left( -\\frac{(\\log K - m_K)^2}{2s_K^2} \\right) \\cdot \\frac{1}{\\sqrt{2\\pi s_n^2}} \\exp\\left( -\\frac{(\\log n - m_n)^2}{2s_n^2} \\right)\n$$\nFrom Bayes' theorem, the posterior probability of the parameters is proportional to the product of the likelihood and the prior:\n$$\np(K, n \\mid \\{E_i, N_i\\}, \\sigma, \\dots) \\propto p(\\{N_i\\} \\mid \\{E_i\\}, K, n, \\sigma) \\cdot p(K,n)\n$$\nIt is more convenient to work with the log-posterior and to reparameterize the problem in terms of $\\theta_K = \\log K$ and $\\theta_n = \\log n$. In this parameter space, the prior is a simple Gaussian. The posterior for $\\theta_K$ and $\\theta_n$ is:\n$$\np(\\theta_K, \\theta_n \\mid \\text{data}) \\propto p(\\text{data} \\mid \\theta_K, \\theta_n) \\cdot p(\\theta_K, \\theta_n)\n$$\nThe log-posterior is therefore:\n$$\n\\log p(\\theta_K, \\theta_n \\mid \\text{data}) = \\log p(\\text{data} \\mid \\theta_K, \\theta_n) + \\log p(\\theta_K) + \\log p(\\theta_n) + C\n$$\nwhere $C$ is a constant of normalization. Substituting the expressions for the log-likelihood and log-priors:\n$$\n\\log p(\\theta_K, \\theta_n \\mid \\dots) = -\\frac{1}{2\\sigma^2} \\sum_{i=1}^m (N_i - f(E_i; e^{\\theta_K}, e^{\\theta_n}))^2 - \\frac{(\\theta_K - m_K)^2}{2s_K^2} - \\frac{(\\theta_n - m_n)^2}{2s_n^2} + C'\n$$\nThe MAP estimate is found by maximizing this log-posterior, which is equivalent to minimizing its negative. The negative log-posterior, which we will denote as $\\mathcal{L}_{\\text{MAP}}$, is our objective function to be minimized. Ignoring constants that do not affect the location of the minimum:\n$$\n\\mathcal{L}_{\\text{MAP}}(\\theta_K, \\theta_n) = \\frac{1}{2\\sigma^2} \\sum_{i=1}^m \\left(N_i - f(E_i; e^{\\theta_K}, e^{\\theta_n})\\right)^2 + \\frac{(\\theta_K - m_K)^2}{2s_K^2} + \\frac{(\\theta_n - m_n)^2}{2s_n^2}\n$$\n\n**2. Algorithm for MAP Estimation**\n\nTo compute the MAP estimates $(\\hat{K}, \\hat{n})$, we minimize the objective function $\\mathcal{L}_{\\text{MAP}}(\\theta_K, \\theta_n)$ with respect to $\\theta_K$ and $\\theta_n$.\n\nFirst, we perform a reparameterization as suggested by the prior structure:\n$$\n\\theta_K = \\log K, \\quad \\theta_n = \\log n\n$$\nThis reparameterization is advantageous for two primary reasons:\n1.  **Constraint Enforcement**: The parameters $K$ and $n$ must be positive. By optimizing over $\\theta_K, \\theta_n \\in (-\\infty, \\infty)$, the original parameters $K = e^{\\theta_K}$ and $n = e^{\\theta_n}$ are inherently constrained to the positive domain $\\mathbb{R}^+$. This transforms a constrained optimization problem into an unconstrained one.\n2.  **Numerical Stability**: The stiffness values $E$ and the parameter $K$ can span several orders of magnitude. Operations like $E^n$ are prone to numerical overflow or underflow. The Hill function can be rewritten in a more stable form using logarithms:\n    $$\n    f(E; K, n) = \\frac{E^n}{K^n + E^n} = \\frac{1}{1 + (K/E)^n} = \\frac{1}{1 + \\exp(n \\log(K/E))} = \\frac{1}{1 + \\exp(n(\\log K - \\log E))}\n    $$\n    In terms of our optimization variables $\\theta_K$ and $\\theta_n$:\n    $$\n    f(E; \\theta_K, \\theta_n) = \\frac{1}{1 + \\exp(e^{\\theta_n}(\\theta_K - \\log E))}\n    $$\n    This form is numerically robust and avoids large intermediate values.\n\nThe optimization problem is now to find $(\\hat{\\theta}_K, \\hat{\\theta}_n) = \\arg\\min_{\\theta_K, \\theta_n} \\mathcal{L}_{\\text{MAP}}(\\theta_K, \\theta_n)$. Since $\\mathcal{L}_{\\text{MAP}}$ is a continuous and differentiable (though non-linear) function, we can use a quasi-Newton method for unconstrained optimization. The Broyden–Fletcher–Goldfarb–Shanno (BFGS) algorithm is a suitable choice, as it is efficient and does not require an analytical Hessian matrix.\n\nThe algorithm is as follows:\n1.  For a given test case (data $\\{E_i, N_i\\}$, noise $\\sigma$, and prior hyperparameters $m_K, s_K, m_n, s_n$), define the objective function $\\mathcal{L}_{\\text{MAP}}(\\theta_K, \\theta_n)$ as formulated above.\n2.  Select an initial guess for the optimization, $(\\theta_{K,0}, \\theta_{n,0})$. A logical choice is the mean of the prior distribution, i.e., $(\\theta_{K,0}, \\theta_{n,0}) = (m_K, m_n)$.\n3.  Use a numerical optimization routine (e.g., `scipy.optimize.minimize` with the `BFGS` method) to find the parameters $(\\hat{\\theta}_K, \\hat{\\theta}_n)$ that minimize $\\mathcal{L}_{\\text{MAP}}$.\n4.  Transform the estimated log-parameters back to the original parameter space to obtain the final MAP estimates:\n    $$\n    \\hat{K} = \\exp(\\hat{\\theta}_K), \\quad \\hat{n} = \\exp(\\hat{\\theta}_n)\n    $$\n5.  Repeat this procedure for all test cases provided.\nThe implementation of this algorithm is provided in the final answer section.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.optimize import minimize\n\ndef solve():\n    \"\"\"\n    Solves the MAP estimation problem for all test cases.\n    \"\"\"\n    \n    test_cases = [\n        {\n            \"E\": np.array([0.5, 1.0, 2.0, 4.0, 8.0, 16.0]),\n            \"N\": np.array([0.015495, 0.010303, 0.180200, 0.490000, 0.869540, 0.939700]),\n            \"sigma\": 0.05,\n            \"priors\": (1.3862943611, 0.8, 0.6931471806, 0.5)  # (m_k, s_k, m_n, s_n)\n        },\n        {\n            \"E\": np.array([0.5, 1.0, 2.0, 5.0, 10.0, 20.0, 40.0]),\n            \"N\": np.array([0.006700, 0.109400, 0.106600, 0.363300, 0.460000, 0.706900, 0.811100]),\n            \"sigma\": 0.10,\n            \"priors\": (2.0794415417, 0.8, 0.4054651081, 0.5)\n        },\n        {\n            \"E\": np.array([0.2, 0.4, 0.8, 1.6]),\n            \"N\": np.array([0.005100, 0.000597, 0.027970, 0.280700]),\n            \"sigma\": 0.03,\n            \"priors\": (1.0986122887, 0.7, 1.0986122887, 0.7)\n        }\n    ]\n\n    results = []\n    \n    for case in test_cases:\n        E_data = case[\"E\"]\n        N_data = case[\"N\"]\n        sigma = case[\"sigma\"]\n        m_k, s_k, m_n, s_n = case[\"priors\"]\n\n        # Pre-compute log(E) for efficiency\n        log_E_data = np.log(E_data)\n\n        def neg_log_posterior(params, E_log, N_obs, sig, mk, sk, mn, sn):\n            \"\"\"\n            Calculates the negative log-posterior for the given parameters.\n            `params` is a list or array [theta_k, theta_n].\n            \"\"\"\n            theta_k, theta_n = params\n            n = np.exp(theta_n)\n\n            # 1. Numerically stable Hill function calculation (vectorized)\n            # f(E) = 1 / (1 + exp(n * (log(K) - log(E))))\n            exponent_term = n * (theta_k - E_log)\n            # Clip exponent to avoid overflow in exp, which can happen for\n            # very large n or large (theta_k - E_log).\n            exponent_term = np.clip(exponent_term, -700, 700)\n            f_model = 1.0 / (1.0 + np.exp(exponent_term))\n\n            # 2. Likelihood term (sum of squared errors)\n            likelihood_term = np.sum((N_obs - f_model)**2) / (2.0 * sig**2)\n\n            # 3. Prior terms for log K and log n\n            prior_k_term = (theta_k - mk)**2 / (2.0 * sk**2)\n            prior_n_term = (theta_n - mn)**2 / (2.0 * sn**2)\n            \n            return likelihood_term + prior_k_term + prior_n_term\n\n        # Initial guess for optimization: the prior means for (log K, log n)\n        initial_guess = [m_k, m_n]\n        \n        # Perform optimization using BFGS\n        opt_result = minimize(\n            fun=neg_log_posterior,\n            x0=initial_guess,\n            args=(log_E_data, N_data, sigma, m_k, s_k, m_n, s_n),\n            method='BFGS'\n        )\n\n        # Extract optimal log-parameters\n        theta_k_hat, theta_n_hat = opt_result.x\n        \n        # Convert back to K and n\n        k_hat = np.exp(theta_k_hat)\n        n_hat = np.exp(theta_n_hat)\n        \n        # Append rounded results to the list\n        results.append(round(k_hat, 3))\n        results.append(round(n_hat, 3))\n\n    # Format the final output as a single comma-separated string in brackets\n    output_str = f\"[{','.join(map(str, results))}]\"\n    print(output_str)\n\nsolve()\n```", "id": "2688230"}]}