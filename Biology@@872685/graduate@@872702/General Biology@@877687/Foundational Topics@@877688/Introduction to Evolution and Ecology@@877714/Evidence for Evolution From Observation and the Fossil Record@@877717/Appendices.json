{"hands_on_practices": [{"introduction": "One of the most powerful lines of evidence for evolution is the nested hierarchy of life, and its strongest confirmation comes from the congruence between phylogenies built from independent data sources, such as fossils and molecules. This practice provides a direct, quantitative method for assessing this congruence by calculating the Robinson-Foulds ($RF$) distance between two trees [@problem_id:2798010]. You will learn how to decompose trees into their fundamental components—bipartitions or 'splits'—and use them to measure topological disagreement, a foundational skill in comparative phylogenetics.", "problem": "A research team is comparing phylogenetic signal between a fossil-based morphological dataset and a molecular alignment for the same taxa to assess evidence for common descent via congruent hierarchical patterns. The team infers one unrooted, fully resolved tree from each dataset: the most parsimonious morphology tree and the maximum likelihood molecular tree. In unrooted, fully resolved trees on $n$ taxa, each internal edge induces a bipartition (split) of the taxa set, and each tree has $n-3$ such nontrivial splits. The Robinson–Foulds (RF) distance counts how many nontrivial splits are not shared between two trees, which operationalizes a measure of topological congruence based on shared hierarchical structure. The permutation test for congruence randomizes taxon labels on one tree to generate a null distribution of RF distances expected by chance if the datasets were unrelated.\n\nYou are given the following for $n=6$ taxa $\\{A,B,C,D,E,F\\}$:\n- Morphology tree topology (unrooted): Newick $=$ $((A,B),(C,D),(E,F))$.\n- Molecular tree topology (unrooted): Newick $=$ $((A,B),(C,E),(D,F))$.\n\nAssume both trees are strictly binary and are to be treated as unrooted. Under $N=20$ independent random permutations of taxon labels on the molecular tree (with the morphology tree held fixed), the observed Robinson–Foulds distances are:\n$\\{6,6,6,4,6,6,6,6,6,6,6,6,4,6,6,6,6,6,6,6\\}$.\n\nUsing these data:\n1) Compute the observed Robinson-Foulds distance between the morphology and molecular trees by comparing their sets of nontrivial splits.\n2) Using the permutation results, compute the one-sided permutation $p$-value for excess congruence defined as the fraction of permuted RF distances less than or equal to the observed RF distance.\n\nReport the $p$-value as your final answer. Round your answer to four significant figures and express it as a decimal (no percent sign).", "solution": "The problem as stated is scientifically grounded, well-posed, and objective. It presents a standard task in computational phylogenetics: assessing the congruence between two evolutionary trees using the Robinson-Foulds distance and a permutation test. All terminology is standard, and all necessary data for a unique solution are provided. The problem is therefore valid, and we may proceed with the analysis.\n\nThe problem requires two main steps: first, to compute the observed Robinson-Foulds ($RF$) distance between the two specified trees, and second, to calculate the permutation $p$-value for this observed distance using the provided null distribution.\n\nStep 1: Compute the observed Robinson-Foulds distance.\n\nAn unrooted, fully resolved (binary) tree with $n$ taxa possesses $n-3$ internal edges. Each internal edge defines a nontrivial bipartition, or split, of the taxa set. The Robinson-Foulds distance between two trees is the number of nontrivial splits that are present in one tree but not the other. This is equivalent to the size of the symmetric difference of their respective sets of splits.\n\nFor the given problem, the number of taxa is $n=6$. Thus, each tree will have $n-3 = 6-3 = 3$ nontrivial splits.\n\nLet $S_{morph}$ be the set of nontrivial splits for the morphology tree, and $S_{mol}$ be the set for the molecular tree. The taxa are $\\{A,B,C,D,E,F\\}$.\n\nFirst, we identify the splits for the morphology tree, given by the Newick string $((A,B),(C,D),(E,F))$. This topology groups the taxa into three pairs. The three internal edges separate each pair from the rest.\nThe splits are:\n1. The edge separating the clade $(A,B)$ from the rest. This bipartition is $\\{A, B\\} | \\{C, D, E, F\\}$.\n2. The edge separating the clade $(C,D)$ from the rest. This bipartition is $\\{C, D\\} | \\{A, B, E, F\\}$.\n3. The edge separating the clade $(E,F)$ from the rest. This bipartition is $\\{E, F\\} | \\{A, B, C, D\\}$.\n\nSo, the set of splits for the morphology tree is:\n$$S_{morph} = \\{ \\{A, B\\} | \\{C, D, E, F\\}, \\quad \\{C, D\\} | \\{A, B, E, F\\}, \\quad \\{E, F\\} | \\{A, B, C, D\\} \\}$$\n\nNext, we identify the splits for the molecular tree, given by the Newick string $((A,B),(C,E),(D,F))$. This topology also groups taxa into pairs, but differently.\nThe splits are:\n1. The edge separating the clade $(A,B)$ from the rest. This bipartition is $\\{A, B\\} | \\{C, D, E, F\\}$.\n2. The edge separating the clade $(C,E)$ from the rest. This bipartition is $\\{C, E\\} | \\{A, B, D, F\\}$.\n3. The edge separating the clade $(D,F)$ from the rest. This bipartition is $\\{D, F\\} | \\{A, B, C, E\\}$.\n\nSo, the set of splits for the molecular tree is:\n$$S_{mol} = \\{ \\{A, B\\} | \\{C, D, E, F\\}, \\quad \\{C, E\\} | \\{A, B, D, F\\}, \\quad \\{D, F\\} | \\{A, B, C, E\\} \\}$$\n\nNow, we compute the Robinson-Foulds distance, $RF_{obs}$. The $RF$ distance is given by the formula:\n$$RF(T_1, T_2) = |S_1| + |S_2| - 2|S_1 \\cap S_2|$$\nWe must find the intersection of the two split sets, $S_{morph} \\cap S_{mol}$. By comparing the elements of $S_{morph}$ and $S_{mol}$, we find only one split in common:\n$$S_{morph} \\cap S_{mol} = \\{ \\{A, B\\} | \\{C, D, E, F\\} \\}$$\nThe number of shared splits is $|S_{morph} \\cap S_{mol}| = 1$.\nThe number of splits in each tree is $|S_{morph}| = |S_{mol}| = 3$.\nSubstituting these values into the formula for the RF distance:\n$$RF_{obs} = 3 + 3 - 2(1) = 4$$\nThe observed Robinson-Foulds distance between the morphology and molecular trees is $4$.\n\nStep 2: Compute the one-sided permutation $p$-value.\n\nThe problem defines the $p$-value for excess congruence as the fraction of permuted $RF$ distances that are less than or equal to the observed $RF$ distance. \"Excess congruence\" corresponds to an unusually low $RF$ distance, as $RF$ is a measure of dissimilarity.\n\nThe observed distance is $RF_{obs} = 4$.\nThe set of $N=20$ permuted $RF$ distances is given as:\n$$\\{6, 6, 6, 4, 6, 6, 6, 6, 6, 6, 6, 6, 4, 6, 6, 6, 6, 6, 6, 6\\}$$\nWe must count the number of values in this set that are less than or equal to $4$. Let this count be $k$.\nBy inspecting the set, we find two values equal to $4$ and no values less than $4$.\nTherefore, $k=2$.\n\nThe total number of permutations is $N=20$.\nThe $p$-value is the fraction $\\frac{k}{N}$.\n$$p = \\frac{2}{20} = \\frac{1}{10} = 0.1$$\nThe problem requires the answer to be rounded to four significant figures.\n$$p = 0.1000$$\nThis is the final calculated $p$-value.", "answer": "$$\\boxed{0.1000}$$", "id": "2798010"}, {"introduction": "While phylogenetic patterns provide a snapshot of evolutionary history, the fossil record itself is the product of complex processes of preservation and discovery that unfold over millions of years. A central challenge in paleobiology is to disentangle the true biological signal from the pervasive filter of sampling incompleteness. This exercise guides you through a core technique to address this challenge: using maximum likelihood estimation to separately quantify the preservation rate and the sampling opportunity rate from a time series of fossil finds [@problem_id:2798052]. Mastering this approach allows for a more nuanced interpretation of the fossil record's tempo and mode.", "problem": "A single taxon is inferred from independent phylogenetic and stratigraphic evidence to have existed continuously from time origin at $t=0$ to extinction at $t=T$, with $T=10$ million years (Myr). Within this known existence interval, $n=8$ fossil occurrences are observed at the following absolute times (in Myr since origination): $t=\\{0.3,\\,1.1,\\,1.6,\\,3.2,\\,3.3,\\,5.0,\\,6.7,\\,8.9\\}$. Assume a homogeneous preservation–sampling regime such that observed fossil occurrences over $[0,T]$ follow a homogeneous Poisson process with net observed rate $\\lambda$ (in occurrences per Myr). Further assume that the net observed rate is the product of an unknown preservation yield per sampling opportunity $\\mu$ (in expected occurrences per sampling opportunity) and an unknown sampling opportunity rate $\\nu$ (in sampling opportunities per Myr), so that $\\lambda=\\mu\\,\\nu$.\n\nTo allow separate identification of $\\mu$ and $\\nu$, you are also given an independently compiled time series of the counts of sampling opportunities $L_i$ in a partition of $[0,T]$ into four non-overlapping subintervals with durations $\\Delta t_i$:\n- Interval $1$: $[0,2]$ Myr, $\\Delta t_1=2$ Myr, $L_1=8$.\n- Interval $2$: $(2,5]$ Myr, $\\Delta t_2=3$ Myr, $L_2=16$.\n- Interval $3$: $(5,7]$ Myr, $\\Delta t_3=2$ Myr, $L_3=10$.\n- Interval $4$: $(7,10]$ Myr, $\\Delta t_4=3$ Myr, $L_4=16$.\n\nAssume the sampling opportunities arise as a homogeneous Poisson process of rate $\\nu$, so that $L_i$ are independent Poisson random variables with means $\\nu\\,\\Delta t_i$, independent of the preservation process. Under the gap-analysis modeling framework (homogeneous Poisson occurrences on a fixed, known duration $T$), derive the joint maximum likelihood estimators (MLEs) for $\\mu$ and $\\nu$, and then compute their numerical values for the data above. Round both estimates to three significant figures. Express $\\mu$ in occurrences per sampling opportunity and $\\nu$ in sampling opportunities per Myr. Report your final answer as a row vector $\\big(\\hat{\\mu}\\ \\hat{\\nu}\\big)$.", "solution": "The problem as stated is scientifically grounded, well-posed, objective, and contains sufficient information for a unique solution. It is a standard problem in statistical inference applied to paleontological data. We may proceed with the solution.\n\nThe problem requires the derivation of the joint maximum likelihood estimators (MLEs) for the preservation yield per sampling opportunity, $\\mu$, and the sampling opportunity rate, $\\nu$. The total set of observations comprises two independent components: first, the count and timing of fossil occurrences, and second, the counts of sampling opportunities in partitioned time intervals. The total likelihood function $\\mathcal{L}(\\mu, \\nu)$ is therefore the product of the likelihoods associated with these two independent data sets.\nLet $\\mathcal{L}_1$ be the likelihood function for the fossil occurrence data and $\\mathcal{L}_2$ be the likelihood function for the sampling opportunity data. The total likelihood is $\\mathcal{L}(\\mu, \\nu) = \\mathcal{L}_1(\\mu, \\nu) \\times \\mathcal{L}_2(\\nu)$.\n\nFirst, we construct $\\mathcal{L}_1(\\mu, \\nu)$. The fossil occurrences are modeled as a homogeneous Poisson process with a net observed rate $\\lambda = \\mu \\nu$ over a known time interval $[0, T]$. For a homogeneous Poisson process, the likelihood of observing $n$ events in an interval of duration $T$ is given by the probability density function of the process, which is $\\lambda^n \\exp(-\\lambda T)$. The specific timings of the events do not add information about the rate $\\lambda$ for a homogeneous process, beyond their total count $n$.\nSubstituting $\\lambda = \\mu \\nu$, the likelihood for the fossil data is:\n$$ \\mathcal{L}_1(\\mu, \\nu) = (\\mu \\nu)^n \\exp(-\\mu \\nu T) $$\nGiven the data, $n=8$ and $T=10$ Myr, this becomes:\n$$ \\mathcal{L}_1(\\mu, \\nu) = (\\mu \\nu)^8 \\exp(-10 \\mu \\nu) $$\n\nSecond, we construct $\\mathcal{L}_2(\\nu)$. The sampling opportunities are modeled as a homogeneous Poisson process with rate $\\nu$. We observe the counts $L_i$ in four independent, non-overlapping intervals of durations $\\Delta t_i$. The number of opportunities $L_i$ in interval $i$ is a Poisson random variable with mean $\\nu \\Delta t_i$. The likelihood of observing the set $\\{L_1, L_2, L_3, L_4\\}$ is the product of the individual Poisson probabilities, due to their independence:\n$$ \\mathcal{L}_2(\\nu) = \\prod_{i=1}^{4} P(L_i | \\nu, \\Delta t_i) = \\prod_{i=1}^{4} \\frac{(\\nu \\Delta t_i)^{L_i} \\exp(-\\nu \\Delta t_i)}{L_i!} $$\nThis can be written as:\n$$ \\mathcal{L}_2(\\nu) = \\left( \\prod_{i=1}^{4} \\frac{(\\Delta t_i)^{L_i}}{L_i!} \\right) \\nu^{\\sum L_i} \\exp\\left(-\\nu \\sum \\Delta t_i\\right) $$\nThe term in the parenthesis is a constant with respect to the parameter $\\nu$.\n\nThe joint likelihood $\\mathcal{L}(\\mu, \\nu)$ is the product of $\\mathcal{L}_1$ and $\\mathcal{L}_2$. It is more convenient to work with the natural logarithm of the likelihood, the log-likelihood function $\\ell(\\mu, \\nu) = \\ln(\\mathcal{L}(\\mu, \\nu))$.\n$$ \\ell(\\mu, \\nu) = \\ln(\\mathcal{L}_1(\\mu, \\nu)) + \\ln(\\mathcal{L}_2(\\nu)) $$\n$$ \\ell(\\mu, \\nu) = [n \\ln(\\mu \\nu) - \\mu \\nu T] + \\left[ \\sum_{i=1}^{4} L_i \\ln(\\nu) + \\sum_{i=1}^{4} (L_i \\ln(\\Delta t_i) - \\ln(L_i!)) - \\nu \\sum_{i=1}^{4} \\Delta t_i \\right] $$\nWe can group the terms containing $\\mu$ and $\\nu$ and drop the constant terms that do not depend on these parameters, as they do not affect the maximization. Let $L_{tot} = \\sum_{i=1}^4 L_i$ and $\\Delta t_{tot} = \\sum_{i=1}^4 \\Delta t_i$.\n$$ \\ell(\\mu, \\nu) = n \\ln(\\mu) + n \\ln(\\nu) - \\mu \\nu T + L_{tot} \\ln(\\nu) - \\nu \\Delta t_{tot} + C $$\nwhere $C$ is a constant. This simplifies to:\n$$ \\ell(\\mu, \\nu) = n \\ln(\\mu) + (n + L_{tot}) \\ln(\\nu) - \\mu \\nu T - \\nu \\Delta t_{tot} + C $$\n\nTo find the MLEs $(\\hat{\\mu}, \\hat{\\nu})$, we take the partial derivatives of $\\ell(\\mu, \\nu)$ with respect to $\\mu$ and $\\nu$ and set them to zero.\n\nPartial derivative with respect to $\\mu$:\n$$ \\frac{\\partial \\ell}{\\partial \\mu} = \\frac{n}{\\mu} - \\nu T = 0 $$\n$$ \\implies \\frac{n}{\\hat{\\mu}} = \\hat{\\nu} T \\implies \\hat{\\mu}\\hat{\\nu} = \\frac{n}{T} $$\nThis result indicates that the MLE for the overall rate $\\lambda$ is $\\hat{\\lambda} = n/T$, which is the standard MLE for a Poisson rate.\n\nPartial derivative with respect to $\\nu$:\n$$ \\frac{\\partial \\ell}{\\partial \\nu} = \\frac{n + L_{tot}}{\\nu} - \\mu T - \\Delta t_{tot} = 0 $$\n$$ \\implies \\frac{n + L_{tot}}{\\hat{\\nu}} = \\hat{\\mu} T + \\Delta t_{tot} $$\n\nWe now have a system of two equations for the estimators $\\hat{\\mu}$ and $\\hat{\\nu}$:\n1.  $\\hat{\\mu} T = \\frac{n}{\\hat{\\nu}}$\n2.  $\\frac{n + L_{tot}}{\\hat{\\nu}} = \\hat{\\mu} T + \\Delta t_{tot}$\n\nSubstitute the first equation into the second:\n$$ \\frac{n + L_{tot}}{\\hat{\\nu}} = \\frac{n}{\\hat{\\nu}} + \\Delta t_{tot} $$\n$$ \\frac{L_{tot}}{\\hat{\\nu}} = \\Delta t_{tot} $$\nThis yields the estimator for $\\nu$:\n$$ \\hat{\\nu} = \\frac{L_{tot}}{\\Delta t_{tot}} = \\frac{\\sum_{i=1}^{4} L_i}{\\sum_{i=1}^{4} \\Delta t_i} $$\nThis is the total number of sampling opportunities divided by the total duration, which is the MLE for the rate $\\nu$ of the sampling opportunity process.\n\nNow, we solve for $\\hat{\\mu}$ using the first equation: $\\hat{\\mu} = \\frac{n}{T \\hat{\\nu}}$.\nSubstitute the expression for $\\hat{\\nu}$:\n$$ \\hat{\\mu} = \\frac{n}{T \\left(\\frac{\\sum L_i}{\\sum \\Delta t_i}\\right)} $$\nThe problem is set up such that the total duration of the subintervals for sampling opportunity counts equals the total duration of the taxon's existence: $T = \\sum_{i=1}^{4} \\Delta t_i$. Therefore, the expression simplifies to:\n$$ \\hat{\\mu} = \\frac{n}{\\sum_{i=1}^{4} L_i} $$\nThis estimator for $\\mu$ is the total number of observed fossils divided by the total number of observed sampling opportunities.\n\nNow we compute the numerical values.\nThe givens are:\n- $n = 8$\n- $T = 10$ Myr\n- Subinterval data:\n  - $L_1=8, \\Delta t_1 = 2$ Myr\n  - $L_2=16, \\Delta t_2 = 3$ Myr\n  - $L_3=10, \\Delta t_3 = 2$ Myr\n  - $L_4=16, \\Delta t_4 = 3$ Myr\n\nFirst, we compute the total counts and durations:\n$$ \\sum_{i=1}^{4} L_i = 8 + 16 + 10 + 16 = 50 $$\n$$ \\sum_{i=1}^{4} \\Delta t_i = 2 + 3 + 2 + 3 = 10 \\text{ Myr} $$\nAs expected, $\\sum \\Delta t_i = T$.\n\nNow, we compute the estimates for $\\hat{\\nu}$ and $\\hat{\\mu}$:\n$$ \\hat{\\nu} = \\frac{\\sum L_i}{\\sum \\Delta t_i} = \\frac{50}{10} = 5 $$\nThe units are sampling opportunities per Myr.\n\n$$ \\hat{\\mu} = \\frac{n}{\\sum L_i} = \\frac{8}{50} = \\frac{4}{25} = 0.16 $$\nThe units are occurrences per sampling opportunity.\n\nThe problem requires rounding to three significant figures.\n$\\hat{\\nu} = 5.00$ sampling opportunities per Myr.\n$\\hat{\\mu} = 0.160$ occurrences per sampling opportunity.\n\nThe final answer is reported as a row vector $(\\hat{\\mu}\\ \\hat{\\nu})$.", "answer": "$$\\boxed{\\begin{pmatrix} 0.160 & 5.00 \\end{pmatrix}}$$", "id": "2798052"}, {"introduction": "Having explored methods to infer patterns and estimate underlying rates, we now ascend to the level of dynamic systems modeling, where we test hypotheses about the macroevolutionary engine itself. This advanced practice challenges you to implement a full birth–death–sampling model, the theoretical foundation for studying diversity through time, and to use it for a posterior predictive check [@problem_id:2798020]. This powerful technique moves beyond simply fitting a model to data; it asks whether your fitted model is even capable of generating the kind of patterns you observe, providing a rigorous test of your underlying evolutionary hypothesis.", "problem": "You are given a macroevolutionary birth–death–sampling model for diversity through time. The core biological assumptions are that per-lineage origination (speciation) and extinction events are well approximated by memoryless processes with constant instantaneous rates within a time bin, and that fossil discovery is a Bernoulli sampling process on true lineages. Formally, at time bin index $t$ with bin width $\\Delta t$, if the true number of extant lineages is $N_t$, then origination events occur with an expected count proportional to $N_t$ and extinction removes a subset of lineages, while fossil observation within the bin samples lineages independently. You will implement a posterior predictive check to evaluate whether the observed diversity volatility can be generated under estimated parameters.\n\nFundamentals and Definitions:\n- Let $\\lambda$ denote the origination rate per lineage per unit time, $\\mu$ denote the extinction rate per lineage per unit time, and $\\psi$ denote the fossil sampling rate per lineage per unit time. These are nonnegative real numbers.\n- Over a small bin of width $\\Delta t$, assume births (originations) are distributed as a Poisson random variable with mean $\\lambda \\, \\Delta t \\, N_t$, and deaths (extinctions) occur independently for each of the $N_t$ lineages with probability $1 - e^{-\\mu \\, \\Delta t}$. The resulting update is $N_{t+1} = \\max\\{0,\\, N_t + B_t - D_t\\}$, where $B_t \\sim \\mathrm{Poisson}(\\lambda \\, \\Delta t \\, N_t)$ and $D_t \\sim \\mathrm{Binomial}(N_t, 1 - e^{-\\mu \\, \\Delta t})$.\n- Observed fossil diversity in bin $t$, denoted $O_t$, is generated by sampling the true diversity with per-lineage sampling probability $q = 1 - e^{-\\psi \\, \\Delta t}$ via $O_t \\sim \\mathrm{Binomial}(N_t, q)$, independently across lineages conditional on $N_t$.\n- Define the volatility statistic on a length-$T$ observed series $\\{O_1,\\ldots, O_T\\}$ as\n$$\nV(O) \\equiv \\frac{\\mathrm{Var}\\big(\\Delta O_t\\big)}{\\overline{O}}, \\quad \\text{where } \\Delta O_t \\equiv O_{t+1} - O_t \\text{ for } t=1,\\ldots, T-1,\n$$\nwith the sample variance computed with denominator $T-2$ (that is, the unbiased estimator), and $\\overline{O}$ the sample mean of $\\{O_t\\}_{t=1}^T$. If $\\overline{O} = 0$, set $V(O) = 0$ by definition.\n- A posterior predictive check evaluates whether the observed statistic $V_{\\mathrm{obs}}$ can be generated under the posterior distribution of $(\\lambda, \\mu, \\psi)$. Given $M$ draws $\\{(\\lambda^{(m)},\\mu^{(m)},\\psi^{(m)})\\}_{m=1}^M$ from an approximate posterior, generate replicated datasets $O^{(m)}$ under the model and compute $V^{(m)} = V(O^{(m)})$. The posterior predictive $p$-value is approximated by\n$$\np_{\\mathrm{ppc}} \\approx \\frac{1}{M} \\sum_{m=1}^M \\mathbf{1}\\big\\{ V^{(m)} \\ge V_{\\mathrm{obs}} \\big\\}.\n$$\nThis $p_{\\mathrm{ppc}}$ is a unitless probability interpreted as the proportion of posterior-replicated volatilities at least as large as the observed volatility.\n\nYour task is to implement a program that, for each test case below, performs the following steps:\n- Compute $V_{\\mathrm{obs}}$ for the provided observed series.\n- Draw $M$ independent parameter triples $(\\lambda^{(m)}, \\mu^{(m)}, \\psi^{(m)})$ from independent Normal distributions truncated to the nonnegative reals, each with the given mean and standard deviation for that test case. Truncation is at $0$ from below only.\n- For each draw, simulate a true diversity trajectory of length $T$ bins using the birth–death process with bin width $\\Delta t$ and initial true diversity $N_0$, then generate an observed series by per-bin binomial sampling with rate $\\psi^{(m)}$ as defined above. Compute $V^{(m)}$ for each replicated series.\n- Compute the posterior predictive $p$-value $p_{\\mathrm{ppc}}$ as the fraction of $V^{(m)}$ values greater than or equal to $V_{\\mathrm{obs}}$.\n- Report the $p_{\\mathrm{ppc}}$ for each test case as a decimal rounded to four digits after the decimal point.\n\nImportant implementation details:\n- All time is in millions of years. Use $\\Delta t$ as specified for each test case in units of million years. There is no unit in the final $p_{\\mathrm{ppc}}$ since it is a probability.\n- Use unbiased sample variance for $\\mathrm{Var}(\\Delta O_t)$, that is, divide by $T-2$.\n- If at any point $N_t = 0$, it remains at $0$ thereafter.\n- Sampling from truncated Normals should be implemented by rejection sampling from the corresponding untruncated Normal distribution until all samples are nonnegative.\n\nTest suite (three test cases):\n- Test case $1$ (general case):\n  - Number of bins $T = 20$, bin width $\\Delta t = 1$, initial true diversity $N_0 = 60$.\n  - Observed diversity time series $O_{\\mathrm{obs}} =$ [$29$, $30$, $31$, $32$, $34$, $35$, $36$, $37$, $38$, $39$, $39$, $40$, $41$, $42$, $43$, $44$, $45$, $46$, $47$, $48$].\n  - Posterior approximation parameters: $\\lambda \\sim \\mathcal{N}(\\text{mean } 0.12, \\text{ sd } 0.02)$ truncated at $0$; $\\mu \\sim \\mathcal{N}(\\text{mean } 0.08, \\text{ sd } 0.02)$ truncated at $0$; $\\psi \\sim \\mathcal{N}(\\text{mean } 0.50, \\text{ sd } 0.10)$ truncated at $0$.\n  - Number of posterior draws $M = 1000$, random seed $321$.\n- Test case $2$ (high observed volatility edge case):\n  - Number of bins $T = 20$, bin width $\\Delta t = 1$, initial true diversity $N_0 = 40$.\n  - Observed diversity time series $O_{\\mathrm{obs}} =$ [$15$, $30$, $12$, $28$, $10$, $26$, $9$, $24$, $8$, $22$, $7$, $20$, $6$, $18$, $5$, $17$, $4$, $16$, $3$, $15$].\n  - Posterior approximation parameters: $\\lambda \\sim \\mathcal{N}(\\text{mean } 0.06, \\text{ sd } 0.015)$ truncated at $0$; $\\mu \\sim \\mathcal{N}(\\text{mean } 0.055, \\text{ sd } 0.015)$ truncated at $0$; $\\psi \\sim \\mathcal{N}(\\text{mean } 0.30, \\text{ sd } 0.08)$ truncated at $0$.\n  - Number of posterior draws $M = 1000$, random seed $654$.\n- Test case $3$ (declining diversity with higher extinction):\n  - Number of bins $T = 20$, bin width $\\Delta t = 1$, initial true diversity $N_0 = 120$.\n  - Observed diversity time series $O_{\\mathrm{obs}} =$ [$55$, $50$, $46$, $43$, $40$, $38$, $36$, $34$, $32$, $30$, $28$, $26$, $24$, $22$, $20$, $18$, $17$, $16$, $15$, $14$].\n  - Posterior approximation parameters: $\\lambda \\sim \\mathcal{N}(\\text{mean } 0.08, \\text{ sd } 0.02)$ truncated at $0$; $\\mu \\sim \\mathcal{N}(\\text{mean } 0.12, \\text{ sd } 0.02)$ truncated at $0$; $\\psi \\sim \\mathcal{N}(\\text{mean } 0.60, \\text{ sd } 0.10)$ truncated at $0$.\n  - Number of posterior draws $M = 1000$, random seed $987$.\n\nFinal output format:\n- Your program should produce a single line of output containing the three posterior predictive $p$-values for the test cases, each rounded to four digits after the decimal point, as a comma-separated list enclosed in square brackets, for example, [$0.1234$, $0.5678$, $0.9012$].", "solution": "The problem presents a valid and well-posed task in computational paleobiology. It is scientifically grounded in the theory of birth-death processes, which are standard models for macroevolutionary dynamics. The problem is self-contained, with all necessary parameters, data, and procedural definitions provided. The requested task is to implement a posterior predictive check, a standard Bayesian statistical method, to assess the fit of a stochastic model to observed time series data. No logical contradictions, factual errors, or ambiguities are present. The problem is a formal exercise in simulation and statistical inference. I will proceed with a solution.\n\nThe objective is to compute a posterior predictive $p$-value, $p_{\\mathrm{ppc}}$, for a volatility statistic derived from an observed fossil diversity time series. This requires simulating replicated time series from a birth-death-sampling model using parameters drawn from an approximate posterior distribution and comparing the statistic computed on the replicated data to that from the observed data.\n\nFirst, let us formalize the volatility statistic, $V(O)$. For a given time series of observed diversity $O = \\{O_1, O_2, \\dots, O_T\\}$ of length $T$, the statistic is defined as:\n$$\nV(O) = \\frac{\\mathrm{Var}(\\Delta O_t)}{\\overline{O}}\n$$\nHere, $\\overline{O}$ is the sample mean of the series $O$:\n$$\n\\overline{O} = \\frac{1}{T} \\sum_{t=1}^{T} O_t\n$$\nThe term $\\Delta O_t$ represents the first differences of the series, $\\Delta O_t = O_{t+1} - O_t$, for $t=1, \\dots, T-1$. There are $T-1$ such differences. $\\mathrm{Var}(\\Delta O_t)$ is the unbiased sample variance of these differences. For a sample of size $n$, the unbiased sample variance uses a denominator of $n-1$. Since there are $T-1$ differences, the denominator is $(T-1)-1 = T-2$. The formula is:\n$$\n\\mathrm{Var}(\\Delta O_t) = \\frac{1}{T-2} \\sum_{t=1}^{T-1} (\\Delta O_t - \\overline{\\Delta O})^2\n$$\nwhere $\\overline{\\Delta O}$ is the mean of the differences. By definition, if $\\overline{O}=0$, then $V(O)$ is set to $0$.\n\nThe core of the task is to simulate replicated observed diversity series, $O^{(m)}$, for each of the $M$ draws from the posterior distribution of the model parameters $(\\lambda, \\mu, \\psi)$. The simulation for a single replicate proceeds in two stages:\n\n1.  **Simulation of the true diversity trajectory:**\n    We are given the initial true diversity $N_0$. The trajectory of true diversity $N_t$ is simulated over $T$ time bins, each of width $\\Delta t$. The true diversity at the start of the next time bin, $N_{t+1}$, is derived from the diversity at the start of the current bin, $N_t$, via the stochastic process:\n    $$\n    N_{t+1} = \\max\\{0, N_t + B_t - D_t\\} \\quad \\text{for } t = 0, 1, \\dots, T-1\n    $$\n    where $B_t$ is the number of new lineages (births) and $D_t$ is the number of extinct lineages (deaths). The number of births $B_t$ is drawn from a Poisson distribution with mean dependent on the origination rate $\\lambda$ and current diversity $N_t$:\n    $$\n    B_t \\sim \\mathrm{Poisson}(\\lambda \\Delta t N_t)\n    $$\n    The number of deaths $D_t$ is drawn from a Binomial distribution. Each of the $N_t$ lineages faces an independent probability of extinction, $p_{\\mathrm{ext}} = 1 - e^{-\\mu \\Delta t}$, derived from the constant-rate extinction process over the interval $\\Delta t$:\n    $$\n    D_t \\sim \\mathrm{Binomial}(N_t, p_{\\mathrm{ext}})\n    $$\n    This iterative process, starting from $N_0$, generates the true diversity trajectory $\\{N_1, N_2, \\dots, N_T\\}$. If $N_t$ ever becomes $0$, it remains $0$ for all subsequent times.\n\n2.  **Simulation of the observed diversity trajectory:**\n    The observed diversity in bin $t$, $O_t$, is obtained by sampling the true diversity $N_t$. Each of the $N_t$ lineages has an independent probability of being sampled as a fossil, $q = 1 - e^{-\\psi \\Delta t}$. The number of observed lineages $O_t$ is thus a random variable drawn from a Binomial distribution:\n    $$\n    O_t \\sim \\mathrm{Binomial}(N_t, q) \\quad \\text{for } t = 1, 2, \\dots, T\n    $$\n    This generates a single replicated observed series $O^{(m)} = \\{O_1^{(m)}, \\dots, O_T^{(m)}\\}$.\n\nThe overall algorithm for each test case is as follows:\n1.  Compute the observed volatility statistic, $V_{\\mathrm{obs}}$, from the provided series $O_{\\mathrm{obs}}$.\n2.  Set the specified random number generator seed for reproducibility.\n3.  Draw $M$ independent samples of each parameter $(\\lambda, \\mu, \\psi)$ from their respective truncated Normal distributions using rejection sampling. This creates $M$ parameter sets $(\\lambda^{(m)}, \\mu^{(m)}, \\psi^{(m)})$.\n4.  For each parameter set $m=1, \\dots, M$:\n    a.  Simulate a true diversity trajectory $\\{N_1^{(m)}, \\dots, N_T^{(m)}\\}$ using the process described above, with initial condition $N_0$ and parameters $(\\lambda^{(m)}, \\mu^{(m)})$.\n    b.  From this true trajectory, simulate an observed diversity trajectory $O^{(m)}$ using the sampling parameter $\\psi^{(m)}$.\n    c.  Compute the volatility statistic $V^{(m)} = V(O^{(m)})$ for this replicated series.\n5.  After all $M$ simulations, the posterior predictive $p$-value is calculated as the proportion of replicated volatilities that are greater than or equal to the observed volatility:\n    $$\n    p_{\\mathrm{ppc}} = \\frac{1}{M} \\sum_{m=1}^{M} \\mathbf{1}\\{V^{(m)} \\ge V_{\\mathrm{obs}}\\}\n    $$\n    where $\\mathbf{1}\\{\\cdot\\}$ is the indicator function.\n6.  The final result for each test case is this $p_{\\mathrm{ppc}}$ value, rounded to four decimal places.\n\nThe implementation will utilize the `numpy` library for numerical operations and random number generation, adhering to the specified environment.", "answer": "```python\nimport numpy as np\n\ndef calculate_volatility(O_series: np.ndarray) -> float:\n    \"\"\"\n    Computes the volatility statistic for a given time series.\n    V(O) = Var(Delta O) / mean(O)\n    \"\"\"\n    if not isinstance(O_series, np.ndarray):\n        O_series = np.array(O_series, dtype=float)\n    \n    T = len(O_series)\n    if T < 3: # Variance of differences requires at least 3 points in original series\n        return 0.0\n\n    mean_O = np.mean(O_series)\n    if mean_O == 0.0:\n        return 0.0\n\n    delta_O = np.diff(O_series)\n    \n    # Unbiased sample variance with denominator (T-1)-1 = T-2\n    # np.var with ddof=1 on a sample of size n uses denominator n-1.\n    # Here, len(delta_O) = T-1, so denominator is (T-1)-1 = T-2.\n    var_delta_O = np.var(delta_O, ddof=1)\n    \n    return var_delta_O / mean_O\n\ndef sample_truncated_normal(mean: float, std: float, size: int, rng: np.random.Generator) -> np.ndarray:\n    \"\"\"\n    Samples from a Normal distribution truncated at 0 from below.\n    Uses rejection sampling.\n    \"\"\"\n    samples = rng.normal(mean, std, size)\n    while np.any(samples < 0):\n        neg_mask = samples < 0\n        num_neg = np.sum(neg_mask)\n        samples[neg_mask] = rng.normal(mean, std, num_neg)\n    return samples\n\ndef solve():\n    \"\"\"\n    Main function to run all test cases and compute posterior predictive p-values.\n    \"\"\"\n    test_cases = [\n        {\n            \"name\": \"general case\",\n            \"T\": 20, \"dt\": 1.0, \"N0\": 60,\n            \"O_obs\": np.array([29, 30, 31, 32, 34, 35, 36, 37, 38, 39, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48]),\n            \"lambda_mean\": 0.12, \"lambda_sd\": 0.02,\n            \"mu_mean\": 0.08, \"mu_sd\": 0.02,\n            \"psi_mean\": 0.50, \"psi_sd\": 0.10,\n            \"M\": 1000, \"seed\": 321\n        },\n        {\n            \"name\": \"high observed volatility edge case\",\n            \"T\": 20, \"dt\": 1.0, \"N0\": 40,\n            \"O_obs\": np.array([15, 30, 12, 28, 10, 26, 9, 24, 8, 22, 7, 20, 6, 18, 5, 17, 4, 16, 3, 15]),\n            \"lambda_mean\": 0.06, \"lambda_sd\": 0.015,\n            \"mu_mean\": 0.055, \"mu_sd\": 0.015,\n            \"psi_mean\": 0.30, \"psi_sd\": 0.08,\n            \"M\": 1000, \"seed\": 654\n        },\n        {\n            \"name\": \"declining diversity with higher extinction\",\n            \"T\": 20, \"dt\": 1.0, \"N0\": 120,\n            \"O_obs\": np.array([55, 50, 46, 43, 40, 38, 36, 34, 32, 30, 28, 26, 24, 22, 20, 18, 17, 16, 15, 14]),\n            \"lambda_mean\": 0.08, \"lambda_sd\": 0.02,\n            \"mu_mean\": 0.12, \"mu_sd\": 0.02,\n            \"psi_mean\": 0.60, \"psi_sd\": 0.10,\n            \"M\": 1000, \"seed\": 987\n        }\n    ]\n\n    results = []\n    \n    for case in test_cases:\n        T, dt, N0 = case[\"T\"], case[\"dt\"], case[\"N0\"]\n        O_obs = case[\"O_obs\"]\n        M, seed = case[\"M\"], case[\"seed\"]\n        \n        rng = np.random.default_rng(seed)\n\n        V_obs = calculate_volatility(O_obs)\n\n        lambda_samples = sample_truncated_normal(case[\"lambda_mean\"], case[\"lambda_sd\"], M, rng)\n        mu_samples = sample_truncated_normal(case[\"mu_mean\"], case[\"mu_sd\"], M, rng)\n        psi_samples = sample_truncated_normal(case[\"psi_mean\"], case[\"psi_sd\"], M, rng)\n        \n        V_replicated = np.zeros(M)\n\n        for m in range(M):\n            lam, mu, psi = lambda_samples[m], mu_samples[m], psi_samples[m]\n            \n            # Simulate true diversity trajectory\n            N_traj = np.zeros(T + 1, dtype=int)\n            N_traj[0] = N0\n            \n            for t in range(T):\n                N_t = N_traj[t]\n                if N_t > 0:\n                    p_ext = 1.0 - np.exp(-mu * dt)\n                    births = rng.poisson(lam * dt * N_t)\n                    deaths = rng.binomial(N_t, p_ext)\n                    N_traj[t+1] = max(0, N_t + births - deaths)\n                else:\n                    N_traj[t+1] = 0\n            \n            # Simulate observed diversity trajectory from true trajectory\n            N_to_sample_from = N_traj[1:] # We need N_1, ..., N_T\n            \n            q_samp = 1.0 - np.exp(-psi * dt)\n            O_rep = rng.binomial(N_to_sample_from, q_samp)\n            \n            V_replicated[m] = calculate_volatility(O_rep)\n\n        p_ppc = np.sum(V_replicated >= V_obs) / M\n        results.append(f\"{p_ppc:.4f}\")\n\n    print(f\"[{','.join(results)}]\")\n\nif __name__ == \"__main__\":\n    solve()\n```", "id": "2798020"}]}