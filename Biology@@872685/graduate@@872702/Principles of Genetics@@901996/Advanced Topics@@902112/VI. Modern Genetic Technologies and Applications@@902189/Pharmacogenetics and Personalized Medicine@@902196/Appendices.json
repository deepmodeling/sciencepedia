{"hands_on_practices": [{"introduction": "A cornerstone of clinical pharmacogenetics is the ability to translate complex genetic data into a clear, functional prediction. This first exercise provides hands-on practice with this critical step by using the standardized activity score system for the highly variable drug-metabolizing enzyme, CYP2D6. Mastering this calculation [@problem_id:2836780] is essential for interpreting modern pharmacogenomic reports that include both star alleles and copy number variations, allowing you to convert a patient's genotype into a clinically actionable phenotype classification.", "problem": "A clinical pharmacogenomics laboratory analyzed an individual’s cytochrome P450 family 2 subfamily D member 6 (CYP2D6) locus using long-read sequencing with read-backed phasing and quantitative copy-number calling. The results show the following phased configuration of star alleles and copy numbers:\n\n- Haplotype 1 contains a tandem duplication of two identical CYP2D6 units, each annotated as star allele `CYP2D6*2`.\n- Haplotype 2 contains a single CYP2D6 unit annotated as star allele `CYP2D6*4`.\n- There is no evidence of hybrid genes or additional copies beyond those described, and no gene deletion beyond what is implied by the stated copy numbers.\n\nUse the following consensus framework, consistent with Clinical Pharmacogenetics Implementation Consortium (CPIC) conventions:\n\n- Functional category to activity value mapping: normal function allele has activity value $1.0$, decreased function allele has activity value $0.5$, and no function allele has activity value $0.0$.\n- Per-haplotype activity is the sum of activity values across all CYP2D6 copies present on that haplotype. The individual-level CYP2D6 activity score is the sum of the per-haplotype activities.\n- Phenotype bins by total CYP2D6 activity score: $0$ is poor metabolizer, any value greater than $0$ and less than or equal to $1.0$ is intermediate metabolizer, any value greater than or equal to $1.25$ and less than or equal to $2.25$ is normal metabolizer, and any value greater than $2.25$ is ultrarapid metabolizer.\n\nAssume `CYP2D6*2` is a normal function allele and `CYP2D6*4` is a no function allele under these conventions. Using only these rules, compute the individual’s CYP2D6 activity score and classify the metabolizer phenotype. Report the activity score as your final numeric answer (unitless). No rounding is required.", "solution": "The problem statement has been subjected to rigorous validation and is found to be scientifically sound, well-posed, and internally consistent. It presents a standard, albeit simplified, scenario in clinical pharmacogenomics, providing all necessary definitions, data, and rules to deduce a unique and unambiguous solution. We may therefore proceed with the analysis.\n\nThe objective is to compute the *CYP2D6* activity score for an individual and classify their metabolizer phenotype based on a provided framework. The process must be executed with strict adherence to the given rules.\n\nFirst, we must assign numerical activity values to the specified *CYP2D6* star alleles according to the problem's functional category mapping.\nThe `CYP2D6*2` allele is defined as a normal function allele. Therefore, its activity value is $1.0$.\nThe `CYP2D6*4` allele is defined as a no function allele. Therefore, its activity value is $0.0$.\n\nNext, we calculate the per-haplotype activity for each of the two haplotypes. The problem states that the per-haplotype activity is the sum of the activity values of all *CYP2D6* gene copies present on that haplotype.\n\nFor Haplotype $1$, the configuration is a tandem duplication of two identical `CYP2D6*2` units. This means there are two copies of the `CYP2D6*2` allele on this single haplotype. The activity of Haplotype $1$, which we shall denote as $A_{H1}$, is the sum of the activities of these two copies.\n$$ A_{H1} = (\\text{Activity of } \\text{`CYP2D6*2`}) + (\\text{Activity of } \\text{`CYP2D6*2`}) $$\n$$ A_{H1} = 1.0 + 1.0 = 2.0 $$\n\nFor Haplotype $2$, the configuration consists of a single `CYP2D6*4` unit. The activity of Haplotype $2$, denoted as $A_{H2}$, is simply the activity of this single allele.\n$$ A_{H2} = \\text{Activity of } \\text{`CYP2D6*4`} $$\n$$ A_{H2} = 0.0 $$\n\nThe total individual-level *CYP2D6* activity score, which we denote as $A_{Total}$, is defined as the sum of the per-haplotype activities.\n$$ A_{Total} = A_{H1} + A_{H2} $$\nSubstituting the calculated values:\n$$ A_{Total} = 2.0 + 0.0 = 2.0 $$\n\nThe individual's *CYP2D6* activity score is therefore $2.0$.\n\nFinally, we must classify the metabolizer phenotype by comparing this total activity score to the provided phenotype bins.\n- Poor metabolizer: score is $0$. Our score is not $0$.\n- Intermediate metabolizer: score is greater than $0$ and less than or equal to $1.0$. Our score of $2.0$ does not fall in this range $(0, 1.0]$.\n- Normal metabolizer: score is greater than or equal to $1.25$ and less than or equal to $2.25$. Our score of $2.0$ satisfies this condition, as $1.25 \\le 2.0 \\le 2.25$.\n- Ultrarapid metabolizer: score is greater than $2.25$. Our score is not greater than $2.25$.\n\nThe individual is classified as a normal metabolizer. The problem, however, asks only for the activity score as the final numeric answer.\nThe computed activity score is $2.0$.", "answer": "$$\\boxed{2.0}$$", "id": "2836780"}, {"introduction": "While the first practice focused on interpreting a known genotype, this exercise explores how the genetic effects themselves are discovered and quantified. It delves into the statistical challenge of linkage disequilibrium ($LD$), where a genotyped marker serves as a proxy for a true, unobserved causal variant. By working through this problem [@problem_id:2836676], you will develop a crucial understanding of attenuation bias and regression calibration, skills necessary to critically evaluate the results of pharmacogenetic association studies and distinguish a statistical association from a causal effect.", "problem": "A pharmacogenetic study of warfarin dose response models the maintenance dose (a continuous phenotype) as a linear function of genotype. Let the true causal variant be a regulatory Single Nucleotide Polymorphism (SNP) at the *VKORC1* locus with genotype $G_c \\in \\{0,1,2\\}$ denoting the count of the effect allele. The data-generating model is\n$$\nY \\;=\\; \\mu \\;+\\; \\beta_c \\, G_c \\;+\\; \\varepsilon,\n$$\nwhere $E[\\varepsilon \\mid G_c] = 0$ and $\\operatorname{Var}(\\varepsilon) = \\sigma^2$. The study, however, genotypes a nearby tag SNP with genotype $G_t \\in \\{0,1,2\\}$ instead of $G_c$. Assume Hardy–Weinberg Equilibrium (HWE) for both loci so that $\\operatorname{Var}(G_j) = 2 p_j (1-p_j)$ for $j \\in \\{c,t\\}$, where $p_j$ is the effect-allele frequency. The tag SNP and the causal SNP are in Linkage Disequilibrium (LD) with squared correlation $r^2 = 0.8$ and positive correlation $r = \\sqrt{0.8}$. Investigators regress $Y$ on $G_t$ (instead of $G_c$) in a large sample, obtaining an estimate $\\hat{\\beta}_t$ and its Standard Error (SE).\n\nLet $p_c = 0.2$ and $p_t = 0.3$. Using only core definitions from linear regression and LD, reason about the direction and magnitude of bias in $E[\\hat{\\beta}_t]$ relative to $\\beta_c$ when $G_t$ is used as a proxy for $G_c$. Then, propose an analytic correction to estimate $\\beta_c$ from $(\\hat{\\beta}_t, \\operatorname{SE}(\\hat{\\beta}_t))$ when ($r$, $p_c$, $p_t$) are known from a high-quality reference panel. Select the option that most accurately characterizes the bias and a valid analytic correction under these assumptions.\n\nA. Because $G_t$ is an imperfect proxy for $G_c$, the single-SNP regression on $G_t$ yields attenuation toward $0$ with\n$$\nE[\\hat{\\beta}_t] \\;=\\; \\beta_c \\,\\frac{\\operatorname{Cov}(G_t,G_c)}{\\operatorname{Var}(G_t)} \\;=\\; \\beta_c \\, r \\, \\sqrt{\\frac{\\operatorname{Var}(G_c)}{\\operatorname{Var}(G_t)}}.\n$$\nWith $r^2 = 0.8$, $p_c = 0.2$, and $p_t = 0.3$, the attenuation factor is\n$$\na \\;=\\; r \\sqrt{\\frac{2 p_c (1-p_c)}{2 p_t (1-p_t)}} \\;\\approx\\; \\sqrt{0.8}\\,\\sqrt{\\frac{0.32}{0.42}} \\;\\approx\\; 0.78,\n$$\nso $E[\\hat{\\beta}_t] \\approx 0.78 \\,\\beta_c$. An analytic correction is an errors-in-variables regression calibration:\n$$\n\\tilde{\\beta}_c \\;=\\; \\frac{\\hat{\\beta}_t}{a}, \\qquad \\operatorname{SE}(\\tilde{\\beta}_c) \\;\\approx\\; \\frac{\\operatorname{SE}(\\hat{\\beta}_t)}{a},\n$$\nwith optional delta-method inflation if ($r,p_c,p_t$) are estimated rather than known.\n\nB. When $r^2 \\ge 0.5$, the tag SNP captures the causal effect without bias; only statistical power changes. Therefore $E[\\hat{\\beta}_t] = \\beta_c$, and no correction is necessary beyond standard genomic control.\n\nC. The effect estimated at the tag SNP is inflated by a factor of $1/r^2$ relative to $\\beta_c$ because LD amplifies the association. A correct analytic fix is to multiply $\\hat{\\beta}_t$ by $r^2$ and keep the same Standard Error.\n\nD. The direction of bias is determined solely by the difference in allele frequencies: if $p_t > p_c$ then $\\hat{\\beta}_t$ overestimates $\\beta_c$, and if $p_t < p_c$ it underestimates it. A correct analytic fix is to rescale by $\\sqrt{\\operatorname{Var}(G_t)/\\operatorname{Var}(G_c)}$ without using $r$.", "solution": "The problem asks to evaluate the bias in estimating a genetic effect size using a proxy Single Nucleotide Polymorphism (SNP) and to define a method for correcting this bias.\n\nWe begin with the fundamental principles of linear regression. The true data-generating model is given as:\n$$\nY \\;=\\; \\mu \\;+\\; \\beta_c \\, G_c \\;+\\; \\varepsilon\n$$\nwhere $Y$ is the phenotype, $G_c \\in \\{0, 1, 2\\}$ is the genotype of the causal variant, $\\beta_c$ is the true effect size, and $\\varepsilon$ is an error term with $E[\\varepsilon \\mid G_c] = 0$.\n\nInstead of the true causal variant, a tag SNP with genotype $G_t \\in \\{0, 1, 2\\}$ is used. A simple linear regression of $Y$ on $G_t$ is performed. In a large sample, the ordinary least squares (OLS) estimator $\\hat{\\beta}_t$ for the coefficient of $G_t$ converges in probability to its population analogue:\n$$\n\\hat{\\beta}_t \\xrightarrow{p} \\frac{\\operatorname{Cov}(Y, G_t)}{\\operatorname{Var}(G_t)}\n$$\nTherefore, the expected value of the estimator, $E[\\hat{\\beta}_t]$, can be approximated by this quantity. We substitute the true model for $Y$ into the covariance term:\n$$\n\\operatorname{Cov}(Y, G_t) = \\operatorname{Cov}(\\mu + \\beta_c G_c + \\varepsilon, G_t)\n$$\nUsing the linearity of the covariance operator, this becomes:\n$$\n\\operatorname{Cov}(Y, G_t) = \\operatorname{Cov}(\\mu, G_t) + \\beta_c \\operatorname{Cov(G_c, G_t)} + \\operatorname{Cov}(\\varepsilon, G_t)\n$$\nThe covariance with a constant $\\mu$ is $0$. It is a standard assumption in this context that the error term $\\varepsilon$, which represents influences on $Y$ other than the causal variant $G_c$, is uncorrelated with the tag SNP genotype $G_t$. Thus, $\\operatorname{Cov}(\\varepsilon, G_t) = 0$. This simplifies the expression to:\n$$\n\\operatorname{Cov}(Y, G_t) = \\beta_c \\operatorname{Cov(G_c, G_t)}\n$$\nSubstituting this result back into the expression for $E[\\hat{\\beta}_t]$, we obtain:\n$$\nE[\\hat{\\beta}_t] \\approx \\beta_c \\frac{\\operatorname{Cov}(G_c, G_t)}{\\operatorname{Var}(G_t)}\n$$\nThe correlation coefficient, $r$, between the genotypes $G_c$ and $G_t$ is defined as:\n$$\nr = \\frac{\\operatorname{Cov}(G_c, G_t)}{\\sqrt{\\operatorname{Var}(G_c) \\operatorname{Var}(G_t)}}\n$$\nRearranging this definition gives $\\operatorname{Cov}(G_c, G_t) = r \\sqrt{\\operatorname{Var}(G_c) \\operatorname{Var}(G_t)}$. We substitute this into our expression for $E[\\hat{\\beta}_t]$:\n$$\nE[\\hat{\\beta}_t] \\approx \\beta_c \\frac{r \\sqrt{\\operatorname{Var}(G_c) \\operatorname{Var}(G_t)}}{\\operatorname{Var}(G_t)} \\;=\\; \\beta_c \\, r \\, \\sqrt{\\frac{\\operatorname{Var}(G_c)}{\\operatorname{Var}(G_t)}}\n$$\nThis formula shows that the expected value of the estimated effect $\\hat{\\beta}_t$ is not equal to the true effect $\\beta_c$ unless the factor $a = r \\sqrt{\\operatorname{Var}(G_c) / \\operatorname{Var}(G_t)}$ is equal to $1$. This phenomenon is known as attenuation bias or regression dilution when a proxy variable is used in place of the true predictor.\n\nWe now calculate the value of the attenuation factor $a$ using the provided data:\n$p_c = 0.2$, $p_t = 0.3$, and $r = \\sqrt{0.8}$.\nUnder Hardy-Weinberg Equilibrium (HWE), the variance of a genotype coded as an allele count is $\\operatorname{Var}(G_j) = 2 p_j (1 - p_j)$.\n$$\n\\operatorname{Var}(G_c) = 2 \\times 0.2 \\times (1 - 0.2) = 2 \\times 0.2 \\times 0.8 = 0.32\n$$\n$$\n\\operatorname{Var}(G_t) = 2 \\times 0.3 \\times (1 - 0.3) = 2 \\times 0.3 \\times 0.7 = 0.42\n$$\nThe attenuation factor $a$ is:\n$$\na = r \\sqrt{\\frac{\\operatorname{Var}(G_c)}{\\operatorname{Var}(G_t)}} = \\sqrt{0.8} \\times \\sqrt{\\frac{0.32}{0.42}} \\approx 0.8944 \\times \\sqrt{0.7619} \\approx 0.8944 \\times 0.8729 \\approx 0.7806\n$$\nThus, $E[\\hat{\\beta}_t] \\approx 0.78 \\beta_c$. Since $|a| < 1$, the estimated effect at the tag SNP is biased toward zero, i.e., it is an underestimation of the true causal effect $\\beta_c$.\n\nTo obtain an unbiased estimate for $\\beta_c$ from the observed $\\hat{\\beta}_t$, we can invert the relationship $E[\\hat{\\beta}_t] = a \\beta_c$. This leads to the corrected estimator $\\tilde{\\beta}_c$:\n$$\n\\tilde{\\beta}_c = \\frac{\\hat{\\beta}_t}{a}\n$$\nThis correction is known as regression calibration. To find the standard error of this corrected estimate, we apply the propagation of error formula (a first-order Taylor expansion, or delta method). Assuming the factor $a$ is known without error as per the problem statement:\n$$\n\\operatorname{Var}(\\tilde{\\beta}_c) = \\operatorname{Var}\\left(\\frac{\\hat{\\beta}_t}{a}\\right) = \\left(\\frac{1}{a}\\right)^2 \\operatorname{Var}(\\hat{\\beta}_t)\n$$\nTaking the square root gives the standard error:\n$$\n\\operatorname{SE}(\\tilde{\\beta}_c) = \\frac{\\operatorname{SE}(\\hat{\\beta}_t)}{|a|}\n$$\nSince $a$ is positive, this is $\\operatorname{SE}(\\tilde{\\beta}_c) = \\operatorname{SE}(\\hat{\\beta}_t)/a$.\n\nWe now evaluate each option:\n\n**A.** This option states that the regression on $G_t$ yields attenuation toward $0$ and provides the formula $E[\\hat{\\beta}_t] = \\beta_c \\frac{\\operatorname{Cov}(G_t,G_c)}{\\operatorname{Var}(G_t)} = \\beta_c \\, r \\, \\sqrt{\\frac{\\operatorname{Var}(G_c)}{\\operatorname{Var}(G_t)}}$. This matches our derivation precisely. It then calculates the attenuation factor $a \\approx 0.78$, which is correct. The resulting bias is correctly characterized as $E[\\hat{\\beta}_t] \\approx 0.78 \\beta_c$. Finally, it proposes the analytic correction $\\tilde{\\beta}_c = \\hat{\\beta}_t / a$ and $\\operatorname{SE}(\\tilde{\\beta}_c) \\approx \\operatorname{SE}(\\hat{\\beta}_t) / a$. This entire statement is consistent with our derivation from first principles.\n\n**Verdict: Correct**\n\n**B.** This option claims that for $r^2 \\ge 0.5$, the effect is captured without bias, i.e., $E[\\hat{\\beta}_t] = \\beta_c$. This is fundamentally incorrect. The condition for no bias is $a=1$, which generally requires both perfect correlation ($r=1$) and equal variances ($\\operatorname{Var}(G_c) = \\operatorname{Var}(G_t)$). The threshold $r^2 \\ge 0.5$ is arbitrary in this context and does not eliminate bias. Our calculation showed for $r^2=0.8$ that $a \\approx 0.78 \\ne 1$, demonstrating a clear bias. This option incorrectly conflates statistical power with estimator bias.\n\n**Verdict: Incorrect**\n\n**C.** This option asserts that the estimated effect is inflated by a factor of $1/r^2$. Our derivation shows the effect is attenuated (multiplied by $a \\approx 0.78$), not inflated. The factor $1/r^2$ is also incorrect; the true scaling factor is $a = r \\sqrt{\\operatorname{Var}(G_c) / \\operatorname{Var}(G_t)}$. This statement misrepresents both the direction and the magnitude of the bias.\n\n**Verdict: Incorrect**\n\n**D.** This option claims the direction of bias is determined solely by the difference in allele frequencies and that the correction does not involve $r$. The bias is determined by the factor $a = r \\sqrt{\\operatorname{Var}(G_c) / \\operatorname{Var}(G_t)}$. While allele frequencies influence the variance ratio, the correlation $r$ is a critical component. Omitting $r$ from the correction is a major error, as $r$ quantifies the strength of the proxy relationship. Without correlation ($r=0$), no information about $\\beta_c$ can be recovered from a regression on $G_t$. The claim about the direction of bias related to $p_t > p_c$ is also shown to be false by our calculation; for $p_c=0.2$ and $p_t=0.3$, we have attenuation, not overestimation.\n\n**Verdict: Incorrect**\n\nBased on the thorough analysis, only option A provides a scientifically correct and complete account of the bias and its correction.", "answer": "$$\\boxed{A}$$", "id": "2836676"}, {"introduction": "This final practice represents the ultimate goal of pharmacogenetics: using genetic and clinical data to guide personalized therapy in real time. You will implement a Bayesian adaptive dosing algorithm, a sophisticated approach that formally integrates prior knowledge from a patient's genotype with new evidence from drug concentration measurements. This capstone exercise [@problem_id:2836657] moves beyond static prediction to dynamic, model-informed precision dosing, providing a practical foundation in the computational methods that are shaping the future of personalized medicine.", "problem": "You are asked to implement a Bayesian adaptive dosing algorithm for a one-compartment, linear pharmacokinetic system under steady-state dosing, in which genotype informs a prior distribution on clearance. The algorithm must update the posterior distribution of clearance using observed steady-state trough concentrations from therapeutic drug monitoring and compute the next dose that targets a specified steady-state trough concentration. All quantities in your program must be handled in the units specified below, and all outputs must follow the required format exactly.\n\nFundamental base and modeling assumptions to use:\n- Central Dogma of Molecular Biology and enzyme-mediated drug metabolism: gene sequence variants can alter enzyme levels or function, which in turn modulate drug clearance. Clearance is defined as the volume of plasma cleared of drug per unit time.\n- One-compartment model with linear kinetics and first-order elimination, with steady-state reached under repeated dosing. Superposition and geometric decay imply that, at steady state with bolus dose $D$ given every $\\tau$ hours, clearance $CL$ in $\\mathrm{L/h}$, and volume of distribution $V$ in $\\mathrm{L}$, the steady-state trough concentration immediately before the next dose is\n$$\nC_{\\mathrm{trough}}(CL; D,\\tau,V) \\;=\\; \\frac{D}{V}\\,\\frac{e^{-\\left(\\frac{CL}{V}\\right)\\tau}}{1 - e^{-\\left(\\frac{CL}{V}\\right)\\tau}} \\quad \\text{in mg/L.}\n$$\n- Genotype-informed prior for clearance: the prior for $CL$ is Log-Normal with parameters on the logarithmic scale determined by a population typical clearance multiplied by a genotype effect. Specifically, let $CL_{\\mathrm{pop}}$ denote the typical clearance for a normal metabolizer, and let $g$ denote a multiplicative genotype factor. Then\n$$\n\\ln(CL) \\sim \\mathcal{N}\\!\\left(\\mu_{\\mathrm{prior}}, \\sigma_{\\mathrm{prior}}^2\\right), \\quad \\mu_{\\mathrm{prior}} = \\ln\\!\\left(g \\cdot CL_{\\mathrm{pop}}\\right).\n$$\n- Residual error model for troughs: conditional on $CL$, each observed steady-state trough concentration $y_i$ (in $\\mathrm{mg/L}$) is independently Log-Normally distributed around the model prediction $C_{\\mathrm{trough}}(CL; D,\\tau,V)$ with logarithmic residual standard deviation $\\sigma_{\\mathrm{res}}$:\n$$\n\\ln(y_i) \\mid CL \\sim \\mathcal{N}\\!\\left(\\ln\\!\\left(C_{\\mathrm{trough}}(CL; D,\\tau,V)\\right),\\, \\sigma_{\\mathrm{res}}^2\\right).\n$$\n- Bayesian update target: compute the posterior mean of $CL$,\n$$\n\\mathbb{E}[CL \\mid \\{y_i\\}] \\;=\\; \\int_{0}^{\\infty} CL \\, p(CL \\mid \\{y_i\\}) \\, dCL,\n$$\nand use this as a plug-in estimator in the dosing equation below.\n\nDosing control objective:\n- Given a target steady-state trough concentration $C_{\\mathrm{target}}$ in $\\mathrm{mg/L}$ and a fixed dosing interval $\\tau$ in $\\mathrm{h}$, compute the next dose $D_{\\mathrm{next}}$ in $\\mathrm{mg}$ that is expected to achieve $C_{\\mathrm{target}}$ under the posterior-mean clearance. Solve the steady-state trough equation for $D$ with $k = \\frac{CL}{V}$ to obtain\n$$\nD_{\\mathrm{next}} \\;=\\; V \\cdot C_{\\mathrm{target}} \\left(\\exp\\!\\left(\\frac{\\mathbb{E}[CL \\mid \\{y_i\\}]}{V}\\,\\tau\\right) - 1\\right).\n$$\n\nComputational requirements to ensure testability and reproducibility:\n- Use a numerical quadrature by discrete grid to approximate the posterior of $CL$:\n  - Grid over $CL$ on a uniform linear grid with $N = 20001$ points spanning $[0.5, 15.0]$ in $\\mathrm{L/h}$, inclusive.\n  - Evaluate the log-prior and log-likelihood at each grid point; combine to obtain unnormalized log-posterior. Exponentiate after subtracting the maximum log value for numerical stability, then normalize to obtain discrete posterior weights that sum to $1$.\n  - Compute the posterior mean as the weighted sum over the grid.\n- Prior hyperparameters:\n  - Population typical clearance $CL_{\\mathrm{pop}} = 4.5$ $\\mathrm{L/h}$.\n  - Log-prior standard deviation $\\sigma_{\\mathrm{prior}} = 0.35$ on the natural logarithm scale.\n- Residual error:\n  - Log-residual standard deviation $\\sigma_{\\mathrm{res}} = 0.25$ on the natural logarithm scale.\n- Genotype-to-factor mapping $g$:\n  - Normal metabolizer (NM): $g = 1.0$\n  - Intermediate metabolizer (IM): $g = 0.8$\n  - Poor metabolizer (PM): $g = 0.6$\n  - Ultrarapid metabolizer (UM): $g = 1.5$\n\nUnits and rounding:\n- Clearance $CL$ in $\\mathrm{L/h}$, volume $V$ in $\\mathrm{L}$, dosing interval $\\tau$ in $\\mathrm{h}$, concentrations in $\\mathrm{mg/L}$, and doses in $\\mathrm{mg}$.\n- Your program must output $D_{\\mathrm{next}}$ for each test case in $\\mathrm{mg}$, rounded to the nearest integer.\n\nInput specification for your program:\n- There is no input. Hard-code the test suite below and produce the specified single-line output.\n\nTest suite:\nFor each case, use the tuple $(\\text{genotype}, V, \\tau, D_{\\mathrm{prev}}, \\{y_i\\}, C_{\\mathrm{target}})$ with the exact values provided.\n\n- Case $1$: $\\text{genotype} = \\text{\"NM\"}$, $V = 50$ $\\mathrm{L}$, $\\tau = 12$ $\\mathrm{h}$, $D_{\\mathrm{prev}} = 1000$ $\\mathrm{mg}$, observed troughs $\\{9.0, 8.5\\}$ $\\mathrm{mg/L}$, $C_{\\mathrm{target}} = 15.0$ $\\mathrm{mg/L}$.\n- Case $2$: $\\text{genotype} = \\text{\"PM\"}$, $V = 50$ $\\mathrm{L}$, $\\tau = 12$ $\\mathrm{h}$, $D_{\\mathrm{prev}} = 1000$ $\\mathrm{mg}$, observed troughs $\\{22.0, 24.0, 23.0\\}$ $\\mathrm{mg/L}$, $C_{\\mathrm{target}} = 15.0$ $\\mathrm{mg/L}$.\n- Case $3$: $\\text{genotype} = \\text{\"UM\"}$, $V = 50$ $\\mathrm{L}$, $\\tau = 12$ $\\mathrm{h}$, $D_{\\mathrm{prev}} = 1000$ $\\mathrm{mg}$, observed trough $\\{4.0\\}$ $\\mathrm{mg/L}$, $C_{\\mathrm{target}} = 15.0$ $\\mathrm{mg/L}$.\n- Case $4$: $\\text{genotype} = \\text{\"IM\"}$, $V = 50$ $\\mathrm{L}$, $\\tau = 24$ $\\mathrm{h}$, $D_{\\mathrm{prev}} = 1500$ $\\mathrm{mg}$, observed troughs $\\{7.0, 6.5\\}$ $\\mathrm{mg/L}$, $C_{\\mathrm{target}} = 10.0$ $\\mathrm{mg/L}$.\n- Case $5$: $\\text{genotype} = \\text{\"NM\"}$, $V = 50$ $\\mathrm{L}$, $\\tau = 24$ $\\mathrm{h}$, $D_{\\mathrm{prev}} = 1000$ $\\mathrm{mg}$, observed trough $\\{5.0\\}$ $\\mathrm{mg/L}$, $C_{\\mathrm{target}} = 5.0$ $\\mathrm{mg/L}$.\n\nRequired final output format:\n- Your program should produce a single line of output containing the $5$ computed next doses in $\\mathrm{mg}$, rounded to the nearest integer, as a comma-separated list enclosed in square brackets. For example, an output with three results should look like $[a,b,c]$, but here you must output exactly five integers in the order of the cases above.", "solution": "The problem statement is scientifically sound, well-posed, and objective. It provides a complete set of equations, parameters, and computational specifications for implementing a Bayesian adaptive dosing algorithm. The task is to calculate the optimal next dose for a series of simulated patient cases based on pharmacogenetic information and therapeutic drug monitoring data. The problem is valid and a solution can be constructed.\n\nThe core of the problem is to implement a Bayesian inference procedure to update our belief about a patient's drug clearance ($CL$) and then use this updated belief to guide dosing. The algorithm proceeds in two main stages: Bayesian updating and dose control.\n\nFirst, we establish the components of the Bayesian model. The parameter of interest is the drug clearance, $CL$, measured in $\\mathrm{L/h}$.\n\nThe prior distribution for $CL$ is informed by the patient's genotype. It is specified as a Log-Normal distribution, which is equivalent to stating that the natural logarithm of clearance is Normally distributed:\n$$\n\\ln(CL) \\sim \\mathcal{N}(\\mu_{\\mathrm{prior}}, \\sigma_{\\mathrm{prior}}^2)\n$$\nThe mean of this distribution, $\\mu_{\\mathrm{prior}}$, is determined by a population typical clearance, $CL_{\\mathrm{pop}}$, adjusted by a genotype-specific factor, $g$. The formula is:\n$$\n\\mu_{\\mathrm{prior}} = \\ln(g \\cdot CL_{\\mathrm{pop}})\n$$\nThe standard deviation, $\\sigma_{\\mathrm{prior}}$, reflects the inter-individual variability in clearance even within the same genotype group. The problem provides values for $CL_{\\mathrm{pop}}$, $\\sigma_{\\mathrm{prior}}$, and the mapping from genotype (NM, IM, PM, UM) to the factor $g$.\n\nThe likelihood function quantifies how probable the observed data are for a given value of $CL$. The data consist of one or more steady-state trough concentrations, $\\{y_i\\}$. According to the one-compartment pharmacokinetic model provided, the predicted trough concentration, $C_{\\mathrm{trough}}$, for a dose $D$ given every $\\tau$ hours to a patient with clearance $CL$ and volume of distribution $V$ is:\n$$\nC_{\\mathrm{trough}}(CL; D, \\tau, V) = \\frac{D}{V} \\frac{e^{-(\\frac{CL}{V})\\tau}}{1 - e^{-(\\frac{CL}{V})\\tau}}\n$$\nThe observed values $y_i$ are assumed to be Log-Normally distributed around this model prediction, accounting for measurement error and model misspecification. The log of an observation $\\ln(y_i)$ is thus Normally distributed:\n$$\n\\ln(y_i) \\mid CL \\sim \\mathcal{N}(\\ln(C_{\\mathrm{trough}}(CL; D, \\tau, V)), \\sigma_{\\mathrm{res}}^2)\n$$\nwhere $\\sigma_{\\mathrm{res}}$ is the residual standard deviation on the logarithmic scale. The total log-likelihood for a set of independent observations $\\{y_i\\}$ is the sum of the individual log-likelihoods:\n$$\n\\ln\\mathcal{L}(CL \\mid \\{y_i\\}) = \\sum_{i} \\ln p(y_i \\mid CL)\n$$\n\nAccording to Bayes' theorem, the posterior probability of $CL$ given the data is proportional to the product of the prior probability and the likelihood: $p(CL \\mid \\{y_i\\}) \\propto p(\\{y_i\\} \\mid CL) \\cdot p(CL)$. In logarithmic space, this becomes:\n$$\n\\ln p(CL \\mid \\{y_i\\}) = \\ln\\mathcal{L}(CL \\mid \\{y_i\\}) + \\ln p(CL) + \\text{constant}\n$$\nThe problem specifies a numerical approach to compute the posterior distribution. We discretize the continuous range of $CL$ into a fine grid of $N = 20001$ points from $0.5$ to $15.0$ $\\mathrm{L/h}$. For each point $CL_j$ on this grid, we compute the log-prior and the total log-likelihood, and sum them to get the unnormalized log-posterior. To obtain a normalized discrete probability distribution (posterior weights), we exponentiate the log-posterior values (after shifting by subtracting the maximum value for numerical stability) and normalize the resulting values to sum to one.\n\nThe second stage is dose control. The goal is to find the next dose, $D_{\\mathrm{next}}$, that will achieve a target trough concentration, $C_{\\mathrm{target}}$. The problem mandates using the posterior mean of clearance, $\\mathbb{E}[CL \\mid \\{y_i\\}]$, as a \"plug-in\" estimate for the true clearance. This posterior mean is calculated as the weighted average of the $CL$ values on the grid, with the posterior probabilities as weights:\n$$\n\\mathbb{E}[CL \\mid \\{y_i\\}] = \\sum_{j} CL_j \\cdot p(CL_j \\mid \\{y_i\\})\n$$\nBy rearranging the trough concentration formula and substituting $\\mathbb{E}[CL \\mid \\{y_i\\}]$ for $CL$ and $C_{\\mathrm{target}}$ for $C_{\\mathrm{trough}}$, we solve for the next dose:\n$$\nD_{\\mathrm{next}} = V \\cdot C_{\\mathrm{target}} \\left(\\exp\\left(\\frac{\\mathbb{E}[CL \\mid \\{y_i\\}]}{V}\\tau\\right) - 1\\right)\n$$\nThis calculation is performed for each test case specified. The final dose in milligrams is rounded to the nearest integer. The implementation will use `numpy` for efficient array computations and `scipy.stats.lognorm` to evaluate the log-probability densities for the prior and likelihood calculations.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.stats import lognorm\n\ndef solve():\n    # Define problem constants and parameters.\n    CL_POP = 4.5  # L/h\n    SIGMA_PRIOR = 0.35\n    SIGMA_RES = 0.25\n    \n    GENOTYPE_FACTORS = {\n        \"NM\": 1.0,\n        \"IM\": 0.8,\n        \"PM\": 0.6,\n        \"UM\": 1.5,\n    }\n    \n    # Computational grid for Clearance (CL)\n    CL_GRID_MIN = 0.5   # L/h\n    CL_GRID_MAX = 15.0  # L/h\n    N_POINTS = 20001\n    cl_grid = np.linspace(CL_GRID_MIN, CL_GRID_MAX, N_POINTS)\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # (genotype, V, tau, D_prev, observed_troughs, C_target)\n        (\"NM\", 50.0, 12.0, 1000.0, [9.0, 8.5], 15.0),\n        (\"PM\", 50.0, 12.0, 1000.0, [22.0, 24.0, 23.0], 15.0),\n        (\"UM\", 50.0, 12.0, 1000.0, [4.0], 15.0),\n        (\"IM\", 50.0, 24.0, 1500.0, [7.0, 6.5], 10.0),\n        (\"NM\", 50.0, 24.0, 1000.0, [5.0], 5.0),\n    ]\n\n    def calculate_next_dose(genotype, V, tau, D_prev, y_obs, C_target):\n        \"\"\"\n        Calculates the next dose based on Bayesian adaptive dosing.\n        \"\"\"\n        # 1. Calculate log-prior\n        g = GENOTYPE_FACTORS[genotype]\n        mu_prior_ln_cl = np.log(g * CL_POP)\n        prior_scale = np.exp(mu_prior_ln_cl)\n        \n        # Using scipy.stats.lognorm.logpdf\n        # s = sigma, scale = exp(mu)\n        log_prior = lognorm.logpdf(cl_grid, s=SIGMA_PRIOR, scale=prior_scale)\n        \n        # 2. Calculate log-likelihood\n        # Calculate predicted trough concentrations for all CL values on the grid\n        k = cl_grid / V\n        exp_term = np.exp(-k * tau)\n        \n        # Avoid division by zero for very small k * tau (though not an issue with given grid)\n        # Using np.expm1 for better precision with small arguments\n        c_trough_pred = (D_prev / V) * exp_term / -np.expm1(-k * tau)\n\n        # Sum log-likelihoods over all observations\n        total_log_likelihood = np.zeros_like(cl_grid)\n        for y in y_obs:\n            # Likelihood of observing y given the predicted trough (as scale)\n            # The model is y ~ LogNormal(mean=c_trough_pred, sigma=SIGMA_RES)\n            # This means ln(y) ~ Normal(mean=ln(c_trough_pred), sigma=SIGMA_RES)\n            # The scale parameter in scipy's lognorm is exp(mu_normal) = c_trough_pred\n            log_lik_y = lognorm.logpdf(y, s=SIGMA_RES, scale=c_trough_pred)\n            total_log_likelihood += log_lik_y\n            \n        # 3. Calculate unnormalized log-posterior\n        log_posterior = log_prior + total_log_likelihood\n        \n        # 4. Normalize the posterior for numerical stability\n        log_posterior_shifted = log_posterior - np.max(log_posterior)\n        unnormalized_posterior = np.exp(log_posterior_shifted)\n        posterior_weights = unnormalized_posterior / np.sum(unnormalized_posterior)\n        \n        # 5. Compute the posterior mean of CL\n        E_cl_posterior = np.sum(cl_grid * posterior_weights)\n        \n        # 6. Calculate the next dose\n        exp_arg = (E_cl_posterior / V) * tau\n        # Use np.expm1 for precision: exp(x) - 1\n        D_next = V * C_target * np.expm1(exp_arg)\n        \n        return round(D_next)\n\n    results = []\n    for case in test_cases:\n        result = calculate_next_dose(*case)\n        results.append(result)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "2836657"}]}