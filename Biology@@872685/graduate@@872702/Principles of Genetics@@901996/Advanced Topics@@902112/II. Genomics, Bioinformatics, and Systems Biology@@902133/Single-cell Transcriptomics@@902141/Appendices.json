{"hands_on_practices": [{"introduction": "Before any data is generated, a successful single-cell experiment requires careful planning. A key consideration is determining the necessary sequencing depth to ensure that cellular populations of interest, especially rare ones, are captured. This exercise grounds experimental design in fundamental probability theory, allowing you to translate a biological goal into a quantitative statistical question. By modeling cell capture as a series of independent trials, you will derive the minimum number of cells required to detect a rare cell type with a desired level of confidence, a calculation essential for effective resource allocation and experimental strategy. [@problem_id:2851229]", "problem": "A researcher is designing a single-cell RNA sequencing (scRNA-seq) experiment to detect a rare cell type in a heterogeneous tissue. Assume the tissue is sufficiently large that sampling without replacement can be approximated by independent sampling with replacement, and that each captured cell is independently of the rare type with probability $f$, where $0<f<1$. The researcher plans to sequence $n$ cells and will declare success if at least one cell of the rare type is captured among the $n$ sequenced cells.\n\nStarting only from the foundational definitions of Bernoulli trials and the binomial distribution, model the detection event and derive the minimal integer $n$ such that the probability of detecting at least one rare cell is at least $0.95$. Express your final answer as a single closed-form expression in terms of $f$ only. Do not substitute any numerical values. No units are required.", "solution": "The problem statement must first be subject to rigorous validation.\n\n**Step 1: Extracted Givens**\n- The process of capturing a single cell is approximated as an independent Bernoulli trial.\n- The probability that a captured cell is of the rare type is denoted by $f$, where $0 < f < 1$.\n- The total number of cells to be sequenced is $n$.\n- A successful experiment is defined as the capture of at least one rare cell.\n- The condition is that the probability of success must be at least $0.95$.\n- The objective is to derive the minimal integer $n$ that satisfies this condition.\n\n**Step 2: Validation Using Extracted Givens**\nThe problem is assessed against the required criteria.\n- **Scientifically Grounded**: The problem uses a binomial distribution to model cell sampling, which is a standard and fundamentally correct approach in statistical genomics and population genetics for such problems. The assumption of sampling with replacement is a valid approximation for a large population, which is typical for a tissue sample.\n- **Well-Posed**: The problem is clearly stated. It provides all necessary parameters ($f$ and the probability threshold of $0.95$) to determine a unique, minimal integer solution for $n$.\n- **Objective**: The problem is formulated with precise, objective mathematical language. Terms like \"probability\", \"at least one\", and \"minimal integer\" are unambiguous.\n\nThe problem exhibits no flaws. It is not scientifically unsound, incomplete, contradictory, or ill-posed. It is a standard, formalizable problem in applied probability theory relevant to its stated field.\n\n**Step 3: Verdict and Action**\nThe problem is valid. We will now proceed with the derivation.\n\nThe task is to find the minimal integer number of cells, $n$, to be sequenced to ensure the probability of detecting at least one rare cell is no less than $0.95$. The fraction of rare cells is $f$.\n\nLet $X$ be the random variable representing the number of rare cells detected in a sample of $n$ cells. Each cell capture is an independent Bernoulli trial with a probability of success (detecting a rare cell) equal to $f$. Consequently, the random variable $X$ follows a binomial distribution, denoted as $X \\sim \\text{Binomial}(n, f)$.\n\nThe probability mass function for a binomial distribution is given by:\n$$P(X=k) = \\binom{n}{k} f^{k} (1-f)^{n-k}$$\nwhere $k$ is the number of successes, which can be any integer from $0$ to $n$.\n\nThe condition stated in the problem is that the probability of detecting at least one rare cell is at least $0.95$. Mathematically, this is expressed as:\n$$P(X \\ge 1) \\ge 0.95$$\n\nIt is more direct to calculate this probability using the complementary event, which is the event of detecting zero rare cells, $P(X=0)$. The relationship is:\n$$P(X \\ge 1) = 1 - P(X=0)$$\n\nSubstituting this into our inequality gives:\n$$1 - P(X=0) \\ge 0.95$$\n\nNow, we calculate $P(X=0)$ using the binomial probability mass function with $k=0$:\n$$P(X=0) = \\binom{n}{0} f^{0} (1-f)^{n-0} = 1 \\cdot 1 \\cdot (1-f)^{n} = (1-f)^{n}$$\n\nSubstituting this result back into the inequality yields:\n$$1 - (1-f)^{n} \\ge 0.95$$\n\nWe must now solve this inequality for $n$.\nFirst, rearrange the terms to isolate the expression containing $n$:\n$$-(1-f)^{n} \\ge 0.95 - 1$$\n$$-(1-f)^{n} \\ge -0.05$$\nMultiplying both sides by $-1$ reverses the inequality sign:\n$$(1-f)^{n} \\le 0.05$$\n\nTo solve for the exponent $n$, we take the natural logarithm of both sides. Since $0 < f < 1$, the base of the exponent, $(1-f)$, is strictly between $0$ and $1$. Both sides of the inequality, $(1-f)^{n}$ and $0.05$, are positive, so the logarithm is well-defined.\n$$\\ln\\left((1-f)^{n}\\right) \\le \\ln(0.05)$$\nUsing the logarithm property $\\ln(a^b) = b\\ln(a)$, we get:\n$$n \\ln(1-f) \\le \\ln(0.05)$$\n\nTo isolate $n$, we must divide by $\\ln(1-f)$. As established, because $0 < (1-f) < 1$, its natural logarithm, $\\ln(1-f)$, is a negative number. Dividing an inequality by a negative number requires reversing the direction of the inequality sign:\n$$n \\ge \\frac{\\ln(0.05)}{\\ln(1-f)}$$\n\nThe problem requires the minimal *integer* $n$ that satisfies this condition. The set of solutions for $n$ is a continuous interval starting from $\\frac{\\ln(0.05)}{\\ln(1-f)}$. The smallest integer that belongs to this set is the ceiling of this lower bound. The ceiling function, denoted $\\lceil x \\rceil$, gives the smallest integer greater than or equal to $x$.\n\nTherefore, the minimal integer $n$ is:\n$$n_{\\min} = \\left\\lceil \\frac{\\ln(0.05)}{\\ln(1-f)} \\right\\rceil$$\n\nThis is the final, closed-form expression for the minimal number of cells $n$ in terms of the rare cell fraction $f$.", "answer": "$$\n\\boxed{\n\\left\\lceil \\frac{\\ln(0.05)}{\\ln(1-f)} \\right\\rceil\n}\n$$", "id": "2851229"}, {"introduction": "The raw output of a single-cell experiment inevitably contains data from low-quality or dying cells, which can confound downstream analyses. A crucial first step in any computational pipeline is a robust quality control (QC) procedure to identify and filter these artifacts. This practice formalizes the QC process using the principles of statistical decision theory. You will derive a Bayes-optimal classification rule to separate high-quality from low-quality cells, providing a first-principles understanding of the automated filtering steps that are fundamental to all modern single-cell analysis software. [@problem_id:2851235]", "problem": "A single-cell RNA sequencing (scRNA-seq) experiment yields a count matrix with entries $c_{ij}$ denoting the number of Unique Molecular Identifier (UMI) molecules for gene $j$ in cell $i$. For each cell $i$, define three quality control metrics grounded in core definitions from single-cell transcriptomics:\n\n- The mitochondrial read fraction $f_{\\mathrm{mt},i}$ is the ratio of UMI counts aligning to the set of annotated mitochondrial genes to the total UMI count in cell $i$, i.e., $f_{\\mathrm{mt},i} = \\frac{c_{i,\\mathrm{mt}}}{c_{i,\\mathrm{tot}}}$ where $c_{i,\\mathrm{tot}} = \\sum_{j} c_{ij}$ and $c_{i,\\mathrm{mt}}$ sums over mitochondrial genes.\n- The number of detected genes $g_i$ is the count of genes with at least one UMI in cell $i$, i.e., $g_i = \\sum_{j} \\mathbf{1}\\{c_{ij} > 0\\}$.\n- The total UMI count $u_i$ is $u_i = \\sum_{j} c_{ij}$.\n\nA commonly used approach to separate low-quality from high-quality cells begins by summarizing these metrics into a scalar score and then fitting a $2$-component mixture model. Consider the scalar summary score\n$$\ns_i = \\ln(1+u_i) + \\ln(1+g_i) - 4\\, f_{\\mathrm{mt},i}.\n$$\nAssume that, in a given dataset, the empirical distribution of the $s_i$ values is well approximated by a two-component Gaussian mixture reflecting two latent classes: low-quality cells ($\\mathrm{L}$) and high-quality cells ($\\mathrm{H}$). Specifically, suppose that $s \\mid \\mathrm{L} \\sim \\mathcal{N}(\\mu_{\\mathrm{L}}, \\sigma^2)$ and $s \\mid \\mathrm{H} \\sim \\mathcal{N}(\\mu_{\\mathrm{H}}, \\sigma^2)$ with equal variances, and prior class probabilities $\\pi_{\\mathrm{L}}$ and $\\pi_{\\mathrm{H}} = 1 - \\pi_{\\mathrm{L}}$. For a particular experiment, let\n$$\n\\mu_{\\mathrm{L}} = 6.0,\\quad \\mu_{\\mathrm{H}} = 10.5,\\quad \\sigma = 0.8,\\quad \\pi_{\\mathrm{L}} = 0.35,\\quad \\pi_{\\mathrm{H}} = 0.65.\n$$\n\nStarting only from the definitions above, the form of the Gaussian probability density function, and Bayes’ rule under $0$–$1$ loss with equal misclassification costs, derive the Bayes-optimal decision threshold $t$ on $s$ that separates low-quality from high-quality cells by the rule “classify as high-quality if $s \\ge t$ and low-quality otherwise.”\n\nReport the numerical value of $t$ as a pure number (unitless). Round your answer to $4$ significant figures.", "solution": "The problem requires the derivation of the Bayes-optimal decision threshold, $t$, for classifying cells into low-quality ($\\mathrm{L}$) or high-quality ($\\mathrm{H}$) categories based on a scalar score $s$. The decision rule is to classify a cell as high-quality if its score $s$ is greater than or equal to the threshold $t$, and as low-quality otherwise. The analysis is based on a two-component Gaussian mixture model for the distribution of $s$.\n\nFirst, we must perform a validation of the problem statement.\n\nStep 1: Extract Givens\n- Quality control metrics definitions:\n  - Mitochondrial read fraction: $f_{\\mathrm{mt},i} = \\frac{c_{i,\\mathrm{mt}}}{c_{i,\\mathrm{tot}}}$ where $c_{i,\\mathrm{tot}} = \\sum_{j} c_{ij}$.\n  - Number of detected genes: $g_i = \\sum_{j} \\mathbf{1}\\{c_{ij} > 0\\}$.\n  - Total UMI count: $u_i = \\sum_{j} c_{ij}$.\n- Scalar summary score: $s_i = \\ln(1+u_i) + \\ln(1+g_i) - 4\\, f_{\\mathrm{mt},i}$.\n- Latent class conditional distributions for the score $s$:\n  - Low-quality cells: $s \\mid \\mathrm{L} \\sim \\mathcal{N}(\\mu_{\\mathrm{L}}, \\sigma^2)$.\n  - High-quality cells: $s \\mid \\mathrm{H} \\sim \\mathcal{N}(\\mu_{\\mathrm{H}}, \\sigma^2)$.\n- Prior class probabilities: $\\pi_{\\mathrm{L}}$ and $\\pi_{\\mathrm{H}} = 1 - \\pi_{\\mathrm{L}}$.\n- Specific parameter values:\n  - $\\mu_{\\mathrm{L}} = 6.0$\n  - $\\mu_{\\mathrm{H}} = 10.5$\n  - $\\sigma = 0.8$\n  - $\\pi_{\\mathrm{L}} = 0.35$\n  - $\\pi_{\\mathrm{H}} = 0.65$\n- Decision criterion: Bayes-optimal decision rule under a $0$–$1$ loss function with equal misclassification costs.\n- Decision rule structure: Classify as $\\mathrm{H}$ if $s \\ge t$, and as $\\mathrm{L}$ if $s < t$.\n\nStep 2: Validate Using Extracted Givens\nThe problem is scientifically grounded, as it uses standard quality control metrics and modeling approaches (Gaussian mixture models) from the field of single-cell transcriptomics. It is well-posed, providing all necessary parameters and a clear objective rooted in statistical decision theory. The language is objective and precise. The problem is self-contained and mathematically consistent. Therefore, the problem is deemed valid.\n\nStep 3: Verdict and Action\nThe problem is valid. We proceed to the solution.\n\nThe objective is to find the decision threshold $t$ that minimizes the probability of misclassification. For a $0$-$1$ loss function with equal misclassification costs, the Bayes-optimal decision rule is to assign an observation $s$ to the class with the highest posterior probability. The decision rule is to classify as $\\mathrm{H}$ if $P(\\mathrm{H}|s) > P(\\mathrm{L}|s)$ and as $\\mathrm{L}$ if $P(\\mathrm{L}|s) > P(\\mathrm{H}|s)$. The decision threshold $t$ is the value of $s$ where these posterior probabilities are equal:\n$$\nP(\\mathrm{H}|s=t) = P(\\mathrm{L}|s=t)\n$$\nUsing Bayes' rule, the posterior probability for a class $C \\in \\{\\mathrm{L}, \\mathrm{H}\\}$ is given by $P(C|s) = \\frac{p(s|C)P(C)}{p(s)}$, where $p(s|C)$ is the class-conditional probability density (the likelihood), $P(C)$ is the prior probability of the class, and $p(s)$ is the marginal density of $s$. In our notation, $P(C)$ corresponds to $\\pi_C$.\n\nThe equality of posteriors at $s=t$ implies:\n$$\n\\frac{p(t|\\mathrm{H})\\pi_{\\mathrm{H}}}{p(t)} = \\frac{p(t|\\mathrm{L})\\pi_{\\mathrm{L}}}{p(t)}\n$$\nThe marginal density $p(t)$ is non-zero and cancels, yielding an equality between the likelihoods weighted by the priors:\n$$\np(t|\\mathrm{H})\\pi_{\\mathrm{H}} = p(t|\\mathrm{L})\\pi_{\\mathrm{L}}\n$$\nThe problem states that the class-conditional distributions are Gaussian with equal variance: $s \\mid \\mathrm{H} \\sim \\mathcal{N}(\\mu_{\\mathrm{H}}, \\sigma^2)$ and $s \\mid \\mathrm{L} \\sim \\mathcal{N}(\\mu_{\\mathrm{L}}, \\sigma^2)$. The probability density function (PDF) for a Gaussian distribution $\\mathcal{N}(\\mu, \\sigma^2)$ is $p(x) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}} \\exp\\left(-\\frac{(x-\\mu)^2}{2\\sigma^2}\\right)$. Substituting the PDFs into our equation gives:\n$$\n\\left(\\frac{1}{\\sqrt{2\\pi\\sigma^2}} \\exp\\left(-\\frac{(t-\\mu_{\\mathrm{H}})^2}{2\\sigma^2}\\right)\\right) \\pi_{\\mathrm{H}} = \\left(\\frac{1}{\\sqrt{2\\pi\\sigma^2}} \\exp\\left(-\\frac{(t-\\mu_{\\mathrm{L}})^2}{2\\sigma^2}\\right)\\right) \\pi_{\\mathrm{L}}\n$$\nThe normalization constant $\\frac{1}{\\sqrt{2\\pi\\sigma^2}}$ is identical on both sides and cancels out. We are left with:\n$$\n\\exp\\left(-\\frac{(t-\\mu_{\\mathrm{H}})^2}{2\\sigma^2}\\right) \\pi_{\\mathrm{H}} = \\exp\\left(-\\frac{(t-\\mu_{\\mathrm{L}})^2}{2\\sigma^2}\\right) \\pi_{\\mathrm{L}}\n$$\nTo solve for $t$, we take the natural logarithm of both sides:\n$$\n\\ln\\left(\\exp\\left(-\\frac{(t-\\mu_{\\mathrm{H}})^2}{2\\sigma^2}\\right) \\pi_{\\mathrm{H}}\\right) = \\ln\\left(\\exp\\left(-\\frac{(t-\\mu_{\\mathrm{L}})^2}{2\\sigma^2}\\right) \\pi_{\\mathrm{L}}\\right)\n$$\n$$\n-\\frac{(t-\\mu_{\\mathrm{H}})^2}{2\\sigma^2} + \\ln(\\pi_{\\mathrm{H}}) = -\\frac{(t-\\mu_{\\mathrm{L}})^2}{2\\sigma^2} + \\ln(\\pi_{\\mathrm{L}})\n$$\nRearranging the terms to isolate $t$:\n$$\n\\frac{(t-\\mu_{\\mathrm{L}})^2 - (t-\\mu_{\\mathrm{H}})^2}{2\\sigma^2} = \\ln(\\pi_{\\mathrm{L}}) - \\ln(\\pi_{\\mathrm{H}})\n$$\n$$\n(t-\\mu_{\\mathrm{L}})^2 - (t-\\mu_{\\mathrm{H}})^2 = 2\\sigma^2 \\ln\\left(\\frac{\\pi_{\\mathrm{L}}}{\\pi_{\\mathrm{H}}}\\right)\n$$\nExpanding the quadratic terms:\n$$\n(t^2 - 2t\\mu_{\\mathrm{L}} + \\mu_{\\mathrm{L}}^2) - (t^2 - 2t\\mu_{\\mathrm{H}} + \\mu_{\\mathrm{H}}^2) = 2\\sigma^2 \\ln\\left(\\frac{\\pi_{\\mathrm{L}}}{\\pi_{\\mathrm{H}}}\\right)\n$$\n$$\n2t\\mu_{\\mathrm{H}} - 2t\\mu_{\\mathrm{L}} + \\mu_{\\mathrm{L}}^2 - \\mu_{\\mathrm{H}}^2 = 2\\sigma^2 \\ln\\left(\\frac{\\pi_{\\mathrm{L}}}{\\pi_{\\mathrm{H}}}\\right)\n$$\n$$\n2t(\\mu_{\\mathrm{H}} - \\mu_{\\mathrm{L}}) = \\mu_{\\mathrm{H}}^2 - \\mu_{\\mathrm{L}}^2 + 2\\sigma^2 \\ln\\left(\\frac{\\pi_{\\mathrm{L}}}{\\pi_{\\mathrm{H}}}\\right)\n$$\nFactoring the difference of squares $\\mu_{\\mathrm{H}}^2 - \\mu_{\\mathrm{L}}^2 = (\\mu_{\\mathrm{H}} - \\mu_{\\mathrm{L}})(\\mu_{\\mathrm{H}} + \\mu_{\\mathrm{L}})$ and dividing by $2(\\mu_{\\mathrm{H}} - \\mu_{\\mathrm{L}})$ (since $\\mu_{\\mathrm{H}} \\neq \\mu_{\\mathrm{L}}$):\n$$\nt = \\frac{(\\mu_{\\mathrm{H}} - \\mu_{\\mathrm{L}})(\\mu_{\\mathrm{H}} + \\mu_{\\mathrm{L}})}{2(\\mu_{\\mathrm{H}} - \\mu_{\\mathrm{L}})} + \\frac{2\\sigma^2}{2(\\mu_{\\mathrm{H}} - \\mu_{\\mathrm{L}})} \\ln\\left(\\frac{\\pi_{\\mathrm{L}}}{\\pi_{\\mathrm{H}}}\\right)\n$$\nThis simplifies to the general expression for the threshold:\n$$\nt = \\frac{\\mu_{\\mathrm{H}} + \\mu_{\\mathrm{L}}}{2} + \\frac{\\sigma^2}{\\mu_{\\mathrm{H}} - \\mu_{\\mathrm{L}}} \\ln\\left(\\frac{\\pi_{\\mathrm{L}}}{\\pi_{\\mathrm{H}}}\\right)\n$$\nNow, we substitute the given numerical values: $\\mu_{\\mathrm{L}} = 6.0$, $\\mu_{\\mathrm{H}} = 10.5$, $\\sigma = 0.8$, $\\pi_{\\mathrm{L}} = 0.35$, and $\\pi_{\\mathrm{H}} = 0.65$.\n$$\nt = \\frac{10.5 + 6.0}{2} + \\frac{(0.8)^2}{10.5 - 6.0} \\ln\\left(\\frac{0.35}{0.65}\\right)\n$$\n$$\nt = \\frac{16.5}{2} + \\frac{0.64}{4.5} \\ln\\left(\\frac{7}{13}\\right)\n$$\n$$\nt = 8.25 + \\frac{0.64}{4.5} \\ln\\left(\\frac{7}{13}\\right)\n$$\nWe now compute the numerical value:\n$$\n\\ln\\left(\\frac{7}{13}\\right) \\approx -0.6190392\n$$\n$$\n\\frac{0.64}{4.5} \\approx 0.1422222\n$$\n$$\nt \\approx 8.25 + (0.1422222) \\times (-0.6190392)\n$$\n$$\nt \\approx 8.25 - 0.0880354\n$$\n$$\nt \\approx 8.1619646\n$$\nThe problem requires the answer to be rounded to $4$ significant figures.\n$$\nt \\approx 8.162\n$$\nThe resulting threshold $t$ is the boundary value for the score $s$. Any cell with $s \\ge 8.162$ will be classified as high-quality, and any cell with $s < 8.162$ will be classified as low-quality, in accordance with the Bayes-optimal decision rule.", "answer": "$$\n\\boxed{8.162}\n$$", "id": "2851235"}, {"introduction": "Single-cell transcriptomics offers more than just static catalogs of cell states; it provides a powerful lens for observing dynamic biological processes like differentiation and response to stimuli. Modeling these dynamics requires moving beyond simple statistical comparisons to mechanistic models of gene regulation. This advanced practice introduces a framework for inferring transcriptional dynamics by combining an ordinary differential equation (ODE) model of gene expression with the principles of optimal transport (OT). This exercise provides hands-on experience with a cutting-edge computational approach, illustrating how to construct and solve a dynamic model to extract otherwise hidden biological parameters from scRNA-seq data. [@problem_id:2851200]", "problem": "You are tasked with modeling transcriptional responses to a stimulus in a single-cell RNA snapshot experiment using a principled dynamical and transport-based approach. You will work with a one-gene model in which the mature messenger RNA abundance per cell, denoted by $m(t)$, evolves according to an Ordinary Differential Equation (ODE) driven by a time-varying transcription (production) rate $\\alpha(t)$ and a first-order degradation rate $\\delta$. The model is\n$$\n\\frac{dm}{dt} \\;=\\; \\alpha(t) \\;-\\; \\delta\\, m(t).\n$$\nYou are given time-stamped single-cell snapshots at discrete time points $t_0 < t_1 < \\dots < t_K$, where within each interval $[t_k,t_{k+1}]$ the transcription rate is assumed to be constant, that is $\\alpha(t)=\\alpha_k$ for $t\\in[t_k,t_{k+1}]$. Your goal is to estimate the piecewise-constant transcription rate values $\\alpha_k$ from the time-stamped snapshots, using the following constraints and principles.\n\nFoundational base and assumptions:\n- Central Dogma of Molecular Biology and the standard gene expression model motivate the ODE above, with $\\alpha(t)$ capturing promoter activity and $\\delta$ capturing first-order decay of transcripts.\n- Deterministic dynamics in one dimension and conservation of probability mass imply that the population evolves via a monotone map on $m$, so that the Optimal Transport (OT) coupling between the distributions at two times in one dimension is the monotone rearrangement that matches equal quantiles.\n- For each interval $[t_k,t_{k+1}]$, the exact ODE solution with constant $\\alpha_k$ is consistent with an increasing affine map on $m$.\n\nMathematical and algorithmic requirements:\n- Work purely from distributions of $m$ at the discrete time points, with no lineage tracking between cells. Use one-dimensional Optimal Transport (OT) to couple $m(t_k)$ to $m(t_{k+1})$ by matching equal quantiles. Implement the monotone transport map numerically by sorting samples and, if sample sizes differ, using linear interpolation of empirical quantiles.\n- Combine the ODE and the OT pairing to derive a mathematically consistent estimator for the interval-wise transcription rate $\\alpha_k$ in terms of the paired values between $t_k$ and $t_{k+1}$, the known degradation rate $\\delta$, and the time step $\\Delta t_k = t_{k+1}-t_k$. Your estimator must be exact in the noiseless case implied by the ODE solution and the monotone coupling.\n- All time units are hours, $m$ is measured in molecules per cell, $\\alpha$ is measured in molecules per cell per hour, and $\\delta$ is measured in per hour.\n\nData generation protocol for the test suite (to be implemented inside your program, with no randomness):\n- For each test case, generate an initial snapshot at $t_0$ by deterministically sampling from a Gamma distribution using evenly spaced quantiles. For a Gamma distribution with shape parameter $k$ and scale parameter $\\theta$ and sample size $N$, define quantiles $q_i = \\frac{i+\\tfrac{1}{2}}{N}$ for $i \\in \\{0,1,\\dots,N-1\\}$ and set $m_i(t_0)$ to the inverse cumulative distribution function at $q_i$. This yields a deterministic, sorted set of initial values without stochastic noise.\n- For each interval $[t_k,t_{k+1}]$ with constant $\\alpha_k$, propagate each cell deterministically under the ODE to obtain $m_i(t_{k+1})$ from $m_i(t_k)$ using the exact closed-form solution of the ODE on that interval. This ensures a scientifically sound, noise-free ground truth that respects the model.\n- Using only the snapshots $m(t_k)$ and $m(t_{k+1})$ and the known $\\delta$ and $\\Delta t_k$, estimate $\\alpha_k$ via one-dimensional OT coupling and your derived estimator.\n\nYour program must compute, for each test case, the maximum absolute estimation error across all intervals, namely\n$$\n\\max_{k \\in \\{0,\\dots,K-1\\}} \\left|\\widehat{\\alpha}_k - \\alpha_k\\right|,\n$$\nand output these errors as floating-point numbers. The errors have units of molecules per cell per hour, but your output should contain numeric values only, with no unit strings.\n\nTest suite (implement exactly the following three cases):\n- Case $1$ (general dynamics):\n  - Times: $t = [\\,0,\\,1,\\,2.5\\,]$ so $\\Delta t_0 = 1$ and $\\Delta t_1 = 1.5$.\n  - Degradation: $\\delta = 0.2$ per hour.\n  - True transcription rates: $\\alpha = [\\,2.0,\\,0.5\\,]$ molecules per cell per hour.\n  - Initial distribution: Gamma with shape $k = 2.0$, scale $\\theta = 1.0$.\n  - Sample size: $N = 200$ cells.\n\n- Case $2$ (no degradation boundary):\n  - Times: $t = [\\,0,\\,0.5,\\,1.0,\\,1.5\\,]$ so each $\\Delta t_k = 0.5$.\n  - Degradation: $\\delta = 0$ per hour.\n  - True transcription rates: $\\alpha = [\\,1.5,\\,1.5,\\,1.5\\,]$ molecules per cell per hour.\n  - Initial distribution: Gamma with shape $k = 0.5$, scale $\\theta = 2.0$.\n  - Sample size: $N = 200$ cells.\n\n- Case $3$ (short interval and fast decay):\n  - Times: $t = [\\,0,\\,0.05,\\,0.2\\,]$ so $\\Delta t_0 = 0.05$ and $\\Delta t_1 = 0.15$.\n  - Degradation: $\\delta = 1.0$ per hour.\n  - True transcription rates: $\\alpha = [\\,0.0,\\,4.0\\,]$ molecules per cell per hour.\n  - Initial distribution: Gamma with shape $k = 5.0$, scale $\\theta = 0.5$.\n  - Sample size: $N = 200$ cells.\n\nFinal output specification:\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, for example $[x_1,x_2,x_3]$, where $x_j$ is the maximum absolute estimation error for test case $j$.\n- Each $x_j$ must be a floating-point number. You may round to a fixed number of decimal places for readability, but the output must contain only the numeric list on one line and no additional text.", "solution": "The problem proposed is scientifically and mathematically valid. It is well-posed, self-contained, and grounded in the established principles of gene expression kinetics and computational single-cell biology. It presents a non-trivial task of deriving and implementing an estimator for transcription rates from snapshot data. I will proceed with a full solution.\n\nThe core of the problem is to estimate the piecewise-constant transcription rate $\\alpha_k$ for a series of time intervals $[t_k, t_{k+1}]$. The estimation must leverage two key pieces of information: the governing Ordinary Differential Equation (ODE) for messenger RNA (mRNA) abundance, $m(t)$, and the principle of one-dimensional Optimal Transport (OT) to couple cell populations between time points.\n\nFirst, we analyze the governing ODE for a single interval $[t_k, t_{k+1}]$, where the transcription rate $\\alpha(t)$ is a constant $\\alpha_k$ and the degradation rate is $\\delta$:\n$$\n\\frac{dm(t)}{dt} = \\alpha_k - \\delta m(t)\n$$\nThis is a standard first-order linear ODE. We solve it with the initial condition $m(t_k)$ to find the state at $t_{k+1}$. Let $\\Delta t_k = t_{k+1} - t_k$. The solution is found using an integrating factor, $e^{\\delta t}$.\n\nFor the case $\\delta > 0$:\n$$\nm(t_{k+1}) = m(t_k) e^{-\\delta \\Delta t_k} + \\frac{\\alpha_k}{\\delta} (1 - e^{-\\delta \\Delta t_k})\n$$\nThis equation reveals that the mRNA abundance at time $t_{k+1}$ is an increasing affine function of the abundance at time $t_k$. This deterministic evolution implies that the ordering of cells by their mRNA abundance is preserved over time, provided no new cells are introduced.\n\nFor the special case where there is no degradation, $\\delta = 0$, the ODE simplifies to $\\frac{dm}{dt} = \\alpha_k$. The solution is:\n$$\nm(t_{k+1}) = m(t_k) + \\alpha_k \\Delta t_k\n$$\nThis is also an increasing affine function of $m(t_k)$.\n\nNext, we incorporate the principle of one-dimensional Optimal Transport. The problem states that the coupling between the distributions of $m$ at $t_k$ and $t_{k+1}$ is a monotone rearrangement matching equal quantiles. For two empirical distributions of the same size $N$, $\\{m_i(t_k)\\}_{i=0}^{N-1}$ and $\\{m_j(t_{k+1})\\}_{j=0}^{N-1}$, this corresponds to sorting both sets of measurements and pairing the $i$-th value of the sorted first set with the $i$-th value of the sorted second set. Since the data generation protocol ensures that the population at $t_{k+1}$ is a deterministic evolution of the population at $t_k$, the population sizes are identical and the cells are already correctly ordered if we maintain their indices. Thus, the OT pairing for cell $i$ is simply $(m_i(t_k), m_i(t_{k+1}))$.\n\nSince the ODE solution holds for each cell $i$, it must also hold for the average over the entire population. Taking the expectation (or sample mean, denoted by $\\bar{m}$) of the ODE solution gives a relationship between the mean abundances at the start and end of the interval.\n\nFor $\\delta > 0$, we have:\n$$\n\\bar{m}(t_{k+1}) = \\bar{m}(t_k) e^{-\\delta \\Delta t_k} + \\frac{\\alpha_k}{\\delta} (1 - e^{-\\delta \\Delta t_k})\n$$\nWe can rearrange this equation to solve for $\\alpha_k$, which yields our estimator $\\widehat{\\alpha}_k$. This is a robust approach as it averages over all cells, reducing the impact of potential noise in a real-world scenario.\n$$\n\\bar{m}(t_{k+1}) - \\bar{m}(t_k) e^{-\\delta \\Delta t_k} = \\frac{\\alpha_k}{\\delta} (1 - e^{-\\delta \\Delta t_k})\n$$\n$$\n\\widehat{\\alpha}_k = \\frac{\\delta \\left( \\bar{m}(t_{k+1}) - \\bar{m}(t_k) e^{-\\delta \\Delta t_k} \\right)}{1 - e^{-\\delta \\Delta t_k}}\n$$\nFor $\\delta = 0$, the relationship for the means is:\n$$\n\\bar{m}(t_{k+1}) = \\bar{m}(t_k) + \\alpha_k \\Delta t_k\n$$\nSolving for $\\alpha_k$ gives the estimator for the zero-degradation case:\n$$\n\\widehat{\\alpha}_k = \\frac{\\bar{m}(t_{k+1}) - \\bar{m}(t_k)}{\\Delta t_k}\n$$\nThis estimator can also be obtained by taking the limit $\\delta \\to 0$ of the general formula using L'Hôpital's rule.\n\nThe computational procedure is as follows:\n1.  For each test case, define the parameters: time points $\\{t_k\\}$, degradation rate $\\delta$, true transcription rates $\\{\\alpha_k\\}$, initial Gamma distribution parameters ($k, \\theta$), and sample size $N$.\n2.  Generate the initial population snapshot $m(t_0)$ of size $N$ by deterministically sampling the inverse cumulative distribution function (PPF) of the specified Gamma distribution at evenly spaced quantiles $q_i = \\frac{i+1/2}{N}$ for $i \\in \\{0, \\dots, N-1\\}$.\n3.  Iterate through the time intervals $[t_k, t_{k+1}]$ for $k = 0, \\dots, K-1$.\n    a.  Let the current snapshot be $m(t_k)$. Use the true transcription rate $\\alpha_k$ for this interval and the known degradation rate $\\delta$ to deterministically propagate each cell's mRNA count to $t_{k+1}$ using the exact ODE solution. This generates the snapshot $m(t_{k+1})$.\n    b.  Using only the snapshots $m(t_k)$ and $m(t_{k+1})$, the time step $\\Delta t_k$, and $\\delta$, calculate the estimated transcription rate $\\widehat{\\alpha}_k$ using the derived estimator based on the sample means.\n    c.  Compute the absolute error $|\\widehat{\\alpha}_k - \\alpha_k|$.\n4.  After iterating through all intervals, find the maximum absolute error for the test case.\n5.  Repeat this process for all test cases and report the maximum errors.\n\nSince the data generation process follows the exact same mathematical model that the estimator is derived from, the estimated rate $\\widehat{\\alpha}_k$ should be identical to the true rate $\\alpha_k$ up to the limits of floating-point precision. The final error is therefore expected to be close to zero. This serves as a rigorous verification of the derived method.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.stats import gamma\n\ndef solve():\n    \"\"\"\n    Solves for the maximum absolute estimation error of transcription rates\n    for a set of test cases based on a 1D ODE model of gene expression.\n    \"\"\"\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        {\n            \"times\": [0.0, 1.0, 2.5],\n            \"delta\": 0.2,\n            \"alphas\": [2.0, 0.5],\n            \"gamma_k\": 2.0,\n            \"gamma_theta\": 1.0,\n            \"N\": 200,\n        },\n        {\n            \"times\": [0.0, 0.5, 1.0, 1.5],\n            \"delta\": 0.0,\n            \"alphas\": [1.5, 1.5, 1.5],\n            \"gamma_k\": 0.5,\n            \"gamma_theta\": 2.0,\n            \"N\": 200,\n        },\n        {\n            \"times\": [0.0, 0.05, 0.2],\n            \"delta\": 1.0,\n            \"alphas\": [0.0, 4.0],\n            \"gamma_k\": 5.0,\n            \"gamma_theta\": 0.5,\n            \"N\": 200,\n        },\n    ]\n\n    def propagate_snapshot(m_initial, alpha, delta, dt):\n        \"\"\"\n        Propagates an mRNA distribution snapshot forward in time using the exact ODE solution.\n        \"\"\"\n        if delta > 0:\n            exp_term = np.exp(-delta * dt)\n            m_final = m_initial * exp_term + (alpha / delta) * (1 - exp_term)\n        else: # delta == 0\n            m_final = m_initial + alpha * dt\n        return m_final\n\n    def estimate_alpha(m_initial, m_final, delta, dt):\n        \"\"\"\n        Estimates the transcription rate alpha from two snapshots.\n        \"\"\"\n        mean_initial = np.mean(m_initial)\n        mean_final = np.mean(m_final)\n\n        if delta > 0:\n            exp_term = np.exp(-delta * dt)\n            # To avoid potential division by zero if 1-exp_term is too small,\n            # although not strictly necessary for the given test cases.\n            if 1 - exp_term == 0:\n                 # Fallback to the delta=0 case via Taylor expansion\n                 return (mean_final - mean_initial) / dt\n            \n            estimated_alpha = (delta * (mean_final - mean_initial * exp_term)) / (1 - exp_term)\n        else: # delta == 0\n            estimated_alpha = (mean_final - mean_initial) / dt\n        \n        return estimated_alpha\n\n    max_errors = []\n\n    for case in test_cases:\n        t_points = case[\"times\"]\n        delta_rate = case[\"delta\"]\n        alpha_rates = case[\"alphas\"]\n        gamma_k = case[\"gamma_k\"]\n        gamma_theta = case[\"gamma_theta\"]\n        N = case[\"N\"]\n\n        # Generate initial snapshot at t_0\n        quantiles = (np.arange(N) + 0.5) / N\n        m_current = gamma.ppf(quantiles, a=gamma_k, scale=gamma_theta)\n        \n        errors_for_case = []\n        \n        # Iterate through each time interval\n        for i in range(len(alpha_rates)):\n            t_k = t_points[i]\n            t_k_plus_1 = t_points[i+1]\n            dt = t_k_plus_1 - t_k\n            true_alpha = alpha_rates[i]\n            \n            # 1. Generate ground truth data for the next snapshot\n            m_next = propagate_snapshot(m_current, true_alpha, delta_rate, dt)\n            \n            # 2. Estimate alpha_k from the two snapshots m_current and m_next\n            estimated_alpha = estimate_alpha(m_current, m_next, delta_rate, dt)\n            \n            # 3. Calculate and store the estimation error\n            error = np.abs(estimated_alpha - true_alpha)\n            errors_for_case.append(error)\n            \n            # 4. Update the current snapshot for the next iteration\n            m_current = m_next\n            \n        max_errors.append(np.max(errors_for_case))\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(f'{err:.16f}' for err in max_errors)}]\")\n\nsolve()\n```", "id": "2851200"}]}