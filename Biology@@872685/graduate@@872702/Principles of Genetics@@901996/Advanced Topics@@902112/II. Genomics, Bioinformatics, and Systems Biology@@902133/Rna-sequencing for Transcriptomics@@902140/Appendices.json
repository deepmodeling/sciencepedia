{"hands_on_practices": [{"introduction": "The foundation of any robust transcriptomic analysis is high-quality sequencing data. The Phred quality score, or $Q$ score, is the universal language sequencers use to report the confidence in each base call. This first exercise provides hands-on practice in translating these logarithmic scores back into tangible error probabilities, allowing you to quantify the expected accuracy of your raw reads from first principles [@problem_id:2848935].", "problem": "A laboratory performs Ribonucleic Acid sequencing (RNA-seq) on a eukaryotic transcriptome, generating single-end reads of length $L=150$ nucleotides. The sequencer reports the following per-cycle base-calling quality summary for the dataset: for cycles $1$ through $60$, the median Phred quality is $Q=36$; for cycles $61$ through $120$, the median Phred quality is $Q=32$; and for cycles $121$ through $150$, the median Phred quality is $Q=25$. Assume that for the purpose of this calculation, each position within a given cycle range has the stated Phred quality score.\n\nUsing only standard definitions and principles that connect Phred quality scores to base-call error probabilities and expectations, derive from first principles:\n- the expected base-call error rate per base for this read, averaged across all $L=150$ positions; and\n- the expected number of base-calling errors per read.\n\nReport your final answer as a single real number equal to the expected number of base-calling errors per read, expressed as a decimal (not a percentage), rounded to four significant figures. No units are required.", "solution": "The problem statement is evaluated and found to be valid. It is scientifically grounded in the standard principles of bioinformatics, specifically the Phred quality score used in DNA/RNA sequencing. The problem is well-posed, objective, and contains all necessary information to derive a unique solution. No contradictions, ambiguities, or logical flaws are present. We may proceed with the derivation.\n\nThe fundamental principle connecting the Phred quality score, $Q$, to the probability of an incorrect base call, $P$, is given by the definition:\n$$ Q = -10 \\log_{10}(P) $$\nFrom this definition, we must first derive the expression for the error probability $P$ as a function of $Q$. Rearranging the equation, we find:\n$$ P = 10^{-Q/10} $$\nThis probability, $P$, represents the expected error rate for a single base call with quality score $Q$.\n\nThe problem specifies a read of total length $L=150$ nucleotides, which is partitioned into three segments, each with a constant median Phred quality score. Let us denote the length of segment $i$ as $n_i$ and its quality score as $Q_i$.\nFor the first segment (cycles $1-60$):\nThe number of bases is $n_1 = 60 - 1 + 1 = 60$.\nThe Phred quality score is $Q_1 = 36$.\nThe probability of error per base in this segment is $P_1 = 10^{-Q_1/10} = 10^{-36/10} = 10^{-3.6}$.\n\nFor the second segment (cycles $61-120$):\nThe number of bases is $n_2 = 120 - 61 + 1 = 60$.\nThe Phred quality score is $Q_2 = 32$.\nThe probability of error per base in this segment is $P_2 = 10^{-Q_2/10} = 10^{-32/10} = 10^{-3.2}$.\n\nFor the third segment (cycles $121-150$):\nThe number of bases is $n_3 = 150 - 121 + 1 = 30$.\nThe Phred quality score is $Q_3 = 25$.\nThe probability of error per base in this segment is $P_3 = 10^{-Q_3/10} = 10^{-25/10} = 10^{-2.5}$.\nThe total length of the read is indeed $L = n_1 + n_2 + n_3 = 60 + 60 + 30 = 150$, which is consistent with the provided information.\n\nThe expected number of errors in a sequence of base calls is governed by the principle of linearity of expectation. If we define an indicator random variable $X_i$ for each position $i$ in the read, such that $X_i=1$ if an error occurs and $X_i=0$ otherwise, then the expected value of $X_i$ is $E[X_i] = (1 \\cdot P(X_i=1)) + (0 \\cdot P(X_i=0)) = p_i$, where $p_i$ is the error probability at position $i$. The total expected number of errors for the entire read, $E_{read}$, is the sum of the individual expectations:\n$$ E_{\\text{read}} = \\sum_{i=1}^{L} E[X_i] = \\sum_{i=1}^{L} p_i $$\nApplying this to our segmented model, we sum the constant error probabilities over their respective segments:\n$$ E_{\\text{read}} = \\sum_{i=1}^{60} P_1 + \\sum_{i=61}^{120} P_2 + \\sum_{i=121}^{150} P_3 $$\nThis simplifies to the sum of the products of the number of bases and the error probability for each segment:\n$$ E_{\\text{read}} = n_1 P_1 + n_2 P_2 + n_3 P_3 $$\nThis is the expression for the expected number of base-calling errors per read.\n\nThe first requested quantity, the expected base-call error rate per base for the read, averaged across all positions, $\\bar{P}$, is the total expected number of errors divided by the total length of the read:\n$$ \\bar{P} = \\frac{E_{\\text{read}}}{L} = \\frac{n_1 P_1 + n_2 P_2 + n_3 P_3}{L} $$\nThe second requested quantity is $E_{read}$ itself. The problem asks for the numerical value of $E_{read}$.\n\nWe now substitute the specific values into the derived expression for $E_{read}$:\n$$ E_{\\text{read}} = 60 \\cdot 10^{-3.6} + 60 \\cdot 10^{-3.2} + 30 \\cdot 10^{-2.5} $$\nTo obtain the final numerical answer, we calculate the terms:\n$10^{-3.6} \\approx 0.0002511886$\n$10^{-3.2} \\approx 0.0006309573$\n$10^{-2.5} \\approx 0.0031622777$\nSubstituting these values:\n$$ E_{\\text{read}} \\approx 60 \\cdot (0.0002511886) + 60 \\cdot (0.0006309573) + 30 \\cdot (0.0031622777) $$\n$$ E_{\\text{read}} \\approx 0.015071316 + 0.037857438 + 0.094868331 $$\n$$ E_{\\text{read}} \\approx 0.147797085 $$\nThe problem requires this value to be rounded to four significant figures. The first significant figure is $1$ in the tenths place. The four significant figures are $1, 4, 7, 7$. The fifth significant figure is $9$, which requires rounding up the fourth digit.\nTherefore, the expected number of base-calling errors per read is approximately $0.1478$.", "answer": "$$\n\\boxed{0.1478}\n$$", "id": "2848935"}, {"introduction": "Once raw reads are processed into a gene-count matrix, the central challenge becomes identifying true biological changes amidst technical and biological noise. The Negative Binomial ($NB$) Generalized Linear Model (GLM) is the statistical workhorse for this task, elegantly modeling count data while accounting for library size differences and overdispersion. This practice challenges you to implement the core algorithm for fitting an NB-GLM, giving you a deep, mechanistic understanding of how differential expression is statistically determined [@problem_id:2848955].", "problem": "You are given independent gene-level RNA-sequencing (RNA-seq) read counts and a linear design with covariates. Assume the Central Dogma of Molecular Biology and the standard model for RNA-sequencing count data: conditional on covariates and library size, the observed read counts for a gene across samples are realizations of a Negative Binomial (NB) generalized linear model (GLM) with a log link, where the mean depends on sample-specific library size factors via an offset. Your task is to implement estimation and inference from first principles using the iteratively reweighted least squares algorithm and Wald statistics.\n\nUse the following foundational base:\n- The Central Dogma of Molecular Biology implies that messenger ribonucleic acid (mRNA) abundance is a proxy for gene expression, and RNA-sequencing read counts are proportional to abundance after adjusting for library size.\n- In the Negative Binomial GLM with NB2 variance parameterization, conditional on covariates, the variance is $V(Y_i) = \\mu_i + \\alpha \\mu_i^2$ for dispersion $\\alpha > 0$.\n- With a log link and offset, the mean satisfies $\\log \\mu_i = o_i + \\boldsymbol{x}_i^\\top \\boldsymbol{\\beta}$, where $o_i = \\log s_i$ is the known offset from the library size factor $s_i > 0$, $\\boldsymbol{x}_i$ is the covariate vector for sample $i$, and $\\boldsymbol{\\beta}$ are regression coefficients.\n- For a specified contrast vector $\\boldsymbol{c}$, the Wald statistic is computed from the estimated coefficient vector $\\hat{\\boldsymbol{\\beta}}$ and its covariance $\\widehat{\\mathrm{Var}}(\\hat{\\boldsymbol{\\beta}})$ as $Z = \\dfrac{\\boldsymbol{c}^\\top \\hat{\\boldsymbol{\\beta}}}{\\sqrt{\\boldsymbol{c}^\\top \\widehat{\\mathrm{Var}}(\\hat{\\boldsymbol{\\beta}})\\, \\boldsymbol{c}}}$, with a two-sided p-value obtained from the standard normal distribution.\n\nImplement the following algorithmic design:\n- Use iteratively reweighted least squares for the Negative Binomial GLM with log link and offset:\n  - At iteration $t$, given $\\boldsymbol{\\beta}^{(t)}$, compute $\\eta_i^{(t)} = o_i + \\boldsymbol{x}_i^\\top \\boldsymbol{\\beta}^{(t)}$, $\\mu_i^{(t)} = \\exp(\\eta_i^{(t)})$.\n  - Define weights $w_i^{(t)} = \\dfrac{\\mu_i^{(t)}}{1 + \\alpha \\mu_i^{(t)}}$ and the pseudo-response $z_i^{(t)} = \\eta_i^{(t)} + \\dfrac{y_i - \\mu_i^{(t)}}{\\mu_i^{(t)}}$.\n  - Update $\\boldsymbol{\\beta}^{(t+1)}$ by solving the weighted least squares normal equations $\\left(\\boldsymbol{X}^\\top \\boldsymbol{W}^{(t)} \\boldsymbol{X}\\right) \\boldsymbol{\\beta}^{(t+1)} = \\boldsymbol{X}^\\top \\boldsymbol{W}^{(t)} \\boldsymbol{z}^{(t)}$, where $\\boldsymbol{W}^{(t)}$ is diagonal with entries $w_i^{(t)}$.\n  - Iterate until convergence of $\\boldsymbol{\\beta}$ to a specified tolerance.\n- After convergence, use the model-based covariance estimate $\\widehat{\\mathrm{Var}}(\\hat{\\boldsymbol{\\beta}}) = \\left(\\boldsymbol{X}^\\top \\hat{\\boldsymbol{W}} \\boldsymbol{X}\\right)^{-1}$, where $\\hat{\\boldsymbol{W}}$ is evaluated at the converged mean.\n\nFor each test case below, fit the model, compute the Wald statistic for the treatment contrast, and interpret the sign of the estimated contrast. Report, for each test case, the following in order:\n- the estimated contrast value $\\hat{\\theta} = \\boldsymbol{c}^\\top \\hat{\\boldsymbol{\\beta}}$ (a float),\n- its standard error $\\widehat{\\mathrm{se}} = \\sqrt{\\boldsymbol{c}^\\top \\widehat{\\mathrm{Var}}(\\hat{\\boldsymbol{\\beta}})\\, \\boldsymbol{c}}$ (a float),\n- the Wald statistic $Z$ (a float),\n- the two-sided p-value under the standard normal distribution (a float),\n- a boolean interpretive indicator $\\mathrm{up}$ equal to true if and only if $\\hat{\\theta} > 0$.\n\nAll numerical answers must be computed according to the definitions above. There are no physical units in this problem. Angles do not appear. No percentages are required. The final output must be produced as a single line: a single list whose elements are the per-test-case result lists, printed as a comma-separated list enclosed in square brackets.\n\nTest suite. For every test case, the design matrix has three columns: an intercept, a treatment indicator, and a batch indicator. The contrast is always the treatment effect, that is $\\boldsymbol{c} = [\\,0,\\,1,\\,0\\,]^\\top$. For each case, you are given the counts vector $\\boldsymbol{y}$, the treatment vector $\\boldsymbol{T}$, the batch vector $\\boldsymbol{B}$, the positive library size factors $\\boldsymbol{s}$, and the dispersion $\\alpha$.\n\n- Case A (general, moderate counts, positive treatment effect):\n  - $\\boldsymbol{y} = [\\,16,\\,17,\\,23,\\,30,\\,45,\\,31\\,]$\n  - $\\boldsymbol{T} = [\\,0,\\,0,\\,0,\\,1,\\,1,\\,1\\,]$\n  - $\\boldsymbol{B} = [\\,0,\\,1,\\,0,\\,1,\\,0,\\,1\\,]$\n  - $\\boldsymbol{s} = [\\,0.8,\\,1.0,\\,1.2,\\,0.9,\\,1.1,\\,0.95\\,]$\n  - $\\alpha = 0.15$\n- Case B (near-null treatment effect, moderate counts):\n  - $\\boldsymbol{y} = [\\,12,\\,12,\\,13,\\,14,\\,12,\\,16\\,]$\n  - $\\boldsymbol{T} = [\\,0,\\,0,\\,0,\\,1,\\,1,\\,1\\,]$\n  - $\\boldsymbol{B} = [\\,0,\\,1,\\,0,\\,1,\\,0,\\,1\\,]$\n  - $\\boldsymbol{s} = [\\,1.0,\\,0.9,\\,1.1,\\,1.05,\\,0.95,\\,1.2\\,]$\n  - $\\alpha = 0.20$\n- Case C (larger sample, negative treatment effect, stronger batch):\n  - $\\boldsymbol{y} = [\\,19,\\,45,\\,27,\\,38,\\,13,\\,25,\\,15,\\,22\\,]$\n  - $\\boldsymbol{T} = [\\,0,\\,0,\\,0,\\,0,\\,1,\\,1,\\,1,\\,1\\,]$\n  - $\\boldsymbol{B} = [\\,0,\\,1,\\,0,\\,1,\\,0,\\,1,\\,0,\\,1\\,]$\n  - $\\boldsymbol{s} = [\\,0.7,\\,1.3,\\,1.0,\\,1.1,\\,0.8,\\,1.2,\\,0.9,\\,1.05\\,]$\n  - $\\alpha = 0.10$\n- Case D (small counts, high dispersion):\n  - $\\boldsymbol{y} = [\\,3,\\,4,\\,2,\\,3\\,]$\n  - $\\boldsymbol{T} = [\\,0,\\,1,\\,0,\\,1\\,]$\n  - $\\boldsymbol{B} = [\\,0,\\,0,\\,1,\\,1\\,]$\n  - $\\boldsymbol{s} = [\\,1.0,\\,0.8,\\,1.2,\\,1.1\\,]$\n  - $\\alpha = 1.00$\n\nConstruction of the design matrix: for each case, define $\\boldsymbol{X}$ as the $n \\times 3$ matrix with columns $\\boldsymbol{1}_n$, $\\boldsymbol{T}$, and $\\boldsymbol{B}$. Use offsets $o_i = \\log s_i$ for each sample $i$.\n\nRequired final output format:\n- For each case in the order A, B, C, D, output the list $[\\,\\hat{\\theta},\\,\\widehat{\\mathrm{se}},\\,Z,\\,p,\\,\\mathrm{up}\\,]$ where $\\hat{\\theta}$, $\\widehat{\\mathrm{se}}$, $Z$, and $p$ are floats rounded to six decimal places, and $\\mathrm{up}$ is a boolean.\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, with each element being the result list for a test case (e.g., \"[[...],[...],[...],[...]]\").", "solution": "The problem requires the implementation of a statistical procedure for analyzing RNA-sequencing (RNA-seq) count data. The validity of the problem statement is confirmed as it is scientifically grounded in established principles of transcriptomics and biostatistics, is well-posed with all necessary information provided, and is formulated objectively. The described model and algorithm are standard in the field of differential gene expression analysis.\n\nThe core of the problem is to fit a Negative Binomial (NB) Generalized Linear Model (GLM) to gene expression counts. The biological premise, rooted in the Central Dogma, is that mRNA abundance, measured by RNA-seq read counts, reflects gene expression levels. The count data $Y_i$ for each sample $i$ is modeled as a random variable following a Negative Binomial distribution.\n\nThe model specification is as follows:\nThe mean $\\mu_i = E[Y_i]$ is related to a set of covariates $\\boldsymbol{x}_i$ through a log link function, with an offset term $o_i$ to account for variations in library size (sequencing depth) across samples. The linear predictor $\\eta_i$ and the mean $\\mu_i$ are given by:\n$$ \\eta_i = \\boldsymbol{x}_i^\\top \\boldsymbol{\\beta} + o_i $$\n$$ \\mu_i = \\exp(\\eta_i) $$\nHere, $\\boldsymbol{\\beta}$ is the vector of regression coefficients to be estimated, and the offset $o_i$ is defined as the logarithm of the library size factor $s_i$, i.e., $o_i = \\log s_i$.\n\nThe variance of the NB distribution, under the NB2 parameterization, is related to the mean by:\n$$ V(Y_i) = \\mu_i + \\alpha \\mu_i^2 $$\nwhere $\\alpha > 0$ is the dispersion parameter, which captures biological and technical variability beyond what is expected from a Poisson model (where variance equals the mean). A fixed value of $\\alpha$ is provided for each test case.\n\nTo estimate the coefficient vector $\\boldsymbol{\\beta}$, we employ the Iteratively Reweighted Least Squares (IRLS) algorithm. IRLS is a numerical method that finds the Maximum Likelihood Estimate (MLE) of $\\boldsymbol{\\beta}$ by iteratively solving a series of weighted least squares (WLS) problems. The algorithm proceeds as follows:\n\n1.  **Initialization**: The algorithm starts with an initial guess for the coefficients, $\\boldsymbol{\\beta}^{(0)}$. A standard and simple choice is $\\boldsymbol{\\beta}^{(0)} = \\boldsymbol{0}$.\n\n2.  **Iteration**: At each iteration $t$, given the current estimate $\\boldsymbol{\\beta}^{(t-1)}$, we compute the following quantities for each sample $i=1, \\dots, n$:\n    -   The linear predictor: $\\eta_i^{(t-1)} = \\boldsymbol{x}_i^\\top \\boldsymbol{\\beta}^{(t-1)} + o_i$.\n    -   The fitted mean value: $\\mu_i^{(t-1)} = \\exp(\\eta_i^{(t-1)})$.\n    -   The pseudo-response or \"working dependent variable\": $z_i^{(t-1)} = \\eta_i^{(t-1)} + \\dfrac{y_i - \\mu_i^{(t-1)}}{\\mu_i^{(t-1)}}$. This linearizes the model around the current estimates.\n    -   The IRLS weights: $w_i^{(t-1)} = \\left( \\left(\\frac{\\partial \\mu_i}{\\partial \\eta_i}\\right)^2 V(Y_i)^{-1} \\right)_{\\boldsymbol{\\beta}^{(t-1)}} = \\dfrac{(\\mu_i^{(t-1)})^2}{\\mu_i^{(t-1)} + \\alpha (\\mu_i^{(t-1)})^2} = \\dfrac{\\mu_i^{(t-1)}}{1 + \\alpha \\mu_i^{(t-1)}}$. These weights are the inverse of the variance of the pseudo-response.\n\n3.  **Update**: A new estimate $\\boldsymbol{\\beta}^{(t)}$ is obtained by solving the WLS normal equations. Let $\\boldsymbol{X}$ be the $n \\times p$ design matrix, $\\boldsymbol{z}^{(t-1)}$ be the vector of pseudo-responses, and $\\boldsymbol{W}^{(t-1)}$ be the diagonal matrix of weights. The update is:\n    $$ \\boldsymbol{\\beta}^{(t)} = \\left(\\boldsymbol{X}^\\top \\boldsymbol{W}^{(t-1)} \\boldsymbol{X}\\right)^{-1} \\boldsymbol{X}^\\top \\boldsymbol{W}^{(t-1)} \\boldsymbol{z}^{(t-1)} $$\n\n4.  **Convergence**: Steps 2 and 3 are repeated until the change in $\\boldsymbol{\\beta}$ between successive iterations is below a specified tolerance, i.e., $||\\boldsymbol{\\beta}^{(t)} - \\boldsymbol{\\beta}^{(t-1)}||_2 < \\epsilon$. The converged vector is the MLE, $\\hat{\\boldsymbol{\\beta}}$.\n\nOnce the MLE $\\hat{\\boldsymbol{\\beta}}$ is obtained, we perform statistical inference on a specific linear combination of the coefficients, defined by a contrast vector $\\boldsymbol{c}$. In this problem, the contrast is $\\boldsymbol{c} = [\\,0,\\,1,\\,0\\,]^\\top$, which isolates the coefficient for the treatment effect. The estimated effect size is $\\hat{\\theta} = \\boldsymbol{c}^\\top \\hat{\\boldsymbol{\\beta}}$.\n\nTo test the null hypothesis $H_0: \\boldsymbol{c}^\\top \\boldsymbol{\\beta} = 0$, we use a Wald test. The Wald statistic requires the standard error of $\\hat{\\theta}$, which is derived from the covariance matrix of $\\hat{\\boldsymbol{\\beta}}$. The estimated covariance matrix is the inverse of the Fisher information matrix, evaluated at the MLE:\n$$ \\widehat{\\mathrm{Var}}(\\hat{\\boldsymbol{\\beta}}) = \\left(\\boldsymbol{X}^\\top \\hat{\\boldsymbol{W}} \\boldsymbol{X}\\right)^{-1} $$\nwhere $\\hat{\\boldsymbol{W}}$ is the weight matrix computed using the final converged mean values $\\hat{\\boldsymbol{\\mu}}$.\n\nThe standard error of the contrast is then:\n$$ \\widehat{\\mathrm{se}}(\\hat{\\theta}) = \\sqrt{\\boldsymbol{c}^\\top \\widehat{\\mathrm{Var}}(\\hat{\\boldsymbol{\\beta}})\\, \\boldsymbol{c}} $$\n\nThe Wald statistic $Z$ is computed as the ratio of the estimate to its standard error:\n$$ Z = \\frac{\\hat{\\theta}}{\\widehat{\\mathrm{se}}(\\hat{\\theta})} $$\n\nUnder the null hypothesis, $Z$ follows a standard normal distribution, $\\mathcal{N}(0, 1)$. The two-sided p-value is calculated as $p = 2 \\cdot P(N > |Z|)$, where $N \\sim \\mathcal{N}(0, 1)$.\n\nFinally, an indicator for the direction of the effect is generated: $\\mathrm{up}$ is true if $\\hat{\\theta} > 0$, indicating upregulation, and false otherwise. This entire procedure is applied to each test case provided.", "answer": "[[0.730335,0.380064,1.921588,0.054657,true],[0.126487,0.473551,0.267123,0.789379,true],[-0.609121,0.301633,-2.019411,0.043446,false],[0.032607,1.353396,0.024093,0.980779,true]]", "id": "2848955"}, {"introduction": "Effective experimental design is arguably the most critical factor for a successful RNA-seq study, and it often involves navigating a fundamental trade-off between the number of biological replicates and the sequencing depth per sample. This decision directly impacts statistical power, but must be made within the constraints of a finite budget. This final exercise places you in the role of a principal investigator, using power analysis to find the optimal experimental design that maximizes your ability to detect true biological effects [@problem_id:2848904].", "problem": "Design and implement a program that, for a balanced two-condition ribonucleic acid sequencing (RNA-seq) differential expression study, selects the optimal number of biological replicates per condition and the optimal per-sample sequencing depth to maximize statistical power under a fixed budget. The setting is grounded in the following fundamental and widely used modeling assumptions.\n\nStart from these core definitions and facts:\n- Central Dogma of Molecular Biology relates gene expression to messenger ribonucleic acid (mRNA) abundance; RNA-seq measures transcript abundance via read counts.\n- For a gene, the per-sample read count under a given condition is modeled as a random variable with expectation that scales linearly with sequencing depth. Let the baseline per-sample expected count at depth $d$ be $\\mu = d \\lambda$, where $\\lambda$ is the gene-specific expected count per unit depth and $d$ is the sequencing depth (in millions of reads per sample).\n- Overdispersion of RNA-seq counts relative to a Poisson model is captured by a Negative Binomial (NB) variance function. If $Y$ is the count for a sample with mean $\\mu$, then $\\mathrm{Var}(Y) = \\mu + \\phi \\mu^2$ where $\\phi \\ge 0$ is the overdispersion parameter.\n- A generalized linear model (GLM) with log link is used for a two-condition comparison. If the true fold-change between the two conditions is $f > 0$, then the true log effect is $\\beta^\\star = \\log(f)$, the control mean is $\\mu_A = d \\lambda$, and the treatment mean is $\\mu_B = f \\mu_A$.\n- A Wald test on the estimated log fold-change (from the NB-GLM) is used to test the null hypothesis of no differential expression; approximate test statistics are asymptotically Normal. Use a two-sided test at significance level $\\alpha \\in (0,1)$.\n\nBudget model and decision variables:\n- There are $r$ biological replicates per condition, for a total of $2r$ libraries (balanced design).\n- The cost per library (library preparation) is $C_{\\mathrm{lib}}$ monetary units, and the cost per million reads is $C_{\\mathrm{read}}$ monetary units.\n- The per-sample depth is $d$ (in millions of reads), identical across all samples.\n- The total budget constraint is $2 r \\left(C_{\\mathrm{lib}} + C_{\\mathrm{read}} d\\right) \\le B$.\n\nObjective:\n- For a given set of genes with baselines $\\{\\lambda_i\\}_{i=1}^G$, a specified overdispersion $\\phi$, a common true fold-change $f$ applied to the treatment condition, and significance level $\\alpha$, compute the average statistical power across the $G$ genes, defined as the arithmetic mean of the per-gene powers under the two-sided Wald test. Your program must search over integer $r \\ge r_{\\min}$ and depths $d$ on a specified grid $d \\in \\{d_{\\min}, d_{\\min} + \\Delta d, d_{\\min} + 2 \\Delta d, \\ldots, d_{\\max}\\}$ that satisfy the budget constraint, and select the pair $(r,d)$ that maximizes the average power.\n- If multiple $(r,d)$ achieve the same maximal average power up to a tolerance of $10^{-12}$, break ties by choosing the largest $r$; if still tied, choose the largest $d$.\n- If no $(r,d)$ satisfies the budget given $r_{\\min}$ and $d_{\\min}$, return $r=0$, $d=0$, and power $0$.\n\nImplementation requirements:\n- Base your power computation on the NB-GLM with log link and the Wald test under the Normal approximation, using the variance structure implied by $\\mathrm{Var}(Y) = \\mu + \\phi \\mu^2$ and the depth scaling $\\mu = d \\lambda$.\n- Treat each gene independently given $(r,d)$, then average the per-gene powers.\n\nUnits and numerical formatting:\n- Sequencing depth $d$ must be expressed in millions of reads per sample.\n- The final reported $d$ must be printed with exactly one decimal place.\n- The final reported power must be printed as a decimal fraction rounded to exactly six digits after the decimal point.\n- The reported $r$ must be an integer.\n\nTest suite and required outputs:\nYour program must solve the optimization for each of the following test cases. Each test case is a tuple\n$\\left(B, C_{\\mathrm{lib}}, C_{\\mathrm{read}}, \\{\\lambda_i\\}_{i=1}^G, \\phi, f, \\alpha, r_{\\min}, d_{\\min}, d_{\\max}, \\Delta d\\right)$.\n\nProvide results for these four cases:\n\n- Case $1$ (happy path):\n  - $B = 4000$, $C_{\\mathrm{lib}} = 150$, $C_{\\mathrm{read}} = 10$,\n  - $\\{\\lambda_i\\} = [5.0, 20.0, 100.0]$,\n  - $\\phi = 0.1$, $f = 2.0$, $\\alpha = 0.05$,\n  - $r_{\\min} = 2$, $d_{\\min} = 5.0$, $d_{\\max} = 50.0$, $\\Delta d = 1.0$.\n\n- Case $2$ (budget boundary, feasibility edge):\n  - $B = 800$, $C_{\\mathrm{lib}} = 150$, $C_{\\mathrm{read}} = 10$,\n  - $\\{\\lambda_i\\} = [5.0, 20.0, 100.0]$,\n  - $\\phi = 0.1$, $f = 2.0$, $\\alpha = 0.05$,\n  - $r_{\\min} = 2$, $d_{\\min} = 5.0$, $d_{\\max} = 50.0$, $\\Delta d = 1.0$.\n\n- Case $3$ (high overdispersion favors replication):\n  - $B = 3000$, $C_{\\mathrm{lib}} = 150$, $C_{\\mathrm{read}} = 10$,\n  - $\\{\\lambda_i\\} = [10.0, 30.0, 60.0, 120.0]$,\n  - $\\phi = 0.4$, $f = 1.5$, $\\alpha = 0.05$,\n  - $r_{\\min} = 2$, $d_{\\min} = 5.0$, $d_{\\max} = 50.0$, $\\Delta d = 1.0$.\n\n- Case $4$ (small effect, stringent significance, generous budget):\n  - $B = 10000$, $C_{\\mathrm{lib}} = 150$, $C_{\\mathrm{read}} = 10$,\n  - $\\{\\lambda_i\\} = [2.0, 5.0, 10.0, 20.0, 50.0, 100.0]$,\n  - $\\phi = 0.1$, $f = 1.2$, $\\alpha = 0.01$,\n  - $r_{\\min} = 2$, $d_{\\min} = 5.0$, $d_{\\max} = 100.0$, $\\Delta d = 1.0$.\n\nFinal output format:\n- Your program should produce a single line of output containing a list of results for the four cases, in order, where each result is a three-element list $[r^\\star, d^\\star, \\mathrm{power}^\\star]$.\n- The line must be formatted exactly as a Python list literal with no spaces after commas, and floating-point numbers formatted as specified above, for example:\n  - $[[3,20.0,0.873421],[2,5.0,0.412345],[\\dots],[\\dots]]$.", "solution": "The problem statement is assessed to be valid. It is scientifically grounded in the principles of transcriptomics and biostatistics, specifically using the Negative Binomial generalized linear model framework, which is the standard for RNA-seq differential expression analysis. The problem is well-posed, with a clear objective function (average statistical power), a defined search space for decision variables (replicates $r$ and sequencing depth $d$), a realistic budget constraint, and unambiguous tie-breaking rules. The formulation is objective, mathematically precise, and provides all necessary information to derive a unique solution. We may therefore proceed with the derivation and implementation of a solution.\n\nThe core task is to find the optimal pair of integer replicates per condition, $r$, and sequencing depth per sample, $d$, that maximizes the average statistical power, $\\bar{P}$, for detecting differentially expressed genes, subject to a total budget $B$.\n\nThe optimization problem is formally stated as:\n$$ \\underset{r, d}{\\text{maximize}} \\quad \\bar{P}(r, d) $$\nsubject to:\n$$ 2 r (C_{\\mathrm{lib}} + C_{\\mathrm{read}} d) \\le B $$\n$$ r \\in \\{r_{\\min}, r_{\\min}+1, \\dots\\} $$\n$$ d \\in \\{d_{\\min}, d_{\\min} + \\Delta d, \\dots, d_{\\max}\\} $$\n\nThe solution is developed through the following steps:\n1.  Derive the formula for the statistical power of a single gene.\n2.  Average this power across the given set of genes to define the objective function.\n3.  Design a search algorithm to find the optimal $(r, d)$ pair that maximizes this objective function within the budget.\n\n**1. Statistical Power for a Single Gene**\n\nThe problem specifies a two-sided Wald test for the null hypothesis $H_0: \\beta = 0$ against the alternative $H_A: \\beta \\ne 0$, where $\\beta = \\log(f)$ is the true log-fold-change. The true value under the alternative is $\\beta^\\star = \\log(f)$. The Wald test statistic for the estimator $\\hat{\\beta}$ is $W = \\hat{\\beta} / \\mathrm{SE}(\\hat{\\beta})$, where $\\mathrm{SE}(\\hat{\\beta})$ is the standard error of the estimator. For large sample sizes (i.e., large $r$), the estimator $\\hat{\\beta}$ is approximately normally distributed:\n$$ \\hat{\\beta} \\sim \\mathcal{N}\\left(\\beta^\\star, \\mathrm{Var}(\\hat{\\beta})\\right) $$\nThe statistical power, which is the probability of correctly rejecting a false null hypothesis, is given by:\n$$ P = \\mathbb{P}\\left(|W| > z_{1-\\alpha/2} \\mid \\beta=\\beta^\\star\\right) = \\mathbb{P}\\left(|\\hat{\\beta}| > z_{1-\\alpha/2} \\cdot \\mathrm{SE}(\\hat{\\beta}) \\mid \\beta=\\beta^\\star\\right) $$\nwhere $z_{1-\\alpha/2}$ is the $(1-\\alpha/2)$-quantile of the standard normal distribution $\\mathcal{N}(0,1)$. By standardizing the variable $\\hat{\\beta}$, the power can be expressed using the cumulative distribution function (CDF) of the standard normal distribution, $\\Phi(\\cdot)$:\n$$ P = \\Phi\\left(\\frac{-z_{1-\\alpha/2} \\cdot \\mathrm{SE}(\\hat{\\beta}) - \\beta^\\star}{\\mathrm{SE}(\\hat{\\beta})}\\right) + 1 - \\Phi\\left(\\frac{z_{1-\\alpha/2} \\cdot \\mathrm{SE}(\\hat{\\beta}) - \\beta^\\star}{\\mathrm{SE}(\\hat{\\beta})}\\right) $$\nUsing the symmetry of the normal distribution, $\\Phi(-x) = 1 - \\Phi(x)$, and a true effect size $|\\beta^\\star| > 0$, this simplifies to:\n$$ P(r, d, \\lambda) = \\Phi\\left(\\frac{|\\beta^\\star|}{\\mathrm{SE}(\\hat{\\beta})} - z_{1-\\alpha/2}\\right) + \\Phi\\left(-\\frac{|\\beta^\\star|}{\\mathrm{SE}(\\hat{\\beta})} - z_{1-\\alpha/2}\\right) $$\nThe key to calculating power is to determine the standard error, $\\mathrm{SE}(\\hat{\\beta}) = \\sqrt{\\mathrm{Var}(\\hat{\\beta})}$.\n\n**2. Variance of the Log-Fold-Change Estimator**\n\nFor a generalized linear model (GLM) with a balanced two-group design ($r$ replicates per group), the asymptotic variance of the log-fold-change estimator $\\hat{\\beta}$ is given by:\n$$ \\mathrm{Var}(\\hat{\\beta}) \\approx \\frac{1}{\\sum_{j=1}^{2r} w_j x_j^2} $$\nwhere $w_j$ is the GLM weight for sample $j$ and $x_j$ is the design matrix entry for the coefficient $\\beta$. For a simple two-group comparison with sum-to-zero contrasts, this simplifies to:\n$$ \\mathrm{Var}(\\hat{\\beta}) \\approx \\frac{1}{r} \\left( \\frac{1}{w_A} + \\frac{1}{w_B} \\right) $$\nwhere $w_A$ and $w_B$ are the inverse-variance weights for an observation in the control (A) and treatment (B) groups, respectively. For a Negative Binomial GLM with variance function $\\mathrm{Var}(Y) = \\mu + \\phi \\mu^2$ and a log link, the weight for an observation with mean $\\mu$ is $w = \\mu / (1 + \\phi \\mu)$. However, a more stable approximation for the variance of the coefficient, often used in power calculations, considers the variance on the link scale, leading to an inverse variance expression of:\n$$ \\mathrm{Var}(\\hat{\\beta}) \\approx \\frac{1}{r} \\left[ \\left(\\frac{1}{\\mu_A} + \\phi\\right) + \\left(\\frac{1}{\\mu_B} + \\phi\\right) \\right] $$\nThis formula correctly captures the contribution of both the Poisson-like shot noise (the $1/\\mu$ terms) and the biological overdispersion (the $\\phi$ terms).\n\nWe substitute the problem's definitions:\n- Control group mean: $\\mu_A = d \\lambda$\n- Treatment group mean: $\\mu_B = f \\mu_A = f d \\lambda$\n\nThis yields the variance of the estimator for a single gene with baseline abundance parameter $\\lambda$:\n$$ \\mathrm{Var}(\\hat{\\beta}) = \\frac{1}{r} \\left[ \\left(\\frac{1}{d \\lambda} + \\phi \\right) + \\left(\\frac{1}{f d \\lambda} + \\phi \\right) \\right] = \\frac{1}{r} \\left[ \\frac{1+f}{f d \\lambda} + 2\\phi \\right] $$\nAnd the standard error is its square root:\n$$ \\mathrm{SE}(\\hat{\\beta}) = \\sqrt{\\frac{1}{r} \\left( \\frac{1+f}{f d \\lambda} + 2\\phi \\right)} $$\n\n**3. Optimization Algorithm**\n\nWith the power formula for a single gene established, the objective function is the average power over $G$ genes:\n$$ \\bar{P}(r,d) = \\frac{1}{G} \\sum_{i=1}^{G} P_i(r, d, \\lambda_i) $$\nWe must search for the pair $(r, d)$ that maximizes $\\bar{P}(r,d)$ within the feasible region defined by the budget and parameter ranges.\n\nThe algorithm proceeds as follows:\n1.  Initialize the optimal parameters: $r^\\star = 0$, $d^\\star = 0.0$, and the maximum average power found so far, $P^\\star = 0.0$.\n2.  Determine the maximum possible number of replicates, $r_{\\text{limit}}$, by considering the minimum possible cost per replicate, which occurs at depth $d_{\\min}$:\n    $$ r_{\\text{limit}} = \\lfloor B / (2(C_{\\mathrm{lib}} + C_{\\mathrm{read}} d_{\\min})) \\rfloor $$\n3.  If $r_{\\text{limit}} < r_{\\min}$, no feasible solution exists. The initial values $(0, 0, 0.0)$ are returned.\n4.  Iterate through integer replicate counts $r$ from $r_{\\min}$ to $r_{\\text{limit}}$.\n    a. For each $r$, calculate the maximum depth, $d_{\\text{budget}}$, allowed by the budget constraint:\n       $$ d_{\\text{budget}} = \\frac{B / (2r) - C_{\\mathrm{lib}}}{C_{\\mathrm{read}}} $$\n    b. If $d_{\\text{budget}} < d_{\\min}$, no depth on the specified grid is feasible for this $r$. Continue to the next $r$.\n    c. Iterate through the depth grid $d \\in \\{d_{\\min}, d_{\\min} + \\Delta d, \\dots, d_{\\max}\\}$. For each $d$:\n        i. Check if $d \\le d_{\\text{budget}}$. If not, all subsequent depths for this $r$ are also infeasible, so break the inner loop.\n        ii. If feasible, calculate the average power $\\bar{P}(r, d)$ by computing the power for each gene using its $\\lambda_i$ and averaging the results.\n        iii. Compare the computed power $\\bar{P}(r, d)$ with the current maximum $P^\\star$:\n            - If $\\bar{P}(r, d) > P^\\star + 10^{-12}$, update the optimal solution: $r^\\star = r$, $d^\\star = d$, $P^\\star = \\bar{P}(r, d)$.\n            - If $|\\bar{P}(r, d) - P^\\star| \\le 10^{-12}$, apply the tie-breaking rules:\n                - If $r > r^\\star$, update with the new $(r, d, \\bar{P})$.\n                - If $r = r^\\star$ and $d > d^\\star$, update with the new $(r, d, \\bar{P})$.\n5.  After the search is complete, the final triplet $(r^\\star, d^\\star, P^\\star)$ is the solution. This systematic grid search guarantees finding the global maximum of the objective function over the discretized domain.\n\nThis methodology provides a complete, robust, and theoretically sound solution to the experimental design optimization problem posed.", "answer": "[[8,15.0,0.916843],[2,20.0,0.573132],[6,15.0,0.738092],[22,12.0,0.925067]]", "id": "2848904"}]}