{"hands_on_practices": [{"introduction": "To truly understand the Meselson-Stahl experiment, we must first master its core predictive logic. This foundational exercise challenges you to step into the shoes of the original researchers and calculate the expected distribution of DNA molecules after two rounds of replication under the semiconservative model ([@problem_id:2849791]). By tracking the fate of the original heavy strands through successive generations, you will derive the classic 1:1 ratio of hybrid to light DNA, solidifying your grasp of the fundamental mechanism.", "problem": "A classical isotopic-labeling replication-shift experiment is performed in the spirit of the Meselson–Stahl design. A synchronous culture of Escherichia coli (E. coli) is grown for many generations in medium containing heavy nitrogen, such that all chromosomal Deoxyribonucleic Acid (DNA) duplexes are uniformly heavy–heavy. At time zero, the culture is shifted to light nitrogen medium and allowed to undergo exactly 2 complete rounds of DNA replication and cell division. Assume the following fundamental basis:\n- Semiconservative replication: each daughter duplex inherits exactly one parental strand and one newly synthesized strand.\n- Equal DNA mass per cell: each cell contains the same genome mass $M$, independent of isotopic composition.\n- Population doubling per generation: the number of cells doubles with each completed replication–division cycle, and replication across the population is synchronous.\n- In cesium chloride ($\\text{CsCl}$) buoyant density ultracentrifugation, band intensity is directly proportional to the total DNA mass at that buoyant density.\n\nLet “HL” denote hybrid duplexes containing one heavy strand and one light strand, and “LL” denote light–light duplexes. Immediately after the $2$nd division following the shift, the DNA is extracted and resolved in a cesium chloride ($\\text{CsCl}$) gradient. Taking the total integrated intensity across all DNA bands to be normalized to $1$, compute the expected relative intensities of the HL and LL bands under strictly semiconservative replication. Report your final result as two numbers corresponding to HL and LL, respectively, that sum to $1$. Do not use a percentage sign; express the values as exact fractions or decimals without units.", "solution": "The problem posed is a classical application of the principle of semiconservative DNA replication, as first demonstrated by Meselson and Stahl. We will validate the problem before proceeding to a solution.\n\n**Problem Validation**\n\nStep 1: Extract Givens.\n- A synchronous culture of *E. coli* is grown in a heavy nitrogen (${}^{15}\\mathrm{N}$) medium for many generations.\n- At time $t=0$, the culture is transferred to a light nitrogen (${}^{14}\\mathrm{N}$) medium.\n- The culture undergoes exactly $2$ complete rounds of DNA replication and cell division.\n- Assumption 1: Replication is semiconservative.\n- Assumption 2: Each cell contains the same genome mass $M$, regardless of isotopic composition.\n- Assumption 3: The cell population doubles synchronously with each generation.\n- Assumption 4: In $\\text{CsCl}$ ultracentrifugation, band intensity is proportional to the total DNA mass at that buoyant density.\n- “HL” denotes hybrid duplexes (one heavy, one light strand).\n- “LL” denotes light-light duplexes.\n- The total integrated band intensity is normalized to $1$.\n- The objective is to compute the relative intensities of the HL and LL bands after the $2$nd division.\n\nStep 2: Validate Using Extracted Givens.\nThe problem is scientifically grounded, describing an idealized version of the canonical Meselson-Stahl experiment. The assumptions provided—semiconservative replication, synchronous division, and the relationship between mass and band intensity—are the standard and necessary idealizations for formalizing this problem. The problem is well-posed, with a clear initial state, a defined process, and a quantifiable objective. It is free from ambiguity, contradiction, and factual error.\n\nStep 3: Verdict and Action.\nThe problem is deemed valid. A rigorous solution can be formulated.\n\n**Solution Derivation**\n\nLet $N_0$ be the initial number of cells at time $t=0$. Due to prolonged growth in the heavy medium, the DNA in every cell is of the heavy-heavy ($HH$) type. Let us denote the total initial mass of DNA as $M_{total}$. All this mass corresponds to $HH$ duplexes.\n\n**Generation 0 (Initial State):**\nAt $t=0$, before the first replication in the light medium, the entire population of DNA duplexes consists of the $HH$ type.\n- Fraction of $HH$ duplexes: $1$.\n- Fraction of hybrid ($HL$) duplexes: $0$.\n- Fraction of light-light ($LL$) duplexes: $0$.\n\n**Generation 1 (After 1 round of replication):**\nThe cells are now in a light (${}^{14}\\mathrm{N}$) medium. According to the principle of semiconservative replication, each $HH$ duplex unwinds, and its two heavy strands serve as templates for the synthesis of new complementary strands. Since the precursors available are light, each heavy template strand ($H$) is paired with a newly synthesized light strand ($L$).\nThus, each initial $HH$ duplex gives rise to two hybrid ($HL$) duplexes.\n$$HH \\xrightarrow{\\text{1st replication in }{}^{14}\\mathrm{N}} HL + HL$$\nAfter one generation, the number of cells doubles to $2N_0$, and the total DNA mass doubles. Every single DNA duplex in the population is now of the $HL$ type.\n- Fraction of $HH$ duplexes: $0$.\n- Fraction of $HL$ duplexes: $1$.\n- Fraction of $LL$ duplexes: $0$.\nThe $\\text{CsCl}$ gradient at this stage would show a single band at the hybrid density position.\n\n**Generation 2 (After 2 rounds of replication):**\nThe cells from Generation $1$, each containing only $HL$ DNA, undergo a second round of replication in the same light medium. Each $HL$ duplex unwinds into one heavy ($H$) strand and one light ($L$) strand. Each of these strands serves as a template.\n- The heavy template strand ($H$) pairs with a new light strand ($L$), forming one $HL$ duplex.\n- The light template strand ($L$) pairs with a new light strand ($L$), forming one $LL$ duplex.\nTherefore, each $HL$ duplex from Generation $1$ gives rise to one $HL$ duplex and one $LL$ duplex.\n$$HL \\xrightarrow{\\text{2nd replication in }{}^{14}\\mathrm{N}} HL + LL$$\nSince the entire DNA population at the start of the second replication was of the $HL$ type, exactly half of the resulting DNA duplexes will be of the $HL$ type, and the other half will be of the $LL$ type. The total number of cells is now $4N_0$, and the total DNA mass has quadrupled relative to the start.\n- Fraction of $HL$ duplexes: $\\frac{1}{2}$.\n- Fraction of $LL$ duplexes: $\\frac{1}{2}$.\n- Fraction of $HH$ duplexes: $0$.\n\n**Calculation of Relative Intensities:**\nThe problem states that band intensity is directly proportional to the total DNA mass at that buoyant density. We have established that after $2$ generations, the total DNA mass is equally distributed between the hybrid ($HL$) and light-light ($LL$) forms.\nLet $I_{HL}$ be the intensity of the hybrid band and $I_{LL}$ be the intensity of the light-light band. The total intensity, $I_{total}$, is normalized to $1$.\n$$I_{total} = I_{HL} + I_{LL} = 1$$\nThe relative intensity of a band is equal to the fraction of the total DNA mass it represents.\nThe fraction of total DNA mass that is $HL$ is $\\frac{1}{2}$.\nThe fraction of total DNA mass that is $LL$ is $\\frac{1}{2}$.\nTherefore, the relative intensities are:\n$$I_{HL} = \\frac{1}{2}$$\n$$I_{LL} = \\frac{1}{2}$$\nThe expected relative intensities of the $HL$ and $LL$ bands are $\\frac{1}{2}$ and $\\frac{1}{2}$, respectively. These values sum to $1$, consistent with the normalization condition.", "answer": "$$\\boxed{\\begin{pmatrix} \\frac{1}{2} & \\frac{1}{2} \\end{pmatrix}}$$", "id": "2849791"}, {"introduction": "In an ideal experiment, DNA bands in a density gradient would be infinitely sharp lines, but in reality, they possess width. This practice delves into the physical reasons for this band broadening, a critical concept for interpreting real experimental data. You will build a quantitative model that combines intrinsic density variation, stemming from genomic guanine-cytosine (GC) content, with instrumental effects to derive an expression for the observed band width ([@problem_id:2849753]). This exercise bridges the gap between a simple discrete model and the continuous profiles seen in actual experiments.", "problem": "In the classic Meselson–Stahl experiment, deoxyribonucleic acid (DNA) is separated at isopycnic equilibrium in cesium chloride ($\\text{CsCl}$) density gradients such that a DNA molecule bands at the position where its buoyant density equals the local gradient density. Consider a single isotopic class of molecules produced under semiconservative replication (for example, the hybrid class after one generation following a heavy-to-light medium shift). Within this isotopic class, suppose that the only source of molecular-to-molecular density heterogeneity arises from variation in genome-local guanine–cytosine fraction (GC fraction). Assume the following:\n- The buoyant density of DNA depends approximately linearly on its GC fraction. If $g \\in [0,1]$ denotes the GC fraction, then the buoyant density is $\\rho(g) = \\rho_{0} + \\delta + \\alpha g$, where $\\rho_{0}$ is a reference density, $\\delta$ is the constant isotopic density offset for the chosen isotopic class, and $\\alpha > 0$ is the slope relating buoyant density to GC fraction.\n- The genome-wide distribution of GC fraction across independently banding DNA segments is Gaussian with mean $\\mu_{g}$ and variance $\\sigma_{g}^{2}$.\n- The instrument response (including gradient imperfections and readout) is well-approximated by a normalized Gaussian kernel with zero mean and variance $\\sigma_{i}^{2}$ in the density coordinate.\n- The observed band profile as a function of density is the convolution of the mapped GC-fraction distribution with the instrument response.\n\nModel the observed density $\\rho$ as a random variable generated by the linear mapping from $g$ followed by independent additive instrument broadening, and treat the observed profile as Gaussian whenever the underlying components are Gaussian. Under these assumptions, derive a closed-form analytic expression for the full width at half maximum (FWHM) of the observed equilibrium band, expressed in the density coordinate, in terms of $\\alpha$, $\\sigma_{g}$, and $\\sigma_{i}$. Your final answer must be a single analytic expression. Do not include any units.", "solution": "The problem as stated is scientifically grounded, well-posed, and objective. It presents a standard model from biophysical chemistry that can be solved analytically. We shall proceed with the derivation.\n\nThe problem requires us to find the full width at half maximum (FWHM) of an observed density profile. This profile results from two independent sources of broadening: the intrinsic heterogeneity of the DNA molecules and the instrument response. We will model each contribution and then combine them.\n\nFirst, we consider the intrinsic heterogeneity, which is stated to arise from the variation in the guanine-cytosine (GC) fraction, denoted by the random variable $g$. The problem specifies that the distribution of $g$ is Gaussian with mean $\\mu_{g}$ and variance $\\sigma_{g}^{2}$. We can write this as $g \\sim N(\\mu_{g}, \\sigma_{g}^{2})$.\n\nThe buoyant density, $\\rho$, is given as a linear function of the GC fraction $g$:\n$$\n\\rho(g) = \\rho_{0} + \\delta + \\alpha g\n$$\nHere, $\\rho_{0}$, $\\delta$, and $\\alpha$ are constants. Since $\\rho(g)$ is a linear transformation of the Gaussian random variable $g$, the resulting distribution of intrinsic densities, which we shall call $\\rho_{true}$, is also Gaussian.\n\nThe mean of the intrinsic density distribution is given by the expectation:\n$$\nE[\\rho_{true}] = E[\\rho_{0} + \\delta + \\alpha g] = \\rho_{0} + \\delta + \\alpha E[g] = \\rho_{0} + \\delta + \\alpha \\mu_{g}\n$$\nThe variance of the intrinsic density distribution is:\n$$\n\\sigma_{true}^{2} = \\text{Var}(\\rho_{true}) = \\text{Var}(\\rho_{0} + \\delta + \\alpha g) = \\text{Var}(\\alpha g) = \\alpha^{2} \\text{Var}(g) = \\alpha^{2} \\sigma_{g}^{2}\n$$\nThus, the distribution of intrinsic molecular densities due to GC content variation is Gaussian, $\\rho_{true} \\sim N(\\rho_{0} + \\delta + \\alpha \\mu_{g}, \\alpha^{2} \\sigma_{g}^{2})$.\n\nNext, we must account for the instrument response. The problem states this is equivalent to an independent, additive broadening effect, described by a Gaussian kernel with zero mean and variance $\\sigma_{i}^{2}$. Let us represent this instrumental noise as a random variable $\\epsilon_{i} \\sim N(0, \\sigma_{i}^{2})$.\n\nThe observed density, $\\rho_{obs}$, is the sum of the true molecular density and the instrumental noise:\n$$\n\\rho_{obs} = \\rho_{true} + \\epsilon_{i}\n$$\nThe problem correctly notes that the distribution of $\\rho_{obs}$ is the convolution of the distribution of $\\rho_{true}$ and the distribution of $\\epsilon_{i}$. For two independent Gaussian random variables, their sum is also a Gaussian random variable. The mean of the sum is the sum of the means, and the variance of the sum is the sum of the variances.\n\nThe mean of the observed density distribution is:\n$$\n\\mu_{obs} = E[\\rho_{obs}] = E[\\rho_{true} + \\epsilon_{i}] = E[\\rho_{true}] + E[\\epsilon_{i}] = (\\rho_{0} + \\delta + \\alpha \\mu_{g}) + 0 = \\rho_{0} + \\delta + \\alpha \\mu_{g}\n$$\nThe variance of the observed density distribution is:\n$$\n\\sigma_{obs}^{2} = \\text{Var}(\\rho_{obs}) = \\text{Var}(\\rho_{true} + \\epsilon_{i}) = \\text{Var}(\\rho_{true}) + \\text{Var}(\\epsilon_{i}) = \\alpha^{2} \\sigma_{g}^{2} + \\sigma_{i}^{2}\n$$\nSo, the observed band profile is described by a Gaussian function of density $\\rho$ with mean $\\mu_{obs}$ and variance $\\sigma_{obs}^{2}$.\n\nFinally, we derive the FWHM for this observed Gaussian distribution. A general Gaussian function centered at $\\mu$ with standard deviation $\\sigma$ is of the form $f(x) = A \\exp\\left(-\\frac{(x - \\mu)^{2}}{2\\sigma^{2}}\\right)$, where $A$ is the peak amplitude. The maximum value of the function is $A$, which occurs at $x=\\mu$. The FWHM is the width of the distribution at half of this maximum value, i.e., at a height of $\\frac{A}{2}$. We must find the values of $x$ for which $f(x) = \\frac{A}{2}$:\n$$\n\\frac{A}{2} = A \\exp\\left(-\\frac{(x - \\mu)^{2}}{2\\sigma^{2}}\\right)\n$$\n$$\n\\frac{1}{2} = \\exp\\left(-\\frac{(x - \\mu)^{2}}{2\\sigma^{2}}\\right)\n$$\nTaking the natural logarithm of both sides gives:\n$$\n\\ln\\left(\\frac{1}{2}\\right) = -\\ln(2) = -\\frac{(x - \\mu)^{2}}{2\\sigma^{2}}\n$$\n$$\n(x - \\mu)^{2} = 2 \\sigma^{2} \\ln(2)\n$$\n$$\nx - \\mu = \\pm \\sqrt{2 \\sigma^{2} \\ln(2)} = \\pm \\sigma \\sqrt{2 \\ln(2)}\n$$\nThe two points are $x_{1} = \\mu - \\sigma \\sqrt{2 \\ln(2)}$ and $x_{2} = \\mu + \\sigma \\sqrt{2 \\ln(2)}$. The FWHM is the difference between these two points:\n$$\n\\text{FWHM} = x_{2} - x_{1} = \\left(\\mu + \\sigma \\sqrt{2 \\ln(2)}\\right) - \\left(\\mu - \\sigma \\sqrt{2 \\ln(2)}\\right) = 2 \\sigma \\sqrt{2 \\ln(2)}\n$$\nTo find the FWHM of the observed band, we substitute our derived standard deviation, $\\sigma_{obs} = \\sqrt{\\alpha^{2} \\sigma_{g}^{2} + \\sigma_{i}^{2}}$, into this expression:\n$$\n\\text{FWHM} = 2 \\sigma_{obs} \\sqrt{2 \\ln(2)} = 2 \\sqrt{\\alpha^{2} \\sigma_{g}^{2} + \\sigma_{i}^{2}} \\sqrt{2 \\ln(2)}\n$$\nCombining the terms under the square root provides the final closed-form expression:\n$$\n\\text{FWHM} = 2 \\sqrt{2 \\ln(2) (\\alpha^{2} \\sigma_{g}^{2} + \\sigma_{i}^{2})}\n$$\nThis expression relates the observable band width to the underlying physical and instrumental parameters, as required.", "answer": "$$\n\\boxed{2 \\sqrt{2 \\ln(2) (\\alpha^{2} \\sigma_{g}^{2} + \\sigma_{i}^{2})}}\n$$", "id": "2849753"}, {"introduction": "Modern quantitative biology relies on sophisticated statistical methods to extract signals from noisy experimental readouts. This advanced practice challenges you to formalize the analysis of a densitometry trace by modeling it as a Gaussian mixture, where each component represents a distinct isotopic class of DNA. You will derive and implement the powerful Expectation-Maximization (EM) algorithm to estimate the relative proportions of each population from simulated data, a technique with broad applications in bioinformatics for dissecting heterogeneous signals ([@problem_id:2849743]).", "problem": "You are tasked with formalizing and implementing a probabilistic inference procedure that connects the principles of semiconservative deoxyribonucleic acid (DNA) replication to a statistical model of buoyant density measurements used in the Meselson–Stahl experiment. The fundamental basis is as follows: semiconservative DNA replication ensures that each newly synthesized double-stranded DNA molecule contains one parental strand and one nascent strand; when cells originally grown in heavy nitrogen are shifted to light nitrogen and allowed to replicate, discrete density classes emerge corresponding to heavy–light (HL) and light–light (LL) duplexes. Because the experimental readout along a density gradient is affected by thermal and instrumental fluctuations arising from many independent microscopic contributions, a Gaussian (normal) approximation for the measurement distribution of each class is well-justified by the central limit theorem.\n\nModel each observed molecular density position as an independent draw from a two-component Gaussian mixture in one dimension with known component means and a known shared standard deviation. Let $x_1, \\dots, x_N$ be the observed densities, where $N$ is a positive integer. Let the HL component have mean $\\mu_{\\mathrm{HL}}$ and the LL component have mean $\\mu_{\\mathrm{LL}}$, and assume a shared standard deviation $\\sigma>0$. Let $\\theta\\in[0,1]$ denote the true fraction of HL molecules. The sampling model is the mixture\n$$\np(x_i\\mid\\theta)=\\theta\\,\\phi(x_i;\\mu_{\\mathrm{HL}},\\sigma^2)+(1-\\theta)\\,\\phi(x_i;\\mu_{\\mathrm{LL}},\\sigma^2),\n$$\nwhere $\\phi(\\cdot;\\mu,\\sigma^2)$ is the Gaussian probability density function with mean $\\mu$ and variance $\\sigma^2$.\n\nYour tasks are:\n- Derive, from first principles, the likelihood function for $\\theta$ under this model and its logarithm, starting from the independence of the $x_i$ and the definition of a finite mixture model.\n- Introduce latent indicator variables for component membership and derive the Expectation–Maximization (EM) algorithm specialized to this setting in which only $\\theta$ is unknown and $\\mu_{\\mathrm{HL}}$, $\\mu_{\\mathrm{LL}}$, and $\\sigma$ are known. Provide explicit expressions for the E-step responsibilities and the M-step update for $\\theta$.\n- Implement a program that simulates data for a given $N$, $\\theta$, $\\mu_{\\mathrm{HL}}$, $\\mu_{\\mathrm{LL}}$, and $\\sigma$, and then recovers a maximum likelihood estimate $\\hat{\\theta}$ using the EM algorithm you derived. Use independent and identically distributed simulation consistent with the mixture model.\n\nScientific and numerical constraints:\n- Treat the semiconservative replication context only as the justification for the two-component mixture; do not assume any other biology-specific shortcuts.\n- All returned fractions must be reported as decimals in $[0,1]$. No percentage symbols are allowed.\n- Means and standard deviations are dimensionless for the purposes of this exercise; no physical units are to be reported.\n\nTest suite specification. Your program must run the EM estimator for the following four cases. Each case specifies a random seed $s$ (a nonnegative integer), sample size $N$, true HL fraction $\\theta$, HL mean $\\mu_{\\mathrm{HL}}$, LL mean $\\mu_{\\mathrm{LL}}$, and shared standard deviation $\\sigma$:\n- Case A (happy path, well-separated components): $s=17$, $N=4000$, $\\theta=0.50$, $\\mu_{\\mathrm{HL}}=-1.0$, $\\mu_{\\mathrm{LL}}=1.0$, $\\sigma=0.30$.\n- Case B (boundary behavior, all-HL population): $s=23$, $N=1500$, $\\theta=1.00$, $\\mu_{\\mathrm{HL}}=0.0$, $\\mu_{\\mathrm{LL}}=3.0$, $\\sigma=0.40$.\n- Case C (rare HL fraction, well-separated components): $s=47$, $N=1000$, $\\theta=0.05$, $\\mu_{\\mathrm{HL}}=-2.0$, $\\mu_{\\mathrm{LL}}=2.0$, $\\sigma=1.00$.\n- Case D (moderate overlap): $s=101$, $N=2000$, $\\theta=0.60$, $\\mu_{\\mathrm{HL}}=0.0$, $\\mu_{\\mathrm{LL}}=0.5$, $\\sigma=0.60$.\n\nAlgorithmic requirements:\n- Use the EM algorithm with an initialization $\\theta^{(0)}=0.50$. Iterate until either the absolute change $\\lvert \\theta^{(t+1)}-\\theta^{(t)}\\rvert$ is less than $10^{-8}$ or the iteration count reaches $10000$.\n- For numerical stability, ensure that all intermediate computations avoid division by zero by constraining iterates to the open interval $(10^{-12},1-10^{-12})$ during the E-step when forming ratios.\n- For each case, simulate the mixture sample of size $N$ under the specified $\\theta$, $\\mu_{\\mathrm{HL}}$, $\\mu_{\\mathrm{LL}}$, and $\\sigma$ using the given seed $s$, then compute and record the EM estimate $\\hat{\\theta}$.\n\nFinal output format:\n- Your program should produce a single line of output in the form of a Python list literal: an opening square bracket, the results in order separated by commas with no spaces, and a closing square bracket.\n- The list must contain the four maximum likelihood estimates $\\hat{\\theta}$ for the cases A, B, C, and D, respectively, each rounded to exactly $6$ decimal places.", "solution": "The problem statement is scrutinized and deemed valid. It is scientifically grounded in the principles of molecular biology and statistical inference, is mathematically well-posed, and contains all necessary information for a unique, reproducible solution. No contradictions, ambiguities, or factual inaccuracies are present. We may therefore proceed with the derivation and solution.\n\nThe problem requires a formal derivation and implementation of the Expectation-Maximization (EM) algorithm to estimate the mixture proportion, $\\theta$, in a two-component Gaussian mixture model. This model is motivated by the buoyant density distribution of DNA molecules in the Meselson-Stahl experiment.\n\n**Part 1: Derivation of the Likelihood Function**\n\nLet the observed buoyant densities of $N$ DNA molecules be denoted by the set of independent and identically distributed (i.i.d.) random variables $\\mathbf{x} = \\{x_1, x_2, \\dots, x_N\\}$. The model for a single observation $x_i$ is a mixture of two Gaussian distributions, representing the heavy-light (HL) and light-light (LL) DNA populations. The probability density function (PDF) for $x_i$ is given as:\n$$\np(x_i \\mid \\theta) = \\theta \\, \\phi(x_i; \\mu_{\\mathrm{HL}}, \\sigma^2) + (1-\\theta) \\, \\phi(x_i; \\mu_{\\mathrm{LL}}, \\sigma^2)\n$$\nHere, $\\theta \\in [0, 1]$ is the unknown proportion of HL molecules. The means $\\mu_{\\mathrm{HL}}$ and $\\mu_{\\mathrm{LL}}$, and the shared standard deviation $\\sigma > 0$, are known constants. The function $\\phi(x; \\mu, \\sigma^2)$ is the Gaussian PDF:\n$$\n\\phi(x; \\mu, \\sigma^2) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}} \\exp\\left(-\\frac{(x-\\mu)^2}{2\\sigma^2}\\right)\n$$\nBecause the $N$ observations are independent, the total likelihood of observing the entire dataset $\\mathbf{x}$ given the parameter $\\theta$ is the product of the individual probabilities:\n$$\nL(\\theta \\mid \\mathbf{x}) = p(\\mathbf{x} \\mid \\theta) = \\prod_{i=1}^{N} p(x_i \\mid \\theta)\n$$\nSubstituting the mixture model definition, we obtain the likelihood function:\n$$\nL(\\theta \\mid \\mathbf{x}) = \\prod_{i=1}^{N} \\left[ \\theta \\, \\phi(x_i; \\mu_{\\mathrm{HL}}, \\sigma^2) + (1-\\theta) \\, \\phi(x_i; \\mu_{\\mathrm{LL}}, \\sigma^2) \\right]\n$$\nFor analytical and numerical convenience, we work with the log-likelihood function, $\\ell(\\theta \\mid \\mathbf{x}) = \\log L(\\theta \\mid \\mathbf{x})$:\n$$\n\\ell(\\theta \\mid \\mathbf{x}) = \\sum_{i=1}^{N} \\log \\left[ \\theta \\, \\phi(x_i; \\mu_{\\mathrm{HL}}, \\sigma^2) + (1-\\theta) \\, \\phi(x_i; \\mu_{\\mathrm{LL}}, \\sigma^2) \\right]\n$$\nDirectly maximizing this log-likelihood function with respect to $\\theta$ is analytically intractable due to the sum inside the logarithm. This structure motivates the use of the Expectation-Maximization (EM) algorithm.\n\n**Part 2: Derivation of the Expectation-Maximization (EM) Algorithm**\n\nThe EM algorithm simplifies this problem by introducing latent indicator variables. For each observation $x_i$, let $Z_i$ be a binary latent variable such that $Z_i=1$ if $x_i$ was generated from the HL component, and $Z_i=0$ if it was from the LL component. The set of all such variables is $\\mathbf{Z} = \\{Z_1, \\dots, Z_N\\}$.\nThe probability of $Z_i$ is governed by $\\theta$: $P(Z_i=1 \\mid \\theta) = \\theta$ and $P(Z_i=0 \\mid \\theta) = 1-\\theta$.\n\nThe complete-data log-likelihood, which includes the latent variables, is $\\ell_c(\\theta \\mid \\mathbf{x}, \\mathbf{Z}) = \\log p(\\mathbf{x}, \\mathbf{Z} \\mid \\theta)$. Given independence, we have:\n$$\n\\ell_c(\\theta \\mid \\mathbf{x}, \\mathbf{Z}) = \\sum_{i=1}^{N} \\log p(x_i, Z_i \\mid \\theta) = \\sum_{i=1}^{N} \\log [p(x_i \\mid Z_i, \\theta) p(Z_i \\mid \\theta)]\n$$\nUsing the definitions of $Z_i$, we can write this as:\n$$\n\\ell_c(\\theta \\mid \\mathbf{x}, \\mathbf{Z}) = \\sum_{i=1}^{N} \\left[ Z_i \\log(\\theta \\, \\phi(x_i; \\mu_{\\mathrm{HL}}, \\sigma^2)) + (1-Z_i) \\log((1-\\theta) \\, \\phi(x_i; \\mu_{\\mathrm{LL}}, \\sigma^2)) \\right]\n$$\n$$\n\\ell_c(\\theta \\mid \\mathbf{x}, \\mathbf{Z}) = \\sum_{i=1}^{N} \\left[ Z_i \\log\\theta + (1-Z_i)\\log(1-\\theta) \\right] + \\text{terms not dependent on } \\theta\n$$\nThe EM algorithm iterates between two steps: the Expectation (E) step and the Maximization (M) step.\n\n**E-Step:**\nIn the E-step, we compute the expectation of the complete-data log-likelihood with respect to the posterior distribution of the latent variables $\\mathbf{Z}$, given the data $\\mathbf{x}$ and the current estimate of the parameter, $\\theta^{(t)}$. This defines the function $Q(\\theta \\mid \\theta^{(t)})$.\n$$\nQ(\\theta \\mid \\theta^{(t)}) = E_{\\mathbf{Z} \\mid \\mathbf{x}, \\theta^{(t)}} \\left[ \\ell_c(\\theta \\mid \\mathbf{x}, \\mathbf{Z}) \\right]\n$$\nDue to the linearity of expectation, we only need the posterior expectation of each $Z_i$. This is called the \"responsibility\" of the HL component for data point $x_i$. Let us denote it by $\\gamma_i^{(t)}$:\n$$\n\\gamma_i^{(t)} = E[Z_i \\mid x_i, \\theta^{(t)}] = P(Z_i=1 \\mid x_i, \\theta^{(t)})\n$$\nUsing Bayes' theorem:\n$$\n\\gamma_i^{(t)} = \\frac{p(x_i \\mid Z_i=1, \\theta^{(t)}) P(Z_i=1 \\mid \\theta^{(t)})}{p(x_i \\mid \\theta^{(t)})}\n$$\nSubstituting the known distributions:\n$$\n\\gamma_i^{(t)} = \\frac{\\phi(x_i; \\mu_{\\mathrm{HL}}, \\sigma^2) \\cdot \\theta^{(t)}}{\\theta^{(t)} \\, \\phi(x_i; \\mu_{\\mathrm{HL}}, \\sigma^2) + (1-\\theta^{(t)}) \\, \\phi(x_i; \\mu_{\\mathrm{LL}}, \\sigma^2)}\n$$\nThis is the explicit formula for the E-step. We compute $\\gamma_i^{(t)}$ for all $i=1, \\dots, N$.\n\n**M-Step:**\nIn the M-step, we find the value of $\\theta$ that maximizes the $Q$ function, which yields the next estimate, $\\theta^{(t+1)}$.\n$$\n\\theta^{(t+1)} = \\arg\\max_{\\theta} Q(\\theta \\mid \\theta^{(t)})\n$$\nThe $Q$ function, isolating terms dependent on $\\theta$, is:\n$$\nQ(\\theta \\mid \\theta^{(t)}) = \\sum_{i=1}^{N} E_{\\mathbf{Z} \\mid \\mathbf{x}, \\theta^{(t)}} \\left[ Z_i \\log\\theta + (1-Z_i)\\log(1-\\theta) \\right] + C\n$$\n$$\nQ(\\theta \\mid \\theta^{(t)}) = \\sum_{i=1}^{N} \\left[ \\gamma_i^{(t)} \\log\\theta + (1-\\gamma_i^{(t)})\\log(1-\\theta) \\right] + C\n$$\nTo maximize, we take the derivative with respect to $\\theta$ and set it to zero:\n$$\n\\frac{\\partial Q}{\\partial \\theta} = \\sum_{i=1}^{N} \\left( \\frac{\\gamma_i^{(t)}}{\\theta} - \\frac{1-\\gamma_i^{(t)}}{1-\\theta} \\right) = 0\n$$\n$$\n\\frac{1}{\\theta} \\sum_{i=1}^{N} \\gamma_i^{(t)} = \\frac{1}{1-\\theta} \\sum_{i=1}^{N} (1-\\gamma_i^{(t)})\n$$\nLet $N_{\\mathrm{HL}}^{(t)} = \\sum_{i=1}^{N} \\gamma_i^{(t)}$, which is the \"effective\" or expected number of data points belonging to the HL component. The equation becomes:\n$$\n\\frac{N_{\\mathrm{HL}}^{(t)}}{\\theta} = \\frac{N - N_{\\mathrm{HL}}^{(t)}}{1-\\theta} \\implies N_{\\mathrm{HL}}^{(t)}(1-\\theta) = \\theta(N - N_{\\mathrm{HL}}^{(t)}) \\implies N_{\\mathrm{HL}}^{(t)} = N\\theta\n$$\nSolving for $\\theta$ gives the M-step update rule:\n$$\n\\theta^{(t+1)} = \\frac{1}{N} \\sum_{i=1}^{N} \\gamma_i^{(t)} = \\frac{N_{\\mathrm{HL}}^{(t)}}{N}\n$$\nThis update has an intuitive interpretation: the new estimate for the HL fraction is the average responsibility of the HL component over all data points.\n\n**Part 3: Implementation and Algorithmic Details**\n\nThe implementation proceeds by first simulating the data according to the problem specification for each test case. An initial estimate for the mixing proportion is set to $\\theta^{(0)} = 0.50$. The algorithm then iteratively applies the E-step and M-step. In the E-step, the responsibilities $\\gamma_i^{(t)}$ are calculated for all $N$ data points using the current estimate $\\theta^{(t)}$. For numerical stability, as specified, the value of $\\theta^{(t)}$ used in the ratio is constrained to the interval $(10^{-12}, 1-10^{-12})$. In the M-step, the next estimate $\\theta^{(t+1)}$ is computed by averaging these responsibilities. The iteration continues until the absolute difference $|\\theta^{(t+1)} - \\theta^{(t)}|$ falls below a tolerance of $10^{-8}$ or a maximum of $10000$ iterations is reached. The final converged value is the maximum likelihood estimate $\\hat{\\theta}$. This procedure is repeated for each of the four specified test cases.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.stats import norm\n\ndef solve():\n    \"\"\"\n    Simulates data for a two-component Gaussian mixture model and estimates\n    the mixing proportion using the Expectation-Maximization (EM) algorithm.\n    \"\"\"\n    \n    # Test suite specification.\n    test_cases = [\n        {'case': 'A', 's': 17, 'N': 4000, 'theta': 0.50, 'mu_hl': -1.0, 'mu_ll': 1.0, 'sigma': 0.30},\n        {'case': 'B', 's': 23, 'N': 1500, 'theta': 1.00, 'mu_hl': 0.0, 'mu_ll': 3.0, 'sigma': 0.40},\n        {'case': 'C', 's': 47, 'N': 1000, 'theta': 0.05, 'mu_hl': -2.0, 'mu_ll': 2.0, 'sigma': 1.00},\n        {'case': 'D', 's': 101, 'N': 2000, 'theta': 0.60, 'mu_hl': 0.0, 'mu_ll': 0.5, 'sigma': 0.60}\n    ]\n\n    results = []\n\n    # Algorithmic requirements\n    theta_init = 0.50\n    tol = 1e-8\n    max_iter = 10000\n    eps = 1e-12\n\n    for case in test_cases:\n        s = case['s']\n        N = case['N']\n        true_theta = case['theta']\n        mu_hl = case['mu_hl']\n        mu_ll = case['mu_ll']\n        sigma = case['sigma']\n\n        # 1. Simulate data\n        rng = np.random.default_rng(seed=s)\n        \n        # Component assignments: 1 for HL, 0 for LL\n        assignments = rng.choice([1, 0], size=N, p=[true_theta, 1 - true_theta])\n        n_hl = np.sum(assignments)\n        n_ll = N - n_hl\n        \n        data_hl = rng.normal(loc=mu_hl, scale=sigma, size=n_hl)\n        data_ll = rng.normal(loc=mu_ll, scale=sigma, size=n_ll)\n        data = np.concatenate((data_hl, data_ll))\n\n        # 2. Run EM algorithm\n        theta_t = theta_init\n        \n        # Pre-calculate PDFs as they do not change during iterations\n        pdf_hl = norm.pdf(data, loc=mu_hl, scale=sigma)\n        pdf_ll = norm.pdf(data, loc=mu_ll, scale=sigma)\n\n        for _ in range(max_iter):\n            # --- E-Step ---\n            # Clamp theta for numerical stability in ratio calculation\n            theta_clamped = np.clip(theta_t, eps, 1 - eps)\n            \n            numerator_resp = theta_clamped * pdf_hl\n            denominator_resp = numerator_resp + (1 - theta_clamped) * pdf_ll\n            \n            # Responsibilities (gamma_i)\n            # Handle potential division by zero if denominator is zero\n            responsibilities = np.divide(numerator_resp, denominator_resp, \n                                        out=np.zeros_like(numerator_resp), \n                                        where=denominator_resp != 0)\n\n            # --- M-Step ---\n            theta_t_plus_1 = np.mean(responsibilities)\n\n            # --- Convergence Check ---\n            if np.abs(theta_t_plus_1 - theta_t)  tol:\n                theta_t = theta_t_plus_1\n                break\n            \n            theta_t = theta_t_plus_1\n        \n        results.append(theta_t)\n\n    # Final print statement in the exact required format.\n    # The output format is a list of strings rounded to 6 decimal places.\n    print(f\"[{','.join([f'{r:.6f}' for r in results])}]\")\n\nsolve()\n```", "id": "2849743"}]}