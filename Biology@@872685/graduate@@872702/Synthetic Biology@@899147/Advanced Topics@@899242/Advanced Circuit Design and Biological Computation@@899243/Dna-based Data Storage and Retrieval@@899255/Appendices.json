{"hands_on_practices": [{"introduction": "A key challenge in DNA data storage is that certain base sequences are difficult to synthesize or sequence accurately. Long runs of the same nucleotide, known as homopolymers, are a primary example. This practice problem [@problem_id:2730426] delves into the principles of constrained coding, where you will design a system that explicitly forbids these problematic sequences. By constructing a finite-state machine to represent the coding constraint, you will learn how to calculate the theoretical maximum information density, or \"capacity,\" of the storage medium, a fundamental metric for evaluating the efficiency of any data storage architecture.", "problem": "A synthetic DNA (Deoxyribonucleic Acid) storage device is required to map binary input symbols to DNA output symbols while forbidding the substrings `AAAA` and `CCCC` anywhere in the output, in order to mitigate homopolymer-associated sequencing errors. \n\nTask:\n1) Construct a minimal deterministic finite-state transducer (FST) that emits symbols from the alphabet $\\{A,C,G,T\\}$ and guarantees that no emitted string ever contains `AAAA` or `CCCC`. Your construction must be minimal in the sense of deterministic finite-state realization: the set of states must encode exactly the minimum necessary memory about the recent output history to enforce the constraint, without redundancy. Explicitly specify the states and the allowed transitions labeled by output symbols.\n\n2) Starting from first principles for constrained systems, derive the asymptotic growth rate of the number of admissible output strings of length $n$, and from it determine the maximum achievable information rate, in bits per nucleotide, for mapping independent fair binary input into output strings produced by your FST without violating the constraint. Base your derivation on standard definitions and well-tested results from finite-state constrained coding theory (e.g., counting admissible sequences via a state transition graph and asymptotic growth rates from spectral radii), not on any shortcut formulas introduced ad hoc for this particular constraint.\n\n3) Report the maximum achievable coding rate in bits per nucleotide as a single real number, rounded to $4$ significant figures. Express the final answer in bits per nucleotide as instructed (do not include units in your final boxed answer).", "solution": "The problem given is a well-posed problem in applied information theory, specifically in the domain of constrained coding for data storage systems. It is scientifically grounded, as homopolymer runs are a known source of errors in DNA sequencing. The problem is to design a code that avoids such runs and to calculate the theoretical maximum efficiency of such a code. The solution requires the application of standard methods from the theory of finite automata and symbolic dynamics.\n\nThe problem consists of three parts. First, the construction of a minimal state machine to enforce the constraint. Second, the derivation of the maximum information rate, or capacity, for this constrained system. Third, the calculation of this capacity's numerical value.\n\n**Part 1: Construction of the Minimal Finite-State Realization**\n\nThe constraint is that the output sequence, composed of symbols from the alphabet $\\{A, C, G, T\\}$, must not contain the substrings `AAAA` or `CCCC`. To enforce this, a system must maintain memory of the recent output sequence. Specifically, it must track the length of any terminal run of $A$'s or $C$'s.\n\nA minimal deterministic finite automaton (DFA) that recognizes the set of all valid sequences can be constructed. The states of this DFA will represent the necessary memory. The states correspond to the longest suffix of the sequence that is also a prefix of a forbidden string.\n\nLet the set of states be $Q = \\{S_0, S_A, S_{AA}, S_{AAA}, S_C, S_{CC}, S_{CCC}\\}$. The meaning of each state is as follows:\n- $S_0$: The initial state. The output sequence is empty or its suffix is not a prefix of `AAAA` or `CCCC`. This is the case if the last output symbol was $G$ or $T$.\n- $S_A$: The last output was $A$.\n- $S_{AA}$: The last two outputs were $AA$.\n- $S_{AAA}$: The last three outputs were $AAA$.\n- $S_C$: The last output was $C$.\n- $S_{CC}$: The last two outputs were $CC$.\n- $S_{CCC}$: The last three outputs were $CCC$.\n\nThis set of $7$ states is minimal. To see this, one must demonstrate that each state is distinguishable in the Myhill-Nerode sense. For instance, a sequence ending in state $S_{AA}$ must be distinguished from one ending in $S_{AAA}$, because appending an $A$ is permissible for the former (leading to $S_{AAA}$) but forbidden for the latter. A similar argument applies to all pairs of states.\n\nThe transitions of the automaton are defined by the current state and the next output symbol. All states are accepting states, as any prefix of a valid sequence is itself valid. The transitions are:\n\n- From state $S_0$:\n  - On output $A$, transition to $S_A$.\n  - On output $C$, transition to $S_C$.\n  - On output $G$ or $T$, transition to $S_0$.\n\n- From state $S_A$:\n  - On output $A$, transition to $S_{AA}$.\n  - On output $C$, transition to $S_C$.\n  - On output $G$ or $T$, transition to $S_0$.\n\n- From state $S_{AA}$:\n  - On output $A$, transition to $S_{AAA}$.\n  - On output $C$, transition to $S_C$.\n  - On output $G$ or $T$, transition to $S_0$.\n\n- From state $S_{AAA}$:\n  - On output $A$, this transition is forbidden.\n  - On output $C$, transition to $S_C$.\n  - On output $G$ or $T$, transition to $S_0$.\n\n- From state $S_C$:\n  - On output $C$, transition to $S_{CC}$.\n  - On output $A$, transition to $S_A$.\n  - On output $G$ or $T$, transition to $S_0$.\n\n- From state $S_{CC}$:\n  - On output $C$, transition to $S_{CCC}$.\n  - On output $A$, transition to $S_A$.\n  - On output $G$ or $T$, transition to $S_0$.\n\n- From state $S_{CCC}$:\n  - On output $C$, this transition is forbidden.\n  - On output $A$, transition to $S_A$.\n  - On output $G$ or $T$, transition to $S_0$.\n\nThis automaton describes the structure of all valid output sequences. A finite-state transducer (FST) would be built upon this automaton by assigning input symbols (e.g., from the binary alphabet $\\{0,1\\}$) to the allowed transitions. The maximum information rate is a property of the underlying constraint graph and is independent of any specific input assignment.\n\n**Part 2: Derivation of the Maximum Information Rate**\n\nThe number of admissible output strings of length $n$, denoted $N(n)$, is the total number of paths of length $n$ in the state transition graph starting from $S_0$. For large $n$, $N(n)$ grows asymptotically as $N(n) \\sim k \\cdot \\lambda^n$, where $\\lambda$ is the spectral radius (the largest-magnitude eigenvalue) of the adjacency matrix of the graph. The maximum achievable information rate, or channel capacity $C$, is given by the Shannon-Hartley theorem adapted for discrete noiseless channels, which is the topological entropy of the system:\n$$C = \\lim_{n\\to\\infty} \\frac{\\log_2 N(n)}{n} = \\log_2(\\lambda)$$\n\nThe adjacency matrix $M$ of the state transition graph represents the number of single-symbol transitions between states. Let the states be ordered as $(S_0, S_A, S_{AA}, S_{AAA}, S_C, S_{CC}, S_{CCC})$. The matrix $M$ is:\n$$ M = \\begin{pmatrix}\n2 & 1 & 0 & 0 & 1 & 0 & 0 \\\\\n2 & 0 & 1 & 0 & 1 & 0 & 0 \\\\\n2 & 0 & 0 & 1 & 1 & 0 & 0 \\\\\n2 & 0 & 0 & 0 & 1 & 0 & 0 \\\\\n2 & 1 & 0 & 0 & 0 & 1 & 0 \\\\\n2 & 1 & 0 & 0 & 0 & 0 & 1 \\\\\n2 & 1 & 0 & 0 & 0 & 0 & 0\n\\end{pmatrix} $$\nTo find the eigenvalue $\\lambda$, we solve the characteristic equation $\\det(M - \\lambda I) = 0$. A more direct approach is to establish a system of recurrence relations for the number of paths ending in each state. Let $N_i(n)$ be the number of valid sequences of length $n$ ending in state $i$. For large $n$, we assume an exponential growth form $N_i(n) \\approx c_i \\lambda^n$ for some constants $c_i$. The recurrence relations for the coefficients $c_i$ form a linear system:\nLet's use a simplified notation for the coefficients: $c_0, c_A, c_{AA}, c_{AAA}, c_C, c_{CC}, c_{CCC}$.\nThe system of equations, derived from the transitions into each state, is:\n$\\lambda c_0 = 2(c_0 + c_A + c_{AA} + c_{AAA} + c_C + c_{CC} + c_{CCC})$\n$\\lambda c_A = c_0 + c_C + c_{CC} + c_{CCC}$\n$\\lambda c_{AA} = c_A$\n$\\lambda c_{AAA} = c_{AA}$\n$\\lambda c_C = c_0 + c_A + c_{AA} + c_{AAA}$\n$\\lambda c_{CC} = c_C$\n$\\lambda c_{CCC} = c_{CC}$\n\nFrom these, we can express the coefficients for longer runs in terms of the first one:\n$c_{AA} = c_A/\\lambda$, $c_{AAA} = c_{AA}/\\lambda = c_A/\\lambda^2$.\n$c_{CC} = c_C/\\lambda$, $c_{CCC} = c_{CC}/\\lambda = c_C/\\lambda^2$.\n\nLet $g(\\lambda) = 1 + \\lambda^{-1} + \\lambda^{-2}$. The system for $c_A$ and $c_C$ becomes:\n$\\lambda c_A = c_0 + c_C(1 + \\lambda^{-1} + \\lambda^{-2}) = c_0 + c_C g(\\lambda)$\n$\\lambda c_C = c_0 + c_A(1 + \\lambda^{-1} + \\lambda^{-2}) = c_0 + c_A g(\\lambda)$\n\nSubtracting these two equations yields $(\\lambda + g(\\lambda))(c_A - c_C) = 0$. Since $\\lambda > 0$ and $g(\\lambda) > 0$, we must have $c_A = c_C$.\nSubstituting $c_A = c_C$ gives $c_A(\\lambda - g(\\lambda)) = c_0$.\n\nThe first equation for $c_0$ involves the sum of all coefficients $\\sum_i c_i$.\n$\\sum_i c_i = c_0 + c_A(1+\\lambda^{-1}+\\lambda^{-2}) + c_C(1+\\lambda^{-1}+\\lambda^{-2}) = c_0 + 2c_A g(\\lambda)$.\nSo, $\\lambda c_0 = 2(c_0 + 2c_A g(\\lambda))$, which means $(\\lambda - 2)c_0 = 4c_A g(\\lambda)$.\n\nWe now have a system of two equations for $c_0$ and $c_A$:\n1) $c_A(\\lambda - g(\\lambda)) = c_0$\n2) $(\\lambda - 2)c_0 = 4c_A g(\\lambda)$\n\nSubstituting (1) into (2) for a non-trivial solution ($c_A \\ne 0, c_0 \\ne 0$):\n$(\\lambda - 2)c_A(\\lambda - g(\\lambda)) = 4c_A g(\\lambda)$\n$(\\lambda - 2)(\\lambda - g(\\lambda)) = 4g(\\lambda)$\n$\\lambda(\\lambda - 2) - (\\lambda - 2)g(\\lambda) = 4g(\\lambda)$\n$\\lambda(\\lambda - 2) = (4 + \\lambda - 2)g(\\lambda) = (\\lambda + 2)g(\\lambda)$\n\nSubstituting $g(\\lambda) = 1 + \\lambda^{-1} + \\lambda^{-2} = \\frac{\\lambda^2+\\lambda+1}{\\lambda^2}$:\n$\\lambda(\\lambda - 2) = (\\lambda + 2)\\frac{\\lambda^2+\\lambda+1}{\\lambda^2}$\nMultiplying by $\\lambda^2$:\n$\\lambda^3(\\lambda - 2) = (\\lambda + 2)(\\lambda^2 + \\lambda + 1)$\n$\\lambda^4 - 2\\lambda^3 = \\lambda^3 + \\lambda^2 + \\lambda + 2\\lambda^2 + 2\\lambda + 2$\n$\\lambda^4 - 2\\lambda^3 = \\lambda^3 + 3\\lambda^2 + 3\\lambda + 2$\nThis simplifies to the characteristic polynomial for $\\lambda$:\n$$ \\lambda^4 - 3\\lambda^3 - 3\\lambda^2 - 3\\lambda - 2 = 0 $$\nBy the Perron-Frobenius theorem, this irreducible and aperiodic system has a unique positive real eigenvalue $\\lambda$ that determines the growth rate.\n\n**Part 3: Numerical Calculation of the Information Rate**\n\nThe polynomial $\\lambda^4 - 3\\lambda^3 - 3\\lambda^2 - 3\\lambda - 2 = 0$ does not have simple analytical roots and must be solved numerically. The maximum number of choices from any state is $4$, so $\\lambda \\le 4$.\nLet $P(\\lambda) = \\lambda^4 - 3\\lambda^3 - 3\\lambda^2 - 3\\lambda - 2$.\n$P(3) = 81 - 81 - 27 - 9 - 2 = -38$.\n$P(4) = 256 - 192 - 48 - 12 - 2 = 2$.\nThe root $\\lambda$ is between $3$ and $4$. Numerical methods (such as Newton's method or bisection) yield the solution:\n$$\\lambda \\approx 3.97436$$\nThe maximum achievable coding rate $C$ is then calculated in bits per nucleotide:\n$$C = \\log_2(\\lambda) = \\log_2(3.97436)$$\n$$ C \\approx 1.99105 $$\nRounding to $4$ significant figures, the capacity is $1.991$ bits per nucleotide. This represents the theoretical upper limit on the amount of information that can be encoded per DNA base under the given constraints.", "answer": "$$\\boxed{1.991}$$", "id": "2730426"}, {"introduction": "While constrained codes can prevent predictable synthesis and sequencing errors, data can also be corrupted by random physical events like base deletions. In variable-length codes, which are often used to improve coding efficiency, a single deletion can cause a catastrophic loss of synchronization, corrupting all subsequent data. This exercise [@problem_id:2730469] explores this critical failure mode and its mitigation, demonstrating the crucial trade-off between coding efficiency and error resilience. You will analyze how synchronization markers can be used to contain error propagation and quantify the expected data loss in such a system.", "problem": "A variable-length binary-to-deoxyribonucleic acid (DNA) mapper is defined by the prefix-free code that maps each source symbol of $2$ bits to a DNA codeword over the alphabet $\\{ \\mathrm{A}, \\mathrm{C}, \\mathrm{G}, \\mathrm{T} \\}$ as follows: $00 \\mapsto \\mathrm{A}$, $01 \\mapsto \\mathrm{CG}$, $10 \\mapsto \\mathrm{CT}$, $11 \\mapsto \\mathrm{GA}$. Assume independent and identically distributed (i.i.d.) equiprobable source bits, so each $2$-bit symbol is equally likely. The encoder concatenates the DNA codewords and, after every block of $N$ source symbols (each of $2$ bits), inserts a reserved state delimiter $\\mathrm{AT}$ that is never produced by the data code. The decoder performs greedy prefix decoding of the data code, continuously scans the received DNA stream for the reserved delimiter $\\mathrm{AT}$, and on seeing it resets to a known synchronization state and discards any partial codeword.\n\nSuppose exactly one single-base deletion occurs at a uniformly random base position in a very long encoded stream. Evaluate the error propagation characteristics (in terms of the number of source bits that are incorrectly decoded or irrecoverably lost) from the deletion point until the next successful resynchronization at a delimiter, and propose a sound resynchronization strategy using reserved states for this mapper. In particular, for $N=64$, which statement is most accurate about:\n\n- whether error propagation is bounded or unbounded without reserved states,\n- the expected number of misdecoded or lost source bits until resynchronization when using the delimiter scheme described,\n- a rigorous worst-case bound on the number of misdecoded or lost source bits per single-base deletion under this scheme, and\n- the correctness of the delimiter design with respect to false positives and detectability under single-base deletion?\n\nChoose the single best option.\n\nA. Without reserved states, a single-base deletion causes unbounded error propagation in this variable-length stream. With the reserved-state delimiter $\\mathrm{AT}$ inserted after every $N=64$ source symbols, the expected number of source bits affected until resynchronization is approximately $64$, with the exact large-block expression $$\\mathbb{E}[\\text{lost bits}] \\approx \\left(\\frac{8}{7}\\right)\\cdot \\frac{\\mathbb{E}[X^{2}]}{2\\,\\mathbb{E}[X]},$$ where $X$ is the random number of data bases in a block (excluding the delimiter); numerically, $\\mathbb{E}[X]=\\frac{7}{4}N=112$, $\\mathrm{Var}(X)=\\frac{3}{16}N=12$, so $\\frac{\\mathbb{E}[X^{2}]}{2\\mathbb{E}[X]} \\approx 56.10$ bases and $\\mathbb{E}[\\text{lost bits}] \\approx 64.11$ bits. A rigorous worst-case bound is $2N=128$ bits per deletion, attained if the deletion occurs immediately after a delimiter and forces discarding the entire following block. The delimiter $\\mathrm{AT}$ is comma-free relative to the data code (it never appears within or straddling data codewords), so it yields reliable resynchronization and no false positives under a single-base deletion.\n\nB. Because the code is prefix-free, a single-base deletion affects at most the codeword containing the deletion; the error does not propagate, so at most $2$ source bits are lost. Reserved states are therefore unnecessary for synchronization in this setting.\n\nC. Use a reserved single-base state $\\mathrm{T}$ inserted every $N=32$ source symbols; because $\\mathrm{T}$ is frequent, the expected number of lost bits until resynchronization is about $16$. This works since any $\\mathrm{T}$ uniquely indicates a delimiter and does not conflict with the data code.\n\nD. Replace $\\mathrm{AT}$ by a longer reserved marker $\\mathrm{ATG}$ inserted every $N=64$ source symbols; because a single-base deletion cannot destroy detection of a length-$3$ marker, the expected number of lost bits becomes strictly less than $32$, and false positives are impossible by prefix-freeness.", "solution": "The user-provided problem will first be validated for scientific and logical integrity.\n\n### Step 1: Extract Givens\n- **Source Symbols**: $2$-bit binary symbols $\\{00, 01, 10, 11\\}$.\n- **Source Statistics**: Independent and identically distributed (i.i.d.) and equiprobable. This implies each $2$-bit symbol has a probability of $p = 1/4$.\n- **DNA Alphabet**: $\\{\\mathrm{A}, \\mathrm{C}, \\mathrm{G}, \\mathrm{T}\\}$.\n- **Code Mapping**: A variable-length, prefix-free code:\n  - $00 \\mapsto \\mathrm{A}$ (length $1$)\n  - $01 \\mapsto \\mathrm{CG}$ (length $2$)\n  - $10 \\mapsto \\mathrm{CT}$ (length $2$)\n  - $11 \\mapsto \\mathrm{GA}$ (length $2$)\n- **Encoding Scheme**:\n  - A block consists of encoding $N$ source symbols.\n  - After each block of $N$ symbols, a reserved state delimiter $\\mathrm{AT}$ is inserted.\n- **Delimiter Property**: $\\mathrm{AT}$ is never produced by the concatenation of data codewords.\n- **Decoding Scheme**:\n  - Greedy prefix decoding is used for data.\n  - The stream is continuously scanned for the delimiter $\\mathrm{AT}$.\n  - Upon detection of $\\mathrm{AT}$, the decoder resets to a synchronized state, and any partial codeword being processed is discarded.\n- **Error Model**: A single-base deletion occurs at a uniformly random position in a very long encoded stream.\n- **Specific Parameter**: Block size $N=64$.\n- **Question**: Evaluate several aspects of the system's response to the single-base deletion, including error propagation, expected data loss, worst-case data loss, and delimiter design correctness.\n\n### Step 2: Validate Using Extracted Givens\nThe problem is subjected to validation against the required criteria.\n\n- **Scientifically Grounded**: The problem is situated in the field of synthetic biology, specifically DNA-based data storage. The concepts of binary-to-DNA encoding, variable-length prefix codes, synchronization markers (delimiters), and error models (single-base deletions) are standard and scientifically valid within this discipline and the broader field of information and coding theory. The setup is a legitimate theoretical exercise in channel coding.\n- **Well-Posed**: The problem is well-defined. The code, source statistics, encoding protocol, and error event are all explicitly specified. The questions posed are quantitative and qualitative assessments that can be answered through logical deduction and calculation based on the provided information.\n- **Objective**: The language is technical, precise, and free of subjectivity or ambiguity.\n- **Consistency and Completeness**: The problem statement is internally consistent. The code given is indeed a prefix code ('A' is not a prefix of 'CG', 'CT', or 'GA', etc.). The delimiter 'AT' is, as claimed, not formable by concatenating data codewords, a property known as comma-freedom. All necessary parameters ($N$, the code itself) are provided.\n\n**Verdict**: The problem statement is valid. It is a well-posed, scientifically grounded problem in coding theory applied to DNA storage. The solution process can proceed.\n\n### Derivation and Option Analysis\n\nThe problem requires an analysis of error propagation due to a single-base deletion.\n\n**1. Error Propagation without Delimiters**\n\nA single-base deletion in a data stream encoded with a variable-length code causes a frame shift. After the deletion, the decoder's reading frame is misaligned with the original codeword boundaries. Because codeword lengths are not uniform (lengths $1$ and $2$), the decoder will parse a sequence of bases that is different from the original. For example, if the original sequence is `...CG|A|CT...` and the `G` is deleted, the stream becomes `...CACT...`. The decoder, after the previous correct codeword, sees `C...`. It may parse `CT` from `...CA[CT]...`, but this is the wrong symbol at the wrong position. There is a very low probability that the decoder will naturally regain synchronization with the original frame. Therefore, a single deletion will lead to a cascade of subsequent decoding errors. This error propagation is, in principle, unbounded, continuing indefinitely or until the end of the data stream.\n\nThis analysis immediately invalidates Option B, which incorrectly claims that errors from a deletion are localized because the code is prefix-free. The prefix property ensures correct decoding only in the absence of errors that alter symbol boundaries.\n\n**2. Statistical Properties of the Code**\n\nLet $s$ be a source symbol, and let $l(s)$ be the length of its corresponding DNA codeword. The source symbols are equiprobable ($P(s)=1/4$).\n- Codeword lengths are $l(00)=1$, $l(01)=2$, $l(10)=2$, $l(11)=2$.\n- The expected codeword length is $$\\mathbb{E}[l] = 1 \\cdot \\frac{1}{4} + 2 \\cdot \\frac{1}{4} + 2 \\cdot \\frac{1}{4} + 2 \\cdot \\frac{1}{4} = \\frac{1+2+2+2}{4} = \\frac{7}{4}$$ bases per source symbol.\n- The expected value of the squared length is $$\\mathbb{E}[l^2] = 1^2 \\cdot \\frac{1}{4} + 2^2 \\cdot \\frac{1}{4} + 2^2 \\cdot \\frac{1}{4} + 2^2 \\cdot \\frac{1}{4} = \\frac{1+4+4+4}{4} = \\frac{13}{4}$$.\n- The variance of the codeword length is $$\\mathrm{Var}(l) = \\mathbb{E}[l^2] - (\\mathbb{E}[l])^2 = \\frac{13}{4} - \\left(\\frac{7}{4}\\right)^2 = \\frac{52}{16} - \\frac{49}{16} = \\frac{3}{16}$$.\n\nA data block consists of $N=64$ i.i.d. symbols. Let $X$ be the random variable for the total length of the data portion of a block.\n- Expected data block length: $\\mathbb{E}[X] = N \\cdot \\mathbb{E}[l] = 64 \\cdot \\frac{7}{4} = 16 \\cdot 7 = 112$ bases.\n- Variance of data block length: $\\mathrm{Var}(X) = N \\cdot \\mathrm{Var}(l) = 64 \\cdot \\frac{3}{16} = 4 \\cdot 3 = 12$.\nThese values match the parameters given in Option A.\n\n**3. Expected Number of Lost Bits**\n\nWhen a single-base deletion occurs, the decoder loses synchronization. It will only resynchronize upon seeing the next valid delimiter, $\\mathrm{AT}$. The data between the point of error and the next delimiter is effectively lost.\n\nThe deletion occurs at a uniformly random base position. Most bases belong to data blocks, not delimiters. The total length of a block in the stream is $X+2$. The expected total length is $\\mathbb{E}[X]+2 = 112+2 = 114$. The fraction of bases in delimiters is small ($2/114 \\approx 1.75\\%$).\n\nLet us analyze the main scenario where the deletion occurs within a data block. This is a classic \"inspection paradox\" or renewal theory problem. The expected number of bases from a random point in a data block to its end is given by the formula for expected residual life:\n$$\\mathbb{E}[X_{rem}] = \\frac{\\mathbb{E}[X^2]}{2\\mathbb{E}[X]}$$\n- $\\mathbb{E}[X^2] = \\mathrm{Var}(X) + (\\mathbb{E}[X])^2 = 12 + (112)^2 = 12 + 12544 = 12556$.\n- $\\mathbb{E}[X_{rem}] = \\frac{12556}{2 \\cdot 112} = \\frac{12556}{224} \\approx 56.05$ bases.\n\nThese lost bases must be converted to lost source bits. The average information rate is $2$ bits per source symbol, and the average codeword length is $\\mathbb{E}[l]=7/4$ bases. The average number of bits per base is $\\frac{2}{7/4} = \\frac{8}{7}$ bits/base.\n- Expected lost bits, assuming the deletion is in a data block: $\\mathbb{E}[\\text{lost bits}] = \\mathbb{E}[X_{rem}] \\cdot \\frac{8}{7} \\approx 56.0536 \\cdot \\frac{8}{7} \\approx 64.06$ bits.\n\nThis calculation shows that the formula and the resulting value in Option A are a very good approximation. The statement that the expected loss is \"approximately $64$\" bits is accurate. The minor difference between $64.06$ and the option's $64.11$ arises from their use of a rounded intermediate value for $\\frac{\\mathbb{E}[X^2]}{2\\mathbb{E}[X]}$. The provided formula is conceptually correct for this estimation.\n\nA more complete calculation would account for deletions hitting the delimiter, which would cause the loss of the entire next block ($128$ bits). This would slightly increase the expectation: $(64.06) \\frac{112}{114} + (128) \\frac{2}{114} \\approx 65.18$ bits. However, as an approximation, \"approximately 64\" is sound.\n\n**4. Worst-Case Bound**\n\nThe worst-case scenario for data loss involves losing one entire block of $N$ symbols. This can happen in two ways:\n- **Deletion at the start of a data block**: If the deletion occurs in the first few bases of a data block, the decoder immediately loses sync. It will be unable to correctly decode any symbols until it finds the delimiter at the end of that block. This results in the loss of all $N=64$ source symbols, which is $2 \\cdot 64 = 128$ bits.\n- **Deletion in a delimiter**: If a deletion mutates $\\mathrm{AT}$ to $\\mathrm{A}$ or $\\mathrm{T}$, the delimiter may be missed. If it becomes $\\mathrm{T}$, the decoder is stuck as no codeword starts with $\\mathrm{T}$. It will scan until it finds the *next* block's delimiter. In doing so, it discards the entire following data block, resulting in a loss of $N=64$ symbols, or $128$ bits. (If it becomes `A`, it is decoded as a data symbol, and the next block is decoded correctly, a much smaller error).\nTherefore, a rigorous worst-case bound is the loss of one full block, which is $2N = 128$ bits. This matches the claim in Option A.\n\n**5. Correctness of Delimiter `AT`**\n\n- **False Positives (Error-Free)**: The delimiter $\\mathrm{AT}$ is stated to be comma-free. Let's verify. Can a sequence of codewords $\\{ \\mathrm{A}, \\mathrm{CG}, \\mathrm{CT}, \\mathrm{GA} \\}$ create $\\mathrm{AT}$? A codeword ending just before the 'A' of 'AT' could be 'A' or 'GA'. The codeword *containing* 'A' must be 'A' itself. The next codeword must then start with 'T'. No codeword starts with 'T'. Therefore, `AT` cannot be formed by concatenating codewords. The claim is correct.\n- **Robustness to single-base deletion**:\n    - **Creation (False Positive)**: Can a deletion create `AT`? Consider the valid codeword sequence `A | CT` which corresponds to the DNA sequence `ACT`. If the `C` is deleted, the sequence becomes `AT`. The decoder would incorrectly identify this as a delimiter, causing premature block termination and data loss. So, the delimiter is not robust against being created by a deletion.\n    - **Destruction (Missed Detection)**: A single deletion in `AT` yields either `A` or `T`. In either case, the decoder will not find `AT`. The delimiter is destroyed.\nThe final sentence of Option A claims the delimiter \"yields reliable resynchronization and no false positives under a single-base deletion.\" This is false. Its reliability is compromised by this specific error model.\n\n### Option-by-Option Analysis\n\n**A.** This option correctly states that error propagation is unbounded without delimiters. It provides a quantitatively sound model and a correct estimate for the expected number of lost bits ($\\approx 64$). It correctly identifies the worst-case loss as $2N=128$ bits. Its only flaw is the final sentence, which incorrectly overstates the robustness of the $\\mathrm{AT}$ delimiter to single-base deletions.\n\n**B.** This option is fundamentally incorrect. It misunderstands the effect of deletion errors on variable-length codes. The prefix-free property does not prevent catastrophic error propagation from frame-shift errors.\n\n**C.** This option proposes using `T` as a delimiter. This is invalid because the codeword `CT` contains `T`. The decoder would be unable to distinguish a delimiter from data, leading to constant false detections.\n\n**D.** This option proposes a longer marker `ATG` and falsely claims \"a single-base deletion cannot destroy detection of a length-3 marker\". This is patently false; deleting any base from `ATG` results in a new length-2 sequence (`TG`, `AG`, or `AT`) that will not be recognized as `ATG`.\n\n### Conclusion\nOptions B, C, and D are based on fundamental errors in coding theory. Option A provides a detailed and largely correct analysis of the system's behavior. It correctly identifies the nature of error propagation, gives a sound estimate for the expected loss based on a proper theoretical model from stochastic processes, and correctly determines the worst-case loss. Its only error is an over-enthusiastic and incorrect assessment of the delimiter's robustness in its final sentence. Despite this flaw, it is overwhelmingly the \"most accurate\" choice among the given options.\n\nFinal verdict on each option:\n- **A**: Mostly correct quantitative and qualitative analysis, with one incorrect statement about delimiter robustness. **Correct** (as the best option available).\n- **B**: Fundamentally incorrect premise about error propagation. **Incorrect**.\n- **C**: Proposes a non-functional delimiter scheme. **Incorrect**.\n- **D**: Based on a false claim about marker robustness. **Incorrect**.", "answer": "$$\\boxed{A}$$", "id": "2730469"}, {"introduction": "The final stage of data retrieval from a DNA pool is a massive random sampling experiment performed by a sequencer. Due to the stochastic nature of this process, there is no guarantee that every unique DNA molecule will be sampled, leading to potential data loss. In this exercise [@problem_id:2730425], you will develop a foundational statistical model for this retrieval process. By deriving from first principles the probability of \"oligonucleotide dropout\"—the complete failure to sequence a specific data-carrying molecule—you will gain insight into the relationship between sequencing depth ($\\lambda$) and the reliability of data recovery.", "problem": "A DNA-based archival system encodes digital information into a well-mixed pool of $M$ unique oligonucleotides, each present at equal molar abundance. A sequencing run performs $R$ independent read events. For each read event, a single molecule is captured and sequenced, and the probability that a particular target oligonucleotide is captured in any given event is $1/M$, assuming unbiased sampling and no amplification bias or read-to-read dependence. Define the mean per-oligonucleotide coverage as $\\lambda = R/M$. In the asymptotic regime of large libraries and deep sequencing where $M \\to \\infty$ and $R \\to \\infty$ while $\\lambda$ remains fixed, the number of reads mapping to any given oligonucleotide is modeled as a Poisson count with mean $\\lambda$ under the standard independent sampling assumptions of massively parallel sequencing.\n\nStarting from the independent Bernoulli sampling model and without appealing to any pre-stated target formula, derive from first principles the limiting probability that a particular oligonucleotide is completely missing from the sequencing output (that is, receives $0$ reads) as a function of $\\lambda$. Provide your final result as a single closed-form analytic expression in terms of $\\lambda$. No numerical approximation or rounding is required, and no units are needed since this is a probability.", "solution": "The problem statement has been validated and is deemed scientifically sound, well-posed, and objective. It poses a standard, non-trivial question in probabilistic modeling relevant to genomics and synthetic biology. We will proceed with the derivation from first principles as requested.\n\nThe process of sequencing molecules from a a large pool can be modeled as a series of independent trials. We consider a single, specific oligonucleotide from the pool of $M$ unique types. For each of the $R$ independent read events, we define a \"success\" as the event where our specific oligonucleotide is captured and sequenced.\n\nGiven that the pool is well-mixed and all $M$ oligonucleotides are at equal molar abundance, the probability of success in any single trial is $p = 1/M$. Consequently, the probability of \"failure\" (sequencing any of the other $M-1$ oligonucleotides) is $q = 1 - p = 1 - 1/M$.\n\nThe total number of reads, $R$, constitutes the number of independent Bernoulli trials. The number of reads mapping to our specific oligonucleotide, which we denote by the random variable $k$, therefore follows a binomial distribution with parameters $n=R$ and $p=1/M$. The probability mass function for observing exactly $k$ reads is given by:\n$$P(k) = \\binom{R}{k} p^k (1-p)^{R-k} = \\binom{R}{k} \\left(\\frac{1}{M}\\right)^k \\left(1 - \\frac{1}{M}\\right)^{R-k}$$\nThe problem asks for the probability that the oligonucleotide is \"completely missing,\" which corresponds to the case where it receives $k=0$ reads. We substitute $k=0$ into the binomial probability mass function:\n$$P(k=0) = \\binom{R}{0} \\left(\\frac{1}{M}\\right)^0 \\left(1 - \\frac{1}{M}\\right)^{R-0}$$\nBy definition, $\\binom{R}{0} = 1$ and for any non-zero base, $x^0 = 1$. This simplifies the expression to:\n$$P(k=0) = \\left(1 - \\frac{1}{M}\\right)^R$$\nThis formula gives the exact probability for finite $M$ and $R$. The problem, however, specifies an asymptotic regime where $M \\to \\infty$ and $R \\to \\infty$ while the mean per-oligonucleotide coverage, $\\lambda = R/M$, remains a fixed constant.\n\nTo find the limiting probability, we first express $R$ in terms of $M$ and the constant $\\lambda$: $R = \\lambda M$. We substitute this into our expression for $P(k=0)$:\n$$P(k=0) = \\left(1 - \\frac{1}{M}\\right)^{\\lambda M}$$\nWe must now evaluate the limit of this expression as $M \\to \\infty$. Let the limiting probability be $P_0$.\n$$P_0 = \\lim_{M \\to \\infty} \\left(1 - \\frac{1}{M}\\right)^{\\lambda M}$$\nUsing the property of exponents $(a^b)^c = a^{bc}$, we can rewrite the expression as:\n$$P_0 = \\lim_{M \\to \\infty} \\left[ \\left(1 - \\frac{1}{M}\\right)^M \\right]^{\\lambda}$$\nThis form contains a well-known limit that serves as a fundamental definition of the exponential function:\n$$\\lim_{n \\to \\infty} \\left(1 + \\frac{x}{n}\\right)^n = \\exp(x)$$\nFor our case, we set the variable $n=M$ and the constant $x=-1$. The limit of the inner part of our expression is therefore:\n$$\\lim_{M \\to \\infty} \\left(1 - \\frac{1}{M}\\right)^M = \\lim_{M \\to \\infty} \\left(1 + \\frac{-1}{M}\\right)^M = \\exp(-1)$$\nSince the function $f(y) = y^{\\lambda}$ is continuous for a fixed $\\lambda$, the limit of the function is the function of the limit. We can thus substitute the result of the inner limit back into our expression for $P_0$:\n$$P_0 = \\left[ \\lim_{M \\to \\infty} \\left(1 - \\frac{1}{M}\\right)^M \\right]^{\\lambda} = \\left(\\exp(-1)\\right)^{\\lambda}$$\nApplying the rules of exponents once more, we arrive at the final expression:\n$$P_0 = \\exp(-\\lambda)$$\nThis result represents the limiting probability that a particular oligonucleotide receives zero reads as a function of the mean coverage $\\lambda$. This derivation, beginning from the basic Bernoulli trial model, rigorously establishes the required probability without pre-supposing the Poisson distribution, although the result is indeed the probability of a zero outcome for a Poisson random variable with mean $\\lambda$.", "answer": "$$\\boxed{\\exp(-\\lambda)}$$", "id": "2730425"}]}