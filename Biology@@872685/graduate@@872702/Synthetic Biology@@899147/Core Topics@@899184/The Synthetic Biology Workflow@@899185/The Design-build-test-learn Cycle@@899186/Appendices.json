{"hands_on_practices": [{"introduction": "The Design-Build-Test-Learn cycle is powered by iterative refinement, where we learn from discrepancies between our designs and reality. This first practice explores a foundational challenge: what happens when a simple theoretical model clashes with experimental data? By analyzing why a biosensor's response saturates instead of remaining linear, you will practice the crucial \"Learn\" step of identifying the underlying biological principles that must be incorporated into the next \"Design\" iteration. [@problem_id:2074912]", "problem": "A team of undergraduate students is working on a synthetic biology project following the Design-Build-Test-Learn (DBTL) cycle. Their goal is to create a whole-cell biosensor in *E. coli* to detect a specific small molecule, the analyte.\n\n**Design Phase:** The students design a simple genetic circuit. In this circuit, a constitutively expressed repressor protein binds to a promoter and blocks the transcription of a gene for a Green Fluorescent Protein (GFP). The analyte molecule can bind to the repressor protein, causing the repressor to detach from the promoter. This de-repression allows the cell to produce GFP, resulting in a fluorescent signal. The students' initial mathematical model for the \"Design\" phase assumes a simple linear relationship: they predict that the steady-state fluorescence output of the cell culture is directly proportional to the concentration of the analyte added to the growth medium.\n\n**Test Phase:** The students \"Build\" the circuit in *E. coli* and \"Test\" it by measuring the steady-state fluorescence at various concentrations of the analyte. They observe that at low analyte concentrations, the fluorescence does increase roughly linearly as predicted. However, as they add more and more analyte, the increase in fluorescence slows down and eventually reaches a plateau, where further additions of the analyte cause no significant change in the fluorescence level. This observed saturating behavior contradicts their initial linear model.\n\n**Learn Phase:** The students must now \"Learn\" from this discrepancy to refine their model. Which of the following biological factors is the most direct and primary reason for the observed saturation, which their initial linear model failed to account for?\n\nA. The total number of repressor protein molecules within each cell is finite.\n\nB. The rate of degradation of the analyte molecule by cellular enzymes.\n\nC. The metabolic cost to the cell of synthesizing the Green Fluorescent Protein.\n\nD. The rate at which the Green Fluorescent Protein matures into its fluorescent form.\n\nE. The limited availability of ribosomes for translating the repressor protein's messenger RNA (mRNA).", "solution": "Let $[A]$ denote the analyte concentration, $R_{\\mathrm{tot}}$ the total cellular concentration (or number per cell scaled to concentration) of repressor, $[R]$ the free repressor, and $[AR]$ the analyte–repressor complex. The analyte binds the repressor according to the law of mass action,\n$$\nA + R \\rightleftharpoons AR, \\quad K_{A} = \\frac{[A][R]}{[AR]}.\n$$\nMass conservation of the repressor gives\n$$\nR_{\\mathrm{tot}} = [R] + [AR] + [RP],\n$$\nwhere $[RP]$ is the promoter-bound repressor. Typically, the number of promoter sites is small compared to $R_{\\mathrm{tot}}$, so for the dependence on $[A]$ we can write the dominant conservation as\n$$\nR_{\\mathrm{tot}} \\approx [R] + [AR].\n$$\nUsing $[AR] = \\frac{[A][R]}{K_{A}}$, we obtain\n$$\nR_{\\mathrm{tot}} = [R] \\left( 1 + \\frac{[A]}{K_{A}} \\right)\n\\quad \\Longrightarrow \\quad\n[R] = \\frac{R_{\\mathrm{tot}}}{1 + \\frac{[A]}{K_{A}}}.\n$$\n\nRepressor binding to the promoter is described by\n$$\nR + P \\rightleftharpoons RP, \\quad K_{R} = \\frac{[R][P]}{[RP]},\n$$\nwith $P_{\\mathrm{tot}} = [P] + [RP]$. The fraction of promoter free of repressor is\n$$\nf_{\\mathrm{free}} = \\frac{[P]}{P_{\\mathrm{tot}}} = \\frac{K_{R}}{K_{R} + [R]}.\n$$\nAssuming transcription from the free promoter leads to GFP production with maximal steady-state fluorescence $F_{\\max}$ (set by cellular expression capacity and maturation at steady state), the fluorescence as a function of analyte is\n$$\nF([A]) = F_{\\max} \\, f_{\\mathrm{free}} = F_{\\max} \\, \\frac{K_{R}}{K_{R} + [R]}.\n$$\nSubstituting $[R] = \\frac{R_{\\mathrm{tot}}}{1 + \\frac{[A]}{K_{A}}}$ yields\n$$\nF([A]) = F_{\\max} \\, \\frac{K_{R}}{K_{R} + \\dfrac{R_{\\mathrm{tot}}}{1 + \\dfrac{[A]}{K_{A}}}}\n= F_{\\max} \\, \\frac{K_{R} \\left( 1 + \\dfrac{[A]}{K_{A}} \\right)}{K_{R} \\left( 1 + \\dfrac{[A]}{K_{A}} \\right) + R_{\\mathrm{tot}}}.\n$$\n\nTwo limiting regimes follow directly:\n\n1) Low analyte, $[A] \\ll K_{A}$:\n$$\nF([A]) \\approx F_{\\max} \\, \\frac{K_{R}}{K_{R} + R_{\\mathrm{tot}}}\n+ F_{\\max} \\, \\frac{K_{R} \\, R_{\\mathrm{tot}}}{\\left( K_{R} + R_{\\mathrm{tot}} \\right)^{2}} \\, \\frac{[A]}{K_{A}},\n$$\nwhich is approximately linear in $[A]$, consistent with the initial observations at low analyte.\n\n2) High analyte, $[A] \\to \\infty$:\n$$\n[R] \\to 0\n\\quad \\Longrightarrow \\quad\nF([A]) \\to F_{\\max}.\n$$\nThus $F([A])$ saturates at a plateau $F_{\\max}$ because the pool of repressor is finite: once essentially all repressor molecules are sequestered by analyte, the promoter is fully de-repressed and further increases in $[A]$ cannot increase expression beyond the maximal level.\n\nTherefore, the most direct and primary cause of the observed saturation is the finiteness of the number of repressor molecules (equivalently, a finite number of binding sites to be titrated by analyte). Options B, C, D, and E can modulate the position of the curve or the absolute maximal level, or affect dynamics, but they do not constitute the primary mechanistic reason for a saturating dose–response with analyte; the saturation arises fundamentally from the finite repressor pool and promoter occupancy limits captured above.\n\nHence the correct choice is A.", "answer": "$$\\boxed{A}$$", "id": "2074912"}, {"introduction": "A successful synthetic circuit is not just a collection of DNA parts; it is a system interacting with a living host. This exercise examines a common and perplexing issue where a circuit that functions perfectly in one bacterial strain fails in another. By diagnosing this context-dependent failure, you will learn to think beyond the genetic blueprint and consider how the cellular environment—the \"chassis\"—critically impacts your design's performance. [@problem_id:1428108]", "problem": "A synthetic biology team is following the Design-Build-Test-Learn (DBTL) cycle to create a simple genetic switch. Their \"Design\" is a plasmid intended to function as an inducible expression system. The plasmid contains two key components:\n1. A gene expressing the LacI repressor protein, driven by a weak, constitutive promoter.\n2. A gene for a Green Fluorescent Protein (GFP), driven by a strong, LacI-repressible promoter (`P_lac`).\n\nThe team \"Builds\" this plasmid and \"Tests\" it in two different strains of *E. coli*.\n- **Test 1:** In the cloning strain *E. coli* DH5α, the circuit works perfectly. The cells show very low fluorescence in the absence of an inducer and high fluorescence when the inducer is added.\n- **Test 2:** The exact same plasmid is moved to the protein expression strain *E. coli* BL21(DE3). In this strain, the circuit fails. The cells exhibit high GFP fluorescence even in the complete absence of any inducer.\n\nNow in the \"Learn\" phase, the team must form a hypothesis to explain this context-dependent failure. Based on the known general characteristics of cloning strains versus protein expression strains, which one of the following hypotheses is the most plausible explanation for the high basal (leaky) expression observed in BL21(DE3)?\n\nA. The GFP protein is folded into its active, fluorescent conformation much more efficiently in the cytoplasm of BL21(DE3) than in DH5α, leading to a higher fluorescent signal for the same amount of protein.\n\nB. The plasmid's origin of replication leads to a significantly higher plasmid copy number per cell in the BL21(DE3) host environment compared to the DH5α host.\n\nC. The BL21(DE3) strain has a much higher concentration of endogenous proteases that specifically degrade the LacI repressor, reducing its ability to bind to the `P_lac` promoter.\n\nD. The ribosomes in BL21(DE3) translate the `gfp` mRNA sequence at a significantly faster rate than the ribosomes in DH5α, leading to a rapid accumulation of GFP.", "solution": "We begin by identifying the regulatory logic of the circuit. The LacI repressor is produced from a weak constitutive promoter, and the GFP reporter is driven by a strong $P_{\\text{lac}}$ promoter repressed by LacI. In the absence of inducer, repression succeeds if the cellular concentration of active LacI tetramers is sufficiently high relative to the number of $P_{\\text{lac}}$ operator sites and the promoter’s intrinsic strength. When moved across hosts, any factor that decreases the effective LacI repression or increases the effective transcriptional drive of $P_{\\text{lac}}$ can manifest as high basal fluorescence.\n\nWe now evaluate each hypothesis against known, general properties of cloning strains (e.g., DH5α) and protein expression strains (e.g., BL21(DE3)) and against the mechanistic requirements for LacI repression.\n\n- Hypothesis A (improved folding in BL21(DE3)): Enhanced folding efficiency would scale the fluorescence signal per GFP molecule by a multiplicative factor $f$ without altering the transcriptional state of $P_{\\text{lac}}$. This affects readout sensitivity but does not convert a tightly repressed promoter into a transcriptionally derepressed state. High basal fluorescence attributable purely to folding would imply that the same low basal expression in DH5α is simply less detectable, yet the observation is a qualitative failure of repression in BL21(DE3). This is therefore not the most plausible cause of leaky transcription.\n\n- Hypothesis B (higher plasmid copy number in BL21(DE3)): Let $N$ denote the plasmid copy number. The number of operator sites scales as $N$. The total LacI produced from a weak promoter also scales with $N$, but because the LacI promoter is weak and $P_{\\text{lac}}$ is strong, effective repression requires a substantial excess of active repressor over the number of available operator sites, factoring in binding stoichiometry, nonspecific binding, and stochastic fluctuations. In practice, high copy numbers can titrate repressors, and tight control of lac-based promoters often necessitates elevated LacI expression (e.g., lacI^{q}) to overcome operator titration. Host-dependent differences in the control of ColE1-like origins can alter $N$, and expression hosts can yield different $N$ than cloning strains. Thus, an increased $N$ in BL21(DE3) is a plausible general mechanism to increase basal expression by outstripping the weak LacI supply relative to the strong $P_{\\text{lac}}$, thereby causing leak.\n\n- Hypothesis C (higher protease levels degrading LacI in BL21(DE3)): A defining feature of BL21(DE3) is that it is protease-deficient (notably lon^{-}, ompT^{-}), which reduces proteolysis of recombinant proteins. The claim of “much higher concentration of endogenous proteases that specifically degrade LacI” contradicts this general property. This hypothesis is not plausible.\n\n- Hypothesis D (faster translation in BL21(DE3)): There is no general property that BL21(DE3) ribosomes translate mRNA “significantly faster” than DH5α ribosomes across arbitrary genes. Moreover, any global increase in translation rate would affect both LacI and GFP, and would not selectively abolish repression. This is not a compelling or general explanation for leaky transcription.\n\nAmong the options, the mechanism that aligns with a known and commonly encountered failure mode in lac-repressed circuits—operator titration due to increased gene dosage—is Hypothesis B. It explains why a weakly expressed LacI (from a weak constitutive promoter) can be sufficient in DH5α yet fail in BL21(DE3) if the host context increases plasmid copy number and thus the number of strong $P_{\\text{lac}}$ promoters to repress. It also fits the broader principle that host-dependent replication control can modulate copy number and thereby repressor demand.", "answer": "$$\\boxed{B}$$", "id": "1428108"}, {"introduction": "The most effective Design-Build-Test-Learn cycles are driven by quantitative principles. This final practice moves into the advanced \"Design\" phase, where we use mathematical models to plan experiments that will be maximally informative. You will implement a D-optimal design strategy to select the best set of experimental conditions for characterizing a biosensor, a core technique in model-based design of experiments that accelerates learning and minimizes resource expenditure. [@problem_id:2782988]", "problem": "In the Design-Build-Test-Learn (DBTL) cycle of synthetic biology, the Design step selects experimental inputs to maximize the quality of learning in the Learn step. Consider an inducible gene expression system where the steady-state reporter level is modeled by a Hill response to an inducer concentration. Let the deterministic mean response be given by the Hill function $f(x;\\boldsymbol{\\theta})$, where the inducer concentration $x$ is strictly positive and the parameter vector is $\\boldsymbol{\\theta} = (\\alpha,\\beta,K,n)$ with $\\alpha \\in \\mathbb{R}$, $\\beta \\in \\mathbb{R}$, $K \\in \\mathbb{R}_{>0}$, and $n \\in \\mathbb{R}_{>0}$. Assume homoscedastic independent Gaussian measurement noise with variance $\\sigma^2$, so that each observation $y_i$ at input $x_i$ satisfies $y_i = f(x_i;\\boldsymbol{\\theta}) + \\varepsilon_i$, where $\\varepsilon_i \\sim \\mathcal{N}(0,\\sigma^2)$ and the $\\varepsilon_i$ are independent. The goal is to choose a multiset of inducer concentrations that is D-optimal for estimating $\\boldsymbol{\\theta}$ at a specified nominal parameter value, under bounded inputs.\n\nUse the following fundamental base:\n- The Hill mean response is $f(x;\\boldsymbol{\\theta}) = \\alpha + \\beta \\dfrac{x^n}{K^n + x^n}$.\n- For independent Gaussian observations with known variance $\\sigma^2$, the Fisher Information Matrix (FIM) for a design $\\{x_1,\\ldots,x_m\\}$ is $I(\\boldsymbol{\\theta}) = \\dfrac{1}{\\sigma^2} \\sum_{i=1}^{m} \\left(\\nabla_{\\boldsymbol{\\theta}} f(x_i;\\boldsymbol{\\theta})\\right)\\left(\\nabla_{\\boldsymbol{\\theta}} f(x_i;\\boldsymbol{\\theta})\\right)^\\top$.\n- The D-optimality criterion maximizes $\\det\\!\\left(I(\\boldsymbol{\\theta})\\right)$, equivalently maximizes $\\log \\det\\!\\left(I(\\boldsymbol{\\theta})\\right)$ when $I(\\boldsymbol{\\theta})$ is positive definite.\n\nTask: Write a complete program that, for each test case below, computes a D-optimal exact design under the following constraints and conventions:\n- You must choose exactly $m$ trials as a multiset from a finite candidate set $\\Gamma \\subset (0,\\infty)$ of allowable inducer concentrations. Repeated selections correspond to technical replicates at the same concentration. The input bounds are enforced by $\\Gamma$.\n- For a given test case, treat $\\boldsymbol{\\theta}$ and $\\sigma$ as known nominal constants for local D-optimal design.\n- If $I(\\boldsymbol{\\theta})$ is singular for a design, define $\\log \\det\\!\\left(I(\\boldsymbol{\\theta})\\right) = -\\infty$. Among designs achieving the maximum value of $\\log \\det$ up to a tolerance $\\tau = 10^{-12}$, choose the lexicographically smallest sorted multiset of concentrations (ascending order) as the tie-breaker.\n- All concentrations must be reported in micromolar, in non-decreasing order, as floating-point numbers. Duplicates indicate replicates.\n- Angles do not appear. There are no percentages in the output.\n\nYour program must compute $\\nabla_{\\boldsymbol{\\theta}} f(x;\\boldsymbol{\\theta})$ from first principles and evaluate the D-optimal design by exhaustive search over all multisets of size $m$ drawn from $\\Gamma$.\n\nTest suite:\n- Case $1$ (happy path):\n  - $\\boldsymbol{\\theta} = (\\alpha,\\beta,K,n) = (10.0, 90.0, 50.0, 2.0)$\n  - $\\sigma = 5.0$\n  - $\\Gamma = [1.0, 5.0, 10.0, 20.0, 40.0, 60.0, 80.0, 100.0]$ micromolar\n  - $m = 4$\n- Case $2$ (bounded candidates near the dissociation constant and higher noise):\n  - $\\boldsymbol{\\theta} = (\\alpha,\\beta,K,n) = (5.0, 95.0, 10.0, 2.0)$\n  - $\\sigma = 10.0$\n  - $\\Gamma = [2.0, 5.0, 10.0, 20.0]$ micromolar\n  - $m = 4$\n- Case $3$ (under-determined edge case where $m < \\dim(\\boldsymbol{\\theta})$):\n  - $\\boldsymbol{\\theta} = (\\alpha,\\beta,K,n) = (2.0, 18.0, 2.0, 3.0)$\n  - $\\sigma = 1.0$\n  - $\\Gamma = [0.5, 1.0, 2.0, 4.0]$ micromolar\n  - $m = 2$\n\nRequired final output format: Your program should produce a single line of output containing the three designs, each as a list of micromolar concentrations rounded to six digits after the decimal point, aggregated as a comma-separated list enclosed in square brackets, for example, $[[x_{1,1},x_{1,2},\\ldots],[x_{2,1},\\ldots],[x_{3,1},\\ldots]]$. There must be no spaces in the printed line.\n\nScientific realism notes:\n- All candidate concentrations are strictly positive to avoid non-differentiability in logarithms.\n- The Learn step uses Maximum Likelihood Estimation (MLE), whose asymptotic covariance is the inverse of the FIM at the true parameter, motivating D-optimality for design in DBTL.", "solution": "The problem requires the determination of a D-optimal experimental design for estimating the $4$ parameters $\\boldsymbol{\\theta} = (\\alpha, \\beta, K, n)$ of a Hill function model. The design consists of a multiset of $m$ inducer concentrations $\\{x_1, \\ldots, x_m\\}$ chosen from a finite candidate set $\\Gamma$. The D-optimality criterion seeks to maximize the determinant of the Fisher Information Matrix (FIM), $I(\\boldsymbol{\\theta})$, or equivalently, its logarithm, $\\log \\det(I(\\boldsymbol{\\theta}))$.\n\nThe mean response is given by the Hill function:\n$$f(x;\\boldsymbol{\\theta}) = \\alpha + \\beta \\dfrac{x^n}{K^n + x^n}$$\nFor independent Gaussian observations with variance $\\sigma^2$, the FIM for a design $D = \\{x_1, \\ldots, x_m\\}$ is:\n$$I(\\boldsymbol{\\theta}) = \\frac{1}{\\sigma^2} \\sum_{i=1}^{m} \\left(\\nabla_{\\boldsymbol{\\theta}} f(x_i;\\boldsymbol{\\theta})\\right) \\left(\\nabla_{\\boldsymbol{\\theta}} f(x_i;\\boldsymbol{\\theta})\\right)^\\top$$\nMaximizing $\\det(I(\\boldsymbol{\\theta}))$ is equivalent to maximizing $\\det\\left(\\sum_{i=1}^{m} \\mathbf{g}_i \\mathbf{g}_i^\\top\\right)$, where $\\mathbf{g}_i = \\nabla_{\\boldsymbol{\\theta}} f(x_i;\\boldsymbol{\\theta})$, because the constant pre-factor $1/\\sigma^2$ does not alter the location of the optimum. We define the unscaled information matrix $M(D) = \\sum_{x_i \\in D} \\mathbf{g}_i \\mathbf{g}_i^\\top$ and seek to maximize its log-determinant, $\\log \\det(M(D))$.\n\nThe first-principles derivation begins with computing the gradient vector $\\nabla_{\\boldsymbol{\\theta}} f(x;\\boldsymbol{\\theta})$, which consists of the partial derivatives with respect to each parameter in $\\boldsymbol{\\theta}$.\n\n1.  Derivative with respect to the basal level, $\\alpha$:\n    $$\\frac{\\partial f}{\\partial \\alpha} = 1$$\n\n2.  Derivative with respect to the dynamic range, $\\beta$:\n    $$\\frac{\\partial f}{\\partial \\beta} = \\frac{x^n}{K^n + x^n}$$\n\n3.  Derivative with respect to the dissociation constant, $K$:\n    $$\\frac{\\partial f}{\\partial K} = \\beta \\frac{\\partial}{\\partial K} \\left( \\frac{x^n}{K^n + x^n} \\right) = \\beta x^n \\frac{\\partial}{\\partial K} \\left( (K^n + x^n)^{-1} \\right)$$\n    Using the chain rule:\n    $$\\frac{\\partial f}{\\partial K} = \\beta x^n \\left( -1 \\cdot (K^n + x^n)^{-2} \\cdot \\frac{\\partial}{\\partial K}(K^n) \\right) = -\\beta x^n (K^n + x^n)^{-2} (n K^{n-1})$$\n    $$\\frac{\\partial f}{\\partial K} = - \\frac{\\beta n K^{n-1} x^n}{(K^n + x^n)^2}$$\n\n4.  Derivative with respect to the Hill coefficient, $n$:\n    $$\\frac{\\partial f}{\\partial n} = \\beta \\frac{\\partial}{\\partial n} \\left( \\frac{x^n}{K^n + x^n} \\right)$$\n    Using the identity $a^b = e^{b \\ln a}$ and applying the quotient rule to $g(n) = \\frac{u(n)}{v(n)}$ where $u(n) = x^n$ and $v(n) = K^n + x^n$:\n    $$\\frac{\\partial u}{\\partial n} = x^n \\ln x \\quad \\text{and} \\quad \\frac{\\partial v}{\\partial n} = K^n \\ln K + x^n \\ln x$$\n    $$\\frac{\\partial g}{\\partial n} = \\frac{v \\frac{\\partial u}{\\partial n} - u \\frac{\\partial v}{\\partial n}}{v^2} = \\frac{(K^n + x^n)(x^n \\ln x) - x^n(K^n \\ln K + x^n \\ln x)}{(K^n + x^n)^2}$$\n    $$= \\frac{K^n x^n \\ln x + (x^n)^2 \\ln x - K^n x^n \\ln K - (x^n)^2 \\ln x}{(K^n + x^n)^2} = \\frac{K^n x^n (\\ln x - \\ln K)}{(K^n + x^n)^2}$$\n    Thus,\n    $$\\frac{\\partial f}{\\partial n} = \\frac{\\beta K^n x^n \\ln(x/K)}{(K^n + x^n)^2}$$\n\nThe full gradient vector for a given concentration $x$ at nominal parameters $\\boldsymbol{\\theta}$ is:\n$$\\nabla_{\\boldsymbol{\\theta}} f(x;\\boldsymbol{\\theta}) = \\begin{pmatrix} 1 \\\\ \\frac{x^n}{K^n + x^n} \\\\ - \\frac{\\beta n K^{n-1} x^n}{(K^n + x^n)^2} \\\\ \\frac{\\beta K^n x^n \\ln(x/K)}{(K^n + x^n)^2} \\end{pmatrix}$$\n\nThe solution is found via an exhaustive search over all possible multisets of size $m$ drawn from the candidate set $\\Gamma$. This corresponds to combinations with replacement. If $|\\Gamma|=k$, the number of such multisets is $\\binom{k+m-1}{m}$. For each candidate design $D = \\{x_1, \\ldots, x_m\\}$, the computational procedure is as follows:\n1.  Initialize a $4 \\times 4$ zero matrix $M(D)$.\n2.  For each concentration $x_i \\in D$, compute the gradient vector $\\mathbf{g}_i = \\nabla_{\\boldsymbol{\\theta}} f(x_i;\\boldsymbol{\\theta})$ using the nominal parameter values.\n3.  Compute the outer product $\\mathbf{g}_i \\mathbf{g}_i^\\top$, which is a $4 \\times 4$ rank-$1$ matrix, and add it to $M(D)$.\n4.  After summing over all $x_i \\in D$, compute the objective function value, which is the log-determinant of the resulting matrix $M(D)$. If $M(D)$ is singular, its determinant is $0$, and its log-determinant is defined as $-\\infty$. This is handled numerically by checking the sign returned by `numpy.linalg.slogdet`.\n\nThe optimal design is the one that maximizes this objective function. A list of all candidate designs and their corresponding log-determinant values is generated. The maximum log-determinant, $\\mathcal{L}_{max}$, is identified. All designs whose log-determinant $\\mathcal{L}$ satisfies $|\\mathcal{L} - \\mathcal{L}_{max}| \\le \\tau$, where the tolerance is $\\tau = 10^{-12}$, are considered optimal. Among this set of optimal designs, the problem specifies selecting the one which is lexicographically smallest, with its a sorted non-decreasing sequence of concentrations.\n\nFor Case $3$, where the number of trials $m=2$ is less than the number of parameters $d=4$, the FIM is necessarily singular. The matrix $M(D)$ is a sum of $m=2$ rank-$1$ matrices, so its rank is at most $2$. A $4 \\times 4$ matrix with rank less than $4$ has a determinant of $0$. Consequently, all possible designs yield an objective value of $-\\infty$. The tie-breaking rule becomes the sole criterion for selection. The optimal design is therefore the lexicographically smallest multiset of size $2$ from $\\Gamma$, which is $\\{0.5, 0.5\\}$. This demonstrates a correct interpretation of the problem's criteria for under-determined cases.", "answer": "```python\nimport numpy as np\nimport itertools\n\ndef solve():\n    \"\"\"\n    Computes D-optimal designs for three test cases by exhaustive search.\n    \"\"\"\n    test_cases = [\n        {\n            \"theta\": (10.0, 90.0, 50.0, 2.0),  # (alpha, beta, K, n)\n            \"sigma\": 5.0,\n            \"gamma\": [1.0, 5.0, 10.0, 20.0, 40.0, 60.0, 80.0, 100.0],\n            \"m\": 4,\n        },\n        {\n            \"theta\": (5.0, 95.0, 10.0, 2.0),\n            \"sigma\": 10.0,\n            \"gamma\": [2.0, 5.0, 10.0, 20.0],\n            \"m\": 4,\n        },\n        {\n            \"theta\": (2.0, 18.0, 2.0, 3.0),\n            \"sigma\": 1.0,\n            \"gamma\": [0.5, 1.0, 2.0, 4.0],\n            \"m\": 2,\n        },\n    ]\n\n    all_results = []\n    tau = 1e-12\n\n    def get_gradient(x, theta):\n        \"\"\"\n        Computes the gradient of the Hill function f with respect to theta.\n        theta = (alpha, beta, K, n)\n        \"\"\"\n        alpha, beta, K, n = theta\n        \n        # To prevent log(0) or division by zero, though problem constraints make it unlikely\n        if x <= 0 or K <= 0:\n            return np.zeros(4)\n\n        x_n = x**n\n        K_n = K**n\n        denominator = K_n + x_n\n        \n        if denominator == 0:\n            return np.zeros(4)\n        \n        common_term_beta = x_n / denominator\n        \n        # Partial derivatives\n        df_d_alpha = 1.0\n        df_d_beta = common_term_beta\n        df_d_K = -beta * n * (K**(n - 1)) * x_n / (denominator**2)\n        df_d_n = beta * K_n * x_n * np.log(x / K) / (denominator**2)\n        \n        return np.array([df_d_alpha, df_d_beta, df_d_K, df_d_n])\n\n    for case in test_cases:\n        theta = case[\"theta\"]\n        gamma = case[\"gamma\"]\n        m = case[\"m\"]\n        \n        num_params = len(theta)\n        \n        design_candidates = itertools.combinations_with_replacement(gamma, m)\n        \n        evaluated_designs = []\n        \n        for design in design_candidates:\n            fim_unscaled = np.zeros((num_params, num_params))\n            for x_i in design:\n                g = get_gradient(x_i, theta)\n                fim_unscaled += np.outer(g, g)\n            \n            sign, logdet = np.linalg.slogdet(fim_unscaled)\n            \n            # If matrix is singular or not positive definite, logdet is -inf\n            if sign <= 0:\n                objective_value = -np.inf\n            else:\n                objective_value = logdet\n            \n            evaluated_designs.append((objective_value, list(design)))\n\n        # Find the maximum log-determinant value\n        if not evaluated_designs:\n            # Should not happen with the given constraints\n            all_results.append([])\n            continue\n            \n        max_log_det = -np.inf\n        for log_det_val, _ in evaluated_designs:\n            if log_det_val > max_log_det:\n                max_log_det = log_det_val\n        \n        # Filter for designs that are optimal within the tolerance\n        best_designs = []\n        for log_det_val, design in evaluated_designs:\n            if abs(log_det_val - max_log_det) <= tau:\n                best_designs.append(design)\n        \n        # The first item in best_designs is the lexicographically smallest\n        # because itertools.combinations_with_replacement generates them in order.\n        optimal_design = best_designs[0]\n        all_results.append(optimal_design)\n\n    # Format the final output string exactly as specified\n    def format_list(lst):\n        return f\"[{','.join(f'{x:.6f}' for x in lst)}]\"\n\n    results_as_strings = [format_list(res) for res in all_results]\n    print(f\"[[{','.join(results_as_strings)}]]\")\n\nsolve()\n```", "id": "2782988"}]}