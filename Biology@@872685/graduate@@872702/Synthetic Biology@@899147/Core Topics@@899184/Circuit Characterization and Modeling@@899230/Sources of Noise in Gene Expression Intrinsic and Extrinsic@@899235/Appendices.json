{"hands_on_practices": [{"introduction": "Before we can dissect noise into its components, we must first learn how to quantify its total magnitude. This exercise [@problem_id:1440232] introduces the squared coefficient of variation ($\\text{CV}^2$), a fundamental metric that normalizes the variance of a distribution by its mean, allowing for a standardized comparison of noise levels across different systems. By applying this concept to a common scenario in synthetic biology, you will solidify your understanding of how overall cell-to-cell variability is measured.", "problem": "In a synthetic biology experiment, a population of genetically identical E. coli bacteria is engineered to constitutively express a fluorescent protein. Due to the inherent stochasticity of biochemical processes, the number of protein molecules is not the same in every cell. Using fluorescence microscopy and single-cell analysis, a researcher characterizes the statistical distribution of the protein count across a large population of these cells.\n\nThe analysis yields the following results:\n- The mean (average) number of protein molecules per cell is 200.\n- The variance in the number of protein molecules across the cell population is $4000 \\text{ molecules}^2$.\n\nThe total noise in gene expression is often quantified by the squared coefficient of variation, which is the ratio of the variance to the square of the mean. Calculate this value and choose the option below that provides both the correct numerical value and the most accurate physical interpretation.\n\nA. The value is 0.1. This represents the total noise, quantifying the overall cell-to-cell variability in protein levels from all combined sources of randomness.\n\nB. The value is 20. This indicates that the system's noise is 20 times greater than that of a purely Poissonian process, where the variance equals the mean.\n\nC. The value is 0.1. This represents only the intrinsic noise, which arises from the random timing of transcription and translation events for this specific gene.\n\nD. The value is 0.005. This represents the extrinsic noise, which arises from variations in shared cellular components like ribosomes and polymerases.\n\nE. The value is 10. This is the inverse of the total noise and indicates a high degree of precision in protein expression.", "solution": "We are given the mean protein count per cell, denoted by $\\mu$, and the variance across the population, denoted by $\\sigma^{2}$. Specifically, $\\mu=200$ and $\\sigma^{2}=4000 \\text{ molecules}^{2}$.\n\nThe squared coefficient of variation, which quantifies total noise, is defined as\n$$\n\\mathrm{CV}^{2}=\\frac{\\sigma^{2}}{\\mu^{2}}.\n$$\nSubstituting the given values,\n$$\n\\mathrm{CV}^{2}=\\frac{4000}{(200)^{2}}=\\frac{4000}{40000}=0.1.\n$$\n\nInterpretation:\n- $\\mathrm{CV}^{2}$ measures the total cell-to-cell variability normalized by the square of the mean, thus capturing the combined effects of all sources of randomness (intrinsic and extrinsic).\n- For a Poisson process, $\\sigma^{2}=\\mu$, so $\\mathrm{CV}^{2}=\\frac{\\mu}{\\mu^{2}}=\\frac{1}{\\mu}=\\frac{1}{200}=0.005$. The observed value $0.1$ is $20$ times this Poisson baseline, but the noise value itself is $0.1$, not $20$.\n- Therefore, the correct option must report $0.1$ and identify it as the total noise, not exclusively intrinsic or extrinsic.\n\nHence, the correct choice is A.", "answer": "$$\\boxed{A}$$", "id": "1440232"}, {"introduction": "Total noise is a composite measure, and a central goal in systems biology is to disentangle its intrinsic and extrinsic sources. The dual-reporter assay is the canonical experimental tool for this task, leveraging the principle that covariance between two co-regulated reporters isolates the shared, extrinsic fluctuations [@problem_id:1444520]. This practice provides a hands-on opportunity to apply this powerful technique and calculate the magnitude of extrinsic noise from representative flow cytometry data.", "problem": "A synthetic biologist is investigating the stochastic nature of gene expression in a bacterial population. A dual-reporter system is used, where a single plasmid carries two identical gene promoters. Each promoter drives the expression of a distinct fluorescent protein: Protein C (Cyan) and Protein Y (Yellow). The fluorescence intensity of individual cells is measured using flow cytometry, providing a statistical snapshot of protein expression levels across the population.\n\nThe total variability in the expression level of each protein arises from two sources: 'intrinsic noise', which is specific to the biochemical reactions of each gene copy, and 'extrinsic noise', which originates from fluctuations in the shared cellular environment and affects both genes simultaneously.\n\nThe analysis of the flow cytometry data yielded the following statistical moments, with intensities measured in arbitrary fluorescence units (AFU):\n- Mean intensity of Protein C: $\\mu_C = 1550$ AFU\n- Mean intensity of Protein Y: $\\mu_Y = 1620$ AFU\n- Variance of Protein C intensity: $\\sigma_C^2 = 1.95 \\times 10^5 \\text{ AFU}^2$\n- Variance of Protein Y intensity: $\\sigma_Y^2 = 2.05 \\times 10^5 \\text{ AFU}^2$\n- Covariance of Protein C and Protein Y intensities: $\\text{Cov}(C, Y) = 8.50 \\times 10^4 \\text{ AFU}^2$\n\nBased on the theory of noise decomposition in dual-reporter systems, calculate the squared coefficient of variation attributable to extrinsic noise, denoted $\\eta_{ext}^2$. This quantity is a key dimensionless measure of the magnitude of extrinsic noise. Round your final answer to three significant figures.", "solution": "In the dual-reporter framework, let $C$ and $Y$ denote the fluorescence intensities from the two identical promoters driving different reporters. Decompose expression as multiplicative fluctuations around their means:\n$$\nC = \\mu_{C}\\left(1 + E + I_{C}\\right), \\quad Y = \\mu_{Y}\\left(1 + E + I_{Y}\\right),\n$$\nwhere $E$ is the extrinsic fluctuation shared by both reporters with $\\mathbb{E}[E]=0$, and $I_{C}, I_{Y}$ are intrinsic, independent, zero-mean fluctuations specific to each reporter. Assume $E$, $I_{C}$, and $I_{Y}$ are mutually uncorrelated and $\\text{Cov}(I_{C}, I_{Y})=0$.\n\nThe covariance between $C$ and $Y$ is then\n$$\n\\text{Cov}(C,Y) = \\mu_{C}\\mu_{Y}\\,\\text{Cov}(1+E+I_{C},\\,1+E+I_{Y})\n= \\mu_{C}\\mu_{Y}\\,\\text{Var}(E).\n$$\nDefine the squared coefficient of variation due to extrinsic noise as $\\eta_{ext}^{2} \\equiv \\text{Var}(E)$. Therefore,\n$$\n\\eta_{ext}^{2} = \\frac{\\text{Cov}(C,Y)}{\\mu_{C}\\mu_{Y}}.\n$$\nSubstitute the given values $\\mu_{C}=1550$, $\\mu_{Y}=1620$, and $\\text{Cov}(C,Y)=8.50\\times 10^{4}$:\n$$\n\\eta_{ext}^{2} = \\frac{8.50\\times 10^{4}}{1550\\times 1620}\n= \\frac{8.50\\times 10^{4}}{2.511\\times 10^{6}}\n= \\frac{85}{2511}\n\\approx 0.033851056\\ldots\n$$\nRounding to three significant figures gives\n$$\n\\eta_{ext}^{2} \\approx 0.0339.\n$$\nThis is dimensionless, as required.", "answer": "$$\\boxed{0.0339}$$", "id": "1444520"}, {"introduction": "Understanding the sources of noise is critical, but it is equally important to understand how they affect the interpretation of biophysical models. This advanced problem [@problem_id:2774339] explores how extrinsic variability can systematically bias the inferred parameters of a transcriptional bursting model, a common challenge in single-cell data analysis. Through a combination of mathematical derivation and a programming task, you will not only quantify this bias but also develop a correction method, a crucial skill for any researcher aiming to build accurate quantitative models from experimental data.", "problem": "You are given a population of cells in which messenger ribonucleic acid (mRNA) counts per cell, denoted by $X$, arise from bursty transcription. Conditional on an extrinsic cell state $A$ (representing cell-to-cell variability in an effective burst frequency per mRNA lifetime), the mRNA count $X \\mid A = a$ follows a Negative Binomial (NB) distribution with shape parameter $a$ and mean $ab$, where $b$ is the mean burst size (molecules per burst). The following well-tested facts are the starting base for this problem: (i) conditional mean $\\mathbb{E}[X \\mid A = a] = ab$, and (ii) conditional variance $\\mathrm{Var}(X \\mid A = a) = ab + ab^{2}$, so that the conditional Fano factor equals $1 + b$. The extrinsic state $A$ is a positive random variable with mean $\\bar{a}$ and coefficient of variation squared $\\mathrm{CV}_{A}^{2} = \\mathrm{Var}(A)/\\bar{a}^{2}$, independent across cells. No other assumptions on the distribution of $A$ are required beyond existence of the first two moments.\n\nA practitioner naively fits an NB model that ignores extrinsic variability by matching the observed mean $\\mu_{\\mathrm{obs}}$ and observed variance $\\sigma_{\\mathrm{obs}}^{2}$ of $X$ to the NB moment relations: for an NB with mean $\\mu$ and shape $k$, the variance is $\\mu + \\mu^{2}/k$. Using the observed moments, the naive moment-based estimates are $\\hat{k}_{\\mathrm{NB}} = \\mu_{\\mathrm{obs}}^{2}/(\\sigma_{\\mathrm{obs}}^{2} - \\mu_{\\mathrm{obs}})$ and $\\hat{b}_{\\mathrm{NB}} = \\sigma_{\\mathrm{obs}}^{2}/\\mu_{\\mathrm{obs}} - 1$, with $\\hat{a}_{\\mathrm{NB}} = \\mu_{\\mathrm{obs}}/\\hat{b}_{\\mathrm{NB}}$ when mapping back to the burst parameters $(a, b)$ under the bursty NB interpretation.\n\nTask 1 (derivation): Starting only from the stated base (the conditional NB mean and variance and the definitions of expectation and variance), use the law of total expectation and the law of total variance to derive formulas for the observed mean $\\mu_{\\mathrm{obs}}$ and observed variance $\\sigma_{\\mathrm{obs}}^{2}$ in terms of $\\bar{a}$, $b$, and $\\mathrm{CV}_{A}^{2}$. Then analyze the bias incurred by the naive NB fit that ignores extrinsic variability: express $\\hat{a}_{\\mathrm{NB}}$ and $\\hat{b}_{\\mathrm{NB}}$ in terms of the true parameters $\\bar{a}$, $b$, and $\\mathrm{CV}_{A}^{2}$.\n\nTask 2 (correction): From your bias expressions, algebraically derive correction factors that recover the true parameters $(\\bar{a}, b)$ from the naive NB moment estimates $(\\hat{a}_{\\mathrm{NB}}, \\hat{b}_{\\mathrm{NB}})$ when $\\mathrm{CV}_{A}^{2}$ is known. Your final corrected estimators must be explicit functions of $\\hat{a}_{\\mathrm{NB}}$, $\\hat{b}_{\\mathrm{NB}}$, and $\\mathrm{CV}_{A}^{2}$ only. State any domain conditions required for the corrections to be well-defined.\n\nProgramming task: Implement a program that, for each test case $(\\bar{a}, b, \\mathrm{CV}_{A}^{2})$, performs the following steps:\n- Compute the observed mean $\\mu_{\\mathrm{obs}}$ and observed variance $\\sigma_{\\mathrm{obs}}^{2}$ using your Task $1$ derivations.\n- Compute the naive NB moment estimates $\\hat{a}_{\\mathrm{NB}}$ and $\\hat{b}_{\\mathrm{NB}}$ from $(\\mu_{\\mathrm{obs}}, \\sigma_{\\mathrm{obs}}^{2})$.\n- Apply your Task $2$ correction formulas to obtain corrected estimates $(\\hat{a}_{\\mathrm{corr}}, \\hat{b}_{\\mathrm{corr}})$ expressed solely in terms of $(\\hat{a}_{\\mathrm{NB}}, \\hat{b}_{\\mathrm{NB}}, \\mathrm{CV}_{A}^{2})$.\n- For each test case, output the list $[\\hat{a}_{\\mathrm{NB}}, \\hat{b}_{\\mathrm{NB}}, \\hat{a}_{\\mathrm{corr}}, \\hat{b}_{\\mathrm{corr}}]$, with all four numbers rounded to six decimal places.\n\nTest suite (each tuple lists $(\\bar{a}, b, \\mathrm{CV}_{A}^{2})$):\n- Case A (happy path): $(5.0, 2.0, 0.3)$.\n- Case B (no extrinsic variability): $(10.0, 0.5, 0.0)$.\n- Case C (boundary-like high extrinsic variability relative to $\\bar a$): $(50.0, 1.0, 1.0)$.\n- Case D (low burst frequency and large burst size): $(0.8, 5.0, 0.5)$.\n- Case E (moderate parameters with non-integer burst size): $(3.2, 1.7, 0.25)$.\n\nFinal output format: Your program should produce a single line of output containing the results as a comma-separated list of sublists enclosed in square brackets, in the same order as the test suite. For example, a valid output line has the form $[[x_{1},y_{1},z_{1},w_{1}],[x_{2},y_{2},z_{2},w_{2}],\\dots]$, where each $x_{i}, y_{i}, z_{i}, w_{i}$ is a decimal number rounded to six decimal places. No other text should be printed.", "solution": "The problem requires the derivation of biases in parameter estimates for a bursty transcription model when extrinsic variability is ignored, and subsequently, the derivation of correction factors to eliminate this bias. The analysis will proceed from first principles using the laws of total expectation and variance.\n\n**Task 1: Derivation of Observed Moments and Naive Estimator Bias**\n\nThe model posits that the mRNA count $X$ for a given cell state $A=a$ follows a Negative Binomial distribution, $X \\mid A=a \\sim \\mathrm{NB}(\\text{shape}=a, \\text{mean}=ab)$. The conditional moments are given as:\n$$\n\\mathbb{E}[X \\mid A=a] = ab\n$$\n$$\n\\mathrm{Var}(X \\mid A=a) = ab + ab^2\n$$\nThe extrinsic state $A$ is a random variable with mean $\\mathbb{E}[A] = \\bar{a}$ and variance $\\mathrm{Var}(A)$. The squared coefficient of variation of $A$ is $\\mathrm{CV}_{A}^{2} = \\mathrm{Var}(A) / \\bar{a}^2$.\n\nFirst, we derive the unconditional (observed) mean $\\mu_{\\mathrm{obs}}$ and variance $\\sigma_{\\mathrm{obs}}^{2}$ of $X$.\n\n**Observed Mean $\\mu_{\\mathrm{obs}}$**\n\nBy the law of total expectation, the observed mean is the expectation of the conditional mean:\n$$\n\\mu_{\\mathrm{obs}} = \\mathbb{E}[X] = \\mathbb{E}_{A}[\\mathbb{E}[X \\mid A]]\n$$\nSubstituting the expression for the conditional mean, $\\mathbb{E}[X \\mid A] = Ab$:\n$$\n\\mu_{\\mathrm{obs}} = \\mathbb{E}_{A}[Ab] = b \\cdot \\mathbb{E}[A]\n$$\nTherefore, the observed mean is:\n$$\n\\mu_{\\mathrm{obs}} = \\bar{a}b\n$$\n\n**Observed Variance $\\sigma_{\\mathrm{obs}}^{2}$**\n\nBy the law of total variance, the observed variance is the sum of the expected conditional variance and the variance of the conditional mean:\n$$\n\\sigma_{\\mathrm{obs}}^{2} = \\mathrm{Var}(X) = \\mathbb{E}_{A}[\\mathrm{Var}(X \\mid A)] + \\mathrm{Var}_{A}(\\mathbb{E}[X \\mid A])\n$$\nWe evaluate each term separately.\n\nThe first term is the expectation of the conditional variance, $\\mathrm{Var}(X \\mid A) = Ab + Ab^2$:\n$$\n\\mathbb{E}_{A}[\\mathrm{Var}(X \\mid A)] = \\mathbb{E}_{A}[A(b+b^2)] = (b+b^2)\\mathbb{E}[A] = \\bar{a}(b+b^2) = \\bar{a}b + \\bar{a}b^2\n$$\nThe second term is the variance of the conditional mean, $\\mathbb{E}[X \\mid A] = Ab$:\n$$\n\\mathrm{Var}_{A}(\\mathbb{E}[X \\mid A]) = \\mathrm{Var}_{A}(Ab) = b^2 \\mathrm{Var}(A)\n$$\nUsing the definition $\\mathrm{Var}(A) = \\bar{a}^2 \\mathrm{CV}_{A}^{2}$, this term becomes:\n$$\n\\mathrm{Var}_{A}(Ab) = b^2 \\bar{a}^2 \\mathrm{CV}_{A}^{2} = (\\bar{a}b)^2 \\mathrm{CV}_{A}^{2}\n$$\nCombining the two terms, we obtain the observed variance:\n$$\n\\sigma_{\\mathrm{obs}}^{2} = (\\bar{a}b + \\bar{a}b^2) + (\\bar{a}b)^2 \\mathrm{CV}_{A}^{2} = \\bar{a}b(1+b) + \\bar{a}^2 b^2 \\mathrm{CV}_{A}^{2}\n$$\n\n**Bias in Naive Estimators**\n\nA naive analysis ignores the extrinsic variability and estimates the parameters $\\hat{a}_{\\mathrm{NB}}$ and $\\hat{b}_{\\mathrm{NB}}$ by matching the observed moments $(\\mu_{\\mathrm{obs}}, \\sigma_{\\mathrm{obs}}^{2})$ to those of a simple NB distribution. The naive estimators are given by:\n$$\n\\hat{b}_{\\mathrm{NB}} = \\frac{\\sigma_{\\mathrm{obs}}^{2}}{\\mu_{\\mathrm{obs}}} - 1\n$$\n$$\n\\hat{a}_{\\mathrm{NB}} = \\frac{\\mu_{\\mathrm{obs}}}{\\hat{b}_{\\mathrm{NB}}}\n$$\nWe substitute our derived expressions for $\\mu_{\\mathrm{obs}}$ and $\\sigma_{\\mathrm{obs}}^{2}$ to find the bias. First, we compute the ratio $\\sigma_{\\mathrm{obs}}^{2}/\\mu_{\\mathrm{obs}}$:\n$$\n\\frac{\\sigma_{\\mathrm{obs}}^{2}}{\\mu_{\\mathrm{obs}}} = \\frac{\\bar{a}b(1+b) + \\bar{a}^2 b^2 \\mathrm{CV}_{A}^{2}}{\\bar{a}b} = (1+b) + \\frac{\\bar{a}^2 b^2 \\mathrm{CV}_{A}^{2}}{\\bar{a}b} = 1+b + \\bar{a}b\\mathrm{CV}_{A}^{2}\n$$\nNow we find the expression for the naive burst size estimate, $\\hat{b}_{\\mathrm{NB}}$:\n$$\n\\hat{b}_{\\mathrm{NB}} = \\left(1+b + \\bar{a}b\\mathrm{CV}_{A}^{2}\\right) - 1 = b + \\bar{a}b\\mathrm{CV}_{A}^{2} = b(1 + \\bar{a}\\mathrm{CV}_{A}^{2})\n$$\nThis result shows that $\\hat{b}_{\\mathrm{NB}}$ is an overestimate of the true mean burst size $b$ whenever there is extrinsic variability ($\\mathrm{CV}_{A}^{2} > 0$).\n\nNext, we find the expression for the naive burst frequency parameter, $\\hat{a}_{\\mathrm{NB}}$:\n$$\n\\hat{a}_{\\mathrm{NB}} = \\frac{\\mu_{\\mathrm{obs}}}{\\hat{b}_{\\mathrm{NB}}} = \\frac{\\bar{a}b}{b(1 + \\bar{a}\\mathrm{CV}_{A}^{2})} = \\frac{\\bar{a}}{1 + \\bar{a}\\mathrm{CV}_{A}^{2}}\n$$\nThis result shows that $\\hat{a}_{\\mathrm{NB}}$ is an underestimate of the true mean burst frequency parameter $\\bar{a}$ when $\\mathrm{CV}_{A}^{2} > 0$.\n\n**Task 2: Derivation of Correction Factors**\n\nThe goal is to reverse the biases and recover the true parameters $(\\bar{a}, b)$ from the naive estimates $(\\hat{a}_{\\mathrm{NB}}, \\hat{b}_{\\mathrm{NB}})$ and the known extrinsic variability $\\mathrm{CV}_{A}^{2}$. We have the following system of equations:\n$$\n(1) \\quad \\hat{a}_{\\mathrm{NB}} = \\frac{\\bar{a}}{1 + \\bar{a}\\mathrm{CV}_{A}^{2}}\n$$\n$$\n(2) \\quad \\hat{b}_{\\mathrm{NB}} = b(1 + \\bar{a}\\mathrm{CV}_{A}^{2})\n$$\nWe must solve this system for $\\bar{a}$ and $b$.\n\n**Correction for $\\bar{a}$**\n\nFrom equation $(1)$, we solve for $\\bar{a}$:\n$$\n\\hat{a}_{\\mathrm{NB}} (1 + \\bar{a}\\mathrm{CV}_{A}^{2}) = \\bar{a}\n$$\n$$\n\\hat{a}_{\\mathrm{NB}} + \\hat{a}_{\\mathrm{NB}}\\bar{a}\\mathrm{CV}_{A}^{2} = \\bar{a}\n$$\n$$\n\\hat{a}_{\\mathrm{NB}} = \\bar{a} - \\hat{a}_{\\mathrm{NB}}\\bar{a}\\mathrm{CV}_{A}^{2} = \\bar{a}(1 - \\hat{a}_{\\mathrm{NB}}\\mathrm{CV}_{A}^{2})\n$$\nThis gives the corrected estimator for $\\bar{a}$, which we denote $\\hat{a}_{\\mathrm{corr}}$:\n$$\n\\hat{a}_{\\mathrm{corr}} = \\bar{a} = \\frac{\\hat{a}_{\\mathrm{NB}}}{1 - \\hat{a}_{\\mathrm{NB}}\\mathrm{CV}_{A}^{2}}\n$$\n\n**Correction for $b$**\n\nTo solve for $b$, we first rearrange equation $(2)$:\n$$\nb = \\frac{\\hat{b}_{\\mathrm{NB}}}{1 + \\bar{a}\\mathrm{CV}_{A}^{2}}\n$$\nWe can find an expression for the term $(1 + \\bar{a}\\mathrm{CV}_{A}^{2})$ using our result for $\\bar{a}$. From the derivation of $\\hat{a}_{\\mathrm{corr}}$, we have $\\hat{a}_{\\mathrm{NB}} = \\bar{a}(1 - \\hat{a}_{\\mathrm{NB}}\\mathrm{CV}_{A}^{2})$.\nLet us use an algebraic identity derived from equation (1): $1 + \\bar{a}\\mathrm{CV}_{A}^{2} = \\bar{a}/\\hat{a}_{\\mathrm{NB}}$.\nSubstitute this into the expression for $b$:\n$$\nb = \\frac{\\hat{b}_{\\mathrm{NB}}}{\\bar{a}/\\hat{a}_{\\mathrm{NB}}} = \\frac{\\hat{a}_{\\mathrm{NB}}\\hat{b}_{\\mathrm{NB}}}{\\bar{a}}\n$$\nThis is simply $\\mu_{\\mathrm{obs}}/\\bar{a} = b$, which is a tautology and not helpful for expressing $b$ in terms of naive estimates.\n\nA more productive path is to express the denominator $(1 + \\bar{a}\\mathrm{CV}_{A}^{2})$ in terms of the naive estimates. From equation $(1)$, we have $1 + \\bar{a}\\mathrm{CV}_{A}^{2} = \\frac{\\bar{a}}{\\hat{a}_{\\mathrm{NB}}}$. Substituting the expression for the corrected $\\bar{a}$, $\\bar{a} = \\frac{\\hat{a}_{\\mathrm{NB}}}{1 - \\hat{a}_{\\mathrm{NB}}\\mathrm{CV}_{A}^{2}}$:\n$$\n1 + \\bar{a}\\mathrm{CV}_{A}^{2} = 1 + \\left(\\frac{\\hat{a}_{\\mathrm{NB}}}{1 - \\hat{a}_{\\mathrm{NB}}\\mathrm{CV}_{A}^{2}}\\right)\\mathrm{CV}_{A}^{2} = \\frac{1 - \\hat{a}_{\\mathrm{NB}}\\mathrm{CV}_{A}^{2} + \\hat{a}_{\\mathrm{NB}}\\mathrm{CV}_{A}^{2}}{1 - \\hat{a}_{\\mathrm{NB}}\\mathrm{CV}_{A}^{2}} = \\frac{1}{1 - \\hat{a}_{\\mathrm{NB}}\\mathrm{CV}_{A}^{2}}\n$$\nNow substitute this back into the expression for $b$:\n$$\nb = \\frac{\\hat{b}_{\\mathrm{NB}}}{1 / (1 - \\hat{a}_{\\mathrm{NB}}\\mathrm{CV}_{A}^{2})} = \\hat{b}_{\\mathrm{NB}}(1 - \\hat{a}_{\\mathrm{NB}}\\mathrm{CV}_{A}^{2})\n$$\nThis gives the corrected estimator for $b$, denoted $\\hat{b}_{\\mathrm{corr}}$:\n$$\n\\hat{b}_{\\mathrm{corr}} = b = \\hat{b}_{\\mathrm{NB}}(1 - \\hat{a}_{\\mathrm{NB}}\\mathrm{CV}_{A}^{2})\n$$\n\n**Summary of Correction Formulas and Conditions**\n\nThe corrected estimators are:\n$$\n\\hat{a}_{\\mathrm{corr}} = \\frac{\\hat{a}_{\\mathrm{NB}}}{1 - \\hat{a}_{\\mathrm{NB}}\\mathrm{CV}_{A}^{2}}\n$$\n$$\n\\hat{b}_{\\mathrm{corr}} = \\hat{b}_{\\mathrm{NB}}(1 - \\hat{a}_{\\mathrm{NB}}\\mathrm{CV}_{A}^{2})\n$$\nFor these estimators to be physically meaningful (i.e., positive), we require the correction factor $(1 - \\hat{a}_{\\mathrm{NB}}\\mathrm{CV}_{A}^{2})$ to be positive. This implies the domain condition:\n$$\n\\hat{a}_{\\mathrm{NB}}\\mathrm{CV}_{A}^{2} < 1\n$$\nIn terms of the true parameters, this condition is $\\frac{\\bar{a}\\mathrm{CV}_{A}^{2}}{1 + \\bar{a}\\mathrm{CV}_{A}^{2}} < 1$, which is always satisfied for non-negative parameters as it simplifies to $0 < 1$. Thus, with population moments, the correction is always well-defined.\n\nThe derivation is complete. The logical-mathematical procedure reveals the precise quantitative impact of extrinsic variability and establishes the method for its correction.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Computes naive and corrected estimates for bursty transcription parameters\n    across several test cases.\n    \"\"\"\n\n    # Test suite: each tuple contains (a_bar, b, CV_A^2)\n    test_cases = [\n        (5.0, 2.0, 0.3),   # Case A (happy path)\n        (10.0, 0.5, 0.0),  # Case B (no extrinsic variability)\n        (50.0, 1.0, 1.0),  # Case C (high extrinsic variability)\n        (0.8, 5.0, 0.5),   # Case D (low burst frequency, large burst size)\n        (3.2, 1.7, 0.25),  # Case E (moderate parameters)\n    ]\n\n    results = []\n    \n    for case in test_cases:\n        a_bar, b, cv2_A = case\n\n        # Step 1: Compute observed moments using derived formulas from Task 1\n        # mu_obs = a_bar * b\n        # sigma2_obs = a_bar*b + a_bar*b^2 + (a_bar*b)^2 * CV_A^2\n        mu_obs = a_bar * b\n        sigma2_obs = a_bar * b * (1 + b) + (a_bar**2) * (b**2) * cv2_A\n\n        # Step 2: Compute naive NB moment estimates\n        # These will be biased if cv2_A > 0\n        \n        # The condition sigma2_obs > mu_obs must hold for b_nb_hat > 0.\n        # sigma2_obs - mu_obs = a_bar*b^2 + (a_bar*b)^2*cv2_A\n        # This is > 0 for a_bar > 0, b > 0.\n        if mu_obs == 0:\n            # Avoid division by zero, though not expected with given test cases.\n            if sigma2_obs == 0:\n                # If mean and variance are 0, this is a degenerate case.\n                b_nb_hat = 0\n            else:\n                # A positive variance with a zero mean is not possible for this model.\n                b_nb_hat = float('inf')\n        else:\n            b_nb_hat = (sigma2_obs / mu_obs) - 1\n\n        # The condition b_nb_hat > 0 must hold for a_nb_hat to be well-defined.\n        if b_nb_hat = 0:\n            # Handle cases that might arise with real, noisy data,\n            # though not with the perfect data from these test cases.\n            a_nb_hat = float('nan')\n        else:\n            a_nb_hat = mu_obs / b_nb_hat\n\n        # Step 3: Apply correction formulas from Task 2 to obtain corrected estimates\n        # Correction factor term\n        correction_factor = 1 - a_nb_hat * cv2_A\n\n        # Check domain condition for correction; correction_factor must be > 0.\n        # As derived, this holds for the true parameters. With sample estimates,\n        # it might be violated. For this problem, it is always satisfied.\n        \n        a_corr = a_nb_hat / correction_factor\n        b_corr = b_nb_hat * correction_factor\n\n        # Step 4: Collect and format the results\n        # Round all four numbers to six decimal places.\n        result_tuple = [\n            round(a_nb_hat, 6),\n            round(b_nb_hat, 6),\n            round(a_corr, 6),\n            round(b_corr, 6)\n        ]\n        results.append(result_tuple)\n\n    # Convert the list of lists to the required string format\n    # [[x1,y1,z1,w1],[x2,y2,z2,w2],...]\n    output_str = \"[\" + \",\".join([f\"[{','.join(map(str, r))}]\" for r in results]) + \"]\"\n    \n    # Final print statement in the exact required format.\n    print(output_str)\n\nsolve()\n```", "id": "2774339"}]}