{"hands_on_practices": [{"introduction": "A primary goal in genome editing is to achieve high specificity, ensuring the engineered nuclease acts only at the intended target. This practice provides a foundational tool for evaluating specificity by asking you to calculate the expected number of perfect binding sites for a Zinc Finger Nuclease (ZFN) in a large genome [@problem_id:2788408]. By applying first principles of probability to a simplified genomic model, you will develop a quantitative intuition for how the length of a recognition sequence dictates its uniqueness and potential for off-target binding.", "problem": "A Cys₂His₂ zinc finger nuclease (ZFN) three-finger array recognizes a contiguous deoxyribonucleic acid (DNA) target of length $9$ base pairs, with one finger per $3$ base pairs. Assume a haploid genome is modeled as an independent and identically distributed (i.i.d.) sequence over the alphabet $\\{A, C, G, T\\}$ with uniform base frequencies, and that the three-finger array specifies a single exact $9$-base-pair motif (no degeneracy). Consider scanning a single strand of length $N = 3\\times 10^{9}$ base pairs for perfect matches to this $9$-base-pair site. Ignore edge effects arising from double-strandedness or chromosome boundaries beyond the standard counting of starting positions.\n\nUsing only the definitions of probability for independent events, indicator random variables, and linearity of expectation, derive from first principles an expression for the expected number of perfect matches to the specified $9$-base-pair motif in the genome, and then evaluate it numerically for $N = 3\\times 10^{9}$ and motif length $k = 9$. Round your final numerical answer to three significant figures.", "solution": "The problem as stated is valid. It is scientifically grounded, well-posed, and objective. It presents a standard simplified model used in bioinformatics for estimating the frequency of sequence motifs, and all parameters and conditions are clearly defined. I will proceed with the derivation as requested.\n\nThe task is to compute the expected number of occurrences of a specific $9$-base-pair motif within a genome of length $N = 3 \\times 10^9$ base pairs. The genome is modeled as a sequence of independent and identically distributed (i.i.d.) random variables, where each base from the set $\\{A, C, G, T\\}$ is chosen with uniform probability $p = \\frac{1}{4}$.\n\nLet the genome be represented by the sequence $S = S_1 S_2 \\dots S_N$, where each $S_i \\in \\{A, C, G, T\\}$. Let the specific target motif be a sequence $M = M_1 M_2 \\dots M_k$ of length $k=9$. A perfect match occurs at a position $i$ in the genome if the subsequence starting at $i$ is identical to $M$. The possible starting positions for a $k$-mer in a sequence of length $N$ are $i=1, 2, \\dots, N-k+1$. The total number of such possible sites is $N-k+1$.\n\nTo solve this rigorously from first principles, we employ the method of indicator random variables and the linearity of expectation. For each possible starting position $i$, where $1 \\le i \\le N-k+1$, we define an indicator random variable $X_i$ as follows:\n$$\nX_i = \\begin{cases} 1 & \\text{if the subsequence } S_i S_{i+1} \\dots S_{i+k-1} \\text{ matches } M \\\\ 0 & \\text{otherwise} \\end{cases}\n$$\nThe total number of perfect matches in the entire genome, which we denote by the random variable $X$, is the sum of these indicator variables over all possible starting positions:\n$$\nX = \\sum_{i=1}^{N-k+1} X_i\n$$\nWe are asked to find the expected number of matches, which is the expectation of $X$, denoted $E[X]$. By the linearity of expectation, the expectation of a sum of random variables is the sum of their individual expectations. This property holds regardless of whether the random variables are independent.\n$$\nE[X] = E\\left[ \\sum_{i=1}^{N-k+1} X_i \\right] = \\sum_{i=1}^{N-k+1} E[X_i]\n$$\nThe expectation of an indicator random variable $X_i$ is, by definition, equal to the probability of the event it indicates.\n$$\nE[X_i] = 1 \\cdot P(X_i=1) + 0 \\cdot P(X_i=0) = P(X_i=1)\n$$\n$P(X_i=1)$ is the probability that the subsequence of the genome starting at position $i$ perfectly matches the specific $k$-mer motif $M$. The genome sequence is modeled as i.i.d., meaning the base at each position is chosen independently of all other bases. The probability of any specific base (A, C, G, or T) appearing at any given position is $p = \\frac{1}{4}$. For the subsequence $S_i S_{i+1} \\dots S_{i+k-1}$ to match $M_1 M_2 \\dots M_k$, we must have $S_i = M_1$, $S_{i+1} = M_2$, and so on, up to $S_{i+k-1} = M_k$.\nDue to independence, the probability of this joint event is the product of the probabilities of the individual events:\n$$\nP(X_i=1) = P(S_i=M_1 \\text{ and } S_{i+1}=M_2 \\text{ and } \\dots \\text{ and } S_{i+k-1}=M_k) = \\prod_{j=0}^{k-1} P(S_{i+j}=M_{j+1})\n$$\nSince the probability for each position is $p = \\frac{1}{4}$, this product becomes:\n$$\nP(X_i=1) = \\left(\\frac{1}{4}\\right)^k\n$$\nThis probability is constant for all positions $i$. Therefore, the expectation of each indicator variable is the same:\n$$\nE[X_i] = \\left(\\frac{1}{4}\\right)^k\n$$\nNow we can substitute this back into the expression for $E[X]$. The sum consists of $N-k+1$ identical terms:\n$$\nE[X] = \\sum_{i=1}^{N-k+1} \\left(\\frac{1}{4}\\right)^k = (N-k+1) \\left(\\frac{1}{4}\\right)^k\n$$\nThis is the general expression for the expected number of perfect matches, derived from first principles as required.\n\nNow, we must evaluate this expression numerically for the given values: genome length $N = 3 \\times 10^9$ and motif length $k = 9$.\nThe number of possible starting positions is $N-k+1 = 3 \\times 10^9 - 9 + 1 = 3 \\times 10^9 - 8 = 2,999,999,992$.\nThe probability of a match at any given site is $\\left(\\frac{1}{4}\\right)^9$.\n$$\n\\left(\\frac{1}{4}\\right)^9 = \\frac{1}{4^9} = \\frac{1}{(2^2)^9} = \\frac{1}{2^{18}} = \\frac{1}{262,144}\n$$\nThe expected number of matches is:\n$$\nE[X] = (2,999,999,992) \\times \\frac{1}{262,144}\n$$\nSince $N \\gg k$, the term $N-k+1$ is very well approximated by $N$. Let us perform the calculation:\n$$\nE[X] = \\frac{2,999,999,992}{262,144} \\approx 11444.09176\n$$\nThe problem requires the answer to be rounded to three significant figures. The first three significant figures of $11444.09176$ are $1$, $1$, and $4$. The fourth significant digit is $4$, which is less than $5$, so we round down.\nThe value $11444.09176$ rounded to three significant figures is $11400$.\nExpressing this in standard scientific notation gives $1.14 \\times 10^4$.", "answer": "$$ \\boxed{1.14 \\times 10^4} $$", "id": "2788408"}, {"introduction": "While the assumption of independent, modular components is a useful starting point, it often fails to predict the behavior of engineered multi-domain proteins in practice. This problem challenges you to move beyond idealized models and reason about the complex biophysical realities of protein-DNA recognition [@problem_id:2788359]. By analyzing the potential sources of non-additivity in ZFN binding energy, you will explore how structural coupling, linker mechanics, and electrostatic context undermine simple modularity, a critical concept for robust protein engineering.", "problem": "A synthetic biology team is assembling a Zinc Finger Nuclease (ZFN) by concatenating a three-finger Zinc Finger Protein (ZFP) DNA-binding array to a FokI endonuclease domain to target a specific Deoxyribonucleic Acid (DNA) site of length $9$ base pairs. Each finger was chosen from a library of pre-characterized modules reported to recognize a particular DNA triplet. The design assumes that the binding energetics of each finger are independent and therefore additive across the array. In practice, the assembled ZFN binds weakly to the intended site and shows unexpected off-target binding to sites with partially overlapping triplets. The pre-characterization was performed in a protein scaffold with different inter-finger linkers and at salt conditions differing from the final assay (pre-characterization at $50$ mM monovalent salt, final assays at $150$ mM).\n\nFrom first principles of protein–DNA recognition, specifically the thermodynamics of binding free energy, structural coupling between adjacent recognition modules, and the role of DNA shape and electrostatics, which of the following statements provide a rigorous mechanistic explanation for why modular assembly using pre-characterized zinc finger modules can fail in practice? Select all that apply.\n\nA. Adjacent zinc fingers and the contacted DNA triplets are energetically and structurally coupled, so the total binding free energy is generally non-additive; neighboring side chains and induced DNA shape changes create context-dependent coupling terms that invalidate independent module assumptions.\n\nB. Under physiological conditions, zinc ions dissociate from the canonical Cys₂His₂ fold, causing finger unfolding and thus eliminating sequence-specific recognition regardless of context, so modular assembly fails because zinc finger domains are intrinsically unstable.\n\nC. The FokI cleavage domain alters base-specific hydrogen bonding patterns after binding, thereby changing DNA sequence preferences and rendering pre-characterized binding modules irrelevant to specificity.\n\nD. The geometry and flexibility of the inter-finger linkers impose entropic and steric constraints that can shift the register and orientation of base contacts relative to those measured for isolated fingers, introducing additional non-additive penalties that depend on the specific module order and linker composition.\n\nE. Transcription Activator-Like Effector (TALE) arrays are immune to such context effects because each repeat binds exactly one base with no backbone-mediated interactions, so modular assembly problems are unique to zinc fingers.\n\nF. Differences in ionic strength between module characterization and use change the screening of electrostatic interactions at the protein–DNA interface, altering backbone-mediated energetic contributions in a context-dependent way and breaking the apparent additivity inferred under different salt conditions.", "solution": "The problem statement is valid. It is scientifically grounded, well-posed, objective, and provides a clear scenario based on established principles of molecular biology and biophysics. The discrepancy between the assumption of modularity in zinc finger design and the observed experimental outcome is a well-documented phenomenon, providing a sound basis for a question about its underlying mechanisms.\n\nThe core of the problem lies in the failure of the simplifying assumption that the total binding free energy, $\\Delta G_{\\text{total}}$, of a multi-finger Zinc Finger Protein (ZFP) array is the simple sum of the binding free energies of its individual, pre-characterized fingers ($\\Delta G_i$):\n$$ \\Delta G_{\\text{total, assumed}} = \\sum_i \\Delta G_i $$\nThe observed weak binding and off-target effects indicate that the actual binding free energy is less favorable (less negative) than predicted and that the specificity landscape is altered. This implies the existence of significant coupling terms, $\\Delta G_{\\text{coupling}}$, such that the true binding energy is:\n$$ \\Delta G_{\\text{total, actual}} = \\sum_i \\Delta G_i + \\Delta G_{\\text{coupling}} $$\nThe term $\\Delta G_{\\text{coupling}}$ arises from context-dependent effects where the binding of one finger influences its neighbors. The problem asks for the mechanistic origins of this non-additivity. We will evaluate each option based on first principles of protein–DNA recognition.\n\nA. **Adjacent zinc fingers and the contacted DNA triplets are energetically and structurally coupled, so the total binding free energy is generally non-additive; neighboring side chains and induced DNA shape changes create context-dependent coupling terms that invalidate independent module assumptions.**\nThis statement is a precise and accurate description of context-dependent effects in protein-DNA interactions. Protein-DNA recognition is not a simple lock-and-key process. Both macromolecules are flexible. The binding of a zinc finger module (e.g., finger $n$) to its DNA triplet can induce local conformational changes in both the protein backbone and the DNA helix (e.g., minor groove width, roll, twist). These structural perturbations propagate to the adjacent binding site for finger $n+1$, altering its geometry and energetics. This is known as indirect readout or shape readout. Furthermore, side chains from finger $n$ can directly interact with side chains on finger $n+1$, creating direct energetic coupling. These effects are not captured when characterizing each module in isolation and are a primary reason for the non-additivity of binding energies.\n**Verdict: Correct.**\n\nB. **Under physiological conditions, zinc ions dissociate from the canonical Cys₂His₂ fold, causing finger unfolding and thus eliminating sequence-specific recognition regardless of context, so modular assembly fails because zinc finger domains are intrinsically unstable.**\nThis statement is incorrect. The Cys₂His₂ zinc finger fold is a stable structural motif found in thousands of eukaryotic transcription factors that function effectively under physiological conditions. The coordination of the zinc ion ($Zn^{2+}$) is very strong, and dissociation does not readily occur in the absence of strong chelating agents or denaturing conditions. While loss of zinc does lead to unfolding and loss of function, it is not a general feature of zinc fingers under physiological conditions. The problem describes weak and altered specificity, not a complete loss of binding that would result from catastrophic unfolding. Therefore, attributing the failure of modularity to intrinsic instability is a factual error.\n**Verdict: Incorrect.**\n\nC. **The FokI cleavage domain alters base-specific hydrogen bonding patterns after binding, thereby changing DNA sequence preferences and rendering pre-characterized binding modules irrelevant to specificity.**\nThis statement misattributes the problem. The DNA sequence specificity of a Zinc Finger Nuclease (ZFN) is determined by the ZFP array, not the FokI nuclease domain. The role of FokI is to cleave the DNA phosphodiester backbone, a function that occurs after the ZFP has bound its target sequence. While the FokI domain is tethered to the ZFP array and could have minor steric or allosteric effects, it does not directly participate in reading the DNA sequence or forming the base-specific hydrogen bonds. Problems with context-dependence and non-additivity are inherent to ZFP arrays themselves and are observed even when they are not fused to a nuclease.\n**Verdict: Incorrect.**\n\nD. **The geometry and flexibility of the inter-finger linkers impose entropic and steric constraints that can shift the register and orientation of base contacts relative to those measured for isolated fingers, introducing additional non-additive penalties that depend on the specific module order and linker composition.**\nThis statement is correct and points to another critical source of non-additivity. The problem explicitly notes that the pre-characterization used \"different inter-finger linkers.\" The linker connecting two fingers dictates their relative spacing and orientation. If a linker is too short, it can cause steric clashes. If it is too long or flexible, orienting it correctly upon binding incurs a significant entropic penalty ($\\Delta S < 0$), which makes the overall binding free energy ($\\Delta G = \\Delta H - T\\Delta S$) less favorable. An inappropriate linker can also cause a \"register shift,\" where a finger is not optimally positioned over its target triplet, weakening its interaction. These effects are fundamentally context-dependent, as they depend on the specific linker and its interaction with the two flanking finger modules. These linker-dependent energetic penalties are a major component of the $\\Delta G_{\\text{coupling}}$ term.\n**Verdict: Correct.**\n\nE. **Transcription Activator-Like Effector (TALE) arrays are immune to such context effects because each repeat binds exactly one base with no backbone-mediated interactions, so modular assembly problems are unique to zinc fingers.**\nThis statement contains multiple inaccuracies. First, while TALE arrays are significantly *more* modular than ZFP arrays, they are not completely \"immune\" to context effects. For instance, weak preferences for neighboring bases have been documented. Second, the claim that TALE repeats have \"no backbone-mediated interactions\" is false. TALEs form extensive contacts with the DNA phosphate backbone, which are crucial for binding affinity. The modularity arises because the specific base-contacting residues (the Repeat Variable Diresidue) are structurally separated from the main scaffold, but the scaffold itself interacts heavily with the DNA. Finally, claiming modularity problems are \"unique\" to zinc fingers is an overstatement; such challenges exist to varying degrees in the engineering of any multi-domain protein.\n**Verdict: Incorrect.**\n\nF. **Differences in ionic strength between module characterization and use change the screening of electrostatic interactions at the protein–DNA interface, altering backbone-mediated energetic contributions in a context-dependent way and breaking the apparent additivity inferred under different salt conditions.**\nThis statement is correct and addresses an explicit variable mentioned in the problem: the difference in salt concentration between characterization ($50$ mM) and the final assay ($150$ mM). Protein-DNA binding involves a substantial electrostatic component due to the attraction between the polyanionic DNA backbone and positive charges on the protein. According to counterion condensation theory, the strength of these electrostatic interactions is highly dependent on the bulk salt concentration. Increasing the salt concentration from $50$ mM to $150$ mM increases ionic screening, thereby weakening electrostatic interactions and generally decreasing binding affinity. This effect is non-uniform across the interface and also affects electrostatic interactions between protein domains (e.g., between fingers). Therefore, an additive model established at one salt concentration will not be valid at another because the electrostatic contributions to both the individual binding energies and the coupling energies have changed. This change in conditions invalidates the transferability of the pre-characterized energetic parameters.\n**Verdict: Correct.**", "answer": "$$\\boxed{ADF}$$", "id": "2788359"}, {"introduction": "To build truly predictive models of nuclease specificity, we must bridge the gap between theoretical principles and experimental data. This practice guides you through a modern, data-driven approach to quantifying binding preferences from high-throughput sequencing assays [@problem_id:2788400]. You will derive and implement a regularized estimator for per-position energy penalties, $\\varepsilon_i(b)$, connecting statistical thermodynamics to real-world count data and developing a core computational skill in quantitative synthetic biology.", "problem": "You are modeling the DNA-binding specificity of modular transcription factors used in genome editing, such as Zinc Finger Nucleases (ZFNs) and Transcription Activator-Like Effector (TALE) domains. Under the standard thermodynamic model of binding, the probability that a DNA sequence is bound is related to its binding energy. For such domains, a widely used first-order approximation is that the binding energy is additive across positions in the target site and that single-base changes at one position contribute independent energy penalties.\n\nStarting from the following foundational base:\n- The Central Dogma of Molecular Biology links genotype to phenotype, and selection assays enrich bound complexes for sequencing.\n- Thermodynamic equilibrium for binding implies that the occupancy probability of a sequence with energy $E$ is proportional to $\\exp\\!\\left(-\\beta E\\right)$, where $\\beta = 1/\\left(k_{\\mathrm{B}} T\\right)$, $k_{\\mathrm{B}}$ is the Boltzmann constant, and $T$ is absolute temperature.\n- In a counting assay after selection and sequencing, the observed read count $C_s$ for sequence $s$ can be modeled as proportional to its relative occupancy and its input abundance $q_s$. A standard statistical idealization is to model counts as independent Poisson random variables with mean $\\lambda_s = \\kappa \\, q_s \\, \\exp\\!\\left(-\\beta E_s\\right)$ for some scaling factor $\\kappa > 0$ collecting total sequencing depth and selection strength.\n- For an additive binding model, the energy of a sequence $s = (b_1, b_2, \\dots, b_L)$ is $E_s = \\sum_{i=1}^{L} \\varepsilon_i(b_i)$, where $\\varepsilon_i(b)$ is the contribution at position $i$ for base $b$. Choose a reference base $b_i^\\star$ at each position such that $\\varepsilon_i(b_i^\\star) = 0$ by definition, and interpret $\\varepsilon_i(b)$ for $b \\neq b_i^\\star$ as the per-position energy penalty.\n\nYou are given observed counts for a wildtype consensus sequence (all positions at their reference bases) and for all single-base mutants that change exactly one position to a non-reference base. For each mutant, you are also given its input abundance $q_s$ and the wildtype input abundance $q_{\\mathrm{WT}}$. Assume that:\n- The wildtype expected mean is $\\lambda_{\\mathrm{WT}} = \\kappa \\, q_{\\mathrm{WT}}$.\n- A single mutant changing position $i$ from $b_i^\\star$ to $b$ has expected mean $\\lambda_{i,b} = \\kappa \\, q_{i,b} \\, \\exp\\!\\left(-\\beta \\, \\varepsilon_i(b)\\right)$.\n- Conditioning on the total number of observed reads transforms the Poisson model into a multinomial model with category probabilities proportional to $q_s \\, \\exp\\!\\left(-\\beta E_s\\right)$.\n\nTask:\n1. Derive, from first principles using the foundations above, the maximum likelihood estimator (MLE) for the energy penalty $\\varepsilon_i(b)$ in units of $k_{\\mathrm{B}} T$ when $\\beta$ is known, based on the observed counts $C_{\\mathrm{WT}}$ and $C_{i,b}$ and the input abundance ratio $q_{i,b}/q_{\\mathrm{WT}}$. Resolve the intrinsic scale invariance by using the wildtype as the reference category.\n2. To handle zero or near-zero counts robustly, incorporate symmetric Dirichlet regularization with concentration parameter $\\alpha > 0$ on the multinomial probabilities across the wildtype and all single mutants. Use the posterior mean probabilities to form a regularized estimator. Express all energies in units of $k_{\\mathrm{B}} T$ as real numbers.\n3. Implement the derived estimator in a program that computes $\\varepsilon_i(b)$ for each position and non-reference base in the provided test suite below. Use $\\beta = 1$ so that energies are reported directly in units of $k_{\\mathrm{B}} T$. Apply the same $\\alpha$ to the wildtype and to every mutant category. For each test case, output a nested list of energy penalties with three decimal places, in the specified base order per position.\n\nAngle and unit specifications:\n- Angles are not used in this problem.\n- All energies must be expressed as real numbers in units of $k_{\\mathrm{B}} T$.\n- Report each energy rounded to exactly three decimal places as a decimal number (not a fraction).\n\nTest Suite:\nFor all test cases, use $\\beta = 1$ and $\\alpha = 0.5$.\n\n- Test Case $1$ (uniform input abundances; \"happy path\"):\n  - Wildtype input abundance: $q_{\\mathrm{WT}} = 1.0$.\n  - Wildtype observed count: $C_{\\mathrm{WT}} = 5000$.\n  - Positions and mutants (each line gives: position index $i$, reference base $b_i^\\star$, mutant base order, mutant input abundances $q_{i,b}$ in that order, observed counts $C_{i,b}$ in the same order):\n    - Position $1$, reference $A$, mutants in order $[C, G, T]$, $q = [1.0, 1.0, 1.0]$, counts $[3033, 1839, 1120]$.\n    - Position $2$, reference $G$, mutants in order $[A, C, T]$, $q = [1.0, 1.0, 1.0]$, counts $[4094, 2247, 676]$.\n    - Position $3$, reference $T$, mutants in order $[A, C, G]$, $q = [1.0, 1.0, 1.0]$, counts $[3352, 1506, 2744]$.\n\n- Test Case $2$ (biased input abundances favoring wildtype):\n  - Wildtype input abundance: $q_{\\mathrm{WT}} = 2.0$.\n  - Wildtype observed count: $C_{\\mathrm{WT}} = 8000$.\n  - Positions and mutants:\n    - Position $1$, reference $C$, mutants in order $[A, G, T]$, $q = [1.0, 1.0, 1.0]$, counts $[1204, 2681, 892]$.\n    - Position $2$, reference $T$, mutants in order $[A, C, G]$, $q = [1.0, 1.0, 1.0]$, counts $[1988, 1332, 2964]$.\n    - Position $3$, reference $A$, mutants in order $[C, T, G]$, $q = [1.0, 1.0, 1.0]$, counts $[1472, 3277, 540]$.\n\n- Test Case $3$ (edge case with zero observed counts for some mutants):\n  - Wildtype input abundance: $q_{\\mathrm{WT}} = 1.0$.\n  - Wildtype observed count: $C_{\\mathrm{WT}} = 1000$.\n  - Positions and mutants:\n    - Position $1$, reference $G$, mutants in order $[A, C, T]$, $q = [1.0, 1.0, 1.0]$, counts $[135, 30, 0]$.\n    - Position $2$, reference $C$, mutants in order $[A, G, T]$, $q = [1.0, 1.0, 1.0]$, counts $[1000, 820, 370]$.\n    - Position $3$, reference $T$, mutants in order $[A, C, G]$, $q = [1.0, 1.0, 1.0]$, counts $[80, 50, 0]$.\n\nRequired final output format:\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets. Each element corresponds to one test case, and is itself a nested list of lists of floats. For each test case, output a list of positions; for each position, output a list of energy penalties in the exact mutant base order specified for that position. For example, a valid overall output structure is of the form $[\\,[\\,[e_{1,1}, e_{1,2}, e_{1,3}], [e_{2,1}, \\dots], [e_{3,1}, \\dots]\\,], \\, [\\dots], \\, [\\dots]\\,]$ with each $e_{i,j}$ rounded to three decimals.", "solution": "The posed problem requires the derivation and implementation of a regularized estimator for the binding energy penalties of modular transcription factors. The analysis will be performed within the framework of statistical thermodynamics and maximum likelihood estimation, augmented with Bayesian regularization to ensure robustness. All mathematical entities are typeset in LaTeX as per the requirements.\n\nThe foundation of our model is the relationship between binding energy $E_s$ of a DNA sequence $s$ and its probability of being bound, which at thermodynamic equilibrium is proportional to the Boltzmann factor, $\\exp(-\\beta E_s)$, where $\\beta = 1/(k_{\\mathrm{B}} T)$. The problem states that observed read counts $C_s$ from a sequencing experiment are modeled as Poisson random variables with mean $\\lambda_s = \\kappa \\, q_s \\, \\exp(-\\beta E_s)$, where $q_s$ is the input abundance of sequence $s$ and $\\kappa$ is a global scaling constant. The binding energy for a sequence $s = (b_1, b_2, \\dots, b_L)$ is assumed to be additive: $E_s = \\sum_{i=1}^{L} \\varepsilon_i(b_i)$. A reference base $b_i^\\star$ is defined for each position $i$ such that its energy contribution is zero, $\\varepsilon_i(b_i^\\star) = 0$. Consequently, the wildtype sequence (WT), composed entirely of reference bases, has a total binding energy $E_{\\mathrm{WT}} = 0$. A single-base mutant at position $i$ from base $b_i^\\star$ to $b$ has an energy $E_{i,b} = \\varepsilon_i(b)$. The dimensionless energy penalty in units of $k_{\\mathrm{B}} T$ is defined as $e_i(b) = \\beta \\varepsilon_i(b)$, which is the quantity we aim to estimate.\n\n**Part 1: Derivation of the Maximum Likelihood Estimator (MLE)**\n\nThe problem specifies that conditioning on the total number of reads transforms the independent Poisson model into a multinomial distribution. The probability $p_s$ of observing a sequence $s$ is proportional to its expected count $\\lambda_s$, so $p_s \\propto q_s \\exp(-\\beta E_s)$. To estimate the energy penalty $e_i(b) = \\beta \\varepsilon_i(b)$ for a single mutant, we consider the ratio of probabilities between the mutant (sequence $s_{i,b}$) and the wildtype sequence ($s_{\\mathrm{WT}}$).\nThe ratio is given by:\n$$\n\\frac{p_{i,b}}{p_{\\mathrm{WT}}} = \\frac{q_{i,b} \\exp(-\\beta E_{i,b})}{q_{\\mathrm{WT}} \\exp(-\\beta E_{\\mathrm{WT}})}\n$$\nSubstituting $E_{\\mathrm{WT}} = 0$ and $E_{i,b} = \\varepsilon_i(b)$, the expression simplifies to:\n$$\n\\frac{p_{i,b}}{p_{\\mathrm{WT}}} = \\frac{q_{i,b}}{q_{\\mathrm{WT}}} \\exp(-\\beta \\varepsilon_i(b)) = \\frac{q_{i,b}}{q_{\\mathrm{WT}}} \\exp(-e_i(b))\n$$\nIn a multinomial context, the maximum likelihood estimate for the ratio of probabilities of two categories is simply the ratio of their observed counts, $C_{i,b}$ and $C_{\\mathrm{WT}}$.\n$$\n\\frac{\\hat{p}_{i,b}}{\\hat{p}_{\\mathrm{WT}}} = \\frac{C_{i,b}}{C_{\\mathrm{WT}}}\n$$\nBy equating the model's prediction for the probability ratio with its maximum likelihood estimate from the data, we obtain:\n$$\n\\frac{C_{i,b}}{C_{\\mathrm{WT}}} = \\frac{q_{i,b}}{q_{\\mathrm{WT}}} \\exp(-\\hat{e}_{i,b}^{\\text{MLE}})\n$$\nSolving for the MLE of the energy penalty, $\\hat{e}_{i,b}^{\\text{MLE}}$, yields:\n$$\n\\exp(-\\hat{e}_{i,b}^{\\text{MLE}}) = \\frac{C_{i,b}}{C_{\\mathrm{WT}}} \\frac{q_{\\mathrm{WT}}}{q_{i,b}}\n$$\n$$\n\\hat{e}_{i,b}^{\\text{MLE}} = -\\ln\\left(\\frac{C_{i,b}}{C_{\\mathrm{WT}}} \\frac{q_{\\mathrm{WT}}}{q_{i,b}}\\right) = \\ln\\left(\\frac{C_{\\mathrm{WT}}}{C_{i,b}} \\frac{q_{i,b}}{q_{\\mathrm{WT}}}\\right)\n$$\nThis estimator is problematic when the count for a mutant is zero ($C_{i,b} = 0$), as it results in an infinite energy penalty.\n\n**Part 2: Derivation of the Regularized Estimator**\n\nTo robustly handle cases of zero or low counts, we introduce Bayesian regularization as specified. We place a symmetric Dirichlet prior with concentration parameter $\\alpha > 0$ on the vector of multinomial probabilities. For any pair of categories, such as the wildtype and a single mutant $(i,b)$, this corresponds to a Beta distribution, $\\text{Beta}(\\alpha, \\alpha)$, as a prior on their respective probabilities. The posterior distribution of the probabilities, given the counts $(C_{\\mathrm{WT}}, C_{i,b})$, is then a Dirichlet (specifically, Beta) distribution with updated parameters:\n$$\nP(p_{\\mathrm{WT}}, p_{i,b} | C_{\\mathrm{WT}}, C_{i,b}) \\sim \\text{Dirichlet}(C_{\\mathrm{WT}} + \\alpha, C_{i,b} + \\alpha)\n$$\nThe problem stipulates using the posterior mean probabilities to form the estimator. The mean of a Dirichlet-distributed variable $p_k$ with parameter $\\alpha_k$ is $E[p_k] = \\alpha_k / \\sum_j \\alpha_j$. The ratio of the posterior mean probabilities for the mutant and the wildtype is therefore:\n$$\n\\frac{E[p_{i,b}]}{E[p_{\\mathrm{WT}}]} = \\frac{(C_{i,b} + \\alpha) / (C_{\\mathrm{WT}} + C_{i,b} + 2\\alpha)}{(C_{\\mathrm{WT}} + \\alpha) / (C_{\\mathrm{WT}} + C_{i,b} + 2\\alpha)} = \\frac{C_{i,b} + \\alpha}{C_{\\mathrm{WT}} + \\alpha}\n$$\nThis regularized ratio, which can be interpreted as using pseudocounts, replaces the raw count ratio in our estimation formula. Let $\\tilde{e}_{i,b}$ be the regularized energy estimate.\n$$\n\\frac{C_{i,b} + \\alpha}{C_{\\mathrm{WT}} + \\alpha} = \\frac{q_{i,b}}{q_{\\mathrm{WT}}} \\exp(-\\tilde{e}_{i,b})\n$$\nSolving for $\\tilde{e}_{i,b}$ gives the final regularized estimator:\n$$\n\\tilde{e}_{i,b} = -\\ln\\left(\\frac{C_{i,b} + \\alpha}{C_{\\mathrm{WT}} + \\alpha} \\frac{q_{\\mathrm{WT}}}{q_{i,b}}\\right) = \\ln\\left(\\frac{C_{\\mathrm{WT}} + \\alpha}{C_{i,b} + \\alpha} \\frac{q_{i,b}}{q_{\\mathrm{WT}}}\\right)\n$$\nThis estimator is robust, as for $\\alpha > 0$, the argument of the logarithm is always finite and positive, even if $C_{i,b} = 0$.\n\n**Part 3: Implementation for Test Suite**\n\nFor the implementation, the problem specifies $\\beta = 1$ (so energies are in units of $k_{\\mathrm{B}} T$) and a regularization parameter $\\alpha = 0.5$. The formula to be implemented is:\n$$\ne_{i,b} = \\ln\\left(\\frac{C_{\\mathrm{WT}} + 0.5}{C_{i,b} + 0.5} \\cdot \\frac{q_{i,b}}{q_{\\mathrm{WT}}}\\right)\n$$\nThis formula is applied to each mutant in the provided test cases, using the corresponding wildtype count $C_{\\mathrm{WT}}$, wildtype abundance $q_{\\mathrm{WT}}$, mutant count $C_{i,b}$, and mutant abundance $q_{i,b}$. The results for each position are collected and formatted as specified.", "answer": "```\n[[[0.500,1.000,1.500],[0.200,0.800,2.000],[0.400,1.200,0.600]],[[1.200,0.400,1.500],[0.700,1.100,0.300],[1.000,0.200,2.000]],[[2.000,3.500,7.601],[0.000,0.200,1.000],[2.500,3.000,7.601]]]\n```", "id": "2788400"}]}