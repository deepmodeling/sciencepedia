{"hands_on_practices": [{"introduction": "This exercise lays the theoretical groundwork for understanding demographic inference. We begin by deriving the classic relationship linking genetic diversity ($\\pi$), mutation rate ($\\mu$), and effective population size ($N_e$) under the simple assumption of a constant-size population. By then introducing a demographic change, you will analytically demonstrate why this equilibrium-based formula fails, revealing the fundamental motivation for using more sophisticated methods like PSMC and skyline plots that can reconstruct a time-varying $N_e(t)$. [@problem_id:2700391]", "problem": "A diploid, randomly mating population is evolving neutrally at an autosomal locus under the infinite-sites mutation model with per-site per-generation mutation rate $\\mu$. Assume the Wright–Fisher model as the fundamental base, the coalescent approximation for large population size, and genome-wide sampling so that $\\pi$ (nucleotide diversity) is well estimated.\n\nStarting from first principles in coalescent theory:\n- For a constant-size population, the expected time to the most recent common ancestor of two lineages is $E[T_{2}] = 2N_{e}$ generations.\n- Under the infinite-sites model, the expected number of pairwise differences per site equals $2\\mu E[T_{2}]$.\n\n1) Use these principles to derive the canonical relationship linking $\\pi$, $N_{e}$, and $\\mu$ for an autosome at demographic equilibrium. Then, using the measured values $\\pi = 2.7 \\times 10^{-3}$ and $\\mu = 1.5 \\times 10^{-8}$, compute the point estimate of $N_{e}$ under the equilibrium assumption.\n\n2) Next, consider a nonequilibrium, two-epoch demographic history in which the population has size $N_{1}$ from the present back to time $\\tau$ generations in the past, and size $N_{2}$ prior to time $\\tau$. Using the coalescent hazard $\\lambda(t) = \\frac{1}{2N_{e}(t)}$ and the survival function $S(t) = \\exp\\!\\left(-\\int_{0}^{t}\\lambda(s)\\,ds\\right)$ for the time to coalescence of two lineages, derive an expression for $\\pi$ in terms of $\\mu$, $N_{1}$, $N_{2}$, and $\\tau$. Using this expression, explain analytically why the equilibrium-based mapping from $\\pi$ to $N_{e}$ fails under nonequilibrium demography, and connect your explanation to what the Bayesian Skyline Plot and the Pairwise Sequentially Markovian Coalescent (PSMC) attempt to infer about $N_{e}(t)$.\n\nReport the numerical answer for part (1) as the number of diploid individuals, rounded to four significant figures. Do not include units in your final answer.", "solution": "This problem will be addressed in two parts, as requested. First, the problem statement must be rigorously validated.\n\n**Problem Validation**\n\nStep 1: Extract Givens.\n-   Model: Diploid, randomly mating population.\n-   Evolutionary dynamics: Neutrally evolving autosomal locus.\n-   Mutation model: Infinite-sites model, per-site per-generation mutation rate is $\\mu$.\n-   Population model: Wright–Fisher, with coalescent approximation for large population size.\n-   Data: Nucleotide diversity $\\pi$ is well estimated from genome-wide sampling.\n-   Provided principle for constant population size: The expected time to the most recent common ancestor for two lineages is $E[T_{2}] = 2N_{e}$ generations.\n-   Provided principle for mutation accumulation: The expected number of pairwise differences per site, $\\pi$, equals $2\\mu E[T_{2}]$.\n-   Part 1 numerical values: $\\pi = 2.7 \\times 10^{-3}$ and $\\mu = 1.5 \\times 10^{-8}$.\n-   Part 2 demographic model: A two-epoch history with population size $N_{1}$ from the present to time $\\tau$ generations ago, and size $N_{2}$ for time prior to $\\tau$.\n-   Part 2 mathematical tools: Coalescent hazard rate $\\lambda(t) = \\frac{1}{2N_{e}(t)}$ and survival function $S(t) = \\exp\\!\\left(-\\int_{0}^{t}\\lambda(s)\\,ds\\right)$.\n\nStep 2: Validate Using Extracted Givens.\nThe problem is a standard exercise in theoretical population genetics, specifically in coalescent theory.\n-   The problem is **scientifically grounded**. All models (Wright-Fisher, infinite-sites, coalescent process) and principles are fundamental and well-established in the field. The provided values for $\\pi$ and $\\mu$ are biologically plausible.\n-   The problem is **well-posed**. It provides sufficient information to derive the required expressions and compute the numerical answer. The questions are unambiguous.\n-   The problem is **objective**. The language is technical and precise, devoid of subjective or unscientific claims.\n-   The problem is directly and precisely related to the specified topic of *demographic history inference from genomes* and the methods (Bayesian Skyline Plots, PSMC) mentioned.\n-   The problem is neither trivial nor pseudo-profound; it tests fundamental understanding of how summary statistics relate to underlying demographic processes and why more sophisticated methods are necessary for non-equilibrium scenarios.\n\nStep 3: Verdict and Action.\nThe problem statement is valid. A solution will be provided.\n\n**Solution**\n\n**Part 1: Equilibrium Demography**\nThe nucleotide diversity, $\\pi$, is defined as the average number of pairwise differences per site between two randomly chosen sequences from the population. The problem statement provides that this quantity is given by the expression:\n$$ \\pi = 2\\mu E[T_{2}] $$\nwhere $\\mu$ is the mutation rate per site per generation and $E[T_{2}]$ is the expected time to the most recent common ancestor (TMRCA) for a pair of lineages.\n\nUnder the assumption of a constant-size diploid population at demographic equilibrium, the expected TMRCA is given as:\n$$ E[T_{2}] = 2N_{e} $$\nwhere $N_{e}$ is the effective population size.\n\nSubstituting this expression for $E[T_{2}]$ into the equation for $\\pi$ yields the canonical relationship for a diploid autosomal locus:\n$$ \\pi = 2\\mu (2N_{e}) = 4N_{e}\\mu $$\nThis equation links the observable genetic diversity ($\\pi$) to the fundamental evolutionary parameters of effective population size ($N_{e}$) and mutation rate ($\\mu$).\n\nTo compute the point estimate of $N_{e}$, we rearrange this formula:\n$$ N_{e} = \\frac{\\pi}{4\\mu} $$\nUsing the provided values $\\pi = 2.7 \\times 10^{-3}$ and $\\mu = 1.5 \\times 10^{-8}$:\n$$ N_{e} = \\frac{2.7 \\times 10^{-3}}{4 \\times (1.5 \\times 10^{-8})} = \\frac{2.7 \\times 10^{-3}}{6.0 \\times 10^{-8}} = 0.45 \\times 10^{5} = 45000 $$\nThe number of diploid individuals is $45000$. Rounding to four significant figures gives $4.500 \\times 10^{4}$.\n\n**Part 2: Non-Equilibrium Demography**\nFor a population with a time-varying size $N_{e}(t)$, the simple relation $E[T_{2}] = 2N_{e}$ is no longer valid. We must calculate $E[T_{2}]$ from first principles using the provided survival function for the coalescence time $T_{2}$. The expected value of a non-negative random variable is the integral of its survival function:\n$$ E[T_{2}] = \\int_{0}^{\\infty} S(t) \\,dt = \\int_{0}^{\\infty} P(T_2 > t) \\,dt $$\nwhere the survival function is $S(t) = \\exp\\!\\left(-\\int_{0}^{t}\\lambda(s)\\,ds\\right)$ and the coalescent hazard rate is $\\lambda(s) = \\frac{1}{2N_{e}(s)}$.\n\nThe specified two-epoch demographic model has a piecewise-constant population size:\n$$ N_{e}(t) = \\begin{cases} N_{1} & \\text{if } 0 \\le t < \\tau \\\\ N_{2} & \\text{if } t \\ge \\tau \\end{cases} $$\nThe integral for $E[T_{2}]$ must be split at the time point $\\tau$:\n$$ E[T_{2}] = \\int_{0}^{\\tau} S(t) \\,dt + \\int_{\\tau}^{\\infty} S(t) \\,dt $$\nFor the first interval, $0 \\le t < \\tau$, the coalescent rate is constant, $\\lambda(s) = \\frac{1}{2N_{1}}$. The survival function is $S(t) = \\exp\\!\\left(-\\int_{0}^{t}\\frac{1}{2N_{1}}\\,ds\\right) = \\exp\\!\\left(-\\frac{t}{2N_{1}}\\right)$. The first integral is:\n$$ \\int_{0}^{\\tau} \\exp\\!\\left(-\\frac{t}{2N_{1}}\\right) \\,dt = \\left[-2N_{1}\\exp\\!\\left(-\\frac{t}{2N_{1}}\\right)\\right]_{0}^{\\tau} = -2N_{1}\\exp\\!\\left(-\\frac{\\tau}{2N_{1}}\\right) - (-2N_{1}) = 2N_{1}\\left(1 - \\exp\\!\\left(-\\frac{\\tau}{2N_{1}}\\right)\\right) $$\nFor the second interval, $t \\ge \\tau$, we first evaluate the cumulative hazard $\\int_{0}^{t}\\lambda(s)\\,ds$:\n$$ \\int_{0}^{t}\\lambda(s)\\,ds = \\int_{0}^{\\tau}\\frac{1}{2N_{1}}\\,ds + \\int_{\\tau}^{t}\\frac{1}{2N_{2}}\\,ds = \\frac{\\tau}{2N_{1}} + \\frac{t-\\tau}{2N_{2}} $$\nThe survival function for $t \\ge \\tau$ is $S(t) = \\exp\\!\\left(-\\left(\\frac{\\tau}{2N_{1}} + \\frac{t-\\tau}{2N_{2}}\\right)\\right)$. The second integral is:\n$$ \\int_{\\tau}^{\\infty} \\exp\\!\\left(-\\frac{\\tau}{2N_{1}}\\right) \\exp\\!\\left(-\\frac{t-\\tau}{2N_{2}}\\right) \\,dt $$\nWe can factor out the constant term $\\exp\\!\\left(-\\frac{\\tau}{2N_{1}}\\right)$ and perform a change of variables $u = t - \\tau$, $du = dt$:\n$$ \\exp\\!\\left(-\\frac{\\tau}{2N_{1}}\\right) \\int_{0}^{\\infty} \\exp\\!\\left(-\\frac{u}{2N_{2}}\\right) \\,du = \\exp\\!\\left(-\\frac{\\tau}{2N_{1}}\\right) \\left[ -2N_{2}\\exp\\!\\left(-\\frac{u}{2N_{2}}\\right) \\right]_{0}^{\\infty} = 2N_{2}\\exp\\!\\left(-\\frac{\\tau}{2N_{1}}\\right) $$\nCombining the two parts gives the total expected TMRCA:\n$$ E[T_{2}] = 2N_{1}\\left(1 - \\exp\\!\\left(-\\frac{\\tau}{2N_{1}}\\right)\\right) + 2N_{2}\\exp\\!\\left(-\\frac{\\tau}{2N_{1}}\\right) $$\nFinally, the expression for nucleotide diversity $\\pi$ is $2\\mu E[T_{2}]$:\n$$ \\pi = 4\\mu \\left( N_{1}\\left(1 - \\exp\\!\\left(-\\frac{\\tau}{2N_{1}}\\right)\\right) + N_{2}\\exp\\!\\left(-\\frac{\\tau}{2N_{1}}\\right) \\right) $$\n\nThis result explains why the equilibrium-based mapping fails. If one measures a single value of $\\pi$ and naively computes an effective population size using $N_{e, inferred} = \\frac{\\pi}{4\\mu}$, the result is:\n$$ N_{e, inferred} = N_{1}\\left(1 - \\exp\\!\\left(-\\frac{\\tau}{2N_{1}}\\right)\\right) + N_{2}\\exp\\!\\left(-\\frac{\\tau}{2N_{1}}\\right) $$\nThis inferred size is not equal to the current size $N_{1}$ or the ancestral size $N_{2}$ (unless $N_{1} = N_{2}$). Instead, it is a weighted average of population sizes over the history of the sampled lineages, where the weights are related to the probability of coalescence in each epoch. A single summary statistic, $\\pi$, which is the mean of the distribution of coalescence times, has insufficient information to disentangle the three parameters $N_{1}$, $N_{2}$, and $\\tau$. It averages out the temporal variation in population size.\n\nMethods such as the Bayesian Skyline Plot (BSP) and the Pairwise Sequentially Markovian Coalescent (PSMC) are designed specifically to address this issue. Instead of relying on a single summary statistic like $\\pi$, they utilize the full distribution of coalescence times as reflected in the patterns of genetic variation along the genome. PSMC, for instance, models the sequence of heterozygous and homozygous blocks in a single diploid genome as a Hidden Markov Model, where the hidden states are the coalescence times for different genomic segments. By estimating the distribution of these times, PSMC infers the time-varying coalescent rate $\\lambda(t) = \\frac{1}{2N_{e}(t)}$, thereby reconstructing the historical trajectory of the effective population size $N_{e}(t)$ as a piecewise-constant function. BSP uses Bayesian MCMC to sample genealogies compatible with the genetic data, from which a posterior distribution of $N_{e}(t)$ is derived. In essence, these methods dissect the information contained in the genome to estimate population size in different historical epochs, rather than collapsing it all into a single, uninformative average.", "answer": "$$\\boxed{4.500 \\times 10^{4}}$$", "id": "2700391"}, {"introduction": "Having established the need for models that accommodate demographic change, this practice delves into the statistical machinery of Bayesian skyline methods. Focusing on a single time interval, you will use a conjugate prior framework to see precisely how observed data—the number of coalescent events and the total time lineages were available to coalesce—updates our knowledge about the effective population size. This exercise demystifies the inferential engine, showing how a prior belief about $N_e$ is transformed into a data-informed posterior distribution. [@problem_id:2700405]", "problem": "In a Bayesian skyline plot (BSP) or Pairwise Sequentially Markovian Coalescent (PSMC) framework, the effective population size is modeled as piecewise constant across time intervals. Consider a single interval in which the effective population size $N_e$ is constant. Under Kingman’s coalescent with continuous time measured in generations, the instantaneous hazard of a coalescent event when there are $k$ ancestral lineages is $\\binom{k}{2} \\, \\theta$, where $\\theta = \\frac{1}{2 N_e}$ is the per-pair coalescent rate.\n\nWithin this interval, suppose $m$ coalescent events occur and the total coalescent opportunity (the lineage-pair time) is $W = \\sum_{j} \\binom{k_j}{2} \\, \\Delta t_j$, where $\\Delta t_j$ are the durations between successive events during which $k_j$ is constant. Assume the prior on the per-pair coalescent rate is $\\theta \\sim \\mathrm{Gamma}(\\alpha_0, \\beta_0)$ with the rate parameterization, that is, with density $f(\\theta) = \\frac{\\beta_0^{\\alpha_0}}{\\Gamma(\\alpha_0)} \\, \\theta^{\\alpha_0 - 1} \\exp(-\\beta_0 \\theta)$ for $\\theta > 0$.\n\nStarting from the definition of the coalescent hazard and the memorylessness of the exponential waiting time, derive the posterior distribution of $N_e$ given $m$ and $W$ under this conjugate setup, and then compute the posterior mean of $N_e$ for the following values: $\\alpha_0 = 2.7$, $\\beta_0 = 1.5 \\times 10^{4}$, $m = 5$, and $W = 1.8 \\times 10^{5}$. Express your final numerical answer as a number of individuals and round your answer to four significant figures.", "solution": "The fundamental base is Kingman’s coalescent in continuous time. When there are $k$ lineages, the instantaneous rate (hazard) of a coalescent event is $\\lambda_k = \\binom{k}{2} \\, \\theta$, where $\\theta = \\frac{1}{2 N_e}$. The waiting time until the next event with fixed $k$ is exponentially distributed with rate $\\lambda_k$, and disjoint waiting times are independent due to the memoryless property of the exponential distribution.\n\nOver an interval where $N_e$ is constant but $k$ can change at event times, the joint likelihood of observing $m$ coalescent events at unspecified times depends on $\\theta$ only through the sufficient statistics $m$ (the number of events) and the total coalescent opportunity $W = \\sum_{j} \\binom{k_j}{2} \\Delta t_j$. Specifically, the exponential waiting-time likelihood accumulates multiplicatively across subintervals where $k$ is constant, giving a kernel in $\\theta$ of the form\n$$\nL(\\theta \\mid m, W) \\propto \\theta^{m} \\exp(-\\theta W).\n$$\nThis is the standard result that the likelihood for the rate parameter of an inhomogeneous Poisson process with piecewise-constant intensity collapses to a gamma kernel in the rate parameter when summarized by the event count and the integrated intensity.\n\nWith the prior $\\theta \\sim \\mathrm{Gamma}(\\alpha_0, \\beta_0)$ in the rate parameterization,\n$$\n\\pi(\\theta) = \\frac{\\beta_0^{\\alpha_0}}{\\Gamma(\\alpha_0)} \\, \\theta^{\\alpha_0 - 1} \\exp(-\\beta_0 \\theta),\n$$\nBayes’ theorem gives the posterior for $\\theta$:\n$$\n\\pi(\\theta \\mid m, W) \\propto \\theta^{m} \\exp(-\\theta W) \\cdot \\theta^{\\alpha_0 - 1} \\exp(-\\beta_0 \\theta)\n= \\theta^{\\alpha_0 + m - 1} \\exp\\!\\big(-(\\beta_0 + W)\\theta\\big).\n$$\nThus,\n$$\n\\theta \\mid m, W \\sim \\mathrm{Gamma}\\!\\big(\\alpha_0 + m, \\, \\beta_0 + W\\big),\n$$\nagain in the rate parameterization.\n\nWe seek the posterior for $N_e$. The transformation is $N_e = \\frac{1}{2 \\theta}$, so $\\theta = \\frac{1}{2 N_e}$, and the Jacobian is\n$$\n\\left|\\frac{d\\theta}{dN_e}\\right| = \\frac{1}{2 N_e^{2}}.\n$$\nIf we denote $\\alpha = \\alpha_0 + m$ and $\\beta = \\beta_0 + W$, the posterior density of $N_e$ follows from change of variables:\n$$\np(N_e \\mid m, W)\n= \\frac{\\beta^{\\alpha}}{\\Gamma(\\alpha)}\n\\left(\\frac{1}{2 N_e}\\right)^{\\alpha - 1}\n\\exp\\!\\left(-\\beta \\cdot \\frac{1}{2 N_e}\\right)\n\\cdot \\frac{1}{2 N_e^{2}},\n$$\nwhich simplifies to\n$$\np(N_e \\mid m, W)\n= \\frac{\\beta^{\\alpha}}{\\Gamma(\\alpha) \\, 2^{\\alpha}} \\, N_e^{-(\\alpha + 1)} \\, \\exp\\!\\left(-\\frac{\\beta}{2 N_e}\\right), \\quad N_e > 0.\n$$\nThis is an inverse-gamma distribution with shape $\\alpha$ and scale parameter $\\frac{\\beta}{2}$. A convenient moment is the posterior mean of $N_e$, which exists for $\\alpha > 1$ and is given by\n$$\n\\mathbb{E}[N_e \\mid m, W] = \\frac{\\beta}{2(\\alpha - 1)} = \\frac{\\beta_0 + W}{2(\\alpha_0 + m - 1)}.\n$$\nWe now plug in the provided values: $\\alpha_0 = 2.7$, $m = 5$, $\\beta_0 = 1.5 \\times 10^{4}$, and $W = 1.8 \\times 10^{5}$. First compute\n$$\n\\alpha = \\alpha_0 + m = 2.7 + 5 = 7.7, \\quad \\alpha - 1 = 6.7,\n$$\nand\n$$\n\\beta = \\beta_0 + W = 1.5 \\times 10^{4} + 1.8 \\times 10^{5} = 1.95 \\times 10^{5}.\n$$\nTherefore,\n$$\n\\mathbb{E}[N_e \\mid m, W] = \\frac{1.95 \\times 10^{5}}{2 \\times 6.7} = \\frac{1.95 \\times 10^{5}}{13.4} \\approx 1.45522388 \\times 10^{4}.\n$$\nRounded to four significant figures and expressed as a count of individuals, the answer is $1.455 \\times 10^{4}$.", "answer": "$$\\boxed{1.455 \\times 10^{4}}$$", "id": "2700405"}, {"introduction": "Any inferred demographic history is an estimate, and a critical part of the scientific process is quantifying the uncertainty around that estimate. This practical exercise simulates the final step of a PSMC or BSP analysis, where you are given a set of population size estimates from bootstrap replicates. You will learn the standard method for calculating variance and, more importantly, how to construct statistically robust confidence intervals on a logarithmic scale, which properly accounts for the multiplicative nature of uncertainty in $N_e$ estimates. [@problem_id:2700401]", "problem": "You are given bootstrap replicate estimates of effective population size in a time bin produced by demographic inference methods such as the Bayesian skyline plot (BSP) or the Pairwise Sequentially Markovian Coalescent (PSMC). In coalescent-based inference, the effective population size is denoted by $N_e$, and resampling by bootstrap yields replicates $\\{\\hat N_e^{(r)}\\}_{r=1}^R$ that approximate the sampling distribution of the estimator for a fixed time bin. You will implement, for each bin, the following two tasks grounded in fundamental statistical definitions and justified by multiplicative uncertainty in population size estimators:\n\n- Compute the unbiased sample variance on the original scale using the standard definition of variance from bootstrap replicates.\n- Construct a two-sided confidence band with nominal coverage $0.95$ on a logarithmic scale to capture multiplicative uncertainty, and then map the band back to the original scale.\n\nFoundational base:\n- Bootstrap replicates approximate the sampling distribution of an estimator by resampling with replacement under the same data-generating process.\n- The unbiased sample variance of a univariate sample $\\{x_r\\}_{r=1}^R$ is $s^2=\\frac{1}{R-1}\\sum_{r=1}^R (x_r-\\bar x)^2$, where $\\bar x=\\frac{1}{R}\\sum_{r=1}^R x_r$ and $R\\ge 2$.\n- For multiplicative noise $X=\\theta\\cdot\\eta$, a logarithmic transform $Y=\\log X$ converts multiplicative deviations into additive ones; if $Y$ is approximately normal, then an approximate two-sided $(1-\\alpha)$ confidence band on the log scale is $\\bar Y \\pm z_{1-\\alpha/2}\\, s_Y$, where $\\bar Y$ and $s_Y$ are the sample mean and sample standard deviation of $\\{Y_r\\}_{r=1}^R$, and $z_{q}$ is the $q$-quantile of the standard normal distribution. Mapping back to the original scale yields $\\left[\\exp(\\bar Y - z_{1-\\alpha/2}\\, s_Y),\\, \\exp(\\bar Y + z_{1-\\alpha/2}\\, s_Y)\\right]$.\n\nFormally, for each bin with strictly positive bootstrap replicates $\\{\\hat N_e^{(r)}\\}_{r=1}^R$:\n- Compute the unbiased sample variance on the original scale,\n$$\ns_{\\text{orig}}^2 \\;=\\; \\frac{1}{R-1}\\sum_{r=1}^R \\left(\\hat N_e^{(r)} - \\bar N_e\\right)^2,\\quad\n\\bar N_e \\;=\\; \\frac{1}{R}\\sum_{r=1}^R \\hat N_e^{(r)}.\n$$\n- Define $Y_r=\\log \\hat N_e^{(r)}$ for $r=1,\\dots,R$, and compute\n$$\n\\bar Y \\;=\\; \\frac{1}{R}\\sum_{r=1}^R Y_r,\\qquad\ns_Y \\;=\\; \\sqrt{\\frac{1}{R-1}\\sum_{r=1}^R \\left(Y_r-\\bar Y\\right)^2}.\n$$\nWith $\\alpha=0.05$, let $z_{1-\\alpha/2}$ denote the standard normal quantile at $1-\\alpha/2=0.975$. The logarithmic confidence band mapped back to the original scale is\n$$\n\\left[L, U\\right] \\;=\\; \\left[\\exp\\!\\left(\\bar Y - z_{0.975}\\, s_Y\\right),\\ \\exp\\!\\left(\\bar Y + z_{0.975}\\, s_Y\\right)\\right].\n$$\n\nYour program must implement these computations for the following test suite of bins, each represented as a list of strictly positive real numbers $\\{\\hat N_e^{(r)}\\}_{r=1}^R$:\n- Case $1$ (typical moderate variability): $[10000.0,\\, 12000.0,\\, 11000.0,\\, 10500.0,\\, 11500.0]$.\n- Case $2$ (identical replicates; boundary for zero variance): $[5000.0,\\, 5000.0,\\, 5000.0,\\, 5000.0]$.\n- Case $3$ (minimal replicates $R=2$; large spread): $[10000.0,\\, 40000.0]$.\n- Case $4$ (strong multiplicative spread): $[10000.0,\\, 20000.0,\\, 40000.0,\\, 80000.0,\\, 160000.0]$.\n\nRequirements:\n- For each case, compute $s_{\\text{orig}}^2$, $L$, and $U$ as defined above, using the natural logarithm.\n- Use the unbiased variance and standard deviation with divisor $R-1$.\n- Use the standard normal quantile $z_{0.975}$ for the confidence band.\n- Round each reported number to $6$ decimal places.\n- Final output format: Your program should produce a single line containing a comma-separated list of results, one per test case, enclosed in square brackets. Each result must itself be a list of three floats in the order $[s_{\\text{orig}}^2, L, U]$. For example, the overall output must look like\n$[[v_1,\\ell_1,u_1],[v_2,\\ell_2,u_2],[v_3,\\ell_3,u_3],[v_4,\\ell_4,u_4]]$\nwith no extra spaces.", "solution": "The problem statement has been evaluated and is determined to be valid. It is scientifically grounded in established statistical and population genetic principles, is well-posed with a clear and complete specification, and is formulated objectively. Therefore, we will proceed to derive the solution.\n\nThe task is to compute two statistical summaries for each provided set of bootstrap replicates of effective population size, $\\{\\hat N_e^{(r)}\\}_{r=1}^R$. These replicates are given for a single time bin. The calculations will be performed for $4$ separate test cases.\n\nThe first quantity is the unbiased sample variance of the replicates on their original scale. For a set of $R$ replicates, this is computed using the formula:\n$$\ns_{\\text{orig}}^2 = \\frac{1}{R-1}\\sum_{r=1}^R \\left(\\hat N_e^{(r)} - \\bar N_e\\right)^2\n$$\nwhere $\\bar N_e$ is the sample mean, $\\bar N_e = \\frac{1}{R}\\sum_{r=1}^R \\hat N_e^{(r)}$. This calculation is only defined for $R \\ge 2$, a condition met by all test cases.\n\nThe second task is to construct a two-sided confidence band with a nominal coverage of $0.95$. This is predicated on the assumption that the uncertainty in $\\hat N_e$ is multiplicative, which is a common and reasonable model in this domain. A logarithmic transformation, $Y_r = \\log \\hat N_e^{(r)}$, converts multiplicative noise to an additive-normal form. We use the natural logarithm for the $\\log$ function. On this log-transformed scale, we compute the sample mean $\\bar Y$ and the unbiased sample standard deviation $s_Y$:\n$$\n\\bar Y = \\frac{1}{R}\\sum_{r=1}^R Y_r, \\qquad s_Y = \\sqrt{\\frac{1}{R-1}\\sum_{r=1}^R \\left(Y_r - \\bar Y\\right)^2}\n$$\nA $(1-\\alpha)$ confidence interval for the mean on the log scale is given by $\\bar Y \\pm z_{1-\\alpha/2} s_Y$. For a $0.95$ confidence level, $\\alpha = 0.05$, so we require the $1 - 0.05/2 = 0.975$ quantile of the standard normal distribution, denoted as $z_{0.975}$. The value is approximately $z_{0.975} \\approx 1.959964$.\n\nThe lower ($L$) and upper ($U$) bounds of the confidence interval are found by exponentiating the limits of the log-scale interval:\n$$\nL = \\exp(\\bar Y - z_{0.975}\\, s_Y)\n$$\n$$\nU = \\exp(\\bar Y + z_{0.975}\\, s_Y)\n$$\nThis results in an asymmetric confidence interval on the original scale, $[L, U]$, which correctly reflects the multiplicative nature of the uncertainty.\n\nThe implementation will proceed as follows for each test case:\n$1$. The input list of replicates is converted to a numerical array. Let the number of replicates be $R$.\n$2$. The unbiased sample variance, $s_{\\text{orig}}^2$, is computed using the formula provided, employing a divisor of $R-1$.\n$3$. The replicates are transformed using the natural logarithm, since all provided values are strictly positive.\n$4$. The mean $\\bar Y$ and unbiased sample standard deviation $s_Y$ of the log-transformed data are computed. If all replicates are identical, $s_Y$ will correctly be $0$.\n$5$. The quantile $z_{0.975}$ is obtained from a high-precision implementation of the standard normal distribution's inverse cumulative distribution function.\n$6$. The confidence limits $L$ and $U$ are calculated by constructing the interval on the log scale and then applying the exponential function to transform it back to the original scale.\n$7$. The final values for $s_{\\text{orig}}^2$, $L$, and $U$ are rounded to $6$ decimal places as required.\n\nThis procedure will be applied to all $4$ test cases provided in the problem statement to generate the final output.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.stats import norm\n\ndef solve():\n    \"\"\"\n    Computes variance and log-normal confidence intervals for bootstrap replicates\n    of effective population size.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # Case 1 (typical moderate variability)\n        [10000.0, 12000.0, 11000.0, 10500.0, 11500.0],\n        # Case 2 (identical replicates; boundary for zero variance)\n        [5000.0, 5000.0, 5000.0, 5000.0],\n        # Case 3 (minimal replicates R=2; large spread)\n        [10000.0, 40000.0],\n        # Case 4 (strong multiplicative spread)\n        [10000.0, 20000.0, 40000.0, 80000.0, 160000.0]\n    ]\n\n    results = []\n    \n    # Set nominal coverage and find the corresponding z-score for a two-sided interval.\n    # For a 95% confidence interval, alpha = 0.05.\n    alpha = 0.05\n    z_score = norm.ppf(1 - alpha / 2)\n\n    for case_data in test_cases:\n        # Use float64 for better precision in numerical computations.\n        replicates = np.array(case_data, dtype=np.float64)\n        R = len(replicates)\n        \n        # The problem statement ensures R >= 2, so ddof=1 is always valid.\n        \n        # Task 1: Compute the unbiased sample variance on the original scale.\n        # np.var with ddof=1 uses a divisor of (R-1).\n        s_orig_sq = np.var(replicates, ddof=1)\n        \n        # Task 2: Construct a log-normal confidence band.\n        # The problem guarantees strictly positive replicates, so log is safe.\n        log_replicates = np.log(replicates)\n        \n        # Compute the sample mean and sample standard deviation on the log scale.\n        # np.std with ddof=1 uses a divisor of (R-1).\n        y_bar = np.mean(log_replicates)\n        s_y = np.std(log_replicates, ddof=1)\n        \n        # If all replicates are identical, s_y will be 0. The subsequent\n        # calculations handle this correctly, yielding a zero-width CI.\n        \n        # Calculate the margin of error on the log scale.\n        margin_of_error = z_score * s_y\n        \n        # Construct the confidence interval on the log scale.\n        log_lower = y_bar - margin_of_error\n        log_upper = y_bar + margin_of_error\n        \n        # Map the interval back to the original scale by exponentiation.\n        L = np.exp(log_lower)\n        U = np.exp(log_upper)\n        \n        # Append the rounded results for the current case.\n        results.append([\n            round(s_orig_sq, 6),\n            round(L, 6),\n            round(U, 6)\n        ])\n\n    # Final print statement must produce a single-line string representation\n    # of the list of lists, with no spaces, as specified.\n    print(str(results).replace(\" \", \"\"))\n\nsolve()\n```", "id": "2700401"}]}