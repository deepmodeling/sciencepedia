{"hands_on_practices": [{"introduction": "The first step in any hybrid zone study is to accurately quantify the ancestry of each individual. The hybrid index, $h$, represents the proportion of an individual's genome derived from one of the two parental populations. This exercise [@problem_id:2717930] walks you through the fundamental process of estimating $h$ from raw genetic data by developing a maximum likelihood model from first principles, a crucial skill for analyzing real-world genomic datasets that are invariably affected by measurement error.", "problem": "Consider a single diploid individual sampled from a hybrid zone between two parental species that are fixed for alternative alleles at a set of ancestry-informative markers (AIMs). At each AIM, the allele denoted $A$ is fixed in parental species $1$ and absent in parental species $2$. The individual’s hybrid index $h$ is defined as the genome-wide probability that a randomly sampled allele copy comes from parental species $1$, with $h \\in [0,1]$. Assume Hardy–Weinberg equilibrium within the individual’s ancestry proportions, independence among loci, and a symmetric, per-allele genotyping error rate $\\epsilon \\in [0,0.5)$ such that any allele copy is miscalled as the alternative allele with probability $\\epsilon$, independently across allele copies and loci.\n\nYou genotype $L$ independent AIMs for this individual and record the dosage $D_i \\in \\{0,1,2\\}$ of allele $A$ at locus $i$, for $i=1,\\dots,L$. Let $n_2$ be the number of loci with $D_i=2$, $n_1$ be the number with $D_i=1$, and $n_0$ be the number with $D_i=0$, so that $L = n_0 + n_1 + n_2$.\n\nUsing only fundamental definitions (including binomial sampling under Hardy–Weinberg equilibrium, independence of allele copies, and the definition of maximum likelihood), derive the likelihood of the observed dosages as a function of $h$ and $\\epsilon$ by appropriately marginalizing over unobserved true genotypes. Then, obtain the maximum likelihood estimate (MLE) $\\hat{h}$ in closed form as a function of $n_0$, $n_1$, $n_2$, and $\\epsilon$.\n\nEvaluate your closed-form expression numerically for the following data: $n_2 = 58$, $n_1 = 34$, $n_0 = 28$, and $\\epsilon = 0.03$. Round your final numerical answer to four significant figures. Your final answer must be a single number.", "solution": "The problem statement is evaluated and found to be valid. It is scientifically grounded in population genetics and statistical theory, objective, well-posed, and contains all necessary information to derive a unique solution. We may therefore proceed with the derivation.\n\nThe objective is to find the maximum likelihood estimate (MLE) of the hybrid index $h$. The hybrid index $h$ represents the probability that a randomly sampled allele copy in a diploid individual is from parental species $1$. Allele $A$ is fixed in species $1$, while the alternative allele, which we shall denote $a$, is fixed in species $2$.\n\nFirst, we establish the probabilities of the three possible true, unobserved genotypes at any given ancestry-informative marker (AIM) locus. Let $G$ be the true genotype, which can be $AA$, $Aa$, or $aa$. Under the assumption of Hardy–Weinberg equilibrium for ancestry proportions, the two allele copies in the diploid individual are independent draws. The probability of drawing an allele from species $1$ (allele $A$) is $h$, and from species $2$ (allele $a$) is $1-h$.\nThe probabilities of the true genotypes are therefore:\n$P(G=AA) = h \\times h = h^2$\n$P(G=Aa) = h(1-h) + (1-h)h = 2h(1-h)$\n$P(G=aa) = (1-h) \\times (1-h) = (1-h)^2$\n\nNext, we model the genotyping error. The observed dosage of allele $A$ is denoted $D \\in \\{0, 1, 2\\}$. A symmetric, per-allele error rate $\\epsilon$ means a true $A$ is miscalled as $a$ with probability $\\epsilon$, and a true $a$ is miscalled as $A$ with probability $\\epsilon$. The probability of a correct call for any allele is $1-\\epsilon$. Errors are independent across the two allele copies at a locus. We now derive the conditional probabilities of observing dosage $D$ given the true genotype $G$.\n\nIf the true genotype is $AA$ ($2$ copies of $A$):\n$P(D=2 | G=AA) = (1-\\epsilon)(1-\\epsilon) = (1-\\epsilon)^2$ (both $A$s called correctly)\n$P(D=1 | G=AA) = \\binom{2}{1}(1-\\epsilon)\\epsilon = 2\\epsilon(1-\\epsilon)$ (one $A$ correct, one miscalled)\n$P(D=0 | G=AA) = \\epsilon \\epsilon = \\epsilon^2$ (both $A$s miscalled)\n\nIf the true genotype is $Aa$ ($1$ copy of $A$, $1$ of $a$):\n$P(D=2 | G=Aa) = (1-\\epsilon)\\epsilon$ ($A$ correct, $a$ miscalled as $A$)\n$P(D=1 | G=Aa) = (1-\\epsilon)(1-\\epsilon) + \\epsilon\\epsilon = (1-\\epsilon)^2 + \\epsilon^2$ ($A$ correct, $a$ correct OR $A$ miscalled, $a$ miscalled)\n$P(D=0 | G=Aa) = \\epsilon(1-\\epsilon)$ ($A$ miscalled as $a$, $a$ correct)\n\nIf the true genotype is $aa$ ($0$ copies of $A$):\n$P(D=2 | G=aa) = \\epsilon\\epsilon = \\epsilon^2$ (both $a$s miscalled as $A$)\n$P(D=1 | G=aa) = \\binom{2}{1}\\epsilon(1-\\epsilon) = 2\\epsilon(1-\\epsilon)$ (one $a$ miscalled, one correct)\n$P(D=0 | G=aa) = (1-\\epsilon)(1-\\epsilon) = (1-\\epsilon)^2$ (both $a$s called correctly)\n\nThe next step is to find the marginal probabilities of observing each dosage, $p_k = P(D=k)$ for $k \\in \\{0, 1, 2\\}$, by summing over the unobserved true genotypes, using the law of total probability: $p_k = \\sum_{G} P(D=k | G) P(G)$.\n\n$p_2 = P(D=2) = P(D=2|G=AA)P(G=AA) + P(D=2|G=Aa)P(G=Aa) + P(D=2|G=aa)P(G=aa)$\n$p_2 = (1-\\epsilon)^2 h^2 + \\epsilon(1-\\epsilon) [2h(1-h)] + \\epsilon^2 (1-h)^2$\nThis expression can be recognized as the expansion of a squared term. Let us define an \"observed\" allele frequency, $h_{obs}$, as the probability that a randomly sampled allele copy is observed as $A$. An allele is observed as $A$ if it was truly $A$ and correctly typed, or if it was truly $a$ and incorrectly typed.\n$h_{obs} = h(1-\\epsilon) + (1-h)\\epsilon = h - h\\epsilon + \\epsilon - h\\epsilon = h(1-2\\epsilon) + \\epsilon$.\nThe probability of observing an allele as $a$ is $1-h_{obs}$.\n$1-h_{obs} = 1 - (h(1-2\\epsilon) + \\epsilon) = h\\epsilon + (1-h)(1-\\epsilon)$.\nDue to the independence of errors between allele copies, the observed genotypes follow Hardy-Weinberg proportions with respect to the observed allele frequency $h_{obs}$. Therefore, the marginal probabilities are:\n$p_2 = h_{obs}^2 = (h(1-2\\epsilon) + \\epsilon)^2$\n$p_1 = 2h_{obs}(1-h_{obs}) = 2(h(1-2\\epsilon) + \\epsilon)(1 - (h(1-2\\epsilon) + \\epsilon))$\n$p_0 = (1-h_{obs})^2 = (1 - (h(1-2\\epsilon) + \\epsilon))^2$\n\nThe data consists of counts $(n_0, n_1, n_2)$ for $L = n_0+n_1+n_2$ independent loci. The likelihood of these data is given by the multinomial probability mass function:\n$L(h | n_0, n_1, n_2, \\epsilon) = \\frac{L!}{n_0! n_1! n_2!} p_0^{n_0} p_1^{n_1} p_2^{n_2}$\nTo find the MLE, we maximize this function with respect to $h$. It is equivalent and simpler to maximize the log-likelihood, $\\ln L$. We can ignore the constant multinomial coefficient.\n$\\ln L \\propto n_0 \\ln(p_0) + n_1 \\ln(p_1) + n_2 \\ln(p_2)$\nSubstituting the expressions in terms of $h_{obs}$:\n$\\ln L \\propto n_0 \\ln((1-h_{obs})^2) + n_1 \\ln(2h_{obs}(1-h_{obs})) + n_2 \\ln(h_{obs}^2)$\n$\\ln L \\propto 2n_0 \\ln(1-h_{obs}) + n_1(\\ln 2 + \\ln h_{obs} + \\ln(1-h_{obs})) + 2n_2 \\ln h_{obs}$\n$\\ln L \\propto (2n_0 + n_1)\\ln(1-h_{obs}) + (n_1 + 2n_2)\\ln h_{obs} + \\text{constant}$\n\nTo find the maximum, we differentiate $\\ln L$ with respect to $h$ and set the derivative to zero. Using the chain rule, $\\frac{d(\\ln L)}{dh} = \\frac{d(\\ln L)}{dh_{obs}} \\frac{dh_{obs}}{dh}$.\n$\\frac{dh_{obs}}{dh} = \\frac{d}{dh}(h(1-2\\epsilon) + \\epsilon) = 1-2\\epsilon$. Since $\\epsilon \\in [0, 0.5)$, $1-2\\epsilon \\neq 0$.\n$\\frac{d(\\ln L)}{dh_{obs}} = \\frac{-(2n_0 + n_1)}{1-h_{obs}} + \\frac{n_1 + 2n_2}{h_{obs}}$\nSetting the derivative to zero:\n$\\frac{n_1 + 2n_2}{h_{obs}} = \\frac{2n_0 + n_1}{1-h_{obs}}$\n$(n_1 + 2n_2)(1-h_{obs}) = (2n_0 + n_1)h_{obs}$\n$n_1 + 2n_2 - (n_1 + 2n_2)h_{obs} = (2n_0 + n_1)h_{obs}$\n$n_1 + 2n_2 = h_{obs}(2n_0 + n_1 + n_1 + 2n_2) = h_{obs}(2n_0 + 2n_1 + 2n_2)$\n$n_1 + 2n_2 = 2h_{obs}(n_0 + n_1 + n_2) = 2h_{obs}L$\nThe MLE for the observed allele frequency, $\\hat{h}_{obs}$, is:\n$\\hat{h}_{obs} = \\frac{n_1 + 2n_2}{2L}$\nThis is the standard gene counting estimate of allele frequency from observed genotype counts.\n\nBy the invariance property of maximum likelihood estimators, the MLE for $h$, denoted $\\hat{h}$, is found by solving the equation for $h$ using $\\hat{h}_{obs}$:\n$\\hat{h}_{obs} = \\hat{h}(1-2\\epsilon) + \\epsilon$\n$\\hat{h}_{obs} - \\epsilon = \\hat{h}(1-2\\epsilon)$\n$\\hat{h} = \\frac{\\hat{h}_{obs} - \\epsilon}{1-2\\epsilon}$\nSubstituting the expression for $\\hat{h}_{obs}$, we obtain the closed-form MLE for $h$:\n$\\hat{h} = \\frac{\\frac{n_1 + 2n_2}{2(n_0+n_1+n_2)} - \\epsilon}{1-2\\epsilon}$\n\nNow we evaluate this expression for the given data: $n_2 = 58$, $n_1 = 34$, $n_0 = 28$, and $\\epsilon = 0.03$.\nFirst, calculate the total number of loci, $L$:\n$L = n_0 + n_1 + n_2 = 28 + 34 + 58 = 120$\nNext, calculate the MLE of the observed allele frequency, $\\hat{h}_{obs}$:\n$\\hat{h}_{obs} = \\frac{n_1 + 2n_2}{2L} = \\frac{34 + 2(58)}{2(120)} = \\frac{34 + 116}{240} = \\frac{150}{240} = \\frac{5}{8} = 0.625$\nFinally, calculate $\\hat{h}$:\n$\\hat{h} = \\frac{\\hat{h}_{obs} - \\epsilon}{1-2\\epsilon} = \\frac{0.625 - 0.03}{1 - 2(0.03)} = \\frac{0.595}{1 - 0.06} = \\frac{0.595}{0.94}$\n$\\hat{h} \\approx 0.6329787...$\nRounding the result to four significant figures gives $0.6330$.", "answer": "$$\n\\boxed{0.6330}\n$$", "id": "2717930"}, {"introduction": "With a way to measure individual ancestry, we can turn to population-level patterns. In classic \"tension zones,\" a geographic cline in allele frequencies is maintained by a balance between dispersal, which tends to broaden the zone, and selection against hybrids, which narrows it. This practice [@problem_id:2717953] explores this balance using a foundational reaction-diffusion model, demonstrating how we can infer the strength of selection, $s$, by analyzing the shape of the cline—a powerful connection between a spatial pattern and an evolutionary process.", "problem": "A one-dimensional hybrid zone between two species spans a linear transect where dispersal between adjacent demes is well-approximated by Gaussian movement with per-generation variance $\\sigma^{2}$ (units: $\\text{km}^{2}\\,\\text{generation}^{-1}$). At a single locus with alleles $A$ and $a$, assume symmetric underdominance: genotypic fitnesses are $w_{AA}=1$, $w_{Aa}=1-s$, and $w_{aa}=1$, where $s \\in (0,1)$ is the selection coefficient against heterozygotes. Assume random mating, no genetic drift, and large population size.\n\nLet $p(x,t)$ denote the allele frequency of $A$ at position $x$ and time $t$. Using the standard diffusion approximation for dispersal and continuous-time selection, the allele-frequency dynamics may be modeled by a reaction-diffusion equation of the form\n$$\n\\frac{\\partial p}{\\partial t} \\;=\\; \\frac{\\sigma^{2}}{2}\\,\\frac{\\partial^{2}p}{\\partial x^{2}} \\;+\\; p(1-p)\\,\\Delta m(p),\n$$\nwhere $\\Delta m(p)$ is the difference in Malthusian fitness between alleles $A$ and $a$, expressed as a function of $p$ under the assumed genotype fitnesses. At equilibrium, a stationary cline $p(x)$ is established that connects $p(-\\infty)=0$ and $p(+\\infty)=1$.\n\nStarting from these assumptions and definitions, and without invoking any pre-given cline-width formulas, do the following:\n\n1. Derive the ordinary differential equation satisfied by the stationary cline $p(x)$, and solve it to obtain an explicit sigmoid form for $p(x)$.\n2. Define the cline width $w$ as $w := 1/\\left|p'(0)\\right|$, i.e., the inverse of the maximum slope at the cline center $x=0$ where $p(0)=\\tfrac{1}{2}$. Express $w$ in terms of $\\sigma^{2}$ and $s$, and then rearrange to obtain $s$ as a function of $w$ and $\\sigma^{2}$.\n3. An empirical study measures a cline width of $w = 24\\,\\text{km}$ and dispersal variance $\\sigma^{2} = 3\\,\\text{km}^{2}\\,\\text{generation}^{-1}$. Using your expression, compute the implied selection coefficient $s$. Round your answer to four significant figures and express it as a pure number with no units.\n4. Briefly enumerate the key biological and modeling assumptions required for the estimator you derived to be valid in this context.\n\nOnly the numerical value of $s$ is to be reported as the final answer, rounded as specified. All units mentioned above are for interpretation; the final reported $s$ should be unitless.", "solution": "The problem statement is scientifically grounded, well-posed, and contains all necessary information for a unique solution. It represents a standard and fundamental problem in mathematical evolutionary biology. The problem is therefore deemed valid.\n\nThe task is to analyze a reaction-diffusion model for allele frequency in a one-dimensional hybrid zone under symmetric underdominance. We are asked to derive the stationary cline profile, an expression for the cline width, use it to estimate the selection coefficient from empirical data, and list the underlying assumptions.\n\nFirst, we determine the selection term in the provided reaction-diffusion equation:\n$$\n\\frac{\\partial p}{\\partial t} = \\frac{\\sigma^{2}}{2}\\,\\frac{\\partial^{2}p}{\\partial x^{2}} + p(1-p)\\,\\Delta m(p)\n$$\nHere, $p$ is the frequency of allele $A$, $\\sigma^{2}$ is the dispersal variance, and $\\Delta m(p)$ is the difference in Malthusian fitnesses between alleles $A$ and $a$. The Wrightian fitnesses are given as $w_{AA}=1$, $w_{Aa}=1-s$, and $w_{aa}=1$. The Malthusian fitnesses $m$ are the natural logarithms of these, $m = \\ln(w)$. Using a first-order Taylor approximation for weak selection ($s \\ll 1$), we have $m_{AA} = \\ln(1) = 0$, $m_{aa} = \\ln(1) = 0$, and $m_{Aa} = \\ln(1-s) \\approx -s$.\n\nThe marginal Malthusian fitness of allele $A$ is $m_A = p \\cdot m_{AA} + (1-p) \\cdot m_{Aa} \\approx p(0) + (1-p)(-s) = -s(1-p)$.\nThe marginal Malthusian fitness of allele $a$ is $m_a = p \\cdot m_{Aa} + (1-p) \\cdot m_{aa} \\approx p(-s) + (1-p)(0) = -sp$.\nThe difference is $\\Delta m(p) = m_A - m_a \\approx -s(1-p) - (-sp) = s(2p-1)$.\nThe selection term is thus $s p(1-p)(2p-1)$.\n\n**1. Derivation and Solution of the Stationary Cline Equation**\n\nAt equilibrium, the allele frequency profile is stationary, so $\\frac{\\partial p}{\\partial t} = 0$. The partial differential equation becomes an ordinary differential equation (ODE) for the stationary cline $p(x)$:\n$$\n\\frac{\\sigma^{2}}{2}\\,\\frac{d^{2}p}{dx^{2}} + s p(1-p)(2p-1) = 0\n$$\nLet $p' = \\frac{dp}{dx}$. To solve this second-order nonlinear ODE, we multiply by $p'$ and integrate with respect to $x$:\n$$\n\\frac{\\sigma^{2}}{2} p' p'' = -s p(1-p)(2p-1) p'\n$$\nIntegrating both sides gives:\n$$\n\\int \\frac{\\sigma^{2}}{2} p' \\frac{dp'}{dx} dx = -s \\int (2p^2 - 3p + 1)p \\cdot p' dx\n$$\nBy changing the variable of integration to $p$ (since $dp = p' dx$), we get:\n$$\n\\frac{\\sigma^{2}}{2} \\int p' dp' = -s \\int (2p^3 - 3p^2 + p) dp\n$$\n$$\n\\frac{\\sigma^{2}}{2} \\frac{(p')^2}{2} = -s \\left(\\frac{1}{2}p^4 - p^3 + \\frac{1}{2}p^2 \\right) + C\n$$\n$$\n\\frac{\\sigma^{2}}{4} (p')^2 = -\\frac{s}{2} (p^4 - 2p^3 + p^2) + C = -\\frac{s}{2} p^2(p-1)^2 + C\n$$\nThe constant of integration $C$ is determined by the boundary conditions. At $x \\to \\pm\\infty$, the cline flattens, so $p' \\to 0$. Also, $p \\to 0$ or $p \\to 1$. In either case, the term $p^2(p-1)^2$ becomes $0$. Thus, $C=0$.\n$$\n\\frac{\\sigma^{2}}{4} (p')^2 = \\frac{s}{2} p^2(1-p)^2\n$$\nSolving for $p'$:\n$$\n(p')^2 = \\frac{2s}{\\sigma^2} p^2(1-p)^2 \\implies p' = \\pm \\sqrt{\\frac{2s}{\\sigma^2}} p(1-p)\n$$\nSince the cline connects $p(-\\infty)=0$ to $p(+\\infty)=1$, the slope must be positive, so we take the positive root:\n$$\n\\frac{dp}{dx} = \\sqrt{\\frac{2s}{\\sigma^2}} p(1-p)\n$$\nThis is a first-order separable ODE. We separate variables and integrate:\n$$\n\\int \\frac{dp}{p(1-p)} = \\int \\sqrt{\\frac{2s}{\\sigma^2}} dx\n$$\nUsing partial fraction decomposition $\\frac{1}{p(1-p)} = \\frac{1}{p} + \\frac{1}{1-p}$:\n$$\n\\int \\left(\\frac{1}{p} + \\frac{1}{1-p}\\right) dp = \\sqrt{\\frac{2s}{\\sigma^2}} x + C_1\n$$\n$$\n\\ln(p) - \\ln(1-p) = \\ln\\left(\\frac{p}{1-p}\\right) = \\sqrt{\\frac{2s}{\\sigma^2}} x + C_1\n$$\nWe use the condition that the cline is centered at $x=0$, where $p(0) = \\frac{1}{2}$.\n$$\n\\ln\\left(\\frac{1/2}{1-1/2}\\right) = \\ln(1) = 0 = \\sqrt{\\frac{2s}{\\sigma^2}}(0) + C_1 \\implies C_1 = 0\n$$\nThus, the logit-transformed frequency is linear in space:\n$$\n\\ln\\left(\\frac{p(x)}{1-p(x)}\\right) = \\sqrt{\\frac{2s}{\\sigma^2}} x\n$$\nSolving for $p(x)$ yields the explicit sigmoid form of the cline:\n$$\np(x) = \\frac{\\exp\\left(\\sqrt{\\frac{2s}{\\sigma^2}} x\\right)}{1 + \\exp\\left(\\sqrt{\\frac{2s}{\\sigma^2}} x\\right)} = \\frac{1}{1 + \\exp\\left(-\\sqrt{\\frac{2s}{\\sigma^2}} x\\right)}\n$$\n\n**2. Cline Width and Estimation of Selection Coefficient**\n\nThe cline width $w$ is defined as the inverse of the maximum slope, which occurs at the center $x=0$: $w = 1/|p'(0)|$. From our first-order ODE for $p'$, we have:\n$$\np'(x) = \\sqrt{\\frac{2s}{\\sigma^2}} p(x)(1-p(x))\n$$\nAt $x=0$, $p(0) = \\frac{1}{2}$, so the slope is:\n$$\np'(0) = \\sqrt{\\frac{2s}{\\sigma^2}} \\left(\\frac{1}{2}\\right)\\left(1-\\frac{1}{2}\\right) = \\frac{1}{4}\\sqrt{\\frac{2s}{\\sigma^2}}\n$$\nSince $s>0$ and $\\sigma^2>0$, $p'(0) > 0$, so $|p'(0)| = p'(0)$. The cline width is:\n$$\nw = \\frac{1}{p'(0)} = \\frac{4}{\\sqrt{\\frac{2s}{\\sigma^2}}} = 4\\sqrt{\\frac{\\sigma^2}{2s}} = \\frac{4\\sigma}{\\sqrt{2s}} = \\frac{2\\sqrt{2}\\sigma}{\\sqrt{s}} = \\sqrt{\\frac{8\\sigma^2}{s}}\n$$\nTo express the selection coefficient $s$ as a function of $w$ and $\\sigma^2$, we rearrange the formula:\n$$\nw^2 = \\frac{8\\sigma^2}{s} \\implies s = \\frac{8\\sigma^2}{w^2}\n$$\n\n**3. Numerical Computation of Selection Coefficient**\n\nGiven the empirical measurements $w = 24\\,\\text{km}$ and $\\sigma^2 = 3\\,\\text{km}^{2}\\,\\text{generation}^{-1}$, we compute $s$:\n$$\ns = \\frac{8 \\times 3}{24^2} = \\frac{24}{576} = \\frac{1}{24}\n$$\nAs a decimal rounded to four significant figures, this is:\n$$\ns \\approx 0.041666... \\approx 0.04167\n$$\n\n**4. Key Biological and Modeling Assumptions**\n\nThe validity of this estimation for $s$ depends on a series of critical assumptions inherent to the model:\n- **Genetic Architecture**: Selection acts on a single locus with two alleles. This locus is the primary determinant of the hybrid incompatibility. Effects of other loci (epistasis) are ignored.\n- **Selection Regime**: Selection is constant across space and time and takes the form of symmetric underdominance ($w_{AA}=w_{aa}  w_{Aa}$). There is no frequency- or density-dependent selection.\n- **Population and Spatial Structure**: The population inhabits a one-dimensional, homogeneous environment. Demography (population density) is uniform.\n- **Dispersal**: Individual movement is random, unbiased, and can be approximated by a diffusion process with a constant dispersal variance $\\sigma^2$. This implies that dispersal distances are typically short and follow a Gaussian distribution.\n- **Mating System**: Mating is random within any local neighborhood (panmixia).\n- **Evolutionary Dynamics**: The system is at equilibrium, resulting in a stationary (non-moving) cline. Other evolutionary forces, such as genetic drift (implying large local population size), mutation, and meiotic drive, are considered negligible.\n- **Model Simplifications**: The use of a continuous reaction-diffusion equation assumes that space, time, and allele frequencies are continuous variables, which is an approximation of the discrete nature of individuals, generations, and gene copies. It also implicitly assumes selection is weak enough for this continuous-time approximation to hold.", "answer": "$$\\boxed{0.04167}$$", "id": "2717953"}, {"introduction": "Modern studies often shift from geographic clines to \"genomic clines,\" where the ancestry of many different loci is analyzed across a collection of individuals with varying hybrid indices, $h$. This powerful approach allows us to screen the genome for loci that show unusual ancestry patterns, potentially indicating they are under selection. This exercise [@problem_id:2718001] delves into the statistical heart of this method, revealing how study design—specifically, the distribution of hybrid indices in your sample—critically affects your statistical power to detect these important outlier loci.", "problem": "In a hybrid zone, let the hybrid index $h \\in [0,1]$ denote the genome-wide proportion of ancestry from parental population $P_{1}$. For a focal locus with biallelic ancestry state $z \\in \\{0,1\\}$ (where $z=1$ indicates ancestry from $P_{1}$), consider the following genomic cline model that perturbs the neutral log-odds by a locus-specific shift and slope:\n$$\\operatorname{logit}\\left(p(h;\\alpha,\\beta)\\right) \\equiv \\ln\\!\\left(\\frac{p(h;\\alpha,\\beta)}{1 - p(h;\\alpha,\\beta)}\\right) \\;=\\; \\ln\\!\\left(\\frac{h}{1-h}\\right) \\;+\\; \\alpha \\;+\\; \\beta\\,x(h),$$\nwith $x(h) \\equiv 2h - 1$. This parameterization ensures the neutral expectation $p(h;0,0)=h$. Assume $z_{i} \\mid h_{i} \\sim \\mathrm{Bernoulli}\\!\\left(p(h_{i};\\alpha,\\beta)\\right)$ independently across individuals $i=1,\\dots,N$.\n\nFocus on inference for the slope parameter $\\beta$, with the intercept fixed at $\\alpha=0$ and the true value $\\beta=2$. You will analyze how the distribution of hybrid indices $h_{i}$ across sampled individuals affects the Fisher information for $\\beta$ and, consequently, the asymptotic standard error of its maximum likelihood estimator.\n\n1) Starting from the Bernoulli log-likelihood and the above link function, derive the expected Fisher information for $\\beta$ as a function of $\\{h_{i}\\}_{i=1}^{N}$ and $\\beta$.\n\n2) Consider two sampling designs for the hybrid indices, each with the same total sample size $N$, but differing in how individuals are distributed across five representative values $h \\in \\{0.1, 0.3, 0.5, 0.7, 0.9\\}$:\n- Design A (balanced): exactly $N/5$ individuals at each of $h=0.1, 0.3, 0.5, 0.7, 0.9$.\n- Design B (uneven; few intermediates): proportions across these same $h$ values are $0.4N$ at $h=0.1$, $0.05N$ at $h=0.3$, $0.1N$ at $h=0.5$, $0.05N$ at $h=0.7$, and $0.4N$ at $h=0.9$.\n\nUsing your expression from part (1) with $\\alpha=0$ and $\\beta=2$, compute the ratio of asymptotic standard errors,\n$$R \\equiv \\frac{\\mathrm{se}_{B}(\\hat{\\beta})}{\\mathrm{se}_{A}(\\hat{\\beta})},$$\nwhere $\\mathrm{se}_{D}(\\hat{\\beta})$ denotes the asymptotic standard error under design $D \\in \\{A,B\\}$. Round your final numeric answer for $R$ to four significant figures. The answer is dimensionless; report it as a pure number (no units).", "solution": "The problem requires the derivation of the expected Fisher information for a parameter in a genomic cline model and a subsequent comparison of two sampling designs based on the precision of the parameter estimate.\n\n**Part 1: Derivation of the Expected Fisher Information**\n\nThe model describes the probability of an allele having ancestry from population $P_1$ for an individual with hybrid index $h$. The probability, denoted $p(h;\\alpha,\\beta)$, is modeled via a logistic link function. We are given the parameterization for the log-odds (logit) of this probability:\n$$ \\operatorname{logit}(p) = \\ln\\left(\\frac{p}{1-p}\\right) = \\ln\\left(\\frac{h}{1-h}\\right) + \\alpha + \\beta x(h) $$\nwhere $x(h) = 2h - 1$. The analysis is focused on the parameter $\\beta$ with $\\alpha$ fixed at $0$. For an individual $i$, let $p_i = p(h_i; 0, \\beta)$ and $x_i = 2h_i - 1$. The model simplifies to:\n$$ \\eta_i \\equiv \\operatorname{logit}(p_i) = \\ln\\left(\\frac{h_i}{1-h_i}\\right) + \\beta x_i $$\nThe ancestry state $z_i$ for individual $i$ is a Bernoulli random variable, $z_i | h_i \\sim \\mathrm{Bernoulli}(p_i)$. The log-likelihood for a single observation $(z_i, h_i)$ is:\n$$ \\ell_i(\\beta) = z_i \\ln(p_i) + (1-z_i) \\ln(1-p_i) $$\nThis is a Generalized Linear Model (GLM) with a Bernoulli distribution and a logit link function. The Fisher information is derived from the second derivative of the log-likelihood function.\n\nFirst, we find the score function, which is the first derivative of the log-likelihood with respect to $\\beta$. Using the chain rule:\n$$ \\frac{\\partial \\ell_i}{\\partial \\beta} = \\frac{\\partial \\ell_i}{\\partial p_i} \\frac{\\partial p_i}{\\partial \\eta_i} \\frac{\\partial \\eta_i}{\\partial \\beta} $$\nThe components of this derivative are:\n1. $\\frac{\\partial \\ell_i}{\\partial p_i} = \\frac{z_i}{p_i} - \\frac{1-z_i}{1-p_i} = \\frac{z_i - p_i}{p_i(1-p_i)}$\n2. For the logistic function $p_i = (1 + \\exp(-\\eta_i))^{-1}$, the derivative is $\\frac{\\partial p_i}{\\partial \\eta_i} = p_i(1-p_i)$.\n3. From the model equation, $\\frac{\\partial \\eta_i}{\\partial \\beta} = x_i$.\n\nCombining these terms, the score function becomes:\n$$ \\frac{\\partial \\ell_i}{\\partial \\beta} = \\left(\\frac{z_i - p_i}{p_i(1-p_i)}\\right) [p_i(1-p_i)] (x_i) = (z_i - p_i)x_i $$\nNext, we compute the second derivative of the log-likelihood:\n$$ \\frac{\\partial^2 \\ell_i}{\\partial \\beta^2} = \\frac{\\partial}{\\partial \\beta} \\left[ (z_i - p_i)x_i \\right] = -x_i \\frac{\\partial p_i}{\\partial \\beta} $$\nWe again use the chain rule for $\\frac{\\partial p_i}{\\partial \\beta}$:\n$$ \\frac{\\partial p_i}{\\partial \\beta} = \\frac{\\partial p_i}{\\partial \\eta_i} \\frac{\\partial \\eta_i}{\\partial \\beta} = p_i(1-p_i)x_i $$\nSubstituting this back into the second derivative expression yields:\n$$ \\frac{\\partial^2 \\ell_i}{\\partial \\beta^2} = -x_i [p_i(1-p_i)x_i] = -x_i^2 p_i(1-p_i) $$\nThe expected Fisher information for a single observation $i$, denoted $I_i(\\beta)$, is the negative of the expectation of the second derivative. The expectation is taken with respect to the distribution of $z_i$.\n$$ I_i(\\beta) = -E_{z_i}\\left[ \\frac{\\partial^2 \\ell_i}{\\partial \\beta^2} \\right] $$\nSince the expression for the second derivative does not depend on the random variable $z_i$, its expectation is simply itself.\n$$ I_i(\\beta) = - \\left[-x_i^2 p_i(1-p_i)\\right] = x_i^2 p_i(1-p_i) $$\nFor a sample of $N$ independent individuals, the total expected Fisher information is the sum of the individual contributions:\n$$ I(\\beta) = \\sum_{i=1}^{N} I_i(\\beta) = \\sum_{i=1}^{N} x_i^2 p_i(1-p_i) $$\nSubstituting $x_i = 2h_i - 1$ and recalling that $p_i = p(h_i; 0, \\beta)$, we obtain the final expression for the expected Fisher information as a function of the hybrid indices $\\{h_i\\}_{i=1}^N$ and the parameter $\\beta$:\n$$ I(\\beta) = \\sum_{i=1}^{N} (2h_i - 1)^2 p(h_i; 0, \\beta)(1-p(h_i; 0, \\beta)) $$\n\n**Part 2: Ratio of Asymptotic Standard Errors**\n\nThe asymptotic standard error of the maximum likelihood estimator $\\hat{\\beta}$ is inversely related to the square root of the Fisher information: $\\mathrm{se}(\\hat{\\beta}) = [I(\\beta)]^{-1/2}$. We are asked to compute the ratio $R = \\mathrm{se}_{B}(\\hat{\\beta}) / \\mathrm{se}_{A}(\\hat{\\beta})$ for two sampling designs, A and B.\n\n$$ R = \\frac{[I_B(\\beta)]^{-1/2}}{[I_A(\\beta)]^{-1/2}} = \\sqrt{\\frac{I_A(\\beta)}{I_B(\\beta)}} $$\nWe must evaluate this ratio at the true parameter value $\\beta=2$. First, we calculate the information weight, $w(h, \\beta) = (2h - 1)^2 p(h; \\alpha=0, \\beta)(1 - p(h; \\alpha=0, \\beta))$, for each specified value of $h \\in \\{0.1, 0.3, 0.5, 0.7, 0.9\\}$.\n\nLet $\\beta=2$. For each $h_j$:\n1. $x_j = 2h_j-1$\n2. $\\eta_j = \\ln\\left(\\frac{h_j}{1-h_j}\\right) + 2x_j$\n3. $p_j = (1 + \\exp(-\\eta_j))^{-1}$\n4. $w_j = x_j^2 p_j(1-p_j)$\n\nThe calculations are as follows:\n- For $h_1 = 0.1$:\n  $x_1 = -0.8$, $\\eta_1 = \\ln(1/9) - 1.6 \\approx -3.7972$, $p_1 \\approx 0.02194$, $p_1(1-p_1) \\approx 0.02146$.\n  $w_1 = (-0.8)^2(0.02146) = 0.64 \\times 0.02146 \\approx 0.013734$.\n- For $h_2 = 0.3$:\n  $x_2 = -0.4$, $\\eta_2 = \\ln(3/7) - 0.8 \\approx -1.6473$, $p_2 \\approx 0.16148$, $p_2(1-p_2) \\approx 0.13541$.\n  $w_2 = (-0.4)^2(0.13541) = 0.16 \\times 0.13541 \\approx 0.021666$.\n- For $h_3 = 0.5$:\n  $x_3 = 0$, $\\eta_3 = \\ln(1) + 0 = 0$, $p_3 = 0.5$, $p_3(1-p_3) = 0.25$.\n  $w_3 = (0)^2(0.25) = 0$.\n- For $h_4 = 0.7$: By symmetry, $x_4 = 0.4 = -x_2$, $\\eta_4 = -\\eta_2$, $p_4 = 1-p_2$, so $p_4(1-p_4) = p_2(1-p_2)$. Thus, $w_4 = x_4^2 p_4(1-p_4) = (-x_2)^2 p_2(1-p_2) = w_2 \\approx 0.021666$.\n- For $h_5 = 0.9$: By symmetry, $x_5 = 0.8 = -x_1$, so $w_5 = w_1 \\approx 0.013734$.\n\nThe total informations for the two designs are sums of these weights, scaled by the sample size $N$ and the sampling proportions. The factor $N$ will cancel in the ratio.\nLet $I_A' = I_A/N$ and $I_B' = I_B/N$ be the average information per individual.\n\nFor Design A (balanced), each $h_j$ has proportion $1/5 = 0.2$.\n$$ I_A' = 0.2(w_1 + w_2 + w_3 + w_4 + w_5) = 0.2(2w_1 + 2w_2) = 0.4(w_1 + w_2) $$\n$$ I_A' = 0.4(0.013734 + 0.021666) = 0.4(0.035400) = 0.014160 $$\n\nFor Design B (uneven), the proportions are $\\{0.4, 0.05, 0.1, 0.05, 0.4\\}$.\n$$ I_B' = 0.4w_1 + 0.05w_2 + 0.1w_3 + 0.05w_4 + 0.4w_5 $$\n$$ I_B' = (0.4+0.4)w_1 + (0.05+0.05)w_2 + 0.1w_3 = 0.8w_1 + 0.1w_2 $$\n$$ I_B' = 0.8(0.013734) + 0.1(0.021666) = 0.0109872 + 0.0021666 = 0.0131538 $$\n\nNow we can compute the ratio of information and then the ratio of standard errors.\n$$ \\frac{I_A}{I_B} = \\frac{I_A'}{I_B'} = \\frac{0.014160}{0.0131538} \\approx 1.07650 $$\nThe ratio of standard errors is the square root of this value:\n$$ R = \\sqrt{\\frac{I_A}{I_B}} = \\sqrt{1.07650} \\approx 1.037545 $$\nRounding to four significant figures gives $1.038$. This indicates that the asymptotic standard error of $\\hat{\\beta}$ is approximately $3.8\\%$ larger under the uneven sampling design (B) compared to the balanced design (A), signifying lower statistical precision for Design B.", "answer": "$$\\boxed{1.038}$$", "id": "2718001"}]}