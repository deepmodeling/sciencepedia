{"hands_on_practices": [{"introduction": "The self-reinforcing nature of Fisherian runaway hinges on the genetic correlation between a male trait and the female preference for it. This exercise unpacks this crucial element by first asking you to demonstrate, using the multivariate breeder’s equation, why this covariance is essential for a correlated response in preference [@problem_id:2713639]. You will then quantitatively model how assortative mating builds this covariance from scratch over several generations, providing a dynamic look at the very foundation of the runaway process.", "problem": "Consider a classic Fisherian runaway framework with two sex-limited quantitative characters: a male display trait $z$ expressed only in males and a female preference $p$ expressed only in females. Let the additive genetic variance-covariance matrix be\n$$\n\\mathbf{G} \\equiv \n\\begin{pmatrix}\nG_{zz}  G_{zp} \\\\\nG_{pz}  G_{pp}\n\\end{pmatrix},\n$$\nwith $G_{zp} = G_{pz}$ representing the additive genetic covariance arising from Linkage Disequilibrium (LD) between loci underlying $z$ and $p$. Assume weak selection and many unlinked loci so that the multivariate breeder’s equation holds in its standard form for the mean vector $\\boldsymbol{\\bar{g}} \\equiv (\\bar{z}, \\bar{p})^{\\top}$,\n$$\n\\Delta \\boldsymbol{\\bar{g}} = \\mathbf{G} \\, \\boldsymbol{\\beta},\n$$\nwhere $\\boldsymbol{\\beta} \\equiv (\\beta_{z}, \\beta_{p})^{\\top}$ is the vector of directional selection gradients, with $\\beta_{p} = 0$ (no direct selection on preference in the current generation) and $\\beta_{z}$ arbitrary but fixed by viability and sexual selection on $z$.\n\nPart (i): Using only the breeder’s equation and the definition of correlated response, show explicitly how setting $G_{zp} = 0$ eliminates the immediate (one-generation) correlated response of $p$ to selection on $z$ when $\\beta_{p} = 0$.\n\nPart (ii): Now incorporate mate choice that creates phenotypic assortment between $z$ and $p$. Assume a weak-preference mating kernel such that, per generation, assortative mating of strength $a$ induces new cross-trait LD that contributes a source term $a \\, V_{z} V_{p}$ to the additive genetic covariance $G_{zp}$, where $V_{z} \\equiv G_{zz}$ and $V_{p} \\equiv G_{pp}$ denote the additive genetic variances of $z$ and $p$ (treated as constants over the short time considered). Recombination and segregation erode cross-trait LD at a per-generation proportional rate $\\rho$. Under these standard assumptions for many unlinked loci and weak assortment, the expected per-generation recursion for the covariance is\n$$\nG_{zp}(t+1) \\;=\\; (1 - \\rho)\\, G_{zp}(t) \\;+\\; a \\, V_{z} V_{p},\n$$\nwith initial condition $G_{zp}(0) = 0$.\n\nTake the parameter values $V_{z} = 1$, $V_{p} = 1$, $\\rho = \\tfrac{1}{2}$, and $a = \\tfrac{1}{75}$. Compute the smallest integer number of generations $t$ such that $G_{zp}(t) \\geq 0.02$. Report your answer as an integer count of generations. Do not include units in your final boxed answer. No rounding is required beyond identifying the smallest integer satisfying the inequality.", "solution": "The problem presented is a standard exercise in quantitative evolutionary genetics, specifically concerning the dynamics of sexual selection via the Fisherian \"runaway\" process. The framework is based on the multivariate breeder's equation and a recurrence relation for genetic covariance, both of which are cornerstones of the theory developed by Lande and Kirkpatrick. The problem is scientifically grounded, well-posed, and contains all necessary information for a unique solution. Therefore, it is deemed valid, and we proceed with the analysis.\n\nThe problem is divided into two parts. We will address them in sequence.\n\nPart (i): Demonstration of the role of genetic covariance in correlated response.\n\nThe evolutionary change in the vector of mean phenotypes, $\\boldsymbol{\\bar{g}} = (\\bar{z}, \\bar{p})^{\\top}$, under selection is given by the multivariate breeder's equation:\n$$\n\\Delta \\boldsymbol{\\bar{g}} = \\mathbf{G} \\, \\boldsymbol{\\beta}\n$$\nHere, $\\Delta \\boldsymbol{\\bar{g}}$ is the vector of changes in the mean trait values over one generation, $\\mathbf{G}$ is the additive genetic variance-covariance matrix, and $\\boldsymbol{\\beta}$ is the vector of directional selection gradients.\n\nWriting this equation in its explicit component form, we have:\n$$\n\\begin{pmatrix} \\Delta \\bar{z} \\\\ \\Delta \\bar{p} \\end{pmatrix} = \\begin{pmatrix} G_{zz}  G_{zp} \\\\ G_{pz}  G_{pp} \\end{pmatrix} \\begin{pmatrix} \\beta_{z} \\\\ \\beta_{p} \\end{pmatrix}\n$$\nThis matrix equation yields two scalar equations, one for the change in each trait mean:\n$$\n\\Delta \\bar{z} = G_{zz} \\beta_{z} + G_{zp} \\beta_{p}\n$$\n$$\n\\Delta \\bar{p} = G_{pz} \\beta_{z} + G_{pp} \\beta_{p}\n$$\nWe are interested in the response of the female preference, $\\bar{p}$. The change, $\\Delta \\bar{p}$, is composed of two parts. The term $G_{pp} \\beta_{p}$ represents the direct response to selection acting on the preference trait itself. The term $G_{pz} \\beta_{z}$ represents the indirect, or correlated, response of the preference trait due to selection acting on the male display trait, $z$. This correlated response is mediated by the genetic covariance between the two traits, $G_{pz}$.\n\nThe problem specifies two conditions:\n$1$. There is no direct selection on female preference, which means $\\beta_{p} = 0$.\n$2$. There is no genetic covariance between the male trait and female preference, which means $G_{zp} = 0$. By the symmetry of the covariance matrix, this also implies $G_{pz} = 0$.\n\nSubstituting these conditions into the equation for $\\Delta \\bar{p}$:\n$$\n\\Delta \\bar{p} = (0) \\cdot \\beta_{z} + G_{pp} \\cdot (0) = 0\n$$\nThe correlated response component, $G_{pz} \\beta_{z}$, is explicitly zero because $G_{pz}=0$. Thus, in the absence of genetic covariance, even if there is selection on the male trait ($\\beta_z \\neq 0$), there can be no immediate correlated evolutionary response in the female preference. This demonstrates that the genetic covariance $G_{zp}$ is essential for the preference to evolve as a by-product of selection on the display trait, which is the foundational mechanism of Fisherian runaway.\n\nPart (ii): Calculation of the time required to build sufficient genetic covariance.\n\nIn this part, we analyze the dynamics of the genetic covariance $G_{zp}$ over time. The covariance builds up due to assortative mating and decays due to recombination. The dynamics are described by the first-order linear recurrence relation:\n$$\nG_{zp}(t+1) = (1 - \\rho)\\, G_{zp}(t) + a \\, V_{z} V_{p}\n$$\nwith the initial condition $G_{zp}(0) = 0$.\n\nWe are given the following parameter values:\n- Additive genetic variance of $z$: $V_{z} = G_{zz} = 1$\n- Additive genetic variance of $p$: $V_{p} = G_{pp} = 1$\n- Recombination rate: $\\rho = \\frac{1}{2}$\n- Strength of assortative mating: $a = \\frac{1}{75}$\n\nSubstituting these values into the recurrence relation:\n$$\nG_{zp}(t+1) = \\left(1 - \\frac{1}{2}\\right) G_{zp}(t) + \\left(\\frac{1}{75}\\right) \\cdot (1) \\cdot (1)\n$$\n$$\nG_{zp}(t+1) = \\frac{1}{2} G_{zp}(t) + \\frac{1}{75}\n$$\nThis is a standard linear non-homogeneous recurrence relation. The solution can be found by determining the fixed point (equilibrium) and solving for the transient dynamics. The fixed point, $G_{zp}^*$, is found by setting $G_{zp}(t+1) = G_{zp}(t) = G_{zp}^*$:\n$$\nG_{zp}^* = \\frac{1}{2} G_{zp}^* + \\frac{1}{75} \\implies \\frac{1}{2} G_{zp}^* = \\frac{1}{75} \\implies G_{zp}^* = \\frac{2}{75}\n$$\nThe general solution to the recurrence is of the form $G_{zp}(t) = G_{zp}^* + C \\cdot (1-\\rho)^t$, where $C$ is a constant determined by the initial condition.\n$$\nG_{zp}(t) = \\frac{2}{75} + C \\left(\\frac{1}{2}\\right)^t\n$$\nUsing the initial condition $G_{zp}(0) = 0$:\n$$\nG_{zp}(0) = 0 = \\frac{2}{75} + C \\left(\\frac{1}{2}\\right)^0 = \\frac{2}{75} + C\n$$\nThis gives $C = -\\frac{2}{75}$.\nTherefore, the explicit solution for the covariance at generation $t$ is:\n$$\nG_{zp}(t) = \\frac{2}{75} - \\frac{2}{75} \\left(\\frac{1}{2}\\right)^t = \\frac{2}{75} \\left(1 - \\left(\\frac{1}{2}\\right)^t\\right)\n$$\nThe problem requires finding the smallest integer number of generations $t$ such that $G_{zp}(t) \\geq 0.02$. We first convert the decimal to a fraction for precision: $0.02 = \\frac{2}{100} = \\frac{1}{50}$. The inequality is:\n$$\n\\frac{2}{75} \\left(1 - \\left(\\frac{1}{2}\\right)^t\\right) \\geq \\frac{1}{50}\n$$\nWe solve this inequality for $t$:\n$$\n1 - \\left(\\frac{1}{2}\\right)^t \\geq \\frac{1}{50} \\cdot \\frac{75}{2}\n$$\n$$\n1 - \\left(\\frac{1}{2}\\right)^t \\geq \\frac{75}{100} = \\frac{3}{4}\n$$\nRearranging the terms to isolate the exponential:\n$$\n1 - \\frac{3}{4} \\geq \\left(\\frac{1}{2}\\right)^t\n$$\n$$\n\\frac{1}{4} \\geq \\left(\\frac{1}{2}\\right)^t\n$$\nWe can write $\\frac{1}{4}$ as $\\left(\\frac{1}{2}\\right)^2$:\n$$\n\\left(\\frac{1}{2}\\right)^2 \\geq \\left(\\frac{1}{2}\\right)^t\n$$\nSince the base of the exponent, $\\frac{1}{2}$, is between $0$ and $1$, the exponential function $f(x) = (\\frac{1}{2})^x$ is a decreasing function. Therefore, to satisfy the inequality, the exponents must have the opposite relationship:\n$$\n2 \\leq t\n$$\nThe condition is that the number of generations $t$ must be greater than or equal to $2$. The smallest integer value for $t$ that satisfies this condition is $t=2$.\n\nLet us verify this result.\nAt $t=1$: $G_{zp}(1) = \\frac{2}{75} (1 - \\frac{1}{2}) = \\frac{1}{75} \\approx 0.0133$. This is less than $0.02$.\nAt $t=2$: $G_{zp}(2) = \\frac{2}{75} (1 - \\frac{1}{4}) = \\frac{2}{75} \\cdot \\frac{3}{4} = \\frac{6}{300} = \\frac{1}{50} = 0.02$.\nThe condition $G_{zp}(2) \\geq 0.02$ is met exactly. Thus, the smallest integer number of generations is $2$.", "answer": "$$\n\\boxed{2}\n$$", "id": "2713639"}, {"introduction": "Once a genetic link between trait and preference is established, will runaway selection inevitably occur? This practice delves into the formal stability analysis used to answer this question. Using a discrete-time quantitative genetics model, you will calculate the eigenvalues of the system's Jacobian matrix to predict whether the coevolutionary dynamic will converge to a stable equilibrium or diverge exponentially in a classic runaway fashion [@problem_id:2713681].", "problem": "In a Fisherian runaway selection scenario with two evolving quantitative traits—a male display trait $z$ and a female mating preference $p$—assume the standard quantitative genetic approximation for the per-generation change in mean traits, $\\Delta \\boldsymbol{x} = \\mathbf{G}\\,\\boldsymbol{\\beta}(\\boldsymbol{x})$, where $\\boldsymbol{x} = (z, p)^{\\top}$, $\\mathbf{G}$ is the additive genetic variance-covariance matrix, and $\\boldsymbol{\\beta}(\\boldsymbol{x})$ is the vector of selection gradients (the gradient of mean log fitness with respect to the mean traits). Near the origin $\\boldsymbol{x} = \\boldsymbol{0}$, assume weak selection and additive effects so that $\\boldsymbol{\\beta}(\\boldsymbol{x})$ can be linearized as $\\boldsymbol{\\beta}(\\boldsymbol{x}) \\approx \\mathbf{B}\\,\\boldsymbol{x}$.\n\nAssume that natural selection imposes Gaussian stabilizing selection of curvature $c$ on each trait around the origin, and mating preferences impose linear sexual selection coupling the traits with strength $a$. Under these assumptions, the local selection-gradient matrix takes the form\n$$\n\\mathbf{B} \\;=\\; \\begin{pmatrix} -c  a \\\\ a  -c \\end{pmatrix}.\n$$\nThe discrete-time dynamical system for the mean traits is then\n$$\n\\boldsymbol{x}_{t+1} \\;=\\; \\boldsymbol{x}_{t} \\;+\\; \\mathbf{G}\\,\\mathbf{B}\\,\\boldsymbol{x}_{t},\n$$\nso the Jacobian matrix of the linearized recursion at the origin is\n$$\n\\mathbf{A} \\;=\\; \\mathbf{I} \\;+\\; \\mathbf{G}\\,\\mathbf{B}.\n$$\n\nGiven\n$$\n\\mathbf{G} \\;=\\; \\begin{pmatrix} 0.2  0 \\\\ 0  0.1 \\end{pmatrix}, \\qquad a \\;=\\; 1.2, \\qquad c \\;=\\; 0.1,\n$$\ncompute the eigenvalues of $\\mathbf{A}$ and determine whether the origin is locally unstable (runaway divergence) or locally stable. State your final answer as the two eigenvalues of $\\mathbf{A}$ written as a single row matrix using the $\\mathrm{pmatrix}$ environment, rounded to four significant figures. No units are required.", "solution": "The fundamental base is the standard quantitative genetic recursion for the mean vector of traits, $\\Delta \\boldsymbol{x} = \\mathbf{G}\\,\\boldsymbol{\\beta}(\\boldsymbol{x})$, combined with a local linearization of the selection gradient near the focal point. Under Gaussian stabilizing natural selection on each trait with curvature $c$ about the origin, the natural selection gradient on each trait is approximately $-c$ times the trait’s mean deviation. Under linear mate choice with strength $a$, the sexual selection gradients couple the traits so that the selection gradient on the male trait $z$ increases linearly with the female preference $p$ and, symmetrically, the selection gradient on the preference $p$ increases linearly with the male trait $z$. Therefore, near $\\boldsymbol{x}=\\boldsymbol{0}$ one has\n$$\n\\boldsymbol{\\beta}(\\boldsymbol{x}) \\;\\approx\\; \\begin{pmatrix} -c  a \\\\ a  -c \\end{pmatrix} \\boldsymbol{x} \\;=\\; \\mathbf{B}\\,\\boldsymbol{x}.\n$$\nThe discrete-time recursion is\n$$\n\\boldsymbol{x}_{t+1} \\;=\\; \\boldsymbol{x}_{t} \\;+\\; \\mathbf{G}\\,\\mathbf{B}\\,\\boldsymbol{x}_{t},\n$$\nso the Jacobian at the origin is\n$$\n\\mathbf{A} \\;=\\; \\mathbf{I} \\;+\\; \\mathbf{G}\\,\\mathbf{B}.\n$$\nLocal stability in a discrete-time system is determined by the eigenvalues of $\\mathbf{A}$: if all eigenvalues have absolute value less than $1$, the fixed point is locally stable; if any eigenvalue has absolute value greater than $1$, the fixed point is locally unstable (consistent with runaway divergence in this context).\n\nWith the given parameters,\n$$\n\\mathbf{G} \\;=\\; \\begin{pmatrix} 0.2  0 \\\\ 0  0.1 \\end{pmatrix},\n\\qquad\n\\mathbf{B} \\;=\\; \\begin{pmatrix} -c  a \\\\ a  -c \\end{pmatrix}\n\\;=\\;\n\\begin{pmatrix} -0.1  1.2 \\\\ 1.2  -0.1 \\end{pmatrix}.\n$$\nCompute $\\mathbf{G}\\mathbf{B}$:\n$$\n\\mathbf{G}\\mathbf{B}\n\\;=\\;\n\\begin{pmatrix} 0.2  0 \\\\ 0  0.1 \\end{pmatrix}\n\\begin{pmatrix} -0.1  1.2 \\\\ 1.2  -0.1 \\end{pmatrix}\n\\;=\\;\n\\begin{pmatrix}\n0.2(-0.1) + 0(1.2)  0.2(1.2) + 0(-0.1) \\\\\n0(-0.1) + 0.1(1.2)  0(1.2) + 0.1(-0.1)\n\\end{pmatrix}\n\\;=\\;\n\\begin{pmatrix} -0.02  0.24 \\\\ 0.12  -0.01 \\end{pmatrix}.\n$$\nTherefore,\n$$\n\\mathbf{A} \\;=\\; \\mathbf{I} \\;+\\; \\mathbf{G}\\mathbf{B}\n\\;=\\;\n\\begin{pmatrix} 1  0 \\\\ 0  1 \\end{pmatrix}\n\\;+\\;\n\\begin{pmatrix} -0.02  0.24 \\\\ 0.12  -0.01 \\end{pmatrix}\n\\;=\\;\n\\begin{pmatrix} 0.98  0.24 \\\\ 0.12  0.99 \\end{pmatrix}.\n$$\nThe characteristic polynomial of $\\mathbf{A}$ is\n$$\n\\chi(\\lambda) \\;=\\; \\det\\!\\left(\\mathbf{A}-\\lambda \\mathbf{I}\\right)\n\\;=\\;\n(0.98-\\lambda)(0.99-\\lambda) - (0.24)(0.12).\n$$\nCompute the terms:\n$$\n(0.98-\\lambda)(0.99-\\lambda) \\;=\\; 0.9702 - 1.97\\,\\lambda + \\lambda^{2}, \\qquad (0.24)(0.12) \\;=\\; 0.0288,\n$$\nso\n$$\n\\chi(\\lambda) \\;=\\; \\lambda^{2} - 1.97\\,\\lambda + (0.9702 - 0.0288)\n\\;=\\;\n\\lambda^{2} - 1.97\\,\\lambda + 0.9414.\n$$\nThe eigenvalues solve\n$$\n\\lambda \\;=\\; \\frac{1.97 \\pm \\sqrt{(1.97)^{2} - 4(0.9414)}}{2}\n\\;=\\;\n\\frac{1.97 \\pm \\sqrt{3.8809 - 3.7656}}{2}\n\\;=\\;\n\\frac{1.97 \\pm \\sqrt{0.1153}}{2}.\n$$\nEvaluating the square root,\n$$\n\\sqrt{0.1153} \\;\\approx\\; 0.3396,\n$$\nso the two eigenvalues are\n$$\n\\lambda_{1} \\;\\approx\\; \\frac{1.97 + 0.3396}{2} \\;\\approx\\; 1.1548,\n\\qquad\n\\lambda_{2} \\;\\approx\\; \\frac{1.97 - 0.3396}{2} \\;\\approx\\; 0.8152.\n$$\nRounded to four significant figures, the eigenvalues are $1.155$ and $0.8152$.\n\nInterpretation: since one eigenvalue satisfies $|\\lambda_{1}| \\approx 1.155  1$, the fixed point at the origin is locally unstable in discrete time. This indicates Fisherian runaway divergence under the given parameter values.\n\nTherefore, the requested eigenvalues (rounded to four significant figures) are as computed below.", "answer": "$$\\boxed{\\begin{pmatrix}1.155  0.8152\\end{pmatrix}}$$", "id": "2713681"}, {"introduction": "Theoretical predictions from stability analysis gain power when we can see them play out in a dynamic simulation. This final practice challenges you to bridge theory and computation by implementing a forward-time simulation of the continuous-time Lande model for coevolution [@problem_id:2713675]. By comparing the results of your simulation to the predictions derived from an eigenvalue analysis, you will gain a more tangible and intuitive understanding of what \"instability\" means in an evolutionary context.", "problem": "Consider the Lande quantitative genetics model for the coevolution of a male trait and a female preference. Let the vector of population means be $\\mathbf{m}(t) = \\begin{bmatrix} z(t) \\\\ p(t) \\end{bmatrix}$, where $z$ is the mean male trait and $p$ is the mean female preference. The fundamental base is the Lande equation, which states that the rate of change of the means equals the additive genetic variance-covariance matrix times the selection gradient: \n$$\n\\frac{d \\mathbf{m}}{dt} = \\mathbf{G}\\,\\boldsymbol{\\beta}(\\mathbf{m}) .\n$$\nNear an equilibrium at $\\mathbf{m} = \\mathbf{0}$, linearize the selection gradient as $\\boldsymbol{\\beta}(\\mathbf{m}) = \\mathbf{S}\\,\\mathbf{m}$, where the matrix $\\mathbf{S}$ captures stabilizing natural selection and Fisherian sexual selection via two parameters $c$ and $a$:\n$$\n\\mathbf{S} = \\begin{bmatrix} -c  a \\\\ a  -c \\end{bmatrix} ,\n$$\nwith $c  0$ representing the strength (curvature) of stabilizing natural selection and $a \\ge 0$ representing the strength of female preference generating sexual selection on the male trait (and reciprocal indirect selection on the preference). The additive genetic variance-covariance matrix $\\mathbf{G}$ is assumed symmetric positive definite.\n\nThus the linearized dynamics are given by the linear Ordinary Differential Equation (ODE):\n$$\n\\frac{d \\mathbf{m}}{dt} = \\mathbf{J}\\,\\mathbf{m}, \\quad \\text{with} \\quad \\mathbf{J} = \\mathbf{G}\\,\\mathbf{S} .\n$$\n\nTask: Write a complete program that, for each parameter set in the test suite, does all of the following:\n- Implements a forward-time simulation of the ODE using the explicit Euler scheme with step size $\\Delta t$:\n$$\n\\mathbf{m}_{t+\\Delta t} = \\mathbf{m}_t + \\Delta t\\,\\mathbf{J}\\,\\mathbf{m}_t,\n$$\nstarting from initial condition $\\mathbf{m}(0) = \\mathbf{m}_0$, for a total duration $T$.\n- Detects Fisherian runaway in two distinct ways:\n  1. Eigenvalue-based prediction: compute the eigenvalues $\\{\\lambda_i\\}$ of $\\mathbf{J}$. Declare an eigenvalue-based runaway prediction if $\\max_i \\mathrm{Re}(\\lambda_i)  0$. Otherwise, declare no eigenvalue-based runaway prediction.\n  2. Trajectory-norm monitoring: compute the Euclidean norm $\\|\\mathbf{m}(t)\\|_2$ along the simulated trajectory. Declare a norm-based detected runaway if both conditions hold: \n     - The norm crosses a detection threshold $L$ at some time during the simulation.\n     - The average slope of $\\log\\|\\mathbf{m}(t)\\|_2$ over the last window of duration $W$ is positive and strictly greater than a small tolerance $\\varepsilon$. Formally, if $t_k$ are the recorded times in the final window and $y_k = \\log\\|\\mathbf{m}(t_k)\\|_2$, compute the least-squares slope $\\hat{s}$ of $y_k$ versus $t_k$; declare a norm-based detected runaway if $\\hat{s}  \\varepsilon$ and the threshold $L$ was crossed at least once.\n\nAdditional implementation requirements:\n- Use $\\Delta t = 0.01$ (in arbitrary time units), $T = 200.0$, $\\mathbf{m}_0 = \\begin{bmatrix} 0.01 \\\\ 0.01 \\end{bmatrix}$, $L = 1.0$, $W = 10.0$, and $\\varepsilon = 10^{-4}$ for every test case.\n- For numerical stability, you may terminate the simulation early once $\\|\\mathbf{m}(t)\\|_2$ exceeds $10^6$; if early termination occurs, still evaluate the slope criterion over the last available window.\n- All matrices and vectors must be handled in a mathematically consistent way. Angles are not involved. No physical units are required.\n\nTest suite:\n- Case $1$: $a = 0.5$, $c = 1.0$, $\\mathbf{G} = \\begin{bmatrix} 0.2  0.05 \\\\ 0.05  0.3 \\end{bmatrix}$.\n- Case $2$: $a = 1.2$, $c = 0.5$, $\\mathbf{G} = \\begin{bmatrix} 1.0  0.0 \\\\ 0.0  1.0 \\end{bmatrix}$.\n- Case $3$: $a = 1.0$, $c = 1.0$, $\\mathbf{G} = \\begin{bmatrix} 1.0  0.0 \\\\ 0.0  1.0 \\end{bmatrix}$.\n- Case $4$: $a = 1.5$, $c = 1.0$, $\\mathbf{G} = \\begin{bmatrix} 0.001  0.0 \\\\ 0.0  0.001 \\end{bmatrix}$.\n\nFor each test case, your program must compute:\n- A boolean indicating the eigenvalue-based runaway prediction (true if $\\max_i \\mathrm{Re}(\\lambda_i)  0$, false otherwise).\n- A boolean indicating the norm-based detected runaway from the simulated trajectory as defined above.\n- The maximum real-part eigenvalue $\\max_i \\mathrm{Re}(\\lambda_i)$ as a floating-point number.\n\nFinal output format:\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets. Each element of this list corresponds to one test case and must itself be a list of the form $[\\text{eig\\_runaway},\\ \\text{sim\\_runaway},\\ \\text{max\\_real\\_eig}]$, where the first two entries are booleans and the third is a floating-point number. For example, a valid overall output would look like \n$[[\\text{True},\\text{False},0.123456],[\\text{False},\\text{False},-0.543210],\\ldots]$.", "solution": "The problem as stated is valid. It is a well-posed, scientifically grounded exercise in the stability analysis of a classical model in evolutionary quantitative genetics. The task requires a combination of analytical calculation and numerical simulation, which are standard methods in this field. We will proceed with the solution.\n\nThe problem centers on the linearized dynamics of a male trait $z$ and a female preference $p$, whose population means are captured by the vector $\\mathbf{m}(t) = \\begin{bmatrix} z(t) \\\\ p(t) \\end{bmatrix}$. The governing equation is a linear system of ordinary differential equations (ODEs):\n$$\n\\frac{d \\mathbf{m}}{dt} = \\mathbf{J}\\,\\mathbf{m}\n$$\nwhere the Jacobian matrix $\\mathbf{J}$ is the product of the additive genetic variance-covariance matrix $\\mathbf{G}$ and the selection gradient matrix $\\mathbf{S}$:\n$$\n\\mathbf{J} = \\mathbf{G}\\,\\mathbf{S} = \\begin{bmatrix} G_{zz}  G_{zp} \\\\ G_{zp}  G_{pp} \\end{bmatrix} \\begin{bmatrix} -c  a \\\\ a  -c \\end{bmatrix} = \\begin{bmatrix} -c G_{zz} + a G_{zp}  a G_{zz} - c G_{zp} \\\\ -c G_{zp} + a G_{pp}  a G_{zp} - c G_{pp} \\end{bmatrix}\n$$\nHere, $c  0$ represents stabilizing natural selection on both the trait and the preference, while $a \\ge 0$ represents the strength of sexual selection. The matrix $\\mathbf{G}$ is symmetric and positive definite.\n\nThe solution to this problem is twofold: an analytical prediction based on system stability, and a numerical verification based on trajectory simulation.\n\n**1. Eigenvalue-Based Prediction of Runaway**\n\nThe equilibrium point at $\\mathbf{m} = \\mathbf{0}$ is stable if all trajectories starting near it converge to it. It is unstable if at least one trajectory moves away from it. For a linear system, this behavior is entirely determined by the eigenvalues $\\{\\lambda_i\\}$ of the Jacobian matrix $\\mathbf{J}$.\n\nThe general solution is a linear combination of terms of the form $\\mathbf{v}_i e^{\\lambda_i t}$, where $\\mathbf{v}_i$ is the eigenvector corresponding to eigenvalue $\\lambda_i$.\n- If all eigenvalues have negative real parts, i.e., $\\mathrm{Re}(\\lambda_i)  0$ for all $i$, all terms decay to zero, and the system is stable.\n- If any eigenvalue has a positive real part, $\\mathrm{Re}(\\lambda_i)  0$, the corresponding term $e^{\\lambda_i t}$ will grow exponentially. The trajectory will diverge from the origin. This exponential divergence corresponds to Fisherian \"runaway\" selection.\n\nTherefore, the first task is to compute the eigenvalues of $\\mathbf{J}$ for each test case. An eigenvalue-based runaway is predicted if the maximum real part of the eigenvalues is greater than zero:\n$$\n\\text{Runaway Prediction} \\iff \\max_i \\mathrm{Re}(\\lambda_i)  0\n$$\n\n**2. Simulation-Based Detection of Runaway**\n\nThe second task is to simulate the system's trajectory over time and analyze its behavior. We use the explicit Euler method, a first-order numerical integration scheme, with a time step of $\\Delta t$. The state vector at time $t + \\Delta t$ is computed from the state at time $t$ as:\n$$\n\\mathbf{m}_{t+\\Delta t} = \\mathbf{m}_t + \\Delta t \\frac{d\\mathbf{m}}{dt}\\bigg|_t = \\mathbf{m}_t + \\Delta t\\,\\mathbf{J}\\,\\mathbf{m}_t = (\\mathbf{I} + \\Delta t\\,\\mathbf{J})\\mathbf{m}_t\n$$\nStarting from the initial condition $\\mathbf{m}(0) = \\mathbf{m}_0 = \\begin{bmatrix} 0.01 \\\\ 0.01 \\end{bmatrix}$, we iterate this equation for a total duration of $T=200.0$ or until the norm $\\|\\mathbf{m}(t)\\|_2$ exceeds a large value, given as $10^6$, to prevent numerical overflow. During the simulation, we record the history of time $t$ and the Euclidean norm of the state vector, $\\|\\mathbf{m}(t)\\|_2 = \\sqrt{z(t)^2 + p(t)^2}$.\n\nA runaway process is detected from the simulation if two conditions are met:\n- **Threshold Crossing**: The norm must exceed a specified threshold $L=1.0$ at some point during the simulation. This indicates that the state has moved a significant distance from the equilibrium. Formally, $\\max_t \\|\\mathbf{m}(t)\\|_2  L$.\n- **Sustained Growth**: The state must exhibit sustained exponential growth at the end of the simulation. For an unstable system, $\\|\\mathbf{m}(t)\\|_2 \\propto e^{\\lambda_{\\max} t}$, where $\\lambda_{\\max}$ is the eigenvalue with the largest real part. This implies that $\\log\\|\\mathbf{m}(t)\\|_2 \\propto \\lambda_{\\max} t$. We verify this by analyzing the final segment of the trajectory of duration $W=10.0$. We extract the time points $t_k$ and the corresponding log-norms $y_k = \\log\\|\\mathbf{m}(t_k)\\|_2$ within this final window. A linear regression of $y_k$ against $t_k$ is performed to estimate the slope $\\hat{s}$. This slope is an empirical estimate of $\\lambda_{\\max}$. A runaway is confirmed if this slope is positive and non-negligible, specifically $\\hat{s}  \\varepsilon$, where $\\varepsilon=10^{-4}$. The slope $\\hat{s}$ is calculated using the standard formula for ordinary least-squares:\n$$\n\\hat{s} = \\frac{\\sum (t_k - \\bar{t})(y_k - \\bar{y})}{\\sum (t_k - \\bar{t})^2}\n$$\nwhere $\\bar{t}$ and $\\bar{y}$ are the means of the time points and log-norms in the window.\n\nA norm-based runaway is declared if and only if both the threshold crossing and the positive slope conditions are satisfied. The program below implements this logic for each of the provided test cases.", "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the Lande model Fisherian runaway problem for a suite of test cases.\n    For each case, it performs an eigenvalue analysis and a numerical simulation \n    to detect runaway selection, then formats the results as specified.\n    \"\"\"\n    # Test suite of parameters\n    test_cases = [\n        {'a': 0.5, 'c': 1.0, 'G': np.array([[0.2, 0.05], [0.05, 0.3]])},\n        {'a': 1.2, 'c': 0.5, 'G': np.array([[1.0, 0.0], [0.0, 1.0]])},\n        {'a': 1.0, 'c': 1.0, 'G': np.array([[1.0, 0.0], [0.0, 1.0]])},\n        {'a': 1.5, 'c': 1.0, 'G': np.array([[0.001, 0.0], [0.0, 0.001]])},\n    ]\n\n    # Simulation and analysis constants\n    dt = 0.01\n    T_final = 200.0\n    m0 = np.array([0.01, 0.01])\n    L = 1.0\n    W = 10.0\n    epsilon = 1e-4\n    norm_limit = 1e6\n\n    all_results = []\n\n    for case in test_cases:\n        a = case['a']\n        c = case['c']\n        G = case['G']\n\n        # Construct the selection and Jacobian matrices\n        S = np.array([[-c, a], [a, -c]])\n        J = G @ S\n\n        # 1. Eigenvalue-based prediction\n        eigenvalues = np.linalg.eigvals(J)\n        max_real_eig = np.max(np.real(eigenvalues))\n        eig_runaway = max_real_eig > 0\n\n        # 2. Simulation-based detection\n        # Setup simulation\n        n_steps = int(T_final / dt)\n        m = m0.copy()\n        \n        t_history = []\n        norm_history = []\n        crossed_L = False\n        \n        # Run explicit Euler simulation\n        for i in range(n_steps + 1):\n            t = i * dt\n            current_norm = np.linalg.norm(m)\n\n            t_history.append(t)\n            norm_history.append(current_norm)\n            \n            if not crossed_L and current_norm > L:\n                crossed_L = True\n\n            # Early termination condition\n            if current_norm > norm_limit:\n                break\n            \n            m = m + dt * (J @ m)\n        \n        # Analyze trajectory norm for runaway detection\n        num_window_points = int(W / dt)\n        \n        # Ensure the window does not exceed the available data\n        if len(t_history)  num_window_points:\n            window_times = np.array(t_history)\n            window_norms = np.array(norm_history)\n        else:\n            window_times = np.array(t_history[-num_window_points:])\n            window_norms = np.array(norm_history[-num_window_points:])\n        \n        # To avoid log(0) if m becomes exactly 0 (unlikely but possible for stable cases)\n        if np.any(window_norms = 0):\n             slope = -np.inf # Assign a non-positive slope\n        else:\n             log_norms = np.log(window_norms)\n             # Perform linear regression of log(norm) vs. time\n             # np.polyfit(x, y, 1) returns [slope, intercept]\n             slope = np.polyfit(window_times, log_norms, 1)[0]\n        \n        slope_positive = slope > epsilon\n        sim_runaway = crossed_L and slope_positive\n        \n        # Store results for this case\n        all_results.append([eig_runaway, sim_runaway, max_real_eig])\n\n    # Format the final output string as required\n    # Creates a list of strings like \"[True,False,0.123]\"\n    formatted_results = [f\"[{res[0]},{res[1]},{res[2]}]\" for res in all_results]\n    \n    # Joins them with commas and wraps in brackets\n    final_output = f\"[{','.join(formatted_results)}]\"\n    \n    # Python's bool __str__ method returns \"True\" and \"False\" (capitalized),\n    # which matches the format requested in the problem.\n    # The f-string conversion implicitly calls str() on an object.\n    print(final_output)\n\nsolve()\n```", "id": "2713675"}]}