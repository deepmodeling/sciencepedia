{"hands_on_practices": [{"introduction": "这个练习将柯西-施瓦茨不等式应用于一个核心的概率概念：协方差。通过计算两个耦合随机变量之间相互作用项 $E[XY]$ 的最大可能值，你将亲身体验如何利用关于单个变量的统计信息（如均值和方差）来为它们的联合行为设定严格的数学界限。这项基本技能对于理解和建模多变量系统至关重要。[@problem_id:1347664]", "problem": "在耦合振荡系统的研究中，我们分析了由随机变量 $X$ 和 $Y$ 表示的两个状态变量的统计特性。实验测量确定了以下期望值：\n$X$ 的均值为 $E[X] = 0.1$。\n$Y$ 的均值为 $E[Y] = 0.2$。\n$X$ 的二阶矩为 $E[X^2] = 0.05$。\n$Y$ 的二阶矩为 $E[Y^2] = 0.13$。\n这两个变量之间的相互作用由它们乘积的期望值 $E[XY]$ 来表征。根据概率论的基本原理，这个相互作用项存在一个可能的最大值。\n根据给定数据，计算 $E[XY]$ 的最大可能值。将您的答案表示为一个实数，并四舍五入到三位有效数字。", "solution": "给定 $E[X]=0.1$，$E[Y]=0.2$，$E[X^{2}]=0.05$ 和 $E[Y^{2}]=0.13$。首先使用公式 $\\operatorname{Var}(X)=E[X^{2}]-(E[X])^{2}$ 和 $\\operatorname{Var}(Y)=E[Y^{2}]-(E[Y])^{2}$ 计算方差：\n$$\\operatorname{Var}(X)=0.05-(0.1)^{2}=0.05-0.01=0.04,$$\n$$\\operatorname{Var}(Y)=0.13-(0.2)^{2}=0.13-0.04=0.09.$$\n将 $E[XY]$ 用协方差表示：\n$$E[XY]=\\operatorname{Cov}(X,Y)+E[X]E[Y].$$\n根据应用于中心化变量的柯西-施瓦茨不等式，\n$$|\\operatorname{Cov}(X,Y)| \\leq \\sqrt{\\operatorname{Var}(X)\\operatorname{Var}(Y)}.$$\n因此，当 $\\operatorname{Cov}(X,Y)=+\\sqrt{\\operatorname{Var}(X)\\operatorname{Var}(Y)}$ 时，$E[XY]$ 达到其最大可能值，即\n$$E[XY]_{\\max}=E[X]E[Y]+\\sqrt{\\operatorname{Var}(X)\\operatorname{Var}(Y)}=0.1\\cdot 0.2+\\sqrt{0.04\\cdot 0.09}=0.02+0.06=0.08.$$\n当 $Y-E[Y]$ 是 $X-E[X]$ 的正标量倍数时，这个界是可达的，因此它是与给定矩相符的最大值。四舍五入到三位有效数字得到 $0.0800$。", "answer": "$$\\boxed{0.0800}$$", "id": "1347664"}, {"introduction": "这个练习旨在挑战你的创造性思维，而不是直接应用标准公式。你需要为随机变量的函数期望 $E[1/(X+1)]$ 找到一个下界，这需要你巧妙地构造一对辅助随机变量，以便应用柯西-施瓦茨不等式。这个过程不仅能加深你对不等式本质的理解，还能锻炼你将抽象工具灵活应用于具体问题的解决策略。[@problem_id:1347651]", "problem": "设 $X$ 是一个随机变量，表示在 $n$ 次独立伯努利试验中的成功次数，其中任意一次试验的成功概率为 $p$，且 $0 < p < 1$。考虑一个新的随机变量 $Y$，定义为 $Y = \\frac{1}{X+1}$。找出一个作为 $Y$ 的期望值（记为 $E[Y]$）下界的简单表达式。将答案表示为 $n$ 和 $p$ 的函数。", "solution": "设 $X \\sim \\mathrm{Bin}(n,p)$，其中 $0<p<1$，并定义 $Y=\\frac{1}{X+1}$。我们寻求一个用 $n$ 和 $p$ 表示的 $E[Y]$ 的下界。\n\n为了应用柯西-施瓦茨不等式 $(E[UV])^2 \\le E[U^2]E[V^2]$，我们需要巧妙地选择随机变量 $U$ 和 $V$。\n        \n我们定义两个新的随机变量：\n$U = \\sqrt{X+1}$\n$V = \\frac{1}{\\sqrt{X+1}}$\n\n现在我们计算不等式中的各项：\n1.  它们的乘积是 $UV = \\sqrt{X+1} \\cdot \\frac{1}{\\sqrt{X+1}} = 1$。因此，乘积的期望是 $E[UV] = E[1] = 1$。\n2.  $U$ 的平方是 $U^2 = (\\sqrt{X+1})^2 = X+1$。它的期望是 $E[U^2] = E[X+1] = E[X] + 1$。\n3.  $V$ 的平方是 $V^2 = \\left(\\frac{1}{\\sqrt{X+1}}\\right)^2 = \\frac{1}{X+1}$。它的期望就是我们要求解的目标：$E[V^2] = E\\left[\\frac{1}{X+1}\\right] = E[Y]$。\n\n将这些项代入柯西-施瓦茨不等式：\n$$\n(E[UV])^2 \\le E[U^2] E[V^2]\n$$\n$$\n1^2 \\le (E[X]+1) \\cdot E\\left[\\frac{1}{X+1}\\right]\n$$\n\n对于二项随机变量 $X \\sim \\mathrm{Bin}(n,p)$，其期望为 $E[X]=np$。代入上式：\n$$\n1 \\le (np+1) \\cdot E[Y]\n$$\n由于 $n \\ge 0, p \\in (0,1)$，所以 $np+1 > 1$。我们可以将不等式两边同除以 $(np+1)$：\n$$\nE[Y] = E\\left[\\frac{1}{X+1}\\right] \\ge \\frac{1}{np+1}\n$$\n这就给出了所求的、以 $n$ 和 $p$ 的函数表示的简单下界。", "answer": "$$\\boxed{\\frac{1}{np+1}}$$", "id": "1347651"}, {"introduction": "这个练习展示了柯西-施瓦茨不等式一个非常精妙且强大的应用：仅利用随机变量的前两阶矩来推导其取正值的概率下界。通过引入重要的“示性函数”概念，你将学会如何建立起矩（如均值 $M_1$ 和均方值 $M_2$）与概率 $P(X > 0)$ 之间的桥梁。掌握这种从统计平均到概率保证的推断能力，是理论和应用统计学中的一项关键技能。[@problem_id:1347643]", "problem": "一个物理学家团队正在研究一个量子系统，其中一个发射出的粒子的能量会发生涨落，该能量由非负随机变量 $X$ 表示。实验装置可以精确测量该能量分布的前两阶矩。设平均能量为 $E[X] = M_1$，能量的均方为 $E[X^2] = M_2$。已知该粒子不总是静止的，因此 $M_1 > 0$。\n\n该系统稳定性的一个关键方面取决于粒子具有非零能量。该团队需要为一个粒子发射事件具有大于零的能量这一情况，确定一个有保证的最小概率。在不对 $X$ 的概率分布做任何其他假设的情况下，推导出概率 $P(X > 0)$ 的一个通用的、紧的下界。\n\n将您的答案表示为以 $M_1$ 和 $M_2$ 表示的闭式解析表达式。", "solution": "设 $X$ 为表示粒子能量的非负随机变量。给定其一阶矩和二阶矩，分别为 $E[X] = M_1$ 和 $E[X^2] = M_2$。还给定 $M_1 > 0$。我们的目标是找到概率 $P(X > 0)$ 的一个下界。\n\n首先，我们可以将概率 $P(X > 0)$ 表示为一个指示随机变量的期望。设 $I_{X>0}$ 是一个指示变量，使得：\n$$\nI_{X>0} = \\begin{cases} 1 & \\text{如果 } X > 0 \\\\ 0 & \\text{如果 } X = 0 \\end{cases}\n$$\n根据离散随机变量期望的定义，$I_{X>0}$ 的期望值为：\n$$\nE[I_{X>0}] = 1 \\cdot P(I_{X>0} = 1) + 0 \\cdot P(I_{X>0} = 0) = P(X > 0)\n$$\n因此，我们的目标是找到 $E[I_{X>0}]$ 的一个下界。\n\n我们将使用期望的柯西-施瓦茨不等式。对于任意两个随机变量 $Y$ 和 $Z$，该不等式表述为：\n$$\n(E[YZ])^2 \\le E[Y^2]E[Z^2]\n$$\n\n为了应用这个不等式，我们需要适当地选择 $Y$ 和 $Z$。一个巧妙的选择是将随机变量 $X$ 与指示变量 $I_{X>0}$ 联系起来。由于 $X$ 是非负的，我们可以写出恒等式 $X = X \\cdot I_{X>0}$。这是因为如果 $X>0$，则 $I_{X>0}=1$，恒等式为 $X=X$。如果 $X=0$，则等式两边都为零。\n\n现在，我们对这个恒等式取期望：\n$$\nE[X] = E[X \\cdot I_{X>0}]\n$$\n这给了我们 $M_1$ 与 $X$ 和我们的指示变量乘积之间的关系。我们现在可以通过设置 $Y = X$ 和 $Z = I_{X>0}$ 来应用柯西-施瓦茨不等式。\n\n将这些代入柯西-施瓦茨不等式：\n$$\n(E[X \\cdot I_{X>0}])^2 \\le E[X^2] E[I_{X>0}^2]\n$$\n\n我们来计算这个不等式中的每一项。\n左边是 $(E[X])^2 = M_1^2$。\n右边的第一项是 $E[X^2] = M_2$。\n右边的第二项是 $E[I_{X>0}^2]$。由于指示变量只能取0或1，它的平方等于它自身：$I_{X>0}^2 = I_{X>0}$。因此：\n$$\nE[I_{X>0}^2] = E[I_{X>0}] = P(X > 0)\n$$\n\n将这些代回不等式中，我们得到：\n$$\nM_1^2 \\le M_2 \\cdot P(X > 0)\n$$\n\n因为给定 $M_1 > 0$，这意味着 $X$ 不可能是零随机变量，所以必须有部分概率质量分布在大于零的值上。这保证了 $E[X^2] = M_2 > 0$（如果 $M_2=0$，那么 $X=0$ 几乎必然成立，这将意味着 $M_1=0$，这是一个矛盾）。因此，我们可以用 $M_2$ 去除不等式两边，而不用改变不等号的方向：\n$$\n\\frac{M_1^2}{M_2} \\le P(X > 0)\n$$\n\n这就为概率 $P(X > 0)$ 提供了所求的下界。这个界是紧的，因为可以构造一个达到此界限的两点分布。", "answer": "$$\\boxed{\\frac{M_1^2}{M_2}}$$", "id": "1347643"}]}