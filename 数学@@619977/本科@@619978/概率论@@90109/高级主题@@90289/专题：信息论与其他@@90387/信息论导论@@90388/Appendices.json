{"hands_on_practices": [{"introduction": "信息论的核心在于量化不确定性，而香农熵（Shannon entropy）正是实现这一目标的基石。本练习将通过一个简单的思想实验，帮助你掌握计算离散随机变量熵的基本方法。你需要为一个源自均匀分布但经过简单数学变换的随机变量推导出其概率分布，并计算其熵，从而深入理解信息是如何被测量的。[@problem_id:1367065]", "problem": "一个基于硬件的真随机数生成器 (TRNG) 生成一个整数，由随机变量 $X$ 表示，该整数在集合 $\\{1, 2, 3, 4, 5, 6, 7, 8\\}$ 上均匀分布。一个后处理算法接收这个整数，并通过运算 $Y = X \\pmod 3$ 计算出一个新值，由随机变量 $Y$ 表示。\n\n计算随机变量 $Y$ 的香农熵。结果以比特为单位表示，并四舍五入到四位有效数字。", "solution": "随机变量 $X$ 在 $\\{1,2,3,4,5,6,7,8\\}$ 上均匀分布，因此对于每个 $x$，$P(X=x)=\\frac{1}{8}$。后处理定义了 $Y=X \\bmod 3$，所以 $Y\\in\\{0,1,2\\}$。枚举如下：\n- 当 $X\\in\\{3,6\\}$ 时，$Y=0$ 发生，因此 $P(Y=0)=\\frac{2}{8}=\\frac{1}{4}$。\n- 当 $X\\in\\{1,4,7\\}$ 时，$Y=1$ 发生，因此 $P(Y=1)=\\frac{3}{8}$。\n- 当 $X\\in\\{2,5,8\\}$ 时，$Y=2$ 发生，因此 $P(Y=2)=\\frac{3}{8}$。\n\n以比特为单位的香农熵为\n$$\nH(Y)=-\\sum_{y\\in\\{0,1,2\\}} P(Y=y)\\log_{2}\\big(P(Y=y)\\big).\n$$\n代入概率可得\n$$\nH(Y)=-\\frac{1}{4}\\log_{2}\\!\\left(\\frac{1}{4}\\right)-\\frac{3}{8}\\log_{2}\\!\\left(\\frac{3}{8}\\right)-\\frac{3}{8}\\log_{2}\\!\\left(\\frac{3}{8}\\right)\n=-\\frac{1}{4}\\log_{2}\\!\\left(\\frac{1}{4}\\right)-\\frac{3}{4}\\log_{2}\\!\\left(\\frac{3}{8}\\right).\n$$\n使用 $\\log_{2}\\!\\left(\\frac{1}{4}\\right)=\\log_{2}\\!\\left(2^{-2}\\right)=-2$ 和 $\\log_{2}\\!\\left(\\frac{3}{8}\\right)=\\log_{2}(3)-3$，我们得到\n$$\nH(Y)=-\\frac{1}{4}(-2)-\\frac{3}{4}\\big(\\log_{2}(3)-3\\big)\n=\\frac{11}{4}-\\frac{3}{4}\\log_{2}(3).\n$$\n数值上，$\\log_{2}(3)\\approx 1.5849625$，所以\n$$\nH(Y)\\approx 2.75-\\frac{3}{4}\\times 1.5849625 \\approx 1.561278125,\n$$\n四舍五入到四位有效数字后为 $1.561$ 比特。", "answer": "$$\\boxed{1.561}$$", "id": "1367065"}, {"introduction": "掌握了如何度量信息之后，下一个自然而然的问题就是：我们如何利用信息的统计特性来更有效地表示它？这便是数据压缩的核心，而霍夫曼编码（Huffman coding）是解决这一问题的优雅算法。通过这个实践，你将亲手为一个具有给定概率分布的符号集构建霍夫曼编码，并计算其期望码长，直观地感受最优前缀码是如何节省存储和传输资源的。[@problem_id:1367067]", "problem": "在一个用于压缩基因组数据的简化模型中，一个信源从五符号字母表 $\\{\\text{A, C, G, T, U}\\}$ 中生成一个符号流。每个符号代表一个特定的功能标记，并以已知的概率出现。概率如下：$P(\\text{A}) = 0.4$，$P(\\text{C}) = 0.2$，$P(\\text{G}) = 0.2$，$P(\\text{T}) = 0.1$，以及 $P(\\text{U}) = 0.1$。\n\n为了高效地传输这些数据，需要设计一种可变长度二进制前缀码。对于这样的编码方案，最小可能的平均码长（以比特/符号为单位）是多少？\n\n请以数值形式给出您的答案，并四舍五入到三位有效数字。", "solution": "题目要求我们在给定信源概率的情况下，求出一种二进制可变长度前缀码的最小可能平均码长（以比特/符号为单位）。最优的此类编码是霍夫曼编码，其期望长度在所有二进制前缀码中是最小的。\n\n给定概率：$P(\\text{A})=0.4$，$P(\\text{C})=0.2$，$P(\\text{G})=0.2$，$P(\\text{T})=0.1$，$P(\\text{U})=0.1$。\n\n应用霍夫曼算法，重复合并两个概率最小的符号/节点，每次合并都为合并节点内的所有叶节点增加一个比特的长度：\n- 合并 $\\text{T}$ 和 $\\text{U}$：$0.1+0.1=0.2$。这使得 $\\text{T}$ 和 $\\text{U}$ 的码长各增加1比特。\n- 现在权重的多重集是 $\\{0.4,0.2,0.2,0.2\\}$。合并两个权重为 0.2 的项，比如说 $\\text{C}$ 和 $\\text{G}$：$0.2+0.2=0.4$。这使得 $\\text{C}$ 和 $\\text{G}$ 的码长各增加1比特。\n- 现在多重集是 $\\{0.4,0.4,0.2\\}$，其中 0.2 对应于 $(\\text{T},\\text{U})$ 节点，一个 0.4 是 $(\\text{C},\\text{G})$，另一个 0.4 是 $\\text{A}$。合并 0.2 和一个 0.4（不失最优性），例如将 $(\\text{T},\\text{U})$ 对与 $\\text{A}$ 合并：$0.2+0.4=0.6$。这会为 $\\text{T}$ 和 $\\text{U}$ 再增加1个比特，并为 $\\text{A}$ 增加1个比特。\n- 最后合并 0.6 和 0.4：$0.6+0.4=1$。这会为 $(\\text{T},\\text{U},\\text{A})$ 再增加1个比特，并为 $(\\text{C},\\text{G})$ 增加1个比特。\n\n从这些合并中追踪码长，得到：\n- $\\text{A}$ 从第三次合并中获得 1 比特，从最后一次合并中获得 1 比特，所以 $l(\\text{A})=2$。\n- $\\text{C}$ 和 $\\text{G}$ 各自从第二次合并中获得 1 比特，从最后一次合并中获得 1 比特，所以 $l(\\text{C})=l(\\text{G})=2$。\n- $\\text{T}$ 和 $\\text{U}$ 各自从第一次合并中获得 1 比特，从第三次合并中获得 1 比特，从最后一次合并中获得 1 比特，所以 $l(\\text{T})=l(\\text{U})=3$。\n\n得到的期望码长为\n$$\nL=\\sum_{x} P(x)\\,l(x)\n=0.4\\cdot 2+0.2\\cdot 2+0.2\\cdot 2+0.1\\cdot 3+0.1\\cdot 3\n=1.6+0.6=2.2\\ \\text{比特/符号}。\n$$\n作为与香农界限的一致性检验，其熵为\n$$\nH=-\\sum_{x}P(x)\\log_{2}P(x)\n=0.4\\log_{2}\\!\\left(\\frac{1}{0.4}\\right)+0.2\\log_{2}\\!\\left(\\frac{1}{0.2}\\right)+0.2\\log_{2}\\!\\left(\\frac{1}{0.2}\\right)+0.1\\log_{2}\\!\\left(\\frac{1}{0.1}\\right)+0.1\\log_{2}\\!\\left(\\frac{1}{0.1}\\right)\\approx 2.122,\n$$\n并且 $H \\leq L < H+1$ 确实成立。因此，对于具有这些概率的二进制前缀码，其最小可能平均码长在四舍五入到三位有效数字后是 $2.20$ 比特/符号。", "answer": "$$\\boxed{2.20}$$", "id": "1367067"}, {"introduction": "高效编码数据后，我们还需面对信息传输的现实挑战：信道噪声。本练习将引导你分析信号在不完美信道中的传输过程，具体模型为二进制对称信道（Binary Symmetric Channel, BSC）。通过计算信号连续通过两个独立BSC后的总等效错误率，你将探索错误在通信系统中的累积方式，为理解信道容量和差错控制等高级概念奠定基础。[@problem_id:1367053]", "problem": "一艘深空探测器正在将科学数据传回地球上的一个中央指挥部。该通信容易出错，并包含两个阶段。首先，探测器将一个二进制信号（一个由0和1组成的序列）传输到一颗绕地球运行的中继卫星。其次，中继卫星放大并重新发射接收到的信号到中央指挥部的地面站。\n\n这两个通信链路（探测器到卫星和卫星到地面）中的每一个都可以被建模为一个独立且相同的二进制对称信道（BSC）。BSC是一种一次传输一个二进制数字的通信信道，其中每个比特都有一定的概率被“翻转”（即0变为1，或1变为0）。这种翻转事件被称为交叉。对于该系统中的每个链路，交叉概率由 $p$ 给出，其中 $0 < p < 1$。\n\n从探测器到中央指挥部的整个两阶段过程可以被视为一个单一的、等效的通信信道。这个等效信道也是一个BSC。请确定该等效信道的交叉概率，并以 $p$ 的函数形式表示。", "solution": "设 $X \\in \\{0, 1\\}$ 为深空探测器传输的比特，$Y \\in \\{0, 1\\}$ 为中继卫星接收的比特，$Z \\in \\{0, 1\\}$ 为中央指挥部接收的比特。\n\n该系统由两个串联的独立二进制对称信道（BSC）组成。第一个信道将 $X$ 映射到 $Y$，第二个信道将 $Y$ 映射到 $Z$。\n\n对于第一个BSC（探测器到卫星），交叉概率为 $p$。这可以用条件概率表示：\n$P(Y=1|X=0) = p$ （一个'0'翻转为'1'）\n$P(Y=0|X=1) = p$ （一个'1'翻转为'0'）\n因此，第一个信道的正确传输概率为 $1-p$：\n$P(Y=0|X=0) = 1-p$\n$P(Y=1|X=1) = 1-p$\n\n第二个BSC（卫星到地面）是相同且独立的，输入为 $Y$，输出为 $Z$。其概率为：\n$P(Z=1|Y=0) = p$\n$P(Z=0|Y=1) = p$\n对于正确传输：\n$P(Z=0|Y=0) = 1-p$\n$P(Z=1|Y=1) = 1-p$\n\n我们需要找到等效信道的交叉概率，我们将其表示为 $p_{eq}$。根据BSC的定义，这是最终输出比特 $Z$ 与初始输入比特 $X$ 不同的概率。由于系统的对称性，无论输入是0还是1，这个概率都是相同的。让我们计算 $p_{eq} = P(Z=1|X=0)$。\n\n为了求得 $P(Z=1|X=0)$，我们可以通过对中间变量 $Y$ 进行边缘化，使用全概率定律。比特 $Y$ 可以是0或1。\n$$p_{eq} = P(Z=1|X=0) = \\sum_{y \\in \\{0,1\\}} P(Z=1, Y=y | X=0)$$\n使用条件概率的链式法则，$P(A, B | C) = P(A | B, C)P(B | C)$，这变为：\n$$p_{eq} = P(Z=1|Y=0, X=0)P(Y=0|X=0) + P(Z=1|Y=1, X=0)P(Y=1|X=0)$$\n由于两个信道是独立的，第二个信道的输出 $Z$ 仅取决于其输入 $Y$，而与原始信号 $X$ 无关。这是马尔可夫链 $X \\to Y \\to Z$ 的一个特性。因此，我们可以简化条件概率：\n$P(Z=1|Y=0, X=0) = P(Z=1|Y=0)$\n$P(Z=1|Y=1, X=0) = P(Z=1|Y=1)$\n\n将这些代回到 $p_{eq}$ 的表达式中：\n$$p_{eq} = P(Z=1|Y=0)P(Y=0|X=0) + P(Z=1|Y=1)P(Y=1|X=0)$$\n现在我们代入每个信道的已知概率：\n- $P(Z=1|Y=0) = p$ （第二个信道发生交叉）\n- $P(Y=0|X=0) = 1-p$ （第一个信道正确传输）\n- $P(Z=1|Y=1) = 1-p$ （第二个信道正确传输）\n- $P(Y=1|X=0) = p$ （第一个信道发生交叉）\n\n将这些值代入方程中：\n$$p_{eq} = (p)(1-p) + (1-p)(p)$$\n$$p_{eq} = p - p^{2} + p - p^{2}$$\n$$p_{eq} = 2p - 2p^{2}$$\n这可以写成因式分解的形式：\n$$p_{eq} = 2p(1-p)$$\n这个表达式代表了单次有效交叉的总概率。这种情况发生在第一阶段发生交叉但第二阶段没有，或者第二阶段发生交叉但第一阶段没有。", "answer": "$$\\boxed{2p(1-p)}$$", "id": "1367053"}]}