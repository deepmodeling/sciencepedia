{"hands_on_practices": [{"introduction": "本练习旨在巩固特征向量的代数定义。特征向量和特征值的核心关系 $T(\\vec{v}) = \\lambda\\vec{v}$ 看似简单，但其威力在于能够优雅地推广到更复杂的变换，例如由 $T$ 构成的多项式。通过这个实践 [@problem_id:2122882]，你将学会如何利用特征向量的基本性质来简化对复合线性变换的分析，这是掌握线性代数中算子理论的关键一步。", "problem": "考虑向量空间 $V$ 上的一个线性变换 $T$。设 $I$ 为该空间上的恒等变换，使得对于 $V$ 中的任意向量 $\\vec{x}$，都有 $I(\\vec{x}) = \\vec{x}$。\n\n一个新的变换 $M$ 定义为变换 $T$ 的一个多项式：\n$$M = 2T^2 - 5T + 7I$$\n其中 $T^2$ 表示将变换 $T$ 应用两次，即 $T^2(\\vec{x}) = T(T(\\vec{x}))$。\n\n已知在 $V$ 中存在一个非零向量 $\\vec{v}$，它是变换 $T$ 的一个特征向量。与该特征向量 $\\vec{v}$ 对应的特征值为 $\\lambda = 3$。\n\n求变换 $M$ 对应于同一特征向量 $\\vec{v}$ 的特征值。", "solution": "根据特征向量和特征值的定义，如果 $\\vec{v} \\neq \\vec{0}$ 是 $T$ 的一个特征向量，其特征值为 $\\lambda$，则\n$$\nT(\\vec{v}) = \\lambda \\vec{v}.\n$$\n再次应用 $T$ 可得\n$$\nT^{2}(\\vec{v}) = T(T(\\vec{v})) = T(\\lambda \\vec{v}) = \\lambda T(\\vec{v}) = \\lambda^{2} \\vec{v},\n$$\n而恒等变换的作用为\n$$\nI(\\vec{v}) = \\vec{v}.\n$$\n对于多项式变换 $M = 2T^{2} - 5T + 7I$，将其作用于 $\\vec{v}$ 可得\n$$\nM(\\vec{v}) = \\left(2T^{2} - 5T + 7I\\right)(\\vec{v}) = 2T^{2}(\\vec{v}) - 5T(\\vec{v}) + 7I(\\vec{v}) = \\left(2\\lambda^{2} - 5\\lambda + 7\\right)\\vec{v}.\n$$\n因此 $\\vec{v}$ 是 $M$ 的一个特征向量，其对应的特征值为 $2\\lambda^{2} - 5\\lambda + 7$。代入给定的 $\\lambda = 3$，\n$$\n2\\lambda^{2} - 5\\lambda + 7 = 2 \\cdot 3^{2} - 5 \\cdot 3 + 7 = 18 - 15 + 7 = 10.\n$$\n因此，对应于 $\\vec{v}$ 的 $M$ 的特征值为 $10$。", "answer": "$$\\boxed{10}$$", "id": "2122882"}, {"introduction": "这个练习鼓励我们超越纯粹的代数计算，培养对特征向量和特征值的几何直觉。特征向量是线性变换的“灵魂”，揭示了其在空间中拉伸、压缩或反转的基本作用方向。通过分析一个具体的几何变换——反射与缩放的组合 [@problem_id:2122850]，我们将学习如何不依赖于矩阵的显式形式，仅通过几何推理来直接确定其特征值，从而深化对变换本质的理解。", "problem": "考虑一个将向量从 $\\mathbb{R}^2$ 映射到 $\\mathbb{R}^2$ 的线性变换 $T$。$T$ 对任意向量的作用由以下两步过程定义：\n1. 首先，将向量关于由方程 $y = 4x$ 给出的直线 $L$ 进行反射。\n2. 其次，将所得向量均匀缩放5倍。\n\n使用关于特征向量和特征值性质的几何推理，确定变换 $T$ 的所有特征值的集合。你应该不需要显式计算 $T$ 的矩阵表示来找到答案。\n\n以下哪个选项表示 $T$ 的特征值集合？\n\nA. $\\{1, -1\\}$\n\nB. $\\{5, -5\\}$\n\nC. $\\{5, 1\\}$\n\nD. $\\{4, -4\\}$\n\nE. $\\{0, 5\\}$", "solution": "令 $R$ 表示关于由 $y=4x$ 给出的直线 $L$ 的反射。因为 $L$ 经过原点，所以 $R$ 是线性的。反射的几何性质意味着：\n- 任何位于 $L$ 上的向量 $v$ 都会被映射到其自身，因此对于 $v \\in L$，有 $R v = v$；所以 $v$ 是一个特征值为 $1$ 的特征向量。\n- 任何与 $L$ 正交的向量 $w$ 的方向会被反转，因此对于 $w \\perp L$，有 $R w = -w$；所以 $w$ 是一个特征值为 $-1$ 的特征向量。\n\n令 $S$ 表示因子为5的均匀缩放，所以 $S = 5I$，其中 $I$ 是 $\\mathbb{R}^{2}$ 上的单位变换。给定的变换是复合变换\n$$\nT = S \\circ R = 5 R.\n$$\n因此，$T$ 与 $R$ 具有相同的特征向量，其特征值被缩放了5倍。具体来说，如果 $R u = \\lambda u$ 且 $\\lambda \\in \\{1,-1\\}$，那么\n$$\nT u = 5 R u = 5 \\lambda u,\n$$\n所以 $T$ 的特征值为 $5 \\cdot 1 = 5$ 和 $5 \\cdot (-1) = -5$。\n\n不会产生其他特征值，因为在 $\\mathbb{R}^{2}$ 上的 $R$ 只有两个特征值 $1$ 和 $-1$，而 $S$ 只是将它们缩放了5倍。因此，$T$ 的特征值集合是 $\\{5,-5\\}$，这对应于选项B。", "answer": "$$\\boxed{B}$$", "id": "2122850"}, {"introduction": "此练习在前一个几何直观的基础上，引入了更深层次的概念——特征空间及其维度。我们研究的是三维空间中的投影变换，它会自然地引出一个重要的情形：一个完整的向量子空间（即变换的核）被映射到零向量，对应于特征值 $0$。这项实践 [@problem_id:2122862] 的重点不仅在于找到特征值，更在于理解特征空间的结构与维度，这对于全面分析一个变换的行为至关重要。", "problem": "考虑一个线性变换 $T: \\mathbb{R}^3 \\to \\mathbb{R}^3$，该变换将任意向量 $\\vec{v} \\in \\mathbb{R}^3$ 正交投影到由非零向量 $\\vec{d} = (1, -2, 2)$ 张成的直线上。确定该变换所有不同特征值的特征空间的维数。\n\n将与 $T$ 的特征值相对应的特征空间的维数，按照相关特征值的降序排列。以行矩阵的形式给出你的答案。", "solution": "设 $T: \\mathbb{R}^{3} \\to \\mathbb{R}^{3}$ 是到直线 $L = \\operatorname{span}\\{\\vec{d}\\}$ 上的正交投影，其中 $\\vec{d} = (1,-2,2) \\neq \\vec{0}$。正交投影的公式是\n$$\nT(\\vec{v}) = \\operatorname{proj}_{\\vec{d}}(\\vec{v}) = \\frac{\\vec{v} \\cdot \\vec{d}}{\\vec{d} \\cdot \\vec{d}}\\,\\vec{d}.\n$$\n首先，我们确定 $T$ 的特征值。因为 $T$ 是一个投影，所以它满足 $T^{2} = T$。对于任意特征对 $(\\lambda, \\vec{v} \\neq \\vec{0})$，\n$$\nT^{2}\\vec{v} = T\\vec{v} \\quad \\Longrightarrow \\quad \\lambda^{2}\\vec{v} = \\lambda \\vec{v} \\quad \\Longrightarrow \\quad \\lambda^{2} = \\lambda \\quad \\Longrightarrow \\quad \\lambda \\in \\{0,1\\}.\n$$\n接下来，我们确定特征空间及其维数。\n\n对于 $\\lambda = 1$，取 $\\vec{v} = \\vec{d}$。则\n$$\nT(\\vec{d}) = \\frac{\\vec{d} \\cdot \\vec{d}}{\\vec{d} \\cdot \\vec{d}}\\,\\vec{d} = \\vec{d},\n$$\n所以 $\\vec{d}$ 是一个特征值为 $1$ 的特征向量。事实上，对于任意 $\\alpha \\in \\mathbb{R}$，\n$$\nT(\\alpha \\vec{d}) = \\alpha T(\\vec{d}) = \\alpha \\vec{d},\n$$\n所以 $\\lambda=1$ 的特征空间恰好是 $L = \\operatorname{span}\\{\\vec{d}\\}$，其维数为 $1$。\n\n对于 $\\lambda = 0$，取任意与 $\\vec{d}$ 正交的向量 $\\vec{v}$，即 $\\vec{v} \\cdot \\vec{d} = 0$。则\n$$\nT(\\vec{v}) = \\frac{\\vec{v} \\cdot \\vec{d}}{\\vec{d} \\cdot \\vec{d}}\\,\\vec{d} = \\vec{0},\n$$\n所以 $\\vec{d}^{\\perp}$ 中的每个向量都是特征值为 $0$ 的特征向量。子空间 $\\vec{d}^{\\perp}$ 是 $\\mathbb{R}^{3}$ 中的一个平面，因此维数为 $2$。等价地，因为 $\\operatorname{rank}(T) = \\dim(\\operatorname{Im} T) = 1$，根据秩-零度定理，$\\dim(\\ker T) = 3 - 1 = 2$，且 $\\ker T$ 恰好是 $\\lambda = 0$ 的特征空间。\n\n因此，不同的特征值为 $1$ 和 $0$，其特征空间的维数分别为 $1$ 和 $2$。按特征值降序排列（先是 $\\lambda = 1$，然后是 $\\lambda = 0$），维数为 $1$ 和 $2$。", "answer": "$$\\boxed{\\begin{pmatrix} 1  2 \\end{pmatrix}}$$", "id": "2122862"}]}