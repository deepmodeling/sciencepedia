{"hands_on_practices": [{"introduction": "掌握了独立性的定义后，让我们将其应用于一个具体的场景。在有放回抽样中，每次抽样的结果通常是独立的，但当抽样无放回时，情况就变得更加复杂。这个练习将挑战你运用独立性的基本公式 $P(A \\cap B) = P(A)P(B)$，在一个生态学研究的假设情景中，通过计算来确定使两个事件变得统计独立的精确条件。[@problem_id:1422282]", "problem": "一个生态学家团队正在研究一个新发现的隔离湖泊的生物多样性。该湖泊中栖息着一个稳定的单一鱼类物种的种群，该物种在两种不同的性状上表现出变异：其鳞片图案和其鳍色。鳞片图案可以是条纹（S）或斑点（s），鳍色可以是红色（R）或蓝色（b）。\n\n生态学家们对该湖泊进行了广泛的抽样，并确定了四种可能的表型组合中三种的确切数量。具有条纹鳞片和蓝色鳍的鱼的数量，记为 $N_{Sb}$，是 60。具有斑点鳞片和红色鳍的鱼的数量，$N_{sR}$，是 40。具有斑点鳞片和蓝色鳍的鱼的数量，$N_{sb}$，是 30。具有条纹鳞片和红色鳍的鱼的数量，$N_{SR}$，是一个未知量，我们将其记为 $x$。因此，湖中鱼的总种群数量 $N$ 是所有四种数量的总和。\n\n现提出一个实验，从湖中依次捕获两条鱼，且不放回。设 A 为捕获的第一条鱼具有条纹鳞片图案的事件。设 B 为捕获的第二条鱼具有红色鳍的事件。你的任务是确定具有条纹鳞片和红色鳍的鱼的确切数量 $x$，使得事件 A 和 B 统计独立。", "solution": "设 $N_{SR}=x$，$N_{Sb}=60$，$N_{sR}=40$，$N_{sb}=30$。总数是 $N=x+60+40+30=x+130$。\n\n事件 $A$ 是第一条鱼是条纹的，因此条纹鱼的总数是 $N_{S}=x+60$。因此\n$$\nP(A)=\\frac{x+60}{N}.\n$$\n事件 $B$ 是第二条鱼有红色鳍。在不放回抽样中，每个位置的边际分布与总体分布相同，所以\n$$\nP(B)=\\frac{N_{R}}{N}=\\frac{x+40}{N}.\n$$\n\n为计算 $P(A\\cap B)$，我们按第一条鱼的类型分情况讨论：\n- 如果第一条鱼是 $SR$ 类型，那么 $P(\\text{第一条是 }SR)=\\frac{x}{N}$ 且 $P(\\text{第二条是 }R\\mid \\text{第一条是 }SR)=\\frac{(x+40)-1}{N-1}=\\frac{x+39}{N-1}$。\n- 如果第一条鱼是 $Sb$ 类型，那么 $P(\\text{第一条是 }Sb)=\\frac{60}{N}$ 且 $P(\\text{第二条是 }R\\mid \\text{第一条是 }Sb)=\\frac{x+40}{N-1}$。\n\n因此，\n$$\nP(A\\cap B)=\\frac{x}{N}\\cdot\\frac{x+39}{N-1}+\\frac{60}{N}\\cdot\\frac{x+40}{N-1}\n=\\frac{x^{2}+99x+2400}{N(N-1)}.\n$$\n\n独立的条件是 $P(A\\cap B)=P(A)P(B)$，所以\n$$\n\\frac{x^{2}+99x+2400}{N(N-1)}=\\frac{(x+60)(x+40)}{N^{2}}.\n$$\n两边同乘以 $N^{2}(N-1)$：\n$$\n(x^{2}+99x+2400)N=(x+60)(x+40)(N-1).\n$$\n将 $N=x+130$ 代入，展开等式两边：\n$$\n\\text{左式}=(x^{2}+99x+2400)(x+130)=x^{3}+229x^{2}+15270x+312000,\n$$\n$$\n\\text{右式}=(x+60)(x+40)(x+129)=x^{3}+229x^{2}+15300x+309600.\n$$\n令两式相等并化简，\n$$\n15270x+312000=15300x+309600 \\quad\\Longrightarrow\\quad 2400=30x \\quad\\Longrightarrow\\quad x=80.\n$$\n\n该值为容许值（非负整数，且不违反任何计数约束）。因此所求数量为 $x=80$。", "answer": "$$\\boxed{80}$$", "id": "1422282"}, {"introduction": "从事件的独立性过渡到随机变量的独立性，我们需要更复杂的工具，但直觉依然重要。如果一个变量的值可以完全或部分地由另一个变量决定，它们显然是相关的。然而，统计上的“不相关”（零协方差）是否等同于独立呢？这个练习通过一个标准正态分布的变量 $X$ 及其平方 $Z = X^2$ 的经典例子，揭示了两者之间的微妙差别，并阐明了为何依赖关系比简单的线性相关性更为宽泛。[@problem_id:1422221]", "problem": "设 $X$ 是一个服从标准正态分布的随机变量，其概率密度函数为 $\\phi(x) = \\frac{1}{\\sqrt{2\\pi}} \\exp\\left(-\\frac{x^2}{2}\\right)$，其中 $x \\in (-\\infty, \\infty)$。考虑两个新的随机变量 $Y$ 和 $Z$，定义为 $Y = X$ 和 $Z = X^2$。\n\n下列哪个陈述准确地描述了随机变量 $Y$ 和 $Z$ 之间的关系？\n\nA. $Y$ 和 $Z$ 相互独立，因为它们乘积的期望 $E[YZ]$ 等于它们期望的乘积 $E[Y]E[Z]$。\n\nB. $Y$ 和 $Z$ 相关，因为知道 $Z$ 的值会提供信息，从而限制 $Y$ 的可能取值。\n\nC. $Y$ 和 $Z$ 相互独立，因为 $Y$ 的概率分布关于原点对称。\n\nD. $Y$ 和 $Z$ 相关，因为它们的协方差 $\\text{Cov}(Y, Z)$ 非零。\n\nE. 仅从给定信息无法确定 $Y$ 和 $Z$ 之间的关系。", "solution": "给定一个标准正态随机变量 $X$，其密度函数为 $\\phi(x) = \\frac{1}{\\sqrt{2\\pi}} \\exp\\left(-\\frac{x^{2}}{2}\\right)$，其中 $x \\in (-\\infty,\\infty)$，并定义 $Y = X$ 和 $Z = X^{2}$。\n\n首先，观察到 $Z$ 是 $Y$ 的一个可测函数，具体来说是 $Z = g(Y)$，其中 $g(y) = y^{2}$。一个基本的概率原理是，如果 $Z = g(Y)$ 几乎必然不是常数，那么 $Y$ 和 $Z$ 就不可能相互独立：知道 $Z$ 的值会将 $Y$ 的取值限制在集合 $\\{y : y^{2} = Z\\}$ 中。具体来说，对于任意 $z > 0$，知道 $Z = z$ 会将 $Y$ 的取值限制在两点集 $\\{-\\sqrt{z}, \\sqrt{z}\\}$ 中，这表明了它们是相关的。这直接支持了陈述 B。\n\n现在我们使用标准定义来逐一评估这些论断。\n\n关于 A：独立性意味着 $E[YZ] = E[Y]E[Z]$，但其逆命题通常不成立。计算\n$$\nE[YZ] = E[X \\cdot X^{2}] = E[X^{3}] = \\int_{-\\infty}^{\\infty} x^{3} \\phi(x) \\, dx = \\frac{1}{\\sqrt{2\\pi}} \\int_{-\\infty}^{\\infty} x^{3} \\exp\\left(-\\frac{x^{2}}{2}\\right) \\, dx = 0,\n$$\n因为被积函数是在对称区间上的一个奇函数。\n另外，\n$$\nE[Y] = E[X] = 0 \\quad \\text{(根据标准正态分布的对称性)},\n$$\n并且\n$$\nE[Z] = E[X^{2}] = \\operatorname{Var}(X) + (E[X])^{2} = 1 + 0 = 1.\n$$\n因此 $E[YZ] = 0 = E[Y]E[Z]$，但仅凭这个等式并不能推断出独立性。所以 A 是错误的。\n\n关于 C：$Y$ 关于原点的对称性并不意味着 $Y$ 和 $Z$ 相互独立；独立性要求联合分布的因式分解（或对一个足够丰富的函数类，其函数乘积的期望等于期望的乘积），而这一点并不能从对称性推断出来。因此 C 是错误的。\n\n关于 D：使用 $\\operatorname{Cov}(Y,Z) = E[YZ] - E[Y]E[Z]$ 计算协方差。根据上面的计算结果，\n$$\n\\operatorname{Cov}(Y,Z) = 0 - 0 \\cdot 1 = 0.\n$$\n因此协方差为零，而不是非零，所以 D 是错误的。（此外，即使协方差为零，通常也不能推断出独立性。）\n\n关于 E：两者之间的关系可以从给定信息中确定，因为 $Z$ 是 $Y$ 的一个非常数函数，这意味着它们是相关的。因此 E 是错误的。\n\n因此，正确的陈述是 B：$Y$ 和 $Z$ 相关，因为知道 $Z$ 的值会限制 $Y$ 的可能取值。", "answer": "$$\\boxed{B}$$", "id": "1422221"}, {"introduction": "上一个练习表明，零协方差并不总是意味着独立。然而，在概率论和统计学中应用最广泛的正态分布族中，“不相关”和“独立”是等价的，这一特性极大地简化了分析。这个练习将引导你证明一个关于多元正态分布的关键性质：两个独立正态变量的线性组合是独立的，当且仅当它们的协方差为零。[@problem_id:1422273]", "problem": "设 $X$ 和 $Y$ 是两个独立的随机变量，都服从标准正态分布，即均值为0，方差为1。考虑两个新的随机变量 $U$ 和 $V$，它们是 $X$ 和 $Y$ 的线性组合，系数为实常数 $a, b, c, d$：\n$$U = aX + bY$$\n$$V = cX + dY$$\n我们假设系数对 $(a, b)$ 和 $(c, d)$ 不全为零，即 $a^2+b^2 \\neq 0$ 且 $c^2+d^2 \\neq 0$。\n\n要使随机变量 $U$ 和 $V$ 独立，关于常数 $a, b, c, d$ 的充分必要条件是什么？\n\nA. $ab + cd = 0$\n\nB. $ac + bd = 0$\n\nC. $ad - bc = 0$\n\nD. $a^2+b^2 = c^2+d^2$\n\nE. $a+b = c+d$", "solution": "设 $(X,Y)$ 是独立的标准正态随机变量，因此 $E[X]=E[Y]=0$，$\\operatorname{Var}(X)=\\operatorname{Var}(Y)=1$，且 $E[XY]=E[X]E[Y]=0$。定义 $U=aX+bY$ 和 $V=cX+dY$。向量 $(U,V)$ 是联合正态向量 $(X,Y)$ 的线性变换；因此 $(U,V)$ 是联合正态分布的。对于联合正态变量，独立等价于协方差为零。\n\n计算协方差：\n$$\n\\operatorname{Cov}(U,V)=E[UV]-E[U]E[V].\n$$\n因为 $E[U]=aE[X]+bE[Y]=0$ 且 $E[V]=cE[X]+dE[Y]=0$，我们有\n$$\n\\operatorname{Cov}(U,V)=E[(aX+bY)(cX+dY)]。\n$$\n展开并利用期望的线性性质，\n$$\nE[(aX+bY)(cX+dY)]=ac\\,E[X^{2}]+bd\\,E[Y^{2}]+ad\\,E[XY]+bc\\,E[XY].\n$$\n使用 $E[X^{2}]=\\operatorname{Var}(X)=1$，$E[Y^{2}]=\\operatorname{Var}(Y)=1$ 和 $E[XY]=0$，我们得到\n$$\n\\operatorname{Cov}(U,V)=ac+bd.\n$$\n因此，$\\operatorname{Cov}(U,V)=0$ 当且仅当 $ac+bd=0$。由于 $(U,V)$ 是联合正态分布的，这个条件是它们独立的充分必要条件。\n\n因此，正确的选项是 $ac+bd=0$，即选项B。", "answer": "$$\\boxed{B}$$", "id": "1422273"}]}