{"hands_on_practices": [{"introduction": "掌握斯卢茨基定理首先要理解其核心机制。这个练习提供了一个理想的起点，它设定了一个清晰的场景：一个序列在分布上收敛，而另一个序列在概率上收敛到一个非零常数。通过解决这个问题，你将直接应用斯卢茨基定理的基本规则，即将两种不同类型的收敛组合起来，以确定一个复合随机变量的极限分布。[@problem_id:1955717]", "problem": "在统计推断中，当样本量 $n$ 趋于无穷大时，估计量和检验统计量的性质具有根本的重要性。对于参数 $\\theta$，如果其估计量序列 $\\{\\hat{\\theta}_n\\}_{n=1}^{\\infty}$ 依概率收敛于 $\\theta$，则称该估计量序列是*相合的*。这被记为 $\\hat{\\theta}_n \\to_p \\theta$，其形式化定义为：对于任意小的正数 $\\epsilon$，当 $n \\to \\infty$ 时，概率 $P(|\\hat{\\theta}_n - \\theta| \\ge \\epsilon)$ 趋近于零。\n\n设 $\\{Z_n\\}_{n=1}^{\\infty}$ 是一个随机变量序列，已知其依分布收敛于一个标准正态随机变量 $Z \\sim N(0, 1)$。这被记为 $Z_n \\to_d Z$。\n\n现在，假设你有一个参数 $\\theta$ 的相合估计量 $\\hat{\\theta}_n$，其中 $\\theta$ 是一个固定的非零实数。考虑一个新的随机变量序列 $\\{T_n\\}_{n=1}^{\\infty}$，其构造为如下比率：\n$$T_n = \\frac{Z_n}{\\hat{\\theta}_n}$$\n当 $n \\to \\infty$ 时，确定 $T_n$ 的极限分布。请使用统计分布的标准记法来表达你的答案，例如，用 $N(\\mu, \\sigma^2)$ 表示均值为 $\\mu$、方差为 $\\sigma^2$ 的正态分布。", "solution": "我们已知两个收敛条件：$Z_{n} \\to_{d} Z$（其中 $Z \\sim N(0,1)$），以及 $\\hat{\\theta}_{n} \\to_{p} \\theta$（其中 $\\theta \\in \\mathbb{R}\\setminus\\{0\\}$）。定义 $T_{n} = Z_{n}/\\hat{\\theta}_{n}$。为了求出 $T_{n}$ 的极限分布，我们可以应用斯卢茨基定理。\n\n首先，由于 $\\hat{\\theta}_{n} \\to_{p} \\theta$ 且 $\\theta \\neq 0$，函数 $f(x,y) = x/y$ 在所有 $y \\neq 0$ 的点上是连续的，特别地，对于任意 $x \\in \\mathbb{R}$，它在点 $(x,\\theta)$ 处是连续的。斯卢茨基定理指出，如果 $X_{n} \\to_{d} X$ 并且 $Y_{n} \\to_{p} c$（其中 $c$ 是一个常数），那么 $X_{n}/Y_{n} \\to_{d} X/c$。令 $X_{n} = Z_{n}$，$Y_{n} = \\hat{\\theta}_{n}$ 以及 $c = \\theta$，我们得到\n$$\nT_{n} \\;=\\; \\frac{Z_{n}}{\\hat{\\theta}_{n}} \\;\\to_{d}\\; \\frac{Z}{\\theta}.\n$$\n由于 $Z \\sim N(0,1)$，并且对于任意常数 $a$，我们有 $aZ \\sim N(0, a^{2})$，因此可以得出\n$$\n\\frac{Z}{\\theta} \\;\\sim\\; N\\!\\left(0,\\;\\frac{1}{\\theta^{2}}\\right).\n$$\n因此，$T_{n}$ 的极限分布是 $N\\!\\left(0, \\theta^{-2}\\right)$。", "answer": "$$\\boxed{N\\!\\left(0,\\,\\theta^{-2}\\right)}$$", "id": "1955717"}, {"introduction": "在实际的统计分析中，斯卢茨基定理的两个组成部分——分布收敛和概率收敛——通常源于其他基本极限定理。本练习将中心极限定理（CLT）和弱大数定律（WLLN）结合起来，为一个常见的统计量（样本比例）构建极限分布。这个实践案例展示了这些基础理论如何协同工作，为更复杂的统计推断奠定基础。[@problem_id:1955718]", "problem": "设 $X_1, X_2, \\dots, X_n$ 为一个来自参数为 $p$ 的伯努利分布的独立同分布随机变量序列，其中 $0 < p < 1$。参数 $p$ 代表成功的概率，即 $P(X_i = 1) = p$ 且 $P(X_i = 0) = 1-p$。\n\n设 $\\hat{p}_n = \\frac{1}{n} \\sum_{i=1}^{n} X_i$ 为前 $n$ 次试验中成功的样本比例。\n\n考虑新的随机变量 $Y_n = (1-\\hat{p}_n)\\sqrt{n}(\\hat{p}_n - p)$。当 $n \\to \\infty$ 时，下列哪项描述了 $Y_n$ 的极限分布？\n\nA. 均值为 $0$、方差为 $p(1-p)$ 的正态分布。\n\nB. 均值为 $0$、方差为 $p^2(1-p)^2$ 的正态分布。\n\nC. 均值为 $0$、方差为 $p(1-p)^2$ 的正态分布。\n\nD. 均值为 $0$、方差为 $p(1-p)^3$ 的正态分布。\n\nE. 随机变量序列 $Y_n$ 不会依分布收敛于正态分布。", "solution": "我们有 $X_{i} \\sim \\text{Bernoulli}(p)$ 独立同分布(i.i.d.)，因此 $E[X_{i}] = p$ 且 $\\operatorname{Var}(X_{i}) = p(1-p)$。样本比例 $\\hat{p}_{n} = \\frac{1}{n}\\sum_{i=1}^{n} X_{i}$ 满足大数定律：\n$$\n\\hat{p}_{n} \\xrightarrow{p} p \\quad \\text{当 } n \\to \\infty \\text{ 时},\n$$\n这意味着\n$$\n1 - \\hat{p}_{n} \\xrightarrow{p} 1 - p.\n$$\n\n根据独立同分布的伯努利变量的中心极限定理，\n$$\n\\sqrt{n}\\,(\\hat{p}_{n} - p) \\xrightarrow{d} Z \\quad \\text{其中 } Z \\sim \\mathcal{N}\\bigl(0,\\,p(1-p)\\bigr).\n$$\n\n定义 $Y_{n} = (1 - \\hat{p}_{n}) \\sqrt{n} (\\hat{p}_{n} - p)$。因为 $(1 - \\hat{p}_{n}) \\xrightarrow{p} (1 - p)$ 且 $\\sqrt{n}(\\hat{p}_{n} - p) \\xrightarrow{d} Z$，根据斯卢茨基定理，\n$$\nY_{n} \\xrightarrow{d} (1 - p)\\,Z.\n$$\n如果 $Z \\sim \\mathcal{N}(0, \\sigma^{2})$，那么对于任意常数 $c$，$cZ \\sim \\mathcal{N}(0, c^{2}\\sigma^{2})$。将此应用于 $c = 1 - p$ 和 $\\sigma^{2} = p(1-p)$，我们得出结论\n$$\n(1 - p)\\,Z \\sim \\mathcal{N}\\bigl(0,\\,(1 - p)^{2}\\,p(1-p)\\bigr) = \\mathcal{N}\\bigl(0,\\,p(1-p)^{3}\\bigr).\n$$\n\n因此，$Y_{n}$ 的极限分布是均值为 $0$、方差为 $p(1-p)^{3}$ 的正态分布，这对应于选项D。", "answer": "$$\\boxed{D}$$", "id": "1955718"}, {"introduction": "斯卢茨基定理最强大的应用之一是它为实际统计检验提供了理论依据，尤其是在真实方差未知的情况下。本问题探讨了如何构建一个类似于$t$-统计量的检验统计量，其中分母中的渐近方差是用其一致估计量替代的。通过这个练习，你将理解为什么尽管我们使用了估计的方差，最终的统计量仍然收敛到一个标准正态分布，这是许多假设检验有效性的关键。[@problem_id:840199]", "problem": "考虑两个独立的独立同分布 (i.i.d.) 随机变量序列 $\\{X_i\\}_{i=1}^n$ 和 $\\{Y_i\\}_{i=1}^n$。随机变量 $X_i$ 的总体均值为 $E[X_i] = \\mu_X$，总体方差为有限值 $Var(X_i) = \\sigma_X^2$。随机变量 $Y_i$ 的总体均值为 $E[Y_i] = \\mu_Y \\neq 0$，总体方差为有限值 $Var(Y_i) = \\sigma_Y^2$。\n\n令 $\\bar{X}_n = \\frac{1}{n}\\sum_{i=1}^n X_i$ 和 $\\bar{Y}_n = \\frac{1}{n}\\sum_{i=1}^n Y_i$ 分别为各自的样本均值。令 $S_{X,n}^2$ 和 $S_{Y,n}^2$ 分别是总体方差 $\\sigma_X^2$ 和 $\\sigma_Y^2$ 的相合估计量。\n\n我们关心的是样本均值的比率 $R_n = \\frac{\\bar{X}_n}{\\bar{Y}_n}$，它是真实均值比率 $\\rho = \\frac{\\mu_X}{\\mu_Y}$ 的一个估计量。可以如下构造一个关于 $\\rho$ 的检验统计量：\n$$ T_n = \\frac{\\sqrt{n}(R_n - \\rho)}{\\sqrt{\\hat{V}_n}} $$\n其中 $\\hat{V}_n$ 是 $\\sqrt{n}(R_n - \\rho)$ 的渐近方差的一个相合估计量，由下式给出：\n$$ \\hat{V}_n = \\frac{S_{X,n}^2 \\bar{Y}_n^2 + S_{Y,n}^2 \\bar{X}_n^2}{\\bar{Y}_n^4} $$\n\n推导当 $n \\to \\infty$ 时，统计量 $T_n$ 的极限分布的方差。", "solution": "1. 根据多元中心极限定理，\n$$\n\\sqrt{n}\\Bigl(\\begin{pmatrix}\\bar X_n\\\\\\bar Y_n\\end{pmatrix}-\\begin{pmatrix}\\mu_X\\\\\\mu_Y\\end{pmatrix}\\Bigr)\n\\xrightarrow{d}N\\!\\Bigl(0,\\begin{pmatrix}\\sigma_X^2&0\\\\0&\\sigma_Y^2\\end{pmatrix}\\Bigr).\n$$\n\n2. 将 Delta 方法应用于 $g(x,y)=x/y$。在 $(\\mu_X,\\mu_Y)$ 处的梯度为\n$$\n\\nabla g(\\mu_X,\\mu_Y)\n=\\begin{pmatrix}1/\\mu_Y\\\\-\\,\\mu_X/\\mu_Y^2\\end{pmatrix}.\n$$\n因此 $\\sqrt{n}(R_n-\\rho)$ 的渐近方差为\n$$\nV\n=\\nabla g(\\mu_X,\\mu_Y)^T\n\\begin{pmatrix}\\sigma_X^2&0\\\\0&\\sigma_Y^2\\end{pmatrix}\n\\nabla g(\\mu_X,\\mu_Y)\n=\\frac{\\sigma_X^2}{\\mu_Y^2}+\\frac{\\sigma_Y^2\\mu_X^2}{\\mu_Y^4}\n=\\frac{\\sigma_X^2\\mu_Y^2+\\sigma_Y^2\\mu_X^2}{\\mu_Y^4}.\n$$\n\n3. 由于 $\\hat V_n \\to_p V$，根据斯卢茨基定理\n$$\nT_n=\\frac{\\sqrt{n}(R_n-\\rho)}{\\sqrt{\\hat V_n}}\\xrightarrow{d}N(0,1),\n$$\n所以极限方差为 $1$。", "answer": "$$\\boxed{1}$$", "id": "840199"}]}