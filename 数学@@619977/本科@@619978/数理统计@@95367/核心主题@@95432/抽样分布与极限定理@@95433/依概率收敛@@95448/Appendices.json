{"hands_on_practices": [{"introduction": "我们熟悉的大数定律告诉我们，独立同分布随机变量的样本均值依概率收敛于其期望。但如果我们将简单的算术平均推广为加权平均，这个结论还成立吗？本练习 [@problem_id:1910722] 探讨了线性加权平均的收敛性，通过计算其方差并证明其趋于零，来巩固证明概率收敛的核心方法。", "problem": "考虑一个独立同分布 (i.i.d.) 的随机变量序列 $X_1, X_2, \\dots, X_n, \\dots$。这些变量具有共同的有限均值 $E[X_i] = \\mu$ 和共同的有限非零方差 $\\text{Var}(X_i) = \\sigma^2$。\n\n一个新的随机变量序列 $Y_n$ 被构造为该序列前 $n$ 个变量的加权平均值：\n$$Y_n = \\frac{\\sum_{i=1}^n i X_i}{\\sum_{i=1}^n i}$$\n这种加权平均给予序列中靠后的观测值线性递增的重要性。可以证明，当 $n \\to \\infty$ 时，序列 $Y_n$ 依概率收敛到一个特定的常数值。\n\n请确定这个常数值。您的答案应为用给定参数表示的解析表达式。", "solution": "定义归一化和 $S_{n}=\\sum_{i=1}^{n} i=\\frac{n(n+1)}{2}$。那么加权平均可以写成\n$$\nY_{n}=\\sum_{i=1}^{n}\\frac{i}{S_{n}}X_{i}.\n$$\n利用期望的线性性质和共同均值 $E[X_{i}]=\\mu$ 计算其期望：\n$$\nE[Y_{n}]=\\sum_{i=1}^{n}\\frac{i}{S_{n}}E[X_{i}]=\\mu\\sum_{i=1}^{n}\\frac{i}{S_{n}}=\\mu.\n$$\n利用独立性、$\\text{Var}(X_{i})=\\sigma^{2}$ 以及当 $i\\neq j$ 时 $\\text{Cov}(X_{i},X_{j})=0$ 来计算其方差：\n$$\n\\text{Var}(Y_{n})=\\sum_{i=1}^{n}\\left(\\frac{i}{S_{n}}\\right)^{2}\\text{Var}(X_{i})=\\sigma^{2}\\frac{\\sum_{i=1}^{n} i^{2}}{S_{n}^{2}}.\n$$\n使用恒等式 $\\sum_{i=1}^{n} i^{2}=\\frac{n(n+1)(2n+1)}{6}$ 和 $S_{n}^{2}=\\left(\\frac{n(n+1)}{2}\\right)^{2}=\\frac{n^{2}(n+1)^{2}}{4}$ 来得到\n$$\n\\text{Var}(Y_{n})=\\sigma^{2}\\cdot\\frac{\\frac{n(n+1)(2n+1)}{6}}{\\frac{n^{2}(n+1)^{2}}{4}}\n=\\sigma^{2}\\cdot\\frac{4(2n+1)}{6n(n+1)}\n=\\sigma^{2}\\cdot\\frac{2(2n+1)}{3n(n+1)}.\n$$\n由于当 $n\\to\\infty$ 时 $\\frac{2(2n+1)}{3n(n+1)}\\to 0$，因此有 $\\text{Var}(Y_{n})\\to 0$。根据 Chebyshev 不等式，对于任意 $\\varepsilon>0$，\n$$\n\\Pr\\big(|Y_{n}-\\mu|>\\varepsilon\\big)=\\Pr\\big(|Y_{n}-E[Y_{n}]|>\\varepsilon\\big)\\leq \\frac{\\text{Var}(Y_{n})}{\\varepsilon^{2}}\\to 0.\n$$\n因此，$Y_{n}$ 依概率收敛于 $\\mu$。该常数极限为 $\\mu$。", "answer": "$$\\boxed{\\mu}$$", "id": "1910722"}, {"introduction": "在熟悉了收敛性的基本应用后，我们来探讨一个著名的反例，它警示我们不能盲目应用定理。本练习 [@problem_id:1353353] 研究了柯西分布（Cauchy distribution）的样本均值的行为，这是一个在统计学中具有“病态”特性的分布。通过这个实践，你将深刻理解为何在使用大数定律等重要定理前，必须严格检验其前提条件，例如期望 $E[X]$ 的存在性。", "problem": "在一个数据分析场景中，记录了一个独立同分布 (i.i.d.) 的测量序列 $X_1, X_2, \\dots, X_n$。每个测量值 $X_i$ 是一个服从标准柯西分布的随机变量。标准柯西分布的概率密度函数 (PDF) 由下式给出：\n$$f(x) = \\frac{1}{\\pi(1+x^2)}$$\n其中 $-\\infty < x < \\infty$。\n\n这些测量值的样本均值计算为 $\\bar{X}_n = \\frac{1}{n} \\sum_{i=1}^n X_i$。\n\n考虑当测量次数 $n$ 趋于无穷大时，样本均值 $\\bar{X}_n$ 的行为。随机变量序列 $\\{\\bar{X}_n\\}$ 依分布收敛于什么？\n\nA. 常数 0。\n\nB. 一个服从标准柯西分布的随机变量。\n\nC. 一个服从标准正态分布的随机变量。\n\nD. 它不依分布收敛于任何随机变量或常数。\n\nE. 一个服从自由度为 $n-1$ 的学生t分布的随机变量。", "solution": "设 $X_{1},\\dots,X_{n}$ 为独立同分布的标准柯西随机变量，其密度函数为 $f(x)=\\frac{1}{\\pi(1+x^{2})}$。记 $S_{n}=\\sum_{i=1}^{n}X_{i}$ 且 $\\bar{X}_{n}=\\frac{S_{n}}{n}$。\n\n一个关键工具是特征函数。一个标准柯西随机变量 $X$ 的特征函数是一个已知的公式\n$$\n\\varphi_{X}(t)=\\exp(-|t|),\\quad t\\in\\mathbb{R}.\n$$\n因为 $X_{1},\\dots,X_{n}$ 是独立同分布的，所以它们的和的特征函数是各个特征函数的乘积：\n$$\n\\varphi_{S_{n}}(t)=\\prod_{i=1}^{n}\\varphi_{X_{i}}(t)=[\\varphi_{X}(t)]^{n}=\\exp(-n|t|).\n$$\n函数 $t\\mapsto \\exp(-\\gamma|t|)$ 是位置参数为0、尺度参数为 $\\gamma$ 的柯西分布的特征函数。因此，$S_{n}$ 服从一个尺度参数为 $n$ 的柯西分布。\n\n对于样本均值 $\\bar{X}_{n}=S_{n}/n$，根据特征函数的尺度变换性质，其特征函数为\n$$\n\\varphi_{\\bar{X}_{n}}(t)=\\varphi_{S_{n}}(t/n)=\\exp\\!\\left(-n\\left|\\frac{t}{n}\\right|\\right)=\\exp(-|t|).\n$$\n这正是一个标准柯西随机变量的特征函数。因此，对于任意 $n$，\n$$\n\\bar{X}_{n}\\stackrel{d}{=}\\text{Cauchy}(0,1).\n$$\n因此，序列 $\\{\\bar{X}_{n}\\}$ 的分布不随 $n$ 而改变，从而（平凡地）依分布收敛到一个标准柯西随机变量。这也表明经典的中心极限定理在此不适用，因为柯西分布没有有限方差。\n\n因此，正确选项是 B。", "answer": "$$\\boxed{B}$$", "id": "1353353"}, {"introduction": "为了更深入地理解随机收敛的精髓，我们需要辨析不同收敛模式之间的细微差别。本练习 [@problem_id:1293189] 构建了一个经典的“打字机序列”（typewriter sequence），它是一个依概率收敛但不几乎处处收敛的著名例子。通过分析这个序列，你将清晰地把握依概率收敛和几乎处处收敛这两种核心概念的本质区别。", "problem": "考虑一个概率空间 $(\\Omega, \\mathcal{F}, P)$，其中 $\\Omega = [0, 1]$，$\\mathcal{F}$ 是 $[0, 1]$ 上的 Borel σ-代数，而 $P$ 是 $[0, 1]$ 上的均匀（勒贝格）测度。我们定义一个随机变量序列 $\\{X_n\\}_{n=1}^{\\infty}$ 如下。对任意整数 $n \\ge 1$，存在唯一的非负整数对 $(k, j)$，使得 $n = 2^k + j$，其中 $0 \\le j < 2^k$。随机变量 $X_n$ 在 $\\omega \\in \\Omega$ 上的取值定义为：\n$$\nX_n(\\omega) =\n\\begin{cases}\n1 & \\text{若 } \\omega \\in \\left[\\frac{j}{2^k}, \\frac{j+1}{2^k}\\right] \\\\\n0 & \\text{否则}\n\\end{cases}\n$$\n这个序列可以被看作是一个“扫描”区间的示性函数，该区间以递减的宽度反复扫过整个空间 $[0, 1]$。令 $X$ 是恒等于零的随机变量，即对所有 $\\omega \\in \\Omega$，$X(\\omega)=0$。\n\n下列哪个陈述正确地描述了序列 $\\{X_n\\}$ 到 $X=0$ 的收敛性？\n\nA. 序列 $\\{X_n\\}$ 几乎必然收敛到 0，但不依概率收敛。\n\nB. 序列 $\\{X_n\\}$ 依概率收敛到 0，但不是几乎必然收敛。\n\nC. 序列 $\\{X_n\\}$ 既几乎必然收敛到 0，也依概率收敛。\n\nD. 序列 $\\{X_n\\}$ 既不几乎必然收敛到 0，也不依概率收敛。", "solution": "我们回顾一下定义。对于每个整数 $n \\geq 1$，存在唯一的整数对 $(k,j)$，其中 $k \\in \\mathbb{Z}_{\\ge 0}$ 且 $0 \\le j < 2^{k}$，使得 $n = 2^{k} + j$。那么\n$$\nX_{n}(\\omega) = \\mathbf{1}_{\\left[\\frac{j}{2^{k}},\\, \\frac{j+1}{2^{k}}\\right]}(\\omega).\n$$\n令 $X \\equiv 0$。我们分析向 $X$ 的几乎必然收敛和依概率收敛。\n\n几乎必然收敛：根据定义，如果\n$$\nP\\big(\\{\\omega \\in \\Omega : \\lim_{n \\to \\infty} X_{n}(\\omega) = 0\\}\\big) = 1.\n$$\n则 $\\{X_{n}\\}$ 几乎必然收敛到 $0$。\n\n固定任意 $\\omega \\in [0,1]$。对每个 $k \\in \\mathbb{Z}_{\\ge 0}$，族 $\\left\\{\\left[\\frac{j}{2^{k}}, \\frac{j+1}{2^{k}}\\right] : j = 0,1,\\dots,2^{k}-1\\right\\}$ 覆盖了 $[0,1]$，因此存在 $j_{k} \\in \\{0,\\dots,2^{k}-1\\}$ 使得\n$$\n\\omega \\in \\left[\\frac{j_{k}}{2^{k}}, \\frac{j_{k}+1}{2^{k}}\\right].\n$$\n定义 $n_{k} = 2^{k} + j_{k}$。根据构造，对每个 $k$ 都有 $X_{n_{k}}(\\omega) = 1$。因此，对每个 $\\omega$，存在无穷多个 $n$ 使得 $X_{n}(\\omega) = 1$。此外，在每个块 $\\{2^{k},\\dots,2^{k+1}-1\\}$ 中，至多有两个指标使得 $X_{n}(\\omega) = 1$（如果 $\\omega$ 不是分母为 $2^{k}$ 的二进有理数，则恰好有一个），其余的则得到 $X_{n}(\\omega) = 0$，所以也存在无穷多个 $n$ 使得 $X_{n}(\\omega) = 0$。因此，对每个 $\\omega \\in [0,1]$，序列 $\\{X_{n}(\\omega)\\}$ 会无限次地取到 1 和 0 且不收敛（特别地，它不收敛于 0）。所以，\n$$\nP\\big(\\{\\omega : \\lim_{n \\to \\infty} X_{n}(\\omega) = 0\\}\\big) = 0 \\neq 1,\n$$\n故 $X_{n} \\not\\to 0$ 几乎必然地。\n\n依概率收敛：根据定义，如果对每个 $\\epsilon > 0$，\n$$\n\\lim_{n \\to \\infty} P\\big(|X_{n} - 0| > \\epsilon\\big) = 0.\n$$\n则 $X_{n} \\to 0$ 依概率收敛。\n\n由于 $X_{n}$ 只取值 0 和 1，对任意 $\\epsilon \\in (0,1]$，\n$$\n\\{|X_{n} - 0| > \\epsilon\\} = \\{X_{n} = 1\\},\n$$\n所以\n$$\nP\\big(|X_{n}| > \\epsilon\\big) = P(X_{n} = 1).\n$$\n给定 $n = 2^{k} + j$，$X_{n}$ 是一个长度为 $2^{-k}$ 的区间的示性函数，且 $P$ 是 $[0,1]$ 上的勒贝格测度。因此\n$$\nP(X_{n} = 1) = 2^{-k}.\n$$\n令 $k(n)$ 表示与 $n$ 相关联的 $k$。当 $n \\to \\infty$ 时，必然有 $k(n) \\to \\infty$，因为 $n \\in \\{2^{k},\\dots,2^{k+1}-1\\}$ 且这些块会移动到更大的 $k$。因此，\n$$\n\\lim_{n \\to \\infty} P\\big(|X_{n}| > \\epsilon\\big) = \\lim_{n \\to \\infty} 2^{-k(n)} = 0 \\quad \\text{对所有 } \\epsilon \\in (0,1].\n$$\n对于 $\\epsilon > 1$，$P(|X_{n}| > \\epsilon) = 0$ 对所有 $n$ 成立，所以极限也为 0。因此 $X_{n} \\to 0$ 依概率收敛。\n\n综合两部分，正确的陈述是 $\\{X_{n}\\}$ 依概率收敛到 $0$，但不是几乎必然收敛。", "answer": "$$\\boxed{B}$$", "id": "1293189"}]}