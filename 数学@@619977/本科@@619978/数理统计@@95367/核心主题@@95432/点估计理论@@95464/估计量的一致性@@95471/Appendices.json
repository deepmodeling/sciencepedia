{"hands_on_practices": [{"introduction": "本部分的练习旨在帮助你建立对估计量一致性的直观理解。我们将从我们熟知的样本均值（一个一致估计量）出发，通过对其进行微小的调整来观察其一致性是否会发生改变。这个练习将检验你对一致性定义的掌握，并巩固像斯卢茨基定理 (Slutsky's theorem) 这样的基本工具在判断估计量性质时的应用 [@problem_id:1909315]。", "problem": "设 $X_1, X_2, \\dots, X_n$ 是来自一个概率分布的独立同分布 (i.i.d.) 随机样本，该分布的均值为有限值 $\\mu$，方差为有限正值 $\\sigma^2 > 0$。设 $\\bar{X}_n = \\frac{1}{n}\\sum_{i=1}^{n} X_i$ 为样本均值。\n\n如果一个参数的估计量在样本量 $n$ 趋于无穷大时依概率收敛于该参数的真实值，则称该估计量是相合的。\n\n考虑以下四个用于估计总体均值 $\\mu$ 的估计量。\n\nA. $\\hat{\\mu}_A = \\bar{X}_n + \\frac{1}{\\sqrt{n}}$\n\nB. $\\hat{\\mu}_B = \\frac{n}{n+2} \\bar{X}_n$\n\nC. $\\hat{\\mu}_C = \\frac{1}{2}(\\bar{X}_n + X_1)$\n\nD. $\\hat{\\mu}_D = \\bar{X}_n + \\frac{\\cos(n\\pi)}{n}$\n\n以上哪些估计量是 $\\mu$ 的相合估计量？选择所有适用项。", "solution": "根据弱大数定律，由于 $X_{i}$ 是独立同分布的，且具有有限均值 $\\mu$ 和有限正方差 $\\sigma^{2}>0$，因此 $\\bar{X}_{n} \\xrightarrow{p} \\mu$。我们利用这个事实和 Slutsky 定理来分析每个估计量。\n\nA. $\\hat{\\mu}_{A}=\\bar{X}_{n}+\\frac{1}{\\sqrt{n}}$。写作\n$$\n\\hat{\\mu}_{A}-\\mu=(\\bar{X}_{n}-\\mu)+\\frac{1}{\\sqrt{n}}.\n$$\n我们有 $\\bar{X}_{n}-\\mu \\xrightarrow{p} 0$ 且 $\\frac{1}{\\sqrt{n}} \\to 0$ 是确定性收敛。根据 Slutsky 定理（一个依概率收敛于 $0$ 的序列与一个确定性收敛于 $0$ 的序列之和），$\\hat{\\mu}_{A} \\xrightarrow{p} \\mu$。因此 $\\hat{\\mu}_{A}$ 是相合的。\n\nB. $\\hat{\\mu}_{B}=\\frac{n}{n+2}\\bar{X}_{n}$。注意到 $\\frac{n}{n+2} \\to 1$ 是确定性收敛。那么根据 Slutsky 定理（一个依概率收敛的序列与一个确定性收敛到常数的序列之积），有\n$$\n\\hat{\\mu}_{B}=\\frac{n}{n+2}\\bar{X}_{n} \\xrightarrow{p} 1 \\cdot \\mu=\\mu\n$$\n更具体地说，\n$$\n\\hat{\\mu}_{B}-\\mu=\\frac{n}{n+2}(\\bar{X}_{n}-\\mu)+\\left(\\frac{n}{n+2}-1\\right)\\mu,\n$$\n其中第一项依概率收敛于 $0$，而第二项确定性地收敛于 $0$。因此 $\\hat{\\mu}_{B}$ 是相合的。\n\nC. $\\hat{\\mu}_{C}=\\frac{1}{2}(\\bar{X}_{n}+X_{1})$。考虑对于任意 $\\epsilon>0$，\n$$\n\\left|\\hat{\\mu}_{C}-\\mu\\right|=\\left|\\frac{1}{2}(\\bar{X}_{n}-\\mu)+\\frac{1}{2}(X_{1}-\\mu)\\right|\\ge \\frac{1}{2}|X_{1}-\\mu|-\\frac{1}{2}|\\bar{X}_{n}-\\mu|.\n$$\n因此，在事件 $\\{|X_{1}-\\mu|>3\\epsilon,\\ |\\bar{X}_{n}-\\mu|<\\epsilon\\}$ 上，我们有 $\\left|\\hat{\\mu}_{C}-\\mu\\right|>\\epsilon$。所以，\n$$\n\\mathbb{P}\\left(\\left|\\hat{\\mu}_{C}-\\mu\\right|>\\epsilon\\right)\\ge \\mathbb{P}\\left(|X_{1}-\\mu|>3\\epsilon,\\ |\\bar{X}_{n}-\\mu|<\\epsilon\\right)\\ge \\mathbb{P}\\left(|X_{1}-\\mu|>3\\epsilon\\right)-\\mathbb{P}\\left(|\\bar{X}_{n}-\\mu|\\ge \\epsilon\\right).\n$$\n根据弱大数定律，$\\mathbb{P}\\left(|\\bar{X}_{n}-\\mu|\\ge \\epsilon\\right)\\to 0$。因为 $\\sigma^{2}>0$，所以 $X_{1}$ 的分布是非退化的，故存在某个 $\\epsilon>0$ 使得 $\\mathbb{P}\\left(|X_{1}-\\mu|>3\\epsilon\\right)>0$。对于这样的 $\\epsilon$，上述下界始终大于一个正数，所以 $\\mathbb{P}\\left(\\left|\\hat{\\mu}_{C}-\\mu\\right|>\\epsilon\\right)\\not\\to 0$。因此 $\\hat{\\mu}_{C}$ 不是相合的。\n\nD. $\\hat{\\mu}_{D}=\\bar{X}_{n}+\\frac{\\cos(n\\pi)}{n}$。注意到 $\\cos(n\\pi)=(-1)^{n}$，所以 $\\frac{\\cos(n\\pi)}{n}\\to 0$ 是确定性收敛。那么\n$$\n\\hat{\\mu}_{D}-\\mu=(\\bar{X}_{n}-\\mu)+\\frac{\\cos(n\\pi)}{n},\n$$\n其中第一项依概率收敛于 $0$，第二项确定性地收敛于 $0$。根据 Slutsky 定理，$\\hat{\\mu}_{D} \\xrightarrow{p} \\mu$。因此 $\\hat{\\mu}_{D}$ 是相合的。\n\n因此，相合的估计量是 A、B 和 D。", "answer": "$$\\boxed{ABD}$$", "id": "1909315"}, {"introduction": "第二个练习是一个重要的“警示故事”。我们很容易假设任何看起来合理的估计量都会是有效的，但这个练习将揭示一个常见的陷阱：一个估计量可能会收敛，但却收敛到一个错误的值。通过分析这个具体例子，你将深刻理解到，在检验一致性时，不仅要确认估计量是否收敛，更重要的是要验证它是否收敛到了我们真正感兴趣的参数 [@problem_id:1909343]。", "problem": "设 $X_1, X_2, \\dots, X_n$ 是从一个总体中抽取的独立同分布 (i.i.d.) 随机变量样本。该总体分布具有有限的非零均值 $E[X_i] = \\mu$ 和有限的正方差 $Var(X_i) = \\sigma^2$。\n\n考虑估计量 $\\hat{\\theta}_n$，其定义为非中心的二阶样本矩：\n$$\n\\hat{\\theta}_n = \\frac{1}{n} \\sum_{i=1}^n X_i^2\n$$\n\n关于 $\\hat{\\theta}_n$ 作为总体方差 $\\sigma^2$ 的估计量的性质，以下哪个陈述是正确的？\n\nA. 是，$\\hat{\\theta}_n$ 是 $\\sigma^2$ 的一个相合估计量，因为当 $n \\to \\infty$ 时，其期望值收敛于 $\\sigma^2$。\n\nB. 是，$\\hat{\\theta}_n$ 是 $\\sigma^2$ 的一个相合估计量，因为它依概率收敛于 $\\sigma^2$。\n\nC. 否，$\\hat{\\theta}_n$ 不是 $\\sigma^2$ 的一个相合估计量，因为它不依概率收敛于 $\\sigma^2$。\n\nD. 否，$\\hat{\\theta}_n$ 不是 $\\sigma^2$ 的一个相合估计量，因为对于任何有限的样本量 $n$，该估计量都是有偏的。\n\nE. 在不知道 $X_i$ 完整分布的情况下，无法确定 $\\hat{\\theta}_n$ 对 $\\sigma^2$ 的相合性。", "solution": "给定独立同分布的随机变量 $X_{1},\\dots,X_{n}$，其满足 $E[X_{i}]=\\mu$ 和 $\\operatorname{Var}(X_{i})=\\sigma^{2}$，以及估计量 $\\hat{\\theta}_{n}=\\frac{1}{n}\\sum_{i=1}^{n}X_{i}^{2}$。我们评估其作为 $\\sigma^{2}$ 的估计量的性质。\n\n首先，使用恒等式 $E[X^{2}]=\\operatorname{Var}(X)+\\{E[X]\\}^{2}$ 来计算其期望：\n$$\nE[\\hat{\\theta}_{n}]=E\\left[\\frac{1}{n}\\sum_{i=1}^{n}X_{i}^{2}\\right]=E[X_{1}^{2}]=\\sigma^{2}+\\mu^{2}.\n$$\n因此，除非 $\\mu=0$，否则 $E[\\hat{\\theta}_{n}]\\neq\\sigma^{2}$。该期望不依赖于 $n$，因此除非 $\\mu=0$，否则当 $n\\to\\infty$ 时它不会收敛于 $\\sigma^{2}$。所以，陈述 A 是错误的。\n\n接下来，考虑依概率收敛。由于 $E[X_{1}^{2}]<\\infty$ (因为 $\\operatorname{Var}(X_{1})<\\infty$)，大数弱定律适用于序列 $X_{i}^{2}$，得到\n$$\n\\hat{\\theta}_{n}=\\frac{1}{n}\\sum_{i=1}^{n}X_{i}^{2}\\xrightarrow{p}E[X_{1}^{2}]=\\sigma^{2}+\\mu^{2}.\n$$\n因此，$\\hat{\\theta}_{n}$ 依概率收敛于 $\\sigma^{2}+\\mu^{2}$，而不是 $\\sigma^{2}$ (除非 $\\mu=0$)。因此，陈述 B 是错误的，而陈述 C 是正确的。\n\n关于偏差，除非 $\\mu=0$，否则对于任何有限的 $n$，$\\hat{\\theta}_{n}$ 对 $\\sigma^{2}$ 是有偏的。但在有限 $n$ 上的偏差本身通常并不意味着不相合。在这个问题中，不相合性是由于其依概率收敛的极限为 $\\sigma^{2}+\\mu^{2}\\neq\\sigma^{2}$。因此，D 中的理由并不是不相合的正确原因，这使得 D 是一个不正确的描述。\n\n最后，给定的矩条件足以确定极限 $E[X^{2}]=\\sigma^{2}+\\mu^{2}$，因此不需要知道完整的分布。因此 E 是错误的。\n\n所以，正确的选项是 C。", "answer": "$$\\boxed{C}$$", "id": "1909343"}, {"introduction": "掌握了基本概念和常见陷阱后，我们现在来学习一种更为强大和系统的方法来证明一致性。这个练习将引导你运用大数定律 (Law of Large Numbers) 和连续映射定理 (Continuous Mapping Theorem) 来证明一个重要估计量的一致性。这个组合方法是统计推断中的一个核心工具，尤其在处理如最大似然估计量 (maximum likelihood estimators) 等复杂估计量时显得尤为重要 [@problem_id:1909316]。", "problem": "一位材料科学家正在研究一种新型光纤电缆的寿命。一段这种电缆的失效时间 $X$ 服从指数分布（Exponential distribution），其失效率为常数 $\\lambda > 0$。其寿命的概率密度函数（PDF）为 $f(x; \\lambda) = \\lambda \\exp(-\\lambda x)$，其中 $x \\ge 0$。为估计失效率，该科学家测试了 $n$ 个独立电缆段的随机样本，测量了它们的寿命 $X_1, X_2, \\ldots, X_n$。\n\n基于样本平均寿命 $\\bar{X}_n = \\frac{1}{n} \\sum_{i=1}^n X_i$，提出了一个 $\\lambda$ 的估计量。所提出的估计量为 $\\hat{\\lambda}_n = \\frac{1}{\\bar{X}_n}$。\n\n该科学家希望证明这是一个好的估计量，即随着样本量 $n$ 的增加，它会变得更加准确。这个性质被称为相合性（consistency）。如果当 $n \\to \\infty$ 时，估计量 $\\hat{\\theta}_n$ 依概率收敛于参数 $\\theta$，则称 $\\hat{\\theta}_n$ 是 $\\theta$ 的一个相合估计量。\n\n以下哪个陈述为证明 $\\hat{\\lambda}_n = 1/\\bar{X}_n$ 是 $\\lambda$ 的相合估计量提供了正确的推理？\n\nA. 该估计量是相合的，因为中心极限定理（Central Limit Theorem）指出，当 $n$ 很大时，$\\hat{\\lambda}_n$ 的抽样分布近似于均值为 $\\lambda$ 的正态分布。\n\nB. 该估计量是相合的，因为大数定律（Law of Large Numbers）指出，样本均值 $\\bar{X}_n$ 依概率收敛于真实的失效率 $\\lambda$，因此 $\\hat{\\lambda}_n = 1/\\bar{X}_n$ 必定依概率收敛于 $1/\\lambda$。\n\nC. 该估计量是相合的，因为它可以被证明是 $\\lambda$ 的一个无偏估计量，即对于任何样本量 $n$，其期望值 $E[\\hat{\\lambda}_n]$ 都精确地等于 $\\lambda$。\n\nD. 该估计量是相合的，因为可以证明当样本量 $n$ 趋近于无穷大时，其方差 $\\text{Var}(\\hat{\\lambda}_n)$ 趋近于零。虽然这个事实是正确的，但它本身并不是相合性的一个完整证明。\n\nE. 该估计量是相合的，因为大数定律保证了样本均值 $\\bar{X}_n$ 依概率收敛于真实的平均寿命，即 $1/\\lambda$。由于函数 $g(y) = 1/y$ 在 $y \\neq 0$ 时是连续的，所以连续映射定理（Continuous Mapping Theorem）保证了 $\\hat{\\lambda}_n = g(\\bar{X}_n)$ 依概率收敛于 $g(1/\\lambda) = \\lambda$。", "solution": "为了确定估计量 $\\hat{\\lambda}_n = 1/\\bar{X}_n$ 的相合性的正确理由，我们必须遵循相合性的正式定义，并应用概率论中的相关定理。\n\n如果一个估计量 $\\hat{\\theta}_n$ 随着样本量 $n$ 趋于无穷大而依概率收敛于参数 $\\theta$，那么它就是 $\\theta$ 的相合估计量。我们将其记为 $\\hat{\\theta}_n \\xrightarrow{p} \\theta$。我们需要证明 $\\hat{\\lambda}_n \\xrightarrow{p} \\lambda$。\n\n首先，我们来确定随机样本 $X_1, X_2, \\ldots, X_n$ 的性质。这些变量是独立同分布（i.i.d.）的，服从失效率为 $\\lambda$ 的指数分布。失效率为 $\\lambda$ 的指数分布随机变量的期望值（或均值）是 $E[X] = 1/\\lambda$。方差是 $\\text{Var}(X) = 1/\\lambda^2$。由于失效率 $\\lambda > 0$，因此均值 $1/\\lambda$ 是有限的。\n\n证明相合性的核心论证通常涉及大数定律。弱大数定律（WLLN）指出，对于一个具有有限均值 $\\mu$ 的独立同分布随机变量序列，其样本均值 $\\bar{X}_n$ 依概率收敛于 $\\mu$。\n在我们的例子中，$\\mu = E[X] = 1/\\lambda$。因此，根据弱大数定律：\n$$ \\bar{X}_n = \\frac{1}{n} \\sum_{i=1}^n X_i \\xrightarrow{p} E[X] = \\frac{1}{\\lambda} \\quad \\text{当 } n \\to \\infty $$\n\n我们的估计量不是 $\\bar{X}_n$，而是它的一个函数：$\\hat{\\lambda}_n = 1/\\bar{X}_n$。为了处理随机变量函数的收敛性，我们使用连续映射定理（CMT）。连续映射定理指出，如果一个随机变量序列 $Y_n$ 依概率收敛于一个常数 $c$（即 $Y_n \\xrightarrow{p} c$），并且函数 $g$ 在点 $c$ 处是连续的，那么经过变换的随机变量序列 $g(Y_n)$ 就依概率收敛于 $g(c)$（即 $g(Y_n) \\xrightarrow{p} g(c)$）。\n\n在这个问题中，我们的随机变量序列是 $Y_n = \\bar{X}_n$，它依概率收敛于常数 $c = 1/\\lambda$。我们的函数是 $g(y) = 1/y$。这个函数在所有 $y \\neq 0$ 处都是连续的。由于 $\\lambda > 0$，常数 $c = 1/\\lambda$ 也大于0，因此函数 $g(y)$ 在 $c=1/\\lambda$ 处是连续的。\n\n应用连续映射定理：\n$$ \\hat{\\lambda}_n = g(\\bar{X}_n) \\xrightarrow{p} g\\left(\\frac{1}{\\lambda}\\right) $$\n现在，我们计算 $g(1/\\lambda)$：\n$$ g\\left(\\frac{1}{\\lambda}\\right) = \\frac{1}{(1/\\lambda)} = \\lambda $$\n因此，我们证明了 $\\hat{\\lambda}_n \\xrightarrow{p} \\lambda$，这正是相合性的定义。\n\n这一推理思路与选项E完全吻合。\n\n我们来分析一下其他选项为什么不正确：\n- **A：** 中心极限定理描述的是依*分布*收敛（收敛于正态分布），而不是依*概率*收敛（收敛于一个常数）。相合性是由依概率收敛定义的。这个推理是有缺陷的。\n- **B：** 这个陈述错误地声称 $\\bar{X}_n$ 收敛于 $\\lambda$。弱大数定律指出 $\\bar{X}_n$ 收敛于分布的均值，即 $E[X] = 1/\\lambda$，而不是 $\\lambda$。这导致了 $\\hat{\\lambda}_n$ 收敛于 $1/\\lambda$ 的矛盾结论。\n- **C：** 这个陈述声称该估计量是无偏的。无偏性（$E[\\hat{\\theta}_n] = \\theta$）与相合性是不同的性质。虽然某些无偏估计量是相合的，但这并非普遍规律，一个性质并不能自动推出另一个。此外，对于指数分布，由于 Jensen 不等式，因为 $1/y$ 是凸函数，所以 $E[1/\\bar{X}_n] > 1/E[\\bar{X}_n] = \\lambda$，因此 $E[\\hat{\\lambda}_n] = E[1/\\bar{X}_n] \\neq \\lambda$。所以该陈述的前提是错误的。\n- **D：** 这个陈述提到 $\\text{Var}(\\hat{\\lambda}_n) \\to 0$。相合性的一个充分条件是，当 $n \\to \\infty$ 时，估计量的偏差和方差都趋于零。仅仅说明方差趋于零是不完整的。还必须证明偏差 $B(\\hat{\\lambda}_n) = E[\\hat{\\lambda}_n] - \\lambda$ 也趋于零。虽然对于这个估计量来说这两个条件都成立，但声称方差趋于零*本身就是一个完整的证明*是错误的。选项E中的推理更直接、更基本。\n\n因此，在所有选项中，唯一正确且完整的理由是E。", "answer": "$$\\boxed{E}$$", "id": "1909316"}]}