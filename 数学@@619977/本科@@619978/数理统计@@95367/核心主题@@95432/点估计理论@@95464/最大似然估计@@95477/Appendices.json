{"hands_on_practices": [{"introduction": "最大似然估计的基本思想是找到一个参数值，使得我们观测到的数据出现的概率最大。当参数的可能取值是有限的几个离散值时，我们可以直接计算每个参数值对应的似然函数值，然后选出最大的那个。这个练习将通过一个简单的伯努利试验模型来实践这一基本概念，这是许多统计分析的基础。[@problem_id:1933649]", "problem": "一位材料科学家正在测试一种新型非易失性存储单元在一年内的数据保持可靠性。将一个比特存入并在一年后读出的过程被建模为一系列独立的伯努利试验。“成功”被定义为该比特被正确读出且没有损坏。对于任何给定的试验，其成功概率由参数 $\\theta$ 表示。\n\n基于该特定单元设计的量子隧穿数据退化模型，首席工程师假设 $\\theta$ 的真实值被限制在一个离散的可能性集合中：$\\{0.1, 0.5, 0.9\\}$。\n\n为了检验这一假设并估计该参数，研究人员对10个相同的存储单元进行了一项实验。一年后，发现其中8个单元正确地保持了其数据（即，观测到8次成功）。\n\n给定这一实验结果，参数 $\\theta$ 的最大似然估计(MLE)是什么？", "solution": "我们将结果建模为二项似然。对于单个参数值 $\\theta$，在 $n=10$ 次试验和 $k=8$ 次成功的情况下，其似然为\n$$\nL(\\theta)\\propto \\theta^{k}(1-\\theta)^{n-k}=\\theta^{8}(1-\\theta)^{2},\n$$\n其中，该比例关系忽略了对所有 $\\theta$ 值都相同的二项式系数 $\\binom{10}{8}$。\n\n候选集为 $\\{0.1,0.5,0.9\\}$。计算未归一化的似然值：\n- 对于 $\\theta=0.1$：\n$$\nL(0.1)\\propto (0.1)^{8}(0.9)^{2}=\\left(\\frac{1}{10}\\right)^{8}\\left(\\frac{9}{10}\\right)^{2}=\\frac{9^{2}}{10^{10}}.\n$$\n- 对于 $\\theta=0.5$：\n$$\nL(0.5)\\propto (0.5)^{8}(0.5)^{2}=\\left(\\frac{1}{2}\\right)^{10}=\\frac{1}{2^{10}}.\n$$\n- 对于 $\\theta=0.9$：\n$$\nL(0.9)\\propto (0.9)^{8}(0.1)^{2}=\\left(\\frac{9}{10}\\right)^{8}\\left(\\frac{1}{10}\\right)^{2}=\\frac{9^{8}}{10^{10}}.\n$$\n\n比较 $L(0.9)$ 和 $L(0.1)$：\n$$\n\\frac{L(0.9)}{L(0.1)}=\\frac{9^{8}/10^{10}}{9^{2}/10^{10}}=9^{6}>1,\n$$\n所以 $L(0.9)>L(0.1)$。\n\n比较 $L(0.9)$ 和 $L(0.5)$：\n$$\n\\frac{L(0.9)}{L(0.5)}=\\frac{9^{8}/10^{10}}{1/2^{10}}=\\frac{9^{8}2^{10}}{10^{10}}=\\frac{9^{8}}{5^{10}}=\\left(\\frac{9^{4}}{5^{5}}\\right)^{2}.\n$$\n因为 $9^{4}=6561$ 且 $5^{5}=3125$，我们有 $9^{4}>5^{5}$，因此 $\\left(\\frac{9^{4}}{5^{5}}\\right)^{2}>1$，所以 $L(0.9)>L(0.5)$。\n\n因此，$L(0.9)$ 超过了所有其他候选值的似然，最大似然估计为 $\\hat{\\theta}=0.9$。", "answer": "$$\\boxed{0.9}$$", "id": "1933649"}, {"introduction": "对于连续的参数空间，逐一比较显然是不可行的。在这种更常见的情况下，我们通常通过微积分来最大化对数似然函数——即找到其导数为零的点。本练习将应用这一标准且强大的技术来估计瑞利分布（Rayleigh distribution）的参数，该分布在物理和工程领域中被广泛用于信号建模。[@problem_id:1933625]", "problem": "在通信理论中，窄带高斯噪声信号的包络通常使用瑞利分布（Rayleigh distribution）进行建模。一位工程师正在研究一组$n$个独立的信号幅度测量值，记为 $x_1, x_2, \\dots, x_n$。假设这些测量值是来自瑞利分布的一个随机样本，其概率密度函数 (PDF) 如下所示：\n$$f(x; \\sigma) = \\frac{x}{\\sigma^2} \\exp\\left(-\\frac{x^2}{2\\sigma^2}\\right)$$\n其中 $x \\ge 0$ 且 $\\sigma > 0$。参数 $\\sigma$ 是一个与噪声功率相关的未知尺度参数。\n\n试确定参数 $\\sigma$ 的最大似然估计量 (MLE)，记为 $\\hat{\\sigma}$，并用样本数据 $x_1, x_2, \\dots, x_n$ 表示。", "solution": "目标是求出瑞利分布参数 $\\sigma$ 的最大似然估计量 (MLE)。设随机样本为 $X_1, X_2, \\dots, X_n$，其观测值为 $x_1, x_2, \\dots, x_n$。\n\n首先，我们构建似然函数 $L(\\sigma)$，它是样本的联合概率密度函数。由于观测值是独立同分布的，似然函数是各个概率密度函数的乘积：\n$$L(\\sigma | x_1, \\dots, x_n) = \\prod_{i=1}^{n} f(x_i; \\sigma) = \\prod_{i=1}^{n} \\frac{x_i}{\\sigma^2} \\exp\\left(-\\frac{x_i^2}{2\\sigma^2}\\right)$$\n\n为了简化最大化过程，我们使用似然函数的自然对数，即对数似然函数 $\\ell(\\sigma) = \\ln(L(\\sigma))$。取对数可以将乘积转化为求和：\n$$\\ell(\\sigma) = \\ln\\left( \\prod_{i=1}^{n} \\frac{x_i}{\\sigma^2} \\exp\\left(-\\frac{x_i^2}{2\\sigma^2}\\right) \\right)$$\n利用对数的性质 $\\ln(ab) = \\ln(a) + \\ln(b)$ 和 $\\ln(a/b) = \\ln(a) - \\ln(b)$，我们得到：\n$$\\ell(\\sigma) = \\sum_{i=1}^{n} \\ln\\left( \\frac{x_i}{\\sigma^2} \\exp\\left(-\\frac{x_i^2}{2\\sigma^2}\\right) \\right)$$\n$$\\ell(\\sigma) = \\sum_{i=1}^{n} \\left[ \\ln(x_i) - \\ln(\\sigma^2) + \\ln\\left(\\exp\\left(-\\frac{x_i^2}{2\\sigma^2}\\right)\\right) \\right]$$\n$$\\ell(\\sigma) = \\sum_{i=1}^{n} \\left[ \\ln(x_i) - 2\\ln(\\sigma) - \\frac{x_i^2}{2\\sigma^2} \\right]$$\n我们可以将求和项分开：\n$$\\ell(\\sigma) = \\sum_{i=1}^{n} \\ln(x_i) - \\sum_{i=1}^{n} 2\\ln(\\sigma) - \\sum_{i=1}^{n} \\frac{x_i^2}{2\\sigma^2}$$\n第二项不依赖于索引 $i$，因此它变为 $2n\\ln(\\sigma)$。第三项可以将求和符号移到分数内部：\n$$\\ell(\\sigma) = \\sum_{i=1}^{n} \\ln(x_i) - 2n\\ln(\\sigma) - \\frac{1}{2\\sigma^2} \\sum_{i=1}^{n} x_i^2$$\n\n为了找到使 $\\ell(\\sigma)$ 最大化的 $\\sigma$ 值，我们对 $\\ell(\\sigma)$ 关于 $\\sigma$ 求导，并令其等于零。\n$$\\frac{d\\ell}{d\\sigma} = \\frac{d}{d\\sigma} \\left( \\sum_{i=1}^{n} \\ln(x_i) - 2n\\ln(\\sigma) - \\frac{1}{2\\sigma^2} \\sum_{i=1}^{n} x_i^2 \\right)$$\n第一项相对于 $\\sigma$ 是一个常数，所以其导数为零。对于第二项，$\\frac{d}{d\\sigma}(-2n\\ln(\\sigma)) = -\\frac{2n}{\\sigma}$。对于第三项，我们使用幂法则，将 $\\sigma^{-2}$ 处理：\n$$\\frac{d}{d\\sigma} \\left(-\\frac{1}{2}\\sigma^{-2} \\sum_{i=1}^{n} x_i^2\\right) = -\\frac{1}{2} (-2\\sigma^{-3}) \\sum_{i=1}^{n} x_i^2 = \\frac{1}{\\sigma^3}\\sum_{i=1}^{n} x_i^2$$\n将这些项合并，我们得到完整的导数：\n$$\\frac{d\\ell}{d\\sigma} = -\\frac{2n}{\\sigma} + \\frac{1}{\\sigma^3} \\sum_{i=1}^{n} x_i^2$$\n\n现在，我们将导数设为零，求解 $\\sigma$。这个解就是最大似然估计量 MLE，我们记为 $\\hat{\\sigma}$。\n$$-\\frac{2n}{\\hat{\\sigma}} + \\frac{1}{\\hat{\\sigma}^3} \\sum_{i=1}^{n} x_i^2 = 0$$\n$$\\frac{1}{\\hat{\\sigma}^3} \\sum_{i=1}^{n} x_i^2 = \\frac{2n}{\\hat{\\sigma}}$$\n假设 $\\hat{\\sigma} \\ne 0$，我们可以在等式两边同乘以 $\\hat{\\sigma}^3$：\n$$\\sum_{i=1}^{n} x_i^2 = 2n\\hat{\\sigma}^2$$\n求解 $\\hat{\\sigma}^2$：\n$$\\hat{\\sigma}^2 = \\frac{1}{2n} \\sum_{i=1}^{n} x_i^2$$\n由于参数 $\\sigma$ 必须为正，我们取其正平方根：\n$$\\hat{\\sigma} = \\sqrt{\\frac{1}{2n} \\sum_{i=1}^{n} x_i^2}$$\n为了确认这是一个最大值，我们可以检查二阶导数（在该点应为负值），但对于这样一个标准问题，我们可以确信这就是最大似然估计量。MLE 的表达式 $\\hat{\\sigma}$ 即为最终答案。", "answer": "$$\\boxed{\\sqrt{\\frac{1}{2n} \\sum_{i=1}^{n} x_i^2}}$$", "id": "1933625"}, {"introduction": "然而，我们必须注意，基于微积分的方法并非万能。有时，似然函数的最大值会出现在参数空间的边界，或者函数在该点不可导。这个问题，有时被称为“德国坦克问题”，是一个经典的例子。它要求我们必须仔细分析似然函数的具体形式和行为，而不是简单地套用求导方法，来找到均匀分布的参数估计。[@problem_id:1933607]", "problem": "一家科技公司正在测试一支新的自动驾驶送货机器人车队。每个机器人被分配一个来自集合 $\\{1, 2, \\dots, N\\}$ 的唯一序列号，其中车队中的机器人总数 $N$ 是一个未知参数。一个质量控制团队通过随机选择 $n$ 个机器人并记录它们的序列号来进行抽查。设这些观察到的序列号为 $\\{X_1, X_2, \\dots, X_n\\}$，这可以被视为来自 $\\{1, 2, \\dots, N\\}$ 上离散均匀分布的一个独立同分布的随机样本。\n\n该团队使用最大似然估计量 (MLE)，记为 $\\hat{N}$，来估计机器人的总数 $N$。已知该估计量是有偏的。确定该估计量偏差的一个近似值，其偏差定义为 $B(\\hat{N}) = E[\\hat{N}] - N$。该近似值应在机器人总数 $N$ 远大于样本量 $n$ 的情况下有效。你的最终答案应该是一个用 $N$ 和 $n$ 表示的表达式。", "solution": "设 $X_{1},\\dots,X_{n}$ 是来自 $\\{1,2,\\dots,N\\}$ 上离散均匀分布的独立同分布样本。令 $M := X_{(n)} = \\max\\{X_{1},\\dots,X_{n}\\}$。\n\n1) 最大似然估计量：\n给定样本，关于 $N$ (视为一个整数参数) 的似然函数是\n$$\nL(N) = \\prod_{i=1}^{n} \\frac{1}{N}\\,\\mathbf{1}\\{1 \\leq X_{i} \\leq N\\}\n= N^{-n}\\,\\mathbf{1}\\{M \\leq N\\}.\n$$\n作为 $N$ 的函数，该函数仅在 $N \\geq M$ 时非零，并且在该定义域上是 $N$ 的递减函数，因此最大化该函数的值是\n$$\n\\hat{N} = M.\n$$\n\n2) $M$ 的分布和期望：\n对于 $m \\in \\{1,\\dots,N\\}$，\n$$\n\\Pr(M \\leq m) = \\Pr(X_{1} \\leq m,\\dots,X_{n} \\leq m) = \\left(\\frac{m}{N}\\right)^{n}.\n$$\n因此，根据非负整数值随机变量的尾和公式，\n$$\nE[M] = \\sum_{m=1}^{N} \\Pr(M \\geq m)\n= \\sum_{m=1}^{N} \\left[1 - \\left(\\frac{m-1}{N}\\right)^{n}\\right]\n= N - \\sum_{k=0}^{N-1} \\left(\\frac{k}{N}\\right)^{n}.\n$$\n\n3) 大$N$近似 (固定 $n$ 且 $N \\gg n$)：\n该和是 $\\int_{0}^{1} x^{n}\\,dx$ 的一个黎曼和，因此\n$$\n\\sum_{k=0}^{N-1} \\left(\\frac{k}{N}\\right)^{n} \\approx N \\int_{0}^{1} x^{n}\\,dx = \\frac{N}{n+1}.\n$$\n于是，\n$$\nE[\\hat{N}] = E[M] \\approx N - \\frac{N}{n+1} = \\frac{n}{n+1}\\,N.\n$$\n\n4) 偏差：\n根据定义 $B(\\hat{N}) = E[\\hat{N}] - N$，所以对于 $N \\gg n$，\n$$\nB(\\hat{N}) \\approx -\\frac{N}{n+1}.\n$$\n这就给出了在 $N$ 远大于 $n$ 的情况下，用 $N$ 和 $n$ 表示的所需近似值。", "answer": "$$\\boxed{-\\frac{N}{n+1}}$$", "id": "1933607"}]}