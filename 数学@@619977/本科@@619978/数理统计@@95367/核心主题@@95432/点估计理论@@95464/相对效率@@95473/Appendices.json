{"hands_on_practices": [{"introduction": "在统计学中，我们常常面临一个问题：对于同一个未知参数，可能存在多种不同的估计方法。那么，我们应该如何选择“最好”的那个？此练习通过一个关于电池寿命的实际场景，引导我们比较两种不同的估计量——一种基于样本均值，另一种基于样本最大值。通过计算它们的相对效率，你将亲身体会到，对于特定的数据分布（如本例中的均匀分布），一个看似不寻常的估计量（基于最大值）可能远比我们常用的样本均值更为有效。[@problem_id:1951462]", "problem": "一家制造商正在测试一种新型固态电池。电池的寿命（用随机变量 $X$ 表示）假定服从区间 $[0, \\theta]$ 上的均匀分布，其中 $\\theta$ 是未知的最大可能寿命。为了估计 $\\theta$，一个由 $n$ 个电池组成的随机样本 $X_1, X_2, \\dots, X_n$ 被测试直至失效。\n\n针对 $\\theta$ 提出了两种不同的估计量：\n1. 第一个估计量 $T_1$ 定义为样本均值的两倍：$T_1 = 2\\bar{X}$，其中 $\\bar{X} = \\frac{1}{n}\\sum_{i=1}^{n} X_i$。\n2. 第二个估计量 $T_2$ 是通过对样本最大值 $X_{(n)} = \\max(X_1, X_2, \\dots, X_n)$ 进行缩放来构造的，以使 $T_2$ 成为 $\\theta$ 的一个无偏估计量。\n\n计算 $T_1$ 相对于 $T_2$ 的相对效率。请将答案表示为样本大小 $n$ 的函数。", "solution": "设 $X_{1},\\dots,X_{n}$ 是来自 $\\mathrm{Uniform}(0,\\theta)$ 分布的独立同分布 (i.i.d.) 样本。那么单个观测值的均值和方差为\n$$\n\\mathbb{E}[X_{i}]=\\frac{\\theta}{2},\\qquad \\mathrm{Var}(X_{i})=\\frac{\\theta^{2}}{12}.\n$$\n对于样本均值 $\\bar{X}=\\frac{1}{n}\\sum_{i=1}^{n}X_{i}$，根据期望的线性性质和独立性，\n$$\n\\mathbb{E}[\\bar{X}]=\\frac{\\theta}{2},\\qquad \\mathrm{Var}(\\bar{X})=\\frac{1}{n}\\mathrm{Var}(X_{i})=\\frac{\\theta^{2}}{12n}.\n$$\n第一个估计量是 $T_{1}=2\\bar{X}$，所以\n$$\n\\mathbb{E}[T_{1}]=2\\,\\mathbb{E}[\\bar{X}]=\\theta,\\qquad \\mathrm{Var}(T_{1})=4\\,\\mathrm{Var}(\\bar{X})=\\frac{\\theta^{2}}{3n}.\n$$\n\n设 $X_{(n)}=\\max(X_{1},\\dots,X_{n})$ 表示样本最大值。对于 $X_{i}\\sim \\mathrm{Uniform}(0,\\theta)$，经过缩放的最大值 $X_{(n)}/\\theta$ 服从 $\\mathrm{Beta}(n,1)$ 分布。因此\n$$\n\\mathbb{E}[X_{(n)}]=\\theta\\,\\frac{n}{n+1},\\qquad \\mathrm{Var}\\!\\left(X_{(n)}\\right)=\\theta^{2}\\,\\frac{n}{(n+1)^{2}(n+2)}.\n$$\n为了使 $T_{2}$ 成为无偏估计量，定义 $T_{2}=c\\,X_{(n)}$，并选择 $c$ 使得 $\\mathbb{E}[T_{2}]=\\theta$。利用 $\\mathbb{E}[X_{(n)}]=\\theta\\,\\frac{n}{n+1}$，我们得到\n$$\nc\\,\\theta\\,\\frac{n}{n+1}=\\theta\\;\\;\\Rightarrow\\;\\; c=\\frac{n+1}{n},\n$$\n所以\n$$\nT_{2}=\\frac{n+1}{n}\\,X_{(n)},\\qquad \\mathrm{Var}(T_{2})=\\left(\\frac{n+1}{n}\\right)^{2}\\mathrm{Var}\\!\\left(X_{(n)}\\right)=\\left(\\frac{n+1}{n}\\right)^{2}\\theta^{2}\\frac{n}{(n+1)^{2}(n+2)}=\\frac{\\theta^{2}}{n(n+2)}.\n$$\n\n对于两个无偏估计量，$T_{1}$ 相对于 $T_{2}$ 的相对效率定义为\n$$\n\\mathrm{RE}(T_{1}\\text{ w.r.t. }T_{2})=\\frac{\\mathrm{Var}(T_{2})}{\\mathrm{Var}(T_{1})}.\n$$\n代入上面推导出的方差，可得\n$$\n\\mathrm{RE}(T_{1}\\text{ w.r.t. }T_{2})=\\frac{\\theta^{2}/\\bigl(n(n+2)\\bigr)}{\\theta^{2}/(3n)}=\\frac{3}{n+2}.\n$$\n这就将相对效率表示为了 $n$ 的函数。", "answer": "$$\\boxed{\\frac{3}{n+2}}$$", "id": "1951462"}, {"introduction": "当拥有多个信息来源时，简单地选择其中一个并非总是最佳策略。更明智的做法可能是将它们结合起来。本练习探讨了如何通过线性组合两种相关的无偏估计量来构造一个更优的新估计量。你将推导出最小化组合估计量方差的最优权重，并分析这种组合带来的效率提升。这项实践不仅是一个理论计算，它揭示了在工程和科学研究中融合多个测量结果以获得更高精度的核心思想。[@problem_id:1951437]", "problem": "一位材料科学家正在开发一类新型半导体晶圆，需要精确估计其平均杂质浓度 $\\theta$。有两种不同的测量系统可用。系统 A 产生 $\\theta$ 的一个无偏估计量 $T_1$，系统 B 产生 $\\theta$ 的另一个无偏估计量 $T_2$。根据历史数据，已知这些估计量的方差为 $\\text{Var}(T_1) = \\sigma_1^2$ 和 $\\text{Var}(T_2) = \\sigma_2^2$。由于影响两个系统的共同环境因素，这些估计量不是独立的，且它们的相关系数为 $\\text{Corr}(T_1, T_2) = \\rho$，其中 $|\\rho| < 1$。\n\n为了改进估计，提出了一个组合线性估计量：$T_C = w T_1 + (1-w) T_2$，其中 $w$ 是一个实值权重。\n\n你的任务是找到该组合估计量的最优配置。确定使 $T_C$ 的方差最小化的最优权重 $w_{opt}$ 的表达式。然后，求出这个最优组合估计量 $T_{C,opt}$ 相对于估计量 $T_1$ 的相对效率的表达式。相对效率定义为比率 $\\text{Eff}(T_{C,opt}, T_1) = \\frac{\\text{Var}(T_1)}{\\text{Var}(T_{C,opt})}$。\n\n将你的最终答案表示为一个包含两个元素的行矩阵：第一个元素是 $w_{opt}$ 的表达式，第二个元素是相对效率的表达式。", "solution": "组合估计量为 $T_{C}=w T_{1}+(1-w) T_{2}$。由于 $T_{1}$ 和 $T_{2}$ 都是 $\\theta$ 的无偏估计量，且权重之和为一，因此 $T_{C}$ 是无偏的：$\\mathbb{E}[T_{C}]=w \\theta+(1-w)\\theta=\\theta$。\n\n$T_{C}$ 的方差使用 $\\text{Cov}(T_{1},T_{2})=\\rho \\sigma_{1}\\sigma_{2}$：\n$$\n\\text{Var}(T_{C})=\\text{Var}\\big(w T_{1}+(1-w) T_{2}\\big)\n=w^{2}\\sigma_{1}^{2}+(1-w)^{2}\\sigma_{2}^{2}+2 w(1-w)\\rho \\sigma_{1}\\sigma_{2}.\n$$\n定义 $V(w)=w^{2}\\sigma_{1}^{2}+(1-w)^{2}\\sigma_{2}^{2}+2 w(1-w)\\rho \\sigma_{1}\\sigma_{2}$。求导并令其为零：\n$$\n\\frac{dV}{dw}=2 w \\sigma_{1}^{2}-2(1-w)\\sigma_{2}^{2}+2(1-2w)\\rho \\sigma_{1}\\sigma_{2}=0.\n$$\n这可以化简为\n$$\nw\\big(\\sigma_{1}^{2}+\\sigma_{2}^{2}-2\\rho \\sigma_{1}\\sigma_{2}\\big)+\\big(\\rho \\sigma_{1}\\sigma_{2}-\\sigma_{2}^{2}\\big)=0,\n$$\n所以最优权重是\n$$\nw_{\\text{opt}}=\\frac{\\sigma_{2}^{2}-\\rho \\sigma_{1}\\sigma_{2}}{\\sigma_{1}^{2}+\\sigma_{2}^{2}-2\\rho \\sigma_{1}\\sigma_{2}}.\n$$\n二阶导数为\n$$\n\\frac{d^{2}V}{dw^{2}}=2\\big(\\sigma_{1}^{2}+\\sigma_{2}^{2}-2\\rho \\sigma_{1}\\sigma_{2}\\big)=2\\,\\text{Var}(T_{1}-T_{2})>0,\n$$\n因为 $|\\rho|<1$，确保了这是一个最小值。\n\n为了求出最小化后的方差，将 $V(w)$ 写成 $V(w)=a w^{2}+2 b w+c$ 的形式，其中\n$$\na=\\sigma_{1}^{2}+\\sigma_{2}^{2}-2\\rho \\sigma_{1}\\sigma_{2},\\quad b=-(\\sigma_{2}^{2}-\\rho \\sigma_{1}\\sigma_{2}),\\quad c=\\sigma_{2}^{2}.\n$$\n那么\n$$\n\\text{Var}(T_{C,\\text{opt}})=V(w_{\\text{opt}})=c-\\frac{b^{2}}{a}\n=\\frac{\\sigma_{1}^{2}\\sigma_{2}^{2}(1-\\rho^{2})}{\\sigma_{1}^{2}+\\sigma_{2}^{2}-2\\rho \\sigma_{1}\\sigma_{2}}.\n$$\n$T_{C,\\text{opt}}$ 相对于 $T_{1}$ 的相对效率是\n$$\n\\text{Eff}(T_{C,\\text{opt}},T_{1})=\\frac{\\text{Var}(T_{1})}{\\text{Var}(T_{C,\\text{opt}})}\n=\\frac{\\sigma_{1}^{2}}{\\dfrac{\\sigma_{1}^{2}\\sigma_{2}^{2}(1-\\rho^{2})}{\\sigma_{1}^{2}+\\sigma_{2}^{2}-2\\rho \\sigma_{1}\\sigma_{2}}}\n=\\frac{\\sigma_{1}^{2}+\\sigma_{2}^{2}-2\\rho \\sigma_{1}\\sigma_{2}}{\\sigma_{2}^{2}(1-\\rho^{2})}.\n$$", "answer": "$$\\boxed{\\begin{pmatrix}\\dfrac{\\sigma_{2}^{2}-\\rho \\sigma_{1}\\sigma_{2}}{\\sigma_{1}^{2}+\\sigma_{2}^{2}-2\\rho \\sigma_{1}\\sigma_{2}} & \\dfrac{\\sigma_{1}^{2}+\\sigma_{2}^{2}-2\\rho \\sigma_{1}\\sigma_{2}}{\\sigma_{2}^{2}(1-\\rho^{2})}\\end{pmatrix}}$$", "id": "1951437"}, {"introduction": "在真实的统计建模中，我们关心的参数（例如位置参数 $\\mu$）的估计精度，常常会受到其他未知参数（即“讨厌参数”，如尺度参数 $\\sigma$）的影响。本练习将带领你进入极大似然估计的渐进理论领域，使用费雪信息矩阵这一强大工具来量化这种影响。通过计算在尺度参数已知与未知两种情况下位置参数估计量的渐进相对效率，你将精确地衡量出由于缺乏对对讨厌参数的了解而付出的“效率代价”。这是一个更高级的实践，它将相对效率的概念与统计推断的根本极限联系了起来。[@problem_id:1951476]", "problem": "在统计建模中，估计量的效率会显著受到讨厌参数（nuisance parameters）存在的影响。考虑一个服从 Gumbel 分布的随机变量 $Y$，该分布是一个非对称的位置-尺度分布族。其概率密度函数由一个位置参数 $\\mu$ 和一个正的尺度参数 $\\sigma$ 参数化。\n\n对于单个观测值 $Y$，参数向量 $\\boldsymbol{\\theta} = (\\mu, \\sigma)^T$ 的费雪信息矩阵 (FIM) 由下式给出\n$$\nI(\\mu, \\sigma) = \\frac{1}{\\sigma^2}\n\\begin{pmatrix}\n1 & 1-\\gamma \\\\\n1-\\gamma & \\frac{\\pi^2}{6} + (1-\\gamma)^2\n\\end{pmatrix}\n$$\n其中 $\\gamma$ 是欧拉-马斯刻若尼常数 ($\\gamma \\approx 0.5772$)。由于 Gumbel 分布的非对称性，其非对角项是非零的。\n\n我们感兴趣的是估计位置参数 $\\mu$。基于 $n$ 个独立同分布的大样本观测值 $Y_1, \\dots, Y_n$，比较以下两种情况：\n1.  **尺度已知：** 尺度参数 $\\sigma$ 已知为某个值 $\\sigma_0$，我们只需要估计 $\\mu$。\n2.  **尺度未知：** $\\mu$ 和 $\\sigma$ 均未知，且必须同时进行估计。\n\n估计量的性能由其渐近方差来衡量。估计量 $\\hat{\\theta}_A$ 相对于另一个估计量 $\\hat{\\theta}_B$ 的渐近相对效率 (ARE) 定义为其渐近方差之比，即 $\\text{ARE}(\\hat{\\theta}_A, \\hat{\\theta}_B) = \\frac{\\text{Asymptotic Var}(\\hat{\\theta}_B)}{\\text{Asymptotic Var}(\\hat{\\theta}_A)}$。\n\n计算在“尺度未知”情况下 $\\mu$ 的最大似然估计量 (MLE) 相对于在“尺度已知”情况下 $\\mu$ 的 MLE 的渐近相对效率 (ARE)。将答案表示为用 $\\pi$ 和 $\\gamma$ 表示的闭式解析表达式。", "solution": "对于单个观测值，$\\boldsymbol{\\theta} = (\\mu,\\sigma)^{T}$ 的费雪信息矩阵 (FIM) 为\n$$\nI_{1}(\\mu,\\sigma) = \\frac{1}{\\sigma^{2}}\n\\begin{pmatrix}\n1 & 1-\\gamma \\\\\n1-\\gamma & \\frac{\\pi^{2}}{6} + (1-\\gamma)^{2}\n\\end{pmatrix},\n$$\n对于 $n$ 个独立同分布的观测值，该矩阵为 $I_{n}(\\mu,\\sigma) = n I_{1}(\\mu,\\sigma)$。\n\nMLE 的渐近正态性意味着，对于大的 $n$，联合 MLE 的渐近协方差矩阵是 $(I_{n})^{-1} = \\frac{1}{n} I_{1}^{-1}$，因此 $\\hat{\\mu}$ 的渐近方差等于 $\\frac{1}{n} I_{1}^{-1}$ 的 (1,1) 元。\n\n尺度 $\\sigma$ 已知：\n当 $\\sigma$ 已知时，$\\mu$ 的相关费雪信息是标量 $I_{1,\\mu\\mu} = \\sigma^{-2}$。因此，对于 $n$ 个观测值，MLE $\\hat{\\mu}$ 的渐近方差是\n$$\n\\operatorname{Avar}_{\\text{known}}(\\hat{\\mu}) = \\frac{1}{n I_{1,\\mu\\mu}} = \\frac{\\sigma^{2}}{n}.\n$$\n\n尺度 $\\sigma$ 未知：\n当 $\\mu$ 和 $\\sigma$ 均未知时，将每个观测值的 FIM 写为\n$$\nI_{1} = \\frac{1}{\\sigma^{2}} M,\\quad M =\n\\begin{pmatrix}\n1 & a \\\\\na & b\n\\end{pmatrix},\\quad a = 1-\\gamma,\\quad b = \\frac{\\pi^{2}}{6} + (1-\\gamma)^{2}.\n$$\n那么 $I_{1}^{-1} = \\sigma^{2} M^{-1}$。对于一个 $2\\times 2$ 矩阵，$M^{-1} = \\frac{1}{\\det(M)}\n\\begin{pmatrix}\nb & -a \\\\\n-a & 1\n\\end{pmatrix}$，所以 (1,1) 元是 $(M^{-1})_{11} = b/\\det(M)$。行列式为\n$$\n\\det(M) = 1\\cdot b - a^{2} = \\left(\\frac{\\pi^{2}}{6} + (1-\\gamma)^{2}\\right) - (1-\\gamma)^{2} = \\frac{\\pi^{2}}{6}.\n$$\n因此，\n$$\n(I_{1}^{-1})_{11} = \\sigma^{2} \\frac{b}{\\det(M)} = \\sigma^{2} \\frac{\\frac{\\pi^{2}}{6} + (1-\\gamma)^{2}}{\\frac{\\pi^{2}}{6}}\n= \\sigma^{2}\\left(1 + \\frac{6}{\\pi^{2}}(1-\\gamma)^{2}\\right).\n$$\n从而，对于 $n$ 个观测值，\n$$\n\\operatorname{Avar}_{\\text{unknown}}(\\hat{\\mu}) = \\frac{1}{n} (I_{1}^{-1})_{11}\n= \\frac{\\sigma^{2}}{n}\\left(1 + \\frac{6}{\\pi^{2}}(1-\\gamma)^{2}\\right).\n$$\n\n渐近相对效率：\n根据定义，对于估计量 A（尺度未知）相对于估计量 B（尺度已知）：\n$$\n\\text{ARE}(\\hat{\\mu}_{\\text{unknown}}, \\hat{\\mu}_{\\text{known}}) = \\frac{\\operatorname{Avar}_{\\text{known}}(\\hat{\\mu})}{\\operatorname{Avar}_{\\text{unknown}}(\\hat{\\mu})}\n= \\frac{\\sigma^{2}/n}{\\frac{\\sigma^{2}}{n}\\left(1 + \\frac{6}{\\pi^{2}}(1-\\gamma)^{2}\\right)}\n= \\frac{1}{1 + \\frac{6}{\\pi^{2}}(1-\\gamma)^{2}}\n= \\frac{\\pi^{2}}{\\pi^{2} + 6(1-\\gamma)^{2}}.\n$$\n这就给出了用 $\\pi$ 和 $\\gamma$ 表示的闭式表达式。", "answer": "$$\\boxed{\\frac{\\pi^{2}}{\\pi^{2} + 6\\left(1-\\gamma\\right)^{2}}}$$", "id": "1951476"}]}