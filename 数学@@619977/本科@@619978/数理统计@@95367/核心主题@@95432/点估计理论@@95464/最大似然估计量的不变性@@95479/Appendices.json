{"hands_on_practices": [{"introduction": "最大似然估计（MLE）的不变性原理最直接的应用之一，就是估计常见分布中参数的函数。本练习将以概率论的基石——二项分布为背景，但我们的目标不是估计成功概率 $p$ 本身，而是估计一个与之密切相关的重要量：其基础伯努利试验的方差 $p(1-p)$。通过这个练习，你将巩固寻找MLE并应用不变性原理的基本步骤。[@problem_id:1925576]", "problem": "在一家半导体制造厂，一位质量控制工程师正在评估某个特定光刻工艺的良率。该工艺设计用于生产大量相同的微芯片。工程师假设，每个生产出的芯片是有缺陷的（即次品）的概率为一个恒定但未知的常数 $p$，且与其他所有芯片的状况相互独立。为了估计与该概率相关联的方差，工程师从生产线上随机抽取了 $n$ 个芯片作为样本，并观察到其中恰好有 $x$ 个是次品。次品的数量 $x$ 可以被建模为来自二项分布 $B(n, p)$ 的单次观测，其中试验次数 $n$ 已知。\n\n其所对应的伯努利试验（即单个芯片是次品与否的结果）的方差由函数 $g(p) = p(1-p)$ 给出。你的任务是基于观测数据 $x$ 和已知样本大小 $n$，求出该方差 $p(1-p)$ 的最大似然估计量 (MLE)。请用一个关于 $x$ 和 $n$ 的符号表达式来表示你的答案。", "solution": "我们将 $x$ 建模为来自二项分布 $B(n,p)$ 的单次观测，其中 $n$ 已知，而 $p \\in [0,1]$ 未知。给定 $x$ 时，关于 $p$ 的似然函数为\n$$\nL(p \\mid x) = \\binom{n}{x} p^{x} (1-p)^{n-x}.\n$$\n最大化 $L$ 等价于最大化对数似然函数\n$$\n\\ell(p) = \\ln L(p \\mid x) = \\ln \\binom{n}{x} + x \\ln p + (n-x) \\ln(1-p).\n$$\n对 $p$ 求导并令其等于零：\n$$\n\\frac{d\\ell}{dp} = \\frac{x}{p} - \\frac{n-x}{1-p} = 0.\n$$\n求解可得，\n$$\n\\frac{x}{p} = \\frac{n-x}{1-p} \\;\\;\\Longrightarrow\\;\\; x(1-p) = (n-x)p \\;\\;\\Longrightarrow\\;\\; x - np = 0 \\;\\;\\Longrightarrow\\;\\; \\hat{p} = \\frac{x}{n}.\n$$\n二阶导数为\n$$\n\\frac{d^{2}\\ell}{dp^{2}} = -\\frac{x}{p^{2}} - \\frac{n-x}{(1-p)^{2}} < 0\n$$\n对于 $p \\in (0,1)$ 和 $x \\in \\{0,1,\\dots,n\\}$，该二阶导数小于0，这证实了我们得到的是一个最大值。对于边界情况 $x=0$ 或 $x=n$，其最大化估计量分别为 $\\hat{p}=0$ 和 $\\hat{p}=1$，这也与 $\\hat{p}=x/n$ 的结果一致。\n\n我们要求的是伯努利方差 $g(p) = p(1-p)$ 的最大似然估计量 (MLE)。根据最大似然估计量的不变性原则，$g(p)$ 的最大似然估计量是 $g(\\hat{p})$。因此，\n$$\n\\widehat{g(p)} \\;=\\; \\hat{p}\\bigl(1-\\hat{p}\\bigr) \\;=\\; \\frac{x}{n}\\left(1-\\frac{x}{n}\\right) \\;=\\; \\frac{x(n-x)}{n^{2}}.\n$$\n当 $x=0$ 或 $x=n$ 时，此表达式也能正确地得到结果0。", "answer": "$$\\boxed{\\frac{x(n-x)}{n^{2}}}$$", "id": "1925576"}, {"introduction": "尽管许多最大似然估计量是通过微积分求导得到的，但情况并非总是如此。本练习将探讨均匀分布，其参数 $\\theta$ 定义了支撑集的边界。你会发现，最大化似然函数需要仔细考虑其定义域，这会导出一个作为顺序统计量的MLE，而非微分方程的解。这个练习对于培养在不同情境下最大化似然函数的深刻理解至关重要，之后才能应用不变性原理。[@problem_id:1925562]", "problem": "设 $X_1, X_2, \\dots, X_n$ 是从区间 $(0, \\theta)$ 上的连续均匀分布中抽取的大小为 $n$ 的随机样本，其中 $\\theta > 0$ 是一个未知参数。任意单个观测值 $X_i$ 的概率密度函数为 $f(x | \\theta) = \\frac{1}{\\theta}$（对于 $0 < x < \\theta$），否则为 $f(x|\\theta) = 0$。\n\n设 $X_{(n)}$ 表示样本中的最大值，即 $X_{(n)} = \\max(X_1, X_2, \\dots, X_n)$。\n\n确定该分布方差的最大似然估计量 (MLE)。用 $X_{(n)}$ 和数值常数表示你的答案。", "solution": "我们首先写出样本的联合似然函数。对于来自 $(0,\\theta)$ 上均匀分布的独立观测值，\n$$\nL(\\theta \\mid x_{1},\\dots,x_{n})=\\prod_{i=1}^{n} f(x_{i}\\mid \\theta)=\\prod_{i=1}^{n}\\frac{1}{\\theta}\\,\\mathbf{1}_{\\{0<x_{i}<\\theta\\}}=\\theta^{-n}\\,\\mathbf{1}_{\\{\\theta\\geq x_{(n)}\\}},\n$$\n其中 $x_{(n)}=\\max\\{x_{1},\\dots,x_{n}\\}$。对于给定的数据，在区间 $[x_{(n)},\\infty)$ 上，$L(\\theta)$ 与 $\\theta^{-n}$ 成正比，其他情况下为零。由于当 $\\theta>0$ 时，$\\theta^{-n}$ 是关于 $\\theta$ 的严格递减函数，因此似然函数在 $\\theta$ 的最小允许值处达到最大，即\n$$\n\\hat{\\theta}_{\\text{MLE}}=X_{(n)}.\n$$\n\n接下来，我们计算单个 Uniform$(0,\\theta)$ 变量的方差。根据定义，\n$$\n\\mathbb{E}[X]=\\int_{0}^{\\theta} x\\,\\frac{1}{\\theta}\\,dx=\\frac{1}{\\theta}\\cdot\\frac{\\theta^{2}}{2}=\\frac{\\theta}{2},\\quad\n\\mathbb{E}[X^{2}]=\\int_{0}^{\\theta} x^{2}\\,\\frac{1}{\\theta}\\,dx=\\frac{1}{\\theta}\\cdot\\frac{\\theta^{3}}{3}=\\frac{\\theta^{2}}{3}.\n$$\n因此，\n$$\n\\operatorname{Var}(X)=\\mathbb{E}[X^{2}]-(\\mathbb{E}[X])^{2}=\\frac{\\theta^{2}}{3}-\\left(\\frac{\\theta}{2}\\right)^{2}=\\frac{\\theta^{2}}{12}.\n$$\n\n根据最大似然估计量的不变性，如果 $g(\\theta)$ 是参数的函数，那么 $g(\\theta)$ 的最大似然估计量是 $g(\\hat{\\theta}_{\\text{MLE}})$。令 $g(\\theta)=\\theta^{2}/12$，则方差的最大似然估计量为\n$$\n\\widehat{\\operatorname{Var}}_{\\text{MLE}}=\\frac{\\hat{\\theta}_{\\text{MLE}}^{2}}{12}=\\frac{X_{(n)}^{2}}{12}.\n$$", "answer": "$$\\boxed{\\frac{X_{(n)}^{2}}{12}}$$", "id": "1925562"}, {"introduction": "现实世界的数据往往需要比标准分布更复杂的模型。零膨胀泊松（ZIP）模型是处理含有过多零值计数数据集的强大工具，在生态学和经济学等领域有广泛应用。这个高级练习将挑战你在一个多参数环境中应用不变性原理。通过求解ZIP分布总体方差的MLE，你将看到该性质如何巧妙地简化了在复杂统计模型中对衍生量的估计过程。[@problem_id:1925553]", "problem": "一个随机变量 $Y$ 被称为服从参数为 $\\pi \\in [0, 1)$ 和 $\\lambda > 0$ 的零膨胀泊松 (Zero-Inflated Poisson, ZIP) 分布，如果其概率质量函数 (PMF) 由下式给出：\n$$\nP(Y=y) = \n\\begin{cases}\n\\pi + (1-\\pi)\\exp(-\\lambda) & \\text{若 } y=0 \\\\\n(1-\\pi) \\frac{\\lambda^y \\exp(-\\lambda)}{y!} & \\text{若 } y \\in \\{1, 2, 3, \\ldots\\}\n\\end{cases}\n$$\n其中，$\\pi$ 表示不源于泊松过程的额外零计数的概率，而 $\\lambda$ 是其基础泊松分布的均值。\n\n考虑从一个 ZIP 分布中抽取的随机样本 $y_1, y_2, \\ldots, y_n$。令 $\\bar{y} = \\frac{1}{n} \\sum_{i=1}^n y_i$ 为样本均值。参数 $\\pi$ 和 $\\lambda$ 是未知的。令 $\\hat{\\pi}$ 和 $\\hat{\\lambda}$ 分别表示它们的最大似然估计量 (MLE)。\n\n利用最大似然估计量的不变性，求该分布方差 $\\sigma^2 = \\text{Var}(Y)$ 的最大似然估计量。请将您的答案表示为关于样本均值 $\\bar{y}$ 和最大似然估计量 $\\hat{\\lambda}$ 的闭式解析表达式。", "solution": "对于一个参数为 $\\pi \\in [0,1)$ 和 $\\lambda > 0$ 的零膨胀泊松 (ZIP) 随机变量 $Y$，可写为 $Y = Z X$，其中 $Z \\sim \\text{Bernoulli}(1-\\pi)$，并且在 $Z=1$ 的条件下，$X \\sim \\text{Poisson}(\\lambda)$；否则 $Y=0$。使用这种混合表示：\n$$\n\\mathbb{E}[Y] = (1 - \\pi)\\lambda \\equiv \\mu,\n$$\n并且由于对于 $X \\sim \\text{Poisson}(\\lambda)$，有 $\\mathbb{E}[X^{2}] = \\lambda + \\lambda^{2}$，我们得到\n$$\n\\mathbb{E}[Y^{2}] = (1 - \\pi)\\mathbb{E}[X^{2}] = (1 - \\pi)(\\lambda + \\lambda^{2}).\n$$\n因此，\n$$\n\\operatorname{Var}(Y) = \\mathbb{E}[Y^{2}] - \\{\\mathbb{E}[Y]\\}^{2} = (1 - \\pi)\\lambda + (1 - \\pi)\\lambda^{2} - (1 - \\pi)^{2}\\lambda^{2} = (1 - \\pi)\\lambda\\{1 + \\pi\\lambda\\}.\n$$\n等价地，用 $\\mu = (1 - \\pi)\\lambda$ 来表示，注意到 $\\pi\\lambda = \\lambda - \\mu$，所以\n$$\n\\sigma^{2} = \\operatorname{Var}(Y) = \\mu\\{1 + \\lambda - \\mu\\}.\n$$\n\n根据最大似然估计量的不变性，将参数的最大似然估计量代入此函数即可得到 $\\sigma^{2}$ 的最大似然估计量。为了用样本均值 $\\bar{y}$ 和 $\\hat{\\lambda}$ 来表示结果，我们证明 $\\mu$ 的最大似然估计量等于 $\\bar{y}$。\n\n通过 $\\mu = (1 - \\pi)\\lambda$ 进行重新参数化，从而 $\\pi = 1 - \\mu/\\lambda$。令 $n_{0} = \\sum_{i=1}^{n} \\mathbf{1}\\{y_{i}=0\\}$。对数似然函数（忽略不含 $\\mu$ 的项）为\n$$\n\\ell(\\mu,\\lambda) = n_{0}\\ln\\!\\left(1 - \\frac{\\mu}{\\lambda}\\{1 - \\exp(-\\lambda)\\}\\right) + (n - n_{0})\\ln \\mu + C(\\lambda,y).\n$$\n对 $\\mu$ 求导并令其为零，得到\n$$\n\\frac{\\partial \\ell}{\\partial \\mu} = -\\,\\frac{n_{0}\\,\\{(1/\\lambda)(1 - \\exp(-\\lambda))\\}}{1 - \\frac{\\mu}{\\lambda}(1 - \\exp(-\\lambda))} + \\frac{n - n_{0}}{\\mu} = 0,\n$$\n由此得出\n$$\n(n - n_{0})\\lambda = \\mu\\,n\\,(1 - \\exp(-\\lambda)).\n$$\n从关于 $\\lambda$ 的得分方程，可以得到\n$$\n\\frac{n\\bar{y}}{\\lambda} = \\frac{n - n_{0}}{1 - \\exp(-\\lambda)}.\n$$\n结合这两个等式可得 $\\mu = \\bar{y}$。因此，在最大似然估计量处，$\\hat{\\mu} = (1 - \\hat{\\pi})\\hat{\\lambda} = \\bar{y}$，即，\n$$\n\\hat{\\pi} = 1 - \\frac{\\bar{y}}{\\hat{\\lambda}}.\n$$\n\n将不变性应用于 $\\sigma^{2} = \\mu(1 + \\lambda - \\mu)$，得到\n$$\n\\hat{\\sigma}^{2} = \\hat{\\mu}\\{1 + \\hat{\\lambda} - \\hat{\\mu}\\} = \\bar{y}\\{1 + \\hat{\\lambda} - \\bar{y}\\}.\n$$\n这是一个以 $\\bar{y}$ 和 $\\hat{\\lambda}$ 表示的闭式解析表达式。", "answer": "$$\\boxed{\\bar{y}\\left(1+\\hat{\\lambda}-\\bar{y}\\right)}$$", "id": "1925553"}]}