{"hands_on_practices": [{"introduction": "通过解决一个实际问题，开启我们的动手实践之旅。本练习将指导你为一个常见的连续分布（伽马分布）推导似然比检验（LRT）统计量。这个过程是应用似然比原理的核心，它要求你首先在整个参数空间内找到最大似然估计（MLE），然后在原假设成立的约束条件下再次寻找，最后构建它们的比值 [@problem_id:1930657]。熟练掌握这一基本流程，将为你解决更复杂的统计推断问题奠定坚实的基础。", "problem": "一位电信工程师正在对网络路由器上数据包的处理时间进行建模。根据该路由器的架构，处理单个数据包所需的时间 $X$（单位为毫秒）已知服从伽玛分布，其形状参数 $\\alpha  0$ 已知，而率参数 $\\beta  0$ 未知。其概率密度函数（PDF）由下式给出：\n$$f(x | \\alpha, \\beta) = \\frac{\\beta^{\\alpha}}{\\Gamma(\\alpha)} x^{\\alpha-1} \\exp(-\\beta x) \\quad \\text{for } x  0$$\n该工程师收集了一个大小为 $n$ 的数据包处理时间的随机样本 $X_1, X_2, \\dots, X_n$，这些样本可被视为独立同分布。她想要检验路由器是否在标称负载下运行，这对应于一个特定的率参数 $\\beta = \\beta_0$，其备择假设为路由器并非在该负载下运行。形式化的假设如下：\n$$H_0: \\beta = \\beta_0$$\n$$H_1: \\beta \\neq \\beta_0$$\n为该假设检验推导似然比检验（LRT）统计量 $\\lambda(x_1, \\dots, x_n)$。请将您的答案表示为样本大小 $n$、已知的形状参数 $\\alpha$、假设的率参数 $\\beta_0$ 以及样本均值 $\\bar{x} = \\frac{1}{n} \\sum_{i=1}^{n} x_i$ 的函数。", "solution": "对于来自 Gamma$(\\alpha,\\beta)$ 分布的独立观测值 $X_{1},\\dots,X_{n}$（其中 $\\alpha$ 已知，$\\beta$ 未知），其联合似然函数为\n$$\nL(\\beta \\mid x_{1},\\dots,x_{n})=\\prod_{i=1}^{n}\\frac{\\beta^{\\alpha}}{\\Gamma(\\alpha)}x_{i}^{\\alpha-1}\\exp(-\\beta x_{i})\n=\\frac{\\beta^{n\\alpha}}{\\Gamma(\\alpha)^{n}}\\left(\\prod_{i=1}^{n}x_{i}^{\\alpha-1}\\right)\\exp\\!\\left(-\\beta\\sum_{i=1}^{n}x_{i}\\right).\n$$\n令 $S=\\sum_{i=1}^{n}x_{i}=n\\bar{x}$。对数似然函数为\n$$\n\\ell(\\beta)=n\\alpha\\ln\\beta-n\\ln\\Gamma(\\alpha)+(\\alpha-1)\\sum_{i=1}^{n}\\ln x_{i}-\\beta S.\n$$\n通过对 $\\beta0$ 进行最大化，可得到无约束最大似然估计（MLE）：\n$$\n\\frac{\\partial \\ell}{\\partial \\beta}=\\frac{n\\alpha}{\\beta}-S=0\\quad\\Rightarrow\\quad \\hat{\\beta}=\\frac{n\\alpha}{S}=\\frac{\\alpha}{\\bar{x}}.\n$$\n似然比统计量为\n$$\n\\lambda(x_{1},\\dots,x_{n})=\\frac{\\sup_{\\beta=\\beta_{0}}L(\\beta\\mid x)}{\\sup_{\\beta0}L(\\beta\\mid x)}=\\frac{L(\\beta_{0}\\mid x)}{L(\\hat{\\beta}\\mid x)}.\n$$\n使用似然函数的形式，与 $\\beta$ 无关的项会消去，从而得到\n$$\n\\lambda(x_{1},\\dots,x_{n})=\\left(\\frac{\\beta_{0}}{\\hat{\\beta}}\\right)^{n\\alpha}\\exp\\!\\left(-(\\beta_{0}-\\hat{\\beta})S\\right).\n$$\n代入 $\\hat{\\beta}=\\alpha/\\bar{x}$ 和 $S=n\\bar{x}$ 可得\n$$\n\\lambda(x_{1},\\dots,x_{n})=\\left(\\frac{\\beta_{0}\\bar{x}}{\\alpha}\\right)^{n\\alpha}\\exp\\!\\left(n\\alpha-n\\beta_{0}\\bar{x}\\right).\n$$\n这就将 LRT 统计量表示为了 $n$、$\\alpha$、$\\beta_{0}$ 和 $\\bar{x}$ 的函数。", "answer": "$$\\boxed{\\left(\\frac{\\beta_{0}\\bar{x}}{\\alpha}\\right)^{n\\alpha}\\exp\\!\\left(n\\alpha-n\\beta_{0}\\bar{x}\\right)}$$", "id": "1930657"}, {"introduction": "掌握了如何构建检验统计量后，我们来探讨其如何转化为一个具体的决策规则。本练习关注一个关于伯努利试验成功概率的单边假设检验问题 [@problem_id:1930665]。通过分析似然比统计量$ \\lambda $与充分统计量（在此为成功次数$ k $）之间的函数关系，你将发现LRT如何自然地导出一个直观的拒绝域。这个练习揭示了抽象的LRT理论与“当观测到的成功次数足够多时拒绝原假设”这类简单实用的检验法则之间的深刻联系。", "problem": "一家大型在线流媒体服务公司的数据科学团队正在进行一项A/B测试，以确定新开发的推荐算法是否比当前算法更有效。历史上，用户观看旧算法推荐的电影的概率已知为 $p_0 = 0.30$。该团队希望新算法能提高这个概率。\n\n为了检验这一点，他们对一个大小为 $n$ 的随机用户样本进行了实验。对于每个用户 $i$，如果用户观看了新算法推荐的电影，则设随机变量 $X_i=1$，否则 $X_i=0$。观测值 $X_1, X_2, \\ldots, X_n$ 被假定为一个具有未知成功概率 $p$ 的独立同分布伯努利试验序列。\n\n该团队建立了一个正式的假设检验来评估证据。原假设 ($H_0$) 是新算法不比旧算法好，而备择假设 ($H_1$) 是新算法有所改进。假设被正式表述为：\n$$ H_0: p \\le p_0 \\quad \\text{versus} \\quad H_1: p  p_0 $$\n令 $k = \\sum_{i=1}^{n} X_i$ 为样本中观看了推荐电影的总用户数。该团队将使用似然比检验 (LRT) 来做出决策。\n\n下列哪项最能描述一个水平为 $\\alpha$ 的似然比检验的拒绝域的结构，其中 $k$ 是观测到的成功次数，$C, C_1, C_2$ 是依赖于 $n$, $p_0$ 和 $\\alpha$ 的常数？\n\nA. 拒绝域的形式为 $\\{k : k  C_1 \\text{ or } k  C_2\\}$。\n\nB. 拒绝域的形式为 $\\{k : k  C\\}$。\n\nC. 拒绝域的形式为 $\\{k : k  C\\}$。\n\nD. 拒绝域的形式为 $\\{k : |k - np_0|  C \\}$。\n\nE. 拒绝域的形式为 $\\{k : (k/n)  p_0 \\text{ and } (k/n)/p_0  C\\}$。", "solution": "我们将 $X_{1},\\ldots,X_{n}$ 建模为独立同分布的 $\\text{Bernoulli}(p)$ 随机变量，并令 $k=\\sum_{i=1}^{n}X_{i}$。基于 $k$ 的似然函数为，在不考虑不依赖于 $p$ 的因子 $\\binom{n}{k}$ 的情况下，\n$$\nL(p;k)=p^{k}(1-p)^{n-k}.\n$$\n我们通过似然比来检验 $H_{0}:p\\le p_{0}$ 与 $H_{1}:pp_{0}$：\n$$\n\\lambda(k)=\\frac{\\sup_{p\\le p_{0}}L(p;k)}{\\sup_{p\\in(0,1)}L(p;k)}.\n$$\n通过最大化 $\\ln L(p;k)=k\\ln p+(n-k)\\ln(1-p)$ 可以得到无约束最大似然估计（MLE）：\n$$\n\\frac{\\partial}{\\partial p}\\ln L(p;k)=\\frac{k}{p}-\\frac{n-k}{1-p}=0\\;\\;\\Rightarrow\\;\\;\\hat p=\\frac{k}{n}.\n$$\n在 $H_{0}$ 下，有约束最大似然估计为 $\\hat p_{0}=\\min\\!\\left\\{\\frac{k}{n},\\,p_{0}\\right\\}$。因此\n$$\n\\lambda(k)=\n\\begin{cases}\n1,  \\text{如果 } \\frac{k}{n}\\le p_{0}, \\\\[4pt]\n\\dfrac{p_{0}^{k}(1-p_{0})^{n-k}}{\\left(\\frac{k}{n}\\right)^{k}\\left(1-\\frac{k}{n}\\right)^{n-k}},  \\text{如果 } \\frac{k}{n}p_{0}.\n\\end{cases}\n$$\n为了确定拒绝域 $\\{\\lambda(k)\\le c\\}$，我们来分析当 $\\frac{k}{n}p_{0}$ 时 $\\lambda(k)$ 的情况。定义 $a=\\frac{k}{n}$。对于 $ap_{0}$，\n$$\n\\ln \\lambda(k)=n\\Big[a\\ln p_{0}+(1-a)\\ln(1-p_{0})-a\\ln a-(1-a)\\ln(1-a)\\Big].\n$$\n对 $a$ 求导：\n$$\n\\frac{1}{n}\\frac{\\mathrm{d}}{\\mathrm{d}a}\\ln \\lambda(k)=\\ln p_{0}-\\ln(1-p_{0})-\\ln a+\\ln(1-a)=\\ln\\!\\left(\\frac{p_{0}}{1-p_{0}}\\cdot\\frac{1-a}{a}\\right).\n$$\n对于 $ap_{0}$，我们有 $\\frac{1-a}{a}\\frac{1-p_{0}}{p_{0}}$，因此对数是负的，并且 $\\lambda(k)$ 在 $\\{k/np_{0}\\}$ 上是关于 $a$（并因此关于 $k$）严格递减的。结合 $k/n\\le p_{0}$ 时 $\\lambda(k)=1$ 的情况，似然比检验会在 $k$ 值较大时拒绝原假设，即当 $k$ 超过某个临界值 $C$ 时拒绝。该临界值 $C$ 的选择要使检验水平为 $\\alpha$（考虑到离散性，边界上可能需要随机化）。\n\n因此，LRT 的拒绝域具有 $\\{k:kC\\}$ 的形式，这对应于选项 C。其他选项不合适：A 和 D 是适用于 $H_{1}:p\\ne p_{0}$ 的双侧区域，B 是适用于 $H_{1}:pp_{0}$ 的下尾区域，而 E 不代表此问题的标准 LRT 结构。", "answer": "$$\\boxed{C}$$", "id": "1930665"}, {"introduction": "似然比检验的强大之处在于其广泛的适用性，能够为许多复杂的统计方法提供理论基础。本练习将LRT应用于一个多样本问题：检验多个正态分布总体的均值是否相等，这在方差分析（ANOVA）中是一个核心问题 [@problem_id:1930651]。你将推导出检验统计量$ -2\\ln\\lambda $，并发现它与组间均值和总体均值之间的平方和有直接关系。这个过程不仅展示了LRT处理多参数问题的能力，也揭示了它作为如ANOVA等经典统计方法背后统一理论的身份。", "problem": "一个环境保护机构的任务是监测一个大型工业园区中特定污染物——细颗粒物（PM2.5）的浓度。为此，他们在不同位置部署了 $k$ 个独立的、同厂制造的空气质量传感器。设 $X_{ij}$ 为第 $i$ 个传感器的第 $j$ 次测量值，其中 $i=1, \\dots, k$ 且 $j=1, \\dots, n_i$。根据生产规格可知，任何传感器的测量值都服从一个具有共同已知方差 $\\sigma^2$ 的正态分布。然而，由于潜在的漂移或故障，每个传感器的平均读数 $\\mu_i$ 可能会有所不同。\n\n该机构希望检验所有传感器是否都得到了正确的校准，即它们是否具有相同的平均响应。正式的假设检验是：\n$H_0: \\mu_1 = \\mu_2 = \\dots = \\mu_k$\n对\n$H_a: \\text{至少有一个 } \\mu_i \\text{ 与其他不同。}$\n\n你的任务是确定广义似然比检验的检验统计量。设 $\\lambda$ 为广义似然比。对于大样本，该检验基于统计量 $-2\\ln\\lambda$。\n\n设 $\\bar{X}_i = \\frac{1}{n_i}\\sum_{j=1}^{n_i} X_{ij}$ 为第 $i$ 个传感器的样本均值，并设 $\\bar{X}_{..} = \\frac{1}{\\sum_{i=1}^k n_i} \\sum_{i=1}^k \\sum_{j=1}^{n_i} X_{ij}$ 为所有测量值的总均值。\n\n下列哪个表达式代表统计量 $-2\\ln\\lambda$？\n\nA. $\\frac{1}{\\sigma^2} \\sum_{i=1}^k n_i (\\bar{X}_i - \\bar{X}_{..})^2$\n\nB. $\\frac{1}{\\sigma^2} \\sum_{i=1}^k \\sum_{j=1}^{n_i} (X_{ij} - \\bar{X}_i)^2$\n\nC. $\\frac{1}{\\sigma^2} \\sum_{i=1}^k (\\bar{X}_i - \\bar{X}_{..})^2$\n\nD. $\\frac{1}{\\sigma^2} \\sum_{i=1}^k n_i (\\bar{X}_i)^2$\n\nE. $\\frac{\\sum_{i=1}^k n_i (\\bar{X}_i - \\bar{X}_{..})^2}{\\sum_{i=1}^k \\sum_{j=1}^{n_i} (X_{ij} - \\bar{X}_i)^2}$", "solution": "设 $N=\\sum_{i=1}^{k} n_{i}$。在模型 $X_{ij}\\sim \\mathcal{N}(\\mu_{i},\\sigma^{2})$（$X_{ij}$ 独立，$\\sigma^{2}$ 已知）下，参数 $\\{\\mu_{i}\\}_{i=1}^{k}$ 的似然函数为\n$$\nL(\\{\\mu_{i}\\})=(2\\pi\\sigma^{2})^{-N/2}\\exp\\!\\left(-\\frac{1}{2\\sigma^{2}}\\sum_{i=1}^{k}\\sum_{j=1}^{n_{i}}(X_{ij}-\\mu_{i})^{2}\\right).\n$$\n广义似然比为 $\\lambda=\\dfrac{\\sup_{H_{0}}L}{\\sup_{H_{1}}L}$，所以\n$$\n\\ln\\lambda=\\ln\\sup_{H_{0}}L-\\ln\\sup_{H_{1}}L.\n$$\n\n在 $H_{1}$ 下，每个 $\\mu_{i}$ 都是自由的。最大化似然函数等价于对每个 $\\mu_{i}$ 分别最小化 $\\sum_{j=1}^{n_{i}}(X_{ij}-\\mu_{i})^{2}$，得到最大似然估计（MLE） $\\hat{\\mu}_{i}=\\bar{X}_{i}$。因此\n$$\n\\sup_{H_{1}}L=(2\\pi\\sigma^{2})^{-N/2}\\exp\\!\\left(-\\frac{1}{2\\sigma^{2}}\\sum_{i=1}^{k}\\sum_{j=1}^{n_{i}}(X_{ij}-\\bar{X}_{i})^{2}\\right).\n$$\n\n在 $H_{0}$ 下，$\\mu_{1}=\\cdots=\\mu_{k}=\\mu$ 为共同均值。最大化似然函数等价于就 $\\mu$ 最小化 $\\sum_{i=1}^{k}\\sum_{j=1}^{n_{i}}(X_{ij}-\\mu)^{2}$，得到最大似然估计（MLE） $\\hat{\\mu}=\\bar{X}_{..}$。因此\n$$\n\\sup_{H_{0}}L=(2\\pi\\sigma^{2})^{-N/2}\\exp\\!\\left(-\\frac{1}{2\\sigma^{2}}\\sum_{i=1}^{k}\\sum_{j=1}^{n_{i}}(X_{ij}-\\bar{X}_{..})^{2}\\right).\n$$\n\n因此，\n$$\n\\ln\\lambda=-\\frac{1}{2\\sigma^{2}}\\left[\\sum_{i=1}^{k}\\sum_{j=1}^{n_{i}}(X_{ij}-\\bar{X}_{..})^{2}-\\sum_{i=1}^{k}\\sum_{j=1}^{n_{i}}(X_{ij}-\\bar{X}_{i})^{2}\\right],\n$$\n所以\n$$\n-2\\ln\\lambda=\\frac{1}{\\sigma^{2}}\\left[\\sum_{i=1}^{k}\\sum_{j=1}^{n_{i}}(X_{ij}-\\bar{X}_{..})^{2}-\\sum_{i=1}^{k}\\sum_{j=1}^{n_{i}}(X_{ij}-\\bar{X}_{i})^{2}\\right].\n$$\n\n对每个 $i$ 使用标准的方差分析（ANOVA）分解：\n$$\n\\sum_{j=1}^{n_{i}}(X_{ij}-\\bar{X}_{..})^{2}=\\sum_{j=1}^{n_{i}}(X_{ij}-\\bar{X}_{i})^{2}+2(\\bar{X}_{i}-\\bar{X}_{..})\\sum_{j=1}^{n_{i}}(X_{ij}-\\bar{X}_{i})+n_{i}(\\bar{X}_{i}-\\bar{X}_{..})^{2}.\n$$\n由于 $\\sum_{j=1}^{n_{i}}(X_{ij}-\\bar{X}_{i})=0$，交叉项为零，所以\n$$\n\\sum_{j=1}^{n_{i}}(X_{ij}-\\bar{X}_{..})^{2}=\\sum_{j=1}^{n_{i}}(X_{ij}-\\bar{X}_{i})^{2}+n_{i}(\\bar{X}_{i}-\\bar{X}_{..})^{2}.\n$$\n对 $i$ 求和可得\n$$\n\\sum_{i=1}^{k}\\sum_{j=1}^{n_{i}}(X_{ij}-\\bar{X}_{..})^{2}-\\sum_{i=1}^{k}\\sum_{j=1}^{n_{i}}(X_{ij}-\\bar{X}_{i})^{2}=\\sum_{i=1}^{k}n_{i}(\\bar{X}_{i}-\\bar{X}_{..})^{2}.\n$$\n因此\n$$\n-2\\ln\\lambda=\\frac{1}{\\sigma^{2}}\\sum_{i=1}^{k}n_{i}(\\bar{X}_{i}-\\bar{X}_{..})^{2},\n$$\n这对应于选项A。", "answer": "$$\\boxed{A}$$", "id": "1930651"}]}