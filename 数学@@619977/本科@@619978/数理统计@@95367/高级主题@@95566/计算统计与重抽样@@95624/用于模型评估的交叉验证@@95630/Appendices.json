{"hands_on_practices": [{"introduction": "掌握交叉验证的第一步是理解其核心机制——数据分割。这个练习将带你亲手计算在K折交叉验证中，当数据集大小无法被折数整除时，训练集和验证集的大小如何确定。通过这个基础计算，你将对交叉验证过程中数据的流动有一个具体而清晰的认识。[@problem_id:1912440]", "problem": "一位数据科学家正在处理一个包含 $n=97$ 个独立观测值的数据集。为了评估一个机器学习模型的泛化性能，他们决定采用 $k$ 折交叉验证程序，其中 $k=10$。\n\n在这种方法中，整个数据集首先被划分为 $k$ 个不重叠的子集，称为“折”。由于观测总数 $n$ 不能被折数 $k$ 整除，因此创建的各折的大小会尽可能相等。具体来说，一些折将包含 $\\lfloor n/k \\rfloor$ 个观测值，而其余的折将包含 $\\lceil n/k \\rceil$ 个观测值。\n\n交叉验证过程接着由 $k$ 次迭代组成。在每次迭代中，会有一个不同的折被留出作为验证集，其余的 $k-1$ 个折被合并起来构成训练集。因此，训练集的大小在不同迭代中可能会有轻微的变化。\n\n确定在此过程的 10 次迭代中，可能遇到的训练集的最小可能大小。", "solution": "我们已知总观测值为 $n=97$，折数为 $k=10$。在 $k$ 折交叉验证中，数据集被划分为 $k$ 个大小尽可能相等的折，这意味着一些折的大小为 $\\lfloor n/k \\rfloor$，其余折的大小为 $\\lceil n/k \\rceil$。\n\n计算基础折的大小：\n$$\n\\left\\lfloor \\frac{n}{k} \\right\\rfloor = \\left\\lfloor \\frac{97}{10} \\right\\rfloor = 9, \\quad \\left\\lceil \\frac{n}{k} \\right\\rceil = \\left\\lceil \\frac{97}{10} \\right\\rceil = 10.\n$$\n根据带余除法，\n$$\nn = k \\left\\lfloor \\frac{n}{k} \\right\\rfloor + r \\quad \\text{其中} \\quad r = n - k \\left\\lfloor \\frac{n}{k} \\right\\rfloor.\n$$\n在这里，\n$$\nr = 97 - 10 \\cdot 9 = 7.\n$$\n因此，有 $r=7$ 个大小为 10 的折，以及 $k-r=3$ 个大小为 9 的折。\n\n在每次迭代中，训练集的大小等于总观测数减去被留出的折的大小。因此，如果一个大小为 $s$ 的折被留出，训练集的大小为\n$$\nT = n - s.\n$$\n当 $s$ 尽可能大时，即留出大小为 $\\lceil n/k \\rceil = 10$ 的折时，训练集的大小最小，得到\n$$\nT_{\\min} = n - \\left\\lceil \\frac{n}{k} \\right\\rceil = 97 - 10 = 87.\n$$\n为完整起见，如果留出的是大小为 9 的折，训练集大小将是 $97 - 9 = 88$，这个值更大。因此，在这 10 次迭代中，训练集的最小可能大小是 $87$。", "answer": "$$\\boxed{87}$$", "id": "1912440"}, {"introduction": "交叉验证不仅用于评估模型性能，更常用于模型选择，特别是在调整模型复杂度时。这个练习介绍了一个重要的实践准则——“单标准误规则”，它帮助我们在模型的预测能力和简洁性之间做出权衡，以选择一个泛化能力强且不易过拟合的模型。通过这个案例，你将学会如何解读交叉验证的结果并做出明智的模型选择决策。[@problem_id:1912455]", "problem": "一个生物统计学家团队正在使用基因组数据建立一个疾病风险的预测模型。他们使用一种称为最小绝对值收敛和选择算子 (LASSO) 回归的方法。LASSO 模型的复杂度由一个调整参数 $\\lambda$ 控制。$\\lambda$ 的值越高，模型就越简单，预测变量也越少。\n\n为了选择 $\\lambda$ 的最佳值，该团队进行了 K 折交叉验证 (CV)。他们测试了五个不同的 $\\lambda$ 值，并为每个值计算了平均交叉验证预测误差以及该均值的标准误。结果总结如下：\n\n*   **模型 A**：$\\lambda = 0.01$，预测变量数量 = 12，平均交叉验证误差 = 0.35，标准误 = 0.05\n*   **模型 B**：$\\lambda = 0.05$，预测变量数量 = 9，平均交叉验证误差 = 0.31，标准误 = 0.04\n*   **模型 C**：$\\lambda = 0.10$，预测变量数量 = 6，平均交叉验证误差 = 0.28，标准误 = 0.03\n*   **模型 D**：$\\lambda = 0.20$，预测变量数量 = 4，平均交叉验证误差 = 0.30，标准误 = 0.04\n*   **模型 E**：$\\lambda = 0.50$，预测变量数量 = 2，平均交叉验证误差 = 0.34，标准误 = 0.06\n\n该团队决定使用“一个标准误规则”来选择最终模型。该规则倾向于选择更简单的模型以避免过拟合。根据一个标准误规则，应选择哪个模型进行最终分析？\n\nA. 模型 A\n\nB. 模型 B\n\nC. 模型 C\n\nD. 模型 D\n\nE. 模型 E", "solution": "我们应用与交叉验证一起使用的“一个标准误（1-SE）规则”。令 $\\hat{E}(\\lambda)$ 表示平均交叉验证误差，$\\operatorname{SE}(\\lambda)$ 表示其标准误。首先，找出具有最小平均交叉验证误差的模型：\n- 最小平均交叉验证误差出现在模型 C，为 $\\hat{E}(\\lambda^{\\ast})=0.28$，其标准误为 $\\operatorname{SE}(\\lambda^{\\ast})=0.03$。\n\n计算 1-SE 阈值：\n$$\nT=\\hat{E}(\\lambda^{\\ast})+\\operatorname{SE}(\\lambda^{\\ast})=0.28+0.03=0.31.\n$$\n\n根据 1-SE 规则，选择平均交叉验证误差最多为 $T$ 的最简单的模型（即 $\\lambda$ 最大，预测变量最少）。将每个模型的平均交叉验证误差与 $T=0.31$ 进行比较：\n- 模型 A：$0.35>T$（排除）。\n- 模型 B：$0.31\\leq T$（符合条件）。\n- 模型 C：$0.28\\leq T$（符合条件）。\n- 模型 D：$0.30\\leq T$（符合条件）。\n- 模型 E：$0.34>T$（排除）。\n\n在符合条件的模型 $\\{B,C,D\\}$ 中，选择最简单的模型（即 $\\lambda$ 值最大或预测变量最少）。它们的复杂度分别为：B 有 $9$ 个预测变量，C 有 $6$ 个，D 有 $4$ 个。其中最简单的是模型 D。因此，根据 1-SE 规则，应选择模型 D。", "answer": "$$\\boxed{D}$$", "id": "1912455"}, {"introduction": "在处理现实世界的数据时，我们常需进行数据预处理，例如填补缺失值，这给交叉验证带来了潜在的陷阱。这个练习探讨了一个高级但至关重要的问题：如何正确地将预处理步骤（如插补）整合到交叉验证流程中以避免“信息泄露”。正确地解决这个问题是确保模型性能评估结果无偏（unbiased）的关键，它将加深你对验证原则的理解。[@problem_id:1912459]", "problem": "一家生物医学研究公司的数据科学家受命开发一个预测模型，用于评估某种特定代谢综合征的风险。可用的数据集表示为 $D$，包含 $N$ 名患者的记录，每条记录包含 $P$ 个特征（生物标志物、临床测量值）和一个二元结果（高风险或低风险）。生物标志物测量值中有很大一部分是缺失的。\n\n选定的预测模型是支持向量机（SVM）。为了处理缺失数据，团队决定使用 k-最近邻（k-NN）插补法。在这种方法中，某个患者记录中一个特征的缺失值，是通过在数据集中基于非缺失特征找到 $k$ 个最相似的患者（“邻居”），然后聚合这些邻居对应的特征值（例如，通过取均值或中位数）来估计的。\n\n为了获得 SVM 在未见数据上性能的可靠估计，数据科学家必须使用 K 折交叉验证。关键挑战在于如何将 k-NN 插补步骤正确地整合到交叉验证流程中，以避免“信息泄露”，因为信息泄露会导致过于乐观的性能估计。\n\n要求您从以下选项中找出一个方法论上合理的操作流程。一个“操作流程”如果能确保来自验证折的信息在任何方面都不影响模型的训练或任何先前的数据准备步骤（如插补），则被认为是合理的。\n\n设带有缺失值的原始数据集为 $D$。\n\nA. **流程 A**\n1.  对整个数据集 $D$ 应用 k-NN 插补，创建一个完整的数据集 $D_{imputed}$。\n2.  将 $D_{imputed}$ 分割成 $K$ 折。\n3.  对每一折 $i=1, \\dots, K$：\n    a. 使用第 $i$ 折作为测试集，其余 $K-1$ 折作为训练集。\n    b. 在训练集上训练 SVM 模型。\n    c. 在测试集上评估 SVM 模型。\n4.  计算所有 $K$ 次评估的平均性能指标。\n\nB. **流程 B**\n1.  将原始数据集 $D$（带有缺失值）分割成 $K$ 折。\n2.  对每一折 $i=1, \\dots, K$：\n    a. 将第 $i$ 折指定为测试集（$D_{test}$），其余 $K-1$ 折指定为训练集（$D_{train}$）。请注意，这两个集合仍然包含缺失值。\n    b. 仅从训练集 $D_{train}$ 中学习 k-NN 结构（即识别邻居），从而构建插补模型。\n    c. 使用步骤（2b）中的插补模型来填充 $D_{train}$ 和 $D_{test}$ 中的缺失值。对于 $D_{test}$ 中任何带有缺失值的样本，其邻居都只在 $D_{train}$ 中寻找。这样就创建了 $D'_{train}$ 和 $D'_{test}$。\n    d. 在插补后的训练集 $D'_{train}$ 上训练 SVM 模型。\n    e. 在插补后的测试集 $D'_{test}$ 上评估 SVM 模型。\n3.  计算所有 $K$ 次评估的平均性能指标。\n\nC. **流程 C**\n1.  将原始数据集 $D$（带有缺失值）分割成 $K$ 折。\n2.  对每一折 $i=1, \\dots, K$：\n    a. 将第 $i$ 折指定为测试集（$D_{test}$），其余 $K-1$ 折指定为训练集（$D_{train}$）。\n    b. 对 $D_{train}$ 应用 k-NN 插补（仅使用 $D_{train}$ 内部的邻居），创建 $D'_{train}$。\n    c. 对 $D_{test}$ 应用 k-NN 插补（仅使用 $D_{test}$ 内部的邻居），创建 $D'_{test}$。\n    d. 在 $D'_{train}$ 上训练 SVM 模型。\n    e. 在 $D'_{test}$ 上评估 SVM 模型。\n3.  计算所有 $K$ 次评估的平均性能指标。\n\nD. **流程 D**\n1.  将原始数据集 $D$ 划分成一个单独的训练集（80% 的数据）和一个单独的测试集（20% 的数据）。\n2.  对训练集应用 k-NN 插补，创建一个插补后的训练集。\n3.  对测试集应用 k-NN 插补，创建一个插补后的测试集。\n4.  在插补后的训练集上训练 SVM 模型。\n5.  在插补后的测试集上评估模型并报告性能。\n\n以上哪个流程正确地实现了带有插补的交叉验证，以提供对模型性能的无偏估计？", "solution": "令 $D=\\{(x_{n},y_{n})\\}_{n=1}^{N}$ 表示数据集，其中 $x_{n}\\in \\mathbb{R}^{P}$ 中有缺失条目，且二元标签为 $y_{n}\\in\\{0,1\\}$。一个有效的交叉验证流程必须确保，使用验证数据拟合的任何函数都不会影响该折的任何训练或预处理步骤。\n\n定义一个由 $\\eta$ 参数化的插补算子 $\\mathcal{I}_{\\eta}$，对于 k-NN 插补，$\\eta$ 包含用于计算邻居关系的训练特征集（以及任何在训练集上拟合的预处理，如缩放）。正确的按折操作流程必须：\n- 仅在 $D_{train}$ 上拟合 $\\eta$，即 $\\hat{\\eta}=g(D_{train})$，\n- 生成插补后的集合 $\\tilde{D}_{train}=\\mathcal{I}_{\\hat{\\eta}}(D_{train})$ 和 $\\tilde{D}_{test}=\\mathcal{I}_{\\hat{\\eta}}(D_{test})$，\n- 在 $\\tilde{D}_{train}$ 上训练模型 $h$ 并在 $\\tilde{D}_{test}$ 上进行评估。\n\n对于 k-NN，将 $\\mathcal{I}_{\\hat{\\eta}}$ 应用于任何具有缺失坐标 $j$ 的 $x$ 时，必须仅从 $D_{train}$ 中寻找邻居，并聚合它们在坐标 $j$ 上的值来插补 $x_{j}$。\n\n根据此要求评估每个选项：\n\n- 流程 A 在分割数据集之前对整个 $D$ 进行插补拟合。这设定了 $\\hat{\\eta}=g(D)$，它依赖于所有的数据折，包括验证数据，违反了 $\\eta$ 必须仅从 $D_{train}$ 学习的约束。这就是信息泄露。\n\n- 流程 B 首先分割 $D$，然后对于每一折 $i$，仅从 $D_{train}$ 学习 k-NN 结构，即 $\\hat{\\eta}_{i}=g(D_{train}^{(i)})$，使用 $D_{train}^{(i)}$ 内部的邻居来插补 $D_{train}^{(i)}$，并通过只在 $D_{train}^{(i)}$ 中寻找邻居来插补 $D_{test}^{(i)}$。因此，$\\tilde{D}_{train}^{(i)}=\\mathcal{I}_{\\hat{\\eta}_{i}}(D_{train}^{(i)})$ 且 $\\tilde{D}_{test}^{(i)}=\\mathcal{I}_{\\hat{\\eta}_{i}}(D_{test}^{(i)})$。没有任何来自 $D_{test}^{(i)}$ 的信息用于构建 $\\hat{\\eta}_{i}$，因此不存在信息泄露。这与部署场景相符，即使用训练存储库对新样本进行插补。\n\n- 流程 C 使用 $D_{train}$ 自身来插补 $D_{train}$，但使用 $D_{test}$ 自身来插补 $D_{test}$。这为测试集转换定义了一个不同的参数 $\\hat{\\eta}_{test}^{(i)}=g(D_{test}^{(i)})$，该参数使用了来自验证数据的统计量/结构，这些信息在部署时是不可用的，并且会导致乐观的评估结果。这违反了所有预处理都必须在 $D_{train}$ 上拟合的要求。\n\n- 流程 D 不是 K 折交叉验证，并且它对训练集和测试集分别进行插补，即使用 $\\hat{\\eta}_{train}=g(D_{train})$ 和 $\\hat{\\eta}_{test}=g(D_{test})$。这种做法不恰当地使用了测试信息进行预处理，并且不能提供 K 折估计。\n\n因此，唯一方法论上合理的带插补的交叉验证是流程 B。", "answer": "$$\\boxed{B}$$", "id": "1912459"}]}