{"hands_on_practices": [{"introduction": "理解一个算法最好的方式之一就是亲手执行它。这个练习将带领你具体地、一步步地完成期望最大化（EM）算法的一次完整迭代。我们以最常见的应用之一——高斯混合模型（GMM）为例 [@problem_id:1960172]，通过这个实践，你将牢固掌握 E 步（计算“责任”）和 M 步（更新参数）的核心机制，为更复杂的应用打下坚实基础。", "problem": "一位研究人员正在分析一个测量数据集，据信该数据集是从两个不同群体 A 和 B 的混合体中抽样得到的。他们决定使用一个双组分高斯混合模型（GMM）来对数据进行建模。单个数据点 $x$ 的概率密度函数（PDF）由下式给出：\n$$p(x | \\theta) = \\pi_A \\mathcal{N}(x | \\mu_A, \\sigma_A^2) + \\pi_B \\mathcal{N}(x | \\mu_B, \\sigma_B^2)$$\n其中 $\\pi_A$ 和 $\\pi_B$ 是混合比例（满足 $\\pi_A + \\pi_B = 1$），而 $\\mathcal{N}(x | \\mu, \\sigma^2)$ 是高斯 PDF：\n$$\\mathcal{N}(x | \\mu, \\sigma^2) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}} \\exp\\left(-\\frac{(x-\\mu)^2}{2\\sigma^2}\\right)$$\n\n数据集包含以下五个测量值：$\\{4.0, 4.5, 5.0, 8.0, 9.0\\}$。\n为简单起见，假设两个组分的方差已知且固定为 $\\sigma_A^2 = \\sigma_B^2 = 1.0$。\n\n研究人员按如下方式初始化期望最大化（EM）算法的模型参数：\n- 初始均值：$\\mu_A^{(0)} = 4.2$ 和 $\\mu_B^{(0)} = 8.8$。\n- 初始混合比例：$\\pi_A^{(0)} = 0.5$ 和 $\\pi_B^{(0)} = 0.5$。\n\n您的任务是执行一次完整的 EM 算法迭代，包括一个期望步骤（E-step）和一个最大化步骤（M-step），以计算更新后的参数。\n\n计算第一个组分均值的更新值 $\\mu_A^{(1)}$。以实数形式报告您的答案，并四舍五入到四位有效数字。", "solution": "我们对双组分高斯混合模型应用一次期望最大化（EM）迭代，其中方差固定为 $\\sigma_{A}^{2}=\\sigma_{B}^{2}=1$，初始参数为 $\\mu_{A}^{(0)}=4.2$，$\\mu_{B}^{(0)}=8.8$，$\\pi_{A}^{(0)}=\\pi_{B}^{(0)}=0.5$。\n\nE-步骤（期望步骤，计算响应度）：\n对于每个数据点 $x_{i}$，组分 A 的响应度为\n$$\nr_{iA} \\equiv \\gamma_{iA} = \\frac{\\pi_{A}^{(0)} \\mathcal{N}(x_{i} \\mid \\mu_{A}^{(0)},1)}{\\pi_{A}^{(0)} \\mathcal{N}(x_{i} \\mid \\mu_{A}^{(0)},1) + \\pi_{B}^{(0)} \\mathcal{N}(x_{i} \\mid \\mu_{B}^{(0)},1)}.\n$$\n由于 $\\pi_{A}^{(0)}=\\pi_{B}^{(0)}$ 且方差相等，公共因子可以消去：\n$$\nr_{iA}=\\frac{\\exp\\!\\left(-\\frac{(x_{i}-\\mu_{A}^{(0)})^{2}}{2}\\right)}{\\exp\\!\\left(-\\frac{(x_{i}-\\mu_{A}^{(0)})^{2}}{2}\\right)+\\exp\\!\\left(-\\frac{(x_{i}-\\mu_{B}^{(0)})^{2}}{2}\\right)}=\\frac{1}{1+\\exp\\!\\left(\\frac{(x_{i}-\\mu_{A}^{(0)})^{2}-(x_{i}-\\mu_{B}^{(0)})^{2}}{2}\\right)}.\n$$\n对于数据集 $\\{4.0,4.5,5.0,8.0,9.0\\}$ 和 $(\\mu_{A}^{(0)},\\mu_{B}^{(0)})=(4.2,8.8)$：\n- 对于 $x_{1}=4.0$：$(x_{1}-\\mu_{A}^{(0)})^{2}=0.04$，$(x_{1}-\\mu_{B}^{(0)})^{2}=23.04$，因此\n$$\nr_{1A}=\\frac{1}{1+\\exp(-11.5)}\\approx 0.9999898625.\n$$\n- 对于 $x_{2}=4.5$：$(x_{2}-\\mu_{A}^{(0)})^{2}=0.09$，$(x_{2}-\\mu_{B}^{(0)})^{2}=18.49$，因此\n$$\nr_{2A}=\\frac{1}{1+\\exp(-9.2)}\\approx 0.9998989606.\n$$\n- 对于 $x_{3}=5.0$：$(x_{3}-\\mu_{A}^{(0)})^{2}=0.64$，$(x_{3}-\\mu_{B}^{(0)})^{2}=14.44$，因此\n$$\nr_{3A}=\\frac{1}{1+\\exp(-6.9)}\\approx 0.9989932309.\n$$\n- 对于 $x_{4}=8.0$：$(x_{4}-\\mu_{A}^{(0)})^{2}=14.44$，$(x_{4}-\\mu_{B}^{(0)})^{2}=0.64$，因此\n$$\nr_{4A}=\\frac{1}{1+\\exp(6.9)}=1-r_{3A}\\approx 0.0010067691.\n$$\n- 对于 $x_{5}=9.0$：$(x_{5}-\\mu_{A}^{(0)})^{2}=23.04$，$(x_{5}-\\mu_{B}^{(0)})^{2}=0.04$，因此\n$$\nr_{5A}=\\frac{1}{1+\\exp(11.5)}=1-r_{1A}\\approx 0.0000101375.\n$$\n根据对称性，注意 $r_{1A}+r_{5A}=1$ 和 $r_{3A}+r_{4A}=1$。\n\nM-步骤（最大化步骤，更新组分 A 的均值）：\n在方差固定的情况下，更新后的均值是响应度加权平均值：\n$$\n\\mu_{A}^{(1)}=\\frac{\\sum_{i=1}^{5} r_{iA} x_{i}}{\\sum_{i=1}^{5} r_{iA}}.\n$$\n使用对称性计算分母：\n$$\n\\sum_{i=1}^{5} r_{iA}=(r_{1A}+r_{5A})+(r_{3A}+r_{4A})+r_{2A}=2+r_{2A}\\approx 2.9998989606.\n$$\n计算分子；对对称的配对进行分组：\n$$\n\\sum_{i=1}^{5} r_{iA} x_{i}=(r_{1A}\\cdot 4.0 + r_{5A}\\cdot 9.0) + (r_{3A}\\cdot 5.0 + r_{4A}\\cdot 8.0) + r_{2A}\\cdot 4.5.\n$$\n使用 $r_{5A}=1-r_{1A}$ 和 $r_{4A}=1-r_{3A}$：\n$$\nr_{1A}\\cdot 4.0 + r_{5A}\\cdot 9.0 = 9 - 5 r_{1A},\\quad\nr_{3A}\\cdot 5.0 + r_{4A}\\cdot 8.0 = 8 - 3 r_{3A}.\n$$\n因此\n$$\n\\sum_{i=1}^{5} r_{iA} x_{i} = 17 - 5 r_{1A} - 3 r_{3A} + 4.5 r_{2A} \\approx 13.5026163178.\n$$\n所以，\n$$\n\\mu_{A}^{(1)}=\\frac{13.5026163178}{2.9998989606}\\approx 4.501023693.\n$$\n四舍五入到四位有效数字，更新后的均值为 $4.501$。", "answer": "$$\\boxed{4.501}$$", "id": "1960172"}, {"introduction": "在数值上演练了 EM 算法的工作流程后，下一步是理解其参数更新规则的由来。这个练习 [@problem_id:1960170] 将焦点放在 M 步，要求你为一个几何分布的混合模型推导出参数的更新公式。这项实践将锻炼你的解析推导能力，并展示极大似然原理是如何在 EM 框架内应用于不同类型的概率分布的。", "problem": "一位质量控制工程师正在分析一批电子元件的可靠性。这些元件来源于两个供应商，A和B。已知一个元件失效前的工作循环次数（记为 $X$）服从几何分布。其概率质量函数 (PMF) 为 $P(X=k) = p(1-p)^{k-1}$，$k=1, 2, 3, \\dots$，其中 $p$ 是在任何一个给定循环中的失效概率。来自供应商A的元件的失效概率为 $p_A$，来自供应商B的为 $p_B$。\n\n在混合库存中，来自供应商A的元件所占比例为 $\\pi$，而来自供应商B的比例为 $1-\\pi$。该工程师有一个从这个混合库存中抽取的 $n$ 个元件的失效时间数据集 $\\{x_1, x_2, \\ldots, x_n\\}$，但每个特定元件的供应商是未知的。\n\n为了估计未知参数 $\\theta = (\\pi, p_A, p_B)$，该工程师决定使用期望最大化 (EM) 算法。该算法迭代地改进参数估计值。设第 $t$ 次迭代的估计值为 $\\theta^{(t)} = (\\pi^{(t)}, p_A^{(t)}, p_B^{(t)})$。\n\n在第 $(t+1)$ 次迭代的E步中，需要计算供应商A对观测值 $x_i$ 的“责任”（responsibility），记为 $\\gamma_i$。这是在给定观测值 $x_i$ 和当前参数估计 $\\theta^{(t)}$ 的条件下，第 $i$ 个元件来自供应商A的后验概率。该概率由下式给出：\n$$\n\\gamma_i = \\frac{\\pi^{(t)} p_A^{(t)}(1-p_A^{(t)})^{x_i-1}}{\\pi^{(t)} p_A^{(t)}(1-p_A^{(t)})^{x_i-1} + (1-\\pi^{(t)}) p_B^{(t)}(1-p_B^{(t)})^{x_i-1}}\n$$\n在M步中，更新参数以最大化期望完全数据对数似然。你的任务是推导参数 $p_A$ 的更新规则。\n\n请找出更新后的估计值 $p_A^{(t+1)}$ 的表达式，该表达式以观测数据 $\\{x_1, \\ldots, x_n\\}$ 和在E步中计算出的响应度 $\\{\\gamma_1, \\ldots, \\gamma_n\\}$ 表示。", "solution": "引入潜变量指标 $z_{i}\\in\\{0,1\\}$，若第 $i$ 个元件来自供应商A，则 $z_{i}=1$，否则 $z_{i}=0$。完全数据对数似然为\n$$\n\\ell_{c}(\\pi,p_{A},p_{B})=\\sum_{i=1}^{n}\\left[z_{i}\\left(\\ln \\pi+\\ln p_{A}+(x_{i}-1)\\ln(1-p_{A})\\right)+(1-z_{i})\\left(\\ln(1-\\pi)+\\ln p_{B}+(x_{i}-1)\\ln(1-p_{B})\\right)\\right].\n$$\n在E步中，用其条件期望 $\\gamma_{i}=\\mathbb{E}[z_{i}\\mid x_{i},\\theta^{(t)}]$ 替换 $z_{i}$。期望完全数据对数似然中与 $p_{A}$ 相关的部分为\n$$\nQ(p_{A})=\\sum_{i=1}^{n}\\gamma_{i}\\left(\\ln p_{A}+(x_{i}-1)\\ln(1-p_{A})\\right).\n$$\n对 $p_{A}$ 求导：\n$$\n\\frac{\\partial Q}{\\partial p_{A}}=\\sum_{i=1}^{n}\\gamma_{i}\\left(\\frac{1}{p_{A}}-\\frac{x_{i}-1}{1-p_{A}}\\right)=\\frac{1}{p_{A}}\\sum_{i=1}^{n}\\gamma_{i}-\\frac{1}{1-p_{A}}\\sum_{i=1}^{n}\\gamma_{i}(x_{i}-1).\n$$\n令导数为零并求解 $p_{A}$。令 $S_{1}=\\sum_{i=1}^{n}\\gamma_{i}$ 及 $S_{x}=\\sum_{i=1}^{n}\\gamma_{i}(x_{i}-1)$。则\n$$\n\\frac{S_{1}}{p_{A}}-\\frac{S_{x}}{1-p_{A}}=0\\quad\\Longrightarrow\\quad S_{1}(1-p_{A})=S_{x}p_{A}\\quad\\Longrightarrow\\quad S_{1}=p_{A}(S_{1}+S_{x}).\n$$\n因此\n$$\np_{A}^{(t+1)}=\\frac{S_{1}}{S_{1}+S_{x}}.\n$$\n注意到 $S_{1}+S_{x}=\\sum_{i=1}^{n}\\gamma_{i}+\\sum_{i=1}^{n}\\gamma_{i}(x_{i}-1)=\\sum_{i=1}^{n}\\gamma_{i}x_{i}$，我们得到\n$$\np_{A}^{(t+1)}=\\frac{\\sum_{i=1}^{n}\\gamma_{i}}{\\sum_{i=1}^{n}\\gamma_{i}x_{i}}.\n$$\n二阶导数为\n$$\n\\frac{\\partial^{2}Q}{\\partial p_{A}^{2}}=-\\sum_{i=1}^{n}\\gamma_{i}\\left(\\frac{1}{p_{A}^{2}}+\\frac{x_{i}-1}{(1-p_{A})^{2}}\\right)<0\\quad\\text{for }0<p_{A}<1,\n$$\n这确认了此解是一个极大值点。", "answer": "$$\\boxed{\\frac{\\sum_{i=1}^{n}\\gamma_{i}}{\\sum_{i=1}^{n}\\gamma_{i}x_{i}}}$$", "id": "1960170"}, {"introduction": "标准的 EM 算法旨在寻找参数的极大似然估计。然而，EM 框架具有很强的灵活性，可以被扩展以融合先验知识，这在贝叶斯统计中至关重要。最后一个练习 [@problem_id:1960196] 将探索这种扩展，通过在一个泊松混合模型中推导参数的最大后验（MAP）估计，来展示如何将先验信念与观测数据优雅地结合起来。", "problem": "一位生物物理学家正在分析来自单分子荧光实验的数据。观测数据由一系列 $n$ 个独立的光子计数 $X_1, X_2, \\dots, X_n$ 组成，这些计数是在连续的时间间隔内记录的。已知该分子会在两种不同的构象状态（状态1和状态2）之间随机切换。当处于状态 $k$ 时，光子计数由泊松分布建模，其未知的率参数为 $\\lambda_k$。任何一次给定的测量来自状态1的概率是已知的常数 $\\pi$，来自状态2的概率是 $1-\\pi$。\n\n为了估计未知的率参数 $\\lambda_1$ 和 $\\lambda_2$，使用了一种迭代算法。由于存在关于该系统的先验知识，因此采用了贝叶斯方法。目标是找到参数的最大后验 (MAP) 估计，而不仅仅是最大似然估计。率参数的先验分布被选为伽马分布，因为它们是泊松似然的共轭先验。具体来说，$\\lambda_k$ 的先验分布是 $\\text{Gamma}(\\alpha_k, \\beta_k)$，其概率密度函数由 $p(\\lambda_k) \\propto \\lambda_k^{\\alpha_k-1} \\exp(-\\beta_k \\lambda_k)$ 给出（对于 $\\lambda_k > 0$）。\n\n该估计是使用期望最大化 (EM) 算法的修改版本进行的。标准的M步（最大化期望完全数据对数似然）被一个最大化期望完全数据对数后验的步骤所取代。\n\n设 $\\theta^{(t)} = (\\lambda_1^{(t)}, \\lambda_2^{(t)})$ 为第 $t$ 次迭代时的参数估计值。在期望步（E-step）中，需要计算“责任”（responsibilities），即在给定数据和当前参数估计值的情况下，观测值 $X_i$ 属于状态 $k$ 的后验概率。我们将状态1的责任记为 $\\gamma_{i,1}^{(t)} = P(\\text{状态}=1 | X_i, \\theta^{(t)})$。\n\n你的任务是在修正的最大化步（M-step）中推导出参数 $\\lambda_1$ 的更新方程。用观测数据 $\\{X_i\\}_{i=1}^n$、责任 $\\{\\gamma_{i,1}^{(t)}\\}_{i=1}^n$ 以及 $\\lambda_1$ 的先验分布的超参数 $\\alpha_1$ 和 $\\beta_1$ 来表示更新后的估计值 $\\lambda_1^{(t+1)}$。", "solution": "引入潜指示变量 $z_{i,1} \\in \\{0,1\\}$，当观测值 $X_{i}$ 来自状态1时，$z_{i,1}=1$，否则 $z_{i,1}=0$。涉及 $\\lambda_{1}$ 的完全数据对数似然项为\n$$\n\\sum_{i=1}^{n} z_{i,1} \\left( X_{i} \\ln \\lambda_{1} - \\lambda_{1} \\right) + \\text{const},\n$$\n因为对于泊松模型，$\\ln p(X_{i} \\mid \\lambda_{1}) = X_{i} \\ln \\lambda_{1} - \\lambda_{1} - \\ln X_{i}!.\n$\n$\\lambda_{1} \\sim \\text{Gamma}(\\alpha_{1},\\beta_{1})$ (形状-率) 的对数先验为\n$$\n(\\alpha_{1}-1)\\ln \\lambda_{1} - \\beta_{1} \\lambda_{1} + \\text{const}.\n$$\n在E步中，将 $z_{i,1}$ 替换为其在给定当前参数下的条件期望 $\\gamma_{i,1}^{(t)} = P(\\text{状态}=1 \\mid X_{i}, \\theta^{(t)})$。于是，关于 $\\lambda_{1}$ 的期望完全数据对数后验为\n$$\nQ(\\lambda_{1}) = \\left( \\alpha_{1}-1 + \\sum_{i=1}^{n} \\gamma_{i,1}^{(t)} X_{i} \\right) \\ln \\lambda_{1} - \\left( \\beta_{1} + \\sum_{i=1}^{n} \\gamma_{i,1}^{(t)} \\right) \\lambda_{1} + \\text{const}.\n$$\n对 $\\lambda_{1}$ 求导，令其等于零并求解：\n$$\n\\frac{\\partial Q}{\\partial \\lambda_{1}} = \\frac{\\alpha_{1}-1 + \\sum_{i=1}^{n} \\gamma_{i,1}^{(t)} X_{i}}{\\lambda_{1}} - \\left( \\beta_{1} + \\sum_{i=1}^{n} \\gamma_{i,1}^{(t)} \\right) = 0\n$$\n得到\n$$\n\\lambda_{1}^{(t+1)} = \\frac{\\alpha_{1}-1 + \\sum_{i=1}^{n} \\gamma_{i,1}^{(t)} X_{i}}{\\beta_{1} + \\sum_{i=1}^{n} \\gamma_{i,1}^{(t)}}.\n$$\n二阶导数为\n$$\n\\frac{\\partial^{2} Q}{\\partial \\lambda_{1}^{2}} = -\\frac{\\alpha_{1}-1 + \\sum_{i=1}^{n} \\gamma_{i,1}^{(t)} X_{i}}{\\lambda_{1}^{2}},\n$$\n只要分子为正，该二阶导数就为负，从而在通常条件下确认了这是一个最大值。", "answer": "$$\\boxed{\\frac{\\alpha_{1}-1+\\sum_{i=1}^{n}\\gamma_{i,1}^{(t)} X_{i}}{\\beta_{1}+\\sum_{i=1}^{n}\\gamma_{i,1}^{(t)}}}$$", "id": "1960196"}]}