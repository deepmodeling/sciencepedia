{"hands_on_practices": [{"introduction": "动手实践的第一步是深入理解算法的内部工作原理。虽然许多统计软件库提供了“一键式”的重抽样功能，但从零开始实现这些算法能够揭开其神秘面紗。本练习将指导你仅使用基础的均匀随机数生成器来实现自助法 (bootstrap) 和刀切法 (jackknife) 程序，从而确保你对“有放回抽样”和“留一法”的机制有深刻的理解，这是任何严肃的数据分析师都应具备的基础技能。[@problem_id:2404323]", "problem": "您必须编写一个完整的程序，以实现以下意义上的非参数重抽样，用于不确定性量化。给定一个由实数组成的有限数据集 $\\{x_{1},x_{2},\\dots,x_{n}\\}$ 和一个将任何有限实数序列映射为实数的统计量 $T$，您的目标是计算两种不确定性量化指标：给定数据集上 $T$ 的自助法标准误和刀切法标准误，以及一个自助法百分位置信区间（confidence interval (CI)）。实现必须仅使用独立抽样 $U \\sim \\mathrm{Uniform}(0,1)$ 的源来执行自助法重抽样；不得使用任何直接有放回抽样索引或元素的内置抽样函数。自助法索引抽样的正确性必须基于以下事实：如果 $U \\sim \\mathrm{Uniform}(0,1)$ 且数据集大小为 $n \\in \\mathbb{N}$，则整数 $J=\\lfloor n U \\rfloor$ 在 $\\{0,1,\\dots,n-1\\}$上均匀分布，即对于每个整数 $k \\in \\{0,1,\\dots,n-1\\}$，都有 $\\mathbb{P}(J=k)=1/n$。利用这一事实将 $U$ 的独立抽样映射为独立的自助法索引。您不能调用任何直接有放回抽样元素或索引的函数。请使用以下基本定义作为出发点。对于选定的统计量 $T$，自助法程序通过对每个重复 $b \\in \\{1,2,\\dots,B\\}$ 从 $\\{0,1,\\dots,n-1\\}$ 中有放回地抽样索引，形成一个大小为 $n$ 的重抽样样本，并在此重抽样样本上计算 $T$，从而构建 $B$ 个自助法重复。将这些自助法统计量表示为 $\\{\\hat{\\theta}_{b}\\}_{b=1}^{B}$。自助法标准误是 $\\{\\hat{\\theta}_{b}\\}_{b=1}^{B}$ 的样本标准差，即 $s_{\\mathrm{boot}}=\\sqrt{\\frac{1}{B-1}\\sum_{b=1}^{B}\\left(\\hat{\\theta}_{b}-\\bar{\\theta}\\right)^{2}}$，其中 $\\bar{\\theta}=\\frac{1}{B}\\sum_{b=1}^{B}\\hat{\\theta}_{b}$。名义水平为 $1-\\alpha$ 的自助法百分位置信区间由 $\\{\\hat{\\theta}_{b}\\}$ 在概率 $p_{\\ell}=\\alpha/2$ 和 $p_{u}=1-\\alpha/2$ 处的经验分位数定义。为避免歧义，定义概率 $p \\in [0,1]$ 处的经验分位数如下：如果 $t_{(1)} \\le t_{(2)} \\le \\dots \\le t_{(B)}$ 是排序后的自助法值，则 $q_{p}=t_{(k)}$，其中 $k=\\lceil p B \\rceil$，并约定如果 $p$ 为 $0$ 或 $1$，则将 $k$ 裁剪到 $\\{1,2,\\dots,B\\}$ 范围内。对于刀切法，定义留一法统计量 $\\{\\hat{\\theta}_{(i)}\\}_{i=1}^{n}$，其中 $\\hat{\\theta}_{(i)}=T(x_{1},\\dots,x_{i-1},x_{i+1},\\dots,x_{n})$ 是在省略 $x_{i}$ 的数据集上计算得出的。设 $\\bar{\\theta}_{\\mathrm{jack}}=\\frac{1}{n}\\sum_{i=1}^{n}\\hat{\\theta}_{(i)}$。刀切法标准误是 $s_{\\mathrm{jack}}=\\sqrt{\\frac{n-1}{n}\\sum_{i=1}^{n}\\left(\\hat{\\theta}_{(i)}-\\bar{\\theta}_{\\mathrm{jack}}\\right)^{2}}$。您的程序必须严格实现这些定义。在有限实数数组上实现以下统计量 $T$：样本均值和样本中位数，其中偶数长度的中位数是两个中心次序统计量的平均值。您不得使用任何内置的重抽样函数，例如直接的有放回选择例程；所有自助法索引都必须通过使用 $J=\\lfloor n U \\rfloor$ 转换来自 $\\mathrm{Uniform}(0,1)$ 的独立抽样来生成。请使用以下测试套件。对于每个测试用例，您将获得一个数据集、一个统计量选择、自助法重复次数 $B$、一个名义尾部概率 $\\alpha$ 和一个随机种子。对于每个测试用例，按顺序计算并返回四个值：自助法标准误 $s_{\\mathrm{boot}}$、刀切法标准误 $s_{\\mathrm{jack}}$，以及使用上述分位数定义的水平为 $1-\\alpha$ 的自助法百分位置信区间的下界和上界 $(q_{\\ell},q_{u})$。测试套件如下：\n- 用例 1：数据 $[1.2,2.0,3.4,2.2]$，统计量 均值，$B=5000$，$\\alpha=0.1$，种子 $=12345$。\n- 用例 2：数据 $[5.0,5.0,5.0,5.0,5.0]$，统计量 中位数，$B=3000$，$\\alpha=0.2$，种子 $=2468$。\n- 用例 3：数据 $[0.2,0.5,1.1,2.8,4.0,7.5,9.0]$，统计量 中位数，$B=6000$，$\\alpha=0.1$，种子 $=13579$。\n- 用例 4：数据 $[0.2,0.5,1.1,2.8,4.0,7.5,9.0]$，统计量 均值，$B=6000$，$\\alpha=0.05$，种子 $=98765$。\n您的程序必须生成单行输出，其中包含一个用方括号括起来的逗号分隔列表形式的结果。该列表必须按此顺序包含 $16$ 个实数：对于用例 1，输出 $s_{\\mathrm{boot}}$、$s_{\\mathrm{jack}}$、$q_{\\ell}$、$q_{u}$；然后按相同顺序输出用例 2 的结果；接着是用例 3；最后是用例 4。为了数值稳定性和结果的直接可比性，请将每个输出值四舍五入到恰好 $6$ 位小数。不涉及物理单位。不涉及角度。百分比必须表示为小数，因此 $\\alpha$ 直接以 $[0,1]$ 中的数字形式提供，您不得打印任何百分号。", "solution": "该问题是有效的。它在计算统计学领域提出了一个清晰、独立且科学上合理的任务。所有定义、数据和参数都明确给出，允许直接且可验证的实现。问题的核心是实现两种非参数重抽样技术——自助法（bootstrap）和刀切法（jackknife）——以估计给定统计量的不确定性。\n\n解决方案首先定义必要的统计函数，然后按规定实现重抽样程序。\n\n**1. 统计学预备知识**\n\n给定一个大小为 $n$ 的数据集 $X = \\{x_{1}, x_{2}, \\dots, x_{n}\\}$ 和一个统计量 $T$，我们的目标是量化估计值 $\\hat{\\theta} = T(X)$ 的不确定性。\n\n该问题要求实现两种特定的统计量：\n- **样本均值**：对于数据集 $\\{y_1, \\dots, y_k\\}$，均值为 $\\bar{y} = \\frac{1}{k}\\sum_{i=1}^{k} y_i$。\n- **样本中位数**：对于一个有序数据集 $y_{(1)} \\le y_{(2)} \\le \\dots \\le y_{(k)}$，如果 $k$ 是奇数，中位数定义为 $y_{((k+1)/2)}$；如果 $k$ 是偶数，则定义为 $\\frac{1}{2}(y_{(k/2)} + y_{(k/2+1)})$。\n\n**2. 自助法（Bootstrap）程序**\n\n自助法通过对给定数据集进行重复抽样来估计 $\\hat{\\theta}$ 的抽样分布。\n\n- **重抽样**：该过程涉及生成 $B$ 个自助法重复。对于每个重复 $b \\in \\{1, 2, \\dots, B\\}$，我们通过从 $\\{0, 1, \\dots, n-1\\}$ 中有放回地抽取索引来构建一个大小为 $n$ 的自助法样本 $X^{*b}$。问题规定了此操作的一种特定方法：对于自助法样本中的每个位置，使用公式 $J = \\lfloor nU \\rfloor$ 从均匀随机变量 $U \\sim \\mathrm{Uniform}(0,1)$ 生成一个索引 $J \\in \\{0, 1, \\dots, n-1\\}$。此过程重复 $n$ 次，以获得一个自助法样本的完整索引集。\n- **自助法统计量**：对于每个自助法样本 $X^{*b}$，计算统计量 $T$，得到一个自助法统计量 $\\hat{\\theta}_b = T(X^{*b})$。对所有 $B$ 个重复执行此过程，以形成自助法分布 $\\{\\hat{\\theta}_1, \\hat{\\theta}_2, \\dots, \\hat{\\theta}_B\\}$。\n\n- **自助法标准误 ($s_{\\mathrm{boot}}$)**：$\\hat{\\theta}$ 的标准误的自助法估计是自助法统计量的样本标准差：\n$$s_{\\mathrm{boot}} = \\sqrt{\\frac{1}{B-1}\\sum_{b=1}^{B}\\left(\\hat{\\theta}_{b}-\\bar{\\theta}\\right)^{2}}$$\n其中 $\\bar{\\theta} = \\frac{1}{B}\\sum_{b=1}^{B}\\hat{\\theta}_{b}$ 是自助法统计量的平均值。\n\n- **自助法百分位置信区间**：为了构建一个 $(1-\\alpha)$ 置信区间，我们使用有序自助法统计量 $t_{(1)} \\le t_{(2)} \\le \\dots \\le t_{(B)}$ 的分位数。该区间由 $[q_{\\ell}, q_{u}]$ 给出，其中 $q_{\\ell}$ 和 $q_{u}$ 分别是对应于概率 $p_{\\ell} = \\alpha/2$ 和 $p_{u} = 1-\\alpha/2$ 的经验分位数。根据问题的定义，分位数 $q_p$ 是 $t_{(k)}$，其中索引 $k$ 计算为 $k = \\lceil pB \\rceil$。这个基于 1 的索引 $k$ 被裁剪到范围 $\\{1, 2, \\dots, B\\}$ 内。为了实现这一点，对于给定的概率 $p$，我们计算 $k = \\max(1, \\lceil pB \\rceil)$，并从基于 0 索引的已排序自助法统计量数组中选择索引为 $k-1$ 的元素。\n\n**3. 刀切法（Jackknife）程序**\n\n刀切法是另一种重抽样技术，它系统地从数据集中省略每个观测值。\n\n- **重抽样**：对于每个观测值 $i \\in \\{1, 2, \\dots, n\\}$，通过从原始数据集中移除 $x_i$ 来形成一个刀切法样本 $X_{(i)}$。这将创建 $n$ 个数据集，每个数据集的大小为 $n-1$。\n- **刀切法统计量**：对这 $n$ 个样本中的每一个计算统计量 $T$，得到留一法统计量 $\\{\\hat{\\theta}_{(1)}, \\hat{\\theta}_{(2)}, \\dots, \\hat{\\theta}_{(n)}\\}$。\n\n- **刀切法标准误 ($s_{\\mathrm{jack}}$)**：$\\hat{\\theta}$ 的标准误的刀切法估计定义为：\n$$s_{\\mathrm{jack}} = \\sqrt{\\frac{n-1}{n}\\sum_{i=1}^{n}\\left(\\hat{\\theta}_{(i)}-\\bar{\\theta}_{\\mathrm{jack}}\\right)^{2}}$$\n其中 $\\bar{\\theta}_{\\mathrm{jack}} = \\frac{1}{n}\\sum_{i=1}^{n}\\hat{\\theta}_{(i)}$ 是刀切法统计量的平均值。\n\n**4. 实现策略**\n\n整个程序的结构是为了处理指定的测试用例。一个主函数遍历每个用例，调用一个核心计算函数。该函数为给定的数据集、统计量和参数（$B, \\alpha$, 种子）执行以下步骤：\n1.  设置随机数生成器种子以确保可复现性。\n2.  执行自助法程序：使用指定的 $\\lfloor nU \\rfloor$ 方法生成 $B$ 个自助法样本，计算 $B$ 个统计量，然后计算 $s_{\\mathrm{boot}}$ 和百分位置信区间界限 $(q_{\\ell}, q_{u})$。\n3.  执行刀切法程序：生成 $n$ 个留一法样本，计算 $n$ 个统计量，并计算 $s_{\\mathrm{jack}}$。\n4.  返回四个所需的值：$s_{\\mathrm{boot}}, s_{\\mathrm{jack}}, q_{\\ell}, q_{u}$。\n\n收集所有测试用例的最终结果，四舍五入到 $6$ 位小数，并以要求的单行格式打印。", "answer": "```python\nimport numpy as np\nimport math\n\ndef compute_uncertainties(data, statistic_name, B, alpha, seed):\n    \"\"\"\n    Computes bootstrap and jackknife standard errors and a bootstrap percentile CI.\n\n    Args:\n        data (np.ndarray): The input dataset.\n        statistic_name (str): The name of the statistic ('mean' or 'median').\n        B (int): The number of bootstrap replicates.\n        alpha (float): The significance level for the confidence interval.\n        seed (int): The random seed for reproducibility.\n\n    Returns:\n        tuple: A tuple containing (s_boot, s_jack, ci_lower, ci_upper).\n    \"\"\"\n    # Set the random seed for reproducibility\n    np.random.seed(seed)\n\n    # Convert data to numpy array\n    data = np.array(data, dtype=float)\n    n = len(data)\n\n    # Define statistic functions\n    if statistic_name == 'mean':\n        statistic_fn = np.mean\n    elif statistic_name == 'median':\n        statistic_fn = np.median\n    else:\n        raise ValueError(\"Unknown statistic\")\n\n    # --- Bootstrap Procedure ---\n    bootstrap_stats = np.empty(B)\n    for i in range(B):\n        # Generate n uniform random numbers U ~ Uniform(0,1)\n        uniform_draws = np.random.rand(n)\n        # Generate bootstrap indices using J = floor(n*U)\n        bootstrap_indices = np.floor(n * uniform_draws).astype(int)\n        # Create bootstrap sample\n        bootstrap_sample = data[bootstrap_indices]\n        # Compute statistic\n        bootstrap_stats[i] = statistic_fn(bootstrap_sample)\n\n    # Bootstrap Standard Error\n    s_boot = np.std(bootstrap_stats, ddof=1)\n\n    # Bootstrap Percentile Confidence Interval\n    sorted_bootstrap_stats = np.sort(bootstrap_stats)\n    \n    # Lower bound\n    p_lower = alpha / 2.0\n    k_lower = int(math.ceil(p_lower * B))\n    k_lower = max(1, k_lower)\n    ci_lower = sorted_bootstrap_stats[k_lower - 1]\n\n    # Upper bound\n    p_upper = 1.0 - alpha / 2.0\n    k_upper = int(math.ceil(p_upper * B))\n    k_upper = max(1, k_upper) \n    ci_upper = sorted_bootstrap_stats[k_upper - 1]\n\n    # --- Jackknife Procedure ---\n    jackknife_stats = np.empty(n)\n    for i in range(n):\n        # Create leave-one-out sample\n        jackknife_sample = np.delete(data, i)\n        # Compute statistic\n        jackknife_stats[i] = statistic_fn(jackknife_sample)\n\n    # Jackknife Standard Error\n    theta_jack_mean = np.mean(jackknife_stats)\n    sum_sq_diff = np.sum((jackknife_stats - theta_jack_mean)**2)\n    s_jack = np.sqrt(((n - 1) / n) * sum_sq_diff)\n    \n    return s_boot, s_jack, ci_lower, ci_upper\n\n\ndef solve():\n    \"\"\"\n    Main function to run the test suite and print the results.\n    \"\"\"\n    test_cases = [\n        {'data': [1.2, 2.0, 3.4, 2.2], 'statistic': 'mean', 'B': 5000, 'alpha': 0.1, 'seed': 12345},\n        {'data': [5.0, 5.0, 5.0, 5.0, 5.0], 'statistic': 'median', 'B': 3000, 'alpha': 0.2, 'seed': 2468},\n        {'data': [0.2, 0.5, 1.1, 2.8, 4.0, 7.5, 9.0], 'statistic': 'median', 'B': 6000, 'alpha': 0.1, 'seed': 13579},\n        {'data': [0.2, 0.5, 1.1, 2.8, 4.0, 7.5, 9.0], 'statistic': 'mean', 'B': 6000, 'alpha': 0.05, 'seed': 98765}\n    ]\n\n    all_results = []\n    for case in test_cases:\n        results = compute_uncertainties(\n            case['data'],\n            case['statistic'],\n            case['B'],\n            case['alpha'],\n            case['seed']\n        )\n        all_results.extend(results)\n\n    # Format results to 6 decimal places and create the final output string\n    formatted_results = [f\"{val:.6f}\" for val in all_results]\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```", "id": "2404323"}, {"introduction": "掌握了算法的实现机制后，下一步是学会在复杂的现实场景中正确地应用它们。这个练习将我们的关注点从“如何”重抽样转移到“对什么”进行重抽样，并突出一个关键的现实挑战：数据中的聚集性或非独立性。对聚集数据（clustered data）错误地应用朴素的自助法会得出错误的统计推断，因此，设计一个能够尊重并模仿原始数据结构的重抽样方案是一项至关重要的实践技能。[@problem_id:1951652]", "problem": "一位环境科学家正在研究工业排放对鱼类汞含量的影响。数据从 $M$ 个不同的河流系统中收集。在每个河流系统 $i$（其中 $i=1, \\dots, M$）中，采样了 $n_i$ 条鱼，对于每条鱼 $j$（其中 $j=1, \\dots, n_i$），记录了两个测量值：其汞浓度 $Y_{ij}$，以及其到特定工业排放点的距离 $X_{ij}$。采样的鱼的总数为 $N = \\sum_{i=1}^M n_i$。\n\n科学家提出了一个简单的线性回归模型来描述这种关系：\n$$\nY_{ij} = \\beta_0 + \\beta_1 X_{ij} + \\epsilon_{ij}\n$$\n主要目标是为系数 $\\beta_1$ 构建一个 95% 的置信区间。一个关键的考虑是，来自同一河流系统的观测值可能不是独立的。同一条河流共有的未观测因素（例如，当地的水化学特性、特定的食物链特征）可能会在误差项中引起相关性。也就是说，对于同一河流 $i$ 中的鱼，当 $j \\neq k$ 时，$\\text{Cov}(\\epsilon_{ij}, \\epsilon_{ik}) \\neq 0$。然而，来自不同河流系统的观测值被假定为独立的。\n\n为了解决这种数据结构，考虑了几种基于自助法（bootstrap）的程序来估计普通最小二乘（OLS）估计量 $\\hat{\\beta_1}$ 的抽样分布。下列哪个陈述最准确地描述了一个有效的程序及其在此背景下有效性的原因？\n\nA. 非聚类（朴素）自助法：通过从所有鱼的完整数据集中有放回地抽取 $N$ 条单独的鱼来创建自助样本，忽略它们来自哪条河流。这个程序是有效的，因为对于大量的鱼 $N$，根据中心极限定理，OLS 估计量 $\\hat{\\beta_1}$ 的分布将近似正态分布。\n\nB. 聚类自助法：首先从 $M$ 条河流的原始列表中有放回地抽取 $M$ 个河流系统来创建自助样本。然后，对于每个选定的河流，将其所有相关的鱼样本包含在新的自助数据集中。这个程序是有效的，因为它将河流系统视为独立的抽样单位，从而保留了原始数据的河流内相关性结构。\n\nC. 参数自助法：首先，将 OLS 模型拟合到原始数据上，以获得估计值 $\\hat{\\beta_0}$ 和 $\\hat{\\beta_1}$ 以及所有 $N$ 个残差的集合 $\\{e_{ij}\\}$。然后，通过从 $\\{e_{ij}\\}$ 中有放回地抽样一个残差 $e_{ij}^*$，并设置 $Y_{ij}^* = \\hat{\\beta_0} + \\hat{\\beta_1} X_{ij} + e_{ij}^*$ 来为每个观测值创建一个自助结果 $Y_{ij}^*$。这个程序是有效的，因为它在尊重原始预测变量值的同时，从拟合的模型中模拟新数据。\n\nD. 簇内重抽样自助法：通过保持原始的 $M$ 个河流集合不变来创建自助样本。然后，对于每条河流 $i$，通过从该河流中原始的 $n_i$ 条鱼中有放回地重抽样，来为该河流生成一组新的 $n_i$ 条鱼。这个程序是有效的，因为它正确地模拟了每个独立河流系统中发生的抽样变异性。\n\nE. 固定X自助法：首先拟合 OLS 模型以获得残差 $\\{e_{ij}\\}$ 来创建自助样本。然后，对于每条鱼，创建一个新的结果 $Y_{ij}^* = \\hat{\\beta_0} + \\hat{\\beta_1} X_{ij} + \\delta_{ij}$，其中 $\\delta_{ij}$ 是从一个正态分布 $N(0, \\hat{\\sigma}^2)$ 中抽取的随机值，$\\hat{\\sigma}^2$ 是残差的估计方差。只要误差是同方差且近似正态的，这个程序就是有效的。", "solution": "我们得到的是聚类数据：鱼嵌套在河流系统中。线性模型是\n$$\nY_{ij}=\\beta_{0}+\\beta_{1}X_{ij}+\\epsilon_{ij},\n$$\n具有跨河流独立性和河流内相关性。形式上，对于 $i \\neq i'$，\n$$\n\\text{Cov}(\\epsilon_{ij},\\epsilon_{i'k})=0,\n$$\n而对于同一河流 $i$ 和不同的鱼 $j \\neq k$，\n$$\n\\text{Cov}(\\epsilon_{ij},\\epsilon_{ik}) \\neq 0.\n$$\n一种标准的表达方式是通过随机效应分解，\n$$\n\\epsilon_{ij}=u_{i}+v_{ij},\n$$\n其中 $u_{i}$ 是河流特有的分量，$v_{ij}$ 是特异性分量，且 $\\text{Var}(u_{i})=\\sigma_{u}^{2}$，$\\text{Var}(v_{ij})=\\sigma_{v}^{2}$，$\\text{Cov}(u_{i},v_{ij})=0$，这意味着\n$$\n\\text{Var}(\\epsilon_{ij})=\\sigma_{u}^{2}+\\sigma_{v}^{2},\\quad \\text{Cov}(\\epsilon_{ij},\\epsilon_{ik})=\\sigma_{u}^{2}\\quad \\text{for }j \\neq k.\n$$\n独立的抽样单位是簇 $\\mathcal{C}_{i}=\\{(X_{ij},Y_{ij}):j=1,\\dots,n_{i}\\}$，其中 $i=1,\\dots,M$。为了使自助法在聚类依赖下对 $\\hat{\\beta}_{1}$ 的抽样分布保持一致性，重抽样方案必须模仿这种依赖结构：对独立的单位（河流）进行重抽样，并保留簇内联合分布。\n\n对所提议程序的评估：\n- 选项 A（朴素的个体层面自助法）从合并样本中有放回地独立同分布（i.i.d.）抽取 $N$ 条鱼，忽略了河流成员关系。这在所有重抽样观测值上强加了一个 i.i.d. 的误差结构，并且没有再现河流内的协方差 $\\text{Cov}(\\epsilon_{ij},\\epsilon_{ik})=\\sigma_{u}^{2}$。因此，当 $\\sigma_{u}^{2}>0$ 时，它产生的自助法方差通常会向下偏倚。引用中心极限定理对大 $N$ 的情况并不能修正自助法的不一致性；自助法必须复制正确的依赖关系才能估计聚类下 $\\hat{\\beta}_{1}$ 的方差。\n- 选项 B（聚类自助法）从 $\\{1,\\dots,M\\}$ 中有放回地抽样河流，并包括每个选定河流中的所有鱼，因此将 $\\{\\mathcal{C}_{i}\\}$ 作为 i.i.d. 单位进行重抽样。这保留了由 $u_{i}$ 引起的河流内相关性，并反映了哪些河流进入样本的随机性。在标准的正则性条件下（特别是，$M \\to \\infty$ 且 $n_{i}$ 有界或受到适当控制时），此程序对于具有聚类误差的 $\\hat{\\beta}_{1}$ 的抽样分布是渐近有效的。\n- 选项 C（合并所有残差的残差自助法）从合并的集合 $\\{e_{ij}\\}$ 中 i.i.d. 地抽样残差，并构造 $Y_{ij}^{*}=\\hat{\\beta}_{0}+\\hat{\\beta}_{1}X_{ij}+e_{ij}^{*}$。这在自助法世界中强制实施了 i.i.d. 误差，并破坏了河流内的协方差结构；因此，它对于聚类依赖是无效的。\n- 选项 D（固定簇的簇内重抽样）在每个观察到的河流内部对鱼进行重抽样，同时保持河流集合不变。这以特定的已实现的簇效应为条件，并没有反映当河流是独立单位时驱动 $\\hat{\\beta}_{1}$ 抽样分布的河流间抽样变异性。当簇效应是随机的时，它会低估方差，并且对于目标是河流总体的推断通常是无效的。\n- 选项 E（固定X的高斯参数自助法与 i.i.d. 噪声）独立地抽取 $\\delta_{ij}\\sim N(0,\\hat{\\sigma}^{2})$ 并设置 $Y_{ij}^{*}=\\hat{\\beta}_{0}+\\hat{\\beta}_{1}X_{ij}+\\delta_{ij}$。这强加了同方差 i.i.d. 误差，并且未能编码河流内的协方差；即使在正态性假设下，正确的参数自助法也需要在每个河流内使用估计的簇协方差来抽取一个多元正态误差向量，而不是独立的抽取。如其所述，它对于聚类依赖是无效的。\n\n因此，将河流正确地视为独立抽样单位并保留河流内相关性的程序是选项 B 中描述的聚类自助法，其陈述的理由与所需的论证相符。", "answer": "$$\\boxed{B}$$", "id": "1951652"}, {"introduction": "重抽样方法不仅限于估计置信区间，它也是进行假设检验的强大工具。本练习介绍了置换检验 (permutation test)，这是一种直观而严谨的方法，用于评估观测到的效应是否显著。通过置换（“洗牌”）数据标签，我们可以模拟在零假设（null hypothesis）成立的情况下可能发生的情景，从而无需对数据分布做特定假设，便可直接计算出 $p$ 值。[@problem_id:1951649]", "problem": "一名工业统计师的任务是比较两种用于生产特定类型电阻器的不同制造过程的一致性。过程 A 和过程 B 用于生产批量的电阻器，并测量其电阻值。目标是确定过程 B 是否表现出比过程 A 更大的变异性。由于可能存在离群值和非正态数据，因此选择了一种稳健的非参数方法。\n\n收集了两个独立的电阻值（单位：欧姆）随机样本：\n- 样本 A（来自过程 A）：$\\{10, 12, 13, 15\\}$\n- 样本 B（来自过程 B）：$\\{40, 48, 50, 53, 61\\}$\n\n该统计师决定使用基于两个样本的中位数绝对偏差（MAD）之比的检验。样本 $\\{x_1, x_2, \\dots, x_n\\}$ 的 MAD 定义为每个数据点与样本中位数之间绝对差的中位数：\n$$ \\text{MAD} = \\text{median} \\left( |x_i - \\text{median}(\\{x_j\\})| \\right) $$\n在本次分析中，MAD 的任何标准缩放常数都被忽略，因为它会在比率中被抵消。检验统计量定义为 $T = \\frac{\\text{MAD}(B)}{\\text{MAD}(A)}$。\n\n为了评估观测到的检验统计量的显著性，执行了一个计算置换程序。将 $4+5=9$ 个总数据点汇集在一起。从这个合并的集合中，生成了 9,999 次随机置换。在每次置换中，无放回地形成一个大小为 4 的新样本（称之为 A'）和一个大小为 5 的新样本（B'），并计算统计量 $T^* = \\frac{\\text{MAD}(B')}{\\text{MAD}(A')}$。\n\n从 9,999 次置换中得到的 30 个最大的 $T^*$ 值，按降序排列如下：\n`3.15, 2.98, 2.81, 2.75, 2.66, 2.54, 2.49, 2.41, 2.35, 2.33, 2.28, 2.22, 2.19, 2.15, 2.11, 2.08, 2.05, 2.02, 1.99, 1.97, 1.94, 1.90, 1.88, 1.85, 1.83, 1.80, 1.77, 1.76, 1.75, 1.72`\n\n使用提供的模拟结果，计算用于检验“过程 B 的尺度（变异性）大于过程 A”这一假设的单侧 p 值。p 值计算公式为 $p = \\frac{1+k}{1+N}$，其中 $N$ 是置换次数，$k$ 是置换统计量 $T^*$ 大于或等于从原始样本中观测到的统计量的次数。将您的答案以十进制形式表示，并四舍五入到四位有效数字。", "solution": "我们正在使用中位数绝对偏差（MAD）之比来检验过程 B 是否比过程 A 具有更大的变异性。样本 $\\{x_{1},\\dots,x_{n}\\}$ 的 MAD 定义为\n$$\n\\text{MAD}=\\text{median}\\left(|x_{i}-\\text{median}(\\{x_{j}\\})|\\right).\n$$\n首先计算观测到的统计量 $T=\\frac{\\text{MAD}(B)}{\\text{MAD}(A)}$。\n\n对于样本 A，$\\{10,12,13,15\\}$，样本中位数是中间两个顺序统计量的平均值：\n$$\n\\text{median}(A)=\\frac{12+13}{2}=12.5.\n$$\n与 $12.5$ 的绝对偏差为\n$$\n|10-12.5|=2.5,\\quad |12-12.5|=0.5,\\quad |13-12.5|=0.5,\\quad |15-12.5|=2.5.\n$$\n将这些值排序得到 $0.5,0.5,2.5,2.5$，所以 MAD 是这四个数的中位数，即中间两个值的平均值：\n$$\n\\text{MAD}(A)=\\frac{0.5+2.5}{2}=1.5.\n$$\n\n对于样本 B，$\\{40,48,50,53,61\\}$，样本中位数是中间的顺序统计量：\n$$\n\\text{median}(B)=50.\n$$\n与 $50$ 的绝对偏差为\n$$\n|40-50|=10,\\quad |48-50|=2,\\quad |50-50|=0,\\quad |53-50|=3,\\quad |61-50|=11.\n$$\n将这些值排序得到 $0,2,3,10,11$，所以 MAD 是中间值：\n$$\n\\text{MAD}(B)=3.\n$$\n因此，观测到的检验统计量为\n$$\nT=\\frac{\\text{MAD}(B)}{\\text{MAD}(A)}=\\frac{3}{1.5}=2.\n$$\n\n根据 $N=9999$ 次置换的置换程序，我们必须计算 $k$，即置换统计量 $T^{*}$ 大于或等于观测值 $T=2$ 的次数。给出了按降序排列的 $30$ 个最大的 $T^{*}$ 值。在这些值中，第 $18$ 大的值是 $2.02\\geq 2$，而第 $19$ 大的值是 $1.99<2$。由于所有剩余的值都小于或等于 $1.99$，因此恰好有 $k=18$ 次置换满足 $T^{*}\\geq 2$。\n\n使用加一 p 值公式\n$$\np=\\frac{1+k}{1+N}=\\frac{1+18}{1+9999}=\\frac{19}{10000}=1.9\\times 10^{-3}.\n$$\n四舍五入到四位有效数字，结果是\n$$\n1.900\\times 10^{-3}.\n$$", "answer": "$$\\boxed{1.900 \\times 10^{-3}}$$", "id": "1951649"}]}