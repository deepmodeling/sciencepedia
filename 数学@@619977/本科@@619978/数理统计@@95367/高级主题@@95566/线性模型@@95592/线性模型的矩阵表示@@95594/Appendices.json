{"hands_on_practices": [{"introduction": "在求解线性模型的系数之前，我们必须首先将问题以矩阵形式建立起来。这个练习提供了构建 $X^T X$ 矩阵的基础实践，它是普通最小二乘法（OLS）正规方程的关键组成部分。掌握这一步对于理解回归系数如何估计至关重要。[@problem_id:1933331]", "problem": "考虑一个用于分析预测变量 $x$ 和响应变量 $y$ 之间关系的简单线性回归模型。该模型由 $y_i = \\beta_0 + \\beta_1 x_i + \\epsilon_i$ 给出，其中 $i=1, 2, 3, 4$。进行了一项实验，得到预测变量的四个观测值：$x_1 = 1$、$x_2 = 2$、$x_3 = 3$ 和 $x_4 = 4$。\n\n该模型可以写成矩阵形式 $\\mathbf{y} = X\\boldsymbol{\\beta} + \\boldsymbol{\\epsilon}$，其中 $X$ 是设计矩阵。\n\n确定矩阵乘积 $X^T X$。将答案表示为一个 $1 \\times 4$ 的行矩阵，按行主序（row-major order）列出这个 $2 \\times 2$ 乘积矩阵的元素（即，第一行的元素后跟第二行的元素）。", "solution": "带截距项的简单线性回归模型，其设计矩阵由一列全为1的列和一列预测变量值构成。因此\n$$\nX=\\begin{pmatrix}\n1 & x_{1}\\\\\n1 & x_{2}\\\\\n1 & x_{3}\\\\\n1 & x_{4}\n\\end{pmatrix}.\n$$\n代入给定的值 $x_{1}=1$、$x_{2}=2$、$x_{3}=3$、$x_{4}=4$，该矩阵变为\n$$\nX=\\begin{pmatrix}\n1 & 1\\\\\n1 & 2\\\\\n1 & 3\\\\\n1 & 4\n\\end{pmatrix}.\n$$\n根据矩阵乘法的定义，$X^{T}X$ 的元素为\n$$\n(X^{T}X)_{11}=\\sum_{i=1}^{4}1\\cdot 1=\\sum_{i=1}^{4}1,\\quad\n(X^{T}X)_{12}=\\sum_{i=1}^{4}1\\cdot x_{i}=\\sum_{i=1}^{4}x_{i},\n$$\n$$\n(X^{T}X)_{21}=\\sum_{i=1}^{4}x_{i}\\cdot 1=\\sum_{i=1}^{4}x_{i},\\quad\n(X^{T}X)_{22}=\\sum_{i=1}^{4}x_{i}\\cdot x_{i}=\\sum_{i=1}^{4}x_{i}^{2}.\n$$\n计算这些和：\n$$\n\\sum_{i=1}^{4}1=4,\\quad \\sum_{i=1}^{4}x_{i}=1+2+3+4=10,\\quad \\sum_{i=1}^{4}x_{i}^{2}=1^{2}+2^{2}+3^{2}+4^{2}=30.\n$$\n因此\n$$\nX^{T}X=\\begin{pmatrix}\n4 & 10\\\\\n10 & 30\n\\end{pmatrix},\n$$\n将其按行主序写成一个 $1\\times 4$ 的行矩阵为\n$$\n\\begin{pmatrix}\n4 & 10 & 10 & 30\n\\end{pmatrix}.\n$$", "answer": "$$\\boxed{\\begin{pmatrix} 4 & 10 & 10 & 30 \\end{pmatrix}}$$", "id": "1933331"}, {"introduction": "普通最小二乘法有几个优美的性质，这些性质直接源于其矩阵表示。本练习将引导你通过矩阵证明，来说明对于任何带截距项的线性模型，其残差之和恒为零。这展示了矩阵代数在揭示我们模型背后几何与统计特性方面的强大能力。[@problem_id:1933375]", "problem": "在简单线性回归模型的研究中，我们使用矩阵表示法来表达响应向量 $\\mathbf{y}$ 和预测向量 $\\mathbf{x}$ 之间的关系。考虑一个包含 $n$ 个观测值的数据集。模型由 $\\mathbf{y} = \\mathbf{X}\\boldsymbol{\\beta} + \\boldsymbol{\\epsilon}$ 给出，其中：\n- $\\mathbf{y}$ 是观测响应值的 $n \\times 1$ 向量。\n- $\\mathbf{X}$ 是 $n \\times 2$ 的设计矩阵。对于一个带截距的简单线性回归模型，$\\mathbf{X}$ 构建为 $[\\mathbf{1} \\quad \\mathbf{x}]$，其中 $\\mathbf{1}$ 是一个 $n \\times 1$ 的全1列向量，$\\mathbf{x}$ 是预测变量观测值的 $n \\times 1$ 列向量。\n- $\\boldsymbol{\\beta} = [\\beta_0 \\quad \\beta_1]^T$ 是 $2 \\times 1$ 的模型系数（截距和斜率）向量。\n- $\\boldsymbol{\\epsilon}$ 是 $n \\times 1$ 的随机误差向量。\n\n系数通过普通最小二乘法 (OLS) 进行估计，得到估计量 $\\hat{\\boldsymbol{\\beta}} = (\\mathbf{X}^T\\mathbf{X})^{-1}\\mathbf{X}^T\\mathbf{y}$。拟合值向量为 $\\hat{\\mathbf{y}} = \\mathbf{X}\\hat{\\boldsymbol{\\beta}}$，残差向量定义为 $\\mathbf{e} = \\mathbf{y} - \\hat{\\mathbf{y}}$。\n\n根据所提供的定义，确定标量 $\\mathbf{1}^T \\mathbf{e}$ 的值。\n\nA. $0$\n\nB. $n$\n\nC. $\\mathbf{1}^T\\mathbf{y}$\n\nD. $\\det(\\mathbf{X}^T\\mathbf{X})$", "solution": "问题要求标量积 $\\mathbf{1}^T \\mathbf{e}$ 的值。我们从普通最小二乘法 (OLS) 估计量 $\\hat{\\boldsymbol{\\beta}}$ 的定义开始。OLS 估计量是通过最小化残差平方和 $S(\\boldsymbol{\\beta}) = \\mathbf{e}^T\\mathbf{e} = (\\mathbf{y} - \\mathbf{X}\\boldsymbol{\\beta})^T(\\mathbf{y} - \\mathbf{X}\\boldsymbol{\\beta})$ 推导出来的。\n\n为了找到最小值，我们对 $S(\\boldsymbol{\\beta})$ 关于向量 $\\boldsymbol{\\beta}$ 求导，并令其为零。\n$$S(\\boldsymbol{\\beta}) = \\mathbf{y}^T\\mathbf{y} - \\mathbf{y}^T\\mathbf{X}\\boldsymbol{\\beta} - \\boldsymbol{\\beta}^T\\mathbf{X}^T\\mathbf{y} + \\boldsymbol{\\beta}^T\\mathbf{X}^T\\mathbf{X}\\boldsymbol{\\beta}$$\n因为 $\\boldsymbol{\\beta}^T\\mathbf{X}^T\\mathbf{y}$ 是一个标量，所以它等于其转置，即 $(\\boldsymbol{\\beta}^T\\mathbf{X}^T\\mathbf{y})^T = \\mathbf{y}^T\\mathbf{X}\\boldsymbol{\\beta}$。因此，我们可以写成：\n$$S(\\boldsymbol{\\beta}) = \\mathbf{y}^T\\mathbf{y} - 2\\boldsymbol{\\beta}^T\\mathbf{X}^T\\mathbf{y} + \\boldsymbol{\\beta}^T\\mathbf{X}^T\\mathbf{X}\\boldsymbol{\\beta}$$\n关于 $\\boldsymbol{\\beta}$ 的导数是：\n$$\\frac{\\partial S(\\boldsymbol{\\beta})}{\\partial \\boldsymbol{\\beta}} = -2\\mathbf{X}^T\\mathbf{y} + 2\\mathbf{X}^T\\mathbf{X}\\boldsymbol{\\beta}$$\n将导数设为零以求得估计量 $\\hat{\\boldsymbol{\\beta}}$，可得：\n$$-2\\mathbf{X}^T\\mathbf{y} + 2\\mathbf{X}^T\\mathbf{X}\\hat{\\boldsymbol{\\beta}} = \\mathbf{0}$$\n$$\\mathbf{X}^T\\mathbf{X}\\hat{\\boldsymbol{\\beta}} = \\mathbf{X}^T\\mathbf{y}$$\n这组方程被称为正规方程组。我们可以将正规方程组重新整理为：\n$$\\mathbf{X}^T\\mathbf{y} - \\mathbf{X}^T\\mathbf{X}\\hat{\\boldsymbol{\\beta}} = \\mathbf{0}$$\n提取公因子 $\\mathbf{X}^T$ 可得：\n$$\\mathbf{X}^T(\\mathbf{y} - \\mathbf{X}\\hat{\\boldsymbol{\\beta}}) = \\mathbf{0}$$\n根据定义，残差向量为 $\\mathbf{e} = \\mathbf{y} - \\hat{\\mathbf{y}}$。由于拟合值向量为 $\\hat{\\mathbf{y}} = \\mathbf{X}\\hat{\\boldsymbol{\\beta}}$，我们可以将残差向量写为 $\\mathbf{e} = \\mathbf{y} - \\mathbf{X}\\hat{\\boldsymbol{\\beta}}$。\n将这个表达式代入重新整理后的正规方程组，我们得到：\n$$\\mathbf{X}^T\\mathbf{e} = \\mathbf{0}$$\n问题指明这是一个带截距的简单线性回归。设计矩阵 $\\mathbf{X}$ 由 $\\mathbf{X} = [\\mathbf{1} \\quad \\mathbf{x}]$ 给出，其中 $\\mathbf{1}$ 是一个 $n \\times 1$ 的全1向量，$\\mathbf{x}$ 是预测变量值的 $n \\times 1$ 向量。\n\n设计矩阵的转置是 $\\mathbf{X}^T = \\begin{pmatrix} \\mathbf{1}^T \\\\ \\mathbf{x}^T \\end{pmatrix}$。\n现在，我们可以明确地写出方程 $\\mathbf{X}^T\\mathbf{e} = \\mathbf{0}$：\n$$\\begin{pmatrix} \\mathbf{1}^T \\\\ \\mathbf{x}^T \\end{pmatrix} \\mathbf{e} = \\begin{pmatrix} \\mathbf{1}^T\\mathbf{e} \\\\ \\mathbf{x}^T\\mathbf{e} \\end{pmatrix} = \\begin{pmatrix} 0 \\\\ 0 \\end{pmatrix}$$\n这个矩阵方程代表一个包含两个独立方程的方程组：\n1. $\\mathbf{1}^T\\mathbf{e} = 0$\n2. $\\mathbf{x}^T\\mathbf{e} = 0$\n\n我们被要求解的量是 $\\mathbf{1}^T\\mathbf{e}$。从方程组的第一个方程中，我们看到 $\\mathbf{1}^T\\mathbf{e} = 0$。\n表达式 $\\mathbf{1}^T\\mathbf{e}$ 是一个全1向量与残差向量的点积，这等价于残差向量各元素之和：$\\mathbf{1}^T\\mathbf{e} = \\sum_{i=1}^n e_i$。因此，我们证明了在一个带截距的简单线性回归中，残差之和为零。\n\n将我们的结果与给定选项进行比较：\nA. $0$\nB. $n$\nC. $\\mathbf{1}^T\\mathbf{y}$\nD. $\\det(\\mathbf{X}^T\\mathbf{X})$\n\n我们推导出的值为 $0$。因此，选项 A 是正确答案。", "answer": "$$\\boxed{A}$$", "id": "1933375"}, {"introduction": "虽然通过矩阵求逆来解正规方程在理论上很直接，但在实践中可能存在数值不稳定的问题。本练习介绍了一种更稳健且计算效率更高的方法：QR分解。通过将该技术应用于一个给定的数据集，你将学会如何绕过直接求逆，并使用回代法求解模型系数，这正是现代统计软件中首选的方法。[@problem_id:1933337]", "problem": "一位材料科学家正在研究一种新开发的热电发电机的性能。电功率输出 $y$ 被建模为两个操作参数的线性函数：器件上的温度梯度 $x_1$ 和用于其结构的一种新型复合材料的热导率 $x_2$。\n\n该关系由以下多元线性回归模型描述：\n$$y = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + \\epsilon$$\n其中 $\\beta_0, \\beta_1, \\beta_2$ 是待估计的模型系数，而 $\\epsilon$ 是随机误差项。\n\n进行了四次实验，得到了响应向量 $Y$ 和设计矩阵 $X$ 的以下数据：\n$$\nY = \\begin{pmatrix} 1 \\\\ 1 \\\\ 4 \\\\ 6 \\end{pmatrix}, \\quad\nX = \\begin{pmatrix} 1 & 1 & 2 \\\\ 1 & 2 & 3 \\\\ 1 & 3 & 5 \\\\ 1 & 4 & 6 \\end{pmatrix}\n$$\n为了数值稳定性和效率，设计矩阵 $X$ 已被分解为乘积 $X=QR$，其中 $Q$ 是一个具有标准正交列的矩阵，而 $R$ 是一个上三角矩阵。这些矩阵如下所示：\n$$\nQ = \\begin{pmatrix}\n\\frac{1}{2} & -\\frac{3}{2\\sqrt{5}} & \\frac{1}{2\\sqrt{5}} \\\\\n\\frac{1}{2} & -\\frac{1}{2\\sqrt{5}} & -\\frac{3}{2\\sqrt{5}} \\\\\n\\frac{1}{2} & \\frac{1}{2\\sqrt{5}} & \\frac{3}{2\\sqrt{5}} \\\\\n\\frac{1}{2} & \\frac{3}{2\\sqrt{5}} & -\\frac{1}{2\\sqrt{5}}\n\\end{pmatrix}, \\quad\nR = \\begin{pmatrix}\n2 & 5 & 8 \\\\\n0 & \\sqrt{5} & \\frac{7}{\\sqrt{5}} \\\\\n0 & 0 & \\frac{1}{\\sqrt{5}}\n\\end{pmatrix}\n$$\n\n确定系数向量的最小二乘 (OLS) 估计 $\\hat{\\boldsymbol{\\beta}} = (\\hat{\\beta}_0, \\hat{\\beta}_1, \\hat{\\beta}_2)^T$。将向量 $\\hat{\\boldsymbol{\\beta}}$ 的每个分量表示为精确的小数。", "solution": "我们使用 QR 方法进行最小二乘法计算。当 $X=QR$ 时，其中 $Q$ 具有标准正交列 ($Q^T Q = I$) 且 $R$ 是上三角矩阵，OLS 估计 $\\hat{\\boldsymbol{\\beta}}$ 是以下最小化问题的解：\n$$\n\\min_{\\boldsymbol{\\beta}}\\|Y-X\\boldsymbol{\\beta}\\|_{2}=\\min_{\\boldsymbol{\\beta}}\\|Y-QR\\boldsymbol{\\beta}\\|_{2}.\n$$\n左乘 $Q^T$ 并利用 $Q^T Q=I$ 可得到以下三角方程组：\n$$\nR\\hat{\\boldsymbol{\\beta}}=Q^T Y.\n$$\n因此，我们先计算 $z=Q^T Y$，然后通过回代法求解 $R\\hat{\\boldsymbol{\\beta}}=z$。\n\n已知\n$$\nQ=\\begin{pmatrix}\n\\frac{1}{2} & -\\frac{3}{2\\sqrt{5}} & \\frac{1}{2\\sqrt{5}} \\\\\n\\frac{1}{2} & -\\frac{1}{2\\sqrt{5}} & -\\frac{3}{2\\sqrt{5}} \\\\\n\\frac{1}{2} & \\frac{1}{2\\sqrt{5}} & \\frac{3}{2\\sqrt{5}} \\\\\n\\frac{1}{2} & \\frac{3}{2\\sqrt{5}} & -\\frac{1}{2\\sqrt{5}}\n\\end{pmatrix},\\quad\nY=\\begin{pmatrix}1\\\\1\\\\4\\\\6\\end{pmatrix},\n$$\n$z=Q^{T}Y$ 的分量是\n$$\nz_{1}=q_{1}^{T}Y=\\frac{1}{2}(1+1+4+6)=6,\n$$\n$$\nz_{2}=q_{2}^{T}Y=\\frac{1}{2\\sqrt{5}}\\big((-3)\\cdot 1+(-1)\\cdot 1+1\\cdot 4+3\\cdot 6\\big)=\\frac{18}{2\\sqrt{5}}=\\frac{9}{\\sqrt{5}},\n$$\n$$\nz_{3}=q_{3}^{T}Y=\\frac{1}{2\\sqrt{5}}\\big(1\\cdot 1+(-3)\\cdot 1+3\\cdot 4+(-1)\\cdot 6\\big)=\\frac{4}{2\\sqrt{5}}=\\frac{2}{\\sqrt{5}}.\n$$\n根据\n$$\nR=\\begin{pmatrix}\n2 & 5 & 8 \\\\\n0 & \\sqrt{5} & \\frac{7}{\\sqrt{5}} \\\\\n0 & 0 & \\frac{1}{\\sqrt{5}}\n\\end{pmatrix},\n$$\n我们求解 $R\\hat{\\boldsymbol{\\beta}}=z$：\n- 第三个方程：$\\frac{1}{\\sqrt{5}}\\hat{\\beta}_{2}=\\frac{2}{\\sqrt{5}} \\implies \\hat{\\beta}_{2}=2$。\n- 第二个方程：$\\sqrt{5}\\hat{\\beta}_{1}+\\frac{7}{\\sqrt{5}}\\hat{\\beta}_{2}=\\frac{9}{\\sqrt{5}}$。两边同乘以 $\\sqrt{5}$ 得到 $5\\hat{\\beta}_{1}+7\\hat{\\beta}_{2}=9$。代入 $\\hat{\\beta}_{2}=2$ 可得 $5\\hat{\\beta}_{1}+14=9 \\implies \\hat{\\beta}_{1}=-1$。\n- 第一个方程：$2\\hat{\\beta}_{0}+5\\hat{\\beta}_{1}+8\\hat{\\beta}_{2}=6$。代入 $\\hat{\\beta}_{1}=-1$ 和 $\\hat{\\beta}_{2}=2$ 可得 $2\\hat{\\beta}_{0}-5+16=6 \\implies 2\\hat{\\beta}_{0}+11=6 \\implies \\hat{\\beta}_{0}=-2.5$。\n\n因此，\n$$\n\\hat{\\boldsymbol{\\beta}}=\\begin{pmatrix}-2.5 \\\\ -1 \\\\ 2\\end{pmatrix}.\n$$", "answer": "$$\\boxed{\\begin{pmatrix} -2.5 \\\\ -1 \\\\ 2 \\end{pmatrix}}$$", "id": "1933337"}]}