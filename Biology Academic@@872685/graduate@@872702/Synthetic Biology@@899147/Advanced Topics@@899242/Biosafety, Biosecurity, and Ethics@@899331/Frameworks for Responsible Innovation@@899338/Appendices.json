{"hands_on_practices": [{"introduction": "Effective biocontainment is fundamental to the safe application of synthetic biology. This practice moves beyond idealized models by challenging the common assumption of independence between safety layers, teaching you how to use first principles of probability to account for common-cause failures that can simultaneously disable redundant systems. Mastering this concept is crucial for creating robust and realistic risk assessments for engineered organisms. [@problem_id:2739681]", "problem": "A synthetic biology team designs a $2$-layer biocontainment architecture for a chassis microbe intended for open-system bioprocessing research. In each operating cycle, layer $1$ fails with marginal probability $p_{1}$ and layer $2$ fails with marginal probability $p_{2}$, where $0 < p_{1} < 1$ and $0 < p_{2} < 1$. Within Responsible Research and Innovation (RRI), the team must quantify the overall probability of organism escape in a single cycle and assess the robustness of the independence assumption for the two layers.\n\nStarting only from the axioms of probability, the definition of independence, and the law of total probability, do the following:\n\n1. Define the escape event as the joint failure of both layers in a cycle and derive, from first principles, the expression for the escape probability under the assumption that layer failures are independent.\n\n2. Independence can fail in realistic field conditions because a single common-cause hazard (for example, an off-nominal temperature spike) can simultaneously disable both layers. Let $C$ be the event that such a common cause occurs in a cycle with probability $\\delta$, where $0 \\leq \\delta \\leq \\min\\{p_{1}, p_{2}\\}$, and suppose that:\n   - Given $C$, both layers fail in that cycle.\n   - Given $\\overline{C}$, the two layers fail independently, and the observed marginal failure probabilities of the layers over the full mixture of conditions remain $p_{1}$ and $p_{2}$.\n\nUsing only these assumptions and the law of total probability, derive a closed-form expression for the escape probability in a single cycle as a function of $p_{1}$, $p_{2}$, and $\\delta$. Your final answer must be a single closed-form analytic expression.\n\nIn your derivation, explicitly state the conditions under which the independence assumption fails in this model in terms of the parameters and events you introduce. Do not use any shortcut formulas that are not derived from the stated foundational principles. Do not perform any numerical substitutions. Express the final escape probability as a symbolic expression in terms of $p_{1}$, $p_{2}$, and $\\delta$ only. No units are required.", "solution": "The problem statement is subjected to validation and is found to be scientifically grounded, well-posed, and objective. It is a standard problem in reliability theory, framed within the context of synthetic biology, and is constructed from fundamental principles of probability theory. All parameters and conditions are clearly defined and consistent. We may therefore proceed with the derivation.\n\nLet $F_{1}$ be the event that layer $1$ fails and $F_{2}$ be the event that layer $2$ fails in a single operating cycle. The problem statement gives their marginal probabilities as $P(F_{1}) = p_{1}$ and $P(F_{2}) = p_{2}$, with $0 < p_{1} < 1$ and $0 < p_{2} < 1$. The escape event, which we denote as $E$, is defined as the joint failure of both layers, i.e., $E = F_{1} \\cap F_{2}$. We are tasked to find the probability of this event, $P(E) = P(F_{1} \\cap F_{2})$.\n\nFirst, we address part $1$ of the problem, which assumes the failure events $F_{1}$ and $F_{2}$ are statistically independent. The definition of independence for two events $A$ and $B$ states that $P(A \\cap B) = P(A)P(B)$. Applying this principle directly to the events $F_{1}$ and $F_{2}$ gives the probability of the escape event $E$:\n$$P(E) = P(F_{1} \\cap F_{2}) = P(F_{1})P(F_{2})$$\nSubstituting the given marginal probabilities, we obtain the expression for the escape probability under the independence assumption:\n$$P(E) = p_{1}p_{2}$$\n\nNext, we address part $2$, which introduces a more complex model involving a common-cause failure event. Let $C$ be the event of a common-cause hazard occurring, with probability $P(C) = \\delta$. The complementary event, $\\overline{C}$, is the absence of such a hazard, and its probability is $P(\\overline{C}) = 1 - P(C) = 1 - \\delta$. The set of events $\\{C, \\overline{C}\\}$ forms a partition of the sample space.\n\nWe are to derive the escape probability $P(E) = P(F_{1} \\cap F_{2})$ using the law of total probability, which states that for any event $A$ and a partition $\\{B_{i}\\}$, $P(A) = \\sum_{i} P(A|B_{i})P(B_{i})$. Applying this to event $E$ over the partition $\\{C, \\overline{C}\\}$:\n$$P(E) = P(F_{1} \\cap F_{2} | C)P(C) + P(F_{1} \\cap F_{2} | \\overline{C})P(\\overline{C})$$\n\nWe evaluate each term based on the problem's stated assumptions:\n1.  \"Given $C$, both layers fail in that cycle.\" This means the conditional probability of joint failure, given the common cause, is unity: $P(F_{1} \\cap F_{2} | C) = 1$.\n2.  \"Given $\\overline{C}$, the two layers fail independently.\" This implies that the conditional probability of joint failure, given no common cause, is the product of their individual conditional probabilities: $P(F_{1} \\cap F_{2} | \\overline{C}) = P(F_{1} | \\overline{C})P(F_{2} | \\overline{C})$.\n\nSubstituting these into the total probability equation yields:\n$$P(E) = (1) \\cdot \\delta + P(F_{1} | \\overline{C})P(F_{2} | \\overline{C})(1 - \\delta)$$\n\nTo complete this expression, we must find the conditional probabilities $P(F_{1} | \\overline{C})$ and $P(F_{2} | \\overline{C})$. The problem specifies that the overall marginal probabilities $P(F_{1}) = p_{1}$ and $P(F_{2}) = p_{2}$ are conserved. We again use the law of total probability, this time for $F_{1}$ and $F_{2}$ individually:\n$$P(F_{1}) = p_{1} = P(F_{1} | C)P(C) + P(F_{1} | \\overline{C})P(\\overline{C})$$\n$$P(F_{2}) = p_{2} = P(F_{2} | C)P(C) + P(F_{2} | \\overline{C})P(\\overline{C})$$\nFrom assumption $1$, if $C$ occurs, both layers are guaranteed to fail, which implies $P(F_1 | C) = 1$ and $P(F_2 | C) = 1$. Substituting these values:\n$$p_{1} = (1)\\cdot\\delta + P(F_{1} | \\overline{C})(1 - \\delta)$$\n$$p_{2} = (1)\\cdot\\delta + P(F_{2} | \\overline{C})(1 - \\delta)$$\nWe must now solve these equations for the conditional probabilities. The condition $0 < p_{1,2} < 1$ and $0 \\leq \\delta \\leq \\min\\{p_{1}, p_{2}\\}$ ensures that $\\delta < 1$, so $1 - \\delta > 0$, and we can divide by this term.\n$$P(F_{1} | \\overline{C}) = \\frac{p_{1} - \\delta}{1 - \\delta}$$\n$$P(F_{2} | \\overline{C}) = \\frac{p_{2} - \\delta}{1 - \\delta}$$\nThe condition $\\delta \\leq p_{1}$ and $\\delta \\leq p_{2}$ ensures the numerators are non-negative, and the condition $p_{1,2} < 1$ ensures the resulting fractions are less than or equal to $1$, confirming these are valid probabilities.\n\nNow, we substitute these expressions back into our formula for $P(E)$:\n$$P(E) = \\delta + \\left( \\frac{p_{1} - \\delta}{1 - \\delta} \\right) \\left( \\frac{p_{2} - \\delta}{1 - \\delta} \\right) (1 - \\delta)$$\nThis simplifies to:\n$$P(E) = \\delta + \\frac{(p_{1} - \\delta)(p_{2} - \\delta)}{1 - \\delta}$$\nTo express this in a more insightful form that separates the independent and common-cause failure contributions, we can show that the increase in risk over the independent case, $p_1 p_2$, is:\n$$ P(E) - p_1 p_2 = \\left( \\delta + \\frac{(p_{1} - \\delta)(p_{2} - \\delta)}{1 - \\delta} \\right) - p_1 p_2 $$\n$$ = \\frac{\\delta(1-\\delta) + (p_1 p_2 - p_1\\delta - p_2\\delta + \\delta^2) - p_1 p_2(1-\\delta)}{1-\\delta} $$\n$$ = \\frac{\\delta - \\delta^2 + p_1 p_2 - p_1\\delta - p_2\\delta + \\delta^2 - p_1 p_2 + p_1 p_2 \\delta}{1-\\delta} $$\n$$ = \\frac{\\delta - p_1\\delta - p_2\\delta + p_1 p_2 \\delta}{1-\\delta} = \\frac{\\delta(1 - p_1 - p_2 + p_1p_2)}{1-\\delta} $$\n$$ = \\frac{\\delta(1 - p_{1})(1 - p_{2})}{1 - \\delta} $$\nTherefore, the escape probability can be expressed as the sum of the independent probability and this additional risk term:\n$$P(E) = p_{1}p_{2} + \\frac{\\delta(1 - p_{1})(1 - p_{2})}{1 - \\delta}$$\nThis expression clearly separates the baseline probability under independence, $p_{1}p_{2}$, from the additional risk term arising from the non-zero probability $\\delta$ of a common-cause failure.\n\nFinally, we identify the conditions under which the independence assumption fails. The events $F_{1}$ and $F_{2}$ are independent if and only if $P(F_{1} \\cap F_{2}) = P(F_{1})P(F_{2})$. In our model, this means:\n$$p_{1}p_{2} + \\frac{\\delta(1 - p_{1})(1 - p_{2})}{1 - \\delta} = p_{1}p_{2}$$\nThis equality holds if and only if the second term is zero:\n$$\\frac{\\delta(1 - p_{1})(1 - p_{2})}{1 - \\delta} = 0$$\nGiven the constraints $0 < p_{1} < 1$ and $0 < p_{2} < 1$, the terms $(1-p_{1})$ and $(1-p_{2})$ are strictly positive. As $\\delta \\le \\min\\{p_1, p_2\\}$, we have $\\delta < 1$, so the denominator $(1-\\delta)$ is also strictly positive. Thus, the fraction is zero if and only if its numerator is zero, which requires $\\delta = 0$.\nThe independence assumption fails if and only if $\\delta > 0$. In terms of the events defined, this means independence is violated whenever the common-cause event $C$ has a non-zero probability of occurrence. The existence of event $C$ is the sole source of statistical dependence in this model.", "answer": "$$\n\\boxed{p_{1}p_{2} + \\frac{\\delta(1 - p_{1})(1 - p_{2})}{1 - \\delta}}\n$$", "id": "2739681"}, {"introduction": "Responsible innovation often involves making high-stakes decisions with incomplete information, such as whether to fund a pilot study before a full-scale deployment. This exercise equips you with a powerful tool from decision theory, the Expected Value of Sample Information (EVSI), to quantify the economic rationale for gathering more data. You will learn to weigh the benefits of reduced uncertainty against the costs and delays of further research, a core skill in adaptive risk governance. [@problem_id:2739646]", "problem": "A municipal authority is applying the principles of Responsible Research and Innovation (RRI) to decide whether to proceed with a city-scale release of an engineered microbe designed to improve wastewater nitrogen removal. Acting under adaptive risk governance, they consider running a small pilot study before a city-scale release. Model the decision using Bayesian decision theory and the Expected Value of Sample Information (EVSI), and determine whether running the pilot is rational when accounting for both direct pilot costs and time delay.\n\nFoundational base facts and definitions:\n- Expected utility is defined as the probability-weighted sum of utilities over uncertain states.\n- Bayes’ theorem updates a prior probability to a posterior probability given new data.\n- The Expected Value of Sample Information (EVSI) is the expected increase in maximum expected utility enabled by observing sample information, before subtracting the cost of obtaining that information.\n\nSetup:\n- There are two states of the world: $S$ (sufficiently safe to deploy) and $U$ (unsafe to deploy).\n- The prior probability of $S$ based on preclinical and contained-field data is $P(S)=0.6$; thus $P(U)=0.4$.\n- If the city deploys at scale and the true state is $S$, the net social benefit is $B=10$ (in millions of dollars). If the city deploys at scale and the true state is $U$, the net social welfare is $-H$ with $H=40$ (in millions of dollars), representing expected harm and mitigation costs. If the city does not deploy, the net utility is $0$ regardless of the state.\n- Without new information, the authority will choose the action with the higher expected utility under the prior.\n- A proposed small pilot produces a binary signal: “pass” (meets containment and ecological performance thresholds) or “fail.” Its performance is characterized by sensitivity and specificity:\n  - Sensitivity $=$ $P(\\text{pass}\\mid S)=0.85$.\n  - Specificity $=$ $P(\\text{fail}\\mid U)=0.90$ (hence $P(\\text{pass}\\mid U)=0.10$).\n- The pilot costs $C_{p}=1$ (in millions of dollars), paid now.\n- The pilot requires $\\tau=0.5$ years to complete, after which the city-scale decision is made conditioned on the signal. Benefits or harms from city-scale deployment, if chosen after observing the pilot, are realized after this delay.\n- Use a continuous discount rate of $\\delta=0.05$ per year for time preference. Assume that any benefits or harms of city-scale deployment are realized as a lump-sum net utility at deployment time; therefore, discount them by $\\exp(-\\delta \\tau)$ when evaluating the with-pilot strategy relative to the status quo.\n\nTask:\n- Starting from the definitions of expected utility, Bayes’ theorem, and the definition of EVSI as an expected gain in optimal expected utility from conditioning the decision on the pilot signal, derive the decision rule with and without the pilot and compute the EVSI.\n- Account for the delay by discounting any post-pilot deployment payoffs by $\\exp(-\\delta \\tau)$, and subtract the pilot cost $C_{p}$ to obtain the net value of running the pilot.\n\nProvide as your final answer the net expected value of running the pilot (EVSI adjusted for delay and minus $C_{p}$), expressed in millions of dollars. Round your answer to four significant figures.", "solution": "The problem asks for the net expected value of conducting a pilot study before making a decision on the city-scale deployment of an engineered microbe. This is a problem in Bayesian decision theory, where we must compare the expected utility of two strategies: making a decision now versus making a decision after gathering more information.\n\nFirst, I will validate the problem statement.\nThe givens are:\nStates of the world: $S$ (sufficiently safe), $U$ (unsafe).\nPrior probabilities: $P(S) = 0.6$, $P(U) = 1 - 0.6 = 0.4$.\nPayoffs for city-scale deployment: Net benefit if state is $S$ is $B=10$. Net harm if state is $U$ is $-H$ with $H=40$. The utility of not deploying is $0$.\nPilot signal performance:\nSensitivity: $P(\\text{pass}\\mid S) = 0.85$.\nSpecificity: $P(\\text{fail}\\mid U) = 0.90$.\nFrom these, we can deduce:\n$P(\\text{fail}\\mid S) = 1 - P(\\text{pass}\\mid S) = 1 - 0.85 = 0.15$.\n$P(\\text{pass}\\mid U) = 1 - P(\\text{fail}\\mid U) = 1 - 0.90 = 0.10$.\nCosts and time parameters:\nPilot cost: $C_{p} = 1$ (millions of dollars), paid at present time.\nPilot duration: $\\tau = 0.5$ years.\nContinuous discount rate: $\\delta = 0.05$ per year.\nThe discount factor for payoffs realized after the pilot is $\\exp(-\\delta \\tau)$.\n\nThe problem is scientifically grounded, well-posed, objective, and contains all necessary information for a solution. It does not violate any listed criteria for invalidity. Therefore, I will proceed with the solution.\n\nThe decision must be made by comparing the expected utility of two strategies. All utility values are in millions of dollars.\n\nStrategy 1: Decision without a pilot study.\nThe decision is between \"Deploy\" and \"Not Deploy\", made at present time based on prior probabilities.\nThe expected utility of deploying, $EU(\\text{Deploy})$, is the sum of probability-weighted outcomes:\n$$EU(\\text{Deploy}) = P(S) \\cdot B + P(U) \\cdot (-H)$$\nSubstituting the given values:\n$$EU(\\text{Deploy}) = (0.6)(10) + (0.4)(-40) = 6 - 16 = -10$$\nThe expected utility of not deploying, $EU(\\text{Not Deploy})$, is given as $0$.\n$$EU(\\text{Not Deploy}) = 0$$\nThe optimal decision is the one with the higher expected utility. Let $V_{\\text{no pilot}}$ be the value of this optimal strategy.\n$$V_{\\text{no pilot}} = \\max(EU(\\text{Deploy}), EU(\\text{Not Deploy})) = \\max(-10, 0) = 0$$\nWithout the pilot, the rational decision is to not deploy, for an expected utility of $0$.\n\nStrategy 2: Decision after conducting the pilot study.\nThis strategy has three components: the immediate cost of the pilot, the time delay, and the information-contingent decision. The value of this strategy is evaluated at the present time.\nFirst, we must calculate the posterior probabilities of the states $S$ and $U$ conditional on the pilot signal (\"pass\" or \"fail\"), using Bayes' theorem. To do so, we first need the marginal probabilities of the signals.\n\nThe probability of a \"pass\" signal, $P(\\text{pass})$, is:\n$$P(\\text{pass}) = P(\\text{pass} \\mid S)P(S) + P(\\text{pass} \\mid U)P(U)$$\n$$P(\\text{pass}) = (0.85)(0.6) + (0.10)(0.4) = 0.51 + 0.04 = 0.55$$\nThe probability of a \"fail\" signal, $P(\\text{fail})$, is:\n$$P(\\text{fail}) = P(\\text{fail} \\mid S)P(S) + P(\\text{fail} \\mid U)P(U)$$\n$$P(\\text{fail}) = (0.15)(0.6) + (0.90)(0.4) = 0.09 + 0.36 = 0.45$$\nAs a check, $P(\\text{pass}) + P(\\text{fail}) = 0.55 + 0.45 = 1.0$, which is correct.\n\nNow, we calculate the posterior probabilities.\nIf the pilot signal is \"pass\":\n$$P(S \\mid \\text{pass}) = \\frac{P(\\text{pass} \\mid S)P(S)}{P(\\text{pass})} = \\frac{(0.85)(0.6)}{0.55} = \\frac{0.51}{0.55} = \\frac{51}{55}$$\n$$P(U \\mid \\text{pass}) = \\frac{P(\\text{pass} \\mid U)P(U)}{P(\\text{pass})} = \\frac{(0.10)(0.4)}{0.55} = \\frac{0.04}{0.55} = \\frac{4}{55}$$\nIf the pilot signal is \"fail\":\n$$P(S \\mid \\text{fail}) = \\frac{P(\\text{fail} \\mid S)P(S)}{P(\\text{fail})} = \\frac{(0.15)(0.6)}{0.45} = \\frac{0.09}{0.45} = \\frac{1}{5} = 0.2$$\n$$P(U \\mid \\text{fail}) = \\frac{P(\\text{fail} \\mid U)P(U)}{P(\\text{fail})} = \\frac{(0.90)(0.4)}{0.45} = \\frac{0.36}{0.45} = \\frac{4}{5} = 0.8$$\nAfter observing the signal, a new decision is made.\nIf the signal is \"pass\", the expected utility of deploying is:\n$$EU(\\text{Deploy} \\mid \\text{pass}) = P(S \\mid \\text{pass}) \\cdot B + P(U \\mid \\text{pass}) \\cdot (-H)$$\n$$EU(\\text{Deploy} \\mid \\text{pass}) = \\left(\\frac{51}{55}\\right)(10) + \\left(\\frac{4}{55}\\right)(-40) = \\frac{510 - 160}{55} = \\frac{350}{55} = \\frac{70}{11} \\approx 6.36$$\nThe optimal action after a \"pass\" signal is to deploy, with an expected utility of $\\frac{70}{11}$, since this is greater than $0$.\nIf the signal is \"fail\", the expected utility of deploying is:\n$$EU(\\text{Deploy} \\mid \\text{fail}) = P(S \\mid \\text{fail}) \\cdot B + P(U \\mid \\text{fail}) \\cdot (-H)$$\n$$EU(\\text{Deploy} \\mid \\text{fail}) = (0.2)(10) + (0.8)(-40) = 2 - 32 = -30$$\nThe optimal action after a \"fail\" signal is to not deploy, with an expected utility of $0$, since $-30 < 0$.\n\nLet $EU_{\\text{post}}$ be the expected utility of the post-pilot decision, calculated before observing the signal. This is the probability-weighted average of the optimal utilities for each signal outcome.\n$$EU_{\\text{post}} = P(\\text{pass}) \\cdot \\max(EU(\\text{Deploy} \\mid \\text{pass}), 0) + P(\\text{fail}) \\cdot \\max(EU(\\text{Deploy} \\mid \\text{fail}), 0)$$\n$$EU_{\\text{post}} = (0.55) \\cdot \\left(\\frac{70}{11}\\right) + (0.45) \\cdot (0) = \\frac{55}{100} \\cdot \\frac{70}{11} = \\frac{5 \\cdot 70}{100} = \\frac{350}{100} = 3.5$$\nThis value of $3.5$ represents the expected benefit from the deployment decision, which is only realized after the pilot completion time $\\tau$. Therefore, its present value must be discounted by the factor $\\exp(-\\delta \\tau)$. The cost of the pilot, $C_p$, is incurred now and is not discounted.\nThe total present value of the pilot strategy, $V_{\\text{pilot}}$, is:\n$$V_{\\text{pilot}} = -C_p + EU_{\\text{post}} \\cdot \\exp(-\\delta \\tau)$$\nThe discount factor is:\n$$\\exp(-\\delta \\tau) = \\exp(-0.05 \\cdot 0.5) = \\exp(-0.025)$$\nSo, the value of the pilot strategy is:\n$$V_{\\text{pilot}} = -1 + 3.5 \\cdot \\exp(-0.025)$$\nThe problem asks for the *net* expected value of running the pilot. This is the difference between the value of the pilot strategy and the value of the no-pilot strategy.\n$$\\text{Net Value} = V_{\\text{pilot}} - V_{\\text{no pilot}}$$\n$$\\text{Net Value} = (-1 + 3.5 \\cdot \\exp(-0.025)) - 0 = 3.5 \\cdot \\exp(-0.025) - 1$$\nNow, we compute the numerical value.\nUsing the value $\\exp(-0.025) \\approx 0.97530991$:\n$$\\text{Net Value} \\approx 3.5 \\cdot (0.97530991) - 1 = 3.41358469 - 1 = 2.41358469$$\nRounding to four significant figures, the net expected value is $2.414$.\nSince this value is positive, it is rational to run the pilot study.\nThe value $V_{\\text{no pilot}} = 0$ is the Expected Value of the Prior Information (EVPIor). The value $V_{\\text{pilot}} = 2.414$ is the Expected Value of Sample Information (EVSI) including costs and discounting. The term EVSI is often used for the gross information gain, which would be $EU_{\\text{post}} - V_{\\text{no pilot}} = 3.5 - 0 = 3.5$. But the question asks for the fully adjusted net value.\nMy calculation provides this net value as requested.\nFinal check of calculation:\n$V_{\\text{pilot}} - V_{\\text{no pilot}} = (3.5 \\cdot \\exp(-0.025) - 1) - 0 = 2.41358... \\approx 2.414$. The calculation is correct.\nThe result is $2.414$ million dollars.", "answer": "$$\\boxed{2.414}$$", "id": "2739646"}, {"introduction": "The duty of care in synthetic biology extends beyond initial deployment and requires continuous vigilance. This practice demonstrates how to build a dynamic Bayesian surveillance model to monitor for potential adverse outcomes in real-time. By applying Bayes' theorem to a stream of observational data, you will learn how to formally update your belief about the presence of a hazard, distinguishing meaningful signals from the noise of false alarms. [@problem_id:2739658]", "problem": "A synthetic biology field trial, governed under Responsible Research and Innovation (RRI), releases an engineered marine microbe designed to sequester carbon. To support responsible innovation, the project deploys a Bayesian environmental surveillance system that updates the probability of an adverse ecological change (for example, a harmful cascade in phytoplankton dynamics) after each day of monitoring. Let the hypothesis $H$ denote that an adverse ecological change is present during the monitoring window, and $\\neg H$ its negation.\n\nEach day $t \\in \\{1,2,3,4,5\\}$, an autonomous buoy produces a binary alert $Y_t \\in \\{0,1\\}$ based on multivariate environmental anomalies. The system has been calibrated prior to deployment so that:\n- The sensitivity (true positive rate) is $s = P(Y_t = 1 \\mid H)$, assumed constant across days.\n- The daily false alarm rate (FAR) is $\\alpha_t = P(Y_t = 1 \\mid \\neg H)$, potentially varying across days.\n- Conditional on $H$ or on $\\neg H$, the daily alerts are independent across days.\n\nSuppose that the prior probability of adverse ecological change at the start of the $5$-day window is $\\pi_0 = P(H) = 0.02$. Lab and field calibrations yield $s = 0.90$, and the daily false alarm rates are:\n- Day $1$: $\\alpha_1 = 0.03$\n- Day $2$: $\\alpha_2 = 0.02$\n- Day $3$: $\\alpha_3 = 0.02$\n- Day $4$: $\\alpha_4 = 0.04$\n- Day $5$: $\\alpha_5 = 0.02$\n\nDuring the $5$ days, the observed alert sequence is\n$$(Y_1, Y_2, Y_3, Y_4, Y_5) = (1, 0, 1, 1, 0).$$\n\nStarting only from the definition of conditional probability and Bayes’ theorem, and using the assumptions stated above, derive a closed-form expression for the posterior probability $P(H \\mid Y_1,\\ldots,Y_5)$ in terms of $\\pi_0$, $s$, and $\\{\\alpha_t\\}_{t=1}^{5}$ and then evaluate it numerically for the given values. Express your final answer as a decimal rounded to four significant figures. Do not use a percent sign.", "solution": "The problem statement must first be validated for scientific and logical integrity.\n\nStep 1: Extract Givens\n- Hypothesis of adverse ecological change: $H$.\n- Hypothesis of no adverse ecological change: $\\neg H$.\n- Monitoring days: $t \\in \\{1, 2, 3, 4, 5\\}$.\n- Daily alert data: $Y_t \\in \\{0, 1\\}$.\n- Sensitivity (True Positive Rate): $s = P(Y_t = 1 \\mid H) = 0.90$. This is constant for all $t$.\n- Daily False Alarm Rate (FAR): $\\alpha_t = P(Y_t = 1 \\mid \\neg H)$.\n- FAR values: $\\alpha_1 = 0.03$, $\\alpha_2 = 0.02$, $\\alpha_3 = 0.02$, $\\alpha_4 = 0.04$, $\\alpha_5 = 0.02$.\n- Conditional Independence: The daily alerts $Y_t$ are independent across days, conditional on $H$ or on $\\neg H$.\n- Prior Probability: $\\pi_0 = P(H) = 0.02$.\n- Observed Data Sequence: $(Y_1, Y_2, Y_3, Y_4, Y_5) = (1, 0, 1, 1, 0)$.\n\nStep 2: Validate Using Extracted Givens\n- **Scientifically Grounded**: The problem is a standard application of Bayesian inference, a cornerstone of modern statistics and machine learning. Its application to environmental monitoring in synthetic biology is a realistic and important scenario. The problem adheres to the fundamental principles of probability theory.\n- **Well-Posed**: All necessary parameters ($\\pi_0, s, \\alpha_t$) and data ($Y_t$) are provided to calculate the required posterior probability. There are no missing or contradictory pieces of information. A unique, stable solution exists.\n- **Objective**: The problem is stated using precise, unambiguous mathematical and technical language.\n\nStep 3: Verdict and Action\nThe problem is valid. It is a well-posed, scientifically sound exercise in applying Bayesian principles. A solution will be derived.\n\nThe task is to compute the posterior probability of an adverse event, $P(H \\mid Y_1, \\ldots, Y_5)$, given the sequence of observations. Let us denote the full data sequence $(Y_1, \\ldots, Y_5)$ as $D$. We seek to compute $P(H \\mid D)$.\n\nAccording to Bayes' theorem, the posterior probability is given by:\n$$P(H \\mid D) = \\frac{P(D \\mid H) P(H)}{P(D)}$$\nThe denominator, $P(D)$, is the marginal probability of the data, often called the evidence. It can be expanded using the law of total probability with respect to the mutually exclusive and exhaustive hypotheses $H$ and $\\neg H$:\n$$P(D) = P(D \\mid H) P(H) + P(D \\mid \\neg H) P(\\neg H)$$\nSubstituting this into the expression for the posterior probability, we obtain:\n$$P(H \\mid D) = \\frac{P(D \\mid H) P(H)}{P(D \\mid H) P(H) + P(D \\mid \\neg H) P(\\neg H)}$$\nThe problem states that the daily alerts $Y_t$ are conditionally independent given either $H$ or $\\neg H$. This allows us to express the joint likelihoods $P(D \\mid H)$ and $P(D \\mid \\neg H)$ as the product of the individual daily probabilities:\n$$P(D \\mid H) = P(Y_1, \\ldots, Y_5 \\mid H) = \\prod_{t=1}^{5} P(Y_t \\mid H)$$\n$$P(D \\mid \\neg H) = P(Y_1, \\ldots, Y_5 \\mid \\neg H) = \\prod_{t=1}^{5} P(Y_t \\mid \\neg H)$$\nWe must define the probability for each type of daily observation, $Y_t=1$ or $Y_t=0$.\nGiven $H$:\n- $P(Y_t=1 \\mid H) = s$ (sensitivity)\n- $P(Y_t=0 \\mid H) = 1 - P(Y_t=1 \\mid H) = 1 - s$ (false negative rate)\nGiven $\\neg H$:\n- $P(Y_t=1 \\mid \\neg H) = \\alpha_t$ (false alarm rate)\n- $P(Y_t=0 \\mid \\neg H) = 1 - P(Y_t=1 \\mid \\neg H) = 1 - \\alpha_t$ (specificity or true negative rate)\n\nThe observed data sequence is $D=(1, 0, 1, 1, 0)$. Let us compute the likelihoods for this specific sequence.\nThe likelihood of the data given $H$ is:\n$$P(D \\mid H) = P(Y_1=1 \\mid H) \\cdot P(Y_2=0 \\mid H) \\cdot P(Y_3=1 \\mid H) \\cdot P(Y_4=1 \\mid H) \\cdot P(Y_5=0 \\mid H)$$\n$$P(D \\mid H) = s \\cdot (1-s) \\cdot s \\cdot s \\cdot (1-s) = s^3 (1-s)^2$$\nThe likelihood of the data given $\\neg H$ is:\n$$P(D \\mid \\neg H) = P(Y_1=1 \\mid \\neg H) \\cdot P(Y_2=0 \\mid \\neg H) \\cdot P(Y_3=1 \\mid \\neg H) \\cdot P(Y_4=1 \\mid \\neg H) \\cdot P(Y_5=0 \\mid \\neg H)$$\n$$P(D \\mid \\neg H) = \\alpha_1 \\cdot (1-\\alpha_2) \\cdot \\alpha_3 \\cdot \\alpha_4 \\cdot (1-\\alpha_5)$$\nThe prior probability of $H$ is $\\pi_0 = P(H) = 0.02$, so $P(\\neg H) = 1 - \\pi_0 = 1 - 0.02 = 0.98$.\n\nWe now have all components to derive the closed-form expression for the posterior probability for the observed data:\n$$P(H \\mid D) = \\frac{s^3(1-s)^2 \\pi_0}{s^3(1-s)^2 \\pi_0 + \\left( \\alpha_1(1-\\alpha_2)\\alpha_3\\alpha_4(1-\\alpha_5) \\right) (1-\\pi_0)}$$\nNow, we substitute the given numerical values:\n- $\\pi_0 = 0.02$\n- $1 - \\pi_0 = 0.98$\n- $s = 0.90$\n- $1 - s = 0.10$\n- $\\alpha_1 = 0.03$\n- $\\alpha_2 = 0.02 \\implies 1-\\alpha_2 = 0.98$\n- $\\alpha_3 = 0.02$\n- $\\alpha_4 = 0.04$\n- $\\alpha_5 = 0.02 \\implies 1-\\alpha_5 = 0.98$\n\nFirst, calculate the numerator term, which is $P(D \\mid H) P(H)$:\n$$s^3(1-s)^2 \\pi_0 = (0.90)^3 (0.10)^2 (0.02) = (0.729)(0.01)(0.02) = 0.0001458$$\nNext, calculate the second term in the denominator, which is $P(D \\mid \\neg H) P(\\neg H)$:\n$$P(D \\mid \\neg H) = (0.03)(1-0.02)(0.02)(0.04)(1-0.02) = (0.03)(0.98)(0.02)(0.04)(0.98)$$\n$$P(D \\mid \\neg H) = (0.03 \\cdot 0.02 \\cdot 0.04) \\cdot (0.98)^2 = (0.000024)(0.9604) = 0.0000230496$$\nThen, multiply by $P(\\neg H)$:\n$$P(D \\mid \\neg H) P(\\neg H) = (0.0000230496)(0.98) = 0.000022588608$$\nNow, assemble the final fraction for the posterior probability:\n$$P(H \\mid D) = \\frac{0.0001458}{0.0001458 + 0.000022588608} = \\frac{0.0001458}{0.000168388608}$$\n$$P(H \\mid D) \\approx 0.86585149$$\nThe problem requires the final answer rounded to four significant figures.\n$$P(H \\mid D) \\approx 0.8659$$\nThis final value represents the updated belief that an adverse ecological change is present, after incorporating the evidence from the five days of monitoring. The probability has increased substantially from the prior of $0.02$.", "answer": "$$\n\\boxed{0.8659}\n$$", "id": "2739658"}]}