{"hands_on_practices": [{"introduction": "At the heart of sensory transduction lies the conversion of a physical stimulus into an electrical signal, most often a change in the cell's membrane potential. This fundamental process can be understood by modeling the cell membrane as an electrical circuit where sensory stimuli modulate the conductance of specific ion channels. This exercise [@problem_id:2836286] provides foundational practice in applying the steady-state current-balance equation to derive how a change in a single channel's conductance alters the receptor potential, and to predict whether the resulting signal is a depolarization or a hyperpolarization.", "problem": "A primary sensory receptor cell can be modeled as a single isopotential compartment whose ionic currents are ohmic. In the absence of capacitive transients and active pumps on the timescale of interest, the steady-state membrane potential is defined by the net ionic current balance. The fundamental current-balance relation is that the net ionic current satisfies $I_{\\text{net}} = \\sum_{i=1}^{n} g_i \\big(V - E_i\\big)$, where $g_i$ is the conductance of channel class $i$ and $E_i$ is its reversal potential. At steady state, the receptor potential $V$ satisfies $I_{\\text{net}}=0$.\n\nConsider a baseline set of $n$ conductances $\\{g_i\\}_{i=1}^{n}$ with associated reversal potentials $\\{E_i\\}_{i=1}^{n}$, and suppose that an external stimulus selectively increases a single conductance $g_s$ (for some index $s \\in \\{1,\\dots,n\\}$) by an amount $\\Delta g$ with $\\Delta g  0$, without altering any other $g_i$ or any $E_i$. Assume that $g_i \\ge 0$ for all $i$ and that $\\sum_{i=1}^{n} g_i  0$. Starting from the current-balance relation above and enforcing steady state, derive the closed-form analytic expression for the new steady-state receptor potential $V$ after the stimulus, in terms of $\\{g_i\\}$, $\\{E_i\\}$, $\\Delta g$, and $E_s$. In your reasoning, use only the stated current-balance relation and basic algebra.\n\nAdditionally, in your solution (not in the final boxed answer), determine the conditions under which the change in $V$ relative to its pre-stimulus value is a depolarization (increase in $V$) versus a hyperpolarization (decrease in $V$). State any assumptions you make about the sign convention for $V$.\n\nYour final answer must be a single closed-form analytic expression. Do not substitute numerical values, do not include units in the final boxed answer, and do not report inequalities or verbal conditions in the final boxed answer. If one were to evaluate the expression numerically, $V$ would be measured in volts.", "solution": "The problem will first be validated against the required criteria.\n\n### Problem Validation\n\n**Step 1: Extract Givens**\nThe problem presents a model for a primary sensory receptor cell with the following givens:\n- Model: Single isopotential compartment with ohmic ionic currents.\n- Timescale: No capacitive transients or active pumps are considered.\n- Fundamental Relation: Net ionic current is $I_{\\text{net}} = \\sum_{i=1}^{n} g_i \\big(V - E_i\\big)$, where $g_i$ is conductance, $E_i$ is reversal potential, and $V$ is membrane potential.\n- Steady-State Condition: $I_{\\text{net}}=0$.\n- Baseline State: A set of $n$ conductances $\\{g_i\\}_{i=1}^{n}$ and reversal potentials $\\{E_i\\}_{i=1}^{n}$.\n- Stimulus: A single conductance $g_s$ is increased by an amount $\\Delta g  0$.\n- Invariance: All other conductances $g_i$ (for $i \\neq s$) and all reversal potentials $E_i$ are constant.\n- Constraints: $g_i \\ge 0$ for all $i$, and the total initial conductance $\\sum_{i=1}^{n} g_i  0$.\n\n**Step 2: Validate Using Extracted Givens**\nThe problem is subjected to validation.\n- **Scientifically Grounded**: The problem is valid. The current-balance equation is a direct application of Ohm's law to a parallel conductance model, which is a standard and fundamental concept in cellular neurophysiology used to approximate the steady-state membrane potential.\n- **Well-Posed**: The problem is valid. It provides a clear algebraic equation and a well-defined change in parameters, asking for the new steady-state solution. The constraints provided ($g_i \\ge 0$ and $\\sum_{i=1}^{n} g_i  0$) ensure that the denominator in the solution will be non-zero, guaranteeing a unique and meaningful solution.\n- **Objective**: The problem is valid. It is stated in a precise mathematical and biophysical language, free of subjective or ambiguous terminology.\nNo flaws from the checklist are present. The problem is a standard exercise in biophysical modeling and does not violate any principles of scientific or logical integrity.\n\n**Step 3: Verdict and Action**\nThe problem is deemed valid. A complete and reasoned solution follows.\n\n### Derivation of the Solution\n\nThe task is to derive the expression for the new steady-state receptor potential after a stimulus has increased a single conductance, $g_s$. Let the baseline potential be $V_0$ and the new potential after the stimulus be $V_1$. The problem statement uses the variable $V$ for this new potential, which we will adopt in the final answer.\n\nThe steady-state condition is that the net current across the membrane is zero, $I_{\\text{net}} = 0$. The general expression for the net current is given as $I_{\\text{net}} = \\sum_{i=1}^{n} g_i \\big(V - E_i\\big)$.\n\nAfter the stimulus, the conductance for the specific channel class $s$ becomes $g_s + \\Delta g$. All other conductances $g_i$ (where $i \\neq s$) and all reversal potentials $E_i$ remain unchanged. The new steady-state potential, $V_1$, must satisfy the current-balance equation with the new set of conductances.\n\nThe new steady-state equation is:\n$$ \\sum_{i \\neq s} g_i (V_1 - E_i) + (g_s + \\Delta g)(V_1 - E_s) = 0 $$\nOur objective is to solve this equation for $V_1$. We expand the terms:\n$$ \\sum_{i \\neq s} g_i V_1 - \\sum_{i \\neq s} g_i E_i + g_s V_1 + \\Delta g V_1 - g_s E_s - \\Delta g E_s = 0 $$\nWe can combine the sums. The term $\\sum_{i \\neq s} g_i V_1 + g_s V_1$ is equivalent to $\\left(\\sum_{i=1}^{n} g_i\\right) V_1$. Similarly, $\\sum_{i \\neq s} g_i E_i + g_s E_s$ is equivalent to $\\sum_{i=1}^{n} g_i E_i$. Substituting these back into the equation gives:\n$$ \\left(\\sum_{i=1}^{n} g_i\\right) V_1 + \\Delta g V_1 - \\left(\\sum_{i=1}^{n} g_i E_i\\right) - \\Delta g E_s = 0 $$\nNow, we group all terms containing $V_1$ on one side of the equation and all other terms on the other side:\n$$ V_1 \\left( \\sum_{i=1}^{n} g_i + \\Delta g \\right) = \\sum_{i=1}^{n} g_i E_i + \\Delta g E_s $$\nFinally, we isolate $V_1$ by dividing by the term in the parenthesis. This is permissible because we are given that $\\sum_{i=1}^{n} g_i  0$ and $\\Delta g  0$, so the denominator is strictly positive and non-zero.\n$$ V_1 = \\frac{\\sum_{i=1}^{n} g_i E_i + \\Delta g E_s}{\\sum_{i=1}^{n} g_i + \\Delta g} $$\nThis is the closed-form expression for the new steady-state receptor potential.\n\nNext, we must determine the conditions under which this change constitutes a depolarization or a hyperpolarization. We assume the standard neurophysiological convention where depolarization is an increase in membrane potential ($V_1  V_0$) and hyperpolarization is a decrease ($V_1  V_0$). We must find the change in potential, $\\Delta V = V_1 - V_0$.\n\nFirst, we find the baseline potential, $V_0$, by applying the steady-state condition to the initial set of conductances $\\{g_i\\}_{i=1}^{n}$:\n$$ \\sum_{i=1}^{n} g_i (V_0 - E_i) = 0 $$\n$$ V_0 \\sum_{i=1}^{n} g_i - \\sum_{i=1}^{n} g_i E_i = 0 $$\n$$ V_0 = \\frac{\\sum_{i=1}^{n} g_i E_i}{\\sum_{i=1}^{n} g_i} $$\nNow we compute $\\Delta V = V_1 - V_0$:\n$$ \\Delta V = \\frac{\\sum_{i=1}^{n} g_i E_i + \\Delta g E_s}{\\sum_{i=1}^{n} g_i + \\Delta g} - \\frac{\\sum_{i=1}^{n} g_i E_i}{\\sum_{i=1}^{n} g_i} $$\nLet $S = \\sum_{i=1}^{n} g_i E_i$ and $G = \\sum_{i=1}^{n} g_i$. The expression becomes:\n$$ \\Delta V = \\frac{S + \\Delta g E_s}{G + \\Delta g} - \\frac{S}{G} $$\nTo subtract these fractions, we find a common denominator, which is $G(G + \\Delta g)$:\n$$ \\Delta V = \\frac{G(S + \\Delta g E_s) - S(G + \\Delta g)}{G(G + \\Delta g)} $$\n$$ \\Delta V = \\frac{GS + G \\Delta g E_s - SG - S \\Delta g}{G(G + \\Delta g)} $$\n$$ \\Delta V = \\frac{G \\Delta g E_s - S \\Delta g}{G(G + \\Delta g)} = \\frac{\\Delta g (G E_s - S)}{G(G + \\Delta g)} $$\nThe sign of $\\Delta V$ determines the nature of the potential change. We analyze the sign of the numerator and denominator.\n- Denominator: $G = \\sum_{i=1}^{n} g_i  0$ and $\\Delta g  0$ are given. Thus, $G(G + \\Delta g)  0$.\n- Numerator: $\\Delta g  0$ is given. The sign of the numerator is therefore determined by the sign of the term $(G E_s - S)$.\nSubstituting the definitions of $G$ and $S$ back gives:\n$$ G E_s - S = E_s \\left(\\sum_{i=1}^{n} g_i\\right) - \\left(\\sum_{i=1}^{n} g_i E_i\\right) $$\nDividing this term by $G = \\sum_{i=1}^{n} g_i$ (which is positive and does not change the sign) simplifies the analysis:\n$$ \\frac{G E_s - S}{G} = E_s - \\frac{S}{G} = E_s - V_0 $$\nTherefore, the sign of $\\Delta V$ is identical to the sign of $(E_s - V_0)$.\n\nThe conditions are as follows:\n- **Depolarization** ($\\Delta V  0$): This occurs when $E_s - V_0  0$, which is equivalent to $E_s  V_0$. If the reversal potential of the activated channel is more positive than the initial membrane potential, the cell will depolarize.\n- **Hyperpolarization** ($\\Delta V  0$): This occurs when $E_s - V_0  0$, which is equivalent to $E_s  V_0$. If the reversal potential of the activated channel is more negative than the initial membrane potential, the cell will hyperpolarize.\n- **No change** ($\\Delta V = 0$): This occurs when $E_s - V_0 = 0$, which is equivalent to $E_s = V_0$. If the reversal potential of the activated channel is exactly equal to the membrane potential, there is no net driving force for that ion, and opening the channel causes no change in potential. This is, by definition, the reversal potential.", "answer": "$$\n\\boxed{\\frac{\\sum_{i=1}^{n} g_i E_i + \\Delta g E_s}{\\sum_{i=1}^{n} g_i + \\Delta g}}\n$$", "id": "2836286"}, {"introduction": "Beyond the electrical consequences, it is crucial to model how a stimulus controls the channel's gating mechanism itself. In mechanosensory systems like hearing, the relationship between a physical displacement and a channel's open probability can be elegantly described by a Boltzmann function, a cornerstone of statistical mechanics. This practice [@problem_id:2836288] guides you through connecting this theoretical model to experimental data, demonstrating how to analyze the steepness of a transduction curve to extract a physically meaningful parameter: the effective gating force ($z$) that quantifies the channel's sensitivity.", "problem": "A mechanosensitive hair bundle controls the opening of mechanoelectrical transduction (MET) channels in response to displacement. Consider a two-state model in which the open probability of the MET channel as a function of hair-bundle displacement $x$ is given by the Boltzmann function\n$$\nP_{o}(x) = \\frac{1}{1 + \\exp\\!\\left[-\\frac{z\\,(x - x_{1/2})}{k_{B} T}\\right]},\n$$\nwhere $z$ is an effective gating force, $x_{1/2}$ is the displacement at half activation, $k_{B}$ is the Boltzmann constant, and $T$ is the absolute temperature. Assume that each open channel passes a displacement-independent single-channel current over the relevant operating range and that the macroscopic current is proportional to the number of open channels at any $x$.\n\nStarting from the definition of open probability for a two-state system in thermal equilibrium and the proportionality between the number of open channels and macroscopic current, derive an explicit expression for the MET current $I(x)$ as a function of displacement $x$ in terms of $P_{o}(x)$ and a saturating current $I_{\\max}$. Then, using the slope of the current–displacement relation at half activation, determine the value of $z$.\n\nAn experiment at temperature $T = 300\\,\\mathrm{K}$ measured a saturating MET current magnitude $I_{\\max} = 600\\,\\mathrm{pA}$ and a local slope of the current–displacement relation at $x = x_{1/2}$ equal to $s_{I} = 30.0\\,\\mathrm{pA\\,nm^{-1}}$. Use $k_{B} = 1.380\\,649 \\times 10^{-23}\\,\\mathrm{J\\,K^{-1}}$. Express the final value of $z$ in picoNewtons (pN). Round your answer to $3$ significant figures.", "solution": "The problem statement is found to be scientifically grounded, well-posed, and internally consistent. It presents a standard model from biophysics and provides all necessary parameters for a unique solution. We will therefore proceed with the derivation and calculation.\n\nThe problem requires a two-part solution: first, to derive an expression for the mechanoelectrical transduction (MET) current $I(x)$, and second, to calculate the effective gating force $z$.\n\nPart 1: Derivation of the MET current $I(x)$.\nThe total number of MET channels is a constant, let us call it $N_{\\text{total}}$. The number of open channels, $N_{o}(x)$, at a given hair-bundle displacement $x$ is given by the product of the total number of channels and the probability that any single channel is open, $P_{o}(x)$.\n$$\nN_{o}(x) = N_{\\text{total}} \\cdot P_{o}(x)\n$$\nThe problem states that the macroscopic current $I(x)$ is proportional to the number of open channels. Let the proportionality constant be $i_{s}$, representing the single-channel current, which is assumed to be independent of displacement.\n$$\nI(x) = i_{s} N_{o}(x) = i_{s} N_{\\text{total}} P_{o}(x)\n$$\nThe saturating current, $I_{\\max}$, is defined as the current when all channels are open. This corresponds to the limit where the open probability $P_{o}(x) \\to 1$. In this limit, $N_{o}(x) \\to N_{\\text{total}}$. Thus, the maximal current is:\n$$\nI_{\\max} = i_{s} N_{\\text{total}}\n$$\nBy substituting the expression for $I_{\\max}$ back into the equation for $I(x)$, we obtain the explicit relationship between the current at displacement $x$, the maximal current, and the open probability:\n$$\nI(x) = I_{\\max} P_{o}(x)\n$$\nSubstituting the given Boltzmann function for $P_{o}(x)$:\n$$\nI(x) = I_{\\max} \\frac{1}{1 + \\exp\\!\\left[-\\frac{z\\,(x - x_{1/2})}{k_{B} T}\\right]}\n$$\nThis completes the first part of the problem.\n\nPart 2: Determination of the gating force $z$.\nThe problem provides the slope of the current-displacement relation at half activation, $x = x_{1/2}$. This slope, $s_{I}$, is the derivative of $I(x)$ with respect to $x$, evaluated at $x=x_{1/2}$.\n$$\ns_{I} = \\left. \\frac{dI}{dx} \\right|_{x=x_{1/2}}\n$$\nWe must first compute the derivative of $I(x)$. For simplicity, let the argument of the exponential be $\\alpha(x) = -\\frac{z(x-x_{1/2})}{k_B T}$.\n$$\nI(x) = I_{\\max} (1 + \\exp(\\alpha(x)))^{-1}\n$$\nUsing the chain rule for differentiation:\n$$\n\\frac{dI}{dx} = I_{\\max} \\cdot (-1) (1 + \\exp(\\alpha(x)))^{-2} \\cdot \\frac{d}{dx}(1 + \\exp(\\alpha(x)))\n$$\n$$\n\\frac{dI}{dx} = -I_{\\max} (1 + \\exp(\\alpha(x)))^{-2} \\cdot \\exp(\\alpha(x)) \\cdot \\frac{d\\alpha}{dx}\n$$\nThe derivative of $\\alpha(x)$ with respect to $x$ is:\n$$\n\\frac{d\\alpha}{dx} = \\frac{d}{dx} \\left(-\\frac{z(x-x_{1/2})}{k_B T}\\right) = -\\frac{z}{k_B T}\n$$\nSubstituting this back into the expression for $\\frac{dI}{dx}$:\n$$\n\\frac{dI}{dx} = -I_{\\max} \\frac{\\exp(\\alpha(x))}{(1 + \\exp(\\alpha(x)))^{2}} \\left(-\\frac{z}{k_{B} T}\\right) = I_{\\max} \\frac{z}{k_{B} T} \\frac{\\exp\\left[-\\frac{z(x - x_{1/2})}{k_{B} T}\\right]}{\\left(1 + \\exp\\left[-\\frac{z(x - x_{1/2})}{k_{B} T}\\right]\\right)^{2}}\n$$\nNow, we evaluate this derivative at $x = x_{1/2}$. At this point, the argument of the exponential becomes $0$, since $x-x_{1/2}=0$.\n$$\n\\left. \\frac{dI}{dx} \\right|_{x=x_{1/2}} = I_{\\max} \\frac{z}{k_{B} T} \\frac{\\exp(0)}{(1 + \\exp(0))^{2}}\n$$\nSince $\\exp(0) = 1$, the expression simplifies:\n$$\ns_{I} = I_{\\max} \\frac{z}{k_{B} T} \\frac{1}{(1 + 1)^{2}} = I_{\\max} \\frac{z}{k_{B} T} \\frac{1}{4}\n$$\nWe can now rearrange this equation to solve for the gating force $z$:\n$$\nz = \\frac{4 s_{I} k_{B} T}{I_{\\max}}\n$$\nThe final step is to substitute the given numerical values. The provided data are:\n$s_{I} = 30.0\\,\\mathrm{pA\\,nm^{-1}}$\n$I_{\\max} = 600\\,\\mathrm{pA}$\n$T = 300\\,\\mathrm{K}$\n$k_{B} = 1.380\\,649 \\times 10^{-23}\\,\\mathrm{J\\,K^{-1}}$\n\nFirst, we calculate the thermal energy $k_{B}T$:\n$$\nk_{B}T = (1.380\\,649 \\times 10^{-23}\\,\\mathrm{J\\,K^{-1}}) \\cdot (300\\,\\mathrm{K}) = 4.141\\,947 \\times 10^{-21}\\,\\mathrm{J}\n$$\nNext, we substitute the values into the expression for $z$:\n$$\nz = \\frac{4 \\cdot (30.0\\,\\mathrm{pA\\,nm^{-1}}) \\cdot (4.141\\,947 \\times 10^{-21}\\,\\mathrm{J})}{600\\,\\mathrm{pA}}\n$$\nThe units of picoamperes ($\\mathrm{pA}$) cancel out, leaving units of Joules per nanometer ($\\mathrm{J\\,nm^{-1}}$).\n$$\nz = \\frac{120.0}{600} \\cdot (4.141\\,947 \\times 10^{-21})\\,\\mathrm{J\\,nm^{-1}} = 0.2 \\cdot (4.141\\,947 \\times 10^{-21})\\,\\mathrm{J\\,nm^{-1}}\n$$\n$$\nz = 0.828\\,389\\,4 \\times 10^{-21}\\,\\mathrm{J\\,nm^{-1}}\n$$\nThe problem requires the answer in picoNewtons ($\\mathrm{pN}$). We must perform a unit conversion.\n$1\\,\\mathrm{J} = 1\\,\\mathrm{N} \\cdot \\mathrm{m}$\n$1\\,\\mathrm{nm} = 10^{-9}\\,\\mathrm{m}$\n$1\\,\\mathrm{pN} = 10^{-12}\\,\\mathrm{N}$\nTherefore,\n$$\n1\\,\\mathrm{J\\,nm^{-1}} = \\frac{1\\,\\mathrm{N} \\cdot \\mathrm{m}}{10^{-9}\\,\\mathrm{m}} = 10^{9}\\,\\mathrm{N} = 10^{9} \\cdot (10^{12}\\,\\mathrm{pN}) = 10^{21}\\,\\mathrm{pN}\n$$\nUsing this conversion factor:\n$$\nz = (0.828\\,389\\,4 \\times 10^{-21}) \\cdot (10^{21}\\,\\mathrm{pN}) = 0.828\\,389\\,4\\,\\mathrm{pN}\n$$\nRounding the result to $3$ significant figures as requested gives $0.828\\,\\mathrm{pN}$.", "answer": "$$\n\\boxed{0.828}\n$$", "id": "2836288"}, {"introduction": "To characterize a sensory neuron's complete operational range, we analyze its full input-output relationship, often described by a sigmoidal dose-response curve like the Naka-Rushton function. This powerful tool allows us to quantify key properties such as sensitivity (the half-maximal stimulus, $I_{50}$) and dynamic range (the Hill coefficient, $n$). This advanced computational practice [@problem_id:2836374] immerses you in the modern workflow of a sensory neuroscientist: generating synthetic data, performing nonlinear regression to estimate model parameters from noisy measurements, and interpreting how these parameters change to reflect sensory adaptation.", "problem": "You are modeling a sensory transduction pathway where the response to a stimulus intensity is saturating and shaped by feedback. Assume a receptor-ligand transduction step where the fractional activation of the effector is proportional to the fraction of receptors in the activated state. Begin from equilibrium binding under the law of mass action and the assumption of $n$ identical and independent binding events with identical dissociation constant, and that the macroscopic response is proportional to the fractional occupancy. From this base, derive a saturating input-output relationship that is monotonic, sigmoidal on logarithmic stimulus axes, and has two interpretable parameters: a half-activation stimulus $I_{50}$ and a Hill coefficient $n$ controlling steepness. Explain why $I_{50}$ equals the stimulus that elicits half-maximal response under these assumptions, and why $n$ reflects cooperativity or effective nonlinearity.\n\nYou will then use this derived function to fit synthetic datasets that emulate background-dependent feedback. Background stimulation is modeled to alter the apparent half-activation stimulus and slope due to feedback acting upstream or downstream of the transduction step. For each dataset, you will fit the parameters by nonlinear least squares, compute background-dependent changes relative to a baseline background, and report quantitative summaries.\n\nFollow these requirements.\n\n- Assumptions and model foundation:\n  - Use the fraction of activated receptors at equilibrium under the law of mass action as the basis. Assume $n$ identical and independent binding events with an effective dissociation constant that defines the stimulus scale, and that the macroscopic response is proportional to this fractional activation.\n  - Justify all steps linking microscopic binding to macroscopic response using standard biophysical reasoning and definitions.\n\n- Data generation (performed by your program deterministically):\n  - For each test case and for each background condition $b \\in \\{0,1,2\\}$, generate a synthetic dataset of stimulus intensities and noisy responses using a saturating transduction curve derived from your model with parameters modified by background-dependent feedback.\n  - For each test case $t$, define the base parameters and feedback as described in the test suite below. The true base parameters are $R_{\\max}$ (response scale), $I_{50,\\text{base}}$ (half-activation stimulus), and $n_{\\text{base}}$ (Hill coefficient). Background $b$ modifies the true parameters to $I_{50}^{(b)} = \\phi^{(b)} \\cdot I_{50,\\text{base}}$ and $n^{(b)} = n_{\\text{base}} + \\Delta n^{(b)}$. The response scale $R_{\\max}$ remains the same across backgrounds for data generation in this task.\n  - Use $N_I = 30$ stimulus intensities per background, logarithmically spaced from $I_{\\min} = 10^{-2} \\cdot I_{50,\\text{base}}$ to $I_{\\max} = 10^{2} \\cdot I_{50,\\text{base}}$.\n  - Generate noise by adding independent zero-mean Gaussian noise with standard deviation $\\sigma = 0.02 \\cdot R_{\\max}$ to each response sample.\n  - Use a deterministic random number generator seeded with $s_t = 12345 + 100 \\cdot t$, where $t$ is the zero-based index of the test case in the suite.\n\n- Parameter estimation:\n  - For each background within each test case, fit the three free parameters $R_{\\max}$, $I_{50}$, and $n$ by minimizing the unweighted sum of squared residuals between the model response and the noisy data generated above.\n  - Constrain parameters during fitting to biologically plausible domains: $R_{\\max}  0$, $I_{50}  0$, and $0.1 \\le n \\le 5$.\n  - Use sensible initial guesses that do not assume prior knowledge of the true parameters. For example, you may initialize $R_{\\max}$ to the maximum observed response in that background, $I_{50}$ to the geometric mean of the intensity grid, and $n$ to $1$.\n\n- Quantities to report:\n  - For each test case, let background $b=0$ be the baseline. For each non-baseline background $b \\in \\{1,2\\}$, compute two quantities from the fitted parameters:\n    - The ratio $r^{(b)} = I_{50,\\text{fit}}^{(b)} \\big/ I_{50,\\text{fit}}^{(0)}$.\n    - The difference $\\delta^{(b)} = n_{\\text{fit}}^{(b)} - n_{\\text{fit}}^{(0)}$.\n  - Report all $r^{(b)}$ and $\\delta^{(b)}$ as decimal floats rounded to three decimal places.\n\n- Test suite:\n  - The program must implement the following three test cases, each specifying ($R_{\\max}$, $I_{50,\\text{base}}$, $n_{\\text{base}}$, $\\{\\phi^{(b)}\\}_{b=0}^2$, $\\{\\Delta n^{(b)}\\}_{b=0}^2$):\n    1. Test case $t=0$: ($R_{\\max} = 1.0, I_{50,\\text{base}} = 50.0, n_{\\text{base}} = 1.2, \\{\\phi^{(0)},\\phi^{(1)},\\phi^{(2)}\\} = \\{1.0, 3.0, 10.0\\}, \\{\\Delta n^{(0)},\\Delta n^{(1)},\\Delta n^{(2)}\\} = \\{0.0, -0.2, -0.4\\}$).\n    2. Test case $t=1$: ($R_{\\max} = 0.8, I_{50,\\text{base}} = 5.0, n_{\\text{base}} = 2.0, \\{\\phi^{(0)},\\phi^{(1)},\\phi^{(2)}\\} = \\{1.0, 2.0, 4.0\\}, \\{\\Delta n^{(0)},\\Delta n^{(1)},\\Delta n^{(2)}\\} = \\{0.0, 0.2, 0.4\\}$).\n    3. Test case $t=2$: ($R_{\\max} = 1.5, I_{50,\\text{base}} = 100.0, n_{\\text{base}} = 1.0, \\{\\phi^{(0)},\\phi^{(1)},\\phi^{(2)}\\} = \\{1.0, 1.5, 2.5\\}, \\{\\Delta n^{(0)},\\Delta n^{(1)},\\Delta n^{(2)}\\} = \\{0.0, 0.0, -0.1\\}$).\n\n- Final output format:\n  - Your program should produce a single line of output containing the results aggregated for all test cases as a comma-separated list enclosed in square brackets. For each test case in order $t=0,1,2$, include in order the four floats $[r^{(1)}, \\delta^{(1)}, r^{(2)}, \\delta^{(2)}]$ for that test case, each rounded to three decimal places. Thus the final line should look like $[\\dots]$ with exactly $12$ floats and no spaces.", "solution": "The goal is to start from a principled microscopic basis of receptor-ligand binding and derive a macroscopic transduction function, then implement a fitting and analysis procedure for synthetic datasets that emulate feedback-dependent adaptation across backgrounds. The foundation is equilibrium binding governed by the law of mass action, which is a well-tested model for receptor activation in many sensory transduction pathways. We consider a receptor or transduction module that effectively requires $n$ ligand interactions to become active; this can represent $n$ identical binding sites with cooperative activation or an effective exponent capturing downstream nonlinearities. We assume a stimulus intensity $I$ proportional to ligand concentration and that in steady state the fraction of activated receptors equals the Hill function fraction of occupancy.\n\nDerivation of the saturating function from first principles proceeds as follows.\n\n- Let $I$ denote the stimulus intensity, proportional to ligand concentration in units arbitrary but consistent. Consider $n$ identical and independent binding events with dissociation constant $K$ for each. Under the law of mass action, the probability that a single site is occupied at equilibrium is $p = \\dfrac{I}{K + I}$, assuming $I \\ll$ saturation capacity and well-mixed conditions.\n- If receptor activation requires all $n$ sites occupied (a concerted model), the fraction of activated receptors is $p^n = \\left(\\dfrac{I}{K + I}\\right)^n = \\dfrac{I^n}{(K + I)^n}$. Under a more general Hill approximation, one writes the fraction of activated effectors as the Hill function $\\theta(I) = \\dfrac{I^n}{K^n + I^n}$, which captures cooperative saturation and has the correct limiting behaviors $\\theta(0)=0$ and $\\lim_{I \\to \\infty} \\theta(I) = 1$. This form is consistent with the derivation for $n$ identical steps under the assumption that the effective activation threshold scales with $K$ and that the detailed microscopic states coarse-grain to the Hill form.\n- If the macroscopic response $R(I)$ is proportional to the fraction of activated effectors with maximum response $R_{\\max}$, then one obtains $R(I) = R_{\\max} \\cdot \\theta(I) = R_{\\max} \\cdot \\dfrac{I^n}{K^n + I^n}$.\n- The half-activation stimulus $I_{50}$ is defined by the condition $R(I_{50}) = \\dfrac{1}{2} R_{\\max}$. Solving $\\dfrac{I_{50}^n}{K^n + I_{50}^n} = \\dfrac{1}{2}$ yields $I_{50}^n = K^n$ and hence $I_{50} = K$. Therefore, under these assumptions, $I_{50}$ equals the dissociation constant scale of stimulus intensities at which half-occupancy occurs.\n- The Hill coefficient $n$ controls steepness because the log-slope at half-activation satisfies $\\left.\\dfrac{d \\log \\theta}{d \\log I}\\right|_{I=I_{50}} = \\dfrac{n}{4}$ for the Hill function, reflecting cooperativity: larger $n$ produces a steeper transition from low to high response, while smaller $n$ yields a more gradual slope.\n\nFeedback and background-dependent adaptation can be represented phenomenologically by modifying effective parameter values. Background $b$ modifies the apparent half-activation stimulus via a multiplicative factor $\\phi^{(b)}$ and modifies slope via an additive change $\\Delta n^{(b)}$, so that the true parameters used for data generation in background $b$ are $I_{50}^{(b)} = \\phi^{(b)} \\cdot I_{50,\\text{base}}$ and $n^{(b)} = n_{\\text{base}} + \\Delta n^{(b)}$. The macroscopic $R_{\\max}$ is kept constant across backgrounds in the synthetic generation for clarity.\n\nAlgorithmic design for fitting and evaluation:\n\n- For each test case $t \\in \\{0,1,2\\}$, define the base parameters ($R_{\\max}$, $I_{50,\\text{base}}$, $n_{\\text{base}}$) and background modifiers $\\{\\phi^{(b)}\\}_{b=0}^2$ and $\\{\\Delta n^{(b)}\\}_{b=0}^2$, as specified in the test suite. Construct a logarithmically spaced intensity grid of $N_I = 30$ points from $I_{\\min} = 10^{-2} \\cdot I_{50,\\text{base}}$ to $I_{\\max} = 10^{2} \\cdot I_{50,\\text{base}}$ to cover several orders of magnitude around the half-activation stimulus, ensuring identifiability.\n- For each background $b$, compute the noise-free response using the derived function $R(I) = R_{\\max} \\cdot \\dfrac{I^{n^{(b)}}}{(I_{50}^{(b)})^{n^{(b)}} + I^{n^{(b)}}}$. Add independent Gaussian noise to each response sample with standard deviation $\\sigma = 0.02 \\cdot R_{\\max}$. Use a deterministic random number generator with seed $s_t = 12345 + 100 \\cdot t$ so that the data are reproducible.\n- Fit the three parameters ($R_{\\max}$, $I_{50}$, $n$) separately for each background by minimizing the sum of squared residuals between the model and noisy responses. Use constraints $R_{\\max}  0$, $I_{50}  0$, and $0.1 \\le n \\le 5$ to enforce biological plausibility and numerical stability. Initialize parameters with $R_{\\max}$ equal to the maximum observed response in that background, $I_{50}$ equal to the geometric mean of the intensity grid (which is the midpoint in logarithmic space), and $n = 1$, which is neutral with respect to cooperativity.\n- After fitting, extract the fitted $I_{50,\\text{fit}}^{(b)}$ and $n_{\\text{fit}}^{(b)}$ for each background $b$. Compute for $b \\in \\{1,2\\}$ the ratio $r^{(b)} = I_{50,\\text{fit}}^{(b)} \\big/ I_{50,\\text{fit}}^{(0)}$ and the difference $\\delta^{(b)} = n_{\\text{fit}}^{(b)} - n_{\\text{fit}}^{(0)}$. These quantities report how background-dependent feedback changes the operating point and slope relative to baseline without requiring absolute calibration.\n- Aggregate the results across the three test cases in the required order. Round each float to three decimal places and print a single line with a comma-separated list enclosed in square brackets and no spaces.\n\nScientific interpretation of the parameters in the context of feedback:\n\n- If background raises the effective half-activation stimulus (e.g., desensitization via negative feedback upstream that reduces gain), then $\\phi^{(b)}  1$ and one expects $r^{(b)}  1$, indicating a rightward shift. Conversely, sensitization would yield $r^{(b)}  1$ for backgrounds that lower effective threshold.\n- If background compresses the response curve (e.g., divisive normalization reducing dynamic steepness), then $\\Delta n^{(b)}  0$ and one expects $\\delta^{(b)}  0$. If feedback sharpens the transition (e.g., positive feedback or cooperative channel gating), then $\\Delta n^{(b)}  0$ and one expects $\\delta^{(b)}  0$.\n- Because the fitting recovers parameters from noisy samples, the reported $r^{(b)}$ and $\\delta^{(b)}$ should approximate the true modifiers $(\\phi^{(b)}, \\Delta n^{(b)})$ relative to baseline, with small deviations due to noise and finite sampling.\n\nThe final program implements all steps, generates the synthetic datasets deterministically according to the specified seeds, performs constrained nonlinear regression for each background and test case, computes the required ratios and differences, rounds to three decimals, and prints them in the specified single-line format.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.optimize import curve_fit\n\ndef naka_rushton(I, Rmax, I50, n):\n    # Naka-Rushton / Hill function\n    I = np.asarray(I, dtype=float)\n    # Avoid numerical issues for extremely small negative n due to bounds; enforce positivity in caller\n    return Rmax * (I ** n) / (I50 ** n + I ** n)\n\ndef generate_synthetic_data(Rmax, I50_base, n_base, phi_list, delta_n_list, N_I, rng):\n    # Generate log-spaced intensities around I50_base\n    I_min = 1e-2 * I50_base\n    I_max = 1e2 * I50_base\n    intensities = np.logspace(np.log10(I_min), np.log10(I_max), N_I)\n    sigma = 0.02 * Rmax\n    data = []\n    for b, (phi, dn) in enumerate(zip(phi_list, delta_n_list)):\n        true_I50 = phi * I50_base\n        true_n = n_base + dn\n        true_resp = naka_rushton(intensities, Rmax, true_I50, true_n)\n        noisy_resp = true_resp + rng.normal(0.0, sigma, size=true_resp.shape)\n        data.append((intensities.copy(), noisy_resp))\n    return data\n\ndef fit_background(intensities, responses):\n    # Initial guesses: Rmax from max response (ensure positive), I50 from geometric mean of intensities, n=1.0\n    R_guess = max(1e-6, float(np.max(responses)))\n    I50_guess = float(np.exp(np.mean(np.log(intensities))))\n    n_guess = 1.0\n    p0 = [R_guess, I50_guess, n_guess]\n    # Bounds: Rmax0, I500, n in [0.1, 5]\n    bounds = ([1e-9, 1e-9, 0.1], [np.inf, np.inf, 5.0])\n    try:\n        popt, _ = curve_fit(\n            naka_rushton,\n            intensities,\n            responses,\n            p0=p0,\n            bounds=bounds,\n            maxfev=20000,\n        )\n    except Exception:\n        # Fallback: perturb initial guesses slightly and retry\n        p0_alt = [R_guess * 0.9 + 1e-3, I50_guess * 1.1 + 1e-3, min(4.9, max(0.2, n_guess * 1.2))]\n        popt, _ = curve_fit(\n            naka_rushton,\n            intensities,\n            responses,\n            p0=p0_alt,\n            bounds=bounds,\n            maxfev=20000,\n        )\n    R_fit, I50_fit, n_fit = popt\n    return R_fit, I50_fit, n_fit\n\ndef solve():\n    # Define the test cases from the problem statement.\n    # Each case: (Rmax, I50_base, n_base, phi_list for b=0..2, delta_n_list for b=0..2)\n    test_cases = [\n        (1.0, 50.0, 1.2, [1.0, 3.0, 10.0], [0.0, -0.2, -0.4]),\n        (0.8, 5.0, 2.0, [1.0, 2.0, 4.0], [0.0, 0.2, 0.4]),\n        (1.5, 100.0, 1.0, [1.0, 1.5, 2.5], [0.0, 0.0, -0.1]),\n    ]\n\n    N_I = 30  # number of intensity points per background\n\n    results = []\n    for t, (Rmax, I50_base, n_base, phi_list, delta_n_list) in enumerate(test_cases):\n        rng = np.random.default_rng(12345 + 100 * t)\n        # Generate synthetic data for three backgrounds\n        background_data = generate_synthetic_data(Rmax, I50_base, n_base, phi_list, delta_n_list, N_I, rng)\n        # Fit each background independently\n        fitted_params = []\n        for intensities, responses in background_data:\n            R_fit, I50_fit, n_fit = fit_background(intensities, responses)\n            fitted_params.append((R_fit, I50_fit, n_fit))\n        # Baseline parameters (background 0)\n        _, I50_fit_0, n_fit_0 = fitted_params[0]\n        # For backgrounds 1 and 2, compute ratios and differences\n        for b in [1, 2]:\n            _, I50_fit_b, n_fit_b = fitted_params[b]\n            r_b = I50_fit_b / I50_fit_0\n            d_b = n_fit_b - n_fit_0\n            # Round to three decimals as required in output\n            results.append(r_b)\n            results.append(d_b)\n\n    # Format with three decimals, no spaces\n    formatted = \",\".join(f\"{x:.3f}\" for x in results)\n    print(f\"[{formatted}]\")\n\nsolve()\n```", "id": "2836374"}]}