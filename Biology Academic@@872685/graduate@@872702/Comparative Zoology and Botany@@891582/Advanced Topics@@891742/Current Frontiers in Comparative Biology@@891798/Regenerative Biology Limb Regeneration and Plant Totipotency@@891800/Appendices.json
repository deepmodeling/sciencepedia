{"hands_on_practices": [{"introduction": "The foundation of any regenerative process, whether forming an axolotl blastema or a plant callus, is the rapid proliferation of cells. This first practice grounds the complex phenomenon of regeneration in the fundamental principles of population kinetics. By modeling the initial phase of cell accumulation with an idealized exponential growth model, you can estimate a key parameter—the doubling time—and critically evaluate its biological plausibility [@problem_id:2607001]. This exercise sharpens your skills in applying quantitative models to biological systems and reasoning about the physiological limits of cellular processes.", "problem": "A regenerating salamander limb blastema is initially composed of $10^{5}$ proliferative cells. Under a nutrient-replete, growth-factor-rich condition, assume the cell population follows idealized exponential growth driven by a constant per-capita division rate, and that cell loss is negligible over the time window considered. After $7$ days of regeneration, the blastema is measured to contain $10^{7}$ cells. Using only the core definitions of exponential growth and doubling time from population kinetics, derive an expression for the constant doubling time that would exactly achieve this expansion over $7$ days, and then compute its numerical value. Express your final answer in hours (h) and round to $3$ significant figures.\n\nThen, using first principles of cell-cycle control and comparative knowledge of proliferative rates in animal blastemas and plant callus cultures derived from totipotent cells, argue briefly whether the computed rate is biologically plausible, explicitly stating the assumptions under which your judgment holds. Your final reported answer must be only the computed doubling time.", "solution": "The problem requires the calculation of the cell population doubling time in a regenerating salamander limb blastema and a subsequent discussion on the biological plausibility of the result. The analysis will proceed in two stages: first, the mathematical derivation and computation based on the provided data, and second, a critical evaluation of the result based on established principles of cell biology.\n\nLet $N(t)$ be the number of cells at time $t$. The problem states that the cell population follows idealized exponential growth, which is described by the differential equation $\\frac{dN}{dt} = rN$, where $r$ is the constant per-capita division rate. The solution to this equation is:\n$$N(t) = N_0 \\exp(rt)$$\nwhere $N_0$ is the initial cell population at $t=0$.\n\nThe givens are:\nInitial population, $N_0 = 10^5$ cells.\nFinal population, $N(t_f) = 10^7$ cells.\nTime interval, $t_f = 7$ days.\n\nFirst, we must determine the growth rate $r$ from the data.\n$$N(t_f) = N_0 \\exp(r t_f)$$\n$$\\frac{N(t_f)}{N_0} = \\exp(r t_f)$$\nTaking the natural logarithm of both sides:\n$$\\ln\\left(\\frac{N(t_f)}{N_0}\\right) = r t_f$$\n$$r = \\frac{1}{t_f} \\ln\\left(\\frac{N(t_f)}{N_0}\\right)$$\nSubstituting the given values:\n$$r = \\frac{1}{7 \\text{ days}} \\ln\\left(\\frac{10^7}{10^5}\\right) = \\frac{1}{7 \\text{ days}} \\ln(100) = \\frac{2 \\ln(10)}{7 \\text{ days}}$$\n\nNext, we derive the expression for the doubling time, $T_d$. The doubling time is defined as the time required for the population to become twice its initial size, i.e., $N(T_d) = 2N_0$.\n$$2N_0 = N_0 \\exp(r T_d)$$\n$$2 = \\exp(r T_d)$$\n$$\\ln(2) = r T_d$$\n$$T_d = \\frac{\\ln(2)}{r}$$\nThis equation shows that the doubling time is inversely proportional to the growth rate.\n\nNow, we substitute our derived expression for $r$ into the equation for $T_d$:\n$$T_d = \\frac{\\ln(2)}{\\frac{1}{t_f} \\ln\\left(\\frac{N(t_f)}{N_0}\\right)} = t_f \\frac{\\ln(2)}{\\ln\\left(\\frac{N(t_f)}{N_0}\\right)}$$\nUsing the specific values from the problem:\n$$T_d = (7 \\text{ days}) \\frac{\\ln(2)}{\\ln\\left(\\frac{10^7}{10^5}\\right)} = (7 \\text{ days}) \\frac{\\ln(2)}{\\ln(100)} = (7 \\text{ days}) \\frac{\\ln(2)}{2\\ln(10)}$$\nTo obtain a numerical value, we use the standard values for $\\ln(2)$ and $\\ln(10)$:\n$$T_d \\approx (7 \\text{ days}) \\frac{0.6931}{2 \\times 2.3026} \\approx (7 \\text{ days}) \\times 0.1505 \\approx 1.0535 \\text{ days}$$\nThe problem requires the answer in hours, rounded to $3$ significant figures. We convert days to hours:\n$$T_d \\approx 1.0535 \\text{ days} \\times \\frac{24 \\text{ hours}}{1 \\text{ day}} \\approx 25.284 \\text{ hours}$$\nRounding to $3$ significant figures gives:\n$$T_d \\approx 25.3 \\text{ hours}$$\n\nThe second part of the task is to assess the biological plausibility of this result.\nA computed average doubling time of approximately $25.3$ hours for the entire cell population is rapid, but it falls within a plausible biological range for highly proliferative tissues, especially under the idealized conditions specified.\n\n1.  **Comparison with Animal Cell Cycle Times**: The eukaryotic cell cycle duration varies significantly depending on cell type and external conditions. Many standard mammalian cell lines grown in optimal culture conditions (e.g., human fibroblasts, HeLa cells) have doubling times of approximately $24$ hours. The calculated value of $25.3$ hours is therefore very close to the proliferation rates of robust, well-established in vitro systems.\n\n2.  **Context of Regenerative Blastemas**: Salamander blastema cells are known for their high proliferative activity, which fuels the regenerative process. Experimental studies on axolotl (Ambystoma mexicanum) blastemas have reported cell cycle times ranging from $30$ to $60$ hours. Our calculated value of $25.3$ hours is at the faster end of this spectrum. However, the problem specifies a \"nutrient-replete, growth-factor-rich condition\". Such idealized laboratory conditions are designed to maximize cell proliferation, primarily by shortening the G1 phase of the cell cycle. Therefore, observing a population doubling time that is faster than typical in vivo measurements is not unexpected and remains plausible.\n\n3.  **Comparative Biology with Plant Totipotency**: A comparison with plant regenerative systems is also instructive. When plant tissues are cultured to form a callus (a mass of undifferentiated, totipotent cells), they also exhibit rapid proliferation. Depending on the plant species and culture medium, the doubling times for plant callus or cell suspension cultures typically range from $24$ to $72$ hours. The calculated value for the salamander blastema fits comfortably within this range, underscoring that such proliferation rates are a common feature of highly regenerative biological systems across different kingdoms.\n\nIn conclusion, the computed doubling time of $25.3$ hours is biologically plausible. This judgment holds under the explicit assumptions of the problem: a simplified model of pure exponential growth (i.e., negligible cell death, differentiation, or exit from the cell cycle) and an optimally stimulating environment that pushes the proliferative capacity of the cells to its physiological limit. In a real biological system, factors such as cell heterogeneity, contact inhibition, and evolving signaling gradients would introduce complexities not captured by this idealized model.", "answer": "$$\\boxed{25.3}$$", "id": "2607001"}, {"introduction": "Once a sufficient mass of cells has been generated, it must be spatially organized to form a patterned, functional structure. This practice delves into one of the most elegant theories of biological pattern formation: diffusion-driven instability, first proposed by Alan Turing. You will derive from first principles the conditions under which a simple system of interacting and diffusing chemicals can spontaneously break symmetry and generate spatial patterns, a process thought to underlie patterning in both animal and plant development [@problem_id:2607048]. This exercise provides a rigorous, hands-on experience with the linear stability analysis of reaction-diffusion systems, a cornerstone of mathematical biology.", "problem": "In both axolotl limb blastema patterning and Arabidopsis callus formation during plant totipotency, spatial organization of morphogen concentrations can be modeled by a two-species activator–inhibitor reaction–diffusion system. Consider the generic linearization of such a system around a spatially homogeneous steady state $(u^{\\ast}, v^{\\ast})$:\n$$\n\\partial_{t}\\begin{pmatrix}u \\\\ v\\end{pmatrix}\n=\n\\begin{pmatrix}\nf_{u} & f_{v} \\\\\ng_{u} & g_{v}\n\\end{pmatrix}\n\\begin{pmatrix}u \\\\ v\\end{pmatrix}\n+\n\\begin{pmatrix}\nD_{u} & 0 \\\\\n0 & D_{v}\n\\end{pmatrix}\n\\nabla^{2}\\begin{pmatrix}u \\\\ v\\end{pmatrix},\n$$\nwhere $f_{u}$, $f_{v}$, $g_{u}$, and $g_{v}$ are the partial derivatives of the reaction kinetics at $(u^{\\ast}, v^{\\ast})$, and $D_{u}$, $D_{v}$ are diffusion coefficients. Using only core principles of linear stability analysis (Fourier mode decomposition, Fick’s law of diffusion, and the interpretation of trace and determinant of a Jacobian), derive from first principles the algebraic conditions that must simultaneously hold for diffusion to destabilize an otherwise kinetically stable homogeneous steady state (diffusion-driven, or Turing, instability). Then, evaluate these conditions for the parameter values $D_{u}=1$, $D_{v}=10$, $f_{u}=0.5$, $f_{v}=-0.6$, $g_{u}=0.7$, $g_{v}=-1.2$ (arbitrary but self-consistent units) to test whether diffusion-driven instability is possible in this comparative regenerative context, and justify your conclusion explicitly in terms of the derived conditions.\n\nAs your final numeric answer, report the determinant $\\Delta = f_{u}g_{v} - f_{v}g_{u}$ evaluated at the given parameter values. Express the final value as an exact fraction; no rounding is required and no units should be reported.", "solution": "The problem statement is a valid exercise in linear stability analysis of reaction-diffusion systems. It is scientifically grounded, well-posed, and all necessary parameters are provided to derive the general conditions for Turing instability and subsequently evaluate a specific case. We will now proceed with the solution.\n\nThe problem asks for the derivation of conditions for diffusion-driven instability in a two-species reaction-diffusion system linearized around a homogeneous steady state $(\\mathbf{u}^*) = (u^*, v^*)$. The governing equation for the perturbations $\\mathbf{u} = (u, v)^T$ is given by:\n$$\n\\partial_{t}\\mathbf{u}\n=\n\\mathbf{J} \\mathbf{u}\n+\n\\mathbf{D} \\nabla^{2}\\mathbf{u}\n$$\nwhere $\\mathbf{J}$ is the Jacobian matrix of the reaction kinetics and $\\mathbf{D}$ is the diagonal matrix of diffusion coefficients:\n$$\n\\mathbf{J} = \\begin{pmatrix} f_{u} & f_{v} \\\\ g_{u} & g_{v} \\end{pmatrix}, \\quad\n\\mathbf{D} = \\begin{pmatrix} D_{u} & 0 \\\\ 0 & D_{v} \\end{pmatrix}\n$$\n\nTo analyze the stability of the homogeneous steady state with respect to spatial perturbations, we employ Fourier analysis. We consider solutions of the form of a single Fourier mode with wavenumber vector $\\mathbf{k}$:\n$$\n\\mathbf{u}(\\mathbf{x}, t) = \\mathbf{u}_{\\mathbf{k}} e^{\\lambda_k t + i \\mathbf{k} \\cdot \\mathbf{x}}\n$$\nwhere $\\lambda_k$ is the growth rate of the mode with wavenumber $k = |\\mathbf{k}|$. Substituting this form into the governing PDE system, the partial derivatives transform as follows: $\\partial_{t} \\to \\lambda_k$ and $\\nabla^2 \\to -k^2$. This converts the system of partial differential equations into a system of algebraic equations for each wavenumber $k$:\n$$\n\\lambda_k \\mathbf{u}_{\\mathbf{k}} e^{\\lambda_k t + i \\mathbf{k} \\cdot \\mathbf{x}} = \\mathbf{J} \\mathbf{u}_{\\mathbf{k}} e^{\\lambda_k t + i \\mathbf{k} \\cdot \\mathbf{x}} - k^2 \\mathbf{D} \\mathbf{u}_{\\mathbf{k}} e^{\\lambda_k t + i \\mathbf{k} \\cdot \\mathbf{x}}\n$$\nDividing by the exponential term, we obtain an eigenvalue problem for each $k$:\n$$\n\\lambda_k \\mathbf{u}_{\\mathbf{k}} = (\\mathbf{J} - k^2 \\mathbf{D}) \\mathbf{u}_{\\mathbf{k}}\n$$\nLet $\\mathbf{M}_k = \\mathbf{J} - k^2 \\mathbf{D}$. The eigenvalues $\\lambda_k$ determine the stability of the mode with wavenumber $k$. The system is unstable if $\\text{Re}(\\lambda_k) > 0$ for at least one $k$. The eigenvalues $\\lambda_k$ are the roots of the characteristic equation $\\det(\\mathbf{M}_k - \\lambda_k \\mathbf{I}) = 0$, which is:\n$$\n\\lambda_k^2 - \\text{Tr}(\\mathbf{M}_k) \\lambda_k + \\det(\\mathbf{M}_k) = 0\n$$\nFor a $2 \\times 2$ system, the steady state is stable if and only if both eigenvalues have negative real parts. According to the Routh-Hurwitz stability criteria, this requires $\\text{Tr}(\\mathbf{M}_k) < 0$ and $\\det(\\mathbf{M}_k) > 0$. An instability arises if at least one of these conditions is violated.\n\nA diffusion-driven, or Turing, instability occurs when a steady state that is stable in the absence of diffusion is destabilized by diffusion for certain spatial patterns.\n\nFirst, we establish the condition for stability in the absence of diffusion. This corresponds to the spatially homogeneous mode, $k=0$. The matrix is $\\mathbf{M}_0 = \\mathbf{J}$. The stability conditions are:\nCondition 1: $\\text{Tr}(\\mathbf{J}) = f_u + g_v < 0$\nCondition 2: $\\det(\\mathbf{J}) = f_u g_v - f_v g_u > 0$\nThese two conditions ensure the homogeneous steady state is kinetically stable.\n\nNext, we investigate if diffusion ($k^2 > 0$) can cause an instability. We analyze the trace and determinant of $\\mathbf{M}_k$:\n$$\n\\text{Tr}(\\mathbf{M}_k) = \\text{Tr}(\\mathbf{J} - k^2 \\mathbf{D}) = (f_u + g_v) - k^2(D_u + D_v)\n$$\nSince $f_u + g_v < 0$ (from Condition 1) and diffusion coefficients $D_u, D_v$ are positive, the term $-k^2(D_u + D_v)$ is non-positive. Thus, $\\text{Tr}(\\mathbf{M}_k)$ is always negative for any $k$. This means that an instability cannot be triggered by the trace becoming positive.\nThe only way for an instability to occur is if the determinant becomes negative for some $k^2 > 0$.\n$$\n\\det(\\mathbf{M}_k) = \\det(\\mathbf{J} - k^2 \\mathbf{D}) = \\det\\begin{pmatrix} f_u - k^2 D_u & f_v \\\\ g_u & g_v - k^2 D_v \\end{pmatrix}\n$$\n$$\n\\det(\\mathbf{M}_k) = (f_u - k^2 D_u)(g_v - k^2 D_v) - f_v g_u\n$$\n$$\n\\det(\\mathbf{M}_k) = (f_u g_v - f_v g_u) - k^2(f_u D_v + g_v D_u) + k^4 D_u D_v\n$$\nLet $q = k^2 > 0$. We can write $\\det(\\mathbf{M}_k)$ as a quadratic function of $q$:\n$$\nh(q) = (D_u D_v) q^2 - (f_u D_v + g_v D_u) q + \\det(\\mathbf{J})\n$$\nFrom Condition 2, we have $h(0) = \\det(\\mathbf{J}) > 0$. The parabola $h(q)$ opens upwards as $D_u D_v > 0$. For $h(q)$ to become negative for some $q > 0$, its minimum must be at a positive $q$ value, and the function value at this minimum must be negative. The minimum of the parabola occurs at $q_c = \\frac{f_u D_v + g_v D_u}{2 D_u D_v}$. For this minimum to be at a physically meaningful (real) wavenumber, we need $q_c > 0$. This gives us the third condition:\nCondition 3: $f_u D_v + g_v D_u > 0$\nIf this condition holds, the vertex of the parabola is at $q_c > 0$. Since $h(0) > 0$ and $h(q) \\to \\infty$ as $q \\to \\infty$, the only way for $h(q)$ to be negative for some $q>0$ is for its minimum value, $h(q_c)$, to be negative. The condition $h(q_c) < 0$ is guaranteed if the three conditions hold and leads to a range of unstable wavenumbers. Therefore, the three necessary and sufficient conditions for Turing instability are:\n1. $f_u + g_v < 0$ (Kinetic stability)\n2. $f_u g_v - f_v g_u > 0$ (Kinetic stability)\n3. $f_u D_v + g_v D_u > 0$ (Diffusion-driven destabilization)\n\nNow, we evaluate these conditions for the given parameter values: $D_u = 1$, $D_v = 10$, $f_u = 0.5$, $f_v = -0.6$, $g_u = 0.7$, $g_v = -1.2$.\n\nEvaluation of Condition 1:\n$f_u + g_v = 0.5 + (-1.2) = -0.7$.\nSince $-0.7 < 0$, Condition 1 is satisfied.\n\nEvaluation of Condition 2:\n$f_u g_v - f_v g_u = (0.5)(-1.2) - (-0.6)(0.7) = -0.6 - (-0.42) = -0.6 + 0.42 = -0.18$.\nSince $-0.18 < 0$, Condition 2 is violated.\n\nConclusion:\nThe system with the given parameters does not exhibit a diffusion-driven (Turing) instability. The definition of a Turing instability requires the homogeneous steady state to be stable in the absence of diffusion. Here, the determinant of the reaction Jacobian, $\\det(\\mathbf{J}) = -0.18$, is negative. This implies that the homogeneous steady state is already unstable due to the reaction kinetics alone (it is a saddle point), irrespective of diffusion. Therefore, while the system is unstable, the instability is not of the Turing type because the prerequisite of kinetic stability is not met.\n\nThe final part of the problem asks for the evaluation of the determinant $\\Delta = f_u g_v - f_v g_u$. As calculated above:\n$\\Delta = -0.18$.\nAs an exact fraction, this is $\\Delta = -\\frac{18}{100} = -\\frac{9}{50}$.", "answer": "$$\\boxed{-\\frac{9}{50}}$$", "id": "2607048"}, {"introduction": "Underlying both cell proliferation and pattern formation is a complex gene regulatory network that makes the initial decision to enter a regenerative state. This final practice introduces a powerful systems biology approach to model the logic of this genetic switch using a Boolean network. You will formalize qualitative biological knowledge into a precise, computational model to explore how injury signals, feedback loops, and epigenetic memory interact to control cell fate [@problem_id:2607051]. By analyzing the network's attractors, you will gain a concrete understanding of how concepts like bistability and cellular memory emerge from network dynamics, providing insight into the robust decision-making processes within a single cell.", "problem": "You are asked to formalize a minimal synchronous Boolean network that captures a switch-like dedifferentiation module used to compare injury-induced limb regeneration in animals and totipotency induction in plants. The network has four conceptual nodes: injury signal, a Myc-like driver, chromatin opening, and cell cycle re-entry. The injury signal is treated as an external clamped input. The Myc-like driver represents a fast-acting transcriptional activator of proliferation and chromatin remodeling. Chromatin opening represents widespread accessibility of Deoxyribonucleic Acid (DNA) regulatory elements. The cell cycle node represents re-entry into proliferation, a hallmark of dedifferentiation.\n\nYour modeling must begin from the following foundational base, which you should treat as definitions and well-tested biological regularities: (i) the Central Dogma of molecular biology linking regulatory state to gene expression dynamics, (ii) the use of deterministic synchronous Boolean networks as minimal abstractions of gene regulatory circuits where each node is updated by a logical function of its regulators, and (iii) the interpretation of attractors as steady cell states (fixed points) or recurring patterns (cycles) in the state space.\n\nDefine binary variables $I$, $M$, $O$, $C$ taking values in $\\{0,1\\}$ for the injury input, Myc-like driver, chromatin opening, and cell cycle, respectively. Time is discrete, $t \\in \\mathbb{N}$. The injury input $I$ is clamped to a constant value $I \\in \\{0,1\\}$ within a given simulation. Let $f \\in \\{0,1\\}$ represent the presence ($f=1$) or absence ($f=0$) of a positive feedback from chromatin opening to sustain the Myc-like driver, capturing driver persistence only when chromatin is open. Let $e \\in \\{0,1\\}$ represent the presence ($e=1$) or absence ($e=0$) of epigenetic memory that can sustain chromatin opening even in the absence of the driver.\n\nUpdate the network synchronously by the following logic, derived from the biological premises but mathematically precise:\n- The driver is activated by injury and can self-sustain when chromatin is open if the feedback is present. Formally, for $t \\mapsto t+1$, set $M(t+1) = I$ if $f=0$, and $M(t+1) = I \\lor (M(t) \\land O(t))$ if $f=1$.\n- Chromatin opening is induced by the driver and may persist via epigenetic memory. Formally, $O(t+1) = M(t) \\lor (e \\land O(t))$.\n- Cell cycle re-entry requires both driver activity and open chromatin, so $C(t+1) = M(t) \\land O(t)$.\n- The input is clamped: $I(t+1) = I$ for all $t$.\n\nAn attractor is any cycle in the finite state space under synchronous updates, including fixed points as cycles of length $1$. You must analyze the attractor structure for each specified parameter set by exhaustively simulating from all initial configurations of the three internal nodes $(M,O,C) \\in \\{0,1\\}^3$ with the input $I$ held fixed.\n\nRepresent any network state of the three internal nodes $(M,O,C)$ as a single integer code using the map\n$$\n\\mathrm{code}(M,O,C) = 4 M + 2 O + C,\n$$\nso that, for example, $(M,O,C)=(1,1,1)$ maps to $7$ and $(M,O,C)=(0,0,0)$ maps to $0$. The input $I$ is not included in this code and must not appear in attractor encodings.\n\nFor each parameter set, collect all distinct attractors reached from the $2^3 = 8$ initial states. For each attractor, output the set of its member states as a sorted list of integer codes in non-decreasing order. For a given parameter set, output a list of these lists, with duplicates removed (attractors that are identical as sets must appear only once). The set of parameter values to analyze (the test suite) is:\n\n- Case A (bistable switch without chromatin memory): $(I,f,e)=(0,1,0)$.\n- Case B (sustained injury drive): $(I,f,e)=(1,1,0)$.\n- Case C (no feedback, no memory, no injury): $(I,f,e)=(0,0,0)$.\n- Case D (chromatin memory present, no injury): $(I,f,e)=(0,1,1)$.\n\nYour program must produce a single line of output containing the results for these four cases, in the above order, as a comma-separated list enclosed in square brackets. Each element of this top-level list must be the list of attractors for the corresponding case, where each attractor is itself represented as a bracket-enclosed, comma-separated list of integer codes. For example, a syntactically valid output has the form\n$[ [\\ldots], [\\ldots], [\\ldots], [\\ldots] ]$\nwith each inner list filled according to the conventions above. There are no physical units or angles in this problem. The final results must be fully determined by the specified update logic and parameter sets, with all simulations run until an attractor is detected by observing a repeated state.", "solution": "The problem statement is critically reviewed and determined to be valid. It is scientifically grounded in the established paradigms of systems biology, specifically the use of synchronous Boolean networks to model gene regulatory circuits. The problem is well-posed, with all variables, parameters, and deterministic update rules explicitly and unambiguously defined. The state space is finite, guaranteeing that all system trajectories converge to attractors (cycles or fixed points). The objective is clear and computationally tractable: to find all attractors for four specified parameter sets by exhaustive simulation. The problem is self-contained, logically consistent, and free of any scientific, mathematical, or formal flaws.\n\nThe problem requires the analysis of a four-node Boolean network designed to model cellular dedifferentiation. The network consists of three dynamic nodes—a Myc-like driver ($M$), chromatin opening ($O$), and cell cycle re-entry ($C$)—and one external input node for an injury signal ($I$). The state of each dynamic node at time $t+1$ is a Boolean function of the states of the nodes at time $t$. The network's behavior is governed by the clamped input $I \\in \\{0, 1\\}$ and two binary parameters: $f \\in \\{0,1\\}$, which controls a positive feedback loop, and $e \\in \\{0,1\\}$, which controls epigenetic memory.\n\nThe state of the three internal nodes $(M, O, C)$ is represented by a unique integer code calculated as:\n$$\n\\mathrm{code}(M,O,C) = 4M + 2O + C\n$$\nThis encoding maps the $2^3 = 8$ possible states onto the integers $\\{0, 1, \\dots, 7\\}$.\n\nThe synchronous update rules for the network are given by:\n\\begin{align*}\n    M(t+1) &= \\begin{cases} I & \\text{if } f=0 \\\\ I \\lor (M(t) \\land O(t)) & \\text{if } f=1 \\end{cases} \\\\\n    O(t+1) &= M(t) \\lor (e \\land O(t)) \\\\\n    C(t+1) &= M(t) \\land O(t)\n\\end{align*}\n\nAn attractor is a set of states that the system cycles through indefinitely. A fixed point is an attractor of length one. We will find all attractors for each of the four specified parameter sets by simulating the network's evolution from all $8$ possible initial states until a cycle is detected.\n\n**Case A: Bistable switch without chromatin memory $(I,f,e)=(0,1,0)$**\nFor this parameter set, the update rules simplify to:\n\\begin{align*}\n    M(t+1) &= M(t) \\land O(t) \\\\\n    O(t+1) &= M(t) \\\\\n    C(t+1) &= M(t) \\land O(t)\n\\end{align*}\nAnalysis of the state transitions reveals two fixed-point attractors:\n1.  Starting from any state where $M(0)=0$ (codes $0,1,2,3$), the system converges to the state $(M,O,C)=(0,0,0)$. This is a fixed point since $(0,0,0) \\to (0,0,0)$. The integer code is $0$.\n2.  Starting from any state where $M(0)=1$ and $O(0)=1$ (codes $6,7$), the system converges to the state $(M,O,C)=(1,1,1)$. This is a fixed point since $(1,1,1) \\to (1,1,1)$. The integer code is $7$. Initial states with $M(0)=1, O(0)=0$ (codes $4,5$) transition to $(0,1,0)$, which subsequently converges to $(0,0,0)$.\nThe distinct attractors are $\\{0\\}$ and $\\{7\\}$. This represents a bistable switch, with \"off\" ($0$) and \"on\" ($7$) states.\nThe set of attractors is `[[0], [7]]`.\n\n**Case B: Sustained injury drive $(I,f,e)=(1,1,0)$**\nWith a constant injury signal ($I=1$), the update rules are:\n\\begin{align*}\n    M(t+1) &= 1 \\lor (M(t) \\land O(t)) = 1 \\\\\n    O(t+1) &= M(t) \\\\\n    C(t+1) &= M(t) \\land O(t)\n\\end{align*}\nSince $M(t+1)$ is always $1$ for any $t \\geq 0$, after one time step, the system will be in a state where $M=1$.\nLet's trace the trajectory from any initial state. If $M(t)=0$, then $M(t+1)=1$ and $O(t+1)=0$. The state becomes $(1,0,C')$. From state $(1,0,C')$, the next state is $(M,O,C)=(1,1,0)$. From $(1,1,0)$, the next state is $(1,1,1)$. The state $(1,1,1)$ is a fixed point: $M(t+1)=1$, $O(t+1)=1$, $C(t+1)=1$.\nTherefore, all $8$ initial states eventually converge to the single fixed-point attractor $(1,1,1)$, which has code $7$. This represents a fully active, pro-regenerative state sustained by injury.\nThe set of attractors is `[[7]]`.\n\n**Case C: No feedback, no memory, no injury $(I,f,e)=(0,0,0)$**\nThis is the baseline case with no activating signals or memory mechanisms. The update rules simplify significantly:\n\\begin{align*}\n    M(t+1) &= 0 \\\\\n    O(t+1) &= M(t) \\\\\n    C(t+1) &= M(t) \\land O(t)\n\\end{align*}\nFor any initial state $(M(0), O(0), C(0))$, after one step, $M(1)=0$. At the next step, $M(2)=0$ and $O(2)=M(1)=0$. At the third step, the state will be $(M,O,C)=(0,0,0)$.\nSpecifically, $(M_t, O_t, C_t) \\to (0, M_t, M_t \\land O_t) \\to (0, 0, 0)$. The state $(0,0,0)$ is a fixed point. Thus, all trajectories converge to the single fixed point $(0,0,0)$, which has code $0$. This represents a quiescent, non-regenerative ground state.\nThe set of attractors is `[[0]]`.\n\n**Case D: Chromatin memory present, no injury $(I,f,e)=(0,1,1)$**\nIn this scenario, we have epigenetic memory ($e=1$) and feedback ($f=1$) but no injury input. The rules are:\n\\begin{align*}\n    M(t+1) &= M(t) \\land O(t) \\\\\n    O(t+1) &= M(t) \\lor O(t) \\\\\n    C(t+1) &= M(t) \\land O(t)\n\\end{align*}\nAnalyzing the state space reveals three distinct fixed-point attractors:\n1.  The state $(0,0,0)$ is a fixed point (code $0$). States $(0,0,1)$ flow into it. This is the quiescent state.\n2.  The state $(0,1,0)$ is a fixed point (code $2$). $(0,1,0) \\to (0\\land1, 0\\lor1, 0\\land1)=(0,1,0)$. States $(0,1,1)$, $(1,0,0)$, and $(1,0,1)$ all converge to this attractor. This represents a state with open chromatin but no driver activity, a form of \"poised\" or memory state.\n3.  The state $(1,1,1)$ is a fixed point (code $7$). States $(1,1,0)$ flow into it. This is the self-sustaining active state, maintained by the feedback loop between $M$ and $O$.\nThe presence of epigenetic memory creates a tristable system with three possible final cell fates in the absence of an injury signal.\nThe set of attractors is `[[0], [2], [7]]`.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Analyzes the attractor structure of a Boolean network for given parameter sets.\n    \"\"\"\n    # test_cases defines the parameters (I, f, e) for each of the four cases.\n    # Case A: (I,f,e)=(0,1,0)\n    # Case B: (I,f,e)=(1,1,0)\n    # Case C: (I,f,e)=(0,0,0)\n    # Case D: (I,f,e)=(0,1,1)\n    test_cases = [\n        (0, 1, 0),\n        (1, 1, 0),\n        (0, 0, 0),\n        (0, 1, 1),\n    ]\n\n    all_results = []\n\n    for params in test_cases:\n        I, f, e = params\n        found_attractors = set()\n\n        # Iterate through all 2^3 = 8 initial states for (M, O, C)\n        for i in range(8):\n            # Decode integer 'i' into state (M, O, C)\n            M = (i >> 2) & 1\n            O = (i >> 1) & 1\n            C = (i & 1)  # C is not needed for update, but part of state\n            \n            current_state = (M, O, C)\n            \n            # Simulate trajectory to find an attractor\n            trajectory = [current_state]\n            visited_states = {current_state: 0} # {state: time_step}\n\n            while True:\n                M_t, O_t, C_t = current_state\n\n                # Apply the synchronous update rules\n                if f == 0:\n                    M_next = I\n                else: # f == 1\n                    M_next = I or (M_t and O_t)\n                \n                O_next = M_t or (e and O_t)\n                C_next = M_t and O_t\n                \n                next_state = (int(M_next), int(O_next), int(C_next))\n\n                if next_state in visited_states:\n                    # Cycle detected, an attractor has been found\n                    cycle_start_index = visited_states[next_state]\n                    attractor_states = trajectory[cycle_start_index:]\n                    \n                    # Convert states to integer codes\n                    attractor_codes = []\n                    for state in attractor_states:\n                        m, o, c = state\n                        code = 4 * m + 2 * o + c\n                        attractor_codes.append(code)\n                    \n                    # Sort codes and add to set of found attractors to ensure uniqueness\n                    attractor_codes.sort()\n                    found_attractors.add(tuple(attractor_codes))\n                    break\n                \n                # Continue simulation\n                visited_states[next_state] = len(trajectory)\n                trajectory.append(next_state)\n                current_state = next_state\n        \n        # Convert set of tuples to a sorted list of lists\n        sorted_attractors = sorted([list(att) for att in found_attractors])\n        all_results.append(sorted_attractors)\n\n    # Format the final output string as per problem specification.\n    # The format is a list of lists of lists, e.g., [[[0],[7]],[[7]],...]\n    outer_list_parts = []\n    for case_attractors in all_results:\n        inner_list_parts = []\n        for attractor in case_attractors:\n            attractor_str = f\"[{','.join(map(str, attractor))}]\"\n            inner_list_parts.append(attractor_str)\n        case_str = f\"[{','.join(inner_list_parts)}]\"\n        outer_list_parts.append(case_str)\n    \n    final_output = f\"[{','.join(outer_list_parts)}]\"\n    print(final_output)\n\nsolve()\n```", "id": "2607051"}]}