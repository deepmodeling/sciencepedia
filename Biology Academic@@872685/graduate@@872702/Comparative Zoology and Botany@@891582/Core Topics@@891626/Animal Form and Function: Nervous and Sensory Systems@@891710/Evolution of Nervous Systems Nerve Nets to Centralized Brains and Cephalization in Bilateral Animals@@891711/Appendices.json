{"hands_on_practices": [{"introduction": "The transition from slow, diffusion-based signaling to rapid neural conduction was a pivotal step enabling the evolution of large, active animals. This exercise explores the fundamental physical limits of chemical diffusion versus the efficiency of axonal transport for long-distance communication within an organism. By deriving and calculating the dimensionless speed-advantage factor, $S$, you will quantify the immense evolutionary pressure that favored the development of dedicated nervous systems, providing a first-principles justification for why nerve cells are a prerequisite for complex animal life [@problem_id:2571069].", "problem": "In early multicellular animals relying primarily on paracrine diffusion across epithelial tissues, long-distance chemical communication is constrained by diffusion, whereas bilateral animals with cephalized organization increasingly rely on fast axonal conduction to coordinate peripheral sensors and effectors with anterior integrative centers. Consider a longitudinal body axis of length $L$ across which a signaling molecule must travel from a posterior sensory field to an anterior integrative ganglion. Assume the diffusing molecule is a small peptide moving effectively along one spatial dimension parallel to the body axis with diffusion coefficient $D$, and compare this to the time required for an action potential to propagate along an axon of length $L$ with conduction velocity $v$.\n\nUse as your only starting points the following well-tested base relations:\n- The one-dimensional diffusion mean-squared displacement relation $\\langle x^{2} \\rangle = 2 D t$.\n- The definition of average speed $v = L/t$ for directed propagation.\n\nDefine the dimensionless speed-advantage factor of neurons over diffusion as\n$$S \\equiv \\frac{t_{\\text{diff}}}{t_{\\text{neuro}}},$$\nwhere $t_{\\text{diff}}$ is the characteristic time for a molecule to traverse distance $L$ by diffusion and $t_{\\text{neuro}}$ is the propagation time of an action potential over the same distance. Derive $S$ from the base relations and then evaluate it numerically for the following biologically plausible parameters representative of an early bilaterian with a developing anterior concentration of neurons (cephalization):\n- Body-axis communication distance $L = 3.0 \\times 10^{-2}\\ \\text{m}$.\n- Peptide diffusion coefficient in extracellular matrix $D = 5.0 \\times 10^{-11}\\ \\text{m}^{2}\\ \\text{s}^{-1}$.\n- Unmyelinated axonal conduction velocity $v = 1.5\\ \\text{m}\\ \\text{s}^{-1}$.\n\nReport $S$ as a pure number (dimensionless). Round your final result to three significant figures. Do not include units in your final answer.", "solution": "The problem requires the derivation and numerical evaluation of a dimensionless factor, $S$, which quantifies the speed advantage of neuronal signal propagation over chemical diffusion for communication along a body axis of length $L$.\n\nThe problem is first validated.\nGivens:\n- One-dimensional diffusion mean-squared displacement: $\\langle x^{2} \\rangle = 2 D t$.\n- Directed propagation speed: $v = L/t$.\n- Speed-advantage factor definition: $S \\equiv \\frac{t_{\\text{diff}}}{t_{\\text{neuro}}}$.\n- Body-axis length: $L = 3.0 \\times 10^{-2}\\ \\text{m}$.\n- Peptide diffusion coefficient: $D = 5.0 \\times 10^{-11}\\ \\text{m}^{2}\\ \\text{s}^{-1}$.\n- Axonal conduction velocity: $v = 1.5\\ \\text{m}\\ \\text{s}^{-1}$.\n\nValidation Verdict:\nThe problem is scientifically grounded, using standard physical models for diffusion and directed motion. The context is a valid topic in comparative biology. The parameters are physically realistic and dimensionally consistent. The problem is well-posed, providing all necessary information to derive a unique solution. Therefore, the problem is valid and a solution will be constructed.\n\nThe derivation proceeds in three stages: first, we determine expressions for the characteristic diffusion time $t_{\\text{diff}}$ and the neuronal conduction time $t_{\\text{neuro}}$; second, we derive the analytical expression for $S$; and third, we compute its numerical value.\n\n1.  **Characteristic Diffusion Time ($t_{\\text{diff}}$)**\nThe motion of the signaling molecule is governed by diffusion, described by the mean-squared displacement in one dimension:\n$$\\langle x^{2} \\rangle = 2 D t$$\nThe characteristic time $t_{\\text{diff}}$ required for the molecule to traverse a distance $L$ is the time at which the root-mean-square displacement $\\sqrt{\\langle x^{2} \\rangle}$ is equal to $L$. This implies we set $\\langle x^{2} \\rangle = L^{2}$.\n$$L^{2} = 2 D t_{\\text{diff}}$$\nSolving for $t_{\\text{diff}}$ gives:\n$$t_{\\text{diff}} = \\frac{L^{2}}{2D}$$\nThis quadratic dependence of time on distance is a fundamental characteristic of diffusive processes.\n\n2.  **Neuronal Conduction Time ($t_{\\text{neuro}}$)**\nThe propagation of an action potential along an axon is a form of directed transport with a well-defined average velocity, $v$. The time required to travel a distance $L$ is given by the definition of velocity:\n$$v = \\frac{L}{t_{\\text{neuro}}}$$\nSolving for $t_{\\text{neuro}}$ gives:\n$$t_{\\text{neuro}} = \\frac{L}{v}$$\nThis linear dependence of time on distance is characteristic of directed propagation.\n\n3.  **Derivation and Evaluation of the Speed-Advantage Factor ($S$)**\nThe dimensionless speed-advantage factor $S$ is defined as the ratio of the two time scales:\n$$S \\equiv \\frac{t_{\\text{diff}}}{t_{\\text{neuro}}}$$\nSubstituting the expressions derived above:\n$$S = \\frac{\\left(\\frac{L^{2}}{2D}\\right)}{\\left(\\frac{L}{v}\\right)}$$\nSimplifying this complex fraction yields the analytical expression for $S$:\n$$S = \\frac{L^{2}}{2D} \\cdot \\frac{v}{L} = \\frac{Lv}{2D}$$\nNow, we substitute the provided numerical values into this expression:\n$L = 3.0 \\times 10^{-2}\\ \\text{m}$\n$v = 1.5\\ \\text{m}\\ \\text{s}^{-1}$\n$D = 5.0 \\times 10^{-11}\\ \\text{m}^{2}\\ \\text{s}^{-1}$\n\n$$S = \\frac{(3.0 \\times 10^{-2}) \\cdot (1.5)}{2 \\cdot (5.0 \\times 10^{-11})}$$\nFirst, compute the numerator and denominator separately:\nNumerator: $(3.0 \\times 1.5) \\times 10^{-2} = 4.5 \\times 10^{-2}$\nDenominator: $2 \\times 5.0 \\times 10^{-11} = 10.0 \\times 10^{-11} = 1.0 \\times 10^{-10}$\n\nNow, compute the ratio:\n$$S = \\frac{4.5 \\times 10^{-2}}{1.0 \\times 10^{-10}} = 4.5 \\times 10^{(-2 - (-10))} = 4.5 \\times 10^{8}$$\nThe problem requires the result to be rounded to three significant figures.\n$$S = 4.50 \\times 10^{8}$$\nThis result demonstrates a profound advantage of neuronal conduction over diffusion for long-distance signaling, explaining the evolutionary pressure for the development of centralized nervous systems in active, macroscopic animals.", "answer": "$$\\boxed{4.50 \\times 10^{8}}$$", "id": "2571069"}, {"introduction": "Beyond the properties of individual neurons, the architecture of the network itself dictates critical functional capacities such as robustness. The evolutionary shift from diffuse nerve nets to centralized brains represents a fundamental change in network topology, from a spatially homogeneous graph to a hub-dominated, scale-free structure. This computational practice applies principles from network science and percolation theory to compare the resilience of these two architectures against damage, a key factor in survival [@problem_id:2571026]. By simulating the effects of random versus targeted neuron removal, you will uncover a crucial trade-off inherent to cephalization: the impressive robustness of centralized networks to random failures comes at the cost of a profound vulnerability to targeted attacks on its critical hub nodes.", "problem": "You are to formalize and simulate a comparative robustness analysis of early nerve nets versus centralized brains under random and targeted node removal, grounded in percolation theory, using a fully specified algorithmic procedure. The evolutionary context is as follows: early animals such as cnidarians exhibit diffuse nerve nets with no cephalization, while bilaterians evolved cephalization and centralized brains. In this problem, a nerve net is modeled as a random geometric graph in the unit square, while a centralized brain is modeled as a scale-free network generated by the Barabási–Albert process. You will compute the critical fraction of nodes that must be removed to fragment each network below a defined giant component threshold under two strategies: random removal and targeted removal.\n\nStart from these core principles and definitions:\n\n- In percolation theory on networks, a graph is modeled as an undirected structure with nodes and edges. A percolation process removes nodes and their incident edges according to a specified rule. The largest connected component size after removing a fraction of nodes is a key observable.\n- The giant component fraction is the size of the largest connected component divided by the initial number of nodes $N_0$. Define the critical fraction $p_c$ as the minimal fraction $p = k / N_0$ such that, after removing $k$ nodes according to the specified strategy, the giant component fraction $S(k)/N_0$ falls strictly below a threshold $\\tau$. If no such $k$ exists up to $k = N_0$, set $p_c = 1$.\n- A random geometric graph is formed by placing $N$ nodes uniformly at random in the unit square and connecting any pair of nodes whose Euclidean distance is less than or equal to $r$.\n- The Barabási–Albert model (preferential attachment) constructs a scale-free network: begin with $m_0$ fully connected nodes; then, for each new node added until reaching $N$ total nodes, attach $m$ edges from the new node to $m$ distinct existing nodes, where each existing node is chosen with probability proportional to its current degree. Use $m \\le m_0$.\n\nAlgorithmic specifications:\n\n1. Graph construction:\n   - Random geometric graph (nerve net proxy): for parameters $(N, r)$, place $N$ points independently and uniformly on $[0,1]^2$, connect undirected edges between any two points with Euclidean distance $\\le r$.\n   - Barabási–Albert graph (centralized brain proxy): for parameters $(N, m_0, m)$ with $m \\le m_0$, initialize $m_0$ nodes fully connected; then add nodes one by one until $N$ nodes exist, connecting each new node to $m$ distinct existing nodes, sampled without replacement with probability proportional to degree.\n\n2. Removal strategies:\n   - Random removal: generate a random permutation of node indices using the given seed. Remove the first $k$ nodes in this order to evaluate $S(k)$.\n   - Targeted removal: iteratively remove one node at a time; at each step, choose among the remaining nodes the node with the highest current degree (count of alive neighbors). Break ties by selecting the smallest node index. Recompute degrees after each removal.\n\n3. Critical fraction computation:\n   - Let $N_0 = N$. Define $S(k)$ as the size of the largest connected component among the remaining nodes after removing $k$ nodes by the given strategy. Define the critical fraction as\n   $$ p_c = \\min \\left\\{ \\frac{k}{N_0} \\; \\bigg| \\; \\frac{S(k)}{N_0} < \\tau,\\; k \\in \\{0,1,\\dots,N_0\\} \\right\\}, $$\n     with the convention $p_c = 1$ if the set is empty.\n\n4. Determinism:\n   - All randomness must be generated deterministically using the provided seed for each test case. Use this seed for both graph generation and, where relevant, random removal ordering.\n\n5. Output and numerical requirements:\n   - For each test case, produce a single real number equal to $p_c$, rounded to exactly three decimal places.\n   - The final program output must be a single line containing a list of these rounded values in order, formatted as a comma-separated list enclosed in square brackets, e.g., $[0.123,0.456]$.\n\nTest suite:\n\nCompute $p_c$ for the following six cases. For all cases, use the giant component threshold $\\tau = 0.1$.\n\n- Case $1$ (nerve net, random removal):\n  - Model: random geometric graph.\n  - Parameters: $N = 200$, $r = 0.14$.\n  - Removal: random removal.\n  - Seed: $42$.\n\n- Case $2$ (nerve net, targeted removal):\n  - Model: random geometric graph.\n  - Parameters: $N = 200$, $r = 0.14$.\n  - Removal: targeted removal.\n  - Seed: $42$.\n\n- Case $3$ (centralized brain, random removal):\n  - Model: Barabási–Albert.\n  - Parameters: $N = 200$, $m_0 = 5$, $m = 3$.\n  - Removal: random removal.\n  - Seed: $101$.\n\n- Case $4$ (centralized brain, targeted removal):\n  - Model: Barabási–Albert.\n  - Parameters: $N = 200$, $m_0 = 5$, $m = 3$.\n  - Removal: targeted removal.\n  - Seed: $101$.\n\n- Case $5$ (nerve net, boundary check, random removal):\n  - Model: random geometric graph.\n  - Parameters: $N = 30$, $r = 0.28$.\n  - Removal: random removal.\n  - Seed: $7$.\n\n- Case $6$ (centralized brain, boundary check, targeted removal):\n  - Model: Barabási–Albert.\n  - Parameters: $N = 30$, $m_0 = 5$, $m = 2$.\n  - Removal: targeted removal.\n  - Seed: $9$.\n\nDefinitions and constraints to be used by your program:\n\n- Nodes are indexed from $0$ to $N-1$.\n- All graphs are undirected and simple (no self-loops, no multi-edges).\n- Connectivity is assessed among the currently alive nodes after $k$ removals; however, the giant component fraction is always normalized by $N_0$.\n- The Euclidean distance is computed in standard units on the unit square; no physical units are required in the answer.\n- Angle units are not involved.\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (e.g., $[0.123,0.456,0.789]$).", "solution": "We base the solution on percolation theory applied to network models that reflect contrasting organizational principles in nervous system evolution: nerve nets without cephalization versus centralized brains with cephalization.\n\nFoundational principles and definitions:\n\n- Let $G = (V, E)$ be an undirected simple graph with $|V| = N_0$. A percolation process removes nodes according to a specified rule, yielding an induced subgraph on the remaining nodes. The largest connected component size after removing $k$ nodes is denoted $S(k)$.\n- The giant component fraction is $S(k)/N_0$. The critical fraction $p_c$ is the minimal $p = k/N_0$ such that $S(k)/N_0 < \\tau$ for a specified threshold $\\tau$, or $p_c = 1$ if no such $k$ exists. This operational definition is consistent with standard percolation thresholds generalized to finite graphs.\n- Modeling assumptions reflecting biology:\n  - A nerve net is approximated as a spatially embedded network with local connectivity; a random geometric graph with parameters $(N, r)$ captures this by connecting nodes within Euclidean radius $r$ in the unit square. This conforms to the diffuse, relatively homogeneous organization of early nerve nets.\n  - A centralized brain is approximated as a scale-free, hub-dominated network, modeled by the Barabási–Albert process with parameters $(N, m_0, m)$, capturing preferential attachment and resulting heavy-tailed degree distributions characteristic of hub-based architectures.\n\nAlgorithmic construction:\n\n1. Random geometric graph generation for parameters $(N, r)$:\n   - Sample $N$ points independently from the uniform distribution on $[0,1]^2$ using a pseudorandom number generator initialized with the given seed.\n   - For each unordered pair of nodes $(i, j)$, compute the Euclidean distance $d_{ij}$; if $d_{ij} \\le r$, add the undirected edge $\\{i, j\\}$.\n\n2. Barabási–Albert graph generation for parameters $(N, m_0, m)$ with $m \\le m_0$:\n   - Initialize nodes indexed $0, 1, \\dots, m_0 - 1$ and connect an edge between every distinct pair, creating a complete graph on $m_0$ nodes. Initialize a degree array $\\mathbf{d}$ reflecting the current degrees.\n   - For each new node index $t$ from $m_0$ to $N - 1$:\n     - Compute attachment probabilities for the existing nodes $0, 1, \\dots, t - 1$ proportional to their current degrees $\\mathbf{d}$, normalized to sum to $1$.\n     - Sample $m$ distinct existing nodes without replacement according to these probabilities and connect the new node $t$ to each sampled node.\n     - Update the degree array $\\mathbf{d}$ accordingly.\n\n3. Removal strategies:\n   - Random removal strategy:\n     - Generate a random permutation $\\pi$ of $\\{0, 1, \\dots, N_0 - 1\\}$ using the given seed.\n     - For $k = 0, 1, 2, \\dots$, declare nodes $\\{\\pi_0, \\pi_1, \\dots, \\pi_{k-1}\\}$ removed and compute $S(k)$ as the size of the largest connected component of the induced subgraph on the remaining nodes.\n     - The process is monotonic in $k$, so the first $k$ such that $S(k)/N_0 < \\tau$ yields $p_c = k/N_0$. If no such $k$ exists up to $k = N_0$, set $p_c = 1$.\n   - Targeted removal strategy:\n     - Initialize all nodes as alive. For $k = 0, 1, 2, \\dots$, if $S(k)/N_0 < \\tau$, stop and set $p_c = k/N_0$.\n     - Otherwise, compute the current degree (number of alive neighbors) for each alive node. Select the node with the highest current degree; break ties by smallest node index. Remove this node and increment $k$. Repeat until the condition is met or all nodes are removed. If never met, set $p_c = 1$.\n\n4. Computing $S(k)$:\n   - Maintain an adjacency list representation. To compute $S(k)$ given a set of removed nodes, perform a breadth-first search (or depth-first search) over alive nodes only, marking visited nodes and tracking connected component sizes. The maximum component size across all alive components is $S(k)$.\n   - The giant component fraction is $S(k)/N_0$, where $N_0$ is the initial node count before any removals.\n\n5. Determinism:\n   - Initialize the pseudorandom number generator with the provided seed for each test case. Use this generator both for graph construction randomness and, when applicable, the random permutation for random removal. The targeted removal strategy is deterministic given the constructed graph.\n\nRationale and expected qualitative outcomes:\n- Scale-free networks (centralized brains) are typically robust to random removal (high $p_c$ under random strategy) and fragile to targeted removal of hubs (low $p_c$ under targeted strategy).\n- Spatially homogeneous networks (nerve nets) with narrower degree distributions tend to show more symmetric vulnerability: targeted removal does not disproportionately accelerate fragmentation compared to random removal as dramatically as in hub-dominated networks.\n\nNumerical procedure and output:\n- For each of the six specified test cases with parameters $(N, r)$ or $(N, m_0, m)$, threshold $\\tau = 0.1$, and given seed, construct the graph, apply the specified removal strategy, compute the minimal $k$ with $S(k)/N_0 < \\tau$, and output $p_c = k/N_0$ rounded to three decimal places.\n- Aggregate all six $p_c$ values into a single line string formatted as $[p_{c,1},p_{c,2},p_{c,3},p_{c,4},p_{c,5},p_{c,6}]$ with exactly three decimal places per value.\n\nThis algorithmic design integrates the biological context (nerve nets versus centralized brains and cephalization) with graph-theoretic percolation principles to produce quantifiable and reproducible robustness metrics for the provided test suite.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef build_random_geometric_graph(N, r, rng):\n    # Positions in unit square\n    pos = rng.random((N, 2))\n    r2 = r * r\n    adj = [set() for _ in range(N)]\n    # Compute pairwise distances (O(N^2))\n    for i in range(N):\n        xi, yi = pos[i]\n        for j in range(i + 1, N):\n            xj, yj = pos[j]\n            dx = xi - xj\n            dy = yi - yj\n            if dx * dx + dy * dy <= r2:\n                adj[i].add(j)\n                adj[j].add(i)\n    return adj\n\ndef build_barabasi_albert_graph(N, m0, m, rng):\n    if m > m0:\n        raise ValueError(\"m must be <= m0\")\n    adj = [set() for _ in range(N)]\n    # Initialize complete graph on m0 nodes\n    for i in range(m0):\n        for j in range(i + 1, m0):\n            adj[i].add(j)\n            adj[j].add(i)\n    # Degree array\n    deg = np.zeros(N, dtype=np.int64)\n    for i in range(m0):\n        deg[i] = m0 - 1\n    # Preferential attachment\n    for t in range(m0 + 0, N):\n        if t < m0:\n            continue\n        # Existing nodes 0..t-1\n        existing = np.arange(t, dtype=np.int64)\n        total_deg = deg[:t].sum()\n        if total_deg == 0:\n            # All degrees zero (should not happen after complete init), fallback to uniform\n            probs = np.ones(t) / float(t)\n        else:\n            probs = deg[:t].astype(float) / float(total_deg)\n        # Sample m distinct nodes without replacement using probs\n        # Handle corner case if t < m\n        sample_size = min(m, t)\n        targets = rng.choice(existing, size=sample_size, replace=False, p=probs)\n        for u in targets:\n            if u == t:\n                continue\n            # add edge if not exists\n            if t not in adj[u]:\n                adj[u].add(t)\n                adj[t].add(u)\n                deg[u] += 1\n                deg[t] += 1\n    return adj\n\ndef largest_component_size(adj, alive):\n    N = len(adj)\n    visited = np.zeros(N, dtype=bool)\n    max_size = 0\n    for start in range(N):\n        if not alive[start] or visited[start]:\n            continue\n        # BFS from start\n        queue = [start]\n        visited[start] = True\n        size = 0\n        q_index = 0\n        while q_index < len(queue):\n            u = queue[q_index]\n            q_index += 1\n            size += 1\n            for v in adj[u]:\n                if alive[v] and not visited[v]:\n                    visited[v] = True\n                    queue.append(v)\n        if size > max_size:\n            max_size = size\n        # Early exit if remaining alive nodes cannot exceed current max? Not necessary.\n    return max_size\n\ndef pc_random_removal(adj, rng, tau):\n    N0 = len(adj)\n    order = rng.permutation(N0)\n    alive = np.ones(N0, dtype=bool)\n    # Check k = 0\n    S = largest_component_size(adj, alive)\n    if S / N0 < tau:\n        return 0.0\n    for k in range(1, N0 + 1):\n        node_to_remove = order[k - 1]\n        alive[node_to_remove] = False\n        S = largest_component_size(adj, alive)\n        if S / N0 < tau:\n            return k / N0\n    return 1.0\n\ndef pc_targeted_removal(adj, tau):\n    N0 = len(adj)\n    alive = np.ones(N0, dtype=bool)\n    # Precompute neighbor lists as lists for faster iteration\n    neighbor_lists = [list(neis) for neis in adj]\n    # Check k = 0\n    S = largest_component_size(adj, alive)\n    if S / N0 < tau:\n        return 0.0\n    removed_count = 0\n    while removed_count < N0:\n        # Compute current degrees among alive nodes\n        # degree of dead nodes = -1 so never chosen\n        max_deg = -1\n        max_node = -1\n        for u in range(N0):\n            if not alive[u]:\n                continue\n            # count alive neighbors\n            deg_u = 0\n            for v in neighbor_lists[u]:\n                if alive[v]:\n                    deg_u += 1\n            if deg_u > max_deg:\n                max_deg = deg_u\n                max_node = u\n            elif deg_u == max_deg and deg_u >= 0 and u < max_node:\n                # tie-breaker: smallest index\n                max_node = u\n        if max_node == -1:\n            # No alive nodes remain\n            return 1.0\n        # Remove selected node\n        alive[max_node] = False\n        removed_count += 1\n        # Compute largest component\n        S = largest_component_size(adj, alive)\n        if S / N0 < tau:\n            return removed_count / N0\n    return 1.0\n\ndef solve():\n    # Define the test cases from the problem statement.\n    # Each test case is a dict with keys:\n    # type: 'rgg' or 'ba'\n    # params: dict of parameters\n    # removal: 'random' or 'targeted'\n    # tau: threshold\n    # seed: integer seed\n    test_cases = [\n        # Case 1\n        {\"type\": \"rgg\", \"params\": {\"N\": 200, \"r\": 0.14}, \"removal\": \"random\", \"tau\": 0.1, \"seed\": 42},\n        # Case 2\n        {\"type\": \"rgg\", \"params\": {\"N\": 200, \"r\": 0.14}, \"removal\": \"targeted\", \"tau\": 0.1, \"seed\": 42},\n        # Case 3\n        {\"type\": \"ba\", \"params\": {\"N\": 200, \"m0\": 5, \"m\": 3}, \"removal\": \"random\", \"tau\": 0.1, \"seed\": 101},\n        # Case 4\n        {\"type\": \"ba\", \"params\": {\"N\": 200, \"m0\": 5, \"m\": 3}, \"removal\": \"targeted\", \"tau\": 0.1, \"seed\": 101},\n        # Case 5\n        {\"type\": \"rgg\", \"params\": {\"N\": 30, \"r\": 0.28}, \"removal\": \"random\", \"tau\": 0.1, \"seed\": 7},\n        # Case 6\n        {\"type\": \"ba\", \"params\": {\"N\": 30, \"m0\": 5, \"m\": 2}, \"removal\": \"targeted\", \"tau\": 0.1, \"seed\": 9},\n    ]\n\n    results = []\n    for case in test_cases:\n        rng = np.random.default_rng(case[\"seed\"])\n        tau = case[\"tau\"]\n        if case[\"type\"] == \"rgg\":\n            N = case[\"params\"][\"N\"]\n            r = case[\"params\"][\"r\"]\n            adj = build_random_geometric_graph(N, r, rng)\n        elif case[\"type\"] == \"ba\":\n            N = case[\"params\"][\"N\"]\n            m0 = case[\"params\"][\"m0\"]\n            m = case[\"params\"][\"m\"]\n            adj = build_barabasi_albert_graph(N, m0, m, rng)\n        else:\n            raise ValueError(\"Unknown graph type\")\n        if case[\"removal\"] == \"random\":\n            pc = pc_random_removal(adj, rng, tau)\n        elif case[\"removal\"] == \"targeted\":\n            pc = pc_targeted_removal(adj, tau)\n        else:\n            raise ValueError(\"Unknown removal strategy\")\n        # Round to 3 decimals\n        results.append(f\"{pc:.3f}\")\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(results)}]\")\n\nif __name__ == \"__main__\":\n    solve()\n```", "id": "2571026"}, {"introduction": "The evolution of large, centralized brains is not only a story of functional advantages but also one of profound metabolic constraints, as neural tissue is among the most energetically expensive to build and maintain. This exercise frames brain evolution within the context of metabolic ecology, using allometric scaling laws and energy budget trade-offs to explore these limits. By deriving the maximum sustainable neural fraction, $f_{\\max}$, for different ecological lifestyles, you will quantitatively demonstrate how an animal's energy budget directly constrains the size and complexity of the nervous system it can afford, highlighting that the evolutionary path toward cephalization is governed as much by ecological opportunity as by functional benefit [@problem_id:2571015].", "problem": "Energy budgets constrain the evolution of nervous systems from diffuse nerve nets to centralized brains, because neural tissue carries a high metabolic cost. Consider two bilaterian lineages of equal body mass $M$ that differ only in lifestyle: an ambush predator and a continuous grazer. Let the non-neural maintenance metabolic rate scale allometrically as $B_{\\mathrm{nn}} = B_{0} M^{3/4}$, where $B_{0}$ is a constant. The total metabolic rate including neural costs is $B = B_{\\mathrm{nn}} + E_{n}$, where the neural energy allocation is defined by $E_{n} = f B$ with neural fraction $f \\in [0,1)$. Each lineage $l$ has a mean daily assimilated energy $A_{l}$ that scales with the same allometric factor as $B_{\\mathrm{nn}}$, modeled as $A_{l} = s_{l} B_{\\mathrm{nn}}$ with lifestyle-specific scope factor $s_{l} > 1$. To avoid compromising growth and reproduction, the net surplus must meet a minimum requirement $G_{\\min} = g B_{\\mathrm{nn}}$ with $g > 0$. Assume steady state over ecological timescales and apply energy conservation.\n\nStarting from these premises, derive the maximum sustainable neural fraction $f_{\\max}(s_{l}, g)$ for a given lifestyle $l$ that satisfies the non-compromise condition $A_{l} - B \\geq G_{\\min}$. Then, using $s_{\\mathrm{AP}} = 2.0$ for the ambush predator, $s_{\\mathrm{G}} = 1.5$ for the grazer, $g = 0.3$, $M = 8.0$ kilograms, and $B_{0} = 3.2 \\times 10^{5}$ joules per day per $\\mathrm{kg}^{-3/4}$, compute the neural energy allocations at the lifestyle-specific maxima, $E_{n,\\mathrm{AP}} = f_{\\max}(s_{\\mathrm{AP}}, g)\\, B_{\\mathrm{AP}}$ and $E_{n,\\mathrm{G}} = f_{\\max}(s_{\\mathrm{G}}, g)\\, B_{\\mathrm{G}}$, where $B_{l}$ is the total metabolic rate at $f_{\\max}(s_{l}, g)$. Finally, report the ratio $\\rho = E_{n,\\mathrm{AP}}/E_{n,\\mathrm{G}}$. Round your answer to four significant figures. Express your final answer as a unitless number (no units).", "solution": "The problem will first be subjected to critical validation before any attempt at a solution is made.\n\nStep 1: Extract Givens\nThe givens are extracted verbatim from the problem statement:\n- Body mass: $M$\n- Non-neural maintenance metabolic rate: $B_{\\mathrm{nn}} = B_{0} M^{3/4}$\n- Allometric constant: $B_{0} = 3.2 \\times 10^{5}$ joules per day per $\\mathrm{kg}^{-3/4}$\n- Total metabolic rate: $B = B_{\\mathrm{nn}} + E_{n}$\n- Neural energy allocation: $E_{n} = f B$\n- Neural fraction: $f \\in [0,1)$\n- Lineage index: $l$\n- Assimilated energy: $A_{l} = s_{l} B_{\\mathrm{nn}}$\n- Lifestyle-specific scope factor: $s_{l} > 1$\n- Minimum net surplus for growth and reproduction: $G_{\\min} = g B_{\\mathrm{nn}}$\n- Surplus factor: $g > 0$\n- Non-compromise condition: $A_{l} - B \\geq G_{\\min}$\n- Ambush predator scope factor: $s_{\\mathrm{AP}} = 2.0$\n- Grazer scope factor: $s_{\\mathrm{G}} = 1.5$\n- Surplus factor value: $g = 0.3$\n- Body mass value: $M = 8.0$ kilograms\n- Quantities to compute: $f_{\\max}(s_{l}, g)$, $E_{n,\\mathrm{AP}} = f_{\\max}(s_{\\mathrm{AP}}, g)\\, B_{\\mathrm{AP}}$, $E_{n,\\mathrm{G}} = f_{\\max}(s_{\\mathrm{G}}, g)\\, B_{\\mathrm{G}}$, and the ratio $\\rho = E_{n,\\mathrm{AP}}/E_{n,\\mathrm{G}}$\n\nStep 2: Validate Using Extracted Givens\nThe problem is evaluated against the validation criteria.\n- **Scientifically Grounded (Critical)**: The problem is founded on established principles of metabolic ecology, particularly allometric scaling laws (e.g., Kleiber's law, where metabolic rate scales with mass to the $3/4$ power) and the concept of energy budgets. These are core, non-controversial concepts in comparative physiology and theoretical biology. The premises are scientifically sound.\n- **Well-Posed**: The problem provides a clear objective (derive an expression and compute a ratio), sufficient definitions for all terms, and a set of consistent mathematical constraints that allow for the derivation of a unique solution.\n- **Objective (Critical)**: The language is precise, quantitative, and free of subjective, ambiguous, or opinion-based statements.\n\nThe problem is found to be self-contained, consistent, and scientifically sound. It does not violate any of the specified invalidity criteria.\n\nStep 3: Verdict and Action\nThe problem is valid. A rigorous solution will now be derived.\n\nThe primary task is to derive an expression for the maximum sustainable neural fraction, $f_{\\max}$, which is constrained by the energy balance of the organism. We begin with the non-compromise condition:\n$$A_{l} - B \\geq G_{\\min}$$\nWe are given the definitions for each term: $A_{l} = s_{l} B_{\\mathrm{nn}}$ and $G_{\\min} = g B_{\\mathrm{nn}}$. The total metabolic rate, $B$, is the sum of non-neural and neural components, $B = B_{\\mathrm{nn}} + E_{n}$. The neural energy allocation, $E_n$, is defined as a fraction $f$ of the total metabolic rate, $E_{n} = f B$.\nWe can express the total metabolic rate $B$ in terms of the non-neural rate $B_{\\mathrm{nn}}$ and the neural fraction $f$.\n$$B = B_{\\mathrm{nn}} + f B$$\n$$B(1-f) = B_{\\mathrm{nn}}$$\n$$B = \\frac{B_{\\mathrm{nn}}}{1-f}$$\nThis relationship holds because the problem defines $f \\in [0,1)$, ensuring the denominator $1-f$ is always positive.\n\nNow, we substitute the expressions for $A_l$, $B$, and $G_{\\min}$ into the inequality:\n$$s_{l} B_{\\mathrm{nn}} - \\frac{B_{\\mathrm{nn}}}{1-f} \\geq g B_{\\mathrm{nn}}$$\nThe non-neural metabolic rate $B_{\\mathrm{nn}} = B_0 M^{3/4}$ is strictly positive, given that $B_0 > 0$ and $M > 0$. We can therefore divide the entire inequality by $B_{\\mathrm{nn}}$ without changing the direction of the inequality:\n$$s_{l} - \\frac{1}{1-f} \\geq g$$\nTo find the maximum sustainable neural fraction, we solve this inequality for $f$:\n$$s_{l} - g \\geq \\frac{1}{1-f}$$\nFor the inequality to be physically meaningful, the left side must be positive, i.e., $s_l > g$. The given values confirm this: $s_{\\mathrm{AP}} - g = 2.0 - 0.3 = 1.7 > 0$ and $s_{\\mathrm{G}} - g = 1.5 - 0.3 = 1.2 > 0$. Since both sides of the inequality are positive, we may take the reciprocal, which reverses the inequality sign:\n$$\\frac{1}{s_{l} - g} \\leq 1-f$$\nFinally, we isolate $f$:\n$$f \\leq 1 - \\frac{1}{s_{l} - g}$$\nThe maximum value of $f$ that satisfies this condition, denoted $f_{\\max}$, is the upper bound of this range:\n$$f_{\\max}(s_{l}, g) = 1 - \\frac{1}{s_{l} - g}$$\nThis is the derived expression for the maximum sustainable neural fraction.\n\nThe next task is to compute the neural energy allocations $E_{n,l}$ for each lifestyle at its respective maximum neural fraction. The total metabolic rate for lineage $l$ at $f_{\\max}(s_l,g)$, denoted $B_l$, is:\n$$B_{l} = \\frac{B_{\\mathrm{nn}}}{1 - f_{\\max}(s_{l}, g)} = \\frac{B_{\\mathrm{nn}}}{1 - \\left(1 - \\frac{1}{s_{l} - g}\\right)} = \\frac{B_{\\mathrm{nn}}}{\\frac{1}{s_{l} - g}} = B_{\\mathrm{nn}}(s_{l} - g)$$\nThe neural energy allocation is then given by $E_{n,l} = f_{\\max}(s_{l}, g) B_{l}$. Substituting the expressions we derived:\n$$E_{n,l} = \\left(1 - \\frac{1}{s_{l} - g}\\right) \\left(B_{\\mathrm{nn}}(s_{l} - g)\\right)$$\n$$E_{n,l} = \\left(\\frac{s_{l} - g - 1}{s_{l} - g}\\right) B_{\\mathrm{nn}}(s_{l} - g)$$\n$$E_{n,l} = B_{\\mathrm{nn}}(s_{l} - g - 1)$$\nThis simplified expression for $E_{n,l}$ is elegant and facilitates the final calculation.\n\nWe are asked to find the ratio $\\rho = E_{n,\\mathrm{AP}}/E_{n,\\mathrm{G}}$. Using our derived expression for $E_{n,l}$:\n$$\\rho = \\frac{E_{n,\\mathrm{AP}}}{E_{n,\\mathrm{G}}} = \\frac{B_{\\mathrm{nn}}(s_{\\mathrm{AP}} - g - 1)}{B_{\\mathrm{nn}}(s_{\\mathrm{G}} - g - 1)}$$\nThe term $B_{\\mathrm{nn}}$ cancels, which signifies that the final ratio $\\rho$ is independent of both body mass $M$ and the specific allometric constant $B_0$. The values $M = 8.0 \\text{ kg}$ and $B_0 = 3.2 \\times 10^{5} \\text{ J/day/kg}^{-3/4}$ are therefore extraneous for this specific calculation.\n$$\\rho = \\frac{s_{\\mathrm{AP}} - g - 1}{s_{\\mathrm{G}} - g - 1}$$\nWe now substitute the provided numerical values: $s_{\\mathrm{AP}} = 2.0$, $s_{\\mathrm{G}} = 1.5$, and $g = 0.3$.\n$$\\rho = \\frac{2.0 - 0.3 - 1}{1.5 - 0.3 - 1} = \\frac{1.7 - 1}{1.2 - 1} = \\frac{0.7}{0.2}$$\n$$\\rho = 3.5$$\nThe problem requires the answer to be reported to four significant figures. Thus, the result is $3.500$.", "answer": "$$\\boxed{3.500}$$", "id": "2571015"}]}