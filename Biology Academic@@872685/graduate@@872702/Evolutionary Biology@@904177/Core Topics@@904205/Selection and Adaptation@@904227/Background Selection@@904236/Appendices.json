{"hands_on_practices": [{"introduction": "Background selection is fundamentally a consequence of purifying selection acting against deleterious mutations. To understand this process, we must first determine the equilibrium frequency of these harmful alleles in a population. This frequency is set by a dynamic tug-of-war between the constant introduction of new deleterious alleles via mutation and their steady removal by natural selection. This foundational exercise [@problem_id:2693173] guides you through the derivation of this mutation-selection balance, a cornerstone concept for quantifying the genetic load that drives the BGS effect.", "problem": "A single, randomly mating, panmictic population of effectively infinite size harbors a biallelic locus with alleles $A$ (wild type) and $a$ (deleterious). Viability selection acts with fitnesses $w_{AA}=1$, $w_{Aa}=1-hs$, and $w_{aa}=1-s$, where $s \\in (0,1]$ is the selection coefficient against homozygotes and $h \\in (0,1]$ is the dominance coefficient. Forward mutation from $A$ to $a$ occurs at rate $u$ per gene copy per generation, with no back mutation. Assume random mating each generation such that genotype frequencies are in Hardy–Weinberg proportions prior to selection. Let $q$ denote the frequency of allele $a$ immediately before selection in a given generation.\n\nStarting from these assumptions and standard deterministic viability selection and mutation recursions, derive the leading-order asymptotic expression (to first order in small quantities) for the equilibrium deleterious-allele frequency $\\hat{q}$ under mutation–selection balance when the deleterious allele is semi-dominant (that is, $h>0$). Your derivation must explicitly:\n- Write the exact recursion for $q$ across one generation combining selection and mutation.\n- Linearize this recursion in the regime where $q$ is small and $u$ is small, keeping only terms up to first order and discarding higher-order terms that are negligible under clearly stated conditions.\n- Solve for $\\hat{q}$ by setting the change in $q$ across one generation to zero and solving the resulting approximate equation for $q$.\n\nState the biological and mathematical conditions required for the approximation to be valid, including relationships among $u$, $h$, and $s$ and assumptions about population-genetic processes. Express your final result for $\\hat{q}$ as a symbolic expression in terms of $u$, $h$, and $s$. No numerical evaluation is required, and no units are to be reported.", "solution": "The problem asks for the leading-order asymptotic expression for the equilibrium frequency of a semi-dominant deleterious allele under mutation-selection balance. We begin by validating the problem statement.\n\nThe givens are:\n- A single, randomly mating, panmictic population of effectively infinite size.\n- A biallelic locus with alleles $A$ (wild type) and $a$ (deleterious).\n- Viability fitnesses: $w_{AA}=1$, $w_{Aa}=1-hs$, and $w_{aa}=1-s$.\n- Selection coefficient $s \\in (0,1]$.\n- Dominance coefficient $h \\in (0,1]$.\n- Forward mutation rate ($A \\to a$) is $u$ per gene copy per generation.\n- No back mutation ($a \\to A$).\n- Lifecycle order: random mating, then selection, then mutation.\n- $q$ is the frequency of allele $a$ before selection.\n\nThe problem is scientifically grounded, well-posed, and objective. It represents a canonical model in population genetics and provides all necessary information for a deterministic derivation. The assumptions are standard simplifications used to study the interplay of mutation and selection. Therefore, the problem is valid, and we may proceed with the solution.\n\nThe derivation follows three main steps as requested.\n\nFirst, we establish the exact recursion for the frequency of the deleterious allele, $q$, from one generation to the next. Let $q_t$ be the frequency of allele $a$ at the start of a generation (before selection). Due to random mating, the genotype frequencies are given by the Hardy–Weinberg proportions:\n- Frequency of $AA$: $(1-q_t)^2$\n- Frequency of $Aa$: $2q_t(1-q_t)$\n- Frequency of $aa$: $q_t^2$\n\nSelection acts on these genotypes according to their fitnesses. The mean fitness of the population, $\\bar{w}$, is the average of the genotype fitnesses weighted by their frequencies:\n$$\n\\bar{w} = (1-q_t)^2 w_{AA} + 2q_t(1-q_t) w_{Aa} + q_t^2 w_{aa}\n$$\nSubstituting the given fitness values:\n$$\n\\bar{w} = (1-q_t)^2 (1) + 2q_t(1-q_t) (1-hs) + q_t^2 (1-s)\n$$\nExpanding this expression gives:\n$$\n\\bar{w} = (1 - 2q_t + q_t^2) + (2q_t - 2q_t^2)(1-hs) + q_t^2(1-s)\n$$\n$$\n\\bar{w} = 1 - 2q_t + q_t^2 + 2q_t - 2hsq_t - 2q_t^2 + 2hsq_t^2 + q_t^2 - sq_t^2\n$$\n$$\n\\bar{w} = 1 - 2hsq_t - (s - 2hs)q_t^2\n$$\nAfter selection, the frequency of the allele $a$, denoted $q'_t$, is the sum of its frequency in homozygous ($aa$) and heterozygous ($Aa$) individuals, weighted by their post-selection frequencies:\n$$\nq'_t = \\frac{q_t^2 w_{aa} + q_t(1-q_t) w_{Aa}}{\\bar{w}} = \\frac{q_t^2(1-s) + q_t(1-q_t)(1-hs)}{\\bar{w}}\n$$\n$$\nq'_t = \\frac{q_t^2 - sq_t^2 + q_t - q_t^2 - hsq_t + hsq_t^2}{\\bar{w}} = \\frac{q_t(1-hs) - (s-hs)q_t^2}{\\bar{w}}\n$$\nAfter selection, mutation occurs. New copies of allele $a$ are created from allele $A$ at rate $u$. The frequency of allele $A$ after selection is $1-q'_t$. The frequency of allele $a$ in the next generation, $q_{t+1}$, is:\n$$\nq_{t+1} = q'_t + u(1-q'_t) = q'_t(1-u) + u\n$$\nSubstituting the expression for $q'_t$, we obtain the exact recursion:\n$$\nq_{t+1} = (1-u) \\left( \\frac{q_t(1-hs) - (s-hs)q_t^2}{1 - 2hsq_t - (s-2hs)q_t^2} \\right) + u\n$$\n\nSecond, we linearize this recursion under the assumption that the mutation rate $u$ is small and the deleterious allele frequency $q_t$ is consequently small. We analyze the change in allele frequency per generation, $\\Delta q = q_{t+1} - q_t$.\n$$\n\\Delta q = q'_{t}(1-u) + u - q_t = (q'_{t} - q_t) - u q'_{t} + u\n$$\nThe term $q'_{t} - q_t$ represents the change due to selection, $\\Delta q_{sel}$. For small $q_t$, we can approximate this change.\n$$\n\\Delta q_{sel} = q'_{t} - q_t = \\frac{q_t(1-hs) - (s-hs)q_t^2}{\\bar{w}} - q_t\n$$\nUsing $\\bar{w} \\approx 1-2hsq_t$ for small $q_t$ and the geometric series approximation $1/(1-x) \\approx 1+x$ for small $x$:\n$$\n\\Delta q_{sel} \\approx (q_t(1-hs) - O(q_t^2))(1+2hsq_t + O(q_t^2)) - q_t\n$$\n$$\n\\Delta q_{sel} \\approx (q_t - hsq_t)(1+2hsq_t) - q_t + O(q_t^2)\n$$\n$$\n\\Delta q_{sel} \\approx q_t + 2hsq_t^2 - hsq_t - 2h^2s^2q_t^2 - q_t + O(q_t^2)\n$$\nKeeping only the lowest-order term in $q_t$ (the linear term), we find:\n$$\n\\Delta q_{sel} \\approx -hsq_t\n$$\nThis is the linearized change due to selection. It shows that for a semi-dominant allele ($h>0$), selection removes the allele at a rate proportional to its frequency.\n\nNow, we approximate the full change $\\Delta q$.\n$$\n\\Delta q = \\Delta q_{sel} - u q'_{t} + u\n$$\nSince $q_t$ is small, selection has a small effect, so $q'_t \\approx q_t$. Therefore, to a first-order approximation:\n$$\n\\Delta q \\approx -hsq_t - uq_t + u\n$$\nAt mutation-selection balance, the input of new alleles from mutation is offset by their removal by selection. The equilibrium frequency $\\hat{q}$ will be small, of the same order as $u$. If we assume $u$ is a small parameter, then $\\hat{q}$ is of order $O(u)$. Let's analyze the magnitudes of the terms in our expression for $\\Delta q$:\n- $u$: order $O(u)$\n- $-hsq_t$: order $O(u)$, since $q_t \\sim O(u)$ and $h,s \\sim O(1)$\n- $-uq_t$: order $O(u^2)$, since $u \\sim O(u)$ and $q_t \\sim O(u)$\n\nTo obtain the leading-order approximation (first order in the small parameter $u$), we retain terms of order $O(u)$ and discard higher-order terms like $O(u^2)$. This gives the linearized equation for the change in allele frequency:\n$$\n\\Delta q \\approx u - hsq_t\n$$\n\nThird, we solve for the equilibrium frequency, $\\hat{q}$. At equilibrium, the allele frequency does not change, so $\\Delta q = 0$.\n$$\n0 = u - hs\\hat{q}\n$$\nSolving for $\\hat{q}$ yields the classic result for a semi-dominant deleterious allele:\n$$\nhs\\hat{q} = u \\implies \\hat{q} = \\frac{u}{hs}\n$$\n\nThe validity of this approximation rests on several conditions:\n1.  **Biological Assumptions**: The derivation assumes an idealized population (infinite size, random mating) where only mutation and viability selection are acting. The parameters $u$, $h$, and $s$ are assumed to be constant over time.\n2.  **Mathematical Conditions for Approximation**: The core of the approximation is treating $u$ and $q$ as small quantities and neglecting higher-order terms. This is justified if the equilibrium frequency $\\hat{q} = u/hs$ is indeed small. This requires $u \\ll hs$. Since $u$ (mutation rate) is typically very small (e.g., $10^{-6}$ to $10^{-5}$) and $s$ can be substantial, this condition holds for any non-trivial selection against heterozygotes (i.e., $h$ not being extremely close to zero). The condition $h>0$ is critical; if $h=0$ (complete recessivity), this formula and its derivation are invalid.", "answer": "$$\n\\boxed{\\frac{u}{hs}}\n$$", "id": "2693173"}, {"introduction": "Having established how selection maintains deleterious alleles at low frequencies, we can now model their impact on linked neutral variation. This practice explores the core mechanism of background selection in its most transparent form: a genome with no recombination, where neutral sites are permanently tethered to their genetic background. By assuming that only individuals completely free of deleterious mutations contribute to the population's long-term ancestry, you can directly calculate the reduction in effective population size. This derivation [@problem_id:2693239] reveals the elegant exponential relationship between the deleterious mutation rate ($U$), selection strength ($s$), and the reduction in diversity ($B$), providing the central intuition for how background selection operates.", "problem": "Consider a large, well-mixed haploid population with a completely nonrecombining genome, so that the recombination rate is $r=0$. Deleterious mutations occur at a total genomic rate $U$ per generation, independently among individuals and across loci. Each deleterious mutation reduces fitness by the same factor and fitness across loci is multiplicative: an individual carrying $k$ deleterious mutations has relative fitness $(1 - s)^{k}$ with $s \\in (0,1)$. Assume that the influx of new deleterious mutations per generation follows a Poisson distribution with mean $U$, selection is strong enough that lineages carrying deleterious mutations make a negligible contribution to long-term neutral genealogies, and that the population is at a stationary mutation–selection balance for the deleterious load.\n\nLet $p_{k}$ denote the equilibrium frequency of individuals carrying exactly $k$ deleterious mutations. Let $B$ denote the proportional reduction in neutral diversity at a focal perfectly neutral site that is completely linked to this genome, defined as the ratio of the neutral heterozygosity under selection to that in the absence of selection but with the same neutral mutation process. Under the assumptions above, derive from first principles an analytic expression for $B$ in terms of $U$ and $s$ only. Your derivation should start from fundamental definitions of mutation–selection balance and the specified multiplicative fitness model, and it should justify how $B$ relates to the equilibrium distribution $\\{p_{k}\\}_{k \\ge 0}$ in the strong selection, $r=0$ limit.\n\nProvide your final answer as a single closed-form expression in terms of $U$ and $s$. Do not include units. No numerical approximation or rounding is required.", "solution": "The problem requires the derivation of an expression for the proportional reduction in neutral diversity, $B$, under a model of background selection in a nonrecombining haploid population. The derivation must proceed from first principles.\n\nFirst, we must establish the equilibrium frequency distribution, $\\{p_{k}\\}_{k \\ge 0}$, of individuals carrying $k$ deleterious mutations. Let $p_{k}$ be the frequency of the class of individuals with $k$ deleterious mutations at the start of a generation. The relative fitness of this class is given as $w_{k} = (1 - s)^{k}$. The mean fitness of the population at equilibrium is $\\bar{w} = \\sum_{j=0}^{\\infty} p_{j} w_{j} = \\sum_{j=0}^{\\infty} p_{j} (1 - s)^{j}$.\n\nAfter selection, the frequency of the $k$-class, denoted $p_k^*$, becomes proportional to its initial frequency weighted by its fitness:\n$$ p_{k}^{*} = \\frac{p_{k} w_{k}}{\\bar{w}} = \\frac{p_{k} (1 - s)^{k}}{\\bar{w}} $$\nFollowing selection, new deleterious mutations occur. The problem states that the number of new mutations per individual per generation follows a Poisson distribution with mean $U$. The probability of an individual acquiring exactly $i$ new mutations is $\\frac{U^{i} \\exp(-U)}{i!}$.\n\nAn individual in the next generation will have $k$ mutations if its parent, which had $j$ mutations after selection, acquired an additional $k-j$ mutations. Summing over all possible parental classes $j \\le k$, the frequency of the $k$-class in the next generation, $p'_k$, is given by the convolution:\n$$ p'_{k} = \\sum_{j=0}^{k} p_{j}^{*} \\left( \\frac{U^{k-j} \\exp(-U)}{(k-j)!} \\right) = \\frac{\\exp(-U)}{\\bar{w}} \\sum_{j=0}^{k} p_{j} (1-s)^{j} \\frac{U^{k-j}}{(k-j)!} $$\nAt mutation-selection balance, the frequency distribution is stationary, so $p'_{k} = p_{k}$ for all $k \\ge 0$.\nFor the class with zero mutations ($k=0$), the equilibrium condition is:\n$$ p_{0} = \\frac{\\exp(-U)}{\\bar{w}} p_{0} (1-s)^{0} \\frac{U^{0}}{0!} = \\frac{\\exp(-U) p_{0}}{\\bar{w}} $$\nSince $p_0$ must be greater than $0$ for a viable population not fixed for deleterious alleles, we can divide by $p_0$ to find the mean fitness of the population at equilibrium:\n$$ \\bar{w} = \\exp(-U) $$\nThis result indicates that the mean fitness is reduced by a factor equal to the probability of escaping new deleterious mutations, a classic result.\n\nWe now seek the full distribution $\\{p_k\\}$. We hypothesize that the equilibrium distribution is a Poisson distribution, $p_{k} = \\exp(-\\lambda) \\frac{\\lambda^{k}}{k!}$, for some parameter $\\lambda$. We must verify this hypothesis and determine $\\lambda$.\nThe frequency of the $k$-class after selection, $p_k^*$, under this hypothesis is:\n$$ p_{k}^{*} = \\frac{p_{k} (1-s)^{k}}{\\bar{w}} = \\frac{\\exp(-\\lambda) \\frac{\\lambda^{k}}{k!} (1-s)^{k}}{\\sum_{j=0}^{\\infty} \\exp(-\\lambda) \\frac{\\lambda^{j}}{j!} (1-s)^{j}} = \\frac{\\frac{(\\lambda(1-s))^{k}}{k!}}{\\sum_{j=0}^{\\infty} \\frac{(\\lambda(1-s))^{j}}{j!}} = \\frac{\\frac{(\\lambda(1-s))^{k}}{k!}}{\\exp(\\lambda(1-s))} = \\exp(-\\lambda(1-s)) \\frac{(\\lambda(1-s))^{k}}{k!} $$\nThis shows that after selection, the distribution of mutations is still Poisson, but with a new mean $\\lambda(1-s)$. The number of mutations in the next generation is the sum of the number of mutations in the selected parents (a Poisson variable with mean $\\lambda(1-s)$) and the number of new mutations (a Poisson variable with mean $U$). The sum of two independent Poisson variables is also a Poisson variable with a mean equal to the sum of their means. Thus, the distribution in the next generation is Poisson with mean $\\lambda(1-s) + U$.\nFor the distribution to be at equilibrium, the mean of the distribution must be unchanged from one generation to the next. Therefore:\n$$ \\lambda = \\lambda(1-s) + U $$\n$$ \\lambda s = U \\implies \\lambda = \\frac{U}{s} $$\nThe equilibrium distribution of deleterious mutations is a Poisson distribution with mean $\\bar{k} = U/s$:\n$$ p_{k} = \\exp\\left(-\\frac{U}{s}\\right) \\frac{(U/s)^{k}}{k!} $$\n\nNext, we relate this to the reduction in neutral diversity, $B$. By definition, $B$ is the ratio of neutral heterozygosity under selection ($H_{s}$) to that in the absence of selection ($H_{0}$). Neutral heterozygosity is proportional to the effective population size, $N_e$. In the absence of selection, the effective size equals the census size, $N$. Thus, $B = H_{s}/H_{0} \\propto N_e/N$. Assuming proportionality, we can write $B = N_e/N$.\n\nThe problem states that selection is strong and there is no recombination ($r=0$). This implies that a neutral locus is permanently linked to its genetic background of deleterious mutations. The assumption that \"lineages carrying deleterious mutations make a negligible contribution to long-term neutral genealogies\" is critical. It means that any lineage carrying one or more deleterious mutations is eventually purged from the population by selection and cannot contribute to the ancestry of the population in the distant future. Consequently, the only individuals that form the basis for the long-term genealogy of the population are those that are free of deleterious mutations, i.e., those in the $k=0$ class.\nThe effective population size is therefore determined by the number of individuals in this mutation-free class. If the census size is $N$, the number of individuals in the mutation-free class is $N p_0$. Therefore, the effective population size is:\n$$ N_{e} = N p_{0} $$\nWe can now calculate the reduction in diversity, $B$:\n$$ B = \\frac{N_{e}}{N} = \\frac{N p_{0}}{N} = p_{0} $$\nUsing our derived equilibrium distribution, the frequency of the $k=0$ class is:\n$$ p_{0} = \\exp\\left(-\\frac{U}{s}\\right) \\frac{(U/s)^{0}}{0!} = \\exp\\left(-\\frac{U}{s}\\right) $$\nCombining these results gives the final expression for $B$.", "answer": "$$\\boxed{\\exp\\left(-\\frac{U}{s}\\right)}$$", "id": "2693239"}, {"introduction": "Theoretical models are powerful, but their value is ultimately determined by their ability to explain real-world data. This final practice moves from abstract derivation to the practical application of testing BGS hypotheses with genomic data. You will step into the role of a genomicist evaluating nested statistical models to determine if a sophisticated background selection map provides a better explanation for observed diversity patterns than a simpler model based on recombination rate alone. By working with standard statistical tools like the Akaike Information Criterion (AIC), likelihood ratio tests, and Bayes factors [@problem_id:2693255], you will develop critical skills for making evidence-based conclusions in modern evolutionary genomics.", "problem": "A genome-wide analysis seeks to assess whether a map of background selection (BGS) explains additional variance in neutral genetic diversity beyond what is explained by recombination alone. Background selection posits that purifying selection against linked deleterious mutations reduces neutral diversity as a function of local mutation input, selection coefficients, and effective recombination, predicting that regions with stronger background selection have lower diversity. Consider $N$ non-overlapping genomic windows with observed pairwise nucleotide diversity $\\,\\pi_i\\,$, recombination rate $\\,r_i\\,$, and a BGS score $\\,B_i\\in(0,1]$ that predicts the expected fraction of neutral diversity maintained under background selection. Two nested Gaussian-error linear models are fit by maximum likelihood to the same set of windows: a recombination-only model $\\,\\mathcal{M}_R\\,$ given by $\\,\\pi_i=\\alpha+\\beta r_i+\\varepsilon_i\\,$ and an augmented model $\\,\\mathcal{M}_{RB}\\,$ that additionally includes the BGS map as $\\,\\pi_i=\\alpha+\\beta r_i+\\gamma B_i+\\varepsilon_i\\,$, where $\\,\\varepsilon_i\\sim \\mathcal{N}(0,\\sigma^2)\\,$ and $\\,\\alpha,\\beta,\\gamma,\\sigma^2\\,$ are free parameters as applicable. The fitted maximum log-likelihoods are $\\,\\ell_R=-1250.3\\,$ for $\\,\\mathcal{M}_R\\,$ and $\\,\\ell_{RB}=-1238.8\\,$ for $\\,\\mathcal{M}_{RB}\\,$, using $\\,N=1000\\,$ windows. In addition, Bayesian fits with weakly informative priors yield log marginal likelihoods (log model evidences) $\\,\\log p(\\text{data}\\mid \\mathcal{M}_R)=-1260.0\\,$ and $\\,\\log p(\\text{data}\\mid \\mathcal{M}_{RB})=-1248.0\\,$.\n\nUsing established first-principles criteria for model comparison that trade off fit and complexity, and that integrate over parameter uncertainty when appropriate, determine which of the following statements are supported by these results. Select all that apply.\n\nA. Using the Akaike Information Criterion (AIC), counting both the mean-structure parameters and the residual variance as parameters, $\\,\\mathcal{M}_{RB}\\,$ is strongly favored, with a difference $\\,\\Delta \\mathrm{AIC}\\approx 21\\,$ in its favor.\n\nB. A likelihood ratio test between $\\,\\mathcal{M}_R\\,$ and $\\,\\mathcal{M}_{RB}\\,$ yields test statistic approximately $\\,D=23.0\\,$ with $\\,1\\,$ degree of freedom, implying $\\,p\\ll 0.001\\,$ and supporting inclusion of the BGS term.\n\nC. From the provided log marginal likelihoods, the Bayes factor in favor of $\\,\\mathcal{M}_{RB}\\,$ over $\\,\\mathcal{M}_R\\,$ is approximately $\\,\\exp(12)\\approx 1.6\\times 10^{5}\\,$, which constitutes decisive evidence for including the BGS map.\n\nD. Because the models are nested and $\\,N\\,$ is large, the Akaike Information Criterion (AIC) will always favor the more complex model $\\,\\mathcal{M}_{RB}\\,$ regardless of the change in fit, so no calculation is necessary.", "solution": "The problem statement is subjected to validation.\n\n**Step 1: Extract Givens**\n- Number of genomic windows: $N = 1000$.\n- Data per window $i$: observed pairwise nucleotide diversity $\\pi_i$, recombination rate $r_i$, BGS score $B_i \\in (0,1]$.\n- Model $\\mathcal{M}_R$ (recombination-only): $\\pi_i = \\alpha + \\beta r_i + \\varepsilon_i$, with $\\varepsilon_i \\sim \\mathcal{N}(0,\\sigma^2)$.\n- Model $\\mathcal{M}_{RB}$ (recombination + BGS): $\\pi_i = \\alpha + \\beta r_i + \\gamma B_i + \\varepsilon_i$, with $\\varepsilon_i \\sim \\mathcal{N}(0,\\sigma^2)$.\n- The parameters $\\alpha, \\beta, \\gamma, \\sigma^2$ are free parameters.\n- Maximum log-likelihood for $\\mathcal{M}_R$: $\\ell_R = -1250.3$.\n- Maximum log-likelihood for $\\mathcal{M}_{RB}$: $\\ell_{RB} = -1238.8$.\n- Log marginal likelihood for $\\mathcal{M}_R$: $\\log p(\\text{data}\\mid \\mathcal{M}_R) = -1260.0$.\n- Log marginal likelihood for $\\mathcal{M}_{RB}$: $\\log p(\\text{data}\\mid \\mathcal{M}_{RB}) = -1248.0$.\n- The number of parameters for each model includes both mean-structure parameters and the residual variance.\n\n**Step 2: Validate Using Extracted Givens**\nThe problem describes a standard statistical comparison of nested linear models in the context of population genetics.\n- **Scientifically Grounded:** The concepts of background selection (BGS), neutral diversity ($\\pi$), recombination rate ($r$), and their relationships are central to modern evolutionary biology. The use of linear models to partition variance is a common and valid approach.\n- **Well-Posed:** The problem provides two clearly defined, nested statistical models. It supplies all necessary quantitative results (log-likelihoods, sample size, log marginal likelihoods) to perform the requested model comparisons using standard criteria (AIC, LRT, Bayes Factor). The question is specific and answerable.\n- **Objective:** The problem is stated in precise, quantitative terms. There are no subjective or ambiguous statements.\n\n**Step 3: Verdict and Action**\nThe problem is scientifically sound, well-posed, and objective. It contains no inconsistencies, contradictions, or missing information. The problem is valid. I will proceed with the solution.\n\nThe problem requires the evaluation of two nested linear models based on provided statistical outputs.\nModel $\\mathcal{M}_R$ is given by $\\pi_i=\\alpha+\\beta r_i+\\varepsilon_i$. The parameters are $\\alpha$, $\\beta$, and the residual variance $\\sigma^2$. Thus, the number of parameters is $k_R = 3$.\nModel $\\mathcal{M}_{RB}$ is given by $\\pi_i=\\alpha+\\beta r_i+\\gamma B_i+\\varepsilon_i$. The parameters are $\\alpha$, $\\beta$, $\\gamma$, and the residual variance $\\sigma^2$. Thus, the number of parameters is $k_{RB} = 4$.\nThe provided values are:\n- Maximum log-likelihoods: $\\ell_R = -1250.3$ and $\\ell_{RB} = -1238.8$.\n- Log marginal likelihoods: $\\log p(\\text{data}\\mid \\mathcal{M}_R) = -1260.0$ and $\\log p(\\text{data}\\mid \\mathcal{M}_{RB}) = -1248.0$.\n- Sample size: $N = 1000$.\n\nI will now evaluate each statement.\n\n**A. Using the Akaike Information Criterion (AIC), counting both the mean-structure parameters and the residual variance as parameters, $\\mathcal{M}_{RB}$ is strongly favored, with a difference $\\Delta \\mathrm{AIC}\\approx 21$ in its favor.**\n\nThe Akaike Information Criterion is defined as $\\mathrm{AIC} = 2k - 2\\ell$, where $k$ is the number of estimated parameters and $\\ell$ is the maximum log-likelihood. A lower AIC value indicates a better trade-off between model fit and complexity.\n\nFor model $\\mathcal{M}_R$:\n$k_R = 3$\n$\\ell_R = -1250.3$\n$\\mathrm{AIC}_R = 2(3) - 2(-1250.3) = 6 + 2500.6 = 2506.6$.\n\nFor model $\\mathcal{M}_{RB}$:\n$k_{RB} = 4$\n$\\ell_{RB} = -1238.8$\n$\\mathrm{AIC}_{RB} = 2(4) - 2(-1238.8) = 8 + 2477.6 = 2485.6$.\n\nThe difference in AIC values, $\\Delta \\mathrm{AIC}$, is used to compare the models. To find the difference in favor of $\\mathcal{M}_{RB}$, we compute $\\mathrm{AIC}_R - \\mathrm{AIC}_{RB}$:\n$\\Delta \\mathrm{AIC} = \\mathrm{AIC}_R - \\mathrm{AIC}_{RB} = 2506.6 - 2485.6 = 21.0$.\n\nSince $\\mathrm{AIC}_{RB}$ is lower, $\\mathcal{M}_{RB}$ is the preferred model. A difference $\\Delta \\mathrm{AIC} > 10$ is conventionally considered very strong support for the model with the lower AIC. Here, the difference is $21.0$ in favor of $\\mathcal{M}_{RB}$. The statement is fully supported by the calculation.\n\nVerdict for A: **Correct**.\n\n**B. A likelihood ratio test between $\\mathcal{M}_R$ and $\\mathcal{M}_{RB}$ yields test statistic approximately $D=23.0$ with $1$ degree of freedom, implying $p\\ll 0.001$ and supporting inclusion of the BGS term.**\n\nThe likelihood ratio test (LRT) is applicable here because the models are nested: $\\mathcal{M}_R$ is a special case of $\\mathcal{M}_{RB}$ under the constraint that $\\gamma=0$. The LRT statistic, $D$, is given by:\n$D = 2(\\ell_{RB} - \\ell_R)$.\nUsing the provided log-likelihood values:\n$D = 2(-1238.8 - (-1250.3)) = 2(-1238.8 + 1250.3) = 2(11.5) = 23.0$.\n\nUnder the null hypothesis ($H_0: \\gamma=0$), the test statistic $D$ follows a chi-squared ($\\chi^2$) distribution with degrees of freedom equal to the difference in the number of parameters between the two models.\nDegrees of freedom ($df$) = $k_{RB} - k_R = 4 - 3 = 1$.\nSo, we compare our test statistic $D=23.0$ to a $\\chi^2_1$ distribution.\n\nThe critical values for the $\\chi^2_1$ distribution are:\n- for $p = 0.05$, $\\chi^2_{1, 0.05} \\approx 3.84$.\n- for $p = 0.01$, $\\chi^2_{1, 0.01} \\approx 6.63$.\n- for $p = 0.001$, $\\chi^2_{1, 0.001} \\approx 10.83$.\n\nOur calculated statistic $D=23.0$ is substantially larger than the critical value for a significance level of $p=0.001$. This implies that the p-value is extremely small ($p \\ll 0.001$). Such a result leads to a strong rejection of the null hypothesis, providing significant statistical support for the inclusion of the BGS term (i.e., for the more complex model $\\mathcal{M}_{RB}$).\n\nVerdict for B: **Correct**.\n\n**C. From the provided log marginal likelihoods, the Bayes factor in favor of $\\mathcal{M}_{RB}$ over $\\mathcal{M}_R$ is approximately $\\exp(12)\\approx 1.6\\times 10^{5}$, which constitutes decisive evidence for including the BGS map.**\n\nThe Bayes factor, $\\mathrm{BF}_{RB,R}$, in favor of model $\\mathcal{M}_{RB}$ over model $\\mathcal{M}_R$ is the ratio of their marginal likelihoods:\n$\\mathrm{BF}_{RB,R} = \\frac{p(\\text{data} \\mid \\mathcal{M}_{RB})}{p(\\text{data} \\mid \\mathcal{M}_R)}$.\n\nIn logarithmic scale, this is:\n$\\log(\\mathrm{BF}_{RB,R}) = \\log p(\\text{data} \\mid \\mathcal{M}_{RB}) - \\log p(\\text{data} \\mid \\mathcal{M}_R)$.\n\nUsing the provided log marginal likelihoods:\n$\\log(\\mathrm{BF}_{RB,R}) = -1248.0 - (-1260.0) = -1248.0 + 1260.0 = 12.0$.\n\nTherefore, the Bayes factor is:\n$\\mathrm{BF}_{RB,R} = \\exp(12.0)$.\nNumerically, $\\exp(12) \\approx 162754.79$. This is approximately $1.6 \\times 10^5$.\n\nAccording to conventional scales (e.g., Kass and Raftery 1995), a Bayes factor greater than $100$ (or a log Bayes factor greater than $\\log(100) \\approx 4.6$) is considered \"decisive\" evidence. Our calculated Bayes factor of $\\approx 1.6 \\times 10^5$ is vastly larger than this threshold. Thus, the evidence in favor of $\\mathcal{M}_{RB}$ is indeed decisive.\n\nVerdict for C: **Correct**.\n\n**D. Because the models are nested and $N$ is large, the Akaike Information Criterion (AIC) will always favor the more complex model $\\mathcal{M}_{RB}$ regardless of the change in fit, so no calculation is necessary.**\n\nThis statement is a claim about the fundamental properties of AIC. Let us analyze it. For AIC to favor the more complex model $\\mathcal{M}_{RB}$ over the simpler model $\\mathcal{M}_R$, we require $\\mathrm{AIC}_{RB} < \\mathrm{AIC}_R$.\n$\\mathrm{AIC}_R - \\mathrm{AIC}_{RB} > 0$\n$(2k_R - 2\\ell_R) - (2k_{RB} - 2\\ell_{RB}) > 0$\n$2(k_R - k_{RB}) + 2(\\ell_{RB} - \\ell_R) > 0$.\n\nSince $k_{RB} = k_R + 1$, we have $k_R - k_{RB} = -1$.\n$2(-1) + 2(\\ell_{RB} - \\ell_R) > 0$\n$-2 + 2(\\ell_{RB} - \\ell_R) > 0$\n$2(\\ell_{RB} - \\ell_R) > 2$\n$\\ell_{RB} - \\ell_R > 1$.\n\nThis inequality demonstrates that AIC will favor the more complex model only if the increase in the maximum log-likelihood is greater than $1$. It is entirely possible for the log-likelihood to increase by an amount less than or equal to $1$ (i.e., $0 \\le \\ell_{RB} - \\ell_R \\le 1$). In such a case, AIC would not favor the more complex model. The statement \"regardless of the change in fit\" is therefore fundamentally incorrect. The AIC explicitly penalizes complexity, and this penalty must be overcome by a sufficient improvement in fit (as measured by the log-likelihood). The size of $N$ does not alter this principle, although a large $N$ may make it more probable that a genuine effect will produce a log-likelihood increase greater than $1$. The claim is an overgeneralization and is false.\n\nVerdict for D: **Incorrect**.", "answer": "ABC", "id": "2693255"}]}