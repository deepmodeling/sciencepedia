{"hands_on_practices": [{"introduction": "The C-value paradox arises because the vast majority of a eukaryotic genome does not code for proteins. This first exercise provides a quantitative look at this composition, asking you to calculate the non-coding fraction in a hypothetical genome. By dissecting the genome into its functional parts—exons, introns, and intergenic regions including transposable elements—you can directly see how genome size can vary independently of gene content. [@problem_id:2756905]", "problem": "A central empirical observation in eukaryotic genomics is the so-called C-value paradox: there is no simple correlation between an organism’s haploid genome size (the C-value) and its phenotypic or developmental complexity. Use only the following core definitions and facts as your starting point: (i) by the Central Dogma of molecular biology, protein-coding information is contained in coding sequences that are transcribed and translated into polypeptides; (ii) introns are transcribed but spliced out and not translated; (iii) intergenic regions, including sequences derived from transposable elements (TEs), are generally not translated; and (iv) the haploid genome can be decomposed into mutually exclusive fractions that sum to unity.\n\nConsider a hypothetical eukaryotic haploid genome whose composition by length is as follows: transposable elements (TEs) occupy a fraction $0.45$, unique intergenic sequence occupies $0.35$, introns occupy $0.15$, and exons occupy $0.05$. For the purpose of this calculation, assume that all exonic sequence is protein-coding, and that introns and all intergenic sequence (both TE-derived and unique) are non-coding.\n\nTask:\n- From first principles based on the definitions above, compute the fraction $f_{\\mathrm{nc}}$ of non-coding DNA in this haploid genome. Express your final answer as a decimal between $0$ and $1$. Do not include any units and do not use a percent sign.\n- In your reasoning, explain how this genomic composition bears on the C-value paradox by identifying which compositional categories can vary to change the C-value without necessarily altering the number of protein-coding genes.\n\nOnly the numerical value of $f_{\\mathrm{nc}}$ will be graded as the final answer. No rounding is required beyond writing the exact decimal implied by the composition provided.", "solution": "We begin with the fundamental decomposition of the haploid genome into mutually exclusive fractions that sum to one. Let the fractions be denoted by $f_{\\mathrm{TE}}$, $f_{\\mathrm{UI}}$ (unique intergenic), $f_{\\mathrm{intron}}$, and $f_{\\mathrm{exon}}$, respectively. By the problem statement, these are:\n$$\nf_{\\mathrm{TE}} = 0.45,\\quad f_{\\mathrm{UI}} = 0.35,\\quad f_{\\mathrm{intron}} = 0.15,\\quad f_{\\mathrm{exon}} = 0.05.\n$$\nBy definition and under the assumptions given, protein-coding information resides solely in the exonic fraction. Specifically, the Central Dogma of molecular biology dictates that protein-coding DNA is that which is transcribed and translated into polypeptides; introns are transcribed but removed by splicing and are not translated; intergenic sequences, including those derived from transposable elements, are not translated. The assumption in the problem simplifies exons to be entirely protein-coding.\n\nTherefore, the non-coding fraction $f_{\\mathrm{nc}}$ is the sum of all fractions that do not contribute to translated polypeptides:\n$$\nf_{\\mathrm{nc}} \\equiv f_{\\mathrm{TE}} + f_{\\mathrm{UI}} + f_{\\mathrm{intron}}.\n$$\nSubstituting the given values,\n$$\nf_{\\mathrm{nc}} = 0.45 + 0.35 + 0.15 = 0.95.\n$$\n\nTo connect this composition to the C-value paradox, recall that the C-value is the haploid genome size, which we may denote by $L$ (in base pairs). The number of protein-coding genes depends primarily on the total amount of coding sequence (and regulatory architecture), not on the total amount of non-coding DNA. In this genome, the coding fraction is $f_{\\mathrm{exon}} = 0.05$, while the non-coding fraction is $f_{\\mathrm{nc}} = 0.95$. The categories $f_{\\mathrm{TE}}$, $f_{\\mathrm{UI}}$, and $f_{\\mathrm{intron}}$ can expand or contract via processes such as transposable element proliferation, accumulation or deletion of intergenic sequence, and intron gain/loss. These processes can increase $L$ (hence the C-value) without a necessary concomitant increase in the number of protein-coding genes or their total coding length. Consequently, variation in $f_{\\mathrm{TE}}$, $f_{\\mathrm{UI}}$, and $f_{\\mathrm{intron}}$—which together dominate the genome at $0.95$ in this example—can drive large changes in the C-value independently of organismal complexity, exemplifying the C-value paradox.", "answer": "$$\\boxed{0.95}$$", "id": "2756905"}, {"introduction": "The accumulation of transposable elements (TEs) is a primary driver of genome expansion, but many TE insertions are mildly harmful. This practice delves into the core of the drift-barrier hypothesis by using the diffusion approximation from population genetics to calculate the fixation probability of a deleterious TE. You will see how the interplay between selection ($s$) and genetic drift (related to effective population size, $N_e$) determines the fate of these genomic additions, providing a powerful mechanism to explain the C-value paradox. [@problem_id:2756912]", "problem": "Consider the evolutionary problem posed by the C-value paradox: genome sizes vary widely and do not correlate with organismal complexity. A major contributor to genome size variation is the accumulation of transposable elements (TEs). Under the drift-barrier hypothesis, species with smaller effective population sizes tend to fix more mildly deleterious TE insertions due to weaker efficacy of purifying selection.\n\nAssume a diploid, randomly mating population with constant effective population size $N_{e}$. A new TE (transposable element) insertion arises in a single copy in a single heterozygous individual, so the initial allele frequency is $x_{0} = \\frac{1}{2 N_{e}}$. The insertion is mildly deleterious with additive fitness effect $s<0$, so that relative fitnesses are $1$, $1+s$, and $1+2s$ for the $aa$, $aA$, and $AA$ genotypes, respectively. Work in the standard Wright–Fisher diffusion framework with selection and genetic drift.\n\nUsing the diffusion approximation for the fixation probability $u(x)$ of a diallelic locus with additive selection in a population of effective size $N_{e}$, derive $u(x)$ from first principles by solving the backward Kolmogorov equation with appropriate boundary conditions, evaluate it at $x_{0} = \\frac{1}{2 N_{e}}$, and then compute the expected fixation probability of this TE insertion for a lineage with $N_{e} = 10^{6}$ and $s = -5 \\times 10^{-7}$. Round your final numerical answer to three significant figures. Express the final answer as a pure number (no units).", "solution": "The probability of fixation $u(x)$ for an allele with current frequency $x$ can be found by solving the backward Kolmogorov equation. In the context of the diffusion approximation of the Wright-Fisher model, this equation is:\n$$ M_{\\delta x}(x) \\frac{du}{dx} + \\frac{1}{2} V_{\\delta x}(x) \\frac{d^2u}{dx^2} = 0 $$\nwhere $M_{\\delta x}(x)$ is the expected change in allele frequency per generation due to selection, and $V_{\\delta x}(x)$ is the variance in the change in allele frequency per generation due to genetic drift.\n\nFirst, we determine the coefficient for selection, $M_{\\delta x}(x)$. The relative fitnesses for genotypes $aa$, $aA$, and $AA$ are $1$, $1+s$, and $1+2s$, respectively. Let $x$ be the frequency of allele $A$. The mean fitness of the population is $\\bar{w} = (1-x)^2 \\cdot 1 + 2x(1-x)(1+s) + x^2 (1+2s) = 1 + 2sx$.\nThe frequency of allele $A$ in the next generation after selection, $x'$, is given by the frequency of alleles contributed by each genotype, weighted by their fitnesses:\n$$ x' = \\frac{x^2(1+2s) + x(1-x)(1+s)}{\\bar{w}} = \\frac{x(x(1+2s) + (1-x)(1+s))}{1+2sx} = \\frac{x(1+s+sx)}{1+2sx} $$\nThe change in allele frequency due to selection is $\\Delta x_{sel} = x' - x$:\n$$ \\Delta x_{sel} = \\frac{x(1+s+sx)}{1+2sx} - x = \\frac{x+sx+sx^2 - x(1+2sx)}{1+2sx} = \\frac{sx - sx^2}{1+2sx} = \\frac{sx(1-x)}{1+2sx} $$\nFor weak selection, where $|s| \\ll 1$, we can approximate $\\bar{w} \\approx 1$, leading to $M_{\\delta x}(x) \\approx sx(1-x)$.\n\nNext, we determine the coefficient for drift, $V_{\\delta x}(x)$. In a diploid population of effective size $N_e$, there are $2N_e$ gene copies. The variance from binomial sampling of these gene copies is $V_{\\delta x}(x) = \\frac{x(1-x)}{2N_e}$.\n\nSubstituting these coefficients into the backward Kolmogorov equation:\n$$ sx(1-x) \\frac{du}{dx} + \\frac{1}{2} \\frac{x(1-x)}{2N_e} \\frac{d^2u}{dx^2} = 0 $$\nFor $x \\in (0, 1)$, we can divide by $x(1-x)$:\n$$ s \\frac{du}{dx} + \\frac{1}{4N_e} \\frac{d^2u}{dx^2} = 0 $$\nRearranging gives a second-order linear ordinary differential equation with constant coefficients:\n$$ \\frac{d^2u}{dx^2} + 4N_e s \\frac{du}{dx} = 0 $$\nLet $\\gamma = 4N_e s$. The equation becomes $\\frac{d^2u}{dx^2} + \\gamma \\frac{du}{dx} = 0$.\n\nThe boundary conditions for fixation probability are $u(0)=0$ (an allele with frequency $0$ cannot fix) and $u(1)=1$ (an allele with frequency $1$ is already fixed).\n\nTo solve the ODE, let $v(x) = \\frac{du}{dx}$. The equation becomes a first-order separable ODE: $\\frac{dv}{dx} + \\gamma v = 0$.\n$$ \\frac{dv}{v} = -\\gamma dx \\implies \\int \\frac{dv}{v} = \\int -\\gamma dx \\implies \\ln|v| = -\\gamma x + C_1 $$\n$$ v(x) = \\exp(-\\gamma x + C_1) = C_2 \\exp(-\\gamma x) $$\nwhere $C_2 = \\exp(C_1)$. Since $v(x) = \\frac{du}{dx}$, we integrate again:\n$$ u(x) = \\int C_2 \\exp(-\\gamma x) dx = -\\frac{C_2}{\\gamma} \\exp(-\\gamma x) + C_3 $$\nLet $K_1 = -C_2/\\gamma$ and $K_2=C_3$. The general solution is $u(x) = K_1 \\exp(-\\gamma x) + K_2$.\n\nWe apply the boundary conditions to find the constants $K_1$ and $K_2$.\nApplying $u(0)=0$:\n$0 = K_1 \\exp(0) + K_2 \\implies 0 = K_1 + K_2 \\implies K_2 = -K_1$.\nApplying $u(1)=1$:\n$1 = K_1 \\exp(-\\gamma) + K_2$.\nSubstituting $K_2 = -K_1$:\n$1 = K_1 \\exp(-\\gamma) - K_1 = K_1(\\exp(-\\gamma) - 1)$.\nThis gives $K_1 = \\frac{1}{\\exp(-\\gamma) - 1}$ and $K_2 = -K_1 = \\frac{1}{1 - \\exp(-\\gamma)}$.\nSubstituting the constants back into the general solution:\n$$ u(x) = \\frac{\\exp(-\\gamma x)}{\\exp(-\\gamma) - 1} - \\frac{1}{\\exp(-\\gamma) - 1} = \\frac{\\exp(-\\gamma x) - 1}{\\exp(-\\gamma) - 1} $$\nMultiplying the numerator and denominator by $-1$:\n$$ u(x) = \\frac{1 - \\exp(-\\gamma x)}{1 - \\exp(-\\gamma)} $$\nSubstituting $\\gamma = 4N_e s$, we obtain the fixation probability as a function of initial frequency $x$:\n$$ u(x) = \\frac{1 - \\exp(-4N_e s x)}{1 - \\exp(-4N_e s)} $$\nThis completes the derivation from first principles.\n\nThe problem states that the TE insertion arises as a single copy in a single heterozygous individual in a diploid population. The initial frequency is therefore $x_0 = \\frac{1}{2N_e}$. We evaluate $u(x)$ at this initial frequency:\n$$ u\\left(\\frac{1}{2N_e}\\right) = \\frac{1 - \\exp\\left(-4N_e s \\frac{1}{2N_e}\\right)}{1 - \\exp(-4N_e s)} = \\frac{1 - \\exp(-2s)}{1 - \\exp(-4N_e s)} $$\nThis expression gives the fixation probability for a new mutation.\n\nNow, we compute the numerical value using the given parameters: $N_e = 10^6$ and $s = -5 \\times 10^{-7}$.\nFirst, calculate the exponents:\nThe scaled selection coefficient in the denominator is $4N_e s = 4 \\times (10^6) \\times (-5 \\times 10^{-7}) = 4 \\times (-0.5) = -2$.\nThe exponent in the numerator is $2s = 2 \\times (-5 \\times 10^{-7}) = -1 \\times 10^{-6}$.\n\nSubstitute these values into the fixation probability formula:\n$$ u = \\frac{1 - \\exp(-(-1 \\times 10^{-6}))}{1 - \\exp(-(-2))} = \\frac{1 - \\exp(10^{-6})}{1 - \\exp(2)} $$\nFor a small value $z$, the Taylor expansion of $\\exp(z)$ is approximately $1+z$. Thus, for the numerator:\n$1 - \\exp(10^{-6}) \\approx 1 - (1 + 10^{-6}) = -10^{-6}$.\nThe denominator is $1 - \\exp(2) \\approx 1 - 7.389056 = -6.389056$.\nThe fixation probability is:\n$$ u \\approx \\frac{-10^{-6}}{-6.389056} \\approx 0.156519 \\times 10^{-6} = 1.56519 \\times 10^{-7} $$\nRounding to three significant figures, we get $1.57 \\times 10^{-7}$.", "answer": "$$\\boxed{1.57 \\times 10^{-7}}$$", "id": "2756912"}, {"introduction": "Transposable element proliferation can occur in dramatic bursts, causing rapid, punctuated increases in genome size over evolutionary time. This advanced exercise challenges you to act as a computational biologist, using statistical model selection to find evidence of such a burst in a simulated evolutionary history. By comparing a null model of gradual change (Brownian motion) with an alternative model incorporating a sudden jump, you will learn how to formally test hypotheses about the tempo and mode of genome size evolution. [@problem_id:2756951]", "problem": "You are asked to formalize and implement a null model of continuous change for the evolution of the logarithm of deoxyribonucleic acid content (the logarithm of the C-value) along a single lineage and to test for deviations that are consistent with punctuated increases, which in biological terms could be caused by bursts of Transposable Elements (TEs), also known as Transposable Element (TE) bursts. The modeling and derivation must be grounded in the following foundational and widely used principles: (i) the definition of Brownian motion as a continuous-time Gaussian process for trait evolution under neutrality, (ii) the definition of a likelihood under independent Gaussian increments, and (iii) the Bayesian Information Criterion (BIC) as a model selection principle. You must not assume any drift in the null model.\n\nFormulate the following:\n\n- Consider a trait $Y(t)$ that represents the natural logarithm of the C-value measured along a single lineage at times $t_0 < t_1 < \\dots < t_n$. Under the null model, assume $Y(t)$ follows Brownian motion with diffusion variance parameter $\\sigma^2$ and zero drift, so that increments $\\Delta Y_i = Y(t_{i+1}) - Y(t_i)$ over time steps $\\Delta t_i = t_{i+1} - t_i$ are independent and distributed as $\\mathcal{N}(0, \\sigma^2 \\Delta t_i)$.\n- Derive from first principles the maximum likelihood estimate of the diffusion variance parameter $\\sigma^2$ under the null model and the corresponding maximized log-likelihood, expressed in terms of the observed increments $\\Delta Y_i$ and time steps $\\Delta t_i$.\n- Define a one-pulse alternative model in which there is a single nonnegative jump $J \\ge 0$ added to exactly one interval between $t_j$ and $t_{j+1}$, so that $\\Delta Y_j \\sim \\mathcal{N}(J, \\sigma^2 \\Delta t_j)$ and all other increments remain $\\mathcal{N}(0, \\sigma^2 \\Delta t_i)$. The location index $j$ is unknown and to be selected by maximizing the likelihood, and the jump magnitude $J$ is also unknown. Derive from first principles the joint maximum likelihood estimates for $\\sigma^2$ and $J$ in this alternative, emphasizing the constraint $J \\ge 0$ and how it affects the estimate when the observed increment $\\Delta Y_j$ is nonpositive.\n- Using the Bayesian Information Criterion defined as $\\mathrm{BIC} = -2 \\log L + k \\log m$, where $L$ is the maximized likelihood, $m = n$ is the number of increments, and $k$ is the number of free parameters counted for the model, implement a decision rule that declares evidence for a punctuated increase if and only if the best single-jump model has a strictly smaller $\\mathrm{BIC}$ than the null model. For the purpose of penalization, treat the null model as having $k = 1$ (the parameter $\\sigma^2$) and the single-jump alternative as having $k = 3$ (the parameters $\\sigma^2$, $J$, and a penalty for the unknown discrete location of the jump).\n- Your program must compute, for each test case, a boolean indicating whether a punctuated increase is supported (true if the best single-jump model has smaller $\\mathrm{BIC}$ than the null model, and false otherwise). No physical units are required.\n\nTest suite. Implement your solution on the following test cases. Each case provides a time grid and corresponding log C-values. For each, produce a boolean result as defined above.\n\n- Case A (null-like, no strong evidence expected):\n  - Times $[0.0, 10.0, 20.0, 40.0, 80.0]$\n  - Log C-values $[1.1, 1.08, 1.12, 1.10, 1.15]$\n- Case B (contains a clear punctuated increase):\n  - Times $[0.0, 10.0, 20.0, 40.0, 80.0]$\n  - Log C-values $[1.0, 1.02, 1.01, 1.41, 1.44]$\n- Case C (contains a large negative change but no punctuated increase):\n  - Times $[0.0, 10.0, 20.0, 40.0, 80.0]$\n  - Log C-values $[1.2, 1.15, 1.10, 1.09, 1.08]$\n- Case D (irregular sampling with a very short initial interval, but no punctuated increase):\n  - Times $[0.0, 0.001, 1.001, 2.001, 5.001]$\n  - Log C-values $[0.0, -0.001, 0.0, 0.01, 0.005]$\n\nFinal output format. Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (e.g., \"[true,false,true,false]\"). Use Python boolean literals, which are capitalized as in $[\\mathrm{True}, \\mathrm{False}, \\dots]$ in the code context, so the exact output must be formatted as a single line string of the form $[\\mathrm{True},\\mathrm{False},\\dots]$ with no spaces.", "solution": "The trait of interest is $Y(t)$, the natural logarithm of the C-value at time $t$. We are given observations at times $t_0 < t_1 < \\dots < t_n$. Let $Y_i = Y(t_i)$. We define the time increments as $\\Delta t_i = t_{i+1} - t_i$ and the trait increments as $\\Delta Y_i = Y_{i+1} - Y_i$ for $i = 0, 1, \\dots, n-1$. There are $n$ such increments.\n\n**1. Null Model ($M_0$): Brownian Motion**\n\nUnder the null model, the evolution of $Y(t)$ is described by a Brownian motion process with zero drift and a diffusion variance parameter $\\sigma^2$. The increments $\\Delta Y_i$ are independent and normally distributed with mean $0$ and variance $\\sigma^2 \\Delta t_i$.\n$$\n\\Delta Y_i \\sim \\mathcal{N}(0, \\sigma^2 \\Delta t_i)\n$$\nThe probability density function (PDF) of an increment $\\Delta Y_i$ is:\n$$\np(\\Delta Y_i | \\sigma^2) = \\frac{1}{\\sqrt{2\\pi \\sigma^2 \\Delta t_i}} \\exp\\left(-\\frac{(\\Delta Y_i)^2}{2\\sigma^2 \\Delta t_i}\\right)\n$$\nThe likelihood function $L_0(\\sigma^2)$ is the product of the PDFs for all $n$ independent increments:\n$$\nL_0(\\sigma^2) = \\prod_{i=0}^{n-1} p(\\Delta Y_i | \\sigma^2) = \\prod_{i=0}^{n-1} \\frac{1}{\\sqrt{2\\pi \\sigma^2 \\Delta t_i}} \\exp\\left(-\\frac{(\\Delta Y_i)^2}{2\\sigma^2 \\Delta t_i}\\right)\n$$\nThe log-likelihood, $\\ell_0(\\sigma^2) = \\log L_0(\\sigma^2)$, is more convenient for maximization:\n$$\n\\ell_0(\\sigma^2) = \\sum_{i=0}^{n-1} \\left[ -\\frac{1}{2}\\log(2\\pi) - \\frac{1}{2}\\log(\\sigma^2) - \\frac{1}{2}\\log(\\Delta t_i) - \\frac{(\\Delta Y_i)^2}{2\\sigma^2 \\Delta t_i} \\right]\n$$\n$$\n\\ell_0(\\sigma^2) = C_0 - \\frac{n}{2}\\log(\\sigma^2) - \\frac{1}{2\\sigma^2} \\sum_{i=0}^{n-1} \\frac{(\\Delta Y_i)^2}{\\Delta t_i}\n$$\nwhere $C_0$ is a constant that does not depend on $\\sigma^2$. To find the maximum likelihood estimate (MLE) of $\\sigma^2$, we differentiate $\\ell_0$ with respect to $\\sigma^2$ and set the result to zero:\n$$\n\\frac{\\partial \\ell_0}{\\partial (\\sigma^2)} = -\\frac{n}{2\\sigma^2} + \\frac{1}{2(\\sigma^2)^2} \\sum_{i=0}^{n-1} \\frac{(\\Delta Y_i)^2}{\\Delta t_i} = 0\n$$\nSolving for $\\sigma^2$ gives the MLE, which we denote as $\\hat{\\sigma}^2_0$:\n$$\n\\hat{\\sigma}^2_0 = \\frac{1}{n} \\sum_{i=0}^{n-1} \\frac{(\\Delta Y_i)^2}{\\Delta t_i}\n$$\nSubstituting this estimate back into the log-likelihood function yields the maximized log-likelihood under the null model, $\\hat{\\ell}_0$:\n$$\n\\hat{\\ell}_0 = \\ell_0(\\hat{\\sigma}^2_0) = C_0 - \\frac{n}{2}\\log(\\hat{\\sigma}^2_0) - \\frac{1}{2\\hat{\\sigma}^2_0} (n\\hat{\\sigma}^2_0) = C_0 - \\frac{n}{2}\\log(\\hat{\\sigma}^2_0) - \\frac{n}{2}\n$$\n\n**2. Alternative Model ($M_1$): Single Punctuated Increase**\n\nThe alternative model posits a single, non-negative jump $J \\ge 0$ occurring in exactly one interval, say between $t_j$ and $t_{j+1}$. For this interval, the increment $\\Delta Y_j$ is distributed as $\\mathcal{N}(J, \\sigma^2 \\Delta t_j)$. All other increments $\\Delta Y_i$ (for $i \\neq j$) retain their null distribution $\\mathcal{N}(0, \\sigma^2 \\Delta t_i)$.\n\nFor a fixed jump location $j$, the log-likelihood function $\\ell_{1,j}(J, \\sigma^2)$ is:\n$$\n\\ell_{1,j}(J, \\sigma^2) = \\log p(\\Delta Y_j|J, \\sigma^2) + \\sum_{i \\neq j} \\log p(\\Delta Y_i|0, \\sigma^2)\n$$\n$$\n\\ell_{1,j}(J, \\sigma^2) = C_1 - \\frac{n}{2}\\log(\\sigma^2) - \\frac{1}{2\\sigma^2}\\left( \\frac{(\\Delta Y_j - J)^2}{\\Delta t_j} + \\sum_{i \\neq j} \\frac{(\\Delta Y_i)^2}{\\Delta t_i} \\right)\n$$\nWe must find the joint MLEs for $J$ and $\\sigma^2$. For a fixed $\\sigma^2$, we maximize $\\ell_{1,j}$ by minimizing the term $(\\Delta Y_j - J)^2$, subject to the constraint $J \\ge 0$. The unconstrained minimizer is $J = \\Delta Y_j$. With the non-negativity constraint, the MLE for $J$ is:\n$$\n\\hat{J}_j = \\max(0, \\Delta Y_j)\n$$\nSubstituting $\\hat{J}_j$ into $\\ell_{1,j}$, we then maximize with respect to $\\sigma^2$. Differentiating with respect to $\\sigma^2$ and setting to zero yields:\n$$\n\\hat{\\sigma}^2_{1,j} = \\frac{1}{n} \\left( \\frac{(\\Delta Y_j - \\hat{J}_j)^2}{\\Delta t_j} + \\sum_{i \\neq j} \\frac{(\\Delta Y_i)^2}{\\Delta t_i} \\right)\n$$\nWe analyze two cases for $\\hat{J}_j$:\n- If $\\Delta Y_j \\le 0$, then $\\hat{J}_j = 0$. The estimate for $\\sigma^2$ becomes $\\hat{\\sigma}^2_{1,j} = \\frac{1}{n} \\sum_{i=0}^{n-1} \\frac{(\\Delta Y_i)^2}{\\Delta t_i} = \\hat{\\sigma}^2_0$. The model is identical to the null model.\n- If $\\Delta Y_j > 0$, then $\\hat{J}_j = \\Delta Y_j$. The term $(\\Delta Y_j - \\hat{J}_j)^2$ becomes $0$. The variance estimate is $\\hat{\\sigma}^2_{1,j} = \\frac{1}{n} \\sum_{i \\neq j} \\frac{(\\Delta Y_i)^2}{\\Delta t_i}$. This can be written in terms of $\\hat{\\sigma}^2_0$ as $\\hat{\\sigma}^2_{1,j} = \\hat{\\sigma}^2_0 - \\frac{1}{n}\\frac{(\\Delta Y_j)^2}{\\Delta t_j}$.\n\nThe jump location $j$ is unknown. We select the location $j^*$ that maximizes the likelihood. This is equivalent to minimizing the estimated variance $\\hat{\\sigma}^2_{1,j}$. The reduction in variance from the null estimate only occurs for intervals where $\\Delta Y_j > 0$. The minimal $\\hat{\\sigma}^2_{1,j}$ is achieved by choosing the index $j^*$ that maximizes the term $\\frac{(\\Delta Y_j)^2}{\\Delta t_j}$ among all $j$ where $\\Delta Y_j > 0$. If no such $j$ exists, the alternative model offers no improvement over the null model.\n\nLet $\\hat{\\sigma}^2_1$ be the variance estimate for the best alternative model (at location $j^*$). The maximized log-likelihood is:\n$$\n\\hat{\\ell}_1 = C_1 - \\frac{n}{2}\\log(\\hat{\\sigma}^2_1) - \\frac{n}{2}\n$$\n\n**3. Model Selection via Bayesian Information Criterion (BIC)**\n\nWe use the BIC to compare the null model $M_0$ and the best single-jump model $M_1$. The BIC is defined as $\\mathrm{BIC} = -2\\hat{\\ell} + k \\log m$, where $\\hat{\\ell}$ is the maximized log-likelihood, $k$ is the number of free parameters, and $m=n$ is the number of data points (increments).\n\n- For the null model $M_0$, there is one parameter $(\\sigma^2)$, so $k_0 = 1$.\n$$\n\\mathrm{BIC}_0 = -2\\hat{\\ell}_0 + k_0 \\log(n)\n$$\n- For the single-jump model $M_1$, we are instructed to count three parameters $(\\sigma^2, J, \\text{and the jump location})$, so $k_1 = 3$.\n$$\n\\mathrm{BIC}_1 = -2\\hat{\\ell}_1 + k_1 \\log(n)\n$$\nEvidence for a punctuated increase is found if $\\mathrm{BIC}_1 < \\mathrm{BIC}_0$. Substituting the expressions for $\\hat{\\ell}_0$ and $\\hat{\\ell}_1$ (and noting that the constants $C_0, C_1$ are identical), the inequality becomes:\n$$\n-2\\left(C - \\frac{n}{2}\\log(\\hat{\\sigma}^2_1) - \\frac{n}{2}\\right) + 3\\log(n) < -2\\left(C - \\frac{n}{2}\\log(\\hat{\\sigma}^2_0) - \\frac{n}{2}\\right) + 1\\log(n)\n$$\n$$\nn\\log(\\hat{\\sigma}^2_1) + n + 3\\log(n) < n\\log(\\hat{\\sigma}^2_0) + n + 1\\log(n)\n$$\n$$\nn\\log(\\hat{\\sigma}^2_1) - n\\log(\\hat{\\sigma}^2_0) < 1\\log(n) - 3\\log(n)\n$$\n$$\nn\\log\\left(\\frac{\\hat{\\sigma}^2_1}{\\hat{\\sigma}^2_0}\\right) < -2\\log(n)\n$$\nThis inequality provides the decision rule for the implementation. If all increments $\\Delta Y_i$ are non-positive, then $\\hat{\\sigma}^2_1 = \\hat{\\sigma}^2_0$. The left side is $0$, while the right side is negative (for $n>1$), so the inequality does not hold. A punctuated increase is only supported if at least one positive increment exists that is large enough to justify the additional model complexity.\n\nThe algorithm is as follows:\n1.  Compute increments $\\Delta Y_i$ and $\\Delta t_i$. Let $n$ be the number of increments.\n2.  Calculate $\\hat{\\sigma}^2_0 = \\frac{1}{n} \\sum_{i=0}^{n-1} (\\Delta Y_i)^2 / \\Delta t_i$.\n3.  Identify indices $j$ where $\\Delta Y_j > 0$. If none exist, the null model is preferred (result is False).\n4.  If such indices exist, find $j^*$ that maximizes $Q_j = (\\Delta Y_j)^2 / \\Delta t_j$.\n5.  Calculate $\\hat{\\sigma}^2_1 = \\hat{\\sigma}^2_0 - \\frac{1}{n} Q_{j^*}$.\n6.  Evaluate the condition $n\\log(\\hat{\\sigma}^2_1 / \\hat{\\sigma}^2_0) < -2\\log(n)$. If true, a punctuated increase is supported.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the problem of detecting punctuated increases in C-value evolution\n    using a model comparison framework based on Brownian motion and BIC.\n    \"\"\"\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # Case A (null-like, no strong evidence expected)\n        (\n            [0.0, 10.0, 20.0, 40.0, 80.0],\n            [1.1, 1.08, 1.12, 1.10, 1.15]\n        ),\n        # Case B (contains a clear punctuated increase)\n        (\n            [0.0, 10.0, 20.0, 40.0, 80.0],\n            [1.0, 1.02, 1.01, 1.41, 1.44]\n        ),\n        # Case C (contains a large negative change but no punctuated increase)\n        (\n            [0.0, 10.0, 20.0, 40.0, 80.0],\n            [1.2, 1.15, 1.10, 1.09, 1.08]\n        ),\n        # Case D (irregular sampling, but no punctuated increase)\n        (\n            [0.0, 0.001, 1.001, 2.001, 5.001],\n            [0.0, -0.001, 0.0, 0.01, 0.005]\n        ),\n    ]\n\n    results = []\n    for times, log_c_values in test_cases:\n        # Convert to numpy arrays for vectorized operations\n        times_arr = np.array(times, dtype=float)\n        values_arr = np.array(log_c_values, dtype=float)\n\n        # 1. Calculate increments\n        delta_t = np.diff(times_arr)\n        delta_y = np.diff(values_arr)\n        \n        # n is the number of increments\n        n = len(delta_t)\n        \n        # Handle cases with insufficient data for comparison\n        if n <= 1:\n            results.append(False)\n            continue\n\n        # 2. Calculate MLE of sigma^2 under the null model (M0)\n        # Avoid division by zero if any delta_t is zero.\n        if np.any(delta_t <= 0):\n            # This case represents an invalid time series; model cannot be fit.\n            # As per robust implementation, we would flag this as an error.\n            # In context of the problem, we can assume delta_t > 0.\n            # For this implementation's safety, return False.\n            results.append(False)\n            continue\n            \n        scaled_sq_increments = (delta_y**2) / delta_t\n        sigma_sq_0 = np.sum(scaled_sq_increments) / n\n        \n        # If variance is zero, the data is constant (scaled by time). Null model is perfect.\n        if sigma_sq_0 <= 0:\n            results.append(False)\n            continue\n\n        # 3. Find the best alternative model (M1)\n        # We only consider positive jumps, so we look at positive increments delta_y > 0.\n        positive_increment_indices = np.where(delta_y > 0)[0]\n\n        if len(positive_increment_indices) == 0:\n            # If there are no positive increments, the alternative model cannot explain\n            # a positive jump and provides no improvement over the null model.\n            # BIC_1 will be greater than BIC_0 due to the higher parameter penalty.\n            results.append(False)\n            continue\n        \n        # 4. Find the best jump location j*\n        # The best jump location j* maximizes the term (delta_y[j]^2 / delta_t[j])\n        q_values = (delta_y[positive_increment_indices]**2) / delta_t[positive_increment_indices]\n        max_q = np.max(q_values)\n\n        # 5. Calculate MLE of sigma^2 under the best alternative model\n        sigma_sq_1 = sigma_sq_0 - (max_q / n)\n        \n        # If sigma_sq_1 is non-positive, it implies a degenerate model or floating point issue.\n        # Under the derivation, sigma_sq_1 >= 0. Log of non-positive number is undefined.\n        if sigma_sq_1 <= 0:\n             results.append(True) # This signifies an extreme fit improvement.\n             continue\n        \n        # 6. Compare models using the BIC-derived inequality\n        # The condition for supporting the alternative model is:\n        # n * log(sigma_sq_1 / sigma_sq_0) < -2 * log(n)\n        \n        log_n = np.log(n)\n        log_ratio = np.log(sigma_sq_1 / sigma_sq_0)\n        \n        is_supported = n * log_ratio < -2 * log_n\n        results.append(is_supported)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "2756951"}]}