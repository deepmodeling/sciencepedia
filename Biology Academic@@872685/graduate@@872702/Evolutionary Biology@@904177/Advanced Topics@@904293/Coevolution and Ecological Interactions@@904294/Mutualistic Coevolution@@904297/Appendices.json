{"hands_on_practices": [{"introduction": "The essence of any mutualistic interaction is a trade-off between the costs of investing in a partner and the benefits received in return. To understand when natural selection will favor such cooperation, we must first determine the point at which the interaction becomes profitable. This practice problem [@problem_id:2738843] provides a foundational exercise in this type of cost-benefit analysis, asking you to calculate the threshold of investment where a hypothetical interaction transitions from being costly or neutral to truly mutualistic.", "problem": "Consider a pairwise interaction between two species engaged in mutualistic coevolution, where the intensity of investment by one focal species is represented by a nonnegative trait $\\rho \\ge 0$. In a continuous-time demographic model, let the per-capita Malthusian fitness of the focal species be written as $m(\\rho) = m_{0} + \\Delta m(\\rho)$, where $m_{0}$ is the baseline per-capita growth rate in the absence of interaction and $\\Delta m(\\rho)$ is the contribution of the interaction to per-capita growth. Assume the contribution decomposes additively into a benefit and a cost, $\\Delta m(\\rho) = B(\\rho) - C(\\rho)$, where $B(\\rho)$ is the per-capita benefit gained from the partner and $C(\\rho)$ is the per-capita cost of investment into the interaction. The interaction is said to be net mutualistic for the focal species at trait value $\\rho$ if $\\Delta m(\\rho)  0$; the threshold $\\rho^{*}$ is defined as the smallest $\\rho \\ge 0$ at which the net effect transitions from nonpositive to positive.\n\nSuppose that the benefit function saturates with investment according to $B(\\rho) = \\dfrac{\\rho}{1+\\rho}$ and the cost is constant, $C(\\rho) = 0.3$. Compute the exact value of the threshold $\\rho^{*}$ at which the interaction becomes net mutualistic for the focal species. Express your answer in exact form (no decimal approximation).", "solution": "The problem statement is first validated for scientific soundness and consistency. The model presented is a standard formulation in evolutionary biology for analyzing trade-offs in mutualistic interactions. The per-capita fitness $m(\\rho)$ is defined as a sum of a baseline fitness $m_{0}$ and a fitness contribution from the interaction, $\\Delta m(\\rho)$. The interaction's contribution is modeled as a net effect of a saturating benefit function $B(\\rho)$ and a constant cost function $C(\\rho)$. These are common and biologically plausible assumptions for such a model. The question asks for a specific threshold value $\\rho^{*}$ based on a clear, mathematically formalizable condition. All necessary information is provided, and there are no contradictions. The problem is well-posed and scientifically grounded. Therefore, it is valid, and a solution can be derived.\n\nThe problem asks for the threshold value of the investment trait, $\\rho^{*}$, which is defined as the smallest value of $\\rho \\ge 0$ at which the net effect of the interaction, $\\Delta m(\\rho)$, transitions from being nonpositive to positive. The net effect is given by the difference between the benefit and cost functions:\n$$ \\Delta m(\\rho) = B(\\rho) - C(\\rho) $$\nThe given functions are $B(\\rho) = \\dfrac{\\rho}{1+\\rho}$ and a constant cost $C(\\rho) = 0.3$.\nThus, the net effect on fitness is:\n$$ \\Delta m(\\rho) = \\frac{\\rho}{1+\\rho} - 0.3 $$\nThe transition from a nonpositive to a positive net effect occurs at the point where the net effect is exactly zero. We therefore seek the value $\\rho^{*}$ that satisfies the equation $\\Delta m(\\rho^{*}) = 0$.\n$$ \\frac{\\rho^{*}}{1+\\rho^{*}} - 0.3 = 0 $$\nTo solve for $\\rho^{*}$, we first isolate the term containing the variable:\n$$ \\frac{\\rho^{*}}{1+\\rho^{*}} = 0.3 $$\nThe problem defines the trait $\\rho$ as non-negative, so $\\rho \\ge 0$. This implies that the denominator $1+\\rho^{*}$ is strictly positive (since $1+\\rho^{*} \\ge 1$). We can safely multiply both sides of the equation by $1+\\rho^{*}$:\n$$ \\rho^{*} = 0.3 (1+\\rho^{*}) $$\nExpanding the right-hand side gives:\n$$ \\rho^{*} = 0.3 + 0.3\\rho^{*} $$\nNow, we collect all terms involving $\\rho^{*}$ on one side of the equation to solve for it.\n$$ \\rho^{*} - 0.3\\rho^{*} = 0.3 $$\nFactoring out $\\rho^{*}$ on the left-hand side:\n$$ (1 - 0.3)\\rho^{*} = 0.3 $$\n$$ 0.7\\rho^{*} = 0.3 $$\nSolving for $\\rho^{*}$:\n$$ \\rho^{*} = \\frac{0.3}{0.7} $$\nTo express this value as an exact fraction of integers, we multiply the numerator and the denominator by $10$:\n$$ \\rho^{*} = \\frac{3}{7} $$\nThis value is positive, which is consistent with the domain $\\rho \\ge 0$. To rigorously verify that this is the correct threshold, we analyze the behavior of $\\Delta m(\\rho)$. At $\\rho = 0$, the net benefit is $\\Delta m(0) = \\frac{0}{1+0} - 0.3 = -0.3$, which is nonpositive. The derivative of the net benefit function with respect to $\\rho$ is:\n$$ \\frac{d}{d\\rho} \\Delta m(\\rho) = \\frac{d}{d\\rho} \\left( \\frac{\\rho}{1+\\rho} - 0.3 \\right) = \\frac{(1)(1+\\rho) - (\\rho)(1)}{(1+\\rho)^{2}} = \\frac{1}{(1+\\rho)^{2}} $$\nFor any $\\rho \\ge 0$, this derivative is strictly positive. This indicates that $\\Delta m(\\rho)$ is a monotonically increasing function of $\\rho$. Since $\\Delta m(\\rho)$ starts at a negative value at $\\rho=0$ and increases monotonically, it will cross zero exactly once for $\\rho  0$. This occurs at $\\rho^{*} = \\frac{3}{7}$. For all $\\rho$ in the interval $[0, \\frac{3}{7})$, the value of $\\Delta m(\\rho)$ is less than $0$. At $\\rho = \\frac{3}{7}$, $\\Delta m(\\rho)=0$. For all $\\rho  \\frac{3}{7}$, $\\Delta m(\\rho)  0$. Consequently, $\\rho^{*} = \\frac{3}{7}$ is the smallest non-negative value at which the net effect of the interaction transitions from nonpositive to positive.", "answer": "$$ \\boxed{\\frac{3}{7}} $$", "id": "2738843"}, {"introduction": "Mutualistic benefits at the individual level have profound consequences for population dynamics, potentially allowing populations to surpass their solitary carrying capacities. However, this raises a classic question in theoretical ecology: what keeps mutualism from destabilizing ecosystems through runaway population growth? This exercise [@problem_id:2738742] uses a standard Lotka-Volterra model to explore this issue, guiding you to derive the equilibrium population densities and the critical stability condition that ensures a bounded, ecologically plausible outcome.", "problem": "Consider two mutualistic partners, species $A$ and $B$, whose ecological population dynamics operate on a faster timescale than the evolution of their interaction traits. Let the per-capita growth of each species follow density dependence (logistic regulation) and be increased by the partner’s density through a linear mutualistic effect, a widely used baseline in theoretical ecology for weak mutualism. Denote abundances by $N_A$ and $N_B$, intrinsic rates by $r_A$ and $r_B$, carrying capacities by $K_A$ and $K_B$, and per-capita mutualistic interaction coefficients by $a$ (effect of $B$ on $A$) and $b$ (effect of $A$ on $B$). The coupled ordinary differential equations (ODEs) are\n$$\n\\frac{dN_A}{dt} \\;=\\; r_A\\,N_A\\left(1 - \\frac{N_A}{K_A} + a\\,N_B\\right), \n\\qquad\n\\frac{dN_B}{dt} \\;=\\; r_B\\,N_B\\left(1 - \\frac{N_B}{K_B} + b\\,N_A\\right).\n$$\nStarting from the definition of equilibrium in deterministic population dynamics and the structure of density-dependent and mutualistic contributions in the above system, analytically derive the interior equilibrium $(N_A^{*},N_B^{*})$ (with both components strictly positive) in terms of $K_A$, $K_B$, $a$, and $b$, and state the parameter condition under which this equilibrium is feasible (positive and finite) for the linear mutualism case. Then, evaluate your expression at $r_A=r_B=1$, $K_A=K_B=100$, and $a=b=0.005$, and compute the numerical value of $(N_A^{*},N_B^{*})$. Finally, determine whether the equilibrium you found is biologically plausible in the sense of being bounded (no runaway growth) and positive under the linear mutualism assumption. Report the equilibrium abundances as absolute numbers of individuals. No rounding is necessary for this parameter set.", "solution": "The problem presented is a standard exercise in theoretical population dynamics. It is scientifically grounded, well-posed, and objective. It describes a classic Lotka-Volterra model for two mutualistic species with linear interaction terms and logistic self-regulation. The task is to find the interior equilibrium, determine the conditions for its feasibility, and calculate its value for a given set of parameters. All components of the problem are standard and formalizable. I will proceed with the solution.\n\nThe population dynamics are governed by the coupled ordinary differential equations:\n$$\n\\frac{dN_A}{dt} = r_A N_A\\left(1 - \\frac{N_A}{K_A} + a N_B\\right)\n$$\n$$\n\\frac{dN_B}{dt} = r_B N_B\\left(1 - \\frac{N_B}{K_B} + b N_A\\right)\n$$\nEquilibrium, denoted by $(N_A^{*}, N_B^{*})$, is defined as the state where population abundances do not change over time. Mathematically, this corresponds to the condition where the time derivatives are zero:\n$$\n\\frac{dN_A}{dt} = 0 \\quad \\text{and} \\quad \\frac{dN_B}{dt} = 0\n$$\nThis system has trivial and semi-trivial equilibria at $(0,0)$, $(K_A, 0)$, and $(0, K_B)$. We are tasked with finding the interior equilibrium, for which both $N_A^{*}  0$ and $N_B^{*}  0$. For this to be true, the expressions within the parentheses must equal zero, as $r_A, r_B, N_A, N_B$ are all positive. This yields a system of two linear equations for the equilibrium abundances $N_A^{*}$ and $N_B^{*}$:\n$$\n1 - \\frac{N_A^{*}}{K_A} + a N_B^{*} = 0\n$$\n$$\n1 - \\frac{N_B^{*}}{K_B} + b N_A^{*} = 0\n$$\nThese are the equations for the zero-growth isoclines for species $A$ and $B$, respectively. To solve for $(N_A^{*}, N_B^{*})$, we can rearrange this system:\n$$\n\\frac{1}{K_A} N_A^{*} - a N_B^{*} = 1\n$$\n$$\n-b N_A^{*} + \\frac{1}{K_B} N_B^{*} = 1\n$$\nWe can solve this system using various methods. Using substitution, from the second equation we express $N_B^{*}$ in terms of $N_A^{*}$:\n$$\n\\frac{1}{K_B} N_B^{*} = 1 + b N_A^{*} \\implies N_B^{*} = K_B (1 + b N_A^{*})\n$$\nSubstitute this expression for $N_B^{*}$ into the first rearranged equation:\n$$\n\\frac{1}{K_A} N_A^{*} - a [K_B (1 + b N_A^{*})] = 1\n$$\n$$\n\\frac{1}{K_A} N_A^{*} - a K_B - a b K_B N_A^{*} = 1\n$$\nNow, we group terms containing $N_A^{*}$:\n$$\nN_A^{*} \\left(\\frac{1}{K_A} - a b K_B\\right) = 1 + a K_B\n$$\n$$\nN_A^{*} \\left(\\frac{1 - a b K_A K_B}{K_A}\\right) = 1 + a K_B\n$$\nSolving for $N_A^{*}$ yields:\n$$\nN_A^{*} = \\frac{K_A (1 + a K_B)}{1 - a b K_A K_B}\n$$\nBy symmetry of the original equations, the expression for $N_B^{*}$ can be obtained by swapping the indices $A$ and $B$ and the coefficients $a$ and $b$:\n$$\nN_B^{*} = \\frac{K_B (1 + b K_A)}{1 - a b K_A K_B}\n$$\nThe problem requires the condition for this equilibrium to be feasible, which means it must be positive ($N_A^{*}  0, N_B^{*}  0$) and finite.\nBy their biological definition, the parameters $K_A, K_B, a, b$ are all positive. Consequently, the numerators of the expressions for $N_A^{*}$ and $N_B^{*}$ are always positive: $K_A (1 + a K_B)  0$ and $K_B (1 + b K_A)  0$.\nThe positivity and finiteness of the equilibrium therefore depend entirely on the shared denominator, $1 - a b K_A K_B$. For the equilibrium to be positive and well-defined (not infinite), the denominator must be strictly positive:\n$$\n1 - a b K_A K_B  0\n$$\nThis leads to the critical condition for a stable, bounded mutualism in this model:\n$$\na b K_A K_B  1\n$$\nIf this condition is violated ($a b K_A K_B \\ge 1$), the mutualistic feedback is too strong for the intraspecific competition to regulate the populations, leading to unbounded growth. The problem refers to this as \"runaway growth,\" which makes the equilibrium biologically implausible. Therefore, the condition $a b K_A K_B  1$ is the condition for a plausible, bounded, positive equilibrium.\n\nNext, we evaluate the equilibrium abundances for the given set of parameters: $r_A=1$, $r_B=1$, $K_A=100$, $K_B=100$, $a=0.005$, and $b=0.005$. The intrinsic growth rates $r_A$ and $r_B$ do not affect the equilibrium values, only the timescale of approach to it.\nFirst, we check the feasibility condition:\n$$\na b K_A K_B = (0.005)(0.005)(100)(100) = (25 \\times 10^{-6})(1 \\times 10^4) = 25 \\times 10^{-2} = 0.25\n$$\nSince $0.25  1$, the condition is satisfied, and a feasible, biologically plausible equilibrium exists.\nNow we compute the numerical values of $N_A^{*}$ and $N_B^{*}$:\nDue to the symmetry in parameters ($K_A=K_B$ and $a=b$), we expect $N_A^{*} = N_B^{*}$. We calculate $N_A^{*}$:\n$$\nN_A^{*} = \\frac{K_A (1 + a K_B)}{1 - a b K_A K_B} = \\frac{100 (1 + (0.005)(100))}{1 - 0.25}\n$$\n$$\nN_A^{*} = \\frac{100 (1 + 0.5)}{0.75} = \\frac{100(1.5)}{0.75} = \\frac{150}{0.75} = \\frac{150}{3/4} = 150 \\times \\frac{4}{3} = 200\n$$\nAs expected due to symmetry, $N_B^{*}$ will have the same value:\n$$\nN_B^{*} = \\frac{K_B (1 + b K_A)}{1 - a b K_A K_B} = \\frac{100 (1 + (0.005)(100))}{1 - 0.25} = 200\n$$\nThe interior equilibrium is located at $(N_A^{*}, N_B^{*}) = (200, 200)$. These values are positive and finite, confirming the equilibrium is biologically plausible under the model's assumptions for the given parameters. The presence of mutualism has allowed both populations to exceed their individual carrying capacities.", "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n200  200\n\\end{pmatrix}\n}\n$$", "id": "2738742"}, {"introduction": "Coevolutionary dynamics are driven by reciprocal selection, where traits in one species exert selective pressure on traits in another. Moving from this theoretical concept to a quantitative measurement requires a robust statistical framework. This hands-on problem [@problem_id:2738886] introduces you to the Lande-Arnold methodology, a cornerstone of modern evolutionary biology, by tasking you with calculating reciprocal selection gradients from phenotypic and fitness data using ordinary least squares regression.", "problem": "You are given paired observations from two mutualist species that interact one-to-one. For each pair, you observe standardized traits and relative fitness. In the framework of Lande–Arnold selection analysis, the directional selection gradients are the partial regression coefficients obtained by regressing relative fitness on standardized traits using Ordinary Least Squares (OLS). In mutualistic coevolution, reciprocal selection is quantified by the cross-partner selection gradients: the effect of species B’s trait on species A’s fitness, and vice versa. Your task is to compute these partial regression coefficients for several datasets and report the magnitudes of reciprocal selection as the absolute values of the cross-partner coefficients.\n\nFundamental base and assumptions:\n- Traits are standardized to mean $0$ and standard deviation $1$ across observations, using the sample standard deviation (dividing by $n-1$).\n- Relative fitness is scaled to have mean $1$ (standard relative fitness).\n- Directional selection gradients are defined as the partial regression coefficients from multiple regression of relative fitness on the set of standardized traits, with an intercept.\n- Ordinary Least Squares (OLS) provides the unique coefficients $\\hat{\\boldsymbol{\\beta}}$ that minimize the sum of squared residuals, obtained by solving the normal equations, consistent with the Gauss–Markov assumptions for linear models.\n\nMathematical formalization:\n- For species A, regress $w_A$ on an intercept and the vector of traits $[z_A, z_B]$ to obtain coefficients $[\\alpha_A, \\beta_{AA}, \\beta_{AB}]$. The reciprocal selection of B on A is quantified by $\\beta_{AB}$.\n- For species B, regress $w_B$ on an intercept and the vector of traits $[z_A, z_B]$ to obtain coefficients $[\\alpha_B, \\beta_{BA}, \\beta_{BB}]$. The reciprocal selection of A on B is quantified by $\\beta_{BA}$.\n- Use OLS with the design matrix $X = [\\mathbf{1}, z_A, z_B]$, which is a matrix with a column of ones and the two trait columns, and with response vectors $w_A$ or $w_B$.\n\nComputation requirements:\n- For each dataset below, compute the OLS coefficients for both regressions (for $w_A$ and $w_B$). Extract the cross-partner coefficients $\\beta_{AB}$ and $\\beta_{BA}$. Report the signed values and interpret magnitudes of reciprocal selection as the absolute values $|\\beta_{AB}|$ and $|\\beta_{BA}|$.\n- Round all reported numbers to $4$ decimal places.\n\nTest suite (each dataset provides trait vectors explicitly; fitness is generated deterministically from the given linear model so that OLS recovers the true coefficients):\n- Dataset $1$ (general positive reciprocal selection):\n  - $z_A = [-1, 0, 1]$\n  - $z_B = [-1, 1, 0]$\n  - $w_A = 1 + 0.4\\, z_B + 0.1\\, z_A$\n  - $w_B = 1 + 0.5\\, z_A + 0.05\\, z_B$\n- Dataset $2$ (boundary case: zero reciprocal selection):\n  - $z_A = [-1, 0, 1]$\n  - $z_B = [0, 1, -1]$\n  - $w_A = 1 + 0.3\\, z_A$\n  - $w_B = 1 - 0.2\\, z_B$\n- Dataset $3$ (negative reciprocal selection):\n  - $z_A = [-1, 0, 1]$\n  - $z_B = [1, -1, 0]$\n  - $w_A = 1 - 0.35\\, z_B + 0.05\\, z_A$\n  - $w_B = 1 - 0.25\\, z_A + 0.02\\, z_B$\n- Dataset $4$ (pure reciprocal selection: only cross effects):\n  - $z_A = [-1, 0, 1]$\n  - $z_B = [0, -1, 1]$\n  - $w_A = 1 + 0.6\\, z_B$\n  - $w_B = 1 + 0.6\\, z_A$\n\nFinal output specification:\n- For each dataset $i$, produce the pair $[\\beta_{AB}^{(i)}, \\beta_{BA}^{(i)}]$ rounded to $4$ decimals.\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, where each element is the two-element list for one dataset, for example: $[[x_1,y_1],[x_2,y_2],\\dots]$.\n- No units are involved, and all angles or percentages are irrelevant to this task.\n\nYour program must be a complete, runnable script that performs these computations with OLS and prints the final line exactly in the specified format. Do not read from input; compute directly from the provided datasets.", "solution": "The problem statement has been subjected to rigorous validation and is found to be scientifically grounded, well-posed, and objective. It presents a clear computational task based on the established Lande-Arnold framework for analyzing natural selection. All necessary data and definitions are provided, and there are no internal contradictions or ambiguities. The problem is therefore deemed valid and a solution will be provided.\n\nThe objective is to compute the reciprocal selection gradients, $\\beta_{AB}$ and $\\beta_{BA}$, for four distinct datasets representing mutualistic interactions between two species, A and B. These gradients quantify the directional selection exerted by one species' trait on the other species' fitness. The specified methodology is Ordinary Least Squares (OLS) multiple regression.\n\nFor each species, we model its relative fitness, $w$, as a linear function of an intercept and the standardized traits of both species, $z_A$ and $z_B$. The model for species A is:\n$$\nw_A = \\alpha_A + \\beta_{AA} z_A + \\beta_{AB} z_B + \\epsilon_A\n$$\nAnd for species B:\n$$\nw_B = \\alpha_B + \\beta_{BA} z_A + \\beta_{BB} z_B + \\epsilon_B\n$$\nHere, the coefficients $\\beta_{AB}$ and $\\beta_{BA}$ are the cross-partner selection gradients of interest.\n\nThe OLS method provides a unique set of coefficient estimates, denoted by the vector $\\hat{\\boldsymbol{\\beta}}$, that minimizes the sum of squared residuals. These coefficients are found by solving the normal equations:\n$$\n(X^T X) \\hat{\\boldsymbol{\\beta}} = X^T \\mathbf{y}\n$$\nwhere $\\mathbf{y}$ is the vector of observed relative fitness values and $X$ is the design matrix. The solution is given by:\n$$\n\\hat{\\boldsymbol{\\beta}} = (X^T X)^{-1} X^T \\mathbf{y}\n$$\nprovided that the matrix $X^T X$ is invertible, which is true if the columns of $X$ are linearly independent.\n\nFor this problem, the observations for the traits $z_A$ and $z_B$ are given for $n$ pairs of individuals. The design matrix $X$ is constructed by augmenting the trait vectors with a column of ones for the intercept term. For $n$ observations, $X$ is an $n \\times 3$ matrix:\n$$\nX = [\\mathbf{1} \\quad \\mathbf{z}_A \\quad \\mathbf{z}_B] = \\begin{pmatrix} 1  z_{A,1}  z_{B,1} \\\\ 1  z_{A,2}  z_{B,2} \\\\ \\vdots  \\vdots  \\vdots \\\\ 1  z_{A,n}  z_{B,n} \\end{pmatrix}\n$$\nThe vector of estimated coefficients will be $\\hat{\\boldsymbol{\\beta}} = [\\hat{\\alpha}, \\hat{\\beta}_1, \\hat{\\beta}_2]^T$. When regressing $w_A$ on the traits, the resulting coefficients correspond to $[\\hat{\\alpha}_A, \\hat{\\beta}_{AA}, \\hat{\\beta}_{AB}]^T$. The reciprocal selection gradient is the third element, $\\beta_{AB}$. When regressing $w_B$, the coefficients correspond to $[\\hat{\\alpha}_B, \\hat{\\beta}_{BA}, \\hat{\\beta}_{BB}]^T$. The reciprocal selection gradient is the second element, $\\beta_{BA}$.\n\nThe problem states that the traits $z_A$ and $z_B$ are standardized to have a mean of $0$ and a sample standard deviation of $1$. The relative fitness values $w_A$ and $w_B$ are generated deterministically from the true linear models specified for each dataset. This implies the error terms $\\epsilon_A$ and $\\epsilon_B$ are zero. Consequently, OLS will recover the true coefficients exactly, free from sampling error.\n\nLet us demonstrate the calculation for Dataset $1$:\nGiven:\n$z_A = [-1, 0, 1]^T$\n$z_B = [-1, 1, 0]^T$\n$w_A = 1 + 0.1 z_A + 0.4 z_B$\n$w_B = 1 + 0.5 z_A + 0.05 z_B$\n\nFirst, we construct the design matrix $X$ and the response vectors $\\mathbf{y}_A$ and $\\mathbf{y}_B$.\n$$\nX = \\begin{pmatrix} 1  -1  -1 \\\\ 1  0  1 \\\\ 1  1  0 \\end{pmatrix}\n$$\n$$\n\\mathbf{y}_A = \\begin{pmatrix} 1 + 0.1(-1) + 0.4(-1) \\\\ 1 + 0.1(0) + 0.4(1) \\\\ 1 + 0.1(1) + 0.4(0) \\end{pmatrix} = \\begin{pmatrix} 0.5 \\\\ 1.4 \\\\ 1.1 \\end{pmatrix}\n$$\n$$\n\\mathbf{y}_B = \\begin{pmatrix} 1 + 0.5(-1) + 0.05(-1) \\\\ 1 + 0.5(0) + 0.05(1) \\\\ 1 + 0.5(1) + 0.05(0) \\end{pmatrix} = \\begin{pmatrix} 0.45 \\\\ 1.05 \\\\ 1.50 \\end{pmatrix}\n$$\nNext, we compute $X^T X$ and its inverse:\n$$\nX^T X = \\begin{pmatrix} 1  1  1 \\\\ -1  0  1 \\\\ -1  1  0 \\end{pmatrix} \\begin{pmatrix} 1  -1  -1 \\\\ 1  0  1 \\\\ 1  1  0 \\end{pmatrix} = \\begin{pmatrix} 3  0  0 \\\\ 0  2  1 \\\\ 0  1  2 \\end{pmatrix}\n$$\n$$\n(X^T X)^{-1} = \\frac{1}{3(4-1)} \\begin{pmatrix} 3  0  0 \\\\ 0  6  -3 \\\\ 0  -3  6 \\end{pmatrix} = \\begin{pmatrix} 1/3  0  0 \\\\ 0  2/3  -1/3 \\\\ 0  -1/3  2/3 \\end{pmatrix}\n$$\nNow, we compute the coefficients for the regression of $w_A$:\n$$\nX^T \\mathbf{y}_A = \\begin{pmatrix} 1  1  1 \\\\ -1  0  1 \\\\ -1  1  0 \\end{pmatrix} \\begin{pmatrix} 0.5 \\\\ 1.4 \\\\ 1.1 \\end{pmatrix} = \\begin{pmatrix} 3.0 \\\\ 0.6 \\\\ 0.9 \\end{pmatrix}\n$$\n$$\n\\hat{\\boldsymbol{\\beta}}_A = (X^T X)^{-1} (X^T \\mathbf{y}_A) = \\begin{pmatrix} 1/3  0  0 \\\\ 0  2/3  -1/3 \\\\ 0  -1/3  2/3 \\end{pmatrix} \\begin{pmatrix} 3.0 \\\\ 0.6 \\\\ 0.9 \\end{pmatrix} = \\begin{pmatrix} 1.0 \\\\ 0.1 \\\\ 0.4 \\end{pmatrix}\n$$\nThe coefficients vector is $[\\hat{\\alpha}_A, \\hat{\\beta}_{AA}, \\hat{\\beta}_{AB}]^T = [1.0, 0.1, 0.4]^T$. Thus, $\\beta_{AB} = 0.4$.\n\nSimilarly, for the regression of $w_B$:\n$$\nX^T \\mathbf{y}_B = \\begin{pmatrix} 1  1  1 \\\\ -1  0  1 \\\\ -1  1  0 \\end{pmatrix} \\begin{pmatrix} 0.45 \\\\ 1.05 \\\\ 1.50 \\end{pmatrix} = \\begin{pmatrix} 3.0 \\\\ 1.05 \\\\ 0.6 \\end{pmatrix}\n$$\n$$\n\\hat{\\boldsymbol{\\beta}}_B = (X^T X)^{-1} (X^T \\mathbf{y}_B) = \\begin{pmatrix} 1/3  0  0 \\\\ 0  2/3  -1/3 \\\\ 0  -1/3  2/3 \\end{pmatrix} \\begin{pmatrix} 3.0 \\\\ 1.05 \\\\ 0.6 \\end{pmatrix} = \\begin{pmatrix} 1.0 \\\\ 0.5 \\\\ 0.05 \\end{pmatrix}\n$$\nThe coefficients vector is $[\\hat{\\alpha}_B, \\hat{\\beta}_{BA}, \\hat{\\beta}_{BB}]^T = [1.0, 0.5, 0.05]^T$. Thus, $\\beta_{BA} = 0.5$.\nThe pair of reciprocal selection gradients for Dataset $1$ is $[0.4, 0.5]$.\n\nThis exact procedure is systematically applied to all four specified datasets. The implementation will use numerical linear algebra routines to perform these calculations efficiently and accurately.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves for reciprocal selection gradients for four datasets using OLS regression.\n    \"\"\"\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        {\n            \"id\": 1,\n            \"z_A\": np.array([-1, 0, 1]),\n            \"z_B\": np.array([-1, 1, 0]),\n            \"w_A_coeffs\": {\"intercept\": 1, \"beta_AA\": 0.1, \"beta_AB\": 0.4},\n            \"w_B_coeffs\": {\"intercept\": 1, \"beta_BA\": 0.5, \"beta_BB\": 0.05},\n        },\n        {\n            \"id\": 2,\n            \"z_A\": np.array([-1, 0, 1]),\n            \"z_B\": np.array([0, 1, -1]),\n            \"w_A_coeffs\": {\"intercept\": 1, \"beta_AA\": 0.3, \"beta_AB\": 0.0},\n            \"w_B_coeffs\": {\"intercept\": 1, \"beta_BA\": 0.0, \"beta_BB\": -0.2},\n        },\n        {\n            \"id\": 3,\n            \"z_A\": np.array([-1, 0, 1]),\n            \"z_B\": np.array([1, -1, 0]),\n            \"w_A_coeffs\": {\"intercept\": 1, \"beta_AA\": 0.05, \"beta_AB\": -0.35},\n            \"w_B_coeffs\": {\"intercept\": 1, \"beta_BA\": -0.25, \"beta_BB\": 0.02},\n        },\n        {\n            \"id\": 4,\n            \"z_A\": np.array([-1, 0, 1]),\n            \"z_B\": np.array([0, -1, 1]),\n            \"w_A_coeffs\": {\"intercept\": 1, \"beta_AA\": 0.0, \"beta_AB\": 0.6},\n            \"w_B_coeffs\": {\"intercept\": 1, \"beta_BA\": 0.6, \"beta_BB\": 0.0},\n        },\n    ]\n\n    results = []\n    \n    for case in test_cases:\n        z_A = case[\"z_A\"]\n        z_B = case[\"z_B\"]\n        w_A_coeffs = case[\"w_A_coeffs\"]\n        w_B_coeffs = case[\"w_B_coeffs\"]\n        \n        # Generate fitness vectors deterministically\n        w_A = w_A_coeffs[\"intercept\"] + w_A_coeffs[\"beta_AA\"] * z_A + w_A_coeffs[\"beta_AB\"] * z_B\n        w_B = w_B_coeffs[\"intercept\"] + w_B_coeffs[\"beta_BA\"] * z_A + w_B_coeffs[\"beta_BB\"] * z_B\n\n        # Construct the design matrix X\n        # Column of 1s for the intercept, followed by trait columns\n        n = len(z_A)\n        X = np.stack([np.ones(n), z_A, z_B], axis=1)\n\n        # Solve the normal equations: (X'X)B = X'y => B = solve(X'X, X'y)\n        # This is more numerically stable than computing the inverse of X'X.\n        \n        # Regression for species A\n        # w_A = alpha_A + beta_AA * z_A + beta_AB * z_B\n        coeffs_A = np.linalg.solve(X.T @ X, X.T @ w_A)\n        beta_AB = coeffs_A[2]\n\n        # Regression for species B\n        # w_B = alpha_B + beta_BA * z_A + beta_BB * z_B\n        coeffs_B = np.linalg.solve(X.T @ X, X.T @ w_B)\n        beta_BA = coeffs_B[1]\n\n        # Round results to 4 decimal places\n        beta_AB_rounded = round(beta_AB, 4)\n        beta_BA_rounded = round(beta_BA, 4)\n        \n        results.append([beta_AB_rounded, beta_BA_rounded])\n\n    # Format the final output string as specified: [[x1,y1],[x2,y2],...]\n    # Using f-strings to format each inner list and join them.\n    # The format specifier ensure trailing zeros are shown, e.g., 0.4000\n    sub_results = [f'[{res[0]:.4f},{res[1]:.4f}]' for res in results]\n    final_output_string = f\"[{','.join(sub_results)}]\"\n    \n    # Final print statement in the exact required format.\n    print(final_output_string)\n\nsolve()\n```", "id": "2738886"}]}