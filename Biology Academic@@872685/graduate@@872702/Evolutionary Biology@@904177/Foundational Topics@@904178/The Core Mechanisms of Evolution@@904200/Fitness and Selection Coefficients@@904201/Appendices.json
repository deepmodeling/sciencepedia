{"hands_on_practices": [{"introduction": "The engine of natural selection is the differential survival and reproduction of genotypes. This foundational exercise allows you to apply the mathematical definition of Wrightian fitness to predict short-term evolutionary change in a simple haploid population. By calculating the shift in genotype frequencies and the resulting change in the population's mean fitness over a single generation, you will solidify your understanding of the core mechanics driving adaptation [@problem_id:2832271].", "problem": "A large, well-mixed, asexual haploid population consists of three genotypes, indexed by $i \\in \\{1,2,3\\}$. Each genotype $i$ has a constant Wrightian fitness $w_i$ that scales its expected contribution to the next generation in a single, discrete, non-overlapping generation life cycle with no mutation, migration, or genetic drift. At the start of generation $t$, the genotype frequency vector is $(p_1, p_2, p_3)$ with $p_1 + p_2 + p_3 = 1$. Selection acts via differential survival/reproduction so that the expected number of surviving offspring descending from genotype $i$ is proportional to $w_i$ times the number of genotype-$i$ parents. Let $\\bar{w}$ denote the population mean fitness (the average per-capita success across genotypes, weighted by current frequencies), and let $(p_1', p_2', p_3')$ denote the genotype frequencies at the start of generation $t+1$ after selection and normalization. \n\nIn a particular experiment, the three genotypes have fitnesses $w = (1.00, 1.05, 0.98)$ and initial frequencies $(p_1, p_2, p_3) = (0.5, 0.3, 0.2)$ at generation $t$. Starting strictly from the definitions above (that genotype contributions are proportional to $w_i$ and that frequencies must normalize to sum to $1$), compute the next-generation frequency vector $(p_1', p_2', p_3')$ and the next-generation mean fitness $\\bar{w}'$. \n\nReport your final numerical results as a single row vector $(p_1', p_2', p_3', \\bar{w}')$, with each entry rounded to four significant figures. Express the entries as plain decimals (no percentage signs). No other quantities should be reported.", "solution": "The problem presents a standard model of discrete-time population genetics for a haploid, asexual population. The task is to compute the genotype frequencies and the population mean fitness in the next generation, given the initial frequencies and fitness values for three genotypes. The problem statement is scientifically grounded, well-posed, and contains all necessary information. It is therefore valid.\n\nLet the population at generation $t$ be described by the frequency vector of the three genotypes, $\\boldsymbol{p} = (p_1, p_2, p_3)$, where $\\sum_{i=1}^{3} p_i = 1$. The corresponding Wrightian fitnesses are given by the vector $\\boldsymbol{w} = (w_1, w_2, w_3)$. The problem states that the expected contribution of each genotype to the subsequent generation is proportional to its fitness and current frequency.\n\nLet the total population size at the beginning of generation $t$ be $N$. The number of individuals of genotype $i$ is $N_i = p_i N$. The number of offspring produced by genotype $i$, let us denote it $N'_i$, is proportional to $w_i N_i$. Therefore, we can write $N'_i = C w_i N_i$ for some constant of proportionality $C$ that is identical for all genotypes.\n\nThe total number of individuals in the offspring generation, before normalization, is the sum over all genotypes:\n$$N' = \\sum_{i=1}^{3} N'_i = \\sum_{i=1}^{3} C w_i N_i = C \\sum_{i=1}^{3} w_i (p_i N) = C N \\sum_{i=1}^{3} w_i p_i$$\nThe frequency of genotype $i$ in the next generation, $p'_i$, is the ratio of the number of its offspring to the total number of offspring:\n$$p'_i = \\frac{N'_i}{N'} = \\frac{C w_i N_i}{\\sum_{j=1}^{3} C w_j N_j} = \\frac{w_i (p_i N)}{\\sum_{j=1}^{3} w_j (p_j N)}$$\nThe constants $C$ and $N$ cancel, yielding the fundamental recurrence relation:\n$$p'_i = \\frac{p_i w_i}{\\sum_{j=1}^{3} p_j w_j}$$\nThe denominator is the population mean fitness at generation $t$, defined as the weighted average of the individual fitnesses:\n$$\\bar{w} = \\sum_{i=1}^{3} p_i w_i$$\nThus, the frequency of genotype $i$ at generation $t+1$ is given by:\n$$p'_i = \\frac{p_i w_i}{\\bar{w}}$$\nThe given data for generation $t$ are:\n- Frequencies: $(p_1, p_2, p_3) = (0.5, 0.3, 0.2)$\n- Fitnesses: $(w_1, w_2, w_3) = (1.00, 1.05, 0.98)$\n\nFirst, we compute the mean fitness $\\bar{w}$ for generation $t$:\n$$\\bar{w} = p_1 w_1 + p_2 w_2 + p_3 w_3$$\n$$\\bar{w} = (0.5)(1.00) + (0.3)(1.05) + (0.2)(0.98) = 0.500 + 0.315 + 0.196 = 1.011$$\nNow we can compute the frequencies for the next generation, $(p'_1, p'_2, p'_3)$:\n$$p'_1 = \\frac{p_1 w_1}{\\bar{w}} = \\frac{(0.5)(1.00)}{1.011} = \\frac{0.500}{1.011} \\approx 0.4945598...$$\n$$p'_2 = \\frac{p_2 w_2}{\\bar{w}} = \\frac{(0.3)(1.05)}{1.011} = \\frac{0.315}{1.011} \\approx 0.3115727...$$\n$$p'_3 = \\frac{p_3 w_3}{\\bar{w}} = \\frac{(0.2)(0.98)}{1.011} = \\frac{0.196}{1.011} \\approx 0.1938674...$$\nThe problem requires these values to be rounded to four significant figures:\n- $p'_1 \\approx 0.4946$\n- $p'_2 \\approx 0.3116$\n- $p'_3 \\approx 0.1939$\n\nNext, we must compute the mean fitness of the population at generation $t+1$, denoted $\\bar{w}'$. This is calculated using the newly computed frequencies $(p'_1, p'_2, p'_3)$:\n$$\\bar{w}' = p'_1 w_1 + p'_2 w_2 + p'_3 w_3$$\nTo avoid propagation of rounding error, we should substitute the exact expressions for $p'_i$:\n$$\\bar{w}' = \\sum_{i=1}^{3} p'_i w_i = \\sum_{i=1}^{3} \\left(\\frac{p_i w_i}{\\bar{w}}\\right) w_i = \\frac{1}{\\bar{w}} \\sum_{i=1}^{3} p_i w_i^2$$\nWe first calculate the sum $\\sum_{i=1}^{3} p_i w_i^2$:\n$$\\sum_{i=1}^{3} p_i w_i^2 = (0.5)(1.00)^2 + (0.3)(1.05)^2 + (0.2)(0.98)^2$$\n$$\\sum_{i=1}^{3} p_i w_i^2 = (0.5)(1.0000) + (0.3)(1.1025) + (0.2)(0.9604)$$\n$$\\sum_{i=1}^{3} p_i w_i^2 = 0.50000 + 0.33075 + 0.19208 = 1.02283$$\nNow, we can find $\\bar{w}'$:\n$$\\bar{w}' = \\frac{1.02283}{1.011} \\approx 1.01170128...$$\nRounding to four significant figures gives:\n- $\\bar{w}' \\approx 1.012$\n\nThe final result is the row vector $(p'_1, p'_2, p'_3, \\bar{w}')$ with each entry rounded to four significant figures.", "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n0.4946  0.3116  0.1939  1.012\n\\end{pmatrix}\n}\n$$", "id": "2832271"}, {"introduction": "While selection provides direction, the ultimate fate of a new mutation is a stochastic contest against genetic drift, particularly when the allele is rare. This practice moves beyond one-generation deterministic predictions to explore the long-term probability of fixation, a cornerstone concept in population genetics. You will apply classical results from diffusion theory to quantify how an allele's dominance coefficient influences its chance of becoming fixed, providing a rigorous basis for the evolutionary principle known as Haldane's Sieve [@problem_id:2714135].", "problem": "A de novo beneficial allele $a$ arises as a single copy at frequency $x_0 = 1/(2N_e)$ in a randomly mating diploid Wright–Fisher population of effective population size $N_e$. Relative genotype fitnesses are $w_{AA} = 1$, $w_{Aa} = 1 + hs$, and $w_{aa} = 1 + s$, where $s > 0$ is small and $h \\in [0,1]$ is the dominance coefficient. Consider two cases in the outcrossing regime with no selfing: additive $(h = 1/2)$ and fully recessive $(h = 0)$. Work in the asymptotic regime $0  s \\ll 1$, $N_e \\gg 1$, and $N_e s \\gg 1$ so that diffusion and branching-process approximations are valid and leading-order terms can be isolated. Starting from core definitions of selection and drift under the Wright–Fisher model and the standard extinction/survival behavior of a slightly supercritical branching process, compare the fixation probabilities of the additive and fully recessive beneficial alleles. Which option correctly gives the leading-order asymptotic expressions for the fixation probabilities $u_{\\mathrm{add}}$ and $u_{\\mathrm{rec}}$, respectively, for a single de novo copy, and the corresponding asymptotic scaling of the ratio $u_{\\mathrm{add}}/u_{\\mathrm{rec}}$?\n\nA. $u_{\\mathrm{add}} \\approx s$, $u_{\\mathrm{rec}} \\approx \\sqrt{\\dfrac{2s}{\\pi N_e}}$, and $u_{\\mathrm{add}}/u_{\\mathrm{rec}} \\approx \\sqrt{\\dfrac{\\pi N_e s}{2}}$.\n\nB. $u_{\\mathrm{add}} \\approx 2s$, $u_{\\mathrm{rec}} \\approx 0$, and $u_{\\mathrm{add}}/u_{\\mathrm{rec}}$ diverges to $+\\infty$.\n\nC. $u_{\\mathrm{add}} \\approx s$, $u_{\\mathrm{rec}} \\approx \\dfrac{1}{2N_e}$, and $u_{\\mathrm{add}}/u_{\\mathrm{rec}} \\approx s N_e$.\n\nD. $u_{\\mathrm{add}} \\approx \\dfrac{s}{2}$, $u_{\\mathrm{rec}} \\approx s^2$, and $u_{\\mathrm{add}}/u_{\\mathrm{rec}} \\approx \\dfrac{1}{2s}$.\n\nSelect all correct statements. Your answer should encapsulate Haldane’s sieve: the systematic disadvantage of de novo beneficial recessives relative to additively beneficial alleles in outcrossing populations.", "solution": "The analysis begins with the validation of the problem statement.\n\n**Step 1: Extract Givens**\n-   Population Model: Diploid Wright–Fisher model, randomly mating, no selfing, effective population size $N_e$.\n-   Allele: A de novo beneficial allele $a$.\n-   Initial Condition: Single copy, corresponding to initial frequency $x_0 = 1/(2N_e)$.\n-   Genotype Fitnesses: $w_{AA} = 1$, $w_{Aa} = 1 + hs$, $w_{aa} = 1 + s$.\n-   Parameters: Selection coefficient $s > 0$, dominance coefficient $h \\in [0,1]$.\n-   Cases: Additive ($h = 1/2$) and fully recessive ($h = 0$).\n-   Asymptotic Regime: $0  s \\ll 1$, $N_e \\gg 1$, $N_e s \\gg 1$.\n-   Objective: Find leading-order asymptotic expressions for fixation probabilities $u_{\\mathrm{add}}$ and $u_{\\mathrm{rec}}$, and their ratio $u_{\\mathrm{add}}/u_{\\mathrm{rec}}$.\n\n**Step 2: Validate Using Extracted Givens**\nThe problem is scientifically grounded in the established principles of theoretical population genetics, specifically the Wright-Fisher model and diffusion theory. It is well-posed, providing all necessary parameters and conditions ($N_e, s, h, x_0$, and the asymptotic regime) to derive a unique solution for the fixation probabilities. The language is objective and precise. The problem is a standard, canonical exercise in calculating fixation probabilities under different dominance schemes and does not suffer from any of the flaws listed in the validation protocol.\n\n**Step 3: Verdict and Action**\nThe problem is valid. We proceed to the solution.\n\nThe derivation of the fixation probability, $u(p)$, for an allele with initial frequency $p$ is based on Kimura's diffusion theory. The general formula for the fixation probability is:\n$$ u(p) = \\frac{\\int_0^p G(x) dx}{\\int_0^1 G(x) dx} $$\nwhere $G(x) = \\exp\\left(-2 \\int_0^x \\frac{M(y)}{V(y)} dy\\right)$. Here, $M(y)$ is the expected change in allele frequency per generation due to selection, and $V(y)$ is the variance in allele frequency change per generation due to genetic drift.\n\nFor a diploid Wright-Fisher population of size $N_e$, these quantities are:\n-   $V(y) = \\frac{y(1-y)}{2N_e}$\n-   $M(y) = \\Delta y_{\\mathrm{sel}}$, the change in frequency from selection alone.\n\nThe mean fitness of the population is $\\bar{w} = (1-y)^2 w_{AA} + 2y(1-y)w_{Aa} + y^2 w_{aa} = 1 + 2y(1-y)hs + y^2 s$.\nThe change in allele frequency due to selection is given by $\\Delta y_{\\mathrm{sel}} = \\frac{y(1-y)}{2\\bar{w}} \\frac{d\\bar{w}}{dy}$.\nFor weak selection ($s \\ll 1$), $\\bar{w} \\approx 1$.\n$\\frac{d\\bar{w}}{dy} = 2(1-2y)hs + 2ys = 2(hs + (s-2hs)y)$.\nSo, $M(y) \\approx y(1-y)(hs + (s-2hs)y)$.\nThe ratio $\\frac{M(y)}{V(y)}$ is therefore:\n$$ \\frac{M(y)}{V(y)} = \\frac{y(1-y)(hs + (s-2hs)y)}{y(1-y)/(2N_e)} = 2N_e (hs + (s-2hs)y) $$\nThe function $G(x)$ is then:\n$$ G(x) = \\exp\\left(-2 \\int_0^x 2N_e (hs + (s-2hs)y) dy\\right) = \\exp\\left(-4N_e \\left(hsx + \\frac{s(1-2h)}{2}x^2\\right)\\right) $$\nWe now apply this general formula to the two specified cases. The initial frequency is $p = x_0 = 1/(2N_e)$.\n\n**Case 1: Additive Allele ($h = 1/2$)**\nFor the additive case, we set $h=1/2$. The term $s(1-2h)$ becomes $0$.\n$G(x) = \\exp\\left(-4N_e \\left(\\frac{s}{2}x\\right)\\right) = \\exp(-2N_e s x)$.\nThe fixation probability $u_{\\mathrm{add}}$ is:\n$$ u_{\\mathrm{add}} = \\frac{\\int_0^{1/(2N_e)} e^{-2N_e s x} dx}{\\int_0^1 e^{-2N_e s x} dx} $$\nEvaluating the integrals:\n$$ u_{\\mathrm{add}} = \\frac{\\left[\\frac{e^{-2N_e s x}}{-2N_e s}\\right]_0^{1/(2N_e)}}{\\left[\\frac{e^{-2N_e s x}}{-2N_e s}\\right]_0^1} = \\frac{1 - \\exp\\left(-2N_e s \\frac{1}{2N_e}\\right)}{1 - \\exp(-2N_e s)} = \\frac{1-e^{-s}}{1-e^{-2N_e s}} $$\nIn the specified asymptotic regime, $s \\ll 1$ and $N_e s \\gg 1$.\n-   The numerator, for $s \\ll 1$, is $1 - e^{-s} \\approx 1 - (1-s) = s$.\n-   The denominator, for $N_e s \\gg 1$, is $1 - e^{-2N_e s} \\approx 1$.\nThus, the leading-order expression for the fixation probability of an additive allele is:\n$$ u_{\\mathrm{add}} \\approx s $$\n\n**Case 2: Fully Recessive Allele ($h = 0$)**\nFor the fully recessive case, we set $h=0$.\n$G(x) = \\exp\\left(-4N_e \\left(0 \\cdot x + \\frac{s}{2}x^2\\right)\\right) = \\exp(-2N_e s x^2)$.\nThe fixation probability $u_{\\mathrm{rec}}$ is:\n$$ u_{\\mathrm{rec}} = \\frac{\\int_0^{1/(2N_e)} e^{-2N_e s x^2} dx}{\\int_0^1 e^{-2N_e s x^2} dx} $$\nFor the numerator, the integration is over a very small interval $[0, 1/(2N_e)]$. In this interval, the exponent $-2N_e s x^2$ is close to zero, so $e^{-2N_e s x^2} \\approx 1$.\n$$ \\text{Numerator} \\approx \\int_0^{1/(2N_e)} 1 \\, dx = \\frac{1}{2N_e} $$\nFor the denominator, we have the integral $\\int_0^1 \\exp(-2N_e s x^2) dx$. Let $a = 2N_e s$. The integral is $\\int_0^1 e^{-ax^2} dx$.\nWith the substitution $y = \\sqrt{a}x$, we get $\\frac{1}{\\sqrt{a}}\\int_0^{\\sqrt{a}} e^{-y^2} dy$.\nSince we are in the regime $N_e s \\gg 1$, $a \\gg 1$ and $\\sqrt{a} \\to \\infty$.\n$$ \\text{Denominator} \\approx \\frac{1}{\\sqrt{2N_e s}} \\int_0^{\\infty} e^{-y^2} dy = \\frac{1}{\\sqrt{2N_e s}} \\frac{\\sqrt{\\pi}}{2} = \\frac{\\sqrt{\\pi}}{2\\sqrt{2N_e s}} $$\nCombining the numerator and denominator:\n$$ u_{\\mathrm{rec}} \\approx \\frac{1/(2N_e)}{\\frac{\\sqrt{\\pi}}{2\\sqrt{2N_e s}}} = \\frac{1}{2N_e} \\frac{2\\sqrt{2N_e s}}{\\sqrt{\\pi}} = \\frac{\\sqrt{2N_e s}}{N_e \\sqrt{\\pi}} = \\sqrt{\\frac{2N_e s}{N_e^2 \\pi}} = \\sqrt{\\frac{2s}{\\pi N_e}} $$\n\n**Ratio of Fixation Probabilities**\nThe ratio of the fixation probabilities is:\n$$ \\frac{u_{\\mathrm{add}}}{u_{\\mathrm{rec}}} \\approx \\frac{s}{\\sqrt{\\frac{2s}{\\pi N_e}}} = s \\sqrt{\\frac{\\pi N_e}{2s}} = \\sqrt{\\frac{s^2 \\pi N_e}{2s}} = \\sqrt{\\frac{\\pi N_e s}{2}} $$\n\n**Evaluation of Options**\nWe now evaluate each option based on the derived results:\n-   $u_{\\mathrm{add}} \\approx s$\n-   $u_{\\mathrm{rec}} \\approx \\sqrt{\\frac{2s}{\\pi N_e}}$\n-   $u_{\\mathrm{add}}/u_{\\mathrm{rec}} \\approx \\sqrt{\\frac{\\pi N_e s}{2}}$\n\n-   **A. $u_{\\mathrm{add}} \\approx s$, $u_{\\mathrm{rec}} \\approx \\sqrt{\\dfrac{2s}{\\pi N_e}}$, and $u_{\\mathrm{add}}/u_{\\mathrm{rec}} \\approx \\sqrt{\\dfrac{\\pi N_e s}{2}}$.**\n    This statement perfectly matches our derived expressions for $u_{\\mathrm{add}}$, $u_{\\mathrm{rec}}$, and their ratio.\n    **Verdict: Correct.**\n\n-   **B. $u_{\\mathrm{add}} \\approx 2s$, $u_{\\mathrm{rec}} \\approx 0$, and $u_{\\mathrm{add}}/u_{\\mathrm{rec}}$ diverges to $+\\infty$.**\n    The expression for $u_{\\mathrm{add}}$ is incorrect. The result $u_{\\mathrm{add}} \\approx 2s$ would arise if the heterozygote advantage was $s$ (e.g., $w_{Aa}=1+s$), but for the given additive case ($h=1/2$), the advantage is $s/2$ and the correct fixation probability is $2(s/2) = s$. The expression for $u_{\\mathrm{rec}}$ is an oversimplification; while much smaller than $u_{\\mathrm{add}}$, it is non-zero and has a specific functional form.\n    **Verdict: Incorrect.**\n\n-   **C. $u_{\\mathrm{add}} \\approx s$, $u_{\\mathrm{rec}} \\approx \\dfrac{1}{2N_e}$, and $u_{\\mathrm{add}}/u_{\\mathrm{rec}} \\approx s N_e$.**\n    This statement correctly gives $u_{\\mathrm{add}} \\approx s$, but it incorrectly claims $u_{\\mathrm{rec}}$ is equal to the neutral fixation probability $1/(2N_e)$. Our derivation shows that $u_{\\mathrm{rec}}$ is greater than the neutral probability by a factor of $\\sqrt{8 N_e s / \\pi}$. The ratio is also incorrect.\n    **Verdict: Incorrect.**\n\n-   **D. $u_{\\mathrm{add}} \\approx \\dfrac{s}{2}$, $u_{\\mathrm{rec}} \\approx s^2$, and $u_{\\mathrm{add}}/u_{\\mathrm{rec}} \\approx \\dfrac{1}{2s}$.**\n    All three parts of this statement are incorrect. The expression for $u_{\\mathrm{rec}}$ lacks the necessary dependence on $N_e$.\n    **Verdict: Incorrect.**\n\nThe only correct statement is A. The large ratio $u_{\\mathrm{add}}/u_{\\mathrm{rec}}$ demonstrates Haldane's sieve: selection is much less efficient at fixing beneficial recessive alleles compared to alleles with some degree of dominance, because the recessive allele is shielded from selection when rare and existing only in heterozygotes.", "answer": "$$\\boxed{A}$$", "id": "2714135"}, {"introduction": "A central task in modern evolutionary biology is to estimate the strength of selection from empirical data, which is often noisy and incomplete. This exercise bridges theoretical models with practical data analysis by guiding you through the process of inferring a selection coefficient from allele frequency time-series. By formulating and implementing a state-space model that accounts for both Wright-Fisher dynamics and observation error, you will gain hands-on experience with the powerful statistical methods used to quantify evolution in action [@problem_id:2714110].", "problem": "You are tasked with formulating a discrete-time state-space model that combines Wright–Fisher drift and selection and using it to infer an unknown selection coefficient from allele count time series that include sequencing errors. Your program must implement the following model and inference procedure and then report results on the specified test suite.\n\nModel specification\n\n- Hidden state: Let $K_t \\in \\{0,1,\\dots,2N_e\\}$ denote the latent count of the focal allele at discrete generation $t$, where $N_e$ is the effective population size and $2N_e$ is the diploid number of gene copies.\n\n- Selection and reproduction: Assume genic selection with selection coefficient $s$ acting on the focal allele each generation, producing a pre-drift allele frequency\n$$\np^{\\text{sel}}_t = \\frac{p_t (1+s)}{1 + s p_t},\n$$\nwhere $p_t = K_t/(2N_e)$. Sampling (genetic drift) then yields the next generation count by\n$$\nK_{t+1} \\sim \\mathrm{Binomial}\\!\\left(2N_e,\\, p^{\\text{sel}}_t\\right).\n$$\n\n- Observation model with sequencing error: At each generation $t$, you observe sequencing read counts $X_t$ of the focal allele out of $R_t$ total reads, with per-read symmetric error rate $\\varepsilon$. The probability of calling the focal allele in sequencing is\n$$\nq_t = \\varepsilon + (1 - 2\\varepsilon) p_t.\n$$\nConditional on $K_t$, the observation is\n$$\nX_t \\sim \\mathrm{Binomial}(R_t, q_t).\n$$\n\n- Prior: Use an uninformative prior on the initial hidden state, $K_0 \\sim \\mathrm{Uniform}\\{0,1,\\dots, 2N_e\\}$.\n\nInference target and approach\n\n- Target: The unknown selection coefficient $s$.\n\n- Likelihood: The marginal likelihood of $s$ given the observed counts is obtained by summing over all hidden state trajectories. Compute this marginal likelihood using a forward algorithm as in a Hidden Markov Model (HMM): iteratively propagate the predictive distribution over $K_t$ via the Wright–Fisher (WF) transition kernel and update with the binomial observation likelihood at each time point.\n\n- Point estimate: Return the value $s^\\star$ that maximizes the marginal likelihood over a grid of candidate values.\n\nFoundational base\n\n- Use the classical Wright–Fisher model with selection and binomial sampling for drift.\n\n- Use the binomial model for sequencing counts with symmetric miscall probability $\\varepsilon$.\n\n- All computations should be in terms of probabilities and probability mass functions with numerically stable evaluation via log-gamma functions as needed.\n\nTest suite\n\nFor each case below, first simulate a synthetic time series using the exact generative model above, then perform inference to estimate $s$ via grid search. The simulation and inference must both use the same $N_e$, $\\varepsilon$, read depths $\\{R_t\\}$, number of time points $T$, and initial allele frequency $p_0$. The simulation protocol is:\n\n- Initialize $K_0 \\sim \\mathrm{Binomial}(2N_e, p_0)$.\n\n- For $t = 0,1,\\dots,T-1$:\n    - Emit $X_t \\sim \\mathrm{Binomial}(R_t, \\varepsilon + (1 - 2\\varepsilon) K_t/(2N_e))$.\n    - Compute $p^{\\text{sel}}_t = \\frac{(K_t/(2N_e)) (1+s_{\\text{true}})}{1 + s_{\\text{true}} (K_t/(2N_e))}$.\n    - Sample $K_{t+1} \\sim \\mathrm{Binomial}(2N_e, p^{\\text{sel}}_t)$.\n\nUse a fixed pseudorandom seed per case to ensure determinism. Then, given the observed $\\{X_t\\}$ and $\\{R_t\\}$, estimate $s$ by maximizing the marginal likelihood over the grid $s \\in \\{-0.200, -0.195, \\dots, 0.200\\}$.\n\nProvide results for the following three cases:\n\n- Case A (happy path, positive selection):\n    - $N_e = 100$, $s_{\\text{true}} = 0.050$, $\\varepsilon = 0.010$, $p_0 = 0.100$, $T = 7$ time points.\n    - Read depths: $R_t = 120$ for all $t \\in \\{0,\\dots,6\\}$.\n    - Random seed: $1337$.\n\n- Case B (boundary, neutral):\n    - $N_e = 80$, $s_{\\text{true}} = 0.000$, $\\varepsilon = 0.020$, $p_0 = 0.500$, $T = 7$ time points.\n    - Read depths by time: $R = [60, 80, 100, 120, 80, 60, 100]$.\n    - Random seed: $7$.\n\n- Case C (negative selection with low error and varied depth):\n    - $N_e = 120$, $s_{\\text{true}} = -0.030$, $\\varepsilon = 0.005$, $p_0 = 0.200$, $T = 7$ time points.\n    - Read depths by time: $R = [100, 100, 150, 150, 120, 120, 100]$.\n    - Random seed: $2021$.\n\nImplementation details and output format\n\n- Use a numerically stable evaluation of binomial probability mass functions via log-gamma where appropriate.\n\n- Treat all probabilities constrained to $[0,1]$ by clipping to a small open interval such as $[10^{-12}, 1 - 10^{-12}]$ to avoid numerical issues.\n\n- The final output must be a single line containing a comma-separated list of the three selected maximizers $[s^\\star_A, s^\\star_B, s^\\star_C]$, each as a floating-point number rounded to three decimal places, enclosed in square brackets.\n\n- No physical units are involved in this problem.\n\n- Angles are not used in this problem.\n\n- Fractions or decimals are acceptable; do not use a percentage sign.\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (e.g., \"[0.045,0.000,-0.030]\").", "solution": "We construct a state-space model where the hidden population genetic process follows Wright–Fisher dynamics with selection and the observation process follows binomial sampling with symmetric sequencing error. The hidden state at generation $t$ is the allele count $K_t \\in \\{0, \\dots, 2N_e\\}$ with corresponding allele frequency $p_t = K_t/(2N_e)$.\n\nFoundational principles and model construction\n\n1. Wright–Fisher transition with selection. Under genic selection with selection coefficient $s$, the relative fitness of the focal allele is $1+s$. The post-selection frequency before drift is\n$$\np^{\\text{sel}}_t = \\frac{p_t (1+s)}{1 + s p_t},\n$$\nderived from standard viability selection in a haploid or additive diploid (genic) scenario. Drift is modeled by binomial sampling of $2N_e$ gene copies:\n$$\nK_{t+1} \\mid K_t \\sim \\mathrm{Binomial}\\!\\left(2N_e,\\, p^{\\text{sel}}_t\\right).\n$$\nThis defines a time-homogeneous Markov chain on $\\{0,\\dots,2N_e\\}$ with transition kernel\n$$\n\\Pr(K_{t+1} = k' \\mid K_t = k; s) = \\binom{2N_e}{k'} \\left(p^{\\text{sel}}(k; s)\\right)^{k'} \\left(1 - p^{\\text{sel}}(k; s)\\right)^{2N_e - k'},\n$$\nwhere $p^{\\text{sel}}(k; s) = \\frac{(k/(2N_e)) (1+s)}{1 + s (k/(2N_e))}$.\n\n2. Observation model with sequencing error. Given the true frequency $p_t = K_t/(2N_e)$ and a symmetric per-read error probability $\\varepsilon$, the probability that a single read is called as the focal allele is\n$$\nq_t = \\varepsilon + (1 - 2\\varepsilon) p_t,\n$$\nwhich follows because with probability $1-\\varepsilon$ a read is correct and with probability $\\varepsilon$ a read is flipped; in the biallelic case this yields a linear transformation of $p_t$. Given $R_t$ total reads at time $t$, the observed count $X_t$ has distribution\n$$\nX_t \\mid K_t \\sim \\mathrm{Binomial}(R_t, q_t).\n$$\n\n3. Prior. We use an uninformative prior on the initial state, $K_0 \\sim \\mathrm{Uniform}\\{0,\\dots,2N_e\\}$, reflecting lack of prior knowledge about the initial allele count. This prior is conjugate neither to the transition nor observation but suffices for a principled likelihood computation via summation over states.\n\nMarginal likelihood via the forward algorithm\n\nLet $\\boldsymbol{\\alpha}_t(k) = \\Pr(K_t = k \\mid X_{0:t}; s)$ denote the filtered distribution after incorporating the observation at time $t$. The forward recursion proceeds as follows:\n\n- Initialization at $t=0$:\n$$\n\\tilde{\\alpha}_0(k) = \\Pr(K_0 = k) \\cdot \\Pr(X_0 \\mid K_0 = k; \\varepsilon, R_0),\n$$\nwhere $\\Pr(K_0 = k) = 1/(2N_e+1)$ for all $k$. Normalize by $Z_0 = \\sum_{k} \\tilde{\\alpha}_0(k)$ to obtain $\\boldsymbol{\\alpha}_0(k) = \\tilde{\\alpha}_0(k)/Z_0$. Accumulate $\\log Z_0$ into the total log-likelihood.\n\n- Induction for $t \\ge 1$:\n    - Prediction:\n    $$\n    \\pi_t(k') = \\sum_{k=0}^{2N_e} \\boldsymbol{\\alpha}_{t-1}(k) \\cdot \\Pr(K_t = k' \\mid K_{t-1} = k; s).\n    $$\n    - Update with observation:\n    $$\n    \\tilde{\\alpha}_t(k') = \\pi_t(k') \\cdot \\Pr(X_t \\mid K_t = k'; \\varepsilon, R_t),\n    $$\n    followed by normalization via $Z_t = \\sum_{k'} \\tilde{\\alpha}_t(k')$ and setting $\\boldsymbol{\\alpha}_t(k') = \\tilde{\\alpha}_t(k')/Z_t$. Accumulate $\\log Z_t$ into the total log-likelihood.\n\nThe total marginal log-likelihood is\n$$\n\\log \\mathcal{L}(s) = \\sum_{t=0}^{T-1} \\log Z_t,\n$$\nsince each normalization constant $Z_t$ corresponds to the predictive probability of the current observation $X_t$ given past observations under parameter $s$.\n\nNumerically stable evaluation\n\n- For the binomial probability mass functions $\\binom{n}{k} p^k (1-p)^{n-k}$, compute $\\log \\binom{n}{k}$ using the log-gamma function: $\\log \\binom{n}{k} = \\Gamma(n+1) - \\Gamma(k+1) - \\Gamma(n-k+1)$ in terms of $\\log \\Gamma(\\cdot)$, i.e., $\\mathrm{gammaln}$.\n\n- Compute probabilities in log-space when forming rows of the transition matrix and emission vectors, exponentiating only after subtracting a suitable offset if necessary, and clip $p$ and $q$ to $[10^{-12}, 1 - 10^{-12}]$ to avoid $\\log 0$.\n\nPoint estimation\n\n- Define a grid of candidate selection coefficients $s \\in \\{-0.200, -0.195, \\dots, 0.200\\}$.\n\n- For each $s$ on the grid, build the transition kernel and run the forward algorithm to compute $\\log \\mathcal{L}(s)$.\n\n- Select the Maximum Likelihood Estimate (MLE) $s^\\star = \\arg\\max_s \\log \\mathcal{L}(s)$.\n\nSimulation for the test suite\n\nFor each case, simulate a dataset using the same model:\n\n- Initialize $K_0 \\sim \\mathrm{Binomial}(2N_e, p_0)$.\n\n- For $t = 0,\\dots,T-1$:\n    - Emit $X_t \\sim \\mathrm{Binomial}(R_t, \\varepsilon + (1-2\\varepsilon) K_t/(2N_e))$.\n    - Compute $p^{\\text{sel}}_t = \\frac{(K_t/(2N_e))(1+s_{\\text{true}})}{1 + s_{\\text{true}} (K_t/(2N_e))}$.\n    - Sample $K_{t+1} \\sim \\mathrm{Binomial}(2N_e, p^{\\text{sel}}_t)$.\n\nUse fixed seeds as specified to guarantee reproducibility.\n\nAlgorithmic structure\n\n- For each case, generate the observed counts with the given parameters and seed.\n\n- For each case, loop over the $s$ grid, construct the transition matrix once per $s$, and compute the marginal log-likelihood using the forward recursion with uniform prior on $K_0$.\n\n- Record the $s$ that maximizes the log-likelihood, rounding to three decimal places.\n\nOutput\n\n- Produce a single line containing the three MLEs for the three cases in order, formatted as a comma-separated list enclosed in square brackets, e.g., $[0.045, 0.000, -0.030]$, with each value rounded to three decimal places.\n\nThis approach integrates fundamental definitions of Wright–Fisher drift with selection and binomial observation noise into a principled Hidden Markov Model likelihood, enabling consistent inference of the selection coefficient from noisy allele count time series.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.special import gammaln\n\ndef rng(seed):\n    # Simple wrapper for NumPy Generator for reproducibility\n    return np.random.default_rng(seed)\n\ndef log_binom_coeff(n, k):\n    # log binomial coefficient log(C(n,k))\n    return gammaln(n + 1.0) - gammaln(k + 1.0) - gammaln(n - k + 1.0)\n\ndef build_transition_matrix(Ne, s):\n    \"\"\"\n    Build the (2Ne+1) x (2Ne+1) transition matrix T where\n    T[i, j] = P(K_{t+1} = j | K_t = i; s)\n    Using genic selection and Wright-Fisher sampling.\n    \"\"\"\n    twoN = 2 * Ne\n    S = twoN + 1\n    T = np.zeros((S, S), dtype=np.float64)\n    # Precompute log binomial coefficients for columns j\n    j = np.arange(S)\n    logC = log_binom_coeff(twoN, j)\n    # For each row i (state k=i)\n    i = np.arange(S)\n    p = i / twoN\n    # Selection-transformed frequency\n    denom = 1.0 + s * p\n    # Avoid division by zero for s near -1\n    denom = np.clip(denom, 1e-12, np.inf)\n    p_sel = p * (1.0 + s) / denom\n    p_sel = np.clip(p_sel, 1e-12, 1.0 - 1e-12)\n    # Fill each row: Binomial(twoN, p_sel[i]) across all j\n    for idx in range(S):\n        ps = p_sel[idx]\n        # log pmf for all j\n        logpmf = logC + j * np.log(ps) + (twoN - j) * np.log(1.0 - ps)\n        # exponentiate safely (values are well-behaved for twoN up to ~300)\n        row = np.exp(logpmf)\n        # Normalize to avoid small numerical drift\n        row_sum = row.sum()\n        if row_sum = 0.0 or not np.isfinite(row_sum):\n            # Fallback normalization in extreme edge cases\n            m = np.max(logpmf)\n            row = np.exp(logpmf - m)\n            row_sum = row.sum()\n        T[idx, :] = row / row_sum\n    return T\n\ndef emission_log_probs_vector(Ne, epsilon, R, X):\n    \"\"\"\n    For a single timepoint with observed X out of R, return a vector of\n    log-likelihoods log P(X | K=k) for k in 0..2Ne, with q = eps + (1-2eps)*p\n    \"\"\"\n    twoN = 2 * Ne\n    S = twoN + 1\n    k = np.arange(S)\n    p = k / twoN\n    q = epsilon + (1.0 - 2.0 * epsilon) * p\n    q = np.clip(q, 1e-12, 1.0 - 1e-12)\n    # log binomial pmf\n    logC_RX = log_binom_coeff(R, X)\n    loglik = logC_RX + X * np.log(q) + (R - X) * np.log(1.0 - q)\n    return loglik  # shape (S,)\n\ndef forward_loglikelihood(Ne, epsilon, R_list, X_list, s):\n    \"\"\"\n    Compute the marginal log-likelihood log L(s) via the forward algorithm\n    with a uniform prior over K_0.\n    \"\"\"\n    twoN = 2 * Ne\n    S = twoN + 1\n    T = build_transition_matrix(Ne, s)\n    # Initial prior over K_0\n    pi = np.full(S, 1.0 / S, dtype=np.float64)\n    logL = 0.0\n    T_steps = len(X_list)\n    for t in range(T_steps):\n        # Emission update\n        loge = emission_log_probs_vector(Ne, epsilon, R_list[t], X_list[t])\n        # Work in linear space via stable exponentiation\n        m = np.max(loge)\n        e = np.exp(loge - m)\n        # alpha_tilde = pi * e\n        alpha_tilde = pi * e\n        Z = alpha_tilde.sum()\n        if Z = 0.0 or not np.isfinite(Z):\n            # Degenerate; avoid failure by small floor\n            Z = 1e-300\n        logZ = np.log(Z) + m  # account for offset m\n        logL += logZ\n        alpha = alpha_tilde / Z\n        # Prediction to next time (skip after last observation)\n        if t  T_steps - 1:\n            pi = alpha @ T\n            # Numerical safety normalization\n            ssum = pi.sum()\n            if ssum  0:\n                pi = pi / ssum\n            else:\n                pi = np.full(S, 1.0 / S, dtype=np.float64)\n    return logL\n\ndef simulate_case(Ne, s_true, p0, epsilon, R_list, T, seed):\n    \"\"\"\n    Simulate a dataset:\n    - Initialize K0 ~ Binomial(2Ne, p0)\n    - For t = 0..T-1:\n        - Observe X_t ~ Binomial(R_t, q_t) with q_t = eps + (1-2 eps) * p_t\n        - Compute p_sel and sample K_{t+1} ~ Binomial(2Ne, p_sel)\n    Returns observed counts X_list.\n    \"\"\"\n    twoN = 2 * Ne\n    S = twoN + 1\n    gen = rng(seed)\n    K = gen.binomial(twoN, p0)\n    X_list = []\n    for t in range(T):\n        p = K / twoN\n        q = epsilon + (1.0 - 2.0 * epsilon) * p\n        q = np.clip(q, 1e-12, 1.0 - 1e-12)\n        X = gen.binomial(R_list[t], q)\n        X_list.append(int(X))\n        # Selection and drift to next generation\n        denom = 1.0 + s_true * p\n        denom = max(denom, 1e-12)\n        p_sel = p * (1.0 + s_true) / denom\n        p_sel = float(np.clip(p_sel, 1e-12, 1.0 - 1e-12))\n        K = gen.binomial(twoN, p_sel)\n    return X_list\n\ndef estimate_s_MLE(Ne, epsilon, R_list, X_list, s_grid):\n    best_s = None\n    best_logL = -np.inf\n    for s in s_grid:\n        logL = forward_loglikelihood(Ne, epsilon, R_list, X_list, s)\n        if logL  best_logL:\n            best_logL = logL\n            best_s = s\n    return best_s, best_logL\n\ndef solve():\n    # Define the test cases from the problem statement.\n    # Each case: (Ne, s_true, epsilon, p0, T, R_list, seed)\n    test_cases = [\n        (100, 0.050, 0.010, 0.100, 7, [120]*7, 1337),                        # Case A\n        (80,  0.000, 0.020, 0.500, 7, [60, 80, 100, 120, 80, 60, 100], 7),   # Case B\n        (120, -0.030, 0.005, 0.200, 7, [100, 100, 150, 150, 120, 120, 100], 2021),  # Case C\n    ]\n\n    # Grid of s to search\n    s_grid = np.round(np.arange(-0.200, 0.200 + 0.0005, 0.005), 3)  # ensure inclusive endpoint\n\n    results = []\n    for (Ne, s_true, epsilon, p0, T, R_list, seed) in test_cases:\n        # Simulate observed counts\n        X_list = simulate_case(Ne, s_true, p0, epsilon, R_list, T, seed)\n        # Estimate s by MLE on the grid\n        s_hat, _ = estimate_s_MLE(Ne, epsilon, R_list, X_list, s_grid)\n        # Round to three decimals for output\n        results.append(f\"{s_hat:.3f}\")\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(results)}]\")\n\nif __name__ == \"__main__\":\n    solve()\n```", "id": "2714110"}]}