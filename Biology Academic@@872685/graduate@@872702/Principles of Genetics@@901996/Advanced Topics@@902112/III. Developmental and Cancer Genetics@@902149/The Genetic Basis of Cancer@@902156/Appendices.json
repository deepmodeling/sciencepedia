{"hands_on_practices": [{"introduction": "A fundamental skill in cancer genomics is the ability to interpret data from tumor sequencing. The Variant Allele Frequency (VAF) of a mutation is not a direct measure of its prevalence, but a composite signal influenced by tumor purity, local copy number, and the fraction of cancer cells harboring the mutation. This exercise challenges you to derive the mathematical relationship connecting these hidden biological parameters to the observable VAF, a crucial first step in quantitatively deconstructing the genetic makeup of a tumor. [@problem_id:2858056]", "problem": "A tumor biopsy is a mixture of cancer and normal cells. Let $p$ denote the tumor purity, defined as the fraction of cells in the sample that are cancer cells, so the fraction of normal cells is $(1 - p)$. Assume normal cells are diploid at the locus of interest with total copy number $2$, and that they do not harbor the mutation. In the cancer cell population, the local total copy number at the locus is $C$ (assume all cancer cells share this local total copy number), and a Single-Nucleotide Variant (SNV) is heterozygous in each cancer cell that carries it, meaning exactly one of the $C$ chromosomal copies carries the mutant allele in those cells. Let $\\phi$ denote the Cancer Cell Fraction (CCF), the fraction of cancer cells that carry the SNV; in a clonal case $\\phi = 1$, whereas subclonal cases have $0  \\phi  1$. The Variant Allele Frequency (VAF), denoted $v$, is defined as the expected fraction of sequencing reads covering the locus that carry the SNV, under the assumptions of unbiased sampling across cells and alleles and no allele-specific amplification bias.\n\nStarting from these definitions and fundamental counting of allele copies contributed by each compartment of the sample, derive an expression for the expected VAF $v$ as a function of $p$, $C$, and $\\phi$. Express your final answer as a single simplified analytic expression in terms of $p$, $C$, and $\\phi$. No numerical approximation or rounding is required, and no units should be reported.", "solution": "The problem statement has been analyzed for validity and is determined to be a well-posed, scientifically grounded problem in quantitative biology. It is free of contradiction, ambiguity, and pseudoscience. We shall now proceed with its formal derivation.\n\nThe Variant Allele Frequency, $v$, is defined as the expected fraction of all alleles at a specific genomic locus that carry the mutant allele. Assuming unbiased sampling, this frequency can be expressed as the ratio of the total number of mutant alleles to the total number of alleles at that locus within the entire cell sample population.\n$$v = \\frac{N_{\\text{mutant}}}{N_{\\text{total}}}$$\nwhere $N_{\\text{mutant}}$ is the total count of mutant alleles and $N_{\\text{total}}$ is the total count of all alleles (mutant and wild-type) at the locus.\n\nTo derive an expression for $v$, we will consider a representative tissue sample comprising an arbitrary total of $N$ cells. This quantity $N$ is a scaling factor that will, and must, be eliminated from the final expression, as $v$ is an intensive property.\n\nThe sample consists of two distinct cell populations: normal cells and cancer cells.\nThe number of normal cells in the sample is given by $N_{\\text{normal}} = (1 - p)N$, where $p$ is the tumor purity.\nThe number of cancer cells is given by $N_{\\text{cancer}} = pN$.\n\nFirst, we will compute the denominator, $N_{\\text{total}}$. This is the sum of alleles contributed by the normal and cancer cell compartments.\nNormal cells are specified to be diploid at the locus of interest, meaning each normal cell contributes $2$ alleles. The total number of alleles from the normal cell population is:\n$$N_{\\text{alleles, normal}} = N_{\\text{normal}} \\times 2 = (1 - p)N \\times 2 = 2(1 - p)N$$\nCancer cells are specified to have a total copy number of $C$ at this locus. Therefore, each cancer cell contributes $C$ alleles. The total number of alleles from the cancer cell population is:\n$$N_{\\text{alleles, cancer}} = N_{\\text{cancer}} \\times C = (pN) \\times C = pCN$$\nThe total number of alleles in the entire sample, $N_{\\text{total}}$, is the sum of these two contributions:\n$$N_{\\text{total}} = N_{\\text{alleles, normal}} + N_{\\text{alleles, cancer}} = 2(1 - p)N + pCN = N(2(1 - p) + pC)$$\n\nNext, we will compute the numerator, $N_{\\text{mutant}}$. This is the total number of alleles carrying the Single-Nucleotide Variant (SNV).\nThe problem states that normal cells do not harbor the mutation. Thus, their contribution to the count of mutant alleles is zero.\nMutant alleles are found only within a subpopulation of the cancer cells. The fraction of cancer cells carrying the SNV is denoted by the Cancer Cell Fraction, $\\phi$. The absolute number of cancer cells with the SNV is:\n$$N_{\\text{cancer, with SNV}} = N_{\\text{cancer}} \\times \\phi = pN\\phi$$\nIn each of these SNV-carrying cancer cells, the mutation is heterozygous. This is defined to mean that precisely one of the $C$ chromosomal copies carries the mutant allele. Therefore, each of these $N_{\\text{cancer, with SNV}}$ cells contributes exactly $1$ mutant allele to the total count.\nThe total number of mutant alleles in the sample is:\n$$N_{\\text{mutant}} = N_{\\text{cancer, with SNV}} \\times 1 = pN\\phi$$\n\nFinally, we construct the ratio for $v$:\n$$v = \\frac{N_{\\text{mutant}}}{N_{\\text{total}}} = \\frac{pN\\phi}{N(2(1 - p) + pC)}$$\nThe arbitrary total cell count $N$ cancels from the expression, yielding the relationship between the VAF and the intrinsic biological parameters of the sample:\n$$v = \\frac{p\\phi}{2(1 - p) + pC}$$\nThis is the required simplified analytical expression. It provides a fundamental model for interpreting variant allele frequencies in the context of tumor purity, copy number alterations, and subclonal architecture.", "answer": "$$\\boxed{\\frac{p\\phi}{2(1 - p) + pC}}$$", "id": "2858056"}, {"introduction": "Moving from a static snapshot to the dynamics of tumor evolution, this practice explores the classic \"two-hit\" model of tumor suppressor gene inactivation. You will develop a quantitative framework using stochastic process theory to understand how different mutational pathways contribute to tumorigenesis. This model provides a powerful demonstration of how genomic instability, specifically Loss of Heterozygosity (LOH), dramatically accelerates the rate of biallelic inactivation, a critical step in cancer development. [@problem_id:2858011]", "problem": "A tumor suppressor gene requires $2$ independent \"hits\" to achieve biallelic inactivation. Consider a single proliferating cell lineage in which mutational and chromosomal events occur as independent Poisson processes per cell division with small hazard rates. Use the following foundational base:\n\n- The two-hit model for tumor suppressor inactivation: biallelic loss requires $2$ independent events.\n- Central Dogma of Molecular Biology and Mendelian segregation are assumed, but only as background; focus on event hazard rates and genotype transitions.\n- Rare-event Poisson processes imply exponential waiting times with memoryless property.\n- Loss of heterozygosity (LOH) includes two mechanistic classes: copy-neutral loss of heterozygosity (CN-LOH) via mitotic recombination, and deletion LOH via segmental deletion.\n\nModel the genotype dynamics as a continuous-time Markov process with states: $S_0$ (homozygous wild-type, $AA$), $S_1$ (heterozygous, $Aa$), $S_h$ (hemizygous wild-type, $A-$), and $S_2$ (biallelically inactivated, $aa$ or $a-$), which is absorbing. Assume symmetry between homologs and the following per-division hazard rates:\n\n- Point mutation inactivating a functional allele: per-allele rate $\\mu$.\n- CN-LOH at the locus in a heterozygote that renders the locus homozygous: per-locus rate $\\rho$, yielding $aa$ with probability $1/2$ and $AA$ with probability $1/2$.\n- Deletion LOH at the locus: per-locus rate $\\delta$. In a heterozygote, with probability $1/2$ it deletes the wild-type homolog (immediately yielding biallelic inactivation), and with probability $1/2$ it deletes the mutant homolog (yielding $S_h$). In a wild-type cell, deletion LOH yields $S_h$. In $S_h$, a single mutation at rate $\\mu$ completes inactivation.\n\nTransitions and their hazards are thus:\n- $S_0 \\to S_1$ at rate $2\\mu$.\n- $S_0 \\to S_h$ at rate $\\delta$.\n- $S_1 \\to S_2$ at rates $\\mu$ (second point mutation), $\\rho/2$ (CN-LOH completes), and $\\delta/2$ (deletion completes); and $S_1 \\to S_h$ at rate $\\delta/2$ (deletion removes the mutant homolog).\n- $S_h \\to S_2$ at rate $\\mu$.\n\nStarting in $S_0$, define the mean first passage time to $S_2$ as $\\mathbb{E}[T]$ and the effective biallelic inactivation rate as $\\lambda_{\\mathrm{eff}} = 1/\\mathbb{E}[T]$. Let $\\lambda_{\\mathrm{eff}}^{(0)}$ denote the effective rate when LOH is absent (set $\\rho = 0$ and $\\delta = 0$). Derive $\\lambda_{\\mathrm{eff}}$ from first principles using the Markov property and conditioning on the first event, and interpret how LOH increases the effective rate by altering the hazard of the second hit. Then, for the quantitative comparison of LOH mechanisms, compute the relative contribution of CN-LOH versus deletion to the second-hit hazard from $S_1$.\n\nUse the following parameter values (per division): $\\mu = 1.0 \\times 10^{-7}$, $\\rho = 1.5 \\times 10^{-6}$, and $\\delta = 4.0 \\times 10^{-7}$. Define the acceleration factor $A = \\lambda_{\\mathrm{eff}} / \\lambda_{\\mathrm{eff}}^{(0)}$. Report only $A$ as your final answer, rounded to three significant figures. The final answer is unitless.", "solution": "The problem presents a valid, well-posed, and scientifically grounded model of tumorigenesis based on the two-hit hypothesis for a tumor suppressor gene. It is a standard application of continuous-time Markov chains to calculate the mean time to an event of interest, in this case, biallelic inactivation. We shall proceed with the derivation.\n\nThe system is modeled by a continuous-time Markov process with four states: $S_0$ (wild-type, $AA$), $S_1$ (heterozygous, $Aa$), $S_h$ (hemizygous, $A-$), and $S_2$ (inactivated, $aa$ or $a-$), which is the absorbing state. The goal is to find the mean first passage time (MFPT) to state $S_2$, starting from state $S_0$. Let $T_i$ be the MFPT to $S_2$ starting from state $S_i$. By definition, $T_2 = 0$. For any other state $S_i$, the MFPT can be found by conditioning on the first transition out of $S_i$. This yields the following system of linear equations:\n$$T_i = \\frac{1}{\\lambda_i} + \\sum_{j \\neq i} \\frac{q_{ij}}{\\lambda_i} T_j$$\nwhere $q_{ij}$ is the transition rate from state $S_i$ to $S_j$, and $\\lambda_i = \\sum_{j \\neq i} q_{ij}$ is the total exit rate from state $S_i$.\n\nThe transition rates are given as follows:\n-   From $S_0$: $q_{01} = 2\\mu$, $q_{0h} = \\delta$. The total exit rate is $\\lambda_0 = 2\\mu + \\delta$.\n-   From $S_1$: $q_{12} = \\mu + \\frac{\\rho}{2} + \\frac{\\delta}{2}$, $q_{1h} = \\frac{\\delta}{2}$. The total exit rate is $\\lambda_1 = q_{12} + q_{1h} = \\mu + \\frac{\\rho}{2} + \\delta$.\n-   From $S_h$: $q_{h2} = \\mu$. The total exit rate is $\\lambda_h = \\mu$.\n\nWe can now write the specific equations for $T_0$, $T_1$, and $T_h$:\nFor $S_h$:\n$$T_h = \\frac{1}{\\lambda_h} + \\frac{q_{h2}}{\\lambda_h} T_2 = \\frac{1}{\\mu} + \\frac{\\mu}{\\mu}(0) \\implies T_h = \\frac{1}{\\mu}$$\nThis is the mean waiting time in the hemizygous state before the final inactivating mutation occurs.\n\nFor $S_1$:\n$$T_1 = \\frac{1}{\\lambda_1} + \\frac{q_{12}}{\\lambda_1} T_2 + \\frac{q_{1h}}{\\lambda_1} T_h = \\frac{1}{\\mu + \\frac{\\rho}{2} + \\delta} + 0 + \\frac{\\delta/2}{\\mu + \\frac{\\rho}{2} + \\delta} T_h$$\nSubstituting $T_h = 1/\\mu$, we get:\n$$T_1 = \\frac{1}{\\mu + \\frac{\\rho}{2} + \\delta} \\left( 1 + \\frac{\\delta}{2\\mu} \\right) = \\frac{2\\mu + \\delta}{2\\mu (\\mu + \\frac{\\rho}{2} + \\delta)}$$\n\nFor $S_0$:\n$$T_0 = \\frac{1}{\\lambda_0} + \\frac{q_{01}}{\\lambda_0} T_1 + \\frac{q_{0h}}{\\lambda_0} T_h = \\frac{1}{2\\mu + \\delta} + \\frac{2\\mu}{2\\mu + \\delta} T_1 + \\frac{\\delta}{2\\mu + \\delta} T_h$$\nRearranging gives $(2\\mu + \\delta)T_0 = 1 + 2\\mu T_1 + \\delta T_h$. Substituting the expressions for $T_1$ and $T_h$:\n$$(2\\mu + \\delta)T_0 = 1 + 2\\mu \\left( \\frac{2\\mu + \\delta}{2\\mu (\\mu + \\frac{\\rho}{2} + \\delta)} \\right) + \\delta \\left( \\frac{1}{\\mu} \\right)$$\n$$(2\\mu + \\delta)T_0 = 1 + \\frac{2\\mu + \\delta}{\\mu + \\frac{\\rho}{2} + \\delta} + \\frac{\\delta}{\\mu}$$\nThe mean first passage time from the initial state $S_0$ is $\\mathbb{E}[T] = T_0$:\n$$T_0 = \\frac{1}{2\\mu + \\delta} \\left( 1 + \\frac{2\\mu + \\delta}{\\mu + \\frac{\\rho}{2} + \\delta} + \\frac{\\delta}{\\mu} \\right)$$\nThe effective biallelic inactivation rate is $\\lambda_{\\mathrm{eff}} = 1/T_0$.\n\nTo interpret the effect of Loss of Heterozygosity (LOH), we consider the hazard of the second hit. If the first hit is a point mutation, the cell enters state $S_1$. Without LOH ($\\rho=0, \\delta=0$), the only path to inactivation is another point mutation, with rate $\\mu$. With LOH, the total rate of inactivation from $S_1$ is $h_2 = \\mu + \\rho/2 + \\delta/2$. Using the given parameters, $\\mu = 1.0 \\times 10^{-7}$, $\\rho = 1.5 \\times 10^{-6}$, and $\\delta = 4.0 \\times 10^{-7}$, the second-hit hazard is $h_2 = (1.0 \\times 10^{-7}) + (1.5 \\times 10^{-6})/2 + (4.0 \\times 10^{-7})/2 = (1.0 + 7.5 + 2.0) \\times 10^{-7} = 1.05 \\times 10^{-6}$. This is a factor of $1.05 \\times 10^{-6} / (1.0 \\times 10^{-7}) = 10.5$ greater than the rate by mutation alone. LOH thus dramatically accelerates the second hit, and this is its primary role in tumor suppression.\n\nThe relative contribution of CN-LOH versus deletion LOH to the second-hit hazard from $S_1$ is the ratio of their respective rates: $\\frac{\\rho/2}{\\delta/2} = \\frac{\\rho}{\\delta}$. Numerically, this is $\\frac{1.5 \\times 10^{-6}}{4.0 \\times 10^{-7}} = 3.75$. This indicates that CN-LOH is $3.75$ times more likely to cause the second hit than deletion LOH, given a heterozygous cell.\n\nNext, we calculate the effective rate in the absence of LOH, $\\lambda_{\\mathrm{eff}}^{(0)}$, by setting $\\rho=0$ and $\\delta=0$. The pathway becomes a simple two-step process $S_0 \\xrightarrow{2\\mu} S_1 \\xrightarrow{\\mu} S_2$. The mean time is the sum of the mean waiting times for each step: $T_0^{(0)} = \\frac{1}{2\\mu} + \\frac{1}{\\mu} = \\frac{3}{2\\mu}$. Thus, $\\lambda_{\\mathrm{eff}}^{(0)} = \\frac{1}{T_0^{(0)}} = \\frac{2\\mu}{3}$.\n\nFinally, we compute the acceleration factor $A = \\lambda_{\\mathrm{eff}} / \\lambda_{\\mathrm{eff}}^{(0)}$. This is equivalent to $T_0^{(0)} / T_0$.\nFirst, we compute the numerical value of $T_0$ with the given parameters:\n$2\\mu + \\delta = 2(1.0 \\times 10^{-7}) + 4.0 \\times 10^{-7} = 6.0 \\times 10^{-7}$.\n$\\mu + \\rho/2 + \\delta = 1.0 \\times 10^{-7} + (1.5 \\times 10^{-6})/2 + 4.0 \\times 10^{-7} = 1.25 \\times 10^{-6}$.\n$\\delta/\\mu = (4.0 \\times 10^{-7}) / (1.0 \\times 10^{-7}) = 4$.\n$$T_0 = \\frac{1}{6.0 \\times 10^{-7}} \\left( 1 + \\frac{6.0 \\times 10^{-7}}{1.25 \\times 10^{-6}} + 4 \\right) = \\frac{1}{6.0 \\times 10^{-7}} (1 + 0.48 + 4) = \\frac{5.48}{6.0 \\times 10^{-7}}$$\nNow, we compute $T_0^{(0)}$:\n$$T_0^{(0)} = \\frac{3}{2\\mu} = \\frac{3}{2(1.0 \\times 10^{-7})} = \\frac{3}{2.0 \\times 10^{-7}}$$\nThe acceleration factor is:\n$$A = \\frac{T_0^{(0)}}{T_0} = \\frac{3/(2.0 \\times 10^{-7})}{5.48/(6.0 \\times 10^{-7})} = \\frac{3}{2.0} \\times \\frac{6.0}{5.48} = \\frac{18}{10.96} = \\frac{9}{5.48}$$\n$$A \\approx 1.642335...$$\nRounding to three significant figures, we get $A = 1.64$. This quantifies the overall speed-up of tumorigenesis due to the LOH pathways in this model. The factor is modest because the first-hit rate is also affected by LOH (via the deletion pathway to $S_h$) and the overall rate is a weighted average over all possible pathways to inactivation.", "answer": "$$\\boxed{1.64}$$", "id": "2858011"}, {"introduction": "This final practice scales up from modeling a single gene to analyzing an entire cohort of tumors, a common task in cancer research. The goal is to distinguish \"driver\" genes under positive selection from the vast background of \"passenger\" mutations. You will act as a computational biologist, building a robust statistical pipeline to identify significantly mutated genes while accounting for confounding factors like hypermutation and uneven sequencing coverage, and applying rigorous methods to control the false discovery rate. [@problem_id:2858052]", "problem": "You are given a statistical modeling task motivated by the genetic basis of cancer: detecting genes under positive selection for somatic mutations while accounting for uneven coverage and hypermutated samples. Build a complete program that, for each provided test case, computes one-sided significance for each gene under a null model of neutral mutagenesis and then applies a multiple-hypothesis correction to control the False Discovery Rate (FDR) at level $q=0.1$. Your program must output the indices of genes deemed significantly mutated for each test case in a single aggregated line as described below.\n\nBase principles to use:\n- Modeling mutations along deoxyribonucleic acid (DNA) as rare and approximately independent events across callable bases. Under the law of rare events, the sum of many independent Bernoulli($p$) trials with small $p$ approaches a Poisson distribution with parameter equal to the expected count.\n- Additivity of independent Poisson variables: if $X_1 \\sim \\mathrm{Poisson}(\\lambda_1)$ and $X_2 \\sim \\mathrm{Poisson}(\\lambda_2)$ are independent, then $X_1 + X_2 \\sim \\mathrm{Poisson}(\\lambda_1 + \\lambda_2)$.\n- Benjamini–Hochberg (BH) procedure to control the expected proportion of false discoveries (False Discovery Rate (FDR)) at target level $q$.\n\nInputs per test case:\n- A cohort of $S$ tumor samples and $G$ genes.\n- A vector of sample-specific background per-base mutation rates $\\mu = [\\mu_1, \\ldots, \\mu_S]$, where $\\mu_s$ is the expected neutral mutation probability per callable base for sample $s$.\n- A matrix of callable bases $C \\in \\mathbb{R}^{G \\times S}$, where $C_{g,s}$ is the number of callable coding bases for gene $g$ in sample $s$.\n- A vector of gene-specific mutability modifiers $r = [r_1, \\ldots, r_G]$ that multiplicatively adjust expected mutations for gene-level features (for example, nucleotide context or replication timing).\n- A vector of observed mutation counts per gene $M = [M_1, \\ldots, M_G]$ across the cohort.\n\nNull model and testing:\n- Under neutrality and independence across samples, for each gene $g$ define the expected mutation count\n$$\nE_g \\;=\\; r_g \\sum_{s=1}^{S} C_{g,s} \\,\\mu_s \\, .\n$$\n- The total observed mutation count $X_g$ under the null is modeled as\n$$\nX_g \\sim \\mathrm{Poisson}(E_g) \\, .\n$$\n- Compute a one-sided $p$-value for enrichment as\n$$\np_g \\;=\\; \\mathbb{P}\\!\\left( X_g \\ge M_g \\,\\middle|\\, X_g \\sim \\mathrm{Poisson}(E_g) \\right) \\, .\n$$\n- Special case: if $E_g = 0$, define $p_g = 1$ when $M_g = 0$, and $p_g = 0$ when $M_g \\ge 1$.\n\nMultiple testing:\n- Apply the Benjamini–Hochberg procedure at level $q = 0.1$ to the set $\\{p_g\\}_{g=1}^{G}$:\n  1. Sort the $p$-values in ascending order to obtain $p_{(1)} \\le \\cdots \\le p_{(m)}$ where $m = G$ and let $p_{(i)}$ have index $j(i)$ in the original ordering.\n  2. Find the largest $k$ such that $p_{(k)} \\le \\frac{k}{m} q$.\n  3. Declare significant all genes with $p_g \\le p_{(k)}$. If no such $k$ exists, select none.\n- Report the indices of significant genes using zero-based indexing.\n\nYour program must implement the above procedure and run on the following test suite. For each test case, you must use the provided parameters exactly as given.\n\nTest Case $1$ (happy path with uneven coverage and a hypermutated sample):\n- $q = 0.1$.\n- $S = 5$, $G = 6$.\n- Sample rates $\\mu$:\n$$\n\\mu = [\\,1\\times 10^{-6},\\; 2\\times 10^{-6},\\; 5\\times 10^{-6},\\; 1\\times 10^{-6},\\; 1\\times 10^{-5}\\,] \\, .\n$$\n- Gene modifiers $r$:\n$$\nr = [\\,1.0,\\; 1.0,\\; 1.5,\\; 1.0,\\; 0.5,\\; 1.0\\,] \\, .\n$$\n- Callable bases matrix $C$ (rows are genes $g=0,\\ldots,5$, columns are samples $s=0,\\ldots,4$):\n$$\nC = \\begin{bmatrix}\n1500  1400  1600  1300  1500\\\\\n2000  2000  2000  2000  2000\\\\\n3000  1000  500   1500  2500\\\\\n0     0     0     0     0\\\\\n10000 10000 10000 10000 10000\\\\\n500   500   500   500   500\n\\end{bmatrix} \\, .\n$$\n- Observed counts $M$:\n$$\nM = [\\,3,\\; 0,\\; 1,\\; 0,\\; 0,\\; 1\\,] \\, .\n$$\n\nTest Case $2$ (boundary conditions, including genes with zero coverage and genes with extremely low expectation but one mutation):\n- $q = 0.1$.\n- $S = 3$, $G = 4$.\n- Sample rates $\\mu$:\n$$\n\\mu = [\\,1\\times 10^{-7},\\; 2\\times 10^{-7},\\; 1\\times 10^{-6}\\,] \\, .\n$$\n- Gene modifiers $r$:\n$$\nr = [\\,1.0,\\; 1.0,\\; 1.0,\\; 0.5\\,] \\, .\n$$\n- Callable bases matrix $C$:\n$$\nC = \\begin{bmatrix}\n0      0      0\\\\\n10     0      0\\\\\n100000 100000 100000\\\\\n5000   0      0\n\\end{bmatrix} \\, .\n$$\n- Observed counts $M$:\n$$\nM = [\\,0,\\; 1,\\; 0,\\; 0\\,] \\, .\n$$\n\nTest Case $3$ (hypermutated sample and nonuniform coverage across samples):\n- $q = 0.1$.\n- $S = 4$, $G = 5$.\n- Sample rates $\\mu$:\n$$\n\\mu = [\\,3\\times 10^{-6},\\; 3\\times 10^{-6},\\; 3\\times 10^{-6},\\; 5\\times 10^{-5}\\,] \\, .\n$$\n- Gene modifiers $r$:\n$$\nr = [\\,1.0,\\; 1.0,\\; 1.0,\\; 1.0,\\; 10.0\\,] \\, .\n$$\n- Callable bases matrix $C$:\n$$\nC = \\begin{bmatrix}\n2000  2000  2000  2000\\\\\n5000  5000  5000  5000\\\\\n50000 50000 50000 50000\\\\\n10000 10000 10000 0\\\\\n2000  2000  2000  2000\n\\end{bmatrix} \\, .\n$$\n- Observed counts $M$:\n$$\nM = [\\,0,\\; 4,\\; 3,\\; 2,\\; 0\\,] \\, .\n$$\n\nComputation and reporting requirements:\n- For each test case, compute $E_g$, then $p_g$, then apply the Benjamini–Hochberg procedure at $q=0.1$ to select significant genes. Use zero-based indices for genes.\n- Your program should produce a single line of output containing the results for all test cases as a comma-separated list of lists of integers, enclosed in square brackets, with no spaces. For example, if the three results are the lists $[\\,0,2,5\\,]$, $[\\,1\\,]$, and $[\\,1,3\\,]$, the exact output should be\n\"[ [0,2,5],[1],[1,3] ]\" but with no spaces, i.e.,\n$$\n[\\,[0,2,5],[1],[1,3]\\,] \\, .\n$$\nYour program must print exactly one line in that format.", "solution": "The problem statement is a valid and well-posed task in computational statistics and bioinformatics. It requires the implementation of a standard statistical model for identifying genes under positive selection in a cancer cohort. All necessary parameters and mathematical procedures are provided without ambiguity or contradiction. The model is scientifically grounded in established principles of population genetics and statistics. It is formalizable, verifiable, and free of subjective content. I will proceed with a solution.\n\nThe objective is to identify genes that harbor a statistically significant excess of somatic mutations compared to a background model of neutral mutagenesis. This procedure is executed for several test cases, and the indices of significant genes are reported. The process involves three primary stages:\n$1$. Calculation of expected mutation counts under the null model.\n$2$. Statistical testing via the Poisson distribution to derive a $p$-value for each gene.\n$3$. Multiple hypothesis test correction using the Benjamini-Hochberg procedure to control the False Discovery Rate.\n\nI shall detail each stage of the algorithm.\n\n**Stage 1: Calculation of Expected Mutation Counts ($E_g$)**\n\nThe null hypothesis posits that mutations arise neutrally across the genome. The expected number of mutations in a gene $g$, denoted $E_g$, is determined by the gene's size, its intrinsic mutability, and the background mutation rates of the samples in the cohort.\n\nGiven:\n- A cohort of $S$ samples and $G$ genes.\n- A vector of sample-specific per-base mutation rates, $\\mu = [\\mu_1, \\ldots, \\mu_S]$.\n- A matrix of callable coding bases, $C \\in \\mathbb{R}^{G \\times S}$, where $C_{g,s}$ is the number of bases available for mutation in gene $g$ for sample $s$.\n- A vector of gene-specific mutability modifiers, $r = [r_1, \\ldots, r_G]$.\n\nFor a single gene $g$ in a single sample $s$, the expected number of mutations is the product of the number of callable bases, the sample-specific mutation rate, and the gene-specific modifier: $r_g C_{g,s} \\mu_s$.\n\nThe problem is based on the principle that mutation events are independent across samples. This allows us to leverage the additivity property of expectations (and of Poisson variables, as will be used later). The total expected mutation count for gene $g$ across all $S$ samples is the sum of the expectations from each sample:\n$$\nE_g = r_g \\sum_{s=1}^{S} C_{g,s} \\mu_s\n$$\nThis calculation is performed for every gene $g \\in \\{1, \\ldots, G\\}$. In matrix notation, letting $\\mu$ be a column vector, this computation is equivalent to the element-wise product of the vector $r$ and the result of the matrix-vector product $C\\mu$.\n\n**Stage 2: P-value Calculation**\n\nThe problem states that under the null hypothesis, the observed number of mutations in a gene, $X_g$, follows a Poisson distribution with a rate parameter equal to the expected count, $E_g$. That is, $X_g \\sim \\mathrm{Poisson}(E_g)$. This is justified by the law of rare events, as mutations are sparse events along the DNA sequence.\n\nWe are given the vector of observed mutation counts, $M = [M_1, \\ldots, M_G]$. For each gene $g$, we test for an enrichment of mutations by computing a one-sided $p$-value. The $p$-value, $p_g$, is the probability of observing at least $M_g$ mutations under the null distribution:\n$$\np_g = \\mathbb{P}(X_g \\ge M_g \\,|\\, X_g \\sim \\mathrm{Poisson}(E_g))\n$$\nThis probability is computed using the survival function (SF) of the Poisson distribution. The survival function is defined as $\\mathrm{SF}(k-1, \\lambda) = \\mathbb{P}(X \\ge k \\text{ for } X \\sim \\mathrm{Poisson}(\\lambda))$.\n\nTwo special cases are defined:\n- If $E_g > 0$: $p_g = \\sum_{k=M_g}^{\\infty} \\frac{e^{-E_g} E_g^k}{k!}$.\n- If $E_g = 0$: The probability of observing any mutations is $0$. Therefore, if $M_g=0$, the observation is perfectly consistent with the expectation, and $p_g=1$. If $M_g > 0$, the observation is impossible under the null model, representing an extreme deviation, so $p_g=0$.\n\n**Stage 3: Multiple Hypothesis Test Correction**\n\nWhen performing many statistical tests simultaneously (one for each of the $G$ genes), a correction for multiple comparisons is required to avoid an inflated number of false positives. The problem mandates the use of the Benjamini-Hochberg (BH) procedure to control the False Discovery Rate (FDR) at a level $q = 0.1$. The FDR is the expected proportion of rejected null hypotheses that are falsely rejected.\n\nThe BH procedure is as follows:\n$1$. Collect the $p$-values for all $G$ genes: $\\{p_1, p_2, \\ldots, p_G\\}$. Let $m=G$.\n$2$. Sort these $p$-values in ascending order: $p_{(1)} \\le p_{(2)} \\le \\cdots \\le p_{(m)}$. Let the gene with $p$-value $p_{(i)}$ have the original index $j(i)$.\n$3$. Find the largest integer $k \\in \\{1, \\ldots, m\\}$ such that the sorted $p$-value $p_{(k)}$ satisfies the condition:\n$$\np_{(k)} \\le \\frac{k}{m} q\n$$\n$4$. If such a $k$ exists, all genes with raw $p$-values less than or equal to the threshold $p_{(k)}$ are declared statistically significant. That is, we identify all genes $g$ such that $p_g \\le p_{(k)}$.\n$5$. If no such $k$ exists (i.e., $p_{(i)} > \\frac{i}{m} q$ for all $i$), then no genes are declared significant.\n\nThe final output for each test case is a list of the zero-based indices of the genes that are declared significant by this procedure. The lists from all test cases are then aggregated into a single list of lists.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.stats import poisson\n\ndef solve():\n    \"\"\"\n    Main function to run the statistical analysis for all test cases.\n    \"\"\"\n    \n    test_cases = [\n        {\n            \"q\": 0.1,\n            \"S\": 5, \"G\": 6,\n            \"mu\": np.array([1e-6, 2e-6, 5e-6, 1e-6, 1e-5]),\n            \"r\": np.array([1.0, 1.0, 1.5, 1.0, 0.5, 1.0]),\n            \"C\": np.array([\n                [1500, 1400, 1600, 1300, 1500],\n                [2000, 2000, 2000, 2000, 2000],\n                [3000, 1000, 500,  1500, 2500],\n                [0,    0,    0,    0,    0],\n                [10000, 10000, 10000, 10000, 10000],\n                [500,  500,  500,  500,  500]\n            ]),\n            \"M\": np.array([3, 0, 1, 0, 0, 1])\n        },\n        {\n            \"q\": 0.1,\n            \"S\": 3, \"G\": 4,\n            \"mu\": np.array([1e-7, 2e-7, 1e-6]),\n            \"r\": np.array([1.0, 1.0, 1.0, 0.5]),\n            \"C\": np.array([\n                [0,     0,     0],\n                [10,    0,     0],\n                [100000, 100000, 100000],\n                [5000,  0,     0]\n            ]),\n            \"M\": np.array([0, 1, 0, 0])\n        },\n        {\n            \"q\": 0.1,\n            \"S\": 4, \"G\": 5,\n            \"mu\": np.array([3e-6, 3e-6, 3e-6, 5e-5]),\n            \"r\": np.array([1.0, 1.0, 1.0, 1.0, 10.0]),\n            \"C\": np.array([\n                [2000, 2000, 2000, 2000],\n                [5000, 5000, 5000, 5000],\n                [50000, 50000, 50000, 50000],\n                [10000, 10000, 10000, 0],\n                [2000, 2000, 2000, 2000]\n            ]),\n            \"M\": np.array([0, 4, 3, 2, 0])\n        }\n    ]\n\n    all_results = []\n\n    for case in test_cases:\n        # Unpack variables for the current test case\n        q = case[\"q\"]\n        G = case[\"G\"]\n        mu = case[\"mu\"]\n        r = case[\"r\"]\n        C = case[\"C\"]\n        M = case[\"M\"]\n\n        # Stage 1: Calculate expected mutation counts E_g\n        # E_g = r_g * sum_s(C_gs * mu_s)\n        # In NumPy, this is effectively an element-wise multiplication of r with the matrix-vector product C @ mu.\n        expected_counts = r * (C @ mu)\n\n        # Stage 2: P-value Calculation\n        p_values = np.zeros(G)\n        for g in range(G):\n            E_g = expected_counts[g]\n            M_g = M[g]\n\n            if E_g == 0:\n                p_values[g] = 1.0 if M_g == 0 else 0.0\n            else:\n                # P(X = M_g) = 1 - P(X  M_g) = 1 - CDF(M_g - 1)\n                # This is computed by the survival function sf(M_g - 1)\n                if M_g == 0:\n                    p_values[g] = 1.0 # P(X = 0) is always 1\n                else:\n                    p_values[g] = poisson.sf(M_g - 1, E_g)\n\n        # Stage 3: Multiple Hypothesis Test Correction (Benjamini-Hochberg)\n        m = G\n        # Sort p-values while keeping track of original indices\n        sorted_indices = np.argsort(p_values)\n        sorted_p_values = p_values[sorted_indices]\n        \n        # Calculate the Benjamini-Hochberg critical values\n        # For each sorted p-value p_(k), the threshold is (k/m)*q\n        ranks = np.arange(1, m + 1)\n        bh_thresholds = (ranks / m) * q\n\n        # Find p-values that are below their corresponding BH threshold\n        significant_mask = sorted_p_values = bh_thresholds\n\n        significant_indices = []\n        if np.any(significant_mask):\n            # Find the largest k for which p_(k) = (k/m)*q\n            # This rank determines the p-value cutoff.\n            # All ranks less than or equal to max_k are also significant.\n            max_k_rank = np.max(ranks[significant_mask])\n            p_value_cutoff = sorted_p_values[max_k_rank - 1] # -1 for 0-based index\n            \n            # Select all genes with original p-values less than or equal to this cutoff\n            # The result of np.where is a tuple, we need the first element.\n            significant_indices_array = np.where(p_values = p_value_cutoff)[0]\n            significant_indices = sorted(significant_indices_array.tolist())\n        \n        all_results.append(significant_indices)\n    \n    # Final print statement in the exact required format.\n    # [ [idx1,idx2,...],[idxA,...],... ] - \"[[idx1,idx2,...],[idxA,...],...]\"\n    result_str = \",\".join([str(res) for res in all_results])\n    result_str = result_str.replace(\" \", \"\")\n    print(f\"[{result_str}]\")\n\nsolve()\n```", "id": "2858052"}]}