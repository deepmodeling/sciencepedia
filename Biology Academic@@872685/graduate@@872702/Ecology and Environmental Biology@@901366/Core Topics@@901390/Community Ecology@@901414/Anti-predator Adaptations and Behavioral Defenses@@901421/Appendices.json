{"hands_on_practices": [{"introduction": "Many anti-predator decisions involve a trade-off between safety and other essential activities like foraging. This exercise introduces one of the most fundamental models in behavioral ecology, which treats the decision of when to flee from an approaching predator as an economic optimization problem. By balancing the costs and benefits of flight, you will derive the optimal flight initiation distance, a cornerstone concept for understanding animal risk management [@problem_id:2471613].", "problem": "A prey animal decides when to initiate flight as a predator approaches. Let the decision variable be the flight initiation distance $d \\ge 0$ at which the prey flees. Assume that the probability that the predator successfully captures the prey if the prey waits until distance $d$ is $P(d) = \\exp(-k d)$ with $k>0$, and that the cost of fleeing is a linear function $C_{f}(d) = c d$ with $c>0$. Let $C_{p}>0$ denote the fitness-equivalent cost of being captured.\n\nUsing the decision-theoretic principle that the prey minimizes expected total cost, model the prey’s objective as minimizing $J(d) = C_{p} P(d) + C_{f}(d)$ subject to $d \\ge 0$. Starting from this formulation, derive the optimality condition, solve for the optimal flight initiation distance $d^{*}$, and determine the parameter constraints under which an interior optimum with $d^{*} > 0$ exists. Provide $d^{*}$ as a single closed-form analytic expression in terms of $k$, $c$, and $C_{p}$. Do not include any units in your final expression.", "solution": "The problem statement is subjected to validation.\n\n**Step 1: Extract Givens**\n- Decision variable: Flight initiation distance, $d$, with domain $d \\ge 0$.\n- Probability of predator capture: $P(d) = \\exp(-k d)$. Parameter $k > 0$.\n- Cost of fleeing: $C_{f}(d) = c d$. Parameter $c > 0$.\n- Cost of being captured: $C_{p}$. Parameter $C_{p} > 0$.\n- Objective function to be minimized: $J(d) = C_{p} P(d) + C_{f}(d)$.\n- Explicit formulation of the objective function: $J(d) = C_{p} \\exp(-k d) + c d$.\n- Task: Find the optimal flight initiation distance $d^{*}$ that minimizes $J(d)$ subject to $d \\ge 0$, and determine the parameter constraints for which $d^{*} > 0$.\n\n**Step 2: Validate Using Extracted Givens**\n- **Scientific Grounding**: The model is a foundational example of optimal escape theory in behavioral ecology, a subfield of biology. It utilizes decision theory to model animal behavior, which is a standard and scientifically sound approach. The functional forms for probability and cost are common and reasonable simplifications. The problem is scientifically grounded.\n- **Well-Posedness**: The problem is a well-posed, one-dimensional constrained optimization problem. The objective function is continuous and twice-differentiable. A minimum exists and can be found using calculus.\n- **Objectivity**: The problem is stated using precise mathematical language, free from subjective or ambiguous terms.\n- **Other Flaws**: The problem is self-contained, consistent, and does not violate any principles of mathematics or science. It is not trivial and requires a rigorous analytical derivation.\n\n**Step 3: Verdict and Action**\nThe problem is valid. A complete solution will be provided.\n\nThe task is to find the value of $d$ that minimizes the total expected cost function\n$$J(d) = C_{p} \\exp(-k d) + c d$$\nsubject to the physical constraint that the flight initiation distance cannot be negative, i.e., $d \\ge 0$. The parameters $C_{p}$, $c$, and $k$ are all positive constants.\n\nThis is a problem of constrained optimization. We will first find the critical points of the function $J(d)$ by finding where its derivative with respect to $d$ equals zero. Then, we will use the second derivative test to confirm that this critical point corresponds to a local minimum. Finally, we will incorporate the constraint $d \\ge 0$ to find the global minimum on the feasible domain.\n\nThe first derivative of the objective function $J(d)$ with respect to $d$ is:\n$$\\frac{dJ}{dd} = \\frac{d}{dd} \\left( C_{p} \\exp(-k d) + c d \\right) = -k C_{p} \\exp(-k d) + c$$\nAn interior extremum, if one exists, must satisfy the first-order condition $\\frac{dJ}{dd} = 0$.\n$$-k C_{p} \\exp(-k d) + c = 0$$\nSolving for $d$, we find the critical point, which we denote as $d_{\\text{crit}}$:\n$$k C_{p} \\exp(-k d_{\\text{crit}}) = c$$\n$$\\exp(-k d_{\\text{crit}}) = \\frac{c}{k C_{p}}$$\nTaking the natural logarithm of both sides:\n$$-k d_{\\text{crit}} = \\ln\\left(\\frac{c}{k C_{p}}\\right)$$\n$$d_{\\text{crit}} = -\\frac{1}{k} \\ln\\left(\\frac{c}{k C_{p}}\\right) = \\frac{1}{k} \\ln\\left(\\left(\\frac{c}{k C_{p}}\\right)^{-1}\\right)$$\n$$d_{\\text{crit}} = \\frac{1}{k} \\ln\\left(\\frac{k C_{p}}{c}\\right)$$\nTo determine the nature of this critical point, we compute the second derivative of $J(d)$:\n$$\\frac{d^2J}{dd^2} = \\frac{d}{dd} \\left( -k C_{p} \\exp(-k d) + c \\right) = (-k) \\left( -k C_{p} \\exp(-k d) \\right) = k^{2} C_{p} \\exp(-k d)$$\nGiven that $k > 0$ and $C_{p} > 0$, it follows that $k^{2} > 0$. The exponential term $\\exp(-k d)$ is strictly positive for all real $d$. Therefore,\n$$\\frac{d^2J}{dd^2} > 0$$\nfor all $d$. This indicates that the function $J(d)$ is strictly convex. A strictly convex function has at most one global minimum. If a critical point exists, it is the unique global minimum of the unconstrained function.\n\nNow, we must consider the constraint $d \\ge 0$. The optimal flight distance $d^{*}$ is the value of $d$ in the interval $[0, \\infty)$ that minimizes $J(d)$.\nThe problem asks for the condition under which an interior optimum with $d^{*} > 0$ exists. This occurs if and only if our derived critical point $d_{\\text{crit}}$ lies within the feasible region and is positive.\n$$d_{\\text{crit}} > 0$$\n$$\\frac{1}{k} \\ln\\left(\\frac{k C_{p}}{c}\\right) > 0$$\nSince $k > 0$, this inequality holds if and only if the argument of the natural logarithm is greater than $1$:\n$$\\ln\\left(\\frac{k C_{p}}{c}\\right) > 0 \\implies \\frac{k C_{p}}{c} > \\exp(0) = 1$$\n$$k C_{p} > c$$\nThis is the condition required for an interior optimum to exist. If this condition is met, the optimal flight initiation distance is $d^{*} = d_{\\text{crit}}$. The interpretation is that an interior solution exists if the initial risk-related term, $k C_{p}$ (which can be seen as the marginal benefit of fleeing at $d=0$), exceeds the constant marginal cost of fleeing, $c$.\n\nIf $k C_{p} \\le c$, then $\\frac{k C_{p}}{c} \\le 1$, which implies $\\ln\\left(\\frac{k C_{p}}{c}\\right) \\le 0$, and thus $d_{\\text{crit}} \\le 0$. Since $J(d)$ is convex, and its minimum occurs at a non-positive value of $d$, the function must be non-decreasing over the feasible region $d \\ge 0$. Specifically, for any $d \\ge 0$, $\\exp(-kd) \\le 1$, so $\\frac{dJ}{dd} = c - k C_{p} \\exp(-kd) \\ge c - k C_{p} \\ge 0$. The minimum of a non-decreasing function on an interval occurs at its left boundary. Therefore, if $k C_{p} \\le c$, the optimum is a corner solution at $d^{*} = 0$.\n\nThe problem requires the expression for the optimal distance $d^{*}$ under the parameter constraints that yield an interior optimum ($d^{*} > 0$). This corresponds to the case where $k C_{p} > c$. The optimal flight initiation distance is thus given by the expression for $d_{\\text{crit}}$.\n$$d^{*} = \\frac{1}{k} \\ln\\left(\\frac{k C_{p}}{c}\\right)$$\nThis expression provides the optimal flight initiation distance as a closed-form analytic solution in terms of the given parameters $k$, $c$, and $C_{p}$.", "answer": "$$\\boxed{\\frac{1}{k}\\ln\\left(\\frac{kC_{p}}{c}\\right)}$$", "id": "2471613"}, {"introduction": "While individual decisions are crucial, many anti-predator defenses operate at the group level. This practice explores the classic trade-off of group living: the safety-in-numbers 'dilution effect' versus the increased conspicuousness 'encounter effect'. You will model how per capita predation risk scales with group size, providing a quantitative foundation for understanding the costs and benefits of sociality [@problem_id:2471600].", "problem": "Group living can reduce individual predation risk via the dilution effect, but predator encounter rates may also increase with group size due to elevated detectability. Consider a prey group of size $N$ subject to predator attack events that arrive as a Poisson process with group-level rate $\\Lambda(N)$ (events per unit time). Conditional on an attack event, the predator targets exactly one prey chosen uniformly at random from the $N$ group members, and attack events within an infinitesimal interval are independent.\n\n(a) Using the definition of the instantaneous hazard of an event for an individual as the limit of the event probability per unit time as the interval shrinks to zero, derive the per capita instantaneous hazard of being attacked, $h(N)$, as a function of $\\Lambda(N)$ and $N$.\n\n(b) Now suppose the attack arrival rate scales with group size as $\\Lambda(N) = \\lambda_{0} N^{\\alpha}$ for constants $\\lambda_{0} > 0$ and real $\\alpha$, reflecting increased predator attraction with group size when $\\alpha > 0$. Define the elasticity of per capita attack hazard with respect to group size as $E(N) \\equiv \\frac{d \\ln h(N)}{d \\ln N}$. Derive a closed-form expression for $E(N)$ in terms of $\\alpha$ only.\n\nYour final answer must be the symbolic expression for $E(N)$, and it must be given as a single closed-form expression. No numerical evaluation is required. Since $E(N)$ is dimensionless, no units are needed in your final expression.", "solution": "The problem statement requires the derivation of an expression for the elasticity of per capita attack hazard with respect to group size. This is a two-part problem. First, the per capita instantaneous hazard, $h(N)$, must be derived from fundamental principles of probability theory as applied to a Poisson process. Second, this result is used to calculate the defined elasticity, $E(N)$.\n\nPart (a): Derivation of the per capita instantaneous hazard, $h(N)$.\nThe problem defines the arrival of predator attacks on a group of size $N$ as a Poisson process with a group-level rate $\\Lambda(N)$. For an infinitesimally small time interval $\\Delta t$, the probability of a single attack event occurring is given by $\\Lambda(N) \\Delta t + o(\\Delta t)$, where $o(\\Delta t)$ represents higher-order terms that become negligible as $\\Delta t \\to 0$.\n\nWe are interested in the risk for a single, specific individual within the group. For this individual to be attacked, two sequential conditions must be satisfied:\n1.  An attack must occur on the group. The probability of this event in the interval $\\Delta t$ is approximately $P_{\\text{group attack}} \\approx \\Lambda(N) \\Delta t$.\n2.  Conditional on an attack on the group, the predator must select that specific individual. The problem states this choice is made uniformly at random from the $N$ group members. The probability of any particular individual being chosen is therefore $P_{\\text{choice | group attack}} = \\frac{1}{N}$.\n\nThe probability that a focal individual is attacked during the interval $\\Delta t$, denoted $P_{\\text{indiv}}(\\Delta t)$, is the product of the probabilities of these two events:\n$$P_{\\text{indiv}}(\\Delta t) = P_{\\text{group attack}} \\times P_{\\text{choice | group attack}} \\approx (\\Lambda(N) \\Delta t) \\left( \\frac{1}{N} \\right)$$\nThe instantaneous hazard rate for an event, $h(N)$, is defined as the probability of the event per unit time, in the limit as the time interval approaches zero. Formally:\n$$h(N) \\equiv \\lim_{\\Delta t \\to 0} \\frac{P_{\\text{indiv}}(\\Delta t)}{\\Delta t}$$\nSubstituting the expression for $P_{\\text{indiv}}(\\Delta t)$ into this definition yields:\n$$h(N) = \\lim_{\\Delta t \\to 0} \\frac{(\\Lambda(N) \\Delta t) / N}{\\Delta t} = \\frac{\\Lambda(N)}{N}$$\nThis expression for the per capita instantaneous hazard $h(N)$ is a logical consequence of the problem setup, representing the total risk to the group, $\\Lambda(N)$, being distributed among its $N$ members.\n\nPart (b): Derivation of the elasticity, $E(N)$.\nThe problem specifies a power-law relationship between the group attack rate and group size: $\\Lambda(N) = \\lambda_{0} N^{\\alpha}$, for constants $\\lambda_{0} > 0$ and $\\alpha$. We substitute this functional form into our derived expression for $h(N)$:\n$$h(N) = \\frac{\\lambda_{0} N^{\\alpha}}{N} = \\lambda_{0} N^{\\alpha - 1}$$\nThe elasticity of $h(N)$ with respect to $N$ is defined as $E(N) \\equiv \\frac{d \\ln h(N)}{d \\ln N}$. This is a standard measure of the proportional sensitivity of one variable to another. To compute this, we first find the natural logarithm of $h(N)$:\n$$\\ln(h(N)) = \\ln(\\lambda_{0} N^{\\alpha - 1})$$\nUsing the properties of the logarithm, we can expand this expression:\n$$\\ln(h(N)) = \\ln(\\lambda_{0}) + \\ln(N^{\\alpha - 1})$$\n$$\\ln(h(N)) = \\ln(\\lambda_{0}) + (\\alpha - 1) \\ln(N)$$\nTo compute the derivative with respect to $\\ln(N)$, it is convenient to perform a change of variables. Let $y = \\ln(h(N))$ and $x = \\ln(N)$. The expression becomes:\n$$y = \\ln(\\lambda_{0}) + (\\alpha - 1) x$$\nThe elasticity $E(N)$ is simply the derivative $\\frac{dy}{dx}$:\n$$E(N) = \\frac{d}{dx} \\left[ \\ln(\\lambda_{0}) + (\\alpha - 1) x \\right]$$\nSince $\\lambda_{0}$ and $\\alpha$ are constants, the term $\\ln(\\lambda_{0})$ is also a constant, and its derivative is $0$. The derivative of $(\\alpha - 1)x$ with respect to $x$ is the constant coefficient $(\\alpha - 1)$.\n$$E(N) = 0 + (\\alpha - 1) \\times 1$$\n$$E(N) = \\alpha - 1$$\nThe elasticity is a constant value, $\\alpha - 1$, which depends only on the scaling exponent of the predator encounter rate, as required. This result quantifies the trade-off between the dilution effect (which always contributes a $-1$ to the exponent of per capita risk) and the group size-dependent encounter rate (which contributes an $\\alpha$).", "answer": "$$\\boxed{\\alpha - 1}$$", "id": "2471600"}, {"introduction": "To truly understand anti-predator adaptations, theoretical models must be connected to empirical data. This advanced practice guides you through a complete computational ecology workflow, from simulating the collective motion of a prey school to analyzing how its kinematic properties influence predator success. This exercise demonstrates how to quantify the 'confusion effect' and provides invaluable hands-on experience in the methods used to bridge theory and data in modern behavioral research [@problem_id:2471575].", "problem": "You are given a formalized, deterministic procedure that transforms schooling-prey trajectory parameters into kinematic predictors, and a statistical framework to quantify the confusion effect by regressing predator success on those predictors. Your task is to implement this end-to-end pipeline, using only the rules, definitions, and parameter values provided below, and to output a single, aggregated result line.\n\nProblem context and foundational base:\n- Kinematics and positions: For individual prey indexed by $i \\in \\{0,\\dots,n-1\\}$ and discrete times $t \\in \\{0,\\dots,T-1\\}$ with fixed time-step $\\Delta t$, positions are $\\mathbf{x}_{i,t} \\in \\mathbb{R}^2$, velocities are $\\mathbf{v}_{i,t} \\in \\mathbb{R}^2$, and speeds are $s_{i,t} = \\lVert \\mathbf{v}_{i,t} \\rVert$. All distances shall be expressed in meters, all times in seconds, and all velocities in meters per second.\n- Group-level kinematic predictors: From the per-time and per-individual velocities and positions, compute the following event-level predictors:\n  1. Nearest-neighbor distance (time-averaged): For each time $t$, compute $d_{i,t} = \\min_{j \\ne i} \\lVert \\mathbf{x}_{i,t} - \\mathbf{x}_{j,t} \\rVert$, then $\\text{NND}_t = \\frac{1}{n} \\sum_{i=0}^{n-1} d_{i,t}$, and finally $\\text{NND} = \\frac{1}{T} \\sum_{t=0}^{T-1} \\text{NND}_t$. The unit of $\\text{NND}$ is meters.\n  2. Polarization (time-averaged): For each time $t$, define unit-velocity vectors $\\mathbf{u}_{i,t} = \\mathbf{v}_{i,t} / \\lVert \\mathbf{v}_{i,t} \\rVert$ when $\\lVert \\mathbf{v}_{i,t} \\rVert > 0$ and $\\mathbf{u}_{i,t} = \\mathbf{0}$ if $\\lVert \\mathbf{v}_{i,t} \\rVert = 0$. Let $\\mathbf{m}_t = \\frac{1}{n} \\sum_{i=0}^{n-1} \\mathbf{u}_{i,t}$ and $p_t = \\lVert \\mathbf{m}_t \\rVert$. Then $\\text{Pol} = \\frac{1}{T} \\sum_{t=0}^{T-1} p_t$. The polarization $\\text{Pol}$ is dimensionless and satisfies $0 \\le \\text{Pol} \\le 1$.\n  3. Speed variance (time-averaged): For each time $t$, let $\\bar{s}_t = \\frac{1}{n} \\sum_{i=0}^{n-1} s_{i,t}$ and $\\text{Var}_t = \\frac{1}{n} \\sum_{i=0}^{n-1} (s_{i,t} - \\bar{s}_t)^2$. Then $\\text{SV} = \\frac{1}{T} \\sum_{t=0}^{T-1} \\text{Var}_t$. The unit of $\\text{SV}$ is $(\\text{m}/\\text{s})^2$.\n\nTrajectory generation model (deterministic):\n- Global constants shared by all events: $T = 20$, $\\Delta t = 0.2\\,\\text{s}$, and a fixed group-direction base velocity $\\mathbf{g} = (0.6, 0.0)\\,\\text{m/s}$. Let $\\hat{\\mathbf{g}} = \\mathbf{g}/\\lVert \\mathbf{g} \\rVert$ and let $\\hat{\\mathbf{w}}$ be the unit vector obtained by rotating $\\hat{\\mathbf{g}}$ by $+90^\\circ$ in the plane (i.e., if $\\hat{\\mathbf{g}} = (g_x,g_y)$ then $\\hat{\\mathbf{w}} = (-g_y, g_x)$).\n- Event parameters: For each event $e$, you are given a tuple $(n_e, d_e, \\alpha_e, \\sigma_e)$ where $n_e$ is the number of individuals, $d_e$ is the grid spacing in meters, $\\alpha_e \\in [0,1]$ controls alignment (higher means more aligned with $\\mathbf{g}$), and $\\sigma_e \\ge 0$ controls within-group speed variability.\n- Initial positions: Place $n_e$ individuals on a centered, axis-aligned rectangular grid with spacing $d_e$. Let $r = \\lceil \\sqrt{n_e} \\rceil$ and $c = \\lceil n_e / r \\rceil$. For index $i \\in \\{0,\\dots,n_e-1\\}$, define the grid row $R_i = \\left\\lfloor i / c \\right\\rfloor$ and column $C_i = i \\bmod c$. The initial position is\n$$\n\\mathbf{x}_{i,0} = \\left( \\big(C_i - \\tfrac{c-1}{2}\\big) d_e,\\ \\big(R_i - \\tfrac{r-1}{2}\\big) d_e \\right).\n$$\n- Velocity field and motion update: For each time $t \\in \\{0,\\dots,T-1\\}$ and individual $i$, define the phase $\\phi_{i,t} = 2\\pi \\, t/T + i$. Let the instantaneous velocity be\n$$\n\\mathbf{v}_{i,t} = \\left( \\alpha_e \\mathbf{g} + (1-\\alpha_e)\\lVert \\mathbf{g} \\rVert \\sin(\\phi_{i,t}) \\, \\hat{\\mathbf{w}} \\right) \\cdot \\left( 1 + \\sigma_e \\cos(2\\phi_{i,t}) \\right),\n$$\nand update positions by explicit Euler integration,\n$$\n\\mathbf{x}_{i,t+1} = \\mathbf{x}_{i,t} + \\mathbf{v}_{i,t}\\, \\Delta t.\n$$\n\nStatistical model to quantify the confusion effect:\n- Let each event $e$ have a binary predator-attack outcome $y_e \\in \\{0,1\\}$, where $y_e = 1$ denotes a successful capture and $y_e = 0$ denotes failure. Model $y_e$ as Bernoulli with success probability\n$$\n\\pi_e = \\sigma(\\eta_e) = \\frac{1}{1 + \\exp(-\\eta_e)},\n$$\nwhere\n$$\n\\eta_e = \\beta_0 + \\beta_1 \\,\\text{NND}_e + \\beta_2 \\,\\text{Pol}_e + \\beta_3 \\,\\text{SV}_e.\n$$\nEstimate coefficients $\\boldsymbol{\\beta} = (\\beta_0,\\beta_1,\\beta_2,\\beta_3)^\\top$ by Maximum Likelihood Estimation (MLE) using Newton–Raphson on the concave log-likelihood\n$$\n\\ell(\\boldsymbol{\\beta}) = \\sum_{e} \\left( y_e \\log \\pi_e + (1-y_e) \\log (1-\\pi_e) \\right),\n$$\noptionally stabilized by a small ridge penalty $\\frac{\\lambda}{2} \\lVert \\mathbf{D} \\boldsymbol{\\beta} \\rVert_2^2$ with $\\mathbf{D} = \\mathrm{diag}(0,1,1,1)$ and $\\lambda > 0$ to avoid numerical singularity. Use the gradient $\\nabla \\ell(\\boldsymbol{\\beta}) = \\mathbf{X}^\\top (\\mathbf{y} - \\boldsymbol{\\pi})$ and the negative expected Hessian $\\mathbf{H} = \\mathbf{X}^\\top \\mathbf{W}\\mathbf{X}$ with $\\mathbf{W} = \\mathrm{diag}(\\pi_e (1-\\pi_e))$, incorporating the ridge terms where appropriate. Iterate until the parameter update has Euclidean norm below a small tolerance.\n\nYour tasks:\n1. For each training event below, generate trajectories via the deterministic procedure above, compute $\\text{NND}_e$ (in meters), $\\text{Pol}_e$ (dimensionless), and $\\text{SV}_e$ (in $(\\text{m}/\\text{s})^2$), and fit the logistic regression model by MLE to obtain $\\hat{\\boldsymbol{\\beta}}$.\n2. For each test event below, generate trajectories and compute its predictors, then compute the predicted success probability $\\hat{\\pi}_e = \\sigma(\\hat{\\beta}_0 + \\hat{\\beta}_1 \\,\\text{NND}_e + \\hat{\\beta}_2 \\,\\text{Pol}_e + \\hat{\\beta}_3 \\,\\text{SV}_e)$.\n3. Output the three predicted probabilities for the test events as a single line containing a Python-like list with exactly six digits after the decimal point for each value, e.g., $[\\hat{\\pi}_1,\\hat{\\pi}_2,\\hat{\\pi}_3]$. No other output is permitted.\n\nTraining events (each tuple is $(n_e, d_e, \\alpha_e, \\sigma_e; y_e)$):\n- $e=1$: $(12, 0.6, 0.9, 0.1; 0)$\n- $e=2$: $(12, 1.2, 0.2, 0.2; 1)$\n- $e=3$: $(8, 0.8, 0.7, 0.0; 0)$\n- $e=4$: $(15, 1.4, 0.1, 0.4; 1)$\n- $e=5$: $(10, 0.9, 0.5, 0.3; 0)$\n- $e=6$: $(6, 1.0, 0.0, 0.0; 1)$\n- $e=7$: $(20, 0.5, 0.8, 0.2; 0)$\n\nTest events (each tuple is $(n_e, d_e, \\alpha_e, \\sigma_e)$):\n- $\\text{Test A}$: $(12, 0.6, 1.0, 0.0)$\n- $\\text{Test B}$: $(2, 1.0, 0.0, 0.5)$\n- $\\text{Test C}$: $(10, 0.5, 0.1, 0.5)$\n\nAngle unit and units:\n- All angles in the trigonometric functions are in radians.\n- Distances are in meters, times in seconds, velocities in meters per second, and speed variance in $(\\text{m}/\\text{s})^2$.\n- The final predicted probabilities must be printed as decimals in $[0,1]$ with exactly six digits after the decimal point.\n\nFinal output format:\n- Your program should produce a single line of output containing the three predicted probabilities for the test events as a comma-separated list enclosed in square brackets, for example, $[0.123456,0.654321,0.500000]$.", "solution": "The problem requires the implementation of a multi-stage computational pipeline to model and predict predator success based on the kinematic properties of prey schools. The solution is structured into three sequential stages: first, a deterministic simulation of prey trajectories to compute kinematic predictors; second, the fitting of a statistical model to relate these predictors to observed outcomes; and third, the application of the fitted model to make predictions on new data.\n\n**Stage 1: Trajectory Simulation and Predictor Extraction**\n\nThe foundation of the analysis is a deterministic simulation of prey movement. For each event, characterized by parameters $(n_e, d_e, \\alpha_e, \\sigma_e)$, a simulation is run to generate trajectories and extract summary statistics.\n\nThe system consists of $n_e$ individuals, indexed by $i \\in \\{0, \\dots, n_e-1\\}$, simulated over $T=20$ discrete time steps, $t \\in \\{0, \\dots, T-1\\}$, with a step size of $\\Delta t=0.2\\,\\text{s}$.\n\nFirst, initial positions $\\mathbf{x}_{i,0}$ are established. Individuals are placed on a centered rectangular grid defined by $r = \\lceil \\sqrt{n_e} \\rceil$ rows and $c = \\lceil n_e / r \\rceil$ columns, with a spacing of $d_e$. The position for individual $i$ is given by:\n$$\n\\mathbf{x}_{i,0} = \\left( \\left(C_i - \\frac{c-1}{2}\\right) d_e, \\left(R_i - \\frac{r-1}{2}\\right) d_e \\right)\n$$\nwhere $R_i = \\lfloor i / c \\rfloor$ is the row index and $C_i = i \\pmod c$ is the column index.\n\nNext, the system's dynamics are simulated. In each time step $t$, the velocity vector $\\mathbf{v}_{i,t}$ for each individual $i$ is computed according to the formula:\n$$\n\\mathbf{v}_{i,t} = \\left( \\alpha_e \\mathbf{g} + (1-\\alpha_e)\\lVert \\mathbf{g} \\rVert \\sin(\\phi_{i,t}) \\, \\hat{\\mathbf{w}} \\right) \\cdot \\left( 1 + \\sigma_e \\cos(2\\phi_{i,t}) \\right)\n$$\nHere, $\\mathbf{g}=(0.6, 0.0)\\,\\text{m/s}$ is the base group velocity, $\\hat{\\mathbf{w}}=(0, 1)$ is a unit vector orthogonal to $\\mathbf{g}$, and $\\phi_{i,t} = 2\\pi t/T + i$ is a phase term that introduces individual variation. The parameters $\\alpha_e$ and $\\sigma_e$ control the degree of alignment with $\\mathbf{g}$ and the magnitude of speed pulsation, respectively. After computing all velocities for the current time step, the positions are updated using the explicit Euler integration method:\n$$\n\\mathbf{x}_{i,t+1} = \\mathbf{x}_{i,t} + \\mathbf{v}_{i,t} \\Delta t\n$$\nAt each time step $t$, three group-level kinematic predictors are calculated: the mean nearest-neighbor distance ($\\text{NND}_t$), the group polarization ($p_t$), and the speed variance ($\\text{SV}_t$, denoted as $\\text{Var}_t$ in the problem description for a single time step). These instantaneous values are then averaged over all $T$ time steps to produce the final event-level predictors: $\\text{NND}$, $\\text{Pol}$, and $\\text{SV}$. The computation adheres strictly to the provided definitions. For polarization, the case where speed $\\lVert \\mathbf{v}_{i,t} \\rVert = 0$ is handled by defining the corresponding unit velocity vector $\\mathbf{u}_{i,t}$ as $\\mathbf{0}$.\n\n**Stage 2: Statistical Model Fitting**\n\nThe relationship between the kinematic predictors and predator success is quantified using a logistic regression model. The binary outcome for each training event, $y_e \\in \\{0, 1\\}$, is modeled as a Bernoulli random variable with success probability $\\pi_e$. This probability is linked to the predictors via the logistic function:\n$$\n\\pi_e = \\sigma(\\eta_e) = \\frac{1}{1 + \\exp(-\\eta_e)}\n$$\nwhere the linear predictor $\\eta_e$ is a weighted sum of the kinematic variables:\n$$\n\\eta_e = \\beta_0 + \\beta_1 \\,\\text{NND}_e + \\beta_2 \\,\\text{Pol}_e + \\beta_3 \\,\\text{SV}_e\n$$\nThe coefficient vector $\\boldsymbol{\\beta} = (\\beta_0, \\beta_1, \\beta_2, \\beta_3)^\\top$ is estimated by maximizing the penalized log-likelihood function using the Newton-Raphson algorithm. The objective function is $L(\\boldsymbol{\\beta}) = \\ell(\\boldsymbol{\\beta}) - \\frac{\\lambda}{2} \\boldsymbol{\\beta}^\\top \\mathbf{D}^\\top \\mathbf{D} \\boldsymbol{\\beta}$, where $\\ell(\\boldsymbol{\\beta})$ is the standard log-likelihood for logistic regression. The ridge penalty term, with $\\mathbf{D}=\\mathrm{diag}(0,1,1,1)$ and a small regularization parameter $\\lambda > 0$, ensures the problem remains well-posed and the Hessian matrix is invertible, which can be an issue with small or separable datasets.\n\nThe Newton-Raphson update at iteration $k$ is $\\boldsymbol{\\beta}_{k+1} = \\boldsymbol{\\beta}_k + \\Delta\\boldsymbol{\\beta}_k$, where the update step $\\Delta\\boldsymbol{\\beta}_k$ is the solution to the linear system $\\mathbf{H}_{\\text{pen}} \\Delta\\boldsymbol{\\beta}_k = \\mathbf{g}_{\\text{pen}}$. The terms are:\n-   Penalized gradient: $\\mathbf{g}_{\\text{pen}} = \\mathbf{X}^\\top(\\mathbf{y} - \\boldsymbol{\\pi}) - \\lambda \\mathbf{D}^\\top\\mathbf{D}\\boldsymbol{\\beta}_k$, where $\\mathbf{X}$ is the design matrix with a leading column of ones.\n-   Penalized negative expected Hessian: $\\mathbf{H}_{\\text{pen}} = \\mathbf{X}^\\top\\mathbf{W}\\mathbf{X} + \\lambda\\mathbf{D}^\\top\\mathbf{D}$, where $\\mathbf{W}=\\mathrm{diag}(\\pi_e(1-\\pi_e))$.\n\nThe algorithm starts with an initial guess $\\boldsymbol{\\beta}_0 = \\mathbf{0}$ and iterates until the Euclidean norm of the update step, $\\lVert\\Delta\\boldsymbol{\\beta}_k\\rVert$, is smaller than a pre-defined tolerance (e.g., $10^{-8}$).\n\n**Stage 3: Prediction for Test Events**\n\nOnce the coefficient vector $\\hat{\\boldsymbol{\\beta}}$ has been estimated from the training data, it is used to predict the outcomes for the test events. For each test event, the kinematic predictors $(\\text{NND}_e, \\text{Pol}_e, \\text{SV}_e)$ are generated using the exact simulation procedure from Stage $1$. These predictors are then used to compute the linear predictor:\n$$\n\\hat{\\eta}_e = \\hat{\\beta}_0 + \\hat{\\beta}_1\\text{NND}_e + \\hat{\\beta}_2\\text{Pol}_e + \\hat{\\beta}_3\\text{SV}_e\n$$\nFinally, the estimated probability of a successful predator attack, $\\hat{\\pi}_e$, is calculated by applying the logistic function, $\\hat{\\pi}_e = \\sigma(\\hat{\\eta}_e)$. The resulting probabilities for the three specified test events are formatted to six decimal places and constitute the final output.", "answer": "[0.088194,0.957591,0.999661]", "id": "2471575"}]}