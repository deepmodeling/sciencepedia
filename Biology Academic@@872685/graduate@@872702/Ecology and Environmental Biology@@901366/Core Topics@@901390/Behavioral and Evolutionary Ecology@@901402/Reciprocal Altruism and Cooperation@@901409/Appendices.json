{"hands_on_practices": [{"introduction": "A core question in evolutionary biology is how cooperation can emerge and persist in a population of self-interested individuals. This practice provides a foundational tool for answering this question: the replicator equation. By modeling a population composed of \"Tit-for-Tat\" and \"Always Defect\" strategies, you will derive their expected fitness from pairwise interactions in a repeated Prisoner's Dilemma and see how these fitness differences drive evolutionary change. This exercise [@problem_id:2527577] is essential for understanding how micro-level interactions scale up to macro-level population dynamics, revealing the precise conditions under which cooperation can invade and stabilize.", "problem": "An infinitely large, well-mixed population is composed of two behavioral strategies that interact in pairwise, indefinitely repeated Prisoner’s Dilemma (PD) encounters with a geometric continuation probability $\\delta \\in (0,1)$. The one-shot PD has standard payoffs satisfying $T>R>P>S$, where $T$ is the temptation payoff, $R$ is the reward for mutual cooperation, $P$ is the punishment for mutual defection, and $S$ is the sucker’s payoff. Each repeated encounter yields a sequence of stage payoffs $\\{u_t\\}_{t=1}^{\\infty}$, and an individual’s fitness contribution from a single encounter is the geometrically weighted average payoff per stage,\n$$(1-\\delta)\\sum_{t=1}^{\\infty}\\delta^{t-1}u_t.$$\nThe two strategies are:\n- Tit-for-Tat (TFT): cooperate in the first round; thereafter, cooperate if the partner cooperated in the previous round, defect otherwise.\n- Always Defect (ALLD): defect in every round.\n\nLet $x \\in [0,1]$ denote the frequency of TFT in the population. Assume random matching and that fitness is equal to the expected weighted average payoff per encounter. The frequency dynamics follow the continuous-time replicator equation for two strategies.\n\nTask:\n1. Starting only from the definitions of the repeated-interaction payoff above and the replicator equation, derive the expected fitnesses of TFT and ALLD as functions of $x$, $\\delta$, and the PD payoffs $T,R,P,S$.\n2. Derive the replicator equation for $x$ and determine all fixed points in $[0,1]$.\n3. Analyze the local stability of the boundary fixed points and any interior fixed point in terms of $\\delta$ and the payoffs $T,R,P,S$, providing explicit conditions derived from first principles.\n4. Report, as your final answer, the closed-form expression for the interior fixed point frequency $x^{\\ast}$ (if it exists) as a function of $\\delta$, $T$, $R$, $P$, and $S$. Do not simplify to numerical values.\n\nYour final answer must be a single closed-form expression. No rounding is required.", "solution": "The problem statement is first subjected to validation.\n\nStep 1: Extract Givens\n- Population: Infinitely large, well-mixed.\n- Strategies: Tit-for-Tat (TFT) and Always Defect (ALLD).\n- Frequency of TFT: $x \\in [0,1]$.\n- Interaction: Pairwise, indefinitely repeated Prisoner’s Dilemma (PD).\n- Continuation probability: $\\delta \\in (0,1)$.\n- One-shot PD payoffs: $T>R>P>S$.\n- Fitness contribution from an encounter: $W = (1-\\delta)\\sum_{t=1}^{\\infty}\\delta^{t-1}u_t$, where $u_t$ is the payoff at stage $t$.\n- Dynamics: Continuous-time replicator equation for two strategies.\n\nStep 2: Validate Using Extracted Givens\nThe problem is a standard and fundamental model in evolutionary game theory, specifically concerning the evolution of cooperation.\n- **Scientifically Grounded**: The problem is based on the well-established framework of the replicator equation and repeated games, central to theoretical biology and economics. The Prisoner's Dilemma is a canonical model for studying cooperation. All premises are factually sound within this framework.\n- **Well-Posed**: The problem is clearly defined with all necessary parameters and equations. It is structured to admit a unique and stable solution under specified conditions.\n- **Objective**: The language is precise and devoid of any subjective or non-scientific claims. The tasks are analytical and require rigorous derivation.\n- The problem is self-contained, consistent, and does not contain any of the invalidating flaws listed in the instructions.\n\nStep 3: Verdict and Action\nThe problem is valid. A complete solution will be provided.\n\nThe solution proceeds by following the four tasks specified in the problem statement.\n\nTask 1: Derivation of Expected Fitnesses\nFirst, we determine the discounted payoffs for each possible pairwise encounter between the two strategies, TFT and ALLD. The fitness contribution is the geometrically weighted average payoff, calculated as $(1-\\delta)\\sum_{t=1}^{\\infty}\\delta^{t-1}u_t$.\n\n- **TFT vs. TFT**: Both individuals cooperate in the first round. Since the partner cooperated, both cooperate in the second round, and this continues indefinitely. The payoff sequence for each player is $\\{R, R, R, \\dots\\}$. The discounted payoff is:\n$$W(\\text{TFT} | \\text{TFT}) = (1-\\delta)\\sum_{t=1}^{\\infty}\\delta^{t-1}R = (1-\\delta)R \\left(\\frac{1}{1-\\delta}\\right) = R$$\n\n- **TFT vs. ALLD**: In the first round ($t=1$), TFT cooperates and ALLD defects. TFT receives the sucker's payoff $S$, and ALLD receives the temptation payoff $T$. For all subsequent rounds ($t \\ge 2$), TFT observes the defection from round $t-1$ and defects in response. ALLD continues to defect. Thus, both individuals defect from round $2$ onwards, receiving the punishment payoff $P$ in each of these rounds.\nThe payoff sequence for TFT is $\\{S, P, P, \\dots\\}$, and its discounted payoff is:\n$$W(\\text{TFT} | \\text{ALLD}) = (1-\\delta) \\left( S \\cdot \\delta^0 + \\sum_{t=2}^{\\infty} \\delta^{t-1}P \\right) = (1-\\delta) \\left( S + P \\frac{\\delta}{1-\\delta} \\right) = (1-\\delta)S + \\delta P$$\nThe payoff sequence for ALLD is $\\{T, P, P, \\dots\\}$, and its discounted payoff is:\n$$W(\\text{ALLD} | \\text{TFT}) = (1-\\delta) \\left( T \\cdot \\delta^0 + \\sum_{t=2}^{\\infty} \\delta^{t-1}P \\right) = (1-\\delta) \\left( T + P \\frac{\\delta}{1-\\delta} \\right) = (1-\\delta)T + \\delta P$$\n\n- **ALLD vs. ALLD**: Both individuals defect in every round, starting from the first. The payoff sequence for each is $\\{P, P, P, \\dots\\}$. The discounted payoff is:\n$$W(\\text{ALLD} | \\text{ALLD}) = (1-\\delta)\\sum_{t=1}^{\\infty}\\delta^{t-1}P = (1-\\delta)P \\left(\\frac{1}{1-\\delta}\\right) = P$$\n\nNow, we can write the expected fitness for each strategy, which is the average payoff over all possible encounters. Let $x$ be the frequency of TFT. A TFT individual encounters another TFT with probability $x$ and an ALLD with probability $1-x$.\n\nThe expected fitness of TFT, $W_{\\text{TFT}}(x)$, is:\n$$W_{\\text{TFT}}(x) = x \\cdot W(\\text{TFT} | \\text{TFT}) + (1-x) \\cdot W(\\text{TFT} | \\text{ALLD})$$\n$$W_{\\text{TFT}}(x) = xR + (1-x)((1-\\delta)S + \\delta P)$$\n\nThe expected fitness of ALLD, $W_{\\text{ALLD}}(x)$, is:\n$$W_{\\text{ALLD}}(x) = x \\cdot W(\\text{ALLD} | \\text{TFT}) + (1-x) \\cdot W(\\text{ALLD} | \\text{ALLD})$$\n$$W_{\\text{ALLD}}(x) = x((1-\\delta)T + \\delta P) + (1-x)P$$\n\nTask 2: Replicator Equation and Fixed Points\nThe continuous-time replicator equation for the frequency $x$ of the TFT strategy is given by:\n$$\\dot{x} = \\frac{dx}{dt} = x (W_{\\text{TFT}}(x) - \\bar{W}(x))$$\nwhere $\\bar{W}(x) = x W_{\\text{TFT}}(x) + (1-x) W_{\\text{ALLD}}(x)$ is the average fitness of the population. The equation can be simplified to:\n$$\\dot{x} = x(1-x) (W_{\\text{TFT}}(x) - W_{\\text{ALLD}}(x))$$\nLet's compute the fitness difference, $W_{\\text{TFT}}(x) - W_{\\text{ALLD}}(x)$:\n$$W_{\\text{TFT}}(x) - W_{\\text{ALLD}}(x) = [xR + (1-x)((1-\\delta)S + \\delta P)] - [x((1-\\delta)T + \\delta P) + (1-x)P]$$\nRearranging terms by powers of $x$:\n$$= x(R - ((1-\\delta)T + \\delta P)) - (1-x)(P - ((1-\\delta)S + \\delta P))$$\n$$= x(R - (1-\\delta)T - \\delta P) + (1-x)(-(P - (1-\\delta)S - \\delta P))$$\n$$= x(R - T + \\delta T - \\delta P) + (1-x)( (1-\\delta)S - (1-\\delta)P )$$\n$$= x(R - T + \\delta(T-P)) + (1-x)(S-P)(1-\\delta)$$\nExpanding this expression into a linear function of $x$:\n$$W_{\\text{TFT}}(x) - W_{\\text{ALLD}}(x) = x[R - T + \\delta(T-P) - (S-P)(1-\\delta)] + (S-P)(1-\\delta)$$\n$$= x[R - T + \\delta T - \\delta P - S + P + \\delta S - \\delta P] + (S-P)(1-\\delta)$$\n$$= x[R - T - S + P + \\delta(T+S-2P)] + (S-P)(1-\\delta)$$\nThe fixed points of the replicator dynamics are the values of $x \\in [0,1]$ for which $\\dot{x}=0$.\nFrom $\\dot{x} = x(1-x)(W_{\\text{TFT}}(x) - W_{\\text{ALLD}}(x)) = 0$, we identify three possible fixed points:\n1. $x = 0$: A monomorphic population of ALLD.\n2. $x = 1$: A monomorphic population of TFT.\n3. An interior fixed point $x^*$, where $W_{\\text{TFT}}(x^*) - W_{\\text{ALLD}}(x^*) = 0$.\nSetting the linear expression for the fitness difference to zero gives:\n$$x^*[R - T - S + P + \\delta(T+S-2P)] + (S-P)(1-\\delta) = 0$$\nSolving for $x^*$:\n$$x^* = -\\frac{(S-P)(1-\\delta)}{R - T - S + P + \\delta(T+S-2P)}$$\n$$x^* = \\frac{(P-S)(1-\\delta)}{R - T - S + P + \\delta(T+S-2P)}$$\nThis interior fixed point $x^*$ is biologically meaningful only if $x^* \\in (0,1)$.\n\nTask 3: Local Stability Analysis\nLet $f(x) = \\dot{x} = x(1-x) (W_{\\text{TFT}}(x) - W_{\\text{ALLD}}(x))$. The local stability of a fixed point $x_{fp}$ is determined by the sign of the derivative $f'(x_{fp})$. If $f'(x_{fp}) < 0$, the fixed point is locally stable. If $f'(x_{fp}) > 0$, it is unstable.\nLet $g(x) = W_{\\text{TFT}}(x) - W_{\\text{ALLD}}(x)$. Then $f(x) = x(1-x)g(x)$.\n$f'(x) = (1-2x)g(x) + x(1-x)g'(x)$.\n\n- Stability of $x=0$:\n$f'(0) = (1-0)g(0) + 0 = g(0) = W_{\\text{TFT}}(0) - W_{\\text{ALLD}}(0)$.\nAt $x=0$, $W_{\\text{TFT}}(0)=(1-\\delta)S+\\delta P$ and $W_{\\text{ALLD}}(0)=P$.\n$f'(0) = (1-\\delta)S+\\delta P - P = (1-\\delta)(S-P)$.\nGiven $P>S$ and $\\delta \\in (0,1)$, we have $S-P<0$ and $1-\\delta>0$. Thus, $f'(0) < 0$.\nThe fixed point $x=0$ is always locally stable.\n\n- Stability of $x=1$:\n$f'(1) = (1-2)g(1) + 0 = -g(1) = -(W_{\\text{TFT}}(1) - W_{\\text{ALLD}}(1))$.\nAt $x=1$, $W_{\\text{TFT}}(1)=R$ and $W_{\\text{ALLD}}(1)=(1-\\delta)T+\\delta P$.\n$f'(1) = -[R - ((1-\\delta)T+\\delta P)] = (1-\\delta)T+\\delta P - R$.\nThe fixed point $x=1$ is locally stable if $f'(1) < 0$, which requires:\n$$(1-\\delta)T+\\delta P - R < 0 \\implies R > (1-\\delta)T+\\delta P$$\nThis is the well-known condition for TFT to be an evolutionarily stable strategy (ESS) against ALLD. If the inequality is reversed, $x=1$ is unstable.\n\n- Stability of the interior fixed point $x^*$:\nFor $x^* \\in (0,1)$, it must be that $W_{\\text{TFT}}(x^*)-W_{\\text{ALLD}}(x^*) = g(x^*) = 0$.\nThe derivative at $x^*$ is $f'(x^*) = x^*(1-x^*) g'(x)$.\nThe slope $g'(x)$ is the coefficient of $x$ in the linear expression for $g(x)$:\n$$g'(x) = R - T - S + P + \\delta(T+S-2P)$$\nSo, $f'(x^*) = x^*(1-x^*)[R - T - S + P + \\delta(T+S-2P)]$.\nThe sign of $f'(x^*)$ is determined by the sign of the term in square brackets, which is the denominator of the expression for $x^*$.\nThe interior fixed point $x^*$ exists in $(0,1)$ if and only if $g(0)$ and $g(1)$ have opposite signs.\nWe know $g(0) = (S-P)(1-\\delta) < 0$.\nTherefore, for an interior fixed point to exist, we must have $g(1) > 0$.\n$g(1) = R - ((1-\\delta)T+\\delta P) > 0$, which is exactly the stability condition for $x=1$.\nSo, an interior fixed point $x^* \\in (0,1)$ exists if and only if $R > (1-\\delta)T+\\delta P$.\nUnder this condition:\n- The numerator of $x^*$ is $(P-S)(1-\\delta) > 0$.\n- The denominator is $g'(x) = g(1)-g(0) = [R - ((1-\\delta)T+\\delta P)] - [(S-P)(1-\\delta)]$. Since $g(1)>0$ and $-g(0)>0$, the denominator $g'(x)$ is positive.\nTherefore $x^* > 0$. The condition $g(1)>0$ is also equivalent to $x^*<1$.\nSince the denominator $g'(x)$ is positive, $f'(x^*) = x^*(1-x^*)g'(x) > 0$.\nThis means that if the interior fixed point $x^*$ exists, it is always unstable. This creates a bistable system where the population evolves to all-TFT ($x=1$) if the initial frequency $x_0 > x^*$ and to all-ALLD ($x=0$) if $x_0 < x^*$.\n\nTask 4: Report the Final Answer\nThe final answer is the closed-form expression for the interior fixed point frequency $x^*$, which exists if $R > (1-\\delta)T + \\delta P$.\nThe expression, as derived in Task $2$, is:\n$$x^* = \\frac{(P-S)(1-\\delta)}{R - T - S + P + \\delta(T+S-2P)}$$\nThis is the required final expression.", "answer": "$$\n\\boxed{\\frac{(P-S)(1-\\delta)}{R - T - S + P + \\delta(T+S-2P)}}\n$$", "id": "2527577"}, {"introduction": "While simple models provide clarity, real-world interactions are rarely perfect; individuals make mistakes. This practice introduces this crucial layer of realism by analyzing the effects of implementation errors, or noise, on cooperative strategies. You will model the dynamics of \"Tit-for-Tat\" (TFT) and \"Win-Stay, Lose-Shift\" (WSLS) as a Markov chain to compare their long-term performance in an error-prone environment. By analyzing the system's stationary distribution, you will discover why TFT's inability to recover from accidental defections makes it fragile, and why strategies like WSLS, which are more forgiving and can correct errors, may be more robust in the natural world [@problem_id:2527576].", "problem": "Consider an infinite-horizon repeated Prisoner’s Dilemma (PD) in the donation-game form, a canonical model in ecology for cooperation among unrelated individuals. In each round, each player chooses either cooperation ($C$) or defection ($D$). Cooperation confers a benefit $b>0$ to the partner at a personal cost $c>0$. The one-shot PD payoffs to the row player are therefore: mutual cooperation ($CC$) yields $R=b-c$, unilateral cooperation when the partner defects ($CD$) yields $S=-c$, unilateral defection when the partner cooperates ($DC$) yields $T=b$, and mutual defection ($DD$) yields $P=0$. Assume $b>c>0$, so that $T>R>P>S$ as required for a PD.\n\nPlayers implement one of two memory-one strategies that depend only on the previous realized outcome:\n- Tit-for-Tat (TFT): cooperate if and only if the partner cooperated in the previous round.\n- Win-Stay, Lose-Shift (WSLS): repeat the previous move if the previous payoff was a “win” ($R$ or $T$), and switch moves if the previous payoff was a “lose” ($P$ or $S$).\n\nImplementation errors occur independently: in each move, a player’s intended action is flipped ($C \\leftrightarrow D$) with probability $\\epsilon \\in (0,1)$, independently across players and rounds. For any fixed pair of strategies, the dynamics over the four realized joint-action states $\\{CC, CD, DC, DD\\}$ form a time-homogeneous Markov chain with a unique stationary distribution because the chain is finite, irreducible, and aperiodic for $0<\\epsilon<1$.\n\nDefine the long-run average payoff per round for a strategy pair as the expected one-shot payoff under the stationary distribution over $\\{CC, CD, DC, DD\\}$. Say that WSLS “outperforms” TFT if the long-run average payoff in WSLS self-play exceeds that in TFT self-play.\n\nStarting only from the above definitions and the law of total probability for Markov chains, derive symbolically the stationary distributions for TFT-vs-TFT and WSLS-vs-WSLS under noise level $\\epsilon$, compute their respective long-run average payoffs, and determine the unique critical error probability $\\epsilon^{\\ast}$ at which WSLS self-play and TFT self-play have equal long-run average payoffs. Your final answer must be the closed-form value of $\\epsilon^{\\ast}$. No rounding is required, and the answer is unitless.", "solution": "The problem requires the derivation of the critical error probability $\\epsilon^{\\ast}$ at which the long-run average payoff for Tit-for-Tat (TFT) self-play, $V_{\\text{TFT}}$, equals the long-run average payoff for Win-Stay, Lose-Shift (WSLS) self-play, $V_{\\text{WSLS}}$. The game is a repeated Prisoner's Dilemma with payoffs $R=b-c$, $S=-c$, $T=b$, and $P=0$, where $b>c>0$. The state of the system is the joint action of the two players in the previous round, from the set $\\{CC, CD, DC, DD\\}$. An intended action is flipped with probability $\\epsilon \\in (0,1)$.\n\nFirst, we analyze the TFT-vs-TFT interaction. A TFT player cooperates if and only if its partner cooperated in the previous round. The intended actions $(I_1, I_2)$ for the next round given the current state $(A_1, A_2)$ are:\n- From $CC$: Both players saw cooperation, so both intend to cooperate. Intended state is $(C,C)$.\n- From $CD$: Player $1$ saw defection, Player $2$ saw cooperation. Intended state is $(D,C)$.\n- From $DC$: Player $1$ saw cooperation, Player $2$ saw defection. Intended state is $(C,D)$.\n- From $DD$: Both players saw defection, so both intend to defect. Intended state is $(D,D)$.\n\nAn intended cooperation ($I_C$) becomes an actual cooperation ($C$) with probability $1-\\epsilon$ and an actual defection ($D$) with probability $\\epsilon$. An intended defection ($I_D$) becomes an actual $D$ with probability $1-\\epsilon$ and an actual $C$ with probability $\\epsilon$. The transition matrix $M_{\\text{TFT}}$ for the Markov chain over states $\\{CC, CD, DC, DD\\}$ is therefore:\n$$\nM_{\\text{TFT}} =\n\\begin{pmatrix}\n(1-\\epsilon)^2 & \\epsilon(1-\\epsilon) & \\epsilon(1-\\epsilon) & \\epsilon^2 \\\\\n\\epsilon(1-\\epsilon) & \\epsilon^2 & (1-\\epsilon)^2 & \\epsilon(1-\\epsilon) \\\\\n\\epsilon(1-\\epsilon) & (1-\\epsilon)^2 & \\epsilon^2 & \\epsilon(1-\\epsilon) \\\\\n\\epsilon^2 & \\epsilon(1-\\epsilon) & \\epsilon(1-\\epsilon) & (1-\\epsilon)^2\n\\end{pmatrix}\n$$\nThe sum of each column in $M_{\\text{TFT}}$ is $1$, meaning the matrix is doubly stochastic. For an irreducible and aperiodic finite Markov chain, a doubly stochastic transition matrix implies that the unique stationary distribution is the uniform distribution. Let $\\pi_{\\text{TFT}} = (p_{CC}, p_{CD}, p_{DC}, p_{DD})$ be this distribution. Thus, $p_{CC} = p_{CD} = p_{DC} = p_{DD} = \\frac{1}{4}$.\nThe long-run average payoff for a TFT player is the expected payoff under this stationary distribution:\n$$V_{\\text{TFT}} = p_{CC}R + p_{CD}S + p_{DC}T + p_{DD}P$$\n$$V_{\\text{TFT}} = \\frac{1}{4} (b-c) + \\frac{1}{4} (-c) + \\frac{1}{4} (b) + \\frac{1}{4} (0) = \\frac{1}{4}(2b - 2c) = \\frac{b-c}{2}$$\n\nNext, we analyze the WSLS-vs-WSLS interaction. A WSLS player repeats its previous move after a \"win\" (payoff $R$ or $T$) and switches its move after a \"lose\" (payoff $P$ or $S$). The intended actions are:\n- From $CC$: Both players received $R$ (a win). Both repeat their move ($C$). Intended state is $(C,C)$.\n- From $CD$: Player $1$ received $S$ (a lose), Player $2$ received $T$ (a win). Player $1$ switches from $C$ to $D$, Player $2$ repeats $D$. Intended state is $(D,D)$.\n- From $DC$: Player $1$ received $T$ (a win), Player $2$ received $S$ (a lose). Player $1$ repeats $D$, Player $2$ switches from $C$ to $D$. Intended state is $(D,D)$.\n- From $DD$: Both received $P$ (a lose). Both switch their move from $D$ to $C$. Intended state is $(C,C)$.\n\nThe transition matrix $M_{\\text{WSLS}}$ is constructed based on these intended moves:\n$$\nM_{\\text{WSLS}} =\n\\begin{pmatrix}\n(1-\\epsilon)^2 & \\epsilon(1-\\epsilon) & \\epsilon(1-\\epsilon) & \\epsilon^2 \\\\\n\\epsilon^2 & \\epsilon(1-\\epsilon) & \\epsilon(1-\\epsilon) & (1-\\epsilon)^2 \\\\\n\\epsilon^2 & \\epsilon(1-\\epsilon) & \\epsilon(1-\\epsilon) & (1-\\epsilon)^2 \\\\\n(1-\\epsilon)^2 & \\epsilon(1-\\epsilon) & \\epsilon(1-\\epsilon) & \\epsilon^2\n\\end{pmatrix}\n$$\nLet the stationary distribution be $\\pi_{\\text{WSLS}} = (q_{CC}, q_{CD}, q_{DC}, q_{DD})$. Due to symmetry, $q_{CD}=q_{DC}$. The stationarity equations $\\pi_{\\text{WSLS}} M_{\\text{WSLS}} = \\pi_{\\text{WSLS}}$ yield for state $CD$:\n$$q_{CD} = q_{CC}\\epsilon(1-\\epsilon) + q_{CD}\\epsilon(1-\\epsilon) + q_{DC}\\epsilon(1-\\epsilon) + q_{DD}\\epsilon(1-\\epsilon)$$\n$$q_{CD} = (q_{CC} + q_{CD} + q_{DC} + q_{DD})\\epsilon(1-\\epsilon)$$\nSince the sum of probabilities is $1$, we find $q_{CD} = \\epsilon(1-\\epsilon)$. Therefore, $q_{DC} = \\epsilon(1-\\epsilon)$.\nThe normalization condition is $q_{CC} + q_{CD} + q_{DC} + q_{DD} = 1$, which gives $q_{CC} + q_{DD} = 1 - 2\\epsilon(1-\\epsilon)$.\nNow consider the flow between the set of symmetric states $S_{sym}=\\{CC, DD\\}$ and asymmetric states $S_{asym}=\\{CD, DC\\}$. Let $X=q_{CC}+q_{DD}$ and $Y=q_{CD}+q_{DC}=2\\epsilon(1-\\epsilon)$.\nThe total probability of transitioning from $S_{sym}$ to $S_{asym}$ is $P(S_{asym}|S_{sym}) = \\epsilon(1-\\epsilon) + \\epsilon(1-\\epsilon) = 2\\epsilon(1-\\epsilon)$.\nThe total probability of transitioning from $S_{asym}$ to $S_{asym}$ is $P(S_{asym}|S_{asym}) = \\epsilon(1-\\epsilon) + \\epsilon(1-\\epsilon) = 2\\epsilon(1-\\epsilon)$. Uh oh, that is incorrect.\nThe probability of going from state $CD$ (intent $(D,D)$) to $CD$ is $\\epsilon(1-\\epsilon)$, to $DC$ is $\\epsilon(1-\\epsilon)$. Sum is $2\\epsilon(1-\\epsilon)$. So this part is correct. Let's use the stationarity equation for $q_{CC}$.\n$$q_{CC} = q_{CC}(1-\\epsilon)^2 + q_{CD}\\epsilon^2 + q_{DC}\\epsilon^2 + q_{DD}(1-\\epsilon)^2$$\n$$q_{CC} = q_{CC}(1-\\epsilon)^2 + 2\\epsilon(1-\\epsilon)\\epsilon^2 + q_{DD}(1-\\epsilon)^2$$\n$$q_{CC}(1 - (1-\\epsilon)^2) = 2\\epsilon^3(1-\\epsilon) + q_{DD}(1-\\epsilon)^2$$\n$$q_{CC}\\epsilon(2-\\epsilon) = 2\\epsilon^3(1-\\epsilon) + (1 - 2\\epsilon(1-\\epsilon) - q_{CC})(1-\\epsilon)^2$$\nSolving this algebraic equation is cumbersome. A more elegant method uses state aggregates. Let $X=q_{CC}+q_{DD}$ and $Y=q_{CD}+q_{DC}$. At stationarity, the probability of being in state $CC$ is:\n$$q_{CC} = (q_{CC}+q_{DD})(1-\\epsilon)^2 + (q_{CD}+q_{DC})\\epsilon^2 = X(1-\\epsilon)^2 + Y\\epsilon^2$$\nAnd for $DD$:\n$$q_{DD} = (q_{CC}+q_{DD})\\epsilon^2 + (q_{CD}+q_{DC})(1-\\epsilon)^2 = X\\epsilon^2 + Y(1-\\epsilon)^2$$\nSumming these gives $X = q_{CC}+q_{DD} = (X+Y)((1-\\epsilon)^2+\\epsilon^2) = 1-2\\epsilon+2\\epsilon^2$. Then $Y=1-X=2\\epsilon-2\\epsilon^2$. This confirms $q_{CD}=q_{DC}=\\epsilon(1-\\epsilon)$.\nSubtracting the equations gives:\n$$q_{CC}-q_{DD} = (X-Y)((1-\\epsilon)^2-\\epsilon^2) = (X-Y)(1-2\\epsilon)$$\nSubstituting $X=1-2\\epsilon+2\\epsilon^2$ and $Y=2\\epsilon-2\\epsilon^2$ gives $X-Y = 1-4\\epsilon+4\\epsilon^2 = (1-2\\epsilon)^2$.\nSo, $q_{CC}-q_{DD} = (1-2\\epsilon)^2(1-2\\epsilon) = (1-2\\epsilon)^3$.\nWe have a system of two linear equations for $q_{CC}$ and $q_{DD}$:\n$q_{CC}+q_{DD} = 1-2\\epsilon+2\\epsilon^2$\n$q_{CC}-q_{DD} = (1-2\\epsilon)^3 = 1-6\\epsilon+12\\epsilon^2-8\\epsilon^3$\nAdding them: $2q_{CC} = 2-8\\epsilon+14\\epsilon^2-8\\epsilon^3 \\implies q_{CC} = 1-4\\epsilon+7\\epsilon^2-4\\epsilon^3$.\nThe long-run average payoff for WSLS is:\n$$V_{\\text{WSLS}} = q_{CC}R + q_{CD}S + q_{DC}T + q_{DD}P$$\n$$V_{\\text{WSLS}} = q_{CC}(b-c) + \\epsilon(1-\\epsilon)(-c) + \\epsilon(1-\\epsilon)(b) + q_{DD}(0)$$\n$$V_{\\text{WSLS}} = q_{CC}(b-c) + \\epsilon(1-\\epsilon)(b-c) = (q_{CC} + \\epsilon-\\epsilon^2)(b-c)$$\n$$V_{\\text{WSLS}} = (1-4\\epsilon+7\\epsilon^2-4\\epsilon^3 + \\epsilon-\\epsilon^2)(b-c)$$\n$$V_{\\text{WSLS}} = (1 - 3\\epsilon + 6\\epsilon^2 - 4\\epsilon^3)(b-c)$$\n\nFinally, we find the critical error probability $\\epsilon^{\\ast}$ by equating the payoffs:\n$$V_{\\text{TFT}} = V_{\\text{WSLS}}$$\n$$\\frac{b-c}{2} = (1 - 3\\epsilon + 6\\epsilon^2 - 4\\epsilon^3)(b-c)$$\nSince $b>c$, $b-c>0$, so we can divide by it:\n$$\\frac{1}{2} = 1 - 3\\epsilon + 6\\epsilon^2 - 4\\epsilon^3$$\n$$0 = \\frac{1}{2} - 3\\epsilon + 6\\epsilon^2 - 4\\epsilon^3$$\nMultiplying by $-2$:\n$$0 = 8\\epsilon^3 - 12\\epsilon^2 + 6\\epsilon - 1$$\nThis is the expansion of a cube:\n$$0 = (2\\epsilon - 1)^3$$\nThe unique real solution in the interval $(0,1)$ is found by setting the base to zero:\n$$2\\epsilon^{\\ast} - 1 = 0 \\implies \\epsilon^{\\ast} = \\frac{1}{2}$$\nThis is the critical error probability at which the long-run average payoffs of TFT and WSLS self-play are identical.", "answer": "$$\\boxed{\\frac{1}{2}}$$", "id": "2527576"}, {"introduction": "Theoretical models of cooperation are powerful, but their value is fully realized only when they can be connected to observable behavior. This practice challenges you to shift from theorist to empirical scientist by developing a statistical framework to analyze behavioral data. Using the principles of maximum likelihood estimation, you will learn how to estimate the key parameters of a reactive strategy—such as baseline cooperativeness, responsiveness to a partner, and error rate—from a time series of interactions. This exercise [@problem_id:2527630] bridges the gap between abstract theory and practical data analysis, highlighting the importance of experimental design and statistical identifiability in uncovering the hidden drivers of cooperation.", "problem": "A pair of individuals in a cooperative species engage in a long run of repeated dyadic interactions indexed by discrete time steps $t \\in \\{1,2,\\dots,T\\}$. At each step $t \\geq 2$, each individual $i \\in \\{A,B\\}$ produces an observed binary act $Y_{t}^{i} \\in \\{0,1\\}$, where $Y_{t}^{i} = 1$ denotes cooperation and $Y_{t}^{i} = 0$ denotes defection. The underlying behavioral control is a symmetric, reactive policy specified as follows.\n\n- Each individual $i$ forms an intended cooperative act $I_{t}^{i} \\in \\{0,1\\}$ that depends only on the partner’s previous observed act $Y_{t-1}^{-i}$. Conditional on $Y_{t-1}^{-i} = x \\in \\{0,1\\}$, the intended cooperative probability is\n$$\n\\mathbb{P}\\!\\left(I_{t}^{i} = 1 \\,\\big|\\, Y_{t-1}^{-i} = x\\right) = p_{x}, \\quad \\text{with } p_{0} = \\delta,\\; p_{1} = \\delta + \\rho,\n$$\nwhere $\\delta \\in [0,1]$ is the baseline propensity to cooperate and $\\rho \\in \\mathbb{R}$ is the responsiveness to the partner’s previous cooperation, constrained by $0 \\leq \\delta \\leq 1$ and $0 \\leq \\delta + \\rho \\leq 1$.\n\n- Execution is imperfect: with probability $\\epsilon \\in [0,1]$, the observed act flips the intended act, $Y_{t}^{i} = 1 - I_{t}^{i}$, and with probability $1 - \\epsilon$ it is executed as intended, $Y_{t}^{i} = I_{t}^{i}$. Conditional on $Y_{t-1}^{-i}$, the two individuals act independently and identically.\n\nData are collected under three protocols, interleaved across the same dyads over the same horizon $t \\in \\{1,2,\\dots,T\\}$:\n\n- Natural steps: no intervention; only $Y_{t}^{i}$ is recorded. Let $N_{x}$ be the total number of individual acts (pooling both individuals across time) that occur at steps with $Y_{t-1}^{-i} = x$, and let $S_{x}$ be the total number of those acts that are cooperative, for $x \\in \\{0,1\\}$.\n\n- Probe steps: the experimenter exogenously sets $Y_{t-1}^{-i} = x$ via a stimulus with $x \\in \\{0,1\\}$ and directly measures the intended act $I_{t}^{i}$ without execution error (e.g., through validated pre-action signaling proxies). Let $M_{x}$ be the number of such probed instances with stimulus $x$, and $R_{x}$ the number of cooperative intentions observed among those, for $x \\in \\{0,1\\}$.\n\n- Calibration steps: the experimenter directly observes both $I_{t}^{i}$ and $Y_{t}^{i}$ under natural conditions (no probe stimulus). Let $K$ be the number of such calibration instances (pooling both individuals across time), and let $E$ be the number of mismatches where $Y_{t}^{i} \\neq I_{t}^{i}$.\n\nAssume that, conditional on the indicated conditioning variables, all acts across individuals and time are independent Bernoulli trials, and that the scheduling of probe and calibration steps is independent of the individuals’ internal states and actions. The time series is long enough that $N_{x}$, $M_{x}$, and $K$ are each large and finite.\n\nTasks:\n\n- Starting from the definitions of Bernoulli likelihood and conditional independence, write the full likelihood for the joint data under the parameter vector $(\\delta,\\epsilon,\\rho)$, and show how this likelihood factorizes by protocol.\n\n- Using first principles of maximum likelihood estimation, derive closed-form maximum likelihood estimators for $(\\delta,\\epsilon,\\rho)$ in terms of the sufficient statistics $(R_{0},M_{0},R_{1},M_{1},E,K)$.\n\n- Derive the structural identifiability conditions for $(\\delta,\\epsilon,\\rho)$ under (i) natural steps only, and (ii) the combined protocol used here (natural, probe, calibration). State the minimal sample size and parameter-space constraints needed so that the maximum likelihood estimators exist, are unique, and lie in the admissible parameter space.\n\nProvide the final estimators in closed form as a single row vector $(\\hat{\\delta},\\hat{\\epsilon},\\hat{\\rho})$ in terms of $(R_{0},M_{0},R_{1},M_{1},E,K)$. No numerical approximation is required and no rounding is required. Express no units.", "solution": "The problem presented is a well-posed question in statistical modeling and parameter estimation, relevant to the field of behavioral ecology. I will first validate its components and then proceed to a rigorous derivation of the solution.\n\nFirst, an analysis of the problem statement is required.\n\n**Givens:**\n- Individuals $i \\in \\{A,B\\}$, discrete time $t \\in \\{1,2,\\dots,T\\}$.\n- Observed act: $Y_{t}^{i} \\in \\{0,1\\}$, with $1$ for cooperation.\n- Intended act: $I_{t}^{i} \\in \\{0,1\\}$.\n- Intended cooperation probability: $\\mathbb{P}(I_{t}^{i} = 1 | Y_{t-1}^{-i} = x) = p_{x}$, where $p_{0} = \\delta$ and $p_{1} = \\delta + \\rho$.\n- Parameter constraints: $\\delta \\in [0,1]$, $\\rho \\in \\mathbb{R}$, $0 \\leq \\delta + \\rho \\leq 1$.\n- Execution error: $\\mathbb{P}(Y_{t}^{i} \\neq I_{t}^{i}) = \\epsilon$, with $\\epsilon \\in [0,1]$.\n- Independence: Individuals act independently and identically, conditional on $Y_{t-1}^{-i}$.\n- Data from Natural steps: $(S_{x}, N_{x})$ for $x \\in \\{0,1\\}$, where $S_x$ is the number of cooperative acts out of a total of $N_x$ acts following a partner's previous act $x$.\n- Data from Probe steps: $(R_{x}, M_{x})$ for $x \\in \\{0,1\\}$, where $R_x$ is the number of cooperative intentions among $M_x$ probes with stimulus $x$.\n- Data from Calibration steps: $(E, K)$, where $E$ is the number of mismatches $Y_{t}^{i} \\neq I_{t}^{i}$ in $K$ calibration instances.\n- Assumptions: independence of trials conditional on specified variables; large finite sample sizes $N_x, M_x, K$.\n\n**Validation:**\n1.  **Scientific Grounding**: The model is a form of a probabilistic reactive strategy, a standard class of models in game theory and behavioral ecology used to study cooperation (e.g., \"Generous Tit-for-Tat\" with implementation error). It is scientifically sound.\n2.  **Well-Posedness**: The problem asks for the likelihood, estimators, and identifiability conditions. This is a standard and well-posed problem in statistical inference.\n3.  **Objectivity**: The problem is stated in precise mathematical terms, free of subjective content.\n4.  All other criteria for validity (completeness, non-triviality, verifiability) are met. The problem is a rigorous exercise in mathematical statistics.\n\n**Verdict:** The problem is valid. I will proceed with the solution.\n\n**Task 1: Likelihood and Factorization**\n\nThe likelihood function $L(\\delta, \\epsilon, \\rho)$ is the probability of observing the complete dataset given the parameters. Because the three data collection protocols (natural, probe, calibration) are independent processes, the total likelihood is the product of the likelihoods from each protocol.\n$L(\\delta, \\epsilon, \\rho) = L_{\\text{probe}}(\\delta, \\rho) \\cdot L_{\\text{calib}}(\\epsilon) \\cdot L_{\\text{nat}}(\\delta, \\epsilon, \\rho)$.\n\n1.  **Probe Likelihood ($L_{\\text{probe}}$)**:\n    In probe steps, the intended act $I_t^i$ is measured directly. For a given stimulus $x \\in \\{0,1\\}$, the probability of an intended cooperative act is $p_x$. The data consist of $R_x$ cooperative intentions in $M_x$ independent Bernoulli trials. This gives a binomial likelihood for each $x$:\n    $$L_{\\text{probe}}(p_0, p_1) = \\left[\\binom{M_0}{R_0} p_0^{R_0} (1-p_0)^{M_0-R_0}\\right] \\cdot \\left[\\binom{M_1}{R_1} p_1^{R_1} (1-p_1)^{M_1-R_1}\\right]$$\n    Substituting $p_0 = \\delta$ and $p_1 = \\delta + \\rho$:\n    $$L_{\\text{probe}}(\\delta, \\rho) \\propto \\delta^{R_0} (1-\\delta)^{M_0-R_0} \\cdot (\\delta+\\rho)^{R_1} (1-\\delta-\\rho)^{M_1-R_1}$$\n    This component of the likelihood depends only on $\\delta$ and $\\rho$.\n\n2.  **Calibration Likelihood ($L_{\\text{calib}}$)**:\n    In calibration steps, mismatches between intention $I_t^i$ and execution $Y_t^i$ are observed. The probability of a mismatch is $\\epsilon$. The data consist of $E$ mismatches in $K$ independent Bernoulli trials. The likelihood is:\n    $$L_{\\text{calib}}(\\epsilon) = \\binom{K}{E} \\epsilon^E (1-\\epsilon)^{K-E}$$\n    This component of the likelihood depends only on $\\epsilon$.\n\n3.  **Natural Likelihood ($L_{\\text{nat}}$)**:\n    In natural steps, only the executed act $Y_t^i$ is observed. The intention $I_t^i$ is a latent variable. We must find the marginal probability of observing a cooperative act, $\\pi_x = \\mathbb{P}(Y_t^i = 1 | Y_{t-1}^{-i} = x)$. Using the law of total probability, marginalizing over $I_t^i$:\n    $$\\pi_x = \\mathbb{P}(Y_t^i=1|I_t^i=1) \\mathbb{P}(I_t^i=1|Y_{t-1}^{-i}=x) + \\mathbb{P}(Y_t^i=1|I_t^i=0) \\mathbb{P}(I_t^i=0|Y_{t-1}^{-i}=x)$$\n    Substituting the given probabilities:\n    $$\\pi_x = (1-\\epsilon) p_x + \\epsilon (1-p_x) = p_x(1-2\\epsilon) + \\epsilon$$\n    The data consist of $S_x$ cooperative acts in $N_x$ independent Bernoulli trials with success probability $\\pi_x$. The likelihood is:\n    $$L_{\\text{nat}}(p_0, p_1, \\epsilon) = \\left[\\binom{N_0}{S_0} \\pi_0^{S_0} (1-\\pi_0)^{N_0-S_0}\\right] \\cdot \\left[\\binom{N_1}{S_1} \\pi_1^{S_1} (1-\\pi_1)^{N_1-S_1}\\right]$$\n    where $\\pi_0 = \\delta(1-2\\epsilon)+\\epsilon$ and $\\pi_1 = (\\delta+\\rho)(1-2\\epsilon)+\\epsilon$. This component depends on all three parameters.\n\n**Factorization:**\nThe full likelihood for the joint data $(\\{R_x, M_x\\}, \\{E,K\\}, \\{S_x, N_x\\})$ is:\n$$L(\\delta, \\epsilon, \\rho) \\propto \\delta^{R_0} (1-\\delta)^{M_0-R_0} (\\delta+\\rho)^{R_1} (1-\\delta-\\rho)^{M_1-R_1} \\cdot \\epsilon^E (1-\\epsilon)^{K-E} \\cdot \\pi_0^{S_0} (1-\\pi_0)^{N_0-S_0} \\pi_1^{S_1} (1-\\pi_1)^{N_1-S_1}$$\nThe likelihood factorizes into three parts corresponding to the three protocols. However, the parameters are coupled across factors, as $\\delta, \\rho, \\epsilon$ all appear in the term $L_{\\text{nat}}$.\n\n**Task 2: Maximum Likelihood Estimators (MLEs)**\n\nTo find the MLEs, we must maximize the full likelihood, or equivalently, its logarithm $\\ell = \\ln L$.\n$$\\ell(\\delta, \\epsilon, \\rho) = \\ell_{\\text{probe}}(\\delta, \\rho) + \\ell_{\\text{calib}}(\\epsilon) + \\ell_{\\text{nat}}(\\delta, \\epsilon, \\rho)$$\nThe derivative of the full log-likelihood with respect to each parameter must be set to zero. This results in a system of coupled non-linear equations. For example, the score function for $\\epsilon$ is:\n$$\\frac{\\partial \\ell}{\\partial \\epsilon} = \\frac{\\partial \\ell_{\\text{calib}}}{\\partial \\epsilon} + \\frac{\\partial \\ell_{\\text{nat}}}{\\partial \\epsilon} = \\left(\\frac{E}{\\epsilon} - \\frac{K-E}{1-\\epsilon}\\right) + \\sum_{x=0,1} \\left(\\frac{S_x}{\\pi_x} - \\frac{N_x-S_x}{1-\\pi_x}\\right)\\frac{\\partial \\pi_x}{\\partial \\epsilon}$$\nSolving this coupled system does not generally yield a closed-form solution.\n\nHowever, the problem structure and the request for a closed-form solution in terms of only $(R_0, M_0, R_1, M_1, E, K)$ is crucial. This implies that the estimation must rely solely on the data from the probe and calibration experiments, which were designed specifically to provide direct, unconfounded measurements of the parameters. The probe data directly measures intended probabilities $p_0$ and $p_1$, while the calibration data directly measures the error rate $\\epsilon$. This approach is justified because these experiments provide direct identification, and in the large-sample limit (which is assumed), the information from these direct measures dominates the confounded information from the naturalistic data for parameter estimation.\n\nTherefore, we find the estimators by maximizing the likelihood components that depend directly on the target parameters.\n\n1.  **Estimator for $\\epsilon$**: We maximize $L_{\\text{calib}}(\\epsilon)$ or its log-likelihood, $\\ell_{\\text{calib}}(\\epsilon) = E \\ln \\epsilon + (K-E) \\ln(1-\\epsilon) + \\text{const}$.\n    $$\\frac{d\\ell_{\\text{calib}}}{d\\epsilon} = \\frac{E}{\\epsilon} - \\frac{K-E}{1-\\epsilon} = 0 \\implies E(1-\\epsilon) = (K-E)\\epsilon \\implies E = K\\epsilon$$\n    $$\\hat{\\epsilon} = \\frac{E}{K}$$\n\n2.  **Estimator for $\\delta$ and $\\rho$**: We maximize $L_{\\text{probe}}(\\delta, \\rho)$ or its log-likelihood, $\\ell_{\\text{probe}}(\\delta, \\rho)$. It is simpler to reparameterize in terms of $p_0=\\delta$ and $p_1=\\delta+\\rho$. Maximizing the binomial likelihoods for $p_0$ and $p_1$ yields:\n    $$\\hat{p}_0 = \\frac{R_0}{M_0} \\quad \\text{and} \\quad \\hat{p}_1 = \\frac{R_1}{M_1}$$\n    Transforming back to the original parameters:\n    $$\\hat{\\delta} = \\hat{p}_0 = \\frac{R_0}{M_0}$$\n    $$\\hat{\\rho} = \\hat{p}_1 - \\hat{p}_0 = \\frac{R_1}{M_1} - \\frac{R_0}{M_0}$$\n\nThese estimators are the MLEs based on the unconfounded data sources and provide the closed-form solution demanded by the problem.\n\n**Task 3: Identifiability and Constraints**\n\n1.  **Identifiability with Natural Steps Only**:\n    With only natural data, we can consistently estimate the observable probabilities $\\pi_0$ and $\\pi_1$ via $\\hat{\\pi}_x = S_x/N_x$. The parameters $(\\delta, \\rho, \\epsilon)$ are linked to these observables through two equations:\n    $$\\pi_0 = \\delta(1-2\\epsilon) + \\epsilon$$\n    $$\\pi_1 = (\\delta+\\rho)(1-2\\epsilon) + \\epsilon$$\n    This is a system of two equations with three unknowns. For any chosen $\\epsilon \\in [0, 1)$ with $\\epsilon \\neq 1/2$, one can solve for a unique pair $(\\delta, \\rho)$: $\\delta = (\\pi_0 - \\epsilon)/(1-2\\epsilon)$ and $\\rho = (\\pi_1 - \\pi_0)/(1-2\\epsilon)$. This means there is an infinite family of parameter triplets that produce the same observable dynamics. The parameters are therefore not structurally identifiable from natural data alone.\n\n2.  **Identifiability with Combined Protocol**:\n    The combined protocol resolves this ambiguity.\n    - The calibration data allows for direct, unique estimation of $\\epsilon$ via $\\hat{\\epsilon} = E/K$.\n    - The probe data allows for direct, unique estimation of $p_0=\\delta$ and $p_1=\\delta+\\rho$ via $\\hat{p}_0=R_0/M_0$ and $\\hat{p}_1=R_1/M_1$.\n    From these, $\\delta$ and $\\rho$ are uniquely determined. Since all three parameters $(\\delta, \\epsilon, \\rho)$ can be determined uniquely, the model is structurally identifiable under the full protocol.\n\n3.  **Minimal Conditions for Estimators**:\n    For the MLEs to exist, be unique, and lie in the admissible parameter space, the denominators of the estimators must be non-zero.\n    - For $\\hat{\\epsilon} = E/K$: we require the number of calibration trials $K > 0$. The condition $0 \\le E \\le K$ guarantees $0 \\le \\hat{\\epsilon} \\le 1$.\n    - For $\\hat{\\delta} = R_0/M_0$: we require the number of probes $M_0 > 0$. The condition $0 \\le R_0 \\le M_0$ guarantees $0 \\le \\hat{\\delta} \\le 1$.\n    - For $\\hat{\\delta}+\\hat{\\rho} = R_1/M_1$: we require the number of probes $M_1 > 0$. The condition $0 \\le R_1 \\le M_1$ guarantees $0 \\le \\hat{\\delta}+\\hat{\\rho} \\le 1$.\n    Uniqueness of the estimators is guaranteed by the strict concavity of the corresponding log-likelihood functions, provided these sample sizes are positive.\n    Thus, the minimal sample size constraints are $K>0$, $M_{0}>0$, and $M_{1}>0$. The problem states these are large, so these conditions are met.\n\nThe final estimators for $(\\hat{\\delta}, \\hat{\\epsilon}, \\hat{\\rho})$ are collected below.", "answer": "$$ \\boxed{ \\begin{pmatrix} \\frac{R_0}{M_0} & \\frac{E}{K} & \\frac{R_1}{M_1} - \\frac{R_0}{M_0} \\end{pmatrix} } $$", "id": "2527630"}]}