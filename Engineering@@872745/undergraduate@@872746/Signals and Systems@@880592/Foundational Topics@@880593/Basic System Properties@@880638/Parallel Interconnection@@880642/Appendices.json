{"hands_on_practices": [{"introduction": "The most direct way to understand parallel systems is by observing their behavior in the time domain. This exercise demonstrates the fundamental additive property by combining two simple, intuitive systemsâ€”an amplifier and a delay unit. Solving this problem will solidify your understanding of the core definition of a parallel connection and provide valuable practice in manipulating basic time-domain signals [@problem_id:1739808].", "problem": "Consider a simple signal processing setup involving a parallel arrangement of two linear time-invariant (LTI) systems. In this configuration, an input signal $x(t)$ is applied to both systems simultaneously, and their respective outputs are summed together to create the final output signal $y(t)$.\n\nThe first system is a simple amplifier that scales the amplitude of its input signal by a factor of 2.\n\nThe second system is a pure delay unit that introduces a time delay of 3 seconds to its input signal.\n\nIf the input signal to this parallel configuration is the unit step function, denoted by $x(t) = u(t)$, determine the resulting output signal $y(t)$. Express your answer as a single analytic expression in terms of the time variable $t$ and the unit step function $u(t)$.", "solution": "In a parallel interconnection of linear time-invariant systems, the total output equals the sum of the outputs of the individual branches driven by the same input. Denote the input by $x(t)$ and the output by $y(t)$. Then\n$$\ny(t)=y_{1}(t)+y_{2}(t),\n$$\nwhere $y_{1}(t)$ is the output of the amplifier branch and $y_{2}(t)$ is the output of the delay branch.\n\nFor the amplifier with gain $2$, linearity gives\n$$\ny_{1}(t)=2\\,x(t).\n$$\nFor the pure delay of $T=3$ seconds, time invariance implies\n$$\ny_{2}(t)=x(t-3).\n$$\nGiven the input $x(t)=u(t)$, the unit step function, we substitute to obtain\n$$\ny(t)=2u(t)+u(t-3).\n$$\nAs a consistency check, this equals $0$ for $t0$, equals $2$ for $0\\leq t3$, and equals $3$ for $t\\geq 3$, which matches the expected sum of a step and its delayed version scaled appropriately.", "answer": "$$\\boxed{2u(t)+u(t-3)}$$", "id": "1739808"}, {"introduction": "Beyond simple analysis, the power of system interconnections shines in design and synthesis. This practice challenges you to use the additive property of transfer functions, where $H_{eq}(s) = H_1(s) + H_2(s)$, to create a system with a specific overall characteristic. By determining the correct subsystem to place in parallel, you will engineer a composite system that functions as a perfect all-pass filter, demonstrating a key technique in system compensation [@problem_id:1739762].", "problem": "In a signal processing application, two stable, causal, continuous-time Linear Time-Invariant (LTI) systems are interconnected in a parallel configuration. The first system is characterized by the transfer function $H_1(s) = \\frac{s-1}{s+2}$. The second system has an unknown transfer function, $H_2(s)$.\n\nThe parallel combination of these two systems results in an equivalent system, $H_{eq}(s)$, which is designed to be an all-pass filter. An all-pass filter is defined as a system whose frequency response magnitude, $|H_{eq}(j\\omega)|$, is a constant value for all angular frequencies $\\omega$.\n\nFurthermore, the overall equivalent system is constrained to have a DC gain, defined as $H_{eq}(0)$, equal to $-3$.\n\nAssuming that the poles of the individual systems $H_1(s)$ and $H_2(s)$ are also the poles of the combined system $H_{eq}(s)$, determine the transfer function $H_2(s)$. Your final answer should be a single closed-form analytic expression in terms of $s$.", "solution": "For a parallel interconnection, the equivalent transfer function is the sum\n$$H_{eq}(s) = H_{1}(s) + H_{2}(s).$$\nAn all-pass filter with real coefficients and stability has the property that, for every pole at $p$ in the open left half-plane, there is a zero at $-p^{\\ast}$; for a real pole at $-a$ with $a0$, a first-order all-pass section has the form\n$$A(s) = \\frac{s - a}{s + a}.$$\nA constant real gain factor $C$ scales the magnitude to a constant $|C|$ for all frequencies, so the general first-order real all-pass with constant magnitude is\n$$H_{eq}(s) = C \\frac{s - a}{s + a}.$$\nBy assumption, the poles of the individual systems are also poles of $H_{eq}(s)$. Since $H_{1}(s) = \\frac{s - 1}{s + 2}$ has a pole at $s = -2$, $H_{eq}(s)$ must have a pole at $s = -2$. Therefore, $a = 2$, and\n$$H_{eq}(s) = C \\frac{s - 2}{s + 2}.$$\nThe DC gain constraint $H_{eq}(0) = -3$ gives\n$$H_{eq}(0) = C \\frac{0 - 2}{0 + 2} = -C = -3 \\quad \\Rightarrow \\quad C = 3,$$\nhence\n$$H_{eq}(s) = 3 \\frac{s - 2}{s + 2}.$$\nUsing $H_{eq}(s) = H_{1}(s) + H_{2}(s)$, solve for $H_{2}(s)$:\n$$H_{2}(s) = H_{eq}(s) - H_{1}(s) = 3 \\frac{s - 2}{s + 2} - \\frac{s - 1}{s + 2} = \\frac{3(s - 2) - (s - 1)}{s + 2} = \\frac{2s - 5}{s + 2}.$$\nThis $H_{2}(s)$ is proper and has its pole at $s = -2$, so it is stable and causal, and the combined $H_{eq}(s)$ retains the pole at $s = -2$ without cancellation, satisfying the stated assumption. Moreover, for $s = j\\omega$,\n$$\\left| \\frac{j\\omega - 2}{j\\omega + 2} \\right| = 1,$$\nso $|H_{eq}(j\\omega)| = 3$ is constant for all $\\omega$, confirming the all-pass specification with constant magnitude.", "answer": "$$\\boxed{\\frac{2s - 5}{s + 2}}$$", "id": "1739762"}, {"introduction": "This final practice explores an advanced application of parallel systems in the realm of optimal digital filter design. You are tasked with approximating a desired, but theoretically non-causal, system response using a practical, causal Finite Impulse Response (FIR) filter that operates in parallel with a time-advance unit. This problem introduces the powerful concept of least-squares error minimization and illustrates how parallel architectures provide elegant solutions for complex signal approximation challenges in modern digital signal processing [@problem_id:1739819].", "problem": "In the field of digital signal processing, designing systems to approximate a desired response is a fundamental task. Consider a discrete-time system, with overall impulse response $h[n]$, constructed to approximate a specific target non-causal impulse response, $h_d[n]$.\n\nThe approximating system $h[n]$ is composed of two subsystems connected in parallel. The first subsystem is a single-sample time advance unit, characterized by an impulse response $h_1[n] = \\delta[n+1]$, where $\\delta[n]$ is the Kronecker delta function. The second subsystem is a causal $N$-tap Finite Impulse Response (FIR) filter, with an impulse response denoted by $h_c[n]$. The causality and finite length constraints mean that $h_c[n]$ can be non-zero only for sample indices $n$ in the range $0 \\le n \\le N-1$.\n\nThe target impulse response to be approximated is given by the two-sided exponential sequence $h_d[n] = a^{|n|}$, where $a$ is a real-valued constant satisfying $0  a  1$.\n\nThe objective is to design the FIR filter $h_c[n]$ to minimize the total least-squares error, defined as $E = \\sum_{n=-\\infty}^{\\infty} (h_d[n] - h[n])^2$. Your task is to first determine the impulse response of the optimal filter $h_c[n]$ and then to calculate the resulting minimum value of this error, denoted as $E_{min}$.\n\nExpress your final answer for the minimum error $E_{min}$ as a single closed-form analytic expression in terms of the parameters $a$ and $N$.", "solution": "The problem asks for the minimum least-squares error $E_{min}$ when approximating a target impulse response $h_d[n]$ with a system $h[n]$. The system $h[n]$ is a parallel combination of a time advance unit $h_1[n]$ and a causal $N$-tap FIR filter $h_c[n]$.\n\nFirst, we write the impulse response of the total system. Since the subsystems are in parallel, their impulse responses add up:\n$h[n] = h_1[n] + h_c[n] = \\delta[n+1] + h_c[n]$.\n\nThe FIR filter $h_c[n]$ has $N$ taps and is causal, so it can be expressed as a weighted sum of delayed impulses:\n$h_c[n] = \\sum_{k=0}^{N-1} c_k \\delta[n-k]$,\nwhere $\\{c_k\\}$ for $k=0, 1, \\dots, N-1$ are the filter coefficients (taps) that we need to determine.\n\nThe total least-squares error $E$ is given by:\n$E = \\sum_{n=-\\infty}^{\\infty} (h_d[n] - h[n])^2 = \\sum_{n=-\\infty}^{\\infty} \\left(h_d[n] - \\left(\\delta[n+1] + \\sum_{k=0}^{N-1} c_k \\delta[n-k]\\right)\\right)^2$.\n\nOur goal is to minimize $E$ by choosing the optimal values for the coefficients $c_k$. We can analyze the sum term by term for different ranges of the index $n$:\n\n1.  For $n = -1$: The term in the sum is $(h_d[-1] - \\delta[-1+1] - 0)^2 = (h_d[-1] - 1)^2$. This term is independent of the coefficients $c_k$. With $h_d[n] = a^{|n|}$, this evaluates to $(a^{|-1|}-1)^2 = (a-1)^2$.\n\n2.  For $n$ in the range $\\{0, 1, \\dots, N-1\\}$: For any specific index $n=m$ in this range, the FIR filter term is $c_m$, while the $\\delta[n+1]$ term is zero. The term in the sum is $(h_d[m] - c_m)^2$.\n\n3.  For all other values of $n$ (i.e., $n  -1$ or $n \\ge N$): Both $\\delta[n+1]$ and $h_c[n]$ are zero. The term in the sum is $(h_d[n])^2$. These terms are also independent of the coefficients $c_k$.\n\nCombining these observations, we can rewrite the total error $E$ as:\n$E = (h_d[-1] - 1)^2 + \\sum_{m=0}^{N-1} (h_d[m] - c_m)^2 + \\sum_{n \\in \\mathbb{Z} \\setminus \\{-1, 0, \\dots, N-1\\}} (h_d[n])^2$.\n\nTo minimize $E$ with respect to the coefficients $\\{c_m\\}$, we only need to minimize the part of the expression that depends on them, which is the sum $\\sum_{m=0}^{N-1} (h_d[m] - c_m)^2$. The other terms are constant with respect to $\\{c_m\\}$. This sum is a sum of non-negative squares. The minimum value of this sum is achieved when each individual term is minimized. The minimum value of $(h_d[m] - c_m)^2$ is zero, which occurs when $c_m = h_d[m]$.\n\nTherefore, the optimal coefficients for the FIR filter are:\n$c_m = h_d[m] = a^{|m|} = a^m$ for $m = 0, 1, \\dots, N-1$.\n\nWith these optimal coefficients, the term $\\sum_{m=0}^{N-1} (h_d[m] - c_m)^2$ becomes zero. The minimum error $E_{min}$ is then the sum of the remaining terms:\n$E_{min} = (h_d[-1] - 1)^2 + \\sum_{n \\in \\mathbb{Z} \\setminus \\{-1, 0, \\dots, N-1\\}} (h_d[n])^2$.\n\nThe set of indices $\\mathbb{Z} \\setminus \\{-1, 0, \\dots, N-1\\}$ can be split into two disjoint sets: $\\{n \\in \\mathbb{Z} \\mid n \\le -2\\}$ and $\\{n \\in \\mathbb{Z} \\mid n \\ge N\\}$.\nSo, we can write $E_{min}$ as:\n$E_{min} = (a-1)^2 + \\sum_{n=-\\infty}^{-2} (h_d[n])^2 + \\sum_{n=N}^{\\infty} (h_d[n])^2$.\n\nNow, we substitute $h_d[n] = a^{|n|}$ and evaluate the sums.\n$E_{min} = (a-1)^2 + \\sum_{n=-\\infty}^{-2} (a^{|n|})^2 + \\sum_{n=N}^{\\infty} (a^{|n|})^2$.\n$E_{min} = (a-1)^2 + \\sum_{n=-\\infty}^{-2} a^{2|n|} + \\sum_{n=N}^{\\infty} a^{2|n|}$.\n\nFor the first sum, let $k = -n$. As $n$ goes from $-2$ to $-\\infty$, $k$ goes from $2$ to $\\infty$.\n$\\sum_{n=-\\infty}^{-2} a^{2|n|} = \\sum_{n=-\\infty}^{-2} a^{-2n} = \\sum_{k=2}^{\\infty} a^{2k}$.\nThis is a geometric series with first term $a^4$ and ratio $r = a^2$. Since $0  a  1$, we have $0  a^2  1$, so the series converges. The sum is $\\frac{\\text{first term}}{1-\\text{ratio}} = \\frac{a^4}{1-a^2}$.\n\nFor the second sum, the indices $n$ are positive, so $|n|=n$.\n$\\sum_{n=N}^{\\infty} a^{2|n|} = \\sum_{n=N}^{\\infty} a^{2n}$.\nThis is a geometric series with first term $a^{2N}$ and ratio $r = a^2$. The sum is $\\frac{a^{2N}}{1-a^2}$.\n\nNow, we add all the parts of $E_{min}$ together:\n$E_{min} = (a-1)^2 + \\frac{a^4}{1-a^2} + \\frac{a^{2N}}{1-a^2}$.\n$E_{min} = a^2 - 2a + 1 + \\frac{a^4 + a^{2N}}{1-a^2}$.\n\nTo get a single fraction, we use the common denominator $1-a^2$:\n$E_{min} = \\frac{(a^2 - 2a + 1)(1-a^2)}{1-a^2} + \\frac{a^4 + a^{2N}}{1-a^2}$.\n$E_{min} = \\frac{(a^2 - a^4 - 2a + 2a^3 + 1 - a^2) + a^4 + a^{2N}}{1-a^2}$.\n$E_{min} = \\frac{1 - 2a + 2a^3 - a^4 + a^4 + a^{2N}}{1-a^2}$.\n$E_{min} = \\frac{1 - 2a + 2a^3 + a^{2N}}{1-a^2}$.\n\nThis is the final closed-form expression for the minimum least-squares error.", "answer": "$$\\boxed{\\frac{1 - 2a + 2a^{3} + a^{2N}}{1 - a^{2}}}$$", "id": "1739819"}]}