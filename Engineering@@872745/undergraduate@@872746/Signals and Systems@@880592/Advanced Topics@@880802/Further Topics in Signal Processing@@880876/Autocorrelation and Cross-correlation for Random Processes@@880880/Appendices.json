{"hands_on_practices": [{"introduction": "In signal processing, we frequently create new processes by combining existing ones. This first exercise explores one of the simplest combinations: the difference between two signals. By working through this problem [@problem_id:1699346], you will practice applying the fundamental definition of autocorrelation to a composite process, seeing how it relates back to the statistical properties of the original signals. This reinforces the core algebraic rules and the power of the expectation operator.", "problem": "Consider two jointly Wide-Sense Stationary (WSS) random processes, denoted by $X(t)$ and $Y(t)$. The statistical properties of these processes are characterized by their autocorrelation and cross-correlation functions. The autocorrelation function of $X(t)$ is defined as $R_{XX}(\\tau) = \\mathbb{E}[X(t+\\tau)X(t)]$, and similarly, the autocorrelation of $Y(t)$ is $R_{YY}(\\tau) = \\mathbb{E}[Y(t+\\tau)Y(t)]$. The cross-correlation functions between the two processes are given by $R_{XY}(\\tau) = \\mathbb{E}[X(t+\\tau)Y(t)]$ and $R_{YX}(\\tau) = \\mathbb{E}[Y(t+\\tau)X(t)]$.\n\nA new random process, $Z(t)$, is created by taking the difference between the original two processes: $Z(t) = X(t) - Y(t)$.\n\nDetermine the autocorrelation function of $Z(t)$, denoted as $R_{ZZ}(\\tau)$, expressed purely in terms of the functions $R_{XX}(\\tau)$, $R_{YY}(\\tau)$, $R_{XY}(\\tau)$, and $R_{YX}(\\tau)$.", "solution": "For a WSS process, the autocorrelation of any process $Z(t)$ is defined as $R_{ZZ}(\\tau) = \\mathbb{E}[Z(t+\\tau)Z(t)]$, which depends only on the lag $\\tau$. With $Z(t) = X(t) - Y(t)$, we write\n$$\nR_{ZZ}(\\tau) = \\mathbb{E}\\big[(X(t+\\tau) - Y(t+\\tau))(X(t) - Y(t))\\big].\n$$\nExpanding the product inside the expectation and using linearity of expectation gives\n$$\nR_{ZZ}(\\tau) = \\mathbb{E}[X(t+\\tau)X(t)] - \\mathbb{E}[X(t+\\tau)Y(t)] - \\mathbb{E}[Y(t+\\tau)X(t)] + \\mathbb{E}[Y(t+\\tau)Y(t)].\n$$\nBy the given definitions of the auto- and cross-correlation functions,\n$$\n\\mathbb{E}[X(t+\\tau)X(t)] = R_{XX}(\\tau), \\quad \\mathbb{E}[Y(t+\\tau)Y(t)] = R_{YY}(\\tau),\n$$\n$$\n\\mathbb{E}[X(t+\\tau)Y(t)] = R_{XY}(\\tau), \\quad \\mathbb{E}[Y(t+\\tau)X(t)] = R_{YX}(\\tau).\n$$\nTherefore,\n$$\nR_{ZZ}(\\tau) = R_{XX}(\\tau) - R_{XY}(\\tau) - R_{YX}(\\tau) + R_{YY}(\\tau) = R_{XX}(\\tau) + R_{YY}(\\tau) - R_{XY}(\\tau) - R_{YX}(\\tau).\n$$\nThis expresses $R_{ZZ}(\\tau)$ purely in terms of $R_{XX}(\\tau)$, $R_{YY}(\\tau)$, $R_{XY}(\\tau)$, and $R_{YX}(\\tau)$.", "answer": "$$\\boxed{R_{ZZ}(\\tau)=R_{XX}(\\tau)+R_{YY}(\\tau)-R_{XY}(\\tau)-R_{YX}(\\tau)}$$", "id": "1699346"}, {"introduction": "Now, let's move from abstract properties to a concrete discrete-time example. This practice [@problem_id:1699370] examines a simple yet illustrative process: a signal that flips its sign at every step, with a random amplitude. Calculating its autocorrelation sequence reveals how this function captures the signal's perfectly alternating structure and its average power, providing a clear link between the mathematical formula and the signal's behavior over time.", "problem": "Consider a discrete-time random process defined by $X[n] = A(-1)^n$, where $n$ is an integer index representing discrete time. In this model, $A$ is a real-valued random variable, independent of $n$, with a known second moment given by $\\mathbb{E}[A^2] = 4$. This process can be thought of as a simple model for a signal that perfectly alternates its sign at each time step, with an amplitude determined by the random variable $A$.\n\nYour task is to determine the autocorrelation sequence of this process, defined as $R_{XX}[k] = \\mathbb{E}[X[n]X[n+k]]$, where $k$ is an integer representing the time lag. Express your answer as a function of $k$.", "solution": "We start from the definition of the autocorrelation sequence for a discrete-time process:\n$$\nR_{XX}[k] = \\mathbb{E}[X[n]X[n+k]].\n$$\nGiven $X[n] = A(-1)^{n}$ with $A$ independent of $n$, substitute into the definition:\n$$\nX[n]X[n+k] = \\left(A(-1)^{n}\\right)\\left(A(-1)^{n+k}\\right) = A^{2}(-1)^{2n+k}.\n$$\nUsing the identity $(-1)^{2n} = 1$ for any integer $n$, this simplifies to\n$$\nX[n]X[n+k] = A^{2}(-1)^{k}.\n$$\nTaking expectation and noting that the only randomness is in $A$, we obtain\n$$\nR_{XX}[k] = \\mathbb{E}[A^{2}(-1)^{k}] = (-1)^{k}\\mathbb{E}[A^{2}].\n$$\nWith the given second moment $\\mathbb{E}[A^{2}] = 4$, the autocorrelation sequence becomes\n$$\nR_{XX}[k] = 4(-1)^{k}.\n$$\nThis depends only on the lag $k$, as expected for a wide-sense stationary process with this structure.", "answer": "$$\\boxed{4(-1)^{k}}$$", "id": "1699370"}, {"introduction": "Cross-correlation is a powerful tool for understanding the relationship between two different random processes. This hands-on practice [@problem_id:1699398] delves into a classic and vital example from communications engineering: two sinusoidal signals driven by the same random phase but offset by 90 degrees (quadrature signals). Determining their cross-correlation function will not only give you practice with integrals involving random variables but will also demonstrate how the result precisely quantifies the time-dependent relationship between the two signals.", "problem": "Consider two continuous-time random processes, $X(t)$ and $Y(t)$, which are generated by the same underlying physical phenomenon. These processes are described by the equations:\n$$X(t) = A \\cos(\\omega_0 t + \\Theta)$$\n$$Y(t) = A \\sin(\\omega_0 t + \\Theta)$$\nwhere $A$ and $\\omega_0$ are positive real constants representing the amplitude and angular frequency, respectively. The term $\\Theta$ is a random variable representing a phase shift, and it is uniformly distributed over the interval $[0, 2\\pi]$.\n\nThe cross-correlation between these two processes is a function of a time lag $\\tau$, defined as $R_{XY}(\\tau) = \\mathbb{E}[X(t) Y(t+\\tau)]$, where $\\mathbb{E}[\\cdot]$ denotes the expectation operator taken over the random variable $\\Theta$.\n\nDetermine the cross-correlation function $R_{XY}(\\tau)$. Your final answer should be a closed-form analytic expression in terms of $A$, $\\omega_0$, and $\\tau$.", "solution": "We are given\n$$X(t)=A\\cos(\\omega_{0}t+\\Theta),\\quad Y(t)=A\\sin(\\omega_{0}t+\\Theta),$$\nwith $\\Theta$ uniformly distributed on $[0,2\\pi]$. The cross-correlation is\n$$R_{XY}(\\tau)=\\mathbb{E}\\big[X(t)Y(t+\\tau)\\big]=\\mathbb{E}\\big[A\\cos(\\omega_{0}t+\\Theta)\\cdot A\\sin(\\omega_{0}(t+\\tau)+\\Theta)\\big].$$\nFactor out $A^{2}$ and define $\\phi=\\omega_{0}t+\\Theta$. Since $\\Theta$ is uniform on $[0,2\\pi]$, $\\phi$ is also uniform on $[0,2\\pi]$, and the expectation over $\\Theta$ equals the expectation over $\\phi$. Then\n$$R_{XY}(\\tau)=A^{2}\\mathbb{E}\\big[\\cos\\phi\\;\\sin(\\phi+\\omega_{0}\\tau)\\big] =\\frac{A^{2}}{2\\pi}\\int_{0}^{2\\pi}\\cos\\phi\\;\\sin(\\phi+\\omega_{0}\\tau)\\,d\\phi.$$\nUse the trigonometric identity $\\cos\\phi\\,\\sin(\\phi+\\alpha)=\\tfrac{1}{2}\\big[\\sin(2\\phi+\\alpha)+\\sin\\alpha\\big]$ with $\\alpha=\\omega_{0}\\tau$. Substituting gives\n$$R_{XY}(\\tau)=\\frac{A^{2}}{2\\pi}\\int_{0}^{2\\pi}\\frac{1}{2}\\big[\\sin(2\\phi+\\omega_{0}\\tau)+\\sin(\\omega_{0}\\tau)\\big]\\,d\\phi.$$\nCompute the integrals: $\\int_{0}^{2\\pi}\\sin(2\\phi+\\omega_{0}\\tau)\\,d\\phi=0$ over a full period, and $\\int_{0}^{2\\pi}\\sin(\\omega_{0}\\tau)\\,d\\phi=2\\pi\\sin(\\omega_{0}\\tau)$ since $\\sin(\\omega_{0}\\tau)$ is constant with respect to $\\phi$. Therefore,\n$$R_{XY}(\\tau)=\\frac{A^{2}}{2}\\sin(\\omega_{0}\\tau).$$\nThis result is independent of $t$, consistent with wide-sense stationarity induced by the uniform random phase.", "answer": "$$\\boxed{\\frac{A^{2}}{2}\\sin(\\omega_{0}\\tau)}$$", "id": "1699398"}]}