{"hands_on_practices": [{"introduction": "Decimation is a fundamental process in multirate signal processing used to reduce a signal's sampling rate. This practice walks you through a concrete example of a single-stage decimator, which combines low-pass filtering to prevent aliasing with the downsampling operation itself. By working through this problem, you will solidify your understanding of how these two steps interact to correctly change a signal's rate [@problem_id:1737262].", "problem": "In a digital signal processing system for data reduction, a sensor's output is modeled as a finite-duration discrete-time signal $x[n]$. This signal is first processed by a low-pass Finite Impulse Response (FIR) filter and then downsampled.\n\nThe input signal $x[n]$ is defined as:\n$$\nx[n] = (n+1) \\quad \\text{for} \\quad 0 \\le n \\le 3\n$$\nand $x[n] = 0$ for all other values of $n$.\n\nThe FIR filter has an impulse response $h[n]$ given by:\n$$\nh[n] = 0.5\\delta[n] + 0.5\\delta[n-1]\n$$\nwhere $\\delta[n]$ is the Kronecker delta function.\n\nThe signal coming out of the filter, let's call it $w[n]$, is then downsampled by an integer factor of $M=2$. The downsampling operation is defined such that the final output signal $y[n]$ is given by $y[n] = w[2n]$.\n\nWhich of the following expressions correctly represents the final output signal $y[n]$?\n\nA. $y[n] = \\delta[n] + 3\\delta[n-1]$\n\nB. $y[n] = 0.5\\delta[n] + 2\\delta[n-1] + 1.5\\delta[n-2]$\n\nC. $y[n] = 0.5\\delta[n] + 2.5\\delta[n-1]$\n\nD. $y[n] = 1.5\\delta[n] + 3.5\\delta[n-1]$\n\nE. $y[n] = 0.5\\delta[n] + 2.5\\delta[n-1] + 2\\delta[n-2]$", "solution": "We are given a finite-duration discrete-time signal defined by $x[n]=(n+1)$ for $0 \\leq n \\leq 3$ and $x[n]=0$ otherwise, so explicitly $x[0]=1$, $x[1]=2$, $x[2]=3$, $x[3]=4$, and $x[n]=0$ for all other $n$. The FIR filter has impulse response $h[n]=\\frac{1}{2}\\delta[n]+\\frac{1}{2}\\delta[n-1]$. Let $w[n]=(x*h)[n]$ denote the output of the filter, where convolution is defined by\n$$\nw[n]=\\sum_{k=-\\infty}^{\\infty} x[k]\\,h[n-k].\n$$\nSubstituting $h[n-k]=\\frac{1}{2}\\delta[n-k]+\\frac{1}{2}\\delta[n-k-1]$ and using linearity and the sifting property of the Kronecker delta, we obtain\n$$\nw[n]=\\frac{1}{2}\\sum_{k} x[k]\\delta[n-k]+\\frac{1}{2}\\sum_{k} x[k]\\delta[n-k-1]\n=\\frac{1}{2}x[n]+\\frac{1}{2}x[n-1].\n$$\nUsing the values of $x[n]$, we compute $w[n]$ at the indices where it can be nonzero:\n- For $n0$, $w[n]=0$.\n- $n=0$: $w[0]=\\frac{1}{2}x[0]+\\frac{1}{2}x[-1]=\\frac{1}{2}\\cdot 1+0=\\frac{1}{2}$.\n- $n=1$: $w[1]=\\frac{1}{2}x[1]+\\frac{1}{2}x[0]=\\frac{1}{2}\\cdot 2+\\frac{1}{2}\\cdot 1=\\frac{3}{2}$.\n- $n=2$: $w[2]=\\frac{1}{2}x[2]+\\frac{1}{2}x[1]=\\frac{1}{2}\\cdot 3+\\frac{1}{2}\\cdot 2=\\frac{5}{2}$.\n- $n=3$: $w[3]=\\frac{1}{2}x[3]+\\frac{1}{2}x[2]=\\frac{1}{2}\\cdot 4+\\frac{1}{2}\\cdot 3=\\frac{7}{2}$.\n- $n=4$: $w[4]=\\frac{1}{2}x[4]+\\frac{1}{2}x[3]=0+\\frac{1}{2}\\cdot 4=2$.\n- For $n\\geq 5$, $w[n]=0$.\nThe downsampling by a factor $M=2$ yields $y[n]=w[2n]$, so\n$$\ny[0]=w[0]=\\frac{1}{2},\\quad y[1]=w[2]=\\frac{5}{2},\\quad y[2]=w[4]=2,\\quad y[n]=0\\ \\text{for all other}\\ n.\n$$\nTherefore, expressed using shifted Kronecker deltas,\n$$\ny[n]=\\frac{1}{2}\\delta[n]+\\frac{5}{2}\\delta[n-1]+2\\delta[n-2],\n$$\nwhich matches option E.", "answer": "$$\\boxed{E}$$", "id": "1737262"}, {"introduction": "Interpolation, the process of increasing a signal's sampling rate, is the conceptual counterpart to decimation. It involves upsampling—inserting zero-valued samples—followed by low-pass filtering to remove the spectral images created by the upsampler. This exercise demonstrates how a simple input signal can be used to generate a specific pulse shape, a common application of interpolation in digital signal synthesis and communications [@problem_id:1737276].", "problem": "In a digital signal processing system designed for creating specific pulse shapes, an input signal $x[n]$ is first expanded by an upsampler and then shaped by a Finite Impulse Response (FIR) filter.\n\nThe input signal is given by the expression $x[n] = \\delta[n] - \\delta[n-1]$, where $\\delta[n]$ is the discrete-time unit impulse function (i.e., $\\delta[n] = 1$ for $n=0$ and is zero otherwise).\n\nThe signal $x[n]$ is first processed by an upsampler with an integer factor of $L=4$. The upsampling operation, also known as interpolation, inserts $L-1$ zero-valued samples between each consecutive sample of the input signal. Let the upsampled signal be denoted by $x_u[n]$.\n\nThis intermediate signal $x_u[n]$ is then passed through an FIR filter with the impulse response $h[n]$ defined as:\n$h[n] = 1$ for $0 \\le n \\le 3$\n$h[n] = 0$ otherwise.\n\nThe final output of the system is $y[n]$, which results from the discrete-time convolution of $x_u[n]$ with $h[n]$.\n\nWhich of the following descriptions correctly represents the output signal $y[n]$? For each option, the sequence lists the non-zero values starting from the sample at time index $n=0$.\n\nA. The sequence $\\{1, 1, 1, 1, -1, -1, -1, -1\\}$.\n\nB. The sequence $\\{1, 0, 0, 0, -1\\}$.\n\nC. The sequence $\\{1, 1, 1, 1\\}$.\n\nD. The sequence $\\{1, 1, 1, 1, 1, 1, 1, 1\\}$.\n\nE. The sequence is $\\{1, -1\\}$ with 15 zero-valued samples between them.", "solution": "The input is the difference of two unit impulses,\n$$\nx[n]=\\delta[n]-\\delta[n-1].\n$$\nUpsampling by a factor $L=4$ means inserting $L-1$ zeros between consecutive samples. Formally,\n$$\nx_{u}[n]=\\sum_{k=-\\infty}^{\\infty}x[k]\\,\\delta[n-4k].\n$$\nSince $x[k]$ is nonzero only at $k=0$ and $k=1$, with $x[0]=1$ and $x[1]=-1$, we obtain\n$$\nx_{u}[n]=x[0]\\delta[n-0]+x[1]\\delta[n-4]=\\delta[n]-\\delta[n-4].\n$$\n\nThe FIR filter has impulse response\n$$\nh[n]=\\begin{cases}\n1,  0\\leq n\\leq 3,\\\\\n0,  \\text{otherwise}.\n\\end{cases}\n$$\nThe output is the convolution $y[n]=x_{u}[n]*h[n]$. Using linearity and time-invariance (sifting) of LTI systems,\n$$\ny[n]=(\\delta[n]-\\delta[n-4])*h[n]=h[n]-h[n-4].\n$$\nFrom the support of $h[n]$, we have $h[n]=1$ for $0\\leq n\\leq 3$ and $0$ otherwise, and $h[n-4]=1$ for $4\\leq n\\leq 7$ and $0$ otherwise. Therefore,\n$$\ny[n]=\\begin{cases}\n1,  0\\leq n\\leq 3,\\\\\n-1,  4\\leq n\\leq 7,\\\\\n0,  \\text{otherwise}.\n\\end{cases}\n$$\nListing the nonzero values starting at $n=0$ gives the sequence $\\{1,1,1,1,-1,-1,-1,-1\\}$, which corresponds to option A.", "answer": "$$\\boxed{A}$$", "id": "1737276"}, {"introduction": "While single-stage rate converters are simple to understand, they can be computationally expensive for large rate changes. A common engineering solution is to use a multi-stage approach, breaking the conversion into smaller, more efficient steps. This advanced practice guides you through an optimization problem to find the most efficient way to factor a two-stage decimator, providing insight into the practical design trade-offs that govern real-world multirate systems [@problem_id:1737252].", "problem": "In the design of modern Software-Defined Radios (SDRs), efficient sample rate conversion is a critical task. Consider the problem of decimating a signal by a large integer factor $M$. To manage computational complexity, this is often implemented as a two-stage process. The overall decimation factor is factorized as $M = M_1 M_2$, where the first stage decimates by $M_1$ and the second stage by $M_2$. Each stage consists of an anti-aliasing Finite Impulse Response (FIR) filter followed by a downsampler.\n\nYour goal is to determine the optimal factorization that minimizes the total computational cost. The following model is to be used:\n\n1.  The total computational cost, $R$, is the sum of the costs of the two stages, $R = R_1 + R_2$.\n2.  The cost of a stage $k$, denoted $R_k$, is measured in operations per second. It is directly proportional to both the order of its FIR filter, $N_k$, and the sampling rate at its input, $f_{\\text{in},k}$. Assume the constant of proportionality, $\\mathcal{C}$, is the same for both stages. Thus, $R_k = \\mathcal{C} N_k f_{\\text{in},k}$.\n3.  The filter order, $N_k$, is determined by the required sharpness of its cutoff. For many filter design methods, the order is inversely proportional to the filter's transition bandwidth, $\\Delta f_k$. Let this relationship be $N_k = \\mathcal{A} / \\Delta f_k$, where $\\mathcal{A}$ is a constant related to the desired passband and stopband ripple.\n4.  For this analysis, a simplified design model is adopted where the transition bandwidth, $\\Delta f_k$, for the anti-aliasing filter in stage $k$ (which decimates by a factor of $M_k$) is assumed to be directly proportional to the Nyquist frequency of the *output* signal of that stage. The output sampling rate is $f_{\\text{out},k} = f_{\\text{in},k} / M_k$. The Nyquist frequency is $f_{\\text{out},k} / 2$. Let the constant of proportionality be $\\mathcal{B}$, so that $\\Delta f_k = \\mathcal{B} \\frac{f_{\\text{in},k}}{2 M_k}$.\n\nThe initial sampling rate of the signal entering the first stage is $f_s$. For the purpose of optimization, treat the decimation factors $M_1$ and $M_2$ as continuous positive real variables.\n\nBased on this model, derive an expression for the optimal first-stage decimation factor, $M_{1,\\text{opt}}$, that minimizes the total computational cost $R$. Express your final answer in terms of the total decimation factor $M$.", "solution": "The total computational cost is modeled as $R=R_{1}+R_{2}$, with each stage cost given by $R_{k}=\\mathcal{C}N_{k}f_{\\text{in},k}$. The filter order is $N_{k}=\\mathcal{A}/\\Delta f_{k}$, and the transition bandwidth is $\\Delta f_{k}=\\mathcal{B}\\frac{f_{\\text{in},k}}{2M_{k}}$.\n\nFor stage $k$, substituting $\\Delta f_{k}$ into $N_{k}$ gives\n$$\nN_{k}=\\frac{\\mathcal{A}}{\\Delta f_{k}}=\\frac{\\mathcal{A}}{\\mathcal{B}\\frac{f_{\\text{in},k}}{2M_{k}}}=\\frac{2\\mathcal{A}}{\\mathcal{B}}\\frac{M_{k}}{f_{\\text{in},k}}.\n$$\nTherefore,\n$$\nR_{k}=\\mathcal{C}N_{k}f_{\\text{in},k}=\\mathcal{C}\\left(\\frac{2\\mathcal{A}}{\\mathcal{B}}\\frac{M_{k}}{f_{\\text{in},k}}\\right)f_{\\text{in},k}=\\frac{2\\mathcal{A}\\mathcal{C}}{\\mathcal{B}}M_{k}.\n$$\n\nApplying this to both stages, with $f_{\\text{in},1}=f_{s}$ and $f_{\\text{in},2}=f_{s}/M_{1}$, and using $M=M_{1}M_{2}$, we can also compute explicitly:\n- Stage 1:\n$$\n\\Delta f_{1}=\\mathcal{B}\\frac{f_{s}}{2M_{1}},\\quad N_{1}=\\frac{2\\mathcal{A}}{\\mathcal{B}}\\frac{M_{1}}{f_{s}},\\quad R_{1}=\\frac{2\\mathcal{A}\\mathcal{C}}{\\mathcal{B}}M_{1}.\n$$\n- Stage 2:\n$$\n\\Delta f_{2}=\\mathcal{B}\\frac{f_{\\text{in},2}}{2M_{2}}=\\mathcal{B}\\frac{f_{s}/M_{1}}{2M_{2}}=\\mathcal{B}\\frac{f_{s}}{2M},\n$$\n$$\nN_{2}=\\frac{\\mathcal{A}}{\\Delta f_{2}}=\\frac{2\\mathcal{A}}{\\mathcal{B}}\\frac{M}{f_{s}},\\quad R_{2}=\\mathcal{C}N_{2}\\frac{f_{s}}{M_{1}}=\\frac{2\\mathcal{A}\\mathcal{C}}{\\mathcal{B}}\\frac{M}{M_{1}}.\n$$\n\nThus the total cost is\n$$\nR=R_{1}+R_{2}=\\frac{2\\mathcal{A}\\mathcal{C}}{\\mathcal{B}}\\left(M_{1}+\\frac{M}{M_{1}}\\right).\n$$\nMinimizing over positive real $M_{1}$ reduces to minimizing $g(M_{1})=M_{1}+\\frac{M}{M_{1}}$. Compute the derivative and set to zero:\n$$\n\\frac{\\mathrm{d}g}{\\mathrm{d}M_{1}}=1-\\frac{M}{M_{1}^{2}}=0\\quad\\Longrightarrow\\quad M_{1}^{2}=M\\quad\\Longrightarrow\\quad M_{1}=M^{1/2}.\n$$\nThe second derivative is $\\frac{\\mathrm{d}^{2}g}{\\mathrm{d}M_{1}^{2}}=\\frac{2M}{M_{1}^{3}}0$, confirming a minimum. Therefore, the optimal first-stage decimation factor is $M_{1,\\text{opt}}=M^{1/2}$.", "answer": "$$\\boxed{M^{1/2}}$$", "id": "1737252"}]}