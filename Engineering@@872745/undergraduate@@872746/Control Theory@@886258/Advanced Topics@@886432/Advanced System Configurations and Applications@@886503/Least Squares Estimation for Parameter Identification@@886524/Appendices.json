{"hands_on_practices": [{"introduction": "The first step in applying least squares is translating a theoretical model and raw data into the matrix equation $Y = \\Phi\\theta$. This exercise provides fundamental practice in this crucial task by asking you to construct the regressor matrix $\\Phi$ from experimental data for a second-order system [@problem_id:1588623]. Mastering this skill is essential, as the regressor matrix forms the basis for all subsequent parameter estimation calculations.", "problem": "An engineer is conducting a system identification experiment on a thermal process. The process is modeled by the following second-order linear discrete-time equation:\n$$y(k) = a_1 y(k-1) + a_2 y(k-2) + b_1 u(k-1)$$\nwhere $k$ is the discrete time index, $y(k)$ is the measured temperature output, $u(k)$ is the heater power input, and $a_1, a_2, b_1$ are the unknown model parameters.\n\nThe system is initially at rest, meaning $y(k) = 0$ for all $k \\leq 0$. At time $k=1$, a unit step input is applied to the system, such that the input signal is defined as $u(k) = 0$ for $k  1$ and $u(k) = 1$ for $k \\geq 1$.\n\nThe following sequence of temperature measurements is recorded:\n$y(1) = 0.5$\n$y(2) = 1.5$\n$y(3) = 2.0$\n$y(4) = 2.2$\n$y(5) = 2.3$\n\nFor the purpose of estimating the parameters using least squares, the system equations are stacked into a linear regression model of the form $Y = \\Phi \\theta$, where $\\theta = \\begin{pmatrix} a_1  a_2  b_1 \\end{pmatrix}^T$ is the vector of parameters. Using the available measurements from $k=2$ to $k=5$, construct the numerical regressor matrix $\\Phi$.", "solution": "The given model is the second-order linear discrete-time equation\n$$y(k)=a_{1}y(k-1)+a_{2}y(k-2)+b_{1}u(k-1).$$\nTo form a linear regression $Y=\\Phi\\theta$ with $\\theta=\\begin{pmatrix}a_{1}a_{2}b_{1}\\end{pmatrix}^{T}$, each row of the regressor matrix $\\Phi$ for time index $k$ is\n$$\\phi(k)^T=\\begin{pmatrix}y(k-1)  y(k-2)  u(k-1)\\end{pmatrix}.$$\nThe system is at rest for $k\\leq 0$, so $y(0)=0$, and the input is a unit step at $k=1$, so $u(k)=0$ for $k1$ and $u(k)=1$ for $k\\geq 1$. Therefore, for $k=2,3,4,5$ we have $u(k-1)=1$.\n\nUsing the measured outputs $y(1)=0.5$, $y(2)=1.5$, $y(3)=2.0$, $y(4)=2.2$, $y(5)=2.3$, the rows of $\\Phi$ are computed as follows:\n- For $k=2$: $\\phi(2)^T=\\begin{pmatrix}y(1)  y(0)  u(1)\\end{pmatrix}=\\begin{pmatrix}0.5  0  1\\end{pmatrix}$.\n- For $k=3$: $\\phi(3)^T=\\begin{pmatrix}y(2)  y(1)  u(2)\\end{pmatrix}=\\begin{pmatrix}1.5  0.5  1\\end{pmatrix}$.\n- For $k=4$: $\\phi(4)^T=\\begin{pmatrix}y(3)  y(2)  u(3)\\end{pmatrix}=\\begin{pmatrix}2.0  1.5  1\\end{pmatrix}$.\n- For $k=5$: $\\phi(5)^T=\\begin{pmatrix}y(4)  y(3)  u(4)\\end{pmatrix}=\\begin{pmatrix}2.2  2.0  1\\end{pmatrix}$.\n\nStacking these rows yields the numerical regressor matrix\n$$\\Phi=\\begin{pmatrix}\n0.5  0  1\\\\\n1.5  0.5  1\\\\\n2.0  1.5  1\\\\\n2.2  2.0  1\n\\end{pmatrix}.$$", "answer": "$$\\boxed{\\begin{pmatrix}0.5  0  1 \\\\ 1.5  0.5  1 \\\\ 2.0  1.5  1 \\\\ 2.2  2.0  1\\end{pmatrix}}$$", "id": "1588623"}, {"introduction": "Real-world systems are often subject to constant disturbances or measurement offsets that are not part of the core dynamics. This practice moves beyond the basic model to show how the least squares framework can be adapted to estimate such constant terms by simply augmenting the parameter vector and regressor matrix [@problem_id:1588627]. By working through a complete solution, you will gain hands-on experience in solving the normal equations for a more realistic and practical model.", "problem": "An engineer is working to identify the parameters of a discrete-time dynamical system observed in a manufacturing process. The system's output, $y(k)$, is believed to follow a first-order linear model driven by an input, $u(k)$, and affected by a constant environmental disturbance, $d$. The proposed model is:\n$$y(k) = a y(k-1) + b u(k-1) + d$$\nwhere $k$ is the time index, and $a$, $b$, and $d$ are the unknown constant parameters to be determined. A sequence of input and output data has been collected from the process as follows:\n- Input sequence: $u(0) = 1$, $u(1) = 0$, $u(2) = 1$, $u(3) = 0$.\n- Output sequence: $y(0) = 2$, $y(1) = 4.1$, $y(2) = 2.9$, $y(3) = 4.6$, $y(4) = 3.3$.\n\nUsing the entire dataset provided, apply the method of batch least squares to find the best estimates for the parameters. The parameter vector to be estimated is $\\theta = \\begin{pmatrix} a  b  d \\end{pmatrix}^T$.\n\nProvide your final answer as a row matrix containing the estimated values of $a$, $b$, and $d$, in that order. Round each parameter to three significant figures.", "solution": "We model the data with the first-order linear system\n$$y(k) = a\\,y(k-1) + b\\,u(k-1) + d,$$\nand form the batch least-squares regression $Y = \\Phi \\theta$ with $\\theta = \\begin{pmatrix} a  b  d \\end{pmatrix}^{T}$. Using the samples for $k=1,2,3,4$, we have\n$$\\Phi = \\begin{pmatrix}\n2  1  1\\\\\n4.1  0  1\\\\\n2.9  1  1\\\\\n4.6  0  1\n\\end{pmatrix}, \\quad\nY = \\begin{pmatrix}\n4.1\\\\\n2.9\\\\\n4.6\\\\\n3.3\n\\end{pmatrix}.$$\nThe batch least-squares solution is\n$$\\hat{\\theta} = \\left(\\Phi^{T}\\Phi\\right)^{-1}\\Phi^{T}Y,$$\nso we compute\n$$\\Phi^{T}\\Phi = \\begin{pmatrix}\n50.38  4.9  13.6\\\\\n4.9  2  2\\\\\n13.6  2  4\n\\end{pmatrix}, \\quad\n\\Phi^{T}Y = \\begin{pmatrix}\n48.61\\\\\n8.7\\\\\n14.9\n\\end{pmatrix}.$$\nThus $\\hat{\\theta}$ solves the normal equations\n$$\\begin{cases}\n50.38\\,a + 4.9\\,b + 13.6\\,d = 48.61,\\\\\n4.9\\,a + 2\\,b + 2\\,d = 8.7,\\\\\n13.6\\,a + 2\\,b + 4\\,d = 14.9.\n\\end{cases}$$\nSubtract the second from the third to eliminate $b$:\n$$(13.6 - 4.9)a + (2-2)b + (4-2)d = 14.9 - 8.7,$$\nwhich gives\n$$8.7\\,a + 2\\,d = 6.2 \\;\\Rightarrow\\; d = 3.1 - 4.35\\,a.$$\nFrom the second equation,\n$$2\\,b = 8.7 - 4.9\\,a - 2\\,d = 8.7 - 4.9\\,a - (6.2 - 8.7\\,a) = 2.5 + 3.8\\,a,$$\nso\n$$b = 1.25 + 1.9\\,a.$$\nSubstitute $b$ and $d$ into the first equation:\n$$50.38\\,a + 4.9(1.25 + 1.9\\,a) + 13.6(3.1 - 4.35\\,a) = 48.61.$$\nCompute terms:\n$$50.38\\,a + 6.125 + 9.31\\,a + 42.16 - 59.16\\,a = 48.61,$$\n$$(50.38 + 9.31 - 59.16)a + (6.125 + 42.16) = 48.61,$$\n$$0.53\\,a + 48.285 = 48.61 \\;\\Rightarrow\\; 0.53\\,a = 0.325 \\;\\Rightarrow\\; a = \\frac{0.325}{0.53} \\approx 0.613207547.$$\nThen\n$$b = 1.25 + 1.9\\,a \\approx 1.25 + 1.9 \\times 0.613207547 \\approx 2.415094339,$$\n$$d = 3.1 - 4.35\\,a \\approx 3.1 - 4.35 \\times 0.613207547 \\approx 0.432547171.$$\nRounding each parameter to three significant figures yields\n$$a \\approx 0.613,\\quad b \\approx 2.42,\\quad d \\approx 0.433.$$", "answer": "$$\\boxed{\\begin{pmatrix}0.613  2.42  0.433\\end{pmatrix}}$$", "id": "1588627"}, {"introduction": "The power of least squares is contingent upon key assumptions, and violating them can lead to misleading results. This analytical exercise serves as a critical cautionary tale, demonstrating how applying a simple model to data with unacknowledged DC offsets results in biased parameter estimates, even with an infinite amount of data [@problem_id:1588606]. Understanding this pitfall highlights the importance of data preprocessing and choosing an appropriate model structure, reinforcing the value of the technique used in the previous exercise [@problem_id:1588627].", "problem": "An engineer is developing a discrete-time model for the thermal dynamics of a server's Central Processing Unit (CPU). The model aims to relate the input power supplied to a cooling fan, $u(k)$, to the CPU's temperature, $y(k)$, at discrete time step $k$. The engineer postulates the following first-order linear model structure for the system:\n$$y(k) = a y(k-1) + b u(k-1) + \\epsilon(k)$$\nwhere $a$ and $b$ are the model parameters to be identified, and $\\epsilon(k)$ represents noise and unmodeled dynamics.\n\nThe true physical process, describing deviations from a stable ambient condition, is accurately represented by:\n$$y_0(k) = a_{\\text{true}} y_0(k-1) + b_{\\text{true}} u_0(k-1)$$\nHere, $y_0(k)$ and $u_0(k)$ are the true temperature deviation and the true fan power input, respectively. The known true parameters are $a_{\\text{true}} = 0.9$ and $b_{\\text{true}} = 0.4$. The input signal $u_0(k)$ is a stationary zero-mean white noise process with variance $\\sigma_u^2 = 2.0$ (in appropriate power units squared).\n\nUnfortunately, the measurement instruments have systematic errors. The measured temperature $y(k)$ and measured fan power $u(k)$ both include constant DC offsets:\n$$y(k) = y_0(k) + y_{\\text{off}}$$\n$$u(k) = u_0(k) + u_{\\text{off}}$$\nThe sensor offsets are determined to be $y_{\\text{off}} = 10.0$ (in units of degrees Celsius) and $u_{\\text{off}} = 1.0$ (in units of power).\n\nThe engineer, not realizing the critical importance of these offsets, applies a standard batch Least Squares Estimation (LSE) algorithm directly to a very large dataset of the raw measurements $(u(k), y(k))$. In the limit of an infinitely large dataset, the LSE algorithm will converge to a biased set of parameter estimates $(\\hat{a}, \\hat{b})$.\n\nCalculate the numerical values of these biased estimates $(\\hat{a}, \\hat{b})$. Provide your answers for $\\hat{a}$ and $\\hat{b}$ rounded to four significant figures.", "solution": "We start from the engineerâ€™s regression model without intercept:\n$$y(k)=a\\,y(k-1)+b\\,u(k-1)+\\epsilon(k),$$\nand define the regressor vector and parameter vector as\n$$\\phi(k)\\triangleq\\begin{bmatrix}y(k-1)\\\\ u(k-1)\\end{bmatrix},\\qquad \\theta\\triangleq\\begin{bmatrix}a\\\\ b\\end{bmatrix}.$$\nFor an infinitely large dataset, the Least Squares estimate converges to the solution of the population normal equations\n$$\\mathbb{E}\\{\\phi(k)\\phi^{\\top}(k)\\}\\,\\hat{\\theta}=\\mathbb{E}\\{\\phi(k)\\,y(k)\\}.$$\n\nGiven the true dynamics for deviations from ambient,\n$$y_{0}(k)=a_{\\text{true}}\\,y_{0}(k-1)+b_{\\text{true}}\\,u_{0}(k-1),$$\nwith $u_{0}(k)$ zero-mean white noise of variance $\\sigma_{u}^{2}$, and the measured signals\n$$y(k)=y_{0}(k)+y_{\\text{off}},\\qquad u(k)=u_{0}(k)+u_{\\text{off}},$$\nwe can express $y(k)$ in terms of the measured regressors:\n$$y(k)=a_{\\text{true}}\\,y_{0}(k-1)+b_{\\text{true}}\\,u_{0}(k-1)+y_{\\text{off}}\n=a_{\\text{true}}\\,y(k-1)+b_{\\text{true}}\\,u(k-1)+c_{0},$$\nwhere the omitted constant (intercept) is\n$$c_{0}=y_{\\text{off}}(1-a_{\\text{true}})-b_{\\text{true}}\\,u_{\\text{off}}.$$\n\nLet $V\\triangleq \\operatorname{var}(y_{0}(k))$. For the stable first-order system driven by white noise,\n$$V=a_{\\text{true}}^{2}V+b_{\\text{true}}^{2}\\sigma_{u}^{2}\\quad\\Rightarrow\\quad V=\\frac{b_{\\text{true}}^{2}\\sigma_{u}^{2}}{1-a_{\\text{true}}^{2}}.$$\nUsing stationarity and zero means of $y_{0}$ and $u_{0}$, and independence of $y_{0}(k-1)$ and $u_{0}(k-1)$, we obtain the required moments:\n$$\\mathbb{E}\\{y(k-1)\\}=y_{\\text{off}},\\quad \\mathbb{E}\\{u(k-1)\\}=u_{\\text{off}},$$\n$$\\mathbb{E}\\{y(k-1)^{2}\\}=V+y_{\\text{off}}^{2},\\quad \\mathbb{E}\\{u(k-1)^{2}\\}=\\sigma_{u}^{2}+u_{\\text{off}}^{2},\\quad \\mathbb{E}\\{y(k-1)u(k-1)\\}=y_{\\text{off}}u_{\\text{off}},$$\nand\n$$y(k)=a_{\\text{true}}\\,y_{0}(k-1)+b_{\\text{true}}\\,u_{0}(k-1)+y_{\\text{off}},$$\nwhich gives\n$$\\mathbb{E}\\{y(k-1)y(k)\\}=a_{\\text{true}}V+y_{\\text{off}}^{2},\\qquad \\mathbb{E}\\{u(k-1)y(k)\\}=b_{\\text{true}}\\sigma_{u}^{2}+y_{\\text{off}}u_{\\text{off}}.$$\n\nTherefore,\n$$\\mathbb{E}\\{\\phi\\phi^{\\top}\\}=\\begin{bmatrix}V+y_{\\text{off}}^{2}  y_{\\text{off}}u_{\\text{off}}\\\\ y_{\\text{off}}u_{\\text{off}}  \\sigma_{u}^{2}+u_{\\text{off}}^{2}\\end{bmatrix},\\qquad\n\\mathbb{E}\\{\\phi y\\}=\\begin{bmatrix}a_{\\text{true}}V+y_{\\text{off}}^{2}\\\\ b_{\\text{true}}\\sigma_{u}^{2}+y_{\\text{off}}u_{\\text{off}}\\end{bmatrix}.$$\nSolving the $2\\times 2$ linear system yields\n$$\\hat{\\theta}=\\begin{bmatrix}\\hat{a}\\\\ \\hat{b}\\end{bmatrix}=\\bigl(\\mathbb{E}\\{\\phi\\phi^{\\top}\\}\\bigr)^{-1}\\,\\mathbb{E}\\{\\phi y\\}.$$\n\nNow substitute the given numerical values $a_{\\text{true}}=0.9$, $b_{\\text{true}}=0.4$, $\\sigma_{u}^{2}=2.0$, $y_{\\text{off}}=10.0$, $u_{\\text{off}}=1.0$. First compute\n$$V=\\frac{b_{\\text{true}}^{2}\\sigma_{u}^{2}}{1-a_{\\text{true}}^{2}}=\\frac{(0.4)^{2}\\cdot 2.0}{1-(0.9)^{2}}=\\frac{0.32}{0.19}=\\frac{32}{19}.$$\nHence\n$$\\mathbb{E}\\{\\phi\\phi^{\\top}\\}=\\begin{bmatrix}\\frac{32}{19}+100  10\\\\ 10  2+1\\end{bmatrix}=\\begin{bmatrix}\\frac{1932}{19}  10\\\\ 10  3\\end{bmatrix},\\quad\n\\mathbb{E}\\{\\phi y\\}=\\begin{bmatrix}0.9\\cdot \\frac{32}{19}+100\\\\ 0.4\\cdot 2+10\\end{bmatrix}=\\begin{bmatrix}\\frac{1928.8}{19}\\\\ 10.8\\end{bmatrix}.$$\nThe determinant is\n$$D=\\left(\\frac{1932}{19}\\right)\\cdot 3-10\\cdot 10=\\frac{5796}{19}-100=\\frac{3896}{19}.$$\nUsing Cramer's rule,\n$$\\hat{a}=\\frac{\\det\\begin{pmatrix} \\frac{1928.8}{19}  10 \\\\ 10.8  3 \\end{pmatrix}}{D} = \\frac{3 \\cdot \\frac{1928.8}{19} - 10 \\cdot 10.8}{\\frac{3896}{19}} = \\frac{5786.4 - 2052}{3896} = \\frac{3734.4}{3896} \\approx 0.95852156058,$$\n$$\\hat{b}=\\frac{\\det\\begin{pmatrix} \\frac{1932}{19}  \\frac{1928.8}{19} \\\\ 10  10.8 \\end{pmatrix}}{D} = \\frac{\\frac{1932}{19} \\cdot 10.8 - 10 \\cdot \\frac{1928.8}{19}}{\\frac{3896}{19}} = \\frac{20865.6 - 19288}{3896} = \\frac{1577.6}{3896} \\approx 0.40492813105.$$\nRounding each to four significant figures gives\n$$\\hat{a}\\approx 0.9585,\\qquad \\hat{b}\\approx 0.4049.$$", "answer": "$$\\boxed{\\begin{pmatrix}0.9585  0.4049\\end{pmatrix}}$$", "id": "1588606"}]}