{"hands_on_practices": [{"introduction": "Before we can build a mathematical model, we must first collect meaningful data through well-designed experiments. This thought experiment explores a crucial concept in system identification: the need for a 'persistently exciting' input [@problem_id:1585908]. By analyzing a flawed experimental setup, you will develop an intuition for what constitutes 'good' data for uniquely identifying a system's full dynamic characteristics.", "problem": "An undergraduate student in a control systems lab is tasked with identifying a linear time-invariant (LTI) model, specifically a transfer function, for the lateral dynamics (leaning motion) of a bicycle. Their proposed experimental procedure is as follows:\n\n1.  Balance the bicycle in a perfectly upright position so it is stationary.\n2.  Provide a small, brief push (approximating a Dirac delta impulse input) to the frame.\n3.  Record the lean angle of the bicycle as it falls over, using a high-precision gyroscopic sensor.\n4.  Use the recorded time-series data of the lean angle as the system's output to fit a model using a standard system identification algorithm, such as an AutoRegressive with eXogenous input (ARX) method.\n\nAssuming the student has access to ideal sensors and data acquisition equipment (i.e., negligible noise and a sufficient sampling rate), which of the following statements best explains the fundamental reason why this experiment is an ill-posed problem for identifying a useful and generalizable transfer function for the bicycle's lateral control?\n\nA. The force of gravity, which causes the bicycle to fall, is a constant and not a dynamic input, making it impossible to identify a dynamic system.\nB. The dynamics of a falling bicycle are highly non-linear, especially at large angles, and thus cannot be approximated by any linear transfer function.\nC. The experiment lacks a persistently exciting input; the system's response is entirely determined by its unstable initial condition and does not contain sufficient frequency content to uniquely identify the system's full dynamic characteristics.\nD. A transfer function is only valid for stable systems, and since the bicycle in this configuration is open-loop unstable, the entire concept of identifying its transfer function is meaningless.", "solution": "We formalize the identification goal as estimating an LTI transfer function $G(s)$ such that, for an input $u(t)$ and output $y(t)$, the output decomposes as\n$$\ny(t)=y_{\\text{zs}}(t)+y_{\\text{zi}}(t),\n$$\nwhere $y_{\\text{zs}}(t)=(g*u)(t)$ is the zero-state response with $g(t)$ the impulse response, and $y_{\\text{zi}}(t)$ is the zero-input response determined by the system’s initial state.\n\nIn the proposed experiment:\n- The bicycle is balanced at an open-loop unstable equilibrium (upright).\n- A brief push is applied at $t=0$ approximating a Dirac impulse, then $u(t)=0$ for $t>0$.\n- The lean angle is recorded as the bicycle falls.\n\nKey identification requirements:\n1) To uniquely identify a finite-dimensional $G(s)$ (or an ARX model of certain orders), the input must be persistently exciting of sufficiently high order. In both continuous and discrete time identification frameworks, this means the input must contain sufficiently rich frequency content over time so that the regressor covariance (or its continuous-time analog) is full rank. In discrete-time ARX with order greater than $1$, a single nonzero input sample (an impulse-like input) yields regressors that are rank deficient, so the data do not satisfy the persistently exciting condition for unique parameter recovery.\n2) With $u(t)=0$ for all $t>0$ after the brief push, the recorded response is dominated by the zero-input response $y_{\\text{zi}}(t)$ of an unstable system, i.e., by the natural modes (poles). Free response data can reveal pole locations but are insufficient to uniquely determine zeros and input-to-output dynamics without a persistently exciting input. In other words, many different $G(s)$ can share the same unstable pole set but differ in zeros and gain; without rich input excitation, these cannot be uniquely identified.\n3) For a useful and generalizable control-oriented transfer function (e.g., mapping a control input such as steering torque to lean angle), one typically excites the system with rich input signals (such as multisine, PRBS, or sufficiently long broadband noise) around the operating point of interest while maintaining small angles so that linearization is valid. The proposed experiment does not maintain small-angle operation: after the brief push, the bicycle departs the linear neighborhood and falls, further confounding linear identification. However, the fundamental system identification issue is the lack of persistently exciting input rather than the mere presence of nonlinearity.\n\nEvaluation of options:\n- A is incorrect: constant gravity can be incorporated into the linearized dynamics about the operating point; dynamic identification does not require a time-varying gravity signal.\n- B is not the fundamental reason: small-angle linearization of bicycle lean dynamics is valid and widely used; the issue here arises before nonlinearity becomes decisive, namely, from the absence of persistently exciting input and dominance of zero-input response.\n- C is correct: the experiment lacks a persistently exciting input. After the brief push, the response is essentially the free response of an unstable system, which cannot uniquely identify the full input-output dynamics (especially zeros and relative degree). A single impulse in discrete-time ARX is not persistently exciting of order greater than $1$, leading to rank-deficient regression and non-unique models.\n- D is incorrect: transfer functions are well-defined for unstable LTI systems; instability does not invalidate the concept of a transfer function.\n\nTherefore, the fundamental reason the experiment is ill-posed for identifying a useful and generalizable transfer function is the lack of a persistently exciting input; the output is dominated by the unstable free response and does not contain sufficient frequency content to uniquely identify the system’s full dynamics.", "answer": "$$\\boxed{C}$$", "id": "1585908"}, {"introduction": "Many real-world systems, like switched-mode power supplies, operate by switching between different dynamic configurations. This exercise guides you through modeling a non-ideal DC-DC buck converter, a fundamental component in modern electronics [@problem_id:1591392]. You will apply physical principles (Kirchhoff's laws) and the powerful technique of state-space averaging to derive a single linear time-invariant model that captures the essential dynamics of this complex hybrid system.", "problem": "Consider a non-ideal synchronous Direct Current to Direct Current (DC-DC) buck converter designed to step down a constant input voltage $V_{in}$. The converter circuit includes an inductor of inductance $L$ with a Direct Current Resistance (DCR) of $R_L$, and a capacitor of capacitance $C$ with an Equivalent Series Resistance (ESR) of $R_C$. The converter drives a purely resistive load $R$.\n\nThe switching elements are two MOSFETs arranged in a synchronous configuration. The high-side MOSFET, which connects the inductor to $V_{in}$, has an on-state resistance of $R_{ds1}$. The low-side MOSFET, which connects the inductor to ground during the freewheeling phase, has an on-state resistance of $R_{ds2}$. Both MOSFETs are treated as ideal switches otherwise.\n\nThe converter operates at a constant switching frequency high enough that the dynamics can be analyzed using averaging techniques. The control input is the duty cycle $D$, which represents the fraction of the switching period during which the high-side MOSFET is ON. The two MOSFETs operate in a complementary fashion, meaning when one is ON, the other is OFF.\n\nThe dynamic behavior of this converter can be approximated by a linear time-invariant system using the state-space averaging technique over one switching period. The resulting model takes the form $\\frac{d\\bar{x}(t)}{dt} = A\\bar{x}(t) + B\\bar{u}(t)$, where the state vector is defined as $\\bar{x}(t) = [\\bar{i}_L(t), \\bar{v}_C(t)]^T$, representing the averaged inductor current $\\bar{i}_L(t)$ and averaged voltage across the capacitor's capacitance $\\bar{v}_C(t)$, respectively. The input vector is defined as $\\bar{u}(t) = [V_{in}]^T$.\n\nDetermine the analytical expression for the element in the first row and first column, $A_{11}$, of the averaged state matrix $A$.", "solution": "Define the state variables as $\\bar{x}(t) = [\\bar{i}_{L}(t), \\bar{v}_{C}(t)]^{T}$, where $\\bar{i}_{L}$ is the averaged inductor current and $\\bar{v}_{C}$ is the averaged voltage across the ideal capacitor. Let $v_{o}$ denote the output node voltage across the load.\n\nInductor voltage-current relation with inductor DCR $R_{L}$ gives\n$$\nL\\frac{d\\bar{i}_{L}}{dt} = v_{x} - v_{o} - \\bar{i}_{L} R_{L},\n$$\nwhere $v_{x}$ is the switch-node voltage. In the ON interval (high-side MOSFET on), $v_{x} = V_{in} - \\bar{i}_{L} R_{ds1}$. In the OFF interval (low-side MOSFET on, current flowing from ground to the switch node through $R_{ds2}$), $v_{x} = - \\bar{i}_{L} R_{ds2}$. Using state-space averaging over one period with duty ratio $D$ yields\n$$\nL\\frac{d\\bar{i}_{L}}{dt}\n= D\\left(V_{in} - \\bar{i}_{L} R_{ds1} - v_{o} - \\bar{i}_{L} R_{L}\\right)\n+ (1-D)\\left(- \\bar{i}_{L} R_{ds2} - v_{o} - \\bar{i}_{L} R_{L}\\right).\n$$\nSimplifying,\n$$\n\\frac{d\\bar{i}_{L}}{dt}\n= \\frac{D}{L}V_{in} - \\frac{1}{L}v_{o}\n- \\frac{1}{L}\\bar{i}_{L}\\left(R_{L} + D R_{ds1} + (1-D)R_{ds2}\\right).\n$$\n\nNext, relate $v_{o}$ to the states. The capacitor ESR $R_{C}$ is in series with $C$, so\n$$\nv_{o} = \\bar{v}_{C} + R_{C} \\bar{i}_{C}, \\quad \\bar{i}_{C} = C \\frac{d\\bar{v}_{C}}{dt}.\n$$\nKCL at the output node gives\n$$\n\\bar{i}_{L} = \\bar{i}_{C} + \\bar{i}_{R} = C \\frac{d\\bar{v}_{C}}{dt} + \\frac{v_{o}}{R}.\n$$\nEliminate $v_{o}$ via the two relations. First write\n$$\n\\bar{i}_{L} = C \\frac{d\\bar{v}_{C}}{dt} + \\frac{1}{R}\\left(\\bar{v}_{C} + R_{C} C \\frac{d\\bar{v}_{C}}{dt}\\right)\n= C \\frac{d\\bar{v}_{C}}{dt}\\left(1 + \\frac{R_{C}}{R}\\right) + \\frac{\\bar{v}_{C}}{R}.\n$$\nHence\n$$\n\\frac{d\\bar{v}_{C}}{dt}\n= \\frac{R}{C(R+R_{C})}\\bar{i}_{L} - \\frac{1}{C(R+R_{C})}\\bar{v}_{C}.\n$$\nThen\n$$\nv_{o} = \\bar{v}_{C} + R_{C} C \\frac{d\\bar{v}_{C}}{dt}\n= \\bar{v}_{C} + R_{C}\\left(\\frac{R}{R+R_{C}}\\bar{i}_{L} - \\frac{1}{R+R_{C}}\\bar{v}_{C}\\right)\n= \\frac{R}{R+R_{C}}\\bar{v}_{C} + \\frac{R R_{C}}{R+R_{C}}\\bar{i}_{L}.\n$$\n\nSubstitute this $v_{o}$ into the averaged inductor equation:\n$$\n\\frac{d\\bar{i}_{L}}{dt}\n= \\frac{D}{L}V_{in} - \\frac{1}{L}\\left(\\frac{R}{R+R_{C}}\\bar{v}_{C} + \\frac{R R_{C}}{R+R_{C}}\\bar{i}_{L}\\right)\n- \\frac{1}{L}\\bar{i}_{L}\\left(R_{L} + D R_{ds1} + (1-D)R_{ds2}\\right).\n$$\nCollecting the $\\bar{i}_{L}$ terms reveals the $A_{11}$ entry as the coefficient multiplying $\\bar{i}_{L}$:\n$$\nA_{11} = -\\frac{1}{L}\\left(R_{L} + D R_{ds1} + (1-D) R_{ds2} + \\frac{R R_{C}}{R + R_{C}}\\right).\n$$\nThis expression reflects the inductor current damping due to its DCR, the duty-cycle-weighted MOSFET on-resistances, and the effective resistive loading seen through the load and capacitor ESR combination.", "answer": "$$\\boxed{-\\frac{1}{L}\\left(R_{L}+D R_{ds1}+(1-D) R_{ds2}+\\frac{R R_{C}}{R+R_{C}}\\right)}$$", "id": "1591392"}, {"introduction": "Dynamic systems can be represented in various mathematical forms, each with unique advantages for analysis and design. This practice focuses on the critical link between the frequency-domain transfer function, $G(s)$, and the time-domain state-space model [@problem_id:2723736]. You will learn to construct a 'controllable canonical form' realization, a standard and systematic procedure that is foundational to modern control theory and synthesis.", "problem": "Consider a single-input single-output, linear time-invariant system with strictly proper transfer function $G(s)=\\dfrac{s+2}{s^{2}+3s+2}$. Assume zero initial conditions. Starting only from fundamental definitions of transfer functions and state-space realizations, do the following:\n\n1) Construct a controllable canonical state-space realization $(A,B,C,D)$ of $G(s)$ with $D=0$ by selecting a companion-form matrix $A$ consistent with the monic denominator polynomial of $G(s)$ and a column vector $B$ that ensures controllability. Determine the row vector $C$ by matching the input-output map $G(s)=C\\,(sI-A)^{-1}B+D$.\n\n2) Using the state-space representation and the definition of the bilateral Laplace transform for linear time-invariant systems, compute the zero-state response $y_{\\mathrm{zs}}(t)$ to a unit step input $u(t)$ for $t\\ge 0$. Express the final answer as a single closed-form function of $t$.\n\nReport as your final answer the expression for $y_{\\mathrm{zs}}(t)$. No numerical rounding is required, and no physical units are needed.", "solution": "The solution proceeds in two parts as requested.\n\n**Part 1: Construction of the State-Space Realization**\n\nThe given transfer function is $G(s) = \\dfrac{s+2}{s^2+3s+2}$. This is a second-order system, $n=2$. The general form for a strictly proper transfer function of order $n=2$ is:\n$$ G(s) = \\frac{b_1 s + b_0}{s^2 + a_1 s + a_0} $$\nBy comparing this with the given $G(s)$, we identify the coefficients:\n- Denominator coefficients: $a_1=3$, $a_0=2$.\n- Numerator coefficients: $b_1=1$, $b_0=2$.\n\nWe are instructed to construct the controllable canonical realization. For a general $n^{th}$-order system, this form is given by:\n$$ A = \\begin{pmatrix} 0 & 1 & 0 & \\dots & 0 \\\\ 0 & 0 & 1 & \\dots & 0 \\\\ \\vdots & \\vdots & \\vdots & \\ddots & \\vdots \\\\ 0 & 0 & 0 & \\dots & 1 \\\\ -a_0 & -a_1 & -a_2 & \\dots & -a_{n-1} \\end{pmatrix}, \\quad B = \\begin{pmatrix} 0 \\\\ 0 \\\\ \\vdots \\\\ 0 \\\\ 1 \\end{pmatrix} $$\n$$ C = \\begin{pmatrix} b_0 & b_1 & \\dots & b_{n-1} \\end{pmatrix}, \\quad D = 0 $$\nFor our second-order system ($n=2$), we substitute the identified coefficients:\nThe companion matrix $A$ is:\n$$ A = \\begin{pmatrix} 0 & 1 \\\\ -a_0 & -a_1 \\end{pmatrix} = \\begin{pmatrix} 0 & 1 \\\\ -2 & -3 \\end{pmatrix} $$\nThe input vector $B$ is:\n$$ B = \\begin{pmatrix} 0 \\\\ 1 \\end{pmatrix} $$\nThe output vector $C$ is:\n$$ C = \\begin{pmatrix} b_0 & b_1 \\end{pmatrix} = \\begin{pmatrix} 2 & 1 \\end{pmatrix} $$\nThe direct feedthrough term $D$ is given as $0$:\n$$ D = 0 $$\nThus, the controllable canonical state-space realization is $(A, B, C, D)$ with the matrices defined above. We can verify that this realization corresponds to the given transfer function:\n$G(s) = C(sI-A)^{-1}B+D$.\n$$ sI-A = s\\begin{pmatrix} 1 & 0 \\\\ 0 & 1 \\end{pmatrix} - \\begin{pmatrix} 0 & 1 \\\\ -2 & -3 \\end{pmatrix} = \\begin{pmatrix} s & -1 \\\\ 2 & s+3 \\end{pmatrix} $$\nThe inverse is:\n$$ (sI-A)^{-1} = \\frac{1}{\\det(sI-A)} \\begin{pmatrix} s+3 & 1 \\\\ -2 & s \\end{pmatrix} = \\frac{1}{s(s+3) - (-1)(2)} \\begin{pmatrix} s+3 & 1 \\\\ -2 & s \\end{pmatrix} = \\frac{1}{s^2+3s+2} \\begin{pmatrix} s+3 & 1 \\\\ -2 & s \\end{pmatrix} $$\nNow, we compute the product $C(sI-A)^{-1}B$:\n$$ C(sI-A)^{-1}B = \\frac{1}{s^2+3s+2} \\begin{pmatrix} 2 & 1 \\end{pmatrix} \\begin{pmatrix} s+3 & 1 \\\\ -2 & s \\end{pmatrix} \\begin{pmatrix} 0 \\\\ 1 \\end{pmatrix} $$\n$$ = \\frac{1}{s^2+3s+2} \\begin{pmatrix} 2(s+3)-2 & 2(1)+1(s) \\end{pmatrix} \\begin{pmatrix} 0 \\\\ 1 \\end{pmatrix} $$\n$$ = \\frac{1}{s^2+3s+2} \\begin{pmatrix} 2s+4 & s+2 \\end{pmatrix} \\begin{pmatrix} 0 \\\\ 1 \\end{pmatrix} $$\n$$ = \\frac{(2s+4)(0) + (s+2)(1)}{s^2+3s+2} = \\frac{s+2}{s^2+3s+2} $$\nThis matches the original transfer function $G(s)$, confirming the correctness of the realization.\n\n**Part 2: Computation of the Zero-State Response**\n\nThe state-space representation of the LTI system is given by:\n$$ \\dot{x}(t) = Ax(t) + Bu(t) $$\n$$ y(t) = Cx(t) + Du(t) $$\nWe are asked to find the zero-state response, which means the initial state is zero: $x(0) = \\mathbf{0}$. The input is a unit step function, $u(t) = 1$ for $t \\ge 0$.\n\nWe apply the Laplace transform to the state equation, using the property $\\mathcal{L}\\{\\dot{x}(t)\\} = sX(s) - x(0)$:\n$$ sX(s) - x(0) = AX(s) + BU(s) $$\nWith $x(0)=\\mathbf{0}$, this simplifies to:\n$$ sX(s) = AX(s) + BU(s) \\implies (sI-A)X(s) = BU(s) $$\nSolving for the state vector in the frequency domain, $X(s)$:\n$$ X(s) = (sI-A)^{-1}BU(s) $$\nNow, we apply the Laplace transform to the output equation, with $D=0$:\n$$ Y(s) = CX(s) $$\nSubstituting the expression for $X(s)$:\n$$ Y(s) = C(sI-A)^{-1}BU(s) $$\nThe term $C(sI-A)^{-1}B$ is precisely the transfer function $G(s)$. The Laplace transform of the unit step input $u(t)=1$ is $U(s) = \\frac{1}{s}$.\nSo, the output $Y(s)$ is:\n$$ Y(s) = G(s)U(s) = \\left(\\frac{s+2}{s^2+3s+2}\\right) \\left(\\frac{1}{s}\\right) $$\nThe denominator can be factored: $s^2+3s+2 = (s+1)(s+2)$.\n$$ Y(s) = \\frac{s+2}{(s+1)(s+2)s} $$\nA pole at $s=-2$ is cancelled by a zero at $s=-2$. This simplification is valid for the input-output response.\n$$ Y(s) = \\frac{1}{s(s+1)} $$\nTo find the time-domain response $y_{\\mathrm{zs}}(t)$, we must compute the inverse Laplace transform of $Y(s)$. We use partial fraction expansion:\n$$ Y(s) = \\frac{1}{s(s+1)} = \\frac{K_1}{s} + \\frac{K_2}{s+1} $$\nThe coefficients $K_1$ and $K_2$ are found using the residue method:\n$$ K_1 = \\lim_{s \\to 0} s Y(s) = \\lim_{s \\to 0} \\frac{1}{s+1} = 1 $$\n$$ K_2 = \\lim_{s \\to -1} (s+1) Y(s) = \\lim_{s \\to -1} \\frac{1}{s} = -1 $$\nSo the expansion is:\n$$ Y(s) = \\frac{1}{s} - \\frac{1}{s+1} $$\nTaking the inverse Laplace transform term by term for $t \\ge 0$:\n$$ y_{\\mathrm{zs}}(t) = \\mathcal{L}^{-1}\\left\\{\\frac{1}{s}\\right\\} - \\mathcal{L}^{-1}\\left\\{\\frac{1}{s+1}\\right\\} $$\nUsing the standard transform pairs $\\mathcal{L}^{-1}\\{1/s\\} = 1$ and $\\mathcal{L}^{-1}\\{1/(s+a)\\} = \\exp(-at)$, we obtain:\n$$ y_{\\mathrm{zs}}(t) = 1 - \\exp(-t) $$\nThis is the closed-form expression for the zero-state response for $t \\ge 0$.", "answer": "$$\\boxed{1 - \\exp(-t)}$$", "id": "2723736"}]}