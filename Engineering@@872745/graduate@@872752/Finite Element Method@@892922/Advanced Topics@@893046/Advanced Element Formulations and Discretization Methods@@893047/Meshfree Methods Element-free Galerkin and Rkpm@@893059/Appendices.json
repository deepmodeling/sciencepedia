{"hands_on_practices": [{"introduction": "Understanding meshfree methods begins with mastering the construction of their shape functions. This first practice problem takes you through the fundamental steps of a Moving Least Squares (MLS) approximation from the ground up [@problem_id:2576499]. By manually calculating the shape function values for a simple one-dimensional node distribution and verifying the method's quadratic reproduction property, you will gain a concrete understanding of the core mechanics that underpin both the Element-Free Galerkin and Reproducing Kernel Particle methods.", "problem": "Consider the one-dimensional moving least squares (MLS) approximation that underlies both the Element-Free Galerkin (EFG) method and the Reproducing Kernel Particle Method (RKPM). Let the nodes be uniformly distributed on the real line at positions $x_I = I h_n$ with spacing $h_n = 0.1$, where $I \\in \\mathbb{Z}$. Use the quadratic polynomial basis $\\mathbf{p}(x) = [1\\ \\ x\\ \\ x^2]^{T}$ and the standard cubic spline weight function with compact support of radius $2 h_n$, defined by\n$$\nW(q) = \n\\begin{cases}\n\\frac{2}{3} - q^2 + \\frac{1}{2} q^3, & 0 \\le q < 1 \\\\[4pt]\n\\frac{1}{6} (2 - q)^3, & 1 \\le q < 2 \\\\[4pt]\n0, & q \\ge 2\n\\end{cases}\n$$\nwhere $q = \\dfrac{|x - x_I|}{h_n}$. For a given evaluation point $x_0 = 0.3$, denote by $\\phi_I(x)$ the MLS shape functions associated with the nodes $\\{x_I\\}$.\n\nStarting from the MLS normal equations and their induced consistency conditions, and without assuming any interpolation property a priori, do the following:\n\n1) Determine the subset of nodes with nonzero weight at $x_0 = 0.3$.\n\n2) Using the MLS construction with the given basis and weight, compute explicitly the values $\\phi_I(x_0)$ for the nodes found in part 1).\n\n3) For the function $u(x) = x^2$, construct the MLS approximation $u_h(x_0) = \\sum_I \\phi_I(x_0) u(x_I)$ and verify quadratic reproduction at $x_0 = 0.3$.\n\nExpress your final answer as a single exact number for $u_h(0.3)$ (no units, no rounding required).", "solution": "The problem statement poses a standard, well-defined exercise in the theory of meshfree methods, specifically the Moving Least Squares (MLS) approximation. All necessary components are provided: node distribution, basis functions, weight function, and the point of evaluation. The problem is scientifically grounded in computational mechanics, internally consistent, and free of ambiguity. Therefore, the problem is deemed valid and a full solution will be provided.\n\nThe MLS approximation $u_h(x)$ of a function $u(x)$ is constructed locally at an evaluation point $x$ as $u_h(x) = \\mathbf{p}^T(x)\\mathbf{a}(x)$, where $\\mathbf{p}(x)$ is a basis of polynomials and $\\mathbf{a}(x)$ is a vector of coefficients determined by minimizing a weighted, discrete $L_2$ norm. This leads to the MLS shape functions $\\phi_I(x)$ such that $u_h(x) = \\sum_I \\phi_I(x) u_I$, where $u_I = u(x_I)$ are the nodal values of the function.\n\n1) Determine the subset of nodes with nonzero weight at $x_0 = 0.3$.\n\nThe weight function $W(q)$ has compact support, being non-zero only for $0 \\le q < 2$. The argument $q$ is defined as $q = \\frac{|x - x_I|}{h_n}$. For a given evaluation point $x = x_0 = 0.3$ and node spacing $h_n = 0.1$, the condition for a node $x_I = I h_n = 0.1 I$ to have a non-zero weight is:\n$$\n\\frac{|x_0 - x_I|}{h_n} < 2\n$$\n$$\n\\frac{|0.3 - 0.1 I|}{0.1} < 2\n$$\n$$\n|3 - I| < 2\n$$\nThis inequality is equivalent to $-2 < 3 - I < 2$.\nFrom $3 - I < 2$, we obtain $I > 1$.\nFrom $-2 < 3 - I$, we obtain $I < 5$.\nThus, the integer indices $I$ must satisfy $1 < I < 5$. The set of qualifying indices is $\\{2, 3, 4\\}$. The corresponding nodes, which constitute the support domain for the evaluation point $x_0 = 0.3$, are:\n$$\nx_2 = 2 \\times 0.1 = 0.2\n$$\n$$\nx_3 = 3 \\times 0.1 = 0.3\n$$\n$$\nx_4 = 4 \\times 0.1 = 0.4\n$$\n\n2) Compute the values $\\phi_I(x_0)$ for the nodes found in part 1).\n\nThe MLS shape function for node $I$ is given by the expression:\n$$\n\\phi_I(x) = \\mathbf{p}^T(x) \\mathbf{M}^{-1}(x) \\mathbf{p}(x_I) W_I(x)\n$$\nwhere $W_I(x) = W(\\frac{|x-x_I|}{h_n})$ and the moment matrix $\\mathbf{M}(x)$ is defined as:\n$$\n\\mathbf{M}(x) = \\sum_J W_J(x) \\mathbf{p}(x_J) \\mathbf{p}^T(x_J)\n$$\nThe sum is over all nodes $J$ in the support domain. The given basis is $\\mathbf{p}(x) = [1, x, x^2]^T$. To simplify the inversion of the moment matrix, we introduce a shifted basis centered at the evaluation point $x_0 = 0.3$:\n$$\n\\mathbf{q}(x) = \\begin{pmatrix} 1 \\\\ x - x_0 \\\\ (x - x_0)^2 \\end{pmatrix}\n$$\nThe shape functions are invariant under this change of basis. In the new basis, the shape function is $\\phi_I(x) = \\mathbf{q}^T(x) \\mathbf{A}^{-1}(x) \\mathbf{q}(x_I) W_I(x)$, with the moment matrix $\\mathbf{A}(x) = \\sum_J W_J(x) \\mathbf{q}(x_J) \\mathbf{q}^T(x_J)$.\n\nWe evaluate at $x = x_0 = 0.3$.\nFirst, calculate the weights $W_I(x_0)$ for the active nodes $I \\in \\{2, 3, 4\\}$.\nFor $I=2$: $q_2 = \\frac{|0.3 - 0.2|}{0.1} = 1$. $W_2(x_0) = \\frac{1}{6}(2 - 1)^3 = \\frac{1}{6}$.\nFor $I=3$: $q_3 = \\frac{|0.3 - 0.3|}{0.1} = 0$. $W_3(x_0) = \\frac{2}{3} - 0^2 + \\frac{1}{2}0^3 = \\frac{2}{3}$.\nFor $I=4$: $q_4 = \\frac{|0.3 - 0.4|}{0.1} = 1$. $W_4(x_0) = \\frac{1}{6}(2 - 1)^3 = \\frac{1}{6}$.\n\nNext, we construct the moment matrix $\\mathbf{A}(x_0)$. Let $y_I = x_I - x_0$.\n$y_2 = 0.2 - 0.3 = -0.1$.\n$y_3 = 0.3 - 0.3 = 0$.\n$y_4 = 0.4 - 0.3 = 0.1$.\nThe entries of $\\mathbf{A}(x_0)$ are $A_{ij} = \\sum_{I=2,3,4} W_I(x_0) y_I^{i-1} y_I^{j-1}$. Due to the symmetry of the node distribution and weights around $x_0$, the off-diagonal terms involving odd powers of $y_I$ will be zero.\n$A_{11} = \\sum W_I = \\frac{1}{6} + \\frac{2}{3} + \\frac{1}{6} = 1$.\n$A_{12} = A_{21} = \\sum W_I y_I = \\frac{1}{6}(-0.1) + \\frac{2}{3}(0) + \\frac{1}{6}(0.1) = 0$.\n$A_{13} = A_{31} = A_{22} = \\sum W_I y_I^2 = \\frac{1}{6}(-0.1)^2 + \\frac{2}{3}(0)^2 + \\frac{1}{6}(0.1)^2 = 2 \\times \\frac{1}{6}(0.01) = \\frac{0.01}{3} = \\frac{1}{300}$.\n$A_{23} = A_{32} = \\sum W_I y_I^3 = \\frac{1}{6}(-0.1)^3 + \\frac{2}{3}(0)^3 + \\frac{1}{6}(0.1)^3 = 0$.\n$A_{33} = \\sum W_I y_I^4 = \\frac{1}{6}(-0.1)^4 + \\frac{2}{3}(0)^4 + \\frac{1}{6}(0.1)^4 = 2 \\times \\frac{1}{6}(0.0001) = \\frac{1}{30000}$.\n\nSo, the moment matrix is:\n$$\n\\mathbf{A}(x_0) = \\begin{pmatrix} 1 & 0 & \\frac{1}{300} \\\\ 0 & \\frac{1}{300} & 0 \\\\ \\frac{1}{300} & 0 & \\frac{1}{30000} \\end{pmatrix}\n$$\nThis matrix is block-diagonal and its inverse $\\mathbf{A}^{-1}(x_0)$ is readily computed. The inverse of the $2 \\times 2$ block $\\begin{pmatrix} 1 & 1/300 \\\\ 1/300 & 1/30000 \\end{pmatrix}$ is $\\begin{pmatrix} 3/2 & -150 \\\\ -150 & 45000 \\end{pmatrix}$. The inverse of the central element is $(1/300)^{-1}=300$.\n$$\n\\mathbf{A}^{-1}(x_0) = \\begin{pmatrix} \\frac{3}{2} & 0 & -150 \\\\ 0 & 300 & 0 \\\\ -150 & 0 & 45000 \\end{pmatrix}\n$$\nThe basis vector evaluated at $x_0$ is $\\mathbf{q}(x_0) = [1, 0, 0]^T$. The shape function values are:\n$$\n\\phi_I(x_0) = \\mathbf{q}^T(x_0) \\mathbf{A}^{-1}(x_0) \\mathbf{q}(x_I) W_I(x_0) = \\begin{pmatrix} 1 & 0 & 0 \\end{pmatrix} \\mathbf{A}^{-1}(x_0) \\begin{pmatrix} 1 \\\\ y_I \\\\ y_I^2 \\end{pmatrix} W_I(x_0)\n$$\n$$\n\\phi_I(x_0) = \\begin{pmatrix} \\frac{3}{2} & 0 & -150 \\end{pmatrix} \\begin{pmatrix} 1 \\\\ y_I \\\\ y_I^2 \\end{pmatrix} W_I(x_0) = \\left(\\frac{3}{2} - 150 y_I^2\\right) W_I(x_0)\n$$\nNow we compute the values for $I \\in \\{2, 3, 4\\}$.\nFor $I=2$: $y_2 = -0.1$. $\\phi_2(0.3) = \\left(\\frac{3}{2} - 150(-0.1)^2\\right) \\frac{1}{6} = (1.5 - 1.5) \\frac{1}{6} = 0$.\nFor $I=3$: $y_3 = 0$. $\\phi_3(0.3) = \\left(\\frac{3}{2} - 150(0)^2\\right) \\frac{2}{3} = \\frac{3}{2} \\times \\frac{2}{3} = 1$.\nFor $I=4$: $y_4 = 0.1$. $\\phi_4(0.3) = \\left(\\frac{3}{2} - 150(0.1)^2\\right) \\frac{1}{6} = (1.5 - 1.5) \\frac{1}{6} = 0$.\nThe shape function values are $\\phi_2(0.3) = 0$, $\\phi_3(0.3) = 1$, and $\\phi_4(0.3) = 0$. This indicates that the MLS approximation possesses the Kronecker delta property at this specific nodal location, $\\phi_I(x_J) = \\delta_{IJ}$.\n\n3) Construct the MLS approximation for $u(x) = x^2$ and verify quadratic reproduction.\n\nThe MLS approximation of $u(x) = x^2$ at $x_0 = 0.3$ is given by:\n$$\nu_h(x_0) = \\sum_{I=2,3,4} \\phi_I(x_0) u(x_I)\n$$\nThe nodal values of the function $u(x) = x^2$ are:\n$u(x_2) = (0.2)^2 = 0.04$.\n$u(x_3) = (0.3)^2 = 0.09$.\n$u(x_4) = (0.4)^2 = 0.16$.\n\nSubstituting the shape function values and nodal values:\n$$\nu_h(0.3) = \\phi_2(0.3) u(x_2) + \\phi_3(0.3) u(x_3) + \\phi_4(0.3) u(x_4)\n$$\n$$\nu_h(0.3) = (0)(0.04) + (1)(0.09) + (0)(0.16) = 0.09\n$$\nTo verify quadratic reproduction, we must compare the approximated value $u_h(x_0)$ with the exact value $u(x_0)$.\nThe exact value is $u(0.3) = (0.3)^2 = 0.09$.\nSince $u_h(0.3) = u(0.3) = 0.09$, quadratic reproduction is verified at the point $x_0 = 0.3$. This result is expected, as the MLS method is constructed to reproduce any polynomial that is present in its basis, a property known as consistency. Given that $u(x)=x^2$ is an element of the chosen quadratic basis $\\mathbf{p}(x)$, its exact reproduction is guaranteed by the formulation.\nThe final required value is $u_h(0.3)$.", "answer": "$$\n\\boxed{0.09}\n$$", "id": "2576499"}, {"introduction": "Building on the foundational calculations, the next logical step is to automate the process by writing a program. This exercise guides you through the implementation of a one-dimensional Reproducing Kernel Particle Method (RKPM), a powerful meshfree technique [@problem_id:2576507]. You will translate the theoretical formulas for the moment matrix and corrected kernel weights into code, and then perform numerical tests to verify the crucial properties of consistency and partition of unity, solidifying the link between theory and computational practice.", "problem": "Implement a one-dimensional Reproducing Kernel Particle Method (RKPM) with quadratic polynomial reproduction using a cubic B-spline base kernel on a uniform lattice. Start from the definitions of meshfree approximation with corrected kernels and the discrete moment conditions that enforce polynomial consistency. Use a uniform lattice of nodes on the closed interval $[0,1]$ with spacing $\\Delta x = 0.1$, so that nodes are at positions $x_I = I \\Delta x$ for integers $I$ from $0$ to $10$. Let the smoothing length be $h = \\Delta x$. The cubic B-spline base kernel is defined by\n$$\nW(r,h) = \\frac{\\alpha_1}{h} f\\!\\left(q\\right), \\quad q = \\frac{|r|}{h}, \\quad \\alpha_1 = \\frac{2}{3},\n$$\nwith the piecewise smooth function\n$$\nf(q) = \n\\begin{cases}\n1 - \\frac{3}{2}q^2 + \\frac{3}{4}q^3, & 0 \\le q < 1 \\\\[4pt]\n\\frac{1}{4}(2 - q)^3, & 1 \\le q < 2 \\\\[4pt]\n0, & q \\ge 2\n\\end{cases}\n$$\nAdopt the monomial basis vector $\\mathbf{p}(x) = [1, x, x^2]^T$ to enforce quadratic reproduction. For any evaluation point $x \\in [0,1]$, define the support index set $\\mathcal{S}(x) = \\{ I \\,:\\, |x - x_I| < 2h \\}$ and the discrete moment matrix\n$$\n\\mathbf{M}(x) = \\sum_{I \\in \\mathcal{S}(x)} W(x - x_I,h)\\, \\mathbf{p}(x_I)\\, \\mathbf{p}^T(x_I).\n$$\nDefine the corrected kernel weight associated with node $I$ at the evaluation point $x$ by\n$$\n\\tilde{W}_I(x) = \\mathbf{p}^T(x)\\, \\mathbf{M}^{-1}(x)\\, \\mathbf{p}(x_I)\\, W(x - x_I,h).\n$$\nUse these corrected kernel weights to form the meshfree approximation of a function $u(x)$ as\n$$\nu_h(x) = \\sum_{I \\in \\mathcal{S}(x)} u(x_I)\\, \\tilde{W}_I(x).\n$$\nTasks:\n- Implement the cubic B-spline base kernel $W(r,h)$ as given.\n- Implement the corrected kernel weights $\\tilde{W}_I(x)$ using the discrete moment matrix with the quadratic monomial basis.\n- Verify consistency for the target function $u(x) = x^2$ by computing the absolute error $|u_h(x) - x^2|$ at specified evaluation points.\n- Additionally verify the partition of unity and linear consistency by computing the absolute deviations $\\left| \\sum_{I \\in \\mathcal{S}(x)} \\tilde{W}_I(x) - 1 \\right|$ and $\\left| \\sum_{I \\in \\mathcal{S}(x)} x_I \\tilde{W}_I(x) - x \\right|$ at the same points.\n- Compute the specific corrected kernel value $\\tilde{W}_{I^\\star}(x^\\star)$ at $x^\\star = 0.37$ for the node index $I^\\star$ such that $x_{I^\\star} = 0.4$.\n\nTest suite:\n- Grid parameters: $\\Delta x = 0.1$, $h = \\Delta x$, domain $[0,1]$.\n- Evaluation points: $x^{(1)} = 0.37$ (interior), $x^{(2)} = 0.02$ (near left boundary), $x^{(3)} = 0.98$ (near right boundary).\n- For each $x^{(k)}$, compute\n  1. $e_u^{(k)} = |u_h(x^{(k)}) - (x^{(k)})^2|$,\n  2. $e_0^{(k)} = \\left| \\sum_{I \\in \\mathcal{S}(x^{(k)})} \\tilde{W}_I(x^{(k)}) - 1 \\right|$,\n  3. $e_1^{(k)} = \\left| \\sum_{I \\in \\mathcal{S}(x^{(k)})} x_I \\tilde{W}_I(x^{(k)}) - x^{(k)} \\right|$.\n- Specific corrected kernel value: $\\tilde{W}_{I^\\star}(x^\\star)$ for $x^\\star = 0.37$ and $x_{I^\\star} = 0.4$.\n\nFinal output format:\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, in the following order:\n$$\n\\left[ e_u^{(1)}, e_0^{(1)}, e_1^{(1)}, e_u^{(2)}, e_0^{(2)}, e_1^{(2)}, e_u^{(3)}, e_0^{(3)}, e_1^{(3)}, \\tilde{W}_{I^\\star}(x^\\star) \\right].\n$$\nNo physical units or angles are involved. All outputs must be floating-point numbers.", "solution": "The problem is validated as scientifically sound, well-posed, and objective. It presents a standard implementation exercise in the field of meshfree methods, specifically the Reproducing Kernel Particle Method (RKPM).\n\nThe objective is to implement a one-dimensional RKPM on a uniform grid of nodes. The implementation must ensure quadratic polynomial reproduction. We will then verify the method's consistency properties numerically.\n\nThe foundation of any meshfree approximation for a function $u(x)$ is the representation:\n$$u_h(x) = \\sum_{I \\in \\mathcal{S}(x)} u(x_I) \\tilde{W}_I(x)$$\nHere, $u_h(x)$ is the approximation of $u(x)$ at an evaluation point $x$. The summation is over a set of influencing nodes, $\\mathcal{S}(x)$, within the \"support\" of the point $x$. The functions $\\tilde{W}_I(x)$ are the shape functions, or corrected kernel weights, associated with each node $I$ with position $x_I$. The values $u(x_I)$ are the known function values at the nodes.\n\nThe central principle of RKPM is polynomial reproduction. This condition dictates that if the function $u(x)$ is a polynomial of a certain degree, the approximation $u_h(x)$ must be exactly equal to $u(x)$. For quadratic reproduction, we choose a monomial basis vector $\\mathbf{p}(x) = [1, x, x^2]^T$. The reproduction condition requires that for each basis function $p_j(x)$ in this vector, the following must hold:\n$$\\sum_{I \\in \\mathcal{S}(x)} p_j(x_I) \\tilde{W}_I(x) = p_j(x)$$\nThis must be true for $j \\in \\{1, 2, 3\\}$, corresponding to $p_1(x)=1$, $p_2(x)=x$, and $p_3(x)=x^2$. In vector form, this is:\n$$\\sum_{I \\in \\mathcal{S}(x)} \\mathbf{p}(x_I) \\tilde{W}_I(x) = \\mathbf{p}(x)$$\nTo satisfy this condition, the RKPM shape function $\\tilde{W}_I(x)$ is constructed by correcting a base kernel $W(r,h)$. The problem provides the specific form for this corrected kernel:\n$$\\tilde{W}_I(x) = \\mathbf{p}^T(x)\\, \\mathbf{M}^{-1}(x)\\, \\mathbf{p}(x_I)\\, W(x - x_I,h)$$\nwhere $\\mathbf{M}(x)$ is the moment matrix, defined as:\n$$\\mathbf{M}(x) = \\sum_{I \\in \\mathcal{S}(x)} W(x - x_I,h)\\, \\mathbf{p}(x_I)\\, \\mathbf{p}^T(x_I)$$\nThe moment matrix $\\mathbf{M}(x)$ is symmetric by construction, as it is a sum of symmetric matrices $\\mathbf{p}(x_I)\\mathbf{p}^T(x_I)$. Its invertibility is essential and depends on having a sufficient number of nodes in the support domain $\\mathcal{S}(x)$. The demonstration that this form of $\\tilde{W}_I(x)$ satisfies the reproduction condition is as follows:\n$$ \\sum_{I \\in \\mathcal{S}(x)} \\mathbf{p}(x_I) \\tilde{W}_I(x) = \\sum_{I \\in \\mathcal{S}(x)} \\mathbf{p}(x_I) \\left[\\mathbf{p}^T(x) \\mathbf{M}^{-1}(x) \\mathbf{p}(x_I) W(x - x_I,h) \\right] $$\nSince the term $\\mathbf{p}^T(x) \\mathbf{M}^{-1}(x) \\mathbf{p}(x_I)$ is a scalar, we can reorder the products:\n$$ = \\sum_{I \\in \\mathcal{S}(x)} \\left[ W(x - x_I,h) \\mathbf{p}(x_I) \\mathbf{p}^T(x_I) \\right] \\left( \\mathbf{M}^{-1}(x) \\mathbf{p}(x) \\right)$$\nRecognizing that $\\mathbf{M}^{-1}(x) \\mathbf{p}(x)$ does not depend on the summation index $I$, we can factor it out of the summation:\n$$ = \\left[ \\sum_{I \\in \\mathcal{S}(x)} W(x - x_I,h) \\mathbf{p}(x_I) \\mathbf{p}^T(x_I) \\right] \\left( \\mathbf{M}^{-1}(x) \\mathbf{p}(x) \\right) $$\nThe term in the square brackets is precisely the definition of the moment matrix $\\mathbf{M}(x)$. Therefore:\n$$ = \\mathbf{M}(x) \\mathbf{M}^{-1}(x) \\mathbf{p}(x) = \\mathbf{I} \\mathbf{p}(x) = \\mathbf{p}(x) $$\nThis confirms theoretically that the chosen shape function guarantees quadratic reproduction. The numerical task is to implement this framework and verify that the errors associated with this property are near machine precision.\n\nThe implementation follows these steps:\n$1$. The domain $[0,1]$ is discretized with nodes $x_I = I \\Delta x$ for $I \\in \\{0, 1, \\dots, 10\\}$, where $\\Delta x = 0.1$. The smoothing length is $h = \\Delta x = 0.1$.\n$2$. For each given evaluation point $x$, the support set $\\mathcal{S}(x)$ is identified as all node indices $I$ for which the condition $|x - x_I| < 2h$ holds. This support radius of $2h$ is dictated by the compact support of the provided cubic B-spline kernel $W(r,h)$.\n$3$. The $3 \\times 3$ moment matrix $\\mathbf{M}(x)$ is assembled by summing the contributions from all nodes $I \\in \\mathcal{S}(x)$.\n$4$. The moment matrix is inverted to obtain $\\mathbf{M}^{-1}(x)$.\n$5$. The corrected kernel weights $\\tilde{W}_I(x)$ for all $I \\in \\mathcal{S}(x)$ are computed using the formula provided.\n$6$. These weights are then used to perform the required verifications:\n- Zeroth-order consistency (partition of unity): $e_0^{(k)} = |\\sum_{I \\in \\mathcal{S}(x^{(k)})} \\tilde{W}_I(x^{(k)}) - 1|$.\n- Linear consistency: $e_1^{(k)} = |\\sum_{I \\in \\mathcal{S}(x^{(k)})} x_I \\tilde{W}_I(x^{(k)}) - x^{(k)}|$.\n- Quadratic consistency error for $u(x)=x^2$: $e_u^{(k)} = |u_h(x^{(k)}) - (x^{(k)})^2| = |\\sum_{I \\in \\mathcal{S}(x^{(k)})} x_I^2 \\tilde{W}_I(x^{(k)}) - (x^{(k)})^2|$.\nDue to the proven reproduction property, these errors are expected to be on the order of floating-point numerical precision, i.e., approximately $10^{-15}$.\n$7$. Finally, the specific kernel value $\\tilde{W}_{I^\\star}(x^\\star)$ for $x^\\star=0.37$ and node $x_{I^\\star}=0.4$ is extracted from the intermediate calculations.\n\nThe provided code implements this procedure for the specified evaluation points $x^{(1)}=0.37$ (interior point), $x^{(2)}=0.02$ (near-boundary point), and $x^{(3)}=0.98$ (near-boundary point), and formats the results as requested. The near-boundary cases are important as the support sets are asymmetric and contain fewer nodes ($3$ nodes instead of $4$), providing a stringent test of the method's robustness.", "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Implements and verifies the 1D Reproducing Kernel Particle Method (RKPM)\n    with quadratic reproduction.\n    \"\"\"\n\n    # Define parameters and the node lattice from the problem statement.\n    DELTA_X = 0.1\n    H = DELTA_X\n    ALPHA_1 = 2.0 / 3.0\n    X_NODES = np.linspace(0, 1, 11)\n\n    def cubic_b_spline_kernel(r, h):\n        \"\"\"Implements the cubic B-spline base kernel W(r, h).\"\"\"\n        q = np.abs(r) / h\n        val = 0.0\n        if 0 <= q < 1:\n            val = 1.0 - 1.5 * q**2 + 0.75 * q**3\n        elif 1 <= q < 2:\n            val = 0.25 * (2.0 - q)**3\n        \n        return (ALPHA_1 / h) * val\n\n    def monomial_basis(x):\n        \"\"\"Returns the quadratic monomial basis vector p(x) = [1, x, x^2]^T.\"\"\"\n        return np.array([1.0, x, x**2])\n\n    def perform_rkpm_calculation(x_eval):\n        \"\"\"\n        Performs the full RKPM calculation for a single evaluation point x_eval.\n        Returns a dictionary containing the calculated errors and specific kernel value.\n        \"\"\"\n        # 1. Determine the support set S(x_eval)\n        support_indices = []\n        support_nodes = []\n        for i, x_i in enumerate(X_NODES):\n            if np.abs(x_eval - x_i) < 2 * H:\n                support_indices.append(i)\n                support_nodes.append(x_i)\n\n        # 2. Calculate the moment matrix M(x_eval)\n        moment_matrix = np.zeros((3, 3))\n        base_kernel_vals = []  # To store W(x-x_I, h) for reuse\n        basis_at_nodes = []    # To store p(x_I) for reuse\n\n        for x_i in support_nodes:\n            r = x_eval - x_i\n            w_i = cubic_b_spline_kernel(r, H)\n            p_i = monomial_basis(x_i)\n            \n            base_kernel_vals.append(w_i)\n            basis_at_nodes.append(p_i)\n            \n            moment_matrix += w_i * np.outer(p_i, p_i)\n\n        # 3. Invert the moment matrix to get M_inv\n        m_inv = np.linalg.inv(moment_matrix)\n\n        # 4. Calculate corrected kernel weights W_tilde_I(x_eval)\n        p_eval = monomial_basis(x_eval)\n        # This is the row vector p^T(x) * M^-1(x)\n        b_T_vec = p_eval @ m_inv\n\n        w_tilde_vals = []\n        for i in range(len(support_nodes)):\n            p_i = basis_at_nodes[i]\n            w_i = base_kernel_vals[i]\n            # w_tilde = (b^T * p_i) * w_i\n            w_tilde = (b_T_vec @ p_i) * w_i\n            w_tilde_vals.append(w_tilde)\n\n        # 5. Perform verifications\n        # Target function u(x) = x^2, so u(x_I) = x_I^2\n        u_at_nodes = [x_i**2 for x_i in support_nodes]\n        \n        # RKPM approximation u_h(x_eval)\n        u_h = np.sum([u_node * w_t for u_node, w_t in zip(u_at_nodes, w_tilde_vals)])\n        \n        # Errors as defined in the problem\n        e_u = np.abs(u_h - x_eval**2)\n        e_0 = np.abs(np.sum(w_tilde_vals) - 1.0)\n        e_1 = np.abs(np.sum([x_i * w_t for x_i, w_t in zip(support_nodes, w_tilde_vals)]) - x_eval)\n        \n        # Identify the specific corrected kernel valuetilde{W}_{I*}(x*)\n        w_tilde_specific = None\n        if np.isclose(x_eval, 0.37):\n            try:\n                # Find the index in the 'support_nodes' list corresponding to x=0.4\n                node_idx_in_support = support_nodes.index(0.4)\n                w_tilde_specific = w_tilde_vals[node_idx_in_support]\n            except ValueError:\n                # This case should not be reached with the given parameters\n                w_tilde_specific = float('nan')\n            \n        return {\n            \"e_u\": e_u,\n            \"e_0\": e_0,\n            \"e_1\": e_1,\n            \"w_tilde_specific\": w_tilde_specific\n        }\n\n    # Define the test cases from the problem statement.\n    test_cases_x = [0.37, 0.02, 0.98]\n    \n    results = []\n    w_tilde_special_val = None\n\n    for x in test_cases_x:\n        calc_results = perform_rkpm_calculation(x)\n        results.extend([calc_results[\"e_u\"], calc_results[\"e_0\"], calc_results[\"e_1\"]])\n        if calc_results[\"w_tilde_specific\"] is not None:\n            w_tilde_special_val = calc_results[\"w_tilde_specific\"]\n\n    results.append(w_tilde_special_val)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(f'{r:.17e}' for r in results)}]\")\n\nsolve()\n```", "id": "2576507"}, {"introduction": "A robust numerical method is one whose limitations are well understood. This final practice confronts a critical issue in meshfree methods: the ill-conditioning of the moment matrix that arises from poor nodal arrangements [@problem_id:2576516]. Through a guided thought experiment involving nearly collinear nodes, you will diagnose the resulting loss of completeness and critically evaluate several proposed remedies, gaining insight into the practical challenges of ensuring stability and accuracy.", "problem": "Consider the Moving Least Squares (MLS) construction that underlies both the Element-Free Galerkin method (EFG) and the Reproducing Kernel Particle Method (RKPM) for a scalar field $u(\\boldsymbol{x})$ in two spatial dimensions. Let the polynomial basis at a query point $\\boldsymbol{x}^\\ast$ be linear, $p(\\boldsymbol{x}) = \\begin{bmatrix} 1 & x & y \\end{bmatrix}^{\\top}$, and let the MLS weight associated with a neighbor node $a$ be a positive scalar $w_a(\\boldsymbol{x}^\\ast) = w\\!\\left(\\lVert \\boldsymbol{x}^\\ast - \\boldsymbol{x}_a \\rVert\\right)$. The normal equations for the MLS coefficients $a(\\boldsymbol{x}^\\ast) \\in \\mathbb{R}^3$ are\n$$\nM(\\boldsymbol{x}^\\ast)\\, a(\\boldsymbol{x}^\\ast) \\;=\\; b(\\boldsymbol{x}^\\ast),\n$$\nwith the moment matrix and right-hand side defined by\n$$\nM(\\boldsymbol{x}^\\ast) \\;=\\; \\sum_{a} w_a(\\boldsymbol{x}^\\ast)\\, p(\\boldsymbol{x}_a)\\, p(\\boldsymbol{x}_a)^{\\top}, \n\\qquad\nb(\\boldsymbol{x}^\\ast) \\;=\\; \\sum_{a} w_a(\\boldsymbol{x}^\\ast)\\, p(\\boldsymbol{x}_a)\\, u_a,\n$$\nwhere $u_a = u(\\boldsymbol{x}_a)$ are the nodal samples. Exact first-order completeness (exact reproduction of any linear polynomial) at $\\boldsymbol{x}^\\ast$ requires that $M(\\boldsymbol{x}^\\ast)$ be invertible; if $u(\\boldsymbol{x}) = c_0 + c_1 x + c_2 y$ for constants $c_0,c_1,c_2$, then $b(\\boldsymbol{x}^\\ast) = M(\\boldsymbol{x}^\\ast)\\, c$ with $c = \\begin{bmatrix} c_0 & c_1 & c_2 \\end{bmatrix}^{\\top}$, so the unique solution is $a(\\boldsymbol{x}^\\ast)=c$.\n\nConstruct the following specific, scientifically plausible scenario in a neighborhood of $\\boldsymbol{x}^\\ast = (0,0)$ that is prone to geometric degeneracy. There are exactly three neighbor nodes used in the fit:\n$$\n\\boldsymbol{x}_1 = (-1, 0), \n\\qquad\n\\boldsymbol{x}_2 = (0, 0), \n\\qquad\n\\boldsymbol{x}_3 = (1, \\epsilon),\n$$\nwith a small parameter $\\epsilon > 0$. Assume a radial weight with width chosen so that the three neighbors above dominate and have weights\n$$\nw_1(\\boldsymbol{x}^\\ast) \\;=\\; w_3(\\boldsymbol{x}^\\ast) \\;=\\; \\omega, \n\\qquad\nw_2(\\boldsymbol{x}^\\ast) \\;=\\; 1,\n$$\nwith $\\omega \\in (0,1)$ a fixed constant. Throughout, use the linear basis $p(\\boldsymbol{x}) = \\begin{bmatrix} 1 & x & y \\end{bmatrix}^{\\top}$ unless otherwise stated.\n\nBased on the definitions above, one computes\n$$\np(\\boldsymbol{x}_1) = \\begin{bmatrix} 1 \\\\ -1 \\\\ 0 \\end{bmatrix}, \n\\quad\np(\\boldsymbol{x}_2) = \\begin{bmatrix} 1 \\\\ 0 \\\\ 0 \\end{bmatrix}, \n\\quad\np(\\boldsymbol{x}_3) = \\begin{bmatrix} 1 \\\\ 1 \\\\ \\epsilon \\end{bmatrix},\n$$\nand hence\n$$\nM(\\boldsymbol{x}^\\ast) \n= \\sum_{a=1}^{3} w_a\\, p(\\boldsymbol{x}_a) p(\\boldsymbol{x}_a)^{\\top}\n= \n\\begin{bmatrix}\n1 + 2\\omega & 0 & \\omega \\epsilon \\\\\n0 & 2\\omega & \\omega \\epsilon \\\\\n\\omega \\epsilon & \\omega \\epsilon & \\omega \\epsilon^2\n\\end{bmatrix}.\n$$\n\nNow consider the following potential remedies in the same neighborhood $\\boldsymbol{x}^\\ast$:\n\n(i) Support enlargement: include one additional neighbor at $\\boldsymbol{x}_4 = (0,\\delta)$ with weight $w_4(\\boldsymbol{x}^\\ast) = \\tilde{\\omega} > 0$ for some $\\delta \\neq 0$, and otherwise keep the setup unchanged.\n\n(ii) Basis reduction: replace the linear basis by the constant basis $p(\\boldsymbol{x}) = \\begin{bmatrix} 1 \\end{bmatrix}$, keeping the original three neighbors only.\n\n(iii) Orthonormal basis change: replace $p(\\boldsymbol{x})$ by $\\tilde{p}(\\boldsymbol{x}) = Q p(\\boldsymbol{x})$ with an orthonormal matrix $Q \\in \\mathbb{R}^{3 \\times 3}$, keeping the original three neighbors and weights.\n\n(iv) Tikhonov regularization: replace the normal equations by $\\left(M(\\boldsymbol{x}^\\ast) + \\lambda I\\right) a_\\lambda(\\boldsymbol{x}^\\ast) = b(\\boldsymbol{x}^\\ast)$ with a small $\\lambda > 0$.\n\nSelect all statements below that are correct, and justify your selection by deriving them from the definitions above.\n\nA. For the given three-node configuration with the linear basis, one has $\\det M(\\boldsymbol{x}^\\ast) = \\omega^{2} \\epsilon^{2}$, so as $\\epsilon \\to 0^{+}$ the moment matrix becomes singular and exact first-order completeness is lost at $\\boldsymbol{x}^\\ast$.\n\nB. Under (i) with the added node at $\\boldsymbol{x}_4 = (0,\\delta)$ of weight $\\tilde{\\omega} > 0$, the determinant at $\\epsilon=0$ equals $2\\omega \\tilde{\\omega} (1+2\\omega)\\, \\delta^{2} > 0$, so the linear basis is admissible and exact first-order completeness is restored at $\\boldsymbol{x}^\\ast$.\n\nC. Under (ii) with the constant basis and the original three neighbors, the resulting moment matrix is invertible and exact first-order completeness is preserved.\n\nD. Under (iii) with an orthonormal change of polynomial basis and the original three neighbors, the rank and condition number of the moment matrix are unchanged, so the near-singularity caused by near collinearity cannot be resolved in this way.\n\nE. Under (iv) with Tikhonov regularization and the original three neighbors, $\\left(M+\\lambda I\\right)$ is invertible but exact first-order completeness of MLS or RKPM at $\\boldsymbol{x}^\\ast$ is not preserved for any $\\lambda>0$.", "solution": "The problem statement is subjected to validation before any solution is attempted.\n\n**Step 1: Extract Givens**\n- Method: Moving Least Squares (MLS) for Element-Free Galerkin (EFG) or Reproducing Kernel Particle Method (RKPM).\n- Field: Scalar field $u(\\boldsymbol{x})$ in two spatial dimensions.\n- Query point: $\\boldsymbol{x}^\\ast = (0,0)$.\n- Polynomial basis: Linear, $p(\\boldsymbol{x}) = \\begin{bmatrix} 1 & x & y \\end{bmatrix}^{\\top}$.\n- Normal equations: $M(\\boldsymbol{x}^\\ast)\\, a(\\boldsymbol{x}^\\ast) = b(\\boldsymbol{x}^\\ast)$ for coefficients $a(\\boldsymbol{x}^\\ast) \\in \\mathbb{R}^3$.\n- Moment matrix: $M(\\boldsymbol{x}^\\ast) \\;=\\; \\sum_{a} w_a(\\boldsymbol{x}^\\ast)\\, p(\\boldsymbol{x}_a)\\, p(\\boldsymbol{x}_a)^{\\top}$.\n- Right-hand side vector: $b(\\boldsymbol{x}^\\ast) \\;=\\; \\sum_{a} w_a(\\boldsymbol{x}^\\ast)\\, p(\\boldsymbol{x}_a)\\, u_a$.\n- Nodal samples: $u_a = u(\\boldsymbol{x}_a)$.\n- First-order completeness condition: $M(\\boldsymbol{x}^\\ast)$ must be invertible.\n- A specific configuration of exactly three neighbor nodes: $\\boldsymbol{x}_1 = (-1, 0)$, $\\boldsymbol{x}_2 = (0, 0)$, $\\boldsymbol{x}_3 = (1, \\epsilon)$ for a small parameter $\\epsilon > 0$.\n- Nodal weights at $\\boldsymbol{x}^\\ast$: $w_1(\\boldsymbol{x}^\\ast) = \\omega$, $w_2(\\boldsymbol{x}^\\ast) = 1$, $w_3(\\boldsymbol{x}^\\ast) = \\omega$, with $\\omega \\in (0,1)$ a constant.\n- Basis vectors at nodes: $p(\\boldsymbol{x}_1) = \\begin{bmatrix} 1 \\\\ -1 \\\\ 0 \\end{bmatrix}$, $p(\\boldsymbol{x}_2) = \\begin{bmatrix} 1 \\\\ 0 \\\\ 0 \\end{bmatrix}$, $p(\\boldsymbol{x}_3) = \\begin{bmatrix} 1 \\\\ 1 \\\\ \\epsilon \\end{bmatrix}$.\n- Stated moment matrix: $M(\\boldsymbol{x}^\\ast) = \\begin{bmatrix} 1 + 2\\omega & 0 & \\omega \\epsilon \\\\ 0 & 2\\omega & \\omega \\epsilon \\\\ \\omega \\epsilon & \\omega \\epsilon & \\omega \\epsilon^2 \\end{bmatrix}$.\n- Proposed remedies:\n    (i) Support enlargement: Add node $\\boldsymbol{x}_4 = (0,\\delta)$, $\\delta \\neq 0$, with weight $w_4 = \\tilde{\\omega} > 0$.\n    (ii) Basis reduction: Use constant basis $p(\\boldsymbol{x}) = \\begin{bmatrix} 1 \\end{bmatrix}$ with the original $3$ nodes.\n    (iii) Orthonormal basis change: Replace $p(\\boldsymbol{x})$ with $\\tilde{p}(\\boldsymbol{x}) = Q p(\\boldsymbol{x})$, where $Q$ is a $3 \\times 3$ orthonormal matrix.\n    (iv) Tikhonov regularization: Solve $\\left(M(\\boldsymbol{x}^\\ast) + \\lambda I\\right) a_\\lambda(\\boldsymbol{x}^\\ast) = b(\\boldsymbol{x}^\\ast)$ for $\\lambda > 0$.\n\n**Step 2: Validate Using Extracted Givens**\n- **Scientifically Grounded**: The problem is correctly formulated within the established theory of meshfree methods. The concepts of MLS, moment matrix, completeness, and ill-conditioning due to nodal geometry are central to this field.\n- **Well-Posed**: The problem is precisely defined. All necessary data and definitions are provided to analyze the given scenario and the proposed remedies.\n- **Objective**: The problem statement is purely mathematical and devoid of subjective or ambiguous language.\nThe provided setup is a classic example of geometric degeneracy leading to an ill-conditioned moment matrix, a well-known issue in meshfree methods. All definitions and calculations are standard. The premises are factually sound and internally consistent.\n\n**Step 3: Verdict and Action**\nThe problem is valid. I will proceed with a full derivation and analysis.\n\n---\n\n**Analysis of Options**\n\n**A. For the given three-node configuration with the linear basis, one has $\\det M(\\boldsymbol{x}^\\ast) = \\omega^{2} \\epsilon^{2}$, so as $\\epsilon \\to 0^{+}$ the moment matrix becomes singular and exact first-order completeness is lost at $\\boldsymbol{x}^\\ast$.**\n\nWe must compute the determinant of the provided moment matrix:\n$$\nM(\\boldsymbol{x}^\\ast) = \n\\begin{bmatrix}\n1 + 2\\omega & 0 & \\omega \\epsilon \\\\\n0 & 2\\omega & \\omega \\epsilon \\\\\n\\omega \\epsilon & \\omega \\epsilon & \\omega \\epsilon^2\n\\end{bmatrix}\n$$\nUsing cofactor expansion along the first row:\n$$\n\\det M(\\boldsymbol{x}^\\ast) = (1 + 2\\omega) \\begin{vmatrix} 2\\omega & \\omega \\epsilon \\\\ \\omega \\epsilon & \\omega \\epsilon^2 \\end{vmatrix} - 0 \\cdot (...) + \\omega \\epsilon \\begin{vmatrix} 0 & 2\\omega \\\\ \\omega \\epsilon & \\omega \\epsilon \\end{vmatrix}\n$$\n$$\n\\det M(\\boldsymbol{x}^\\ast) = (1 + 2\\omega) \\left( (2\\omega)(\\omega \\epsilon^2) - (\\omega \\epsilon)(\\omega \\epsilon) \\right) + \\omega \\epsilon \\left( (0)(\\omega \\epsilon) - (2\\omega)(\\omega \\epsilon) \\right)\n$$\n$$\n\\det M(\\boldsymbol{x}^\\ast) = (1 + 2\\omega) (2\\omega^2 \\epsilon^2 - \\omega^2 \\epsilon^2) - 2\\omega^3 \\epsilon^2\n$$\n$$\n\\det M(\\boldsymbol{x}^\\ast) = (1 + 2\\omega) (\\omega^2 \\epsilon^2) - 2\\omega^3 \\epsilon^2\n$$\n$$\n\\det M(\\boldsymbol{x}^\\ast) = \\omega^2 \\epsilon^2 + 2\\omega^3 \\epsilon^2 - 2\\omega^3 \\epsilon^2 = \\omega^2 \\epsilon^2\n$$\nThe calculation is correct. As $\\epsilon \\to 0^+$, the three nodes $\\boldsymbol{x}_1, \\boldsymbol{x}_2, \\boldsymbol{x}_3$ become collinear. In this limit, $\\det M(\\boldsymbol{x}^\\ast) \\to 0$. A matrix with a zero determinant is singular and thus not invertible. According to the problem definition, invertibility of the moment matrix is required for exact first-order completeness. Therefore, completeness is lost at $\\boldsymbol{x}^\\ast$ as the nodes become collinear.\nVerdict: **Correct**.\n\n**B. Under (i) with the added node at $\\boldsymbol{x}_4 = (0,\\delta)$ of weight $\\tilde{\\omega} > 0$, the determinant at $\\epsilon=0$ equals $2\\omega \\tilde{\\omega} (1+2\\omega)\\, \\delta^{2} > 0$, so the linear basis is admissible and exact first-order completeness is restored at $\\boldsymbol{x}^\\ast$.**\n\nWe consider remedy (i) at the degenerate limit where $\\epsilon=0$. The original moment matrix becomes:\n$$\nM_{\\text{orig}}(\\epsilon=0) = \n\\begin{bmatrix}\n1 + 2\\omega & 0 & 0 \\\\\n0 & 2\\omega & 0 \\\\\n0 & 0 & 0\n\\end{bmatrix}\n$$\nThe new node is $\\boldsymbol{x}_4 = (0, \\delta)$ with weight $w_4 = \\tilde{\\omega}$. The basis vector at this node is $p(\\boldsymbol{x}_4) = \\begin{bmatrix} 1 & 0 & \\delta \\end{bmatrix}^\\top$. The contribution to the moment matrix is:\n$$\nM_{\\text{add}} = w_4 p(\\boldsymbol{x}_4) p(\\boldsymbol{x}_4)^\\top = \\tilde{\\omega} \\begin{bmatrix} 1 \\\\ 0 \\\\ \\delta \\end{bmatrix} \\begin{bmatrix} 1 & 0 & \\delta \\end{bmatrix} = \\begin{bmatrix} \\tilde{\\omega} & 0 & \\tilde{\\omega}\\delta \\\\ 0 & 0 & 0 \\\\ \\tilde{\\omega}\\delta & 0 & \\tilde{\\omega}\\delta^2 \\end{bmatrix}\n$$\nThe new total moment matrix is $M_{\\text{new}} = M_{\\text{orig}}(\\epsilon=0) + M_{\\text{add}}$:\n$$\nM_{\\text{new}} = \\begin{bmatrix}\n1 + 2\\omega + \\tilde{\\omega} & 0 & \\tilde{\\omega}\\delta \\\\\n0 & 2\\omega & 0 \\\\\n\\tilde{\\omega}\\delta & 0 & \\tilde{\\omega}\\delta^2\n\\end{bmatrix}\n$$\nIts determinant is:\n$$\n\\det M_{\\text{new}} = (1 + 2\\omega + \\tilde{\\omega}) \\begin{vmatrix} 2\\omega & 0 \\\\ 0 & \\tilde{\\omega} \\delta^2 \\end{vmatrix} - 0 \\cdot (...) + \\tilde{\\omega}\\delta \\begin{vmatrix} 0 & 2\\omega \\\\ \\tilde{\\omega}\\delta & 0 \\end{vmatrix}\n$$\n$$\n\\det M_{\\text{new}} = (1 + 2\\omega + \\tilde{\\omega})(2\\omega \\tilde{\\omega} \\delta^2) + \\tilde{\\omega}\\delta(-2\\omega \\tilde{\\omega} \\delta)\n$$\n$$\n\\det M_{\\text{new}} = (2\\omega \\tilde{\\omega} \\delta^2)(1+2\\omega) + (2\\omega \\tilde{\\omega} \\delta^2)(\\tilde{\\omega}) - 2\\omega \\tilde{\\omega}^2 \\delta^2\n$$\n$$\n\\det M_{\\text{new}} = 2\\omega \\tilde{\\omega} (1+2\\omega) \\delta^2 + 2\\omega \\tilde{\\omega}^2 \\delta^2 - 2\\omega \\tilde{\\omega}^2 \\delta^2 = 2\\omega \\tilde{\\omega} (1+2\\omega) \\delta^2\n$$\nThe calculation in the statement is correct. Given that $\\omega \\in (0,1)$, $\\tilde{\\omega} > 0$, and $\\delta \\neq 0$ (so $\\delta^2 > 0$), we have $\\det M_{\\text{new}} > 0$. The matrix is invertible. Adding a non-collinear node breaks the geometric degeneracy, allowing the linear basis to be admissible and restoring exact first-order completeness.\nVerdict: **Correct**.\n\n**C. Under (ii) with the constant basis and the original three neighbors, the resulting moment matrix is invertible and exact first-order completeness is preserved.**\n\nUnder remedy (ii), the basis is reduced to the constant basis, $p(\\boldsymbol{x}) = \\begin{bmatrix} 1 \\end{bmatrix}$. The moment matrix becomes a $1 \\times 1$ matrix (a scalar):\n$$\nM(\\boldsymbol{x}^\\ast) = \\sum_{a=1}^3 w_a p(\\boldsymbol{x}_a) p(\\boldsymbol{x}_a)^\\top = w_1 (1)(1)^\\top + w_2 (1)(1)^\\top + w_3 (1)(1)^\\top\n$$\n$$\nM(\\boldsymbol{x}^\\ast) = \\omega + 1 + \\omega = 1+2\\omega\n$$\nSince $\\omega \\in (0,1)$, $M(\\boldsymbol{x}^\\ast) = 1+2\\omega > 1 > 0$, so the matrix is invertible. However, the statement claims that \"exact first-order completeness is preserved\". First-order completeness means the ability to exactly reproduce any linear polynomial. A constant basis can only guarantee the exact reproduction of constant functions (zeroth-order completeness). By reducing the basis from linear to constant, first-order completeness is explicitly lost, not preserved.\nVerdict: **Incorrect**.\n\n**D. Under (iii) with an orthonormal change of polynomial basis and the original three neighbors, the rank and condition number of the moment matrix are unchanged, so the near-singularity caused by near collinearity cannot be resolved in this way.**\n\nUnder remedy (iii), the new basis is $\\tilde{p}(\\boldsymbol{x}) = Q p(\\boldsymbol{x})$ where $Q$ is an orthonormal matrix ($Q Q^\\top = Q^\\top Q = I$). The new moment matrix $\\tilde{M}$ is:\n$$\n\\tilde{M} = \\sum_a w_a \\tilde{p}(\\boldsymbol{x}_a) \\tilde{p}(\\boldsymbol{x}_a)^\\top = \\sum_a w_a (Q p(\\boldsymbol{x}_a)) (Q p(\\boldsymbol{x}_a))^\\top = \\sum_a w_a Q p(\\boldsymbol{x}_a) p(\\boldsymbol{x}_a)^\\top Q^\\top\n$$\n$$\n\\tilde{M} = Q \\left( \\sum_a w_a p(\\boldsymbol{x}_a) p(\\boldsymbol{x}_a)^\\top \\right) Q^\\top = Q M Q^\\top\n$$\nThis is an orthogonal similarity transformation.\n- Rank: Since $Q$ is invertible, $\\text{rank}(\\tilde{M}) = \\text{rank}(M)$. The rank is invariant.\n- Condition Number (with respect to the Euclidean $2$-norm): For any matrix $A$ and orthogonal matrix $Q$, $\\text{cond}_2(Q A Q^\\top) = \\text{cond}_2(A)$. The condition number is also invariant.\nA change of basis is a purely algebraic manipulation. It does not alter the underlying geometric information content of the nodal configuration, which is the source of the ill-conditioning. If the original matrix $M$ is singular or nearly singular (high condition number), the transformed matrix $\\tilde{M}$ will have exactly the same properties. This remedy is therefore ineffective.\nVerdict: **Correct**.\n\n**E. Under (iv) with Tikhonov regularization and the original three neighbors, $\\left(M+\\lambda I\\right)$ is invertible but exact first-order completeness of MLS or RKPM at $\\boldsymbol{x}^\\ast$ is not preserved for any $\\lambda>0$.**\n\nUnder remedy (iv), we solve the regularized system $(M + \\lambda I) a_\\lambda = b$ with $\\lambda > 0$.\n- Invertibility: The matrix $M$ is symmetric and positive semi-definite, as $v^\\top M v = \\sum_a w_a (p_a^\\top v)^2 \\ge 0$. Its eigenvalues $\\mu_i$ are all non-negative. The eigenvalues of the regularized matrix $M+\\lambda I$ are $\\mu_i + \\lambda$. Since $\\mu_i \\ge 0$ and $\\lambda > 0$, all eigenvalues of $M+\\lambda I$ are strictly positive. A symmetric matrix with strictly positive eigenvalues is positive definite and thus invertible. This is true even if $M$ is singular.\n- Completeness: Exact first-order completeness requires that if the nodal values come from a linear polynomial, $u(\\boldsymbol{x}) = p(\\boldsymbol{x})^\\top c$, then the computed coefficients $a_\\lambda$ must be equal to $c$. For such a field, the right-hand side is $b = M c$. The regularized system becomes:\n$$\n(M + \\lambda I) a_\\lambda = M c\n$$\nThe solution for the coefficients is $a_\\lambda = (M + \\lambda I)^{-1} M c$.\nFor completeness, we require $a_\\lambda = c$, which implies $(M + \\lambda I)^{-1} M c = c$ for any vector $c$. This would mean $(M + \\lambda I)^{-1} M = I$. Pre-multiplying by $(M+\\lambda I)$ gives $M = M + \\lambda I$, which simplifies to $\\lambda I = 0$. This is only true if $\\lambda=0$. However, Tikhonov regularization is defined for $\\lambda > 0$. For any $\\lambda > 0$, $a_\\lambda \\neq c$ (unless $c=0$). The regularization scheme stabilizes the matrix inversion at the cost of introducing a bias, thereby losing the exact reproduction property.\nVerdict: **Correct**.", "answer": "$$\\boxed{ABDE}$$", "id": "2576516"}]}