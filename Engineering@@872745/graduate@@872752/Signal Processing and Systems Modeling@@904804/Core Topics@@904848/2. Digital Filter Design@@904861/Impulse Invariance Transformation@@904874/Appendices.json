{"hands_on_practices": [{"introduction": "Before applying a transformation, a firm grasp of its fundamental definition is essential. This first exercise challenges you to derive the impulse invariance relationship from first principles, based on a specific model of system interconnection. By doing so, you will clarify a common point of confusion regarding the scaling factor $T$ and see how it depends on the underlying theoretical model [@problem_id:2877401].", "problem": "Consider a continuous-time linear time-invariant system with impulse response $h_a(t)$ that is absolutely integrable, and the continuous-time Fourier transform (CTFT) convention\n$$\nH_a(j\\Omega)=\\int_{-\\infty}^{\\infty} h_a(t)\\, \\exp(-j\\Omega t)\\, dt.\n$$\nLet the sampling period be $T0$. We seek a discrete-time linear time-invariant system with impulse response $h_d[n]$ that is obtained from $h_a(t)$ by the impulse invariance principle. Assume the following interconnection: For an arbitrary discrete-time input sequence $x[n]$, form a continuous-time input\n$$\nx_a(t) = \\sum_{n=-\\infty}^{\\infty} x[n]\\, \\delta(t-nT),\n$$\ndrive the continuous-time system with $x_a(t)$ to obtain $y_a(t)$, and require that the discrete-time system output $y[n]$ satisfy\n$$\ny[n]=y_a(nT)\\quad\\text{for all integers }n.\n$$\nLet the discrete-time Fourier transform (DTFT) be defined by\n$$\nX_d(\\exp(j\\omega))=\\sum_{n=-\\infty}^{\\infty} x[n]\\, \\exp(-j\\omega n),\n$$\nwith inverse\n$$\nx[n]=\\frac{1}{2\\pi}\\int_{-\\pi}^{\\pi} X_d(\\exp(j\\omega))\\, \\exp(j\\omega n)\\, d\\omega.\n$$\nPostulate a time-domain relation of the form\n$$\nh_d[n]=\\gamma\\, h_a(nT),\n$$\nwhere $\\gamma$ is a scalar independent of $n$ and $T$. Starting from the convolution definitions of $y_a(t)$ and $y[n]$ and the above CTFT and DTFT conventions, derive whether the impulse invariance relation includes a factor $T$ in $h_d[n]$; that is, determine the value of $\\gamma$. Then confirm your result in the frequency domain by relating $H_d(\\exp(j\\omega))$ to $H_a(j\\Omega)$ using only well-tested results about sampling and the Poisson summation formula. Your final answer must be the value of $\\gamma$ as a single real number. No rounding is required.", "solution": "The problem requires the determination of a scaling constant $\\gamma$ in the impulse invariance relationship $h_d[n] = \\gamma h_a(nT)$ for a specific discrete-time system derived from a continuous-time system. The derivation must be performed first in the time domain, based on the provided system interconnection, and then confirmed in the frequency domain.\n\nFirst, we validate the problem statement.\nThe givens are:\n1.  A continuous-time linear time-invariant (LTI) system with an absolutely integrable impulse response $h_a(t)$.\n2.  The continuous-time Fourier transform (CTFT) definition: $H_a(j\\Omega)=\\int_{-\\infty}^{\\infty} h_a(t)\\, \\exp(-j\\Omega t)\\, dt$.\n3.  A sampling period $T0$.\n4.  A discrete-time LTI system with impulse response $h_d[n]$.\n5.  The system interconnection is defined as: an arbitrary discrete-time input $x[n]$ is converted to a continuous-time signal $x_a(t) = \\sum_{n=-\\infty}^{\\infty} x[n]\\, \\delta(t-nT)$. This signal drives the continuous-time system to produce $y_a(t)$. The output of the discrete-time system, $y[n]$, is obtained by sampling the continuous-time output: $y[n]=y_a(nT)$.\n6.  The discrete-time Fourier transform (DTFT) definition: $X_d(\\exp(j\\omega))=\\sum_{n=-\\infty}^{\\infty} x[n]\\, \\exp(-j\\omega n)$.\n7.  The postulated relationship: $h_d[n]=\\gamma\\, h_a(nT)$.\n\nThe problem is scientifically grounded, well-posed, objective, and contains no internal contradictions or missing information. All terms are standard in signal processing theory. The question is a formal derivation based on the provided definitions. Thus, the problem is valid.\n\nWe proceed to the solution.\n\n**Time-Domain Derivation**\n\nThe most direct method to find the impulse response $h_d[n]$ of the equivalent discrete-time system is to use a discrete-time impulse as the input and find the corresponding output sequence. Let the input be the unit impulse sequence, $x[n]=\\delta[n]$, where $\\delta[n]=1$ for $n=0$ and $\\delta[n]=0$ for $n \\neq 0$.\n\nAccording to the problem definition, this discrete-time input is used to form the continuous-time signal $x_a(t)$:\n$$\nx_a(t) = \\sum_{k=-\\infty}^{\\infty} x[k]\\, \\delta(t-kT) = \\sum_{k=-\\infty}^{\\infty} \\delta[k]\\, \\delta(t-kT)\n$$\nDue to the properties of the discrete-time impulse $\\delta[k]$, the only non-zero term in the summation is for $k=0$. Thus, the continuous-time input signal becomes:\n$$\nx_a(t) = \\delta[0]\\, \\delta(t-0 \\cdot T) = 1 \\cdot \\delta(t) = \\delta(t)\n$$\nThis signal, a continuous-time Dirac impulse, is the input to the continuous-time LTI system with impulse response $h_a(t)$. The output of this system, $y_a(t)$, is given by the convolution of the input with the impulse response:\n$$\ny_a(t) = x_a(t) * h_a(t) = \\int_{-\\infty}^{\\infty} x_a(\\tau) h_a(t-\\tau) \\, d\\tau = \\int_{-\\infty}^{\\infty} \\delta(\\tau) h_a(t-\\tau) \\, d\\tau\n$$\nBy the sifting property of the Dirac delta function, this integral evaluates to:\n$$\ny_a(t) = h_a(t-0) = h_a(t)\n$$\nThe problem states that the discrete-time output $y[n]$ is obtained by sampling $y_a(t)$ at integer multiples of the sampling period $T$:\n$$\ny[n] = y_a(nT) = h_a(nT)\n$$\nBy definition, the output of a discrete-time LTI system when the input is the unit impulse sequence $\\delta[n]$ is the system's impulse response, $h_d[n]$. Therefore, we have found that:\n$$\nh_d[n] = h_a(nT)\n$$\nThe problem postulates a relationship of the form $h_d[n]=\\gamma\\, h_a(nT)$. Comparing our derived result with this postulate, we can directly conclude that the scaling constant $\\gamma$ is:\n$$\n\\gamma = 1\n$$\n\n**Frequency-Domain Confirmation**\n\nWe now confirm this result by analyzing the system in the frequency domain. Let's find the frequency response $H_d(\\exp(j\\omega))$ of the discrete-time system.\nThe relationship between the discrete-time input $x[n]$ and the continuous-time input $x_a(t)$ is given. Their Fourier transforms are related. The CTFT of $x_a(t)$ is:\n$$\nX_a(j\\Omega) = \\mathcal{F}\\left\\{\\sum_{n=-\\infty}^{\\infty} x[n]\\, \\delta(t-nT)\\right\\} = \\sum_{n=-\\infty}^{\\infty} x[n]\\, \\mathcal{F}\\{\\delta(t-nT)\\} = \\sum_{n=-\\infty}^{\\infty} x[n]\\, \\exp(-j\\Omega nT)\n$$\nThis expression is the DTFT of $x[n]$, $X_d(\\exp(j\\omega))$, with the substitution $\\omega=\\Omega T$. So, $X_a(j\\Omega) = X_d(\\exp(j\\Omega T))$.\n\nThe output of the continuous-time filter in the frequency domain is $Y_a(j\\Omega) = H_a(j\\Omega) X_a(j\\Omega)$:\n$$\nY_a(j\\Omega) = H_a(j\\Omega) X_d(\\exp(j\\Omega T))\n$$\nThe discrete-time output $y[n]$ is obtained by sampling $y_a(t)$ at $t=nT$. The DTFT of the sampled signal, $Y_d(\\exp(j\\omega))$, is related to the CTFT of the original signal, $Y_a(j\\Omega)$, by the aliasing formula, which is a consequence of the Poisson summation formula:\n$$\nY_d(\\exp(j\\omega)) = \\frac{1}{T} \\sum_{k=-\\infty}^{\\infty} Y_a\\left(j\\left(\\frac{\\omega}{T} - \\frac{2\\pi k}{T}\\right)\\right)\n$$\nSubstituting the expression for $Y_a(j\\Omega)$:\n$$\nY_d(\\exp(j\\omega)) = \\frac{1}{T} \\sum_{k=-\\infty}^{\\infty} H_a\\left(j\\left(\\frac{\\omega}{T} - \\frac{2\\pi k}{T}\\right)\\right) X_d\\left(\\exp\\left(j\\left(\\frac{\\omega}{T} - \\frac{2\\pi k}{T}\\right)T\\right)\\right)\n$$\nThe argument of the exponential in $X_d$ simplifies:\n$$\n\\exp\\left(j\\left(\\frac{\\omega}{T} - \\frac{2\\pi k}{T}\\right)T\\right) = \\exp(j(\\omega - 2\\pi k)) = \\exp(j\\omega)\\exp(-j2\\pi k) = \\exp(j\\omega)\n$$\nsince $k$ is an integer. Thus, the term $X_d(\\exp(j\\omega))$ is independent of the summation index $k$ and can be factored out:\n$$\nY_d(\\exp(j\\omega)) = X_d(\\exp(j\\omega)) \\left[ \\frac{1}{T} \\sum_{k=-\\infty}^{\\infty} H_a\\left(j\\left(\\frac{\\omega}{T} - \\frac{2\\pi k}{T}\\right)\\right) \\right]\n$$\nFor a discrete-time LTI system, we have $Y_d(\\exp(j\\omega)) = H_d(\\exp(j\\omega)) X_d(\\exp(j\\omega))$. By comparing this with the derived expression, we identify the frequency response of the discrete-time system:\n$$\nH_d(\\exp(j\\omega)) = \\frac{1}{T} \\sum_{k=-\\infty}^{\\infty} H_a\\left(j\\left(\\frac{\\omega}{T} - \\frac{2\\pi k}{T}\\right)\\right)\n$$\nTo find the impulse response $h_d[n]$ from this frequency response, we take the inverse DTFT:\n$$\nh_d[n] = \\frac{1}{2\\pi} \\int_{-\\pi}^{\\pi} H_d(\\exp(j\\omega)) \\exp(j\\omega n) \\, d\\omega\n$$\nSubstituting the expression for $H_d(\\exp(j\\omega))$:\n$$\nh_d[n] = \\frac{1}{2\\pi} \\int_{-\\pi}^{\\pi} \\left[ \\frac{1}{T} \\sum_{k=-\\infty}^{\\infty} H_a\\left(j\\left(\\frac{\\omega}{T} - \\frac{2\\pi k}{T}\\right)\\right) \\right] \\exp(j\\omega n) \\, d\\omega\n$$\nExchanging the order of integration and summation:\n$$\nh_d[n] = \\frac{1}{2\\pi T} \\sum_{k=-\\infty}^{\\infty} \\int_{-\\pi}^{\\pi} H_a\\left(j\\left(\\frac{\\omega}{T} - \\frac{2\\pi k}{T}\\right)\\right) \\exp(j\\omega n) \\, d\\omega\n$$\nFor each integral, let's perform a change of variables. Let $\\Omega = \\frac{\\omega}{T} - \\frac{2\\pi k}{T}$. This implies $\\omega = T\\Omega + 2\\pi k$ and $d\\omega = T d\\Omega$. The integration limits for each term change: for $\\omega \\in [-\\pi, \\pi]$, the new limits for $\\Omega$ are $[\\frac{-\\pi}{T} - \\frac{2\\pi k}{T}, \\frac{\\pi}{T} - \\frac{2\\pi k}{T}]$.\nThe integral for a given $k$ becomes:\n$$\n\\int_{\\frac{-\\pi-2\\pi k}{T}}^{\\frac{\\pi-2\\pi k}{T}} H_a(j\\Omega) \\exp(j(T\\Omega + 2\\pi k) n) (T d\\Omega) = T \\int_{\\frac{-\\pi-2\\pi k}{T}}^{\\frac{\\pi-2\\pi k}{T}} H_a(j\\Omega) \\exp(j\\Omega nT) \\exp(j2\\pi kn) d\\Omega\n$$\nSince $k$ and $n$ are integers, $\\exp(j2\\pi kn) = 1$. Substituting this back into the sum for $h_d[n]$:\n$$\nh_d[n] = \\frac{1}{2\\pi T} \\sum_{k=-\\infty}^{\\infty} T \\int_{\\frac{-\\pi-2\\pi k}{T}}^{\\frac{\\pi-2\\pi k}{T}} H_a(j\\Omega) \\exp(j\\Omega nT) d\\Omega\n$$\nThe factors of $T$ cancel. The summation of the integrals over these adjacent intervals covers the entire real line:\n$$\nh_d[n] = \\frac{1}{2\\pi} \\sum_{k=-\\infty}^{\\infty} \\int_{\\frac{-\\pi-2\\pi k}{T}}^{\\frac{\\pi-2\\pi k}{T}} H_a(j\\Omega) \\exp(j\\Omega nT) d\\Omega = \\frac{1}{2\\pi} \\int_{-\\infty}^{\\infty} H_a(j\\Omega) \\exp(j\\Omega nT) d\\Omega\n$$\nThis final integral is the definition of the inverse CTFT of $H_a(j\\Omega)$, evaluated at time $t=nT$. The inverse CTFT corresponding to the given forward transform is $h_a(t) = \\frac{1}{2\\pi}\\int_{-\\infty}^{\\infty} H_a(j\\Omega)\\, \\exp(j\\Omega t)\\, d\\Omega$.\nThus, we find:\n$$\nh_d[n] = h_a(nT)\n$$\nThis frequency-domain analysis confirms the result obtained from the time-domain analysis. Comparing again to the postulate $h_d[n]=\\gamma\\, h_a(nT)$, we confirm that $\\gamma = 1$. It is important to note that this result is a direct consequence of the specific system block diagram defined in the problem. Other definitions of impulse invariance may lead to a different scaling factor.", "answer": "$$\n\\boxed{1}\n$$", "id": "2877401"}, {"introduction": "Having established the basic transformation, we now turn to a practical challenge in filter design. While impulse invariance aims to preserve the shape of the impulse response, the inherent sampling process can distort the frequency response due to aliasing. This practice guides you through correcting one such distortion by ensuring the designed digital filter has the same direct-current (DC) gain as the original analog filter, a critical requirement in many control and signal processing applications [@problem_id:2877422].", "problem": "Consider a strictly proper, causal, continuous-time Linear Time-Invariant (LTI) system with transfer function\n$$\nH_{c}(s)=\\sum_{k=1}^{M} \\frac{A_{k}}{s-p_{k}},\n$$\nwhere the poles $\\{p_{k}\\}_{k=1}^{M}$ are simple and satisfy $\\Re\\{p_{k}\\}0$, and the residues $\\{A_{k}\\}_{k=1}^{M}$ are finite. Let $h_{c}(t)$ denote the corresponding impulse response, so that for $t \\ge 0$,\n$$\nh_{c}(t)=\\sum_{k=1}^{M} A_{k}\\,\\exp(p_{k} t).\n$$\nLet the sampling period be $T0$, and define the discrete-time system obtained by the Impulse Invariance Transformation (IIT) as the one whose impulse response is\n$$\nh_{\\mathrm{ii}}[n]=T\\,h_{c}(nT), \\quad n \\in \\{0,1,2,\\dots\\}.\n$$\nDefine the direct-current (DC) gain of the continuous-time system as $H_{c}(0)$ and the DC gain of the discrete-time system as $H_{\\mathrm{ii}}(1)$, where $H_{\\mathrm{ii}}(z)$ is the $z$-transform of $h_{\\mathrm{ii}}[n]$.\n\nYou are asked to design a normalization that enforces equality of DC gains after IIT by post-scaling the discrete-time system. That is, seek a scalar factor $\\gamma$ (depending only on $T$, $\\{A_{k}\\}$, and $\\{p_{k}\\}$) such that the scaled discrete-time system with transfer function\n$$\nH_{\\mathrm{norm}}(z)=\\gamma\\, H_{\\mathrm{ii}}(z)\n$$\nsatisfies the DC-gain-matching condition $H_{\\mathrm{norm}}(1)=H_{c}(0)$. In other words, the discrete-time DC gain equals the continuous-time DC gain.\n\nStarting only from the definitions above and first principles for the Laplace transform and $z$-transform of absolutely integrable impulse responses, derive a closed-form analytical expression for $\\gamma$ in terms of $T$, $\\{A_{k}\\}$, and $\\{p_{k}\\}$. Provide a complete derivation and a rigorous proof that your expression indeed enforces $H_{\\mathrm{norm}}(1)=H_{c}(0)$ for all choices of $\\{A_{k}\\}$ and $\\{p_{k}\\}$ obeying the assumptions. Your final answer must be the single closed-form expression for $\\gamma$.", "solution": "The problem statement will first be subjected to a rigorous validation process.\n\n**Step 1: Extract Givens**\n- Continuous-time LTI system: strictly proper, causal.\n- Transfer function: $H_{c}(s)=\\sum_{k=1}^{M} \\frac{A_{k}}{s-p_{k}}$.\n- Poles: $\\{p_{k}\\}_{k=1}^{M}$ are simple and satisfy $\\Re\\{p_{k}\\}0$.\n- Residues: $\\{A_{k}\\}_{k=1}^{M}$ are finite.\n- Continuous-time impulse response for $t \\ge 0$: $h_{c}(t)=\\sum_{k=1}^{M} A_{k}\\,\\exp(p_{k} t)$.\n- Sampling period: $T0$.\n- Discrete-time impulse response (Impulse Invariance Transformation): $h_{\\mathrm{ii}}[n]=T\\,h_{c}(nT)$ for $n \\in \\{0,1,2,\\dots\\}$.\n- Continuous-time DC gain: $H_{c}(0)$.\n- Discrete-time DC gain: $H_{\\mathrm{ii}}(1)$, where $H_{\\mathrm{ii}}(z)$ is the $z$-transform of $h_{\\mathrm{ii}}[n]$.\n- Normalization condition: Find a scalar $\\gamma$ such that the system with transfer function $H_{\\mathrm{norm}}(z)=\\gamma\\, H_{\\mathrm{ii}}(z)$ satisfies $H_{\\mathrm{norm}}(1)=H_{c}(0)$.\n\n**Step 2: Validate Using Extracted Givens**\nThe problem is scientifically grounded, as it deals with standard concepts in digital signal processing, specifically the Impulse Invariance Transformation and the properties of LTI systems. The definitions for transfer functions, impulse responses, and DC gains are correct and standard in the field. The problem is well-posed; it asks for the derivation of a specific quantity ($\\gamma$) based on a given set of definitions and constraints. The language is objective and precise, devoid of ambiguity or subjectivity. All necessary information appears to be provided. The assumptions, such as the poles being in the left-half plane ($\\Re\\{p_k\\}  0$), are standard for ensuring stability of the continuous-time system and, consequently, the convergence of the sums involved in the discrete-time analysis. The problem is not trivial, as it requires a formal derivation using transform theory, but it is not ill-posed or contradictory.\n\n**Step 3: Verdict and Action**\nThe problem is deemed valid. A solution will be derived.\n\nThe objective is to find a scalar normalization factor $\\gamma$ such that the DC gain of a scaled discrete-time system matches the DC gain of its parent continuous-time system. The defining equation for $\\gamma$ is:\n$$\nH_{\\mathrm{norm}}(1)=H_{c}(0)\n$$\nGiven that $H_{\\mathrm{norm}}(z) = \\gamma H_{\\mathrm{ii}}(z)$, this condition becomes:\n$$\n\\gamma H_{\\mathrm{ii}}(1) = H_{c}(0)\n$$\nAssuming that $H_{\\mathrm{ii}}(1) \\neq 0$, we can express $\\gamma$ as:\n$$\n\\gamma = \\frac{H_{c}(0)}{H_{\\mathrm{ii}}(1)}\n$$\nWe must now derive expressions for $H_{c}(0)$ and $H_{\\mathrm{ii}}(1)$ from first principles.\n\nFirst, we compute the DC gain of the continuous-time system, $H_{c}(0)$. This is obtained by evaluating the transfer function $H_c(s)$ at $s=0$.\n$$\nH_{c}(0) = \\left. \\sum_{k=1}^{M} \\frac{A_{k}}{s-p_{k}} \\right|_{s=0} = \\sum_{k=1}^{M} \\frac{A_{k}}{0-p_{k}} = -\\sum_{k=1}^{M} \\frac{A_{k}}{p_{k}}\n$$\n\nNext, we compute the DC gain of the unscaled discrete-time system, $H_{\\mathrm{ii}}(1)$. This is obtained by evaluating the $z$-transform of $h_{\\mathrm{ii}}[n]$ at $z=1$. The $z$-transform is defined as:\n$$\nH_{\\mathrm{ii}}(z) = \\sum_{n=0}^{\\infty} h_{\\mathrm{ii}}[n] z^{-n}\n$$\nEvaluating at $z=1$ gives the sum of the impulse response coefficients:\n$$\nH_{\\mathrm{ii}}(1) = \\sum_{n=0}^{\\infty} h_{\\mathrm{ii}}[n] (1)^{-n} = \\sum_{n=0}^{\\infty} h_{\\mathrm{ii}}[n]\n$$\nWe substitute the given definition of $h_{\\mathrm{ii}}[n] = T h_c(nT)$:\n$$\nH_{\\mathrm{ii}}(1) = \\sum_{n=0}^{\\infty} T h_{c}(nT) = T \\sum_{n=0}^{\\infty} h_{c}(nT)\n$$\nNow, substitute the expression for $h_c(t)$:\n$$\nH_{\\mathrm{ii}}(1) = T \\sum_{n=0}^{\\infty} \\left( \\sum_{k=1}^{M} A_{k}\\,\\exp(p_{k} nT) \\right)\n$$\nSince the sum over $k$ is finite, and the sum over $n$ converges absolutely (as will be shown), we can interchange the order of summation:\n$$\nH_{\\mathrm{ii}}(1) = T \\sum_{k=1}^{M} A_{k} \\left( \\sum_{n=0}^{\\infty} \\exp(p_{k} nT) \\right)\n$$\nThe inner sum is a geometric series of the form $\\sum_{n=0}^{\\infty} r^n$, with $r = \\exp(p_{k} T)$. For this series to converge, we require $|r|1$. Let us verify this condition. The pole $p_k$ can be written in Cartesian form as $p_k = \\sigma_k + j\\omega_k$. The condition $\\Re\\{p_k\\}  0$ means $\\sigma_k  0$. The magnitude of the ratio $r$ is:\n$$\n|\\exp(p_{k} T)| = |\\exp((\\sigma_k + j\\omega_k)T)| = |\\exp(\\sigma_k T)\\exp(j\\omega_k T)| = |\\exp(\\sigma_k T)| \\cdot |\\exp(j\\omega_k T)|\n$$\nSince $\\sigma_k  0$ and $T  0$, $\\sigma_k T$ is a negative real number, so $|\\exp(\\sigma_k T)| = \\exp(\\sigma_k T)  1$. Also, $|\\exp(j\\omega_k T)| = 1$. Thus, $|r| = \\exp(\\sigma_k T)  1$, and the geometric series converges.\nThe sum of the geometric series is $\\frac{1}{1-r}$. Applying this to our expression:\n$$\n\\sum_{n=0}^{\\infty} \\exp(p_k nT) = \\sum_{n=0}^{\\infty} (\\exp(p_k T))^n = \\frac{1}{1 - \\exp(p_k T)}\n$$\nSubstituting this result back into the expression for $H_{\\mathrm{ii}}(1)$:\n$$\nH_{\\mathrm{ii}}(1) = T \\sum_{k=1}^{M} \\frac{A_{k}}{1 - \\exp(p_{k} T)}\n$$\nWe now have the necessary expressions for $H_{c}(0)$ and $H_{\\mathrm{ii}}(1)$. We can substitute them into the formula for $\\gamma$:\n$$\n\\gamma = \\frac{H_{c}(0)}{H_{\\mathrm{ii}}(1)} = \\frac{-\\sum_{k=1}^{M} \\frac{A_{k}}{p_{k}}}{T \\sum_{k=1}^{M} \\frac{A_{k}}{1 - \\exp(p_{k} T)}}\n$$\nThis is the closed-form analytical expression for the normalization factor $\\gamma$.\n\nFinally, we provide the proof that this expression for $\\gamma$ enforces the desired DC-gain-matching condition. By construction, we define the normalized system as $H_{\\mathrm{norm}}(z) = \\gamma H_{\\mathrm{ii}}(z)$. The DC gain of this normalized system is:\n$$\nH_{\\mathrm{norm}}(1) = \\gamma H_{\\mathrm{ii}}(1)\n$$\nSubstituting our derived expression for $\\gamma$:\n$$\nH_{\\mathrm{norm}}(1) = \\left( \\frac{-\\sum_{k=1}^{M} \\frac{A_{k}}{p_{k}}}{T \\sum_{k=1}^{M} \\frac{A_{k}}{1 - \\exp(p_{k} T)}} \\right) \\left( T \\sum_{k=1}^{M} \\frac{A_{k}}{1 - \\exp(p_{k} T)} \\right)\n$$\nAssuming the denominator is non-zero, it cancels with the term for $H_{\\mathrm{ii}}(1)$, yielding:\n$$\nH_{\\mathrm{norm}}(1) = -\\sum_{k=1}^{M} \\frac{A_{k}}{p_{k}}\n$$\nThis is precisely the expression we derived for $H_c(0)$. Therefore, we have proven that $H_{\\mathrm{norm}}(1) = H_c(0)$ for all choices of $\\{A_k\\}$ and $\\{p_k\\}$ that satisfy the initial assumptions and for which $H_{\\mathrm{ii}}(1) \\neq 0$.", "answer": "$$\n\\boxed{\\frac{-\\sum_{k=1}^{M} \\frac{A_{k}}{p_{k}}}{T \\sum_{k=1}^{M} \\frac{A_{k}}{1 - \\exp(p_{k} T)}}}\n$$", "id": "2877422"}, {"introduction": "This final practice reverses the direction of our thinking in an advanced computational exercise that mirrors a real-world engineering task: system identification. Given a measured discrete-time impulse response that is assumed to follow an impulse-invariant model, you will develop a procedure to estimate the poles of the original continuous-time system. This problem delves into the practical aspects of model fitting and the critical step of correctly interpreting the multi-valued complex logarithm to recover the continuous-time pole locations from their discrete-time counterparts [@problem_id:2877423].", "problem": "You are given the impulse invariance setting for a continuous-time, linear time-invariant (LTI) rational system with transfer function $H_a(s)$ and impulse response $h_a(t)$. Under uniform sampling with period $T$, the discrete-time impulse response is $h_d[n] = h_a(nT)$ for integer $n \\ge 0$. Assume the continuous-time transfer function $H_a(s)$ is strictly proper with simple poles $\\{p_k\\}_{k=1}^K$ with $\\Re\\{p_k\\} lt; 0$ and residues $\\{R_k\\}_{k=1}^K$, so that the impulse response is a finite sum of exponentials $h_a(t) = \\sum_{k=1}^K R_k e^{p_k t}$. Then $h_d[n] = \\sum_{k=1}^K R_k \\left(e^{p_k T}\\right)^n$. Let $z_k = e^{p_k T}$ denote the discrete-time modes.\n\nFrom the definitions above and the properties of exponentials, the sequence $h_d[n]$ is a finite sum of $K$ complex exponentials, which implies it satisfies a homogeneous linear recurrence with constant coefficients of order $K$ whose characteristic roots are $\\{z_k\\}_{k=1}^K$. This can be exploited to estimate the discrete-time modes $\\{z_k\\}$ from a finite set of samples $\\{h_d[n]\\}_{n=0}^{N-1}$ using a consistent data-driven method such as linear prediction or Pronyâ€™s method. Once $\\{z_k\\}$ are estimated, recovering the continuous-time poles requires selecting a logarithm branch because the complex logarithm is multivalued. A physically meaningful and widely used choice consistent with impulse invariance is to select the branch so that the imaginary parts $\\Im\\{p_k\\}$ lie within the open Nyquist band $(-\\pi/T,\\pi/T]$ and the stability constraint $\\Re\\{p_k\\} lt; 0$ holds. The residues $\\{R_k\\}$ can then be obtained by solving a linear system defined by the exponential model for $h_d[n]$.\n\nTask: Develop a complete program that, given measured discrete-time impulse responses $\\{h_d[n]\\}$, the sampling period $T$ in seconds, and the model order $K$, estimates the continuous-time poles $\\{p_k\\}$ and validates them against ground truth using a quantitative criterion. Your program must:\n\n- Implement a robust procedure to estimate the $K$ discrete-time modes $\\{z_k\\}$ from $\\{h_d[n]\\}$ using only the properties above (sum of exponentials implies a linear annihilating filter).\n- Map $\\{z_k\\}$ to continuous-time poles $\\{p_k\\}$ using a branch selection that enforces the imaginary parts in $(-\\pi/T,\\pi/T]$ (angles in radians) and yields $\\Re\\{p_k\\} lt; 0$ when supported by the data.\n- Estimate the residues $\\{R_k\\}$ by least squares from the exponential model implied by the estimated $\\{z_k\\}$.\n- For evaluation, perform an optimal matching between estimated poles and true poles that minimizes the total absolute error in $\\mathbb{C}$, and declare success if the maximum absolute pole error across the matched set is less than or equal to a specified tolerance $\\varepsilon_p$ (in radians per second).\n\nUse the following test suite. For each case, synthesize $h_d[n]$ from the stated ground-truth poles and residues via $h_d[n] = \\sum_{k=1}^K R_k e^{p_k n T}$ for $n \\in \\{0,1,\\dots,N-1\\}$, then apply your estimation procedure. All angular frequencies must be treated in radians per second, and time in seconds. The tolerance for pole estimation must be $\\varepsilon_p = 1.0 \\times 10^{-1}$ (radians per second).\n\n- Case A (two real poles, noiseless):\n  - $K = 2$, $T = 0.1$ (seconds), $N = 50$ (samples).\n  - Poles: $p = \\{-3.0,\\,-7.0\\}$.\n  - Residues: $R = \\{2.0,\\,-1.0\\}$.\n  - Additive noise standard deviation: $\\sigma = 0.0$.\n\n- Case B (one complex-conjugate pair, noiseless):\n  - $K = 2$, $T = 0.05$ (seconds), $N = 120$ (samples).\n  - Poles: $p = \\{-1.0 + 5.0\\,\\mathrm{j},\\,-1.0 - 5.0\\,\\mathrm{j}\\}$.\n  - Residues: $R = \\{1.0 - 0.5\\,\\mathrm{j},\\,1.0 + 0.5\\,\\mathrm{j}\\}$.\n  - Additive noise standard deviation: $\\sigma = 0.0$.\n\n- Case C (complex-conjugate pair near the Nyquist boundary, noiseless):\n  - $K = 2$, $T = 0.05$ (seconds), $N = 200$ (samples). Note that $\\pi/T \\approx 62.831853\\ldots$ (radians per second).\n  - Poles: $p = \\{-0.5 + 60.0\\,\\mathrm{j},\\,-0.5 - 60.0\\,\\mathrm{j}\\}$.\n  - Residues: $R = \\{0.3 + 0.2\\,\\mathrm{j},\\,0.3 - 0.2\\,\\mathrm{j}\\}$.\n  - Additive noise standard deviation: $\\sigma = 0.0$.\n\n- Case D (three poles with small noise):\n  - $K = 3$, $T = 0.02$ (seconds), $N = 200$ (samples).\n  - Poles: $p = \\{-2.0,\\,-0.5 + 20.0\\,\\mathrm{j},\\,-0.5 - 20.0\\,\\mathrm{j}\\}$.\n  - Residues: $R = \\{1.0,\\,0.6 - 0.2\\,\\mathrm{j},\\,0.6 + 0.2\\,\\mathrm{j}\\}$.\n  - Additive noise standard deviation: $\\sigma = 1.0 \\times 10^{-6}$.\n\nEvaluation and output specification:\n\n- For each case, compute the estimated continuous-time poles $\\{\\hat{p}_k\\}$ and match them to ground truth $\\{p_k\\}$ by minimizing the sum of absolute errors $\\sum_k |\\hat{p}_{\\pi(k)} - p_k|$ over all permutations $\\pi$. Let the maximum matched pole error be $e_{\\max} = \\max_k |\\hat{p}_{\\pi(k)} - p_k|$. Declare the case successful if $e_{\\max} \\le \\varepsilon_p$.\n- Your program should produce a single line of output containing the success values for the four cases as a comma-separated list enclosed in square brackets, for example, $[\\text{true},\\text{false},\\text{true},\\text{true}]$, but using Python boolean literals in lowercase.\n\nAll numeric outputs in the internal computations must be consistent with radians for angular quantities and seconds for time. The final printed output must be exactly one line in the specified list format with booleans.", "solution": "We begin from the fundamental model of a continuous-time, linear time-invariant (LTI) rational system with strictly proper transfer function $H_a(s)$. If $H_a(s)$ has simple poles $\\{p_k\\}_{k=1}^K$ with $\\Re\\{p_k\\} lt; 0$ and residues $\\{R_k\\}_{k=1}^K$, then the impulse response is\n$$\nh_a(t) \\;=\\; \\sum_{k=1}^K R_k e^{p_k t},\n$$\na direct consequence of the partial fraction expansion of rational functions and the linearity and time-invariance of the system. Under impulse invariance sampling with sampling period $T$ (seconds), the discrete-time impulse response is\n$$\nh_d[n] \\;=\\; h_a(nT) \\;=\\; \\sum_{k=1}^K R_k \\left(e^{p_k T}\\right)^n \\;=\\; \\sum_{k=1}^K R_k z_k^n,\n$$\nwhere $z_k = e^{p_k T}$ are the discrete-time modes. This expresses $h_d[n]$ as a finite sum of $K$ complex exponentials. A well-tested fact is that any such sequence obeys a homogeneous linear recurrence of order $K$ with constant coefficients: there exist coefficients $\\{a_\\ell\\}_{\\ell=1}^K$ such that for all $n$ in a valid range,\n$$\nh_d[n + K] + \\sum_{\\ell=1}^K a_\\ell\\, h_d[n + K - \\ell] = 0.\n$$\nThe characteristic polynomial of this recurrence,\n$$\nA(z) = z^K + a_1 z^{K-1} + \\cdots + a_K,\n$$\nhas roots at the discrete-time modes $\\{z_k\\}_{k=1}^K$. This follows from substituting a trial solution $h_d[n] = c z^n$ and obtaining $A(z) = 0$.\n\nPrinciple-based estimation of $\\{z_k\\}$: Given a finite set of measured samples $\\{h_d[n]\\}_{n=0}^{N-1}$ and assuming $N$ is sufficiently larger than $K$, we can form a set of $M = N - K$ linear equations of the recurrence. Denote $y[n] = -h_d[n + K]$ and $X[n, \\ell] = h_d[n + K - (\\ell+1)]$ for $\\ell \\in \\{0,1,\\dots,K-1\\}$ and $n \\in \\{0,1,\\dots,M-1\\}$. The linear system $X a \\approx y$ with $a = [a_1,\\dots,a_K]^\\top$ can be solved in the least-squares sense. Once $a$ is estimated, compute the roots of $A(z)$ to obtain $\\{\\hat{z}_k\\}$.\n\nBranch-consistent recovery of $\\{p_k\\}$: The mapping from $z_k$ to $p_k$ is multi-valued because the complex logarithm is multivalued: for any integer $m$, $\\log(z_k) = \\ln|z_k| + \\mathrm{j}(\\arg(z_k) + 2\\pi m)$ is a valid branch. The physically meaningful branch under impulse invariance assumes that analog frequencies are in the Nyquist band and thus chooses the branch whose imaginary parts lie in $(-\\pi/T,\\pi/T]$. A consistent way to achieve this is:\n- Compute the magnitude $|z_k|$ and principal argument $\\arg(z_k) \\in (-\\pi,\\pi]$.\n- Form $\\hat{p}_k = \\dfrac{\\ln|z_k| + \\mathrm{j}\\,\\arg(z_k)}{T}$, which places $\\Im\\{\\hat{p}_k\\}$ in $(-\\pi/T,\\pi/T]$ due to the principal value of the argument. This delivers the branch selection aligned with the Nyquist band. Because $|z_k| = e^{\\Re\\{p_k\\} T}$, stable continuous-time poles yield $|z_k| lt; 1$ and thus $\\Re\\{\\hat{p}_k\\} lt; 0$ in the absence of noise.\n\nResidue estimation: With $\\{\\hat{z}_k\\}$ in hand, fit residues $\\{\\hat{R}_k\\}$ to the model $h_d[n] \\approx \\sum_{k=1}^K \\hat{R}_k \\hat{z}_k^n$ by solving a linear least-squares problem. Using the Vandermonde-like matrix $V \\in \\mathbb{C}^{N \\times K}$ with entries $V[n,k] = \\hat{z}_k^n$ for $n \\in \\{0,\\dots,N-1\\}$ and $k \\in \\{1,\\dots,K\\}$, solve $V \\hat{R} \\approx h_d$ in the least-squares sense.\n\nMatching and validation: To compare the estimated poles $\\{\\hat{p}_k\\}$ with ground-truth $\\{p_k\\}$, a permutation-invariant comparison is required. Construct the cost matrix $C \\in \\mathbb{R}^{K \\times K}$ with $C_{ij} = |\\hat{p}_j - p_i|$, then solve the linear sum assignment (Hungarian) problem to find the permutation that minimizes the total absolute error. Let $e_{\\max}$ be the maximum absolute error under this optimal pairing. A test case is declared successful if $e_{\\max} \\le \\varepsilon_p$. Here the tolerance is set to $\\varepsilon_p = 1.0 \\times 10^{-1}$ (radians per second), balancing numerical sensitivity and model identifiability.\n\nAlgorithmic and numerical considerations:\n- Data length $N$ must satisfy $N \\ge 2K$ to ensure at least $K$ equations for a $K$-parameter recurrence, and in practice one uses $N \\gg K$ for robustness.\n- The least-squares solution of the annihilating filter coefficients and of the residues should be computed using numerically stable methods (for example, the singular value decomposition) provided by standard linear algebra routines.\n- The principal argument function $\\arg(\\cdot)$ returns values in $(-\\pi,\\pi]$, ensuring the imaginary parts of $\\hat{p}_k$ lie in $(-\\pi/T,\\pi/T]$, consistent with the Nyquist band assumption of impulse invariance. If noise causes small violations of stability (for example, $\\Re\\{\\hat{p}_k\\}  0$ slightly), the mismatch will typically be minor and can be tolerated within the tolerance.\n- Complex-conjugate pole pairs with conjugate residues generate real $h_d[n]$. The estimator does not need to explicitly enforce conjugacy; it will typically recover approximate conjugate pairs due to the structure of the data.\n\nTest suite construction:\n- Case A uses two real poles with $K = 2$, $T = 0.1$ (seconds), $N = 50$, zero noise, poles $\\{-3.0,\\,-7.0\\}$, residues $\\{2.0,\\,-1.0\\}$. This verifies basic recovery for real exponentials.\n- Case B uses one complex-conjugate pair with $K = 2$, $T = 0.05$ (seconds), $N = 120$, zero noise, poles $\\{-1.0 \\pm 5.0\\,\\mathrm{j}\\}$, residues $\\{1.0 \\mp 0.5\\,\\mathrm{j}\\}$. This verifies branch handling and complex modes.\n- Case C uses a pair near the Nyquist boundary with $K = 2$, $T = 0.05$ (seconds), $N = 200$, zero noise, poles $\\{-0.5 \\pm 60.0\\,\\mathrm{j}\\}$, residues $\\{0.3 \\pm 0.2\\,\\mathrm{j}\\}$. Since $\\pi/T \\approx 62.831853\\ldots$ (radians per second), the imaginary parts lie inside the band, testing sensitivity to near-boundary angles.\n- Case D uses three poles with small additive noise with $K = 3$, $T = 0.02$ (seconds), $N = 200$, $\\sigma = 1.0 \\times 10^{-6}$, poles $\\{-2.0,\\,-0.5 \\pm 20.0\\,\\mathrm{j}\\}$, and residues $\\{1.0,\\,0.6 \\mp 0.2\\,\\mathrm{j}\\}$. This tests multi-mode recovery under slight perturbations.\n\nFinal program behavior: For each case, synthesize $h_d[n]$, estimate $\\{\\hat{z}_k\\}$, map to $\\{\\hat{p}_k\\}$ with branch selection in the Nyquist band, estimate residues $\\{\\hat{R}_k\\}$, perform optimal pole matching with the ground truth, and emit a boolean indicating whether $e_{\\max} \\le \\varepsilon_p$. The program prints a single line with the booleans for the four cases as a Python list, for example $[\\text{True},\\text{True},\\text{True},\\text{True}]$.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.optimize import linear_sum_assignment\n\ndef generate_hd(poles, residues, T, N, noise_sigma=0.0, rng=None):\n    \"\"\"\n    Generate discrete-time impulse response h_d[n] = sum R_k * exp(p_k * T * n)\n    \"\"\"\n    n = np.arange(N, dtype=float)\n    h = np.zeros(N, dtype=complex)\n    for p, R in zip(poles, residues):\n        h += R * np.exp(p * T * n)\n    if noise_sigma > 0.0:\n        if rng is None:\n            rng = np.random.default_rng(0)\n        # Add real-valued Gaussian noise to keep output real if underlying signal is real\n        noise = noise_sigma * rng.standard_normal(N)\n        h = h + noise\n    return h\n\ndef prony_estimate_z(h, K):\n    \"\"\"\n    Estimate discrete-time modes z_k from sequence h using linear prediction (Prony).\n    h: 1-D numpy array (complex or real)\n    K: model order\n    Returns: array of K roots (z_k)\n    \"\"\"\n    h = np.asarray(h, dtype=complex).ravel()\n    N = h.shape[0]\n    M = N - K\n    if M = K:\n        raise ValueError(\"Insufficient data length N relative to model order K.\")\n    # Build least-squares system X a = y, where\n    # y[n] = -h[n+K], X[n, i] = h[n+K-(i+1)] for i=0..K-1\n    X = np.zeros((M, K), dtype=complex)\n    y = -h[K:K+M]\n    for n in range(M):\n        for i in range(K):\n            X[n, i] = h[n + K - (i + 1)]\n    # Solve for a (prediction coefficients)\n    a, *_ = np.linalg.lstsq(X, y, rcond=None)\n    # Characteristic polynomial A(z) = z^K + a1 z^{K-1} + ... + aK\n    poly_coeffs = np.concatenate(([1.0], a))\n    # Roots\n    z_roots = np.roots(poly_coeffs)\n    return z_roots\n\ndef estimate_residues(h, z):\n    \"\"\"\n    Given sequence h[n] and modes z_k, estimate residues R_k in h[n] ~ sum R_k z_k^n\n    via least squares.\n    \"\"\"\n    h = np.asarray(h, dtype=complex).ravel()\n    N = h.shape[0]\n    K = len(z)\n    n = np.arange(N, dtype=float)[:, None]  # shape (N,1)\n    V = (z[None, :] ** n)  # Vandermonde-like matrix\n    R, *_ = np.linalg.lstsq(V, h, rcond=None)\n    return R\n\ndef map_z_to_p(z, T):\n    \"\"\"\n    Map discrete-time modes z to continuous-time poles p using branch selection\n    in the Nyquist band: p = (ln|z| + j*angle(z)) / T, where angle in (-pi, pi].\n    \"\"\"\n    z = np.asarray(z, dtype=complex)\n    mags = np.abs(z)\n    angs = np.angle(z)  # principal value (-pi, pi]\n    p = (np.log(mags) + 1j * angs) / T\n    return p\n\ndef match_poles(p_true, p_est):\n    \"\"\"\n    Match estimated poles to true poles by minimizing total absolute difference.\n    Returns the permutation indices for p_est to match p_true, and the errors.\n    \"\"\"\n    p_true = np.asarray(p_true, dtype=complex)\n    p_est = np.asarray(p_est, dtype=complex)\n    K = len(p_true)\n    cost = np.abs(p_true[:, None] - p_est[None, :])\n    row_ind, col_ind = linear_sum_assignment(cost)\n    errs = np.abs(p_true[row_ind] - p_est[col_ind])\n    return col_ind, errs\n\ndef run_case(poles, residues, T, N, K, noise_sigma=0.0, eps_p=1e-1, rng=None):\n    h = generate_hd(poles, residues, T, N, noise_sigma=noise_sigma, rng=rng)\n    # Estimate z modes\n    z_est = prony_estimate_z(h, K)\n    # Map to continuous-time poles with branch selection in Nyquist band\n    p_est = map_z_to_p(z_est, T)\n    # Estimate residues (not used for validation here, but computed as part of the requested procedure)\n    _ = estimate_residues(h, z_est)\n    # Match estimated poles to true poles\n    _, errs = match_poles(np.array(poles, dtype=complex), p_est)\n    emax = float(np.max(errs)) if errs.size > 0 else float('inf')\n    return emax = eps_p\n\ndef solve():\n    # Fixed RNG for reproducibility of noise in Case D\n    rng = np.random.default_rng(12345)\n    eps_p = 1.0e-1  # radians per second\n\n    # Define the test cases\n    test_cases = [\n        # Case A\n        {\n            \"poles\": np.array([-3.0 + 0.0j, -7.0 + 0.0j], dtype=complex),\n            \"residues\": np.array([2.0 + 0.0j, -1.0 + 0.0j], dtype=complex),\n            \"T\": 0.1,\n            \"N\": 50,\n            \"K\": 2,\n            \"noise_sigma\": 0.0\n        },\n        # Case B\n        {\n            \"poles\": np.array([-1.0 + 5.0j, -1.0 - 5.0j], dtype=complex),\n            \"residues\": np.array([1.0 - 0.5j, 1.0 + 0.5j], dtype=complex),\n            \"T\": 0.05,\n            \"N\": 120,\n            \"K\": 2,\n            \"noise_sigma\": 0.0\n        },\n        # Case C\n        {\n            \"poles\": np.array([-0.5 + 60.0j, -0.5 - 60.0j], dtype=complex),\n            \"residues\": np.array([0.3 + 0.2j, 0.3 - 0.2j], dtype=complex),\n            \"T\": 0.05,\n            \"N\": 200,\n            \"K\": 2,\n            \"noise_sigma\": 0.0\n        },\n        # Case D\n        {\n            \"poles\": np.array([-2.0 + 0.0j, -0.5 + 20.0j, -0.5 - 20.0j], dtype=complex),\n            \"residues\": np.array([1.0 + 0.0j, 0.6 - 0.2j, 0.6 + 0.2j], dtype=complex),\n            \"T\": 0.02,\n            \"N\": 200,\n            \"K\": 3,\n            \"noise_sigma\": 1.0e-6\n        },\n    ]\n\n    results = []\n    for case in test_cases:\n        ok = run_case(\n            poles=case[\"poles\"],\n            residues=case[\"residues\"],\n            T=case[\"T\"],\n            N=case[\"N\"],\n            K=case[\"K\"],\n            noise_sigma=case[\"noise_sigma\"],\n            eps_p=eps_p,\n            rng=rng\n        )\n        results.append(ok)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(lambda b: str(b).lower(), results))}]\")\n\nsolve()\n```", "id": "2877423"}]}