{"hands_on_practices": [{"introduction": "To begin our hands-on exploration, we address the most fundamental question in quantizer design: for a given number of levels, what is the optimal way to place decision thresholds and reproduction values to minimize distortion? This exercise [@problem_id:2898106] guides you through deriving the celebrated Lloyd-Max conditions from first principles for a simple, symmetric uniform source. By solving for the optimal three-level quantizer, you will build a concrete understanding of the centroid condition and nearest-neighbor rule that form the bedrock of quantization theory.", "problem": "Consider a memoryless real-valued source $X$ with probability density function (PDF) $f_{X}(x)$ that is uniform on the bounded interval $\\left[-A, A\\right]$, where $A>0$ is known, that is $f_{X}(x)=\\frac{1}{2A}$ for $x\\in[-A,A]$ and $f_{X}(x)=0$ otherwise. Let $Q$ be a scalar quantizer with $3$ reproduction levels $y_{1}<y_{2}<y_{3}$ and $2$ finite decision thresholds $b_{1}<b_{2}$ that partition $\\left[-A, A\\right]$ into three contiguous cells. Assume $Q$ maps $x\\in[-A,b_{1})$ to $y_{1}$, $x\\in[b_{1},b_{2})$ to $y_{2}$, and $x\\in[b_{2},A]$ to $y_{3}$, with measure-zero conventions at the boundaries being irrelevant. Define the mean squared error (MSE) distortion\n$$\nD(y_{1},y_{2},y_{3},b_{1},b_{2}) \\triangleq \\mathbb{E}\\!\\left[(X-Q(X))^{2}\\right].\n$$\nStarting only from the definition of $D$ and first principles of optimization, and without invoking any pre-quoted quantizer optimality conditions, do the following:\n- Justify that, without loss of optimality, an optimal solution can be taken to be symmetric about $0$ and deduce the resulting structural constraints on $(y_{1},y_{2},y_{3})$ and $(b_{1},b_{2})$.\n- Derive the necessary conditions for optimality by minimizing $D$ jointly over $(y_{1},y_{2},y_{3})$ for fixed $(b_{1},b_{2})$ and by minimizing $D$ over $(b_{1},b_{2})$ for fixed $(y_{1},y_{2},y_{3})$, using only the stated PDF and the MSE criterion.\n- Solve these conditions in closed form to obtain the globally optimal decision thresholds and reproduction levels as functions of $A$.\n- Compute the resulting minimized distortion $D^{\\star}$ as a closed-form expression in $A$.\n\nProvide the final answer as a single row matrix in the following order:\n$$\n\\begin{pmatrix}\nb_{1} & b_{2} & y_{1} & y_{2} & y_{3} & D^{\\star}\n\\end{pmatrix}.\n$$\nNo numerical approximation is required; provide exact symbolic expressions. Do not include any units.", "solution": "We begin with $X\\sim\\mathrm{Unif}([-A,A])$ and a scalar quantizer $Q$ with three cells and reproduction levels $y_{1}<y_{2}<y_{3}$ separated by thresholds $b_{1}<b_{2}$. The mean squared error (MSE) distortion is\n$$\nD=\\mathbb{E}\\!\\left[(X-Q(X))^{2}\\right]\n=\\int_{-A}^{A} (x-Q(x))^{2} f_{X}(x)\\,dx\n=\\frac{1}{2A}\\left[\\int_{-A}^{b_{1}}(x-y_{1})^{2}\\,dx+\\int_{b_{1}}^{b_{2}}(x-y_{2})^{2}\\,dx+\\int_{b_{2}}^{A}(x-y_{3})^{2}\\,dx\\right].\n$$\n\nSymmetry reduction. The PDF $f_{X}$ is even, and the squared error loss $(x-q)^{2}$ is invariant under the joint sign flip $(x,q)\\mapsto(-x,-q)$. If $Q$ is any quantizer with distortion $D(Q)$, define $\\widetilde{Q}(x)\\triangleq -Q(-x)$. Then $D(\\widetilde{Q})=D(Q)$ because the distribution of $X$ is symmetric and the loss is even. Consider the symmetrized mapping $Q_{s}(x)\\triangleq \\frac{1}{2}\\left(Q(x)+\\widetilde{Q}(x)\\right)$. By convexity of the function $q\\mapsto (x-q)^{2}$ for each fixed $x$, Jensen’s inequality implies\n$$\n(x-Q_{s}(x))^{2}\\leq \\frac{1}{2}\\left[(x-Q(x))^{2}+(x-\\widetilde{Q}(x))^{2}\\right].\n$$\nIntegrating against the symmetric PDF yields $D(Q_{s})\\leq D(Q)$. Therefore an optimal quantizer can be taken to be symmetric about $0$. For a $3$-level quantizer, symmetry imposes\n$$\nb_{1}=-t,\\quad b_{2}=t,\\quad y_{1}=-r,\\quad y_{2}=0,\\quad y_{3}=r,\n$$\nfor some $t\\in(0,A)$ and $r>0$. The cells are $[-A,-t)$, $[-t,t)$, and $[t,A]$.\n\nOptimal reproduction levels for fixed thresholds. For fixed $t$, minimizing $D$ with respect to each reproduction level decouples cellwise. For a given cell $[a,b]$ with reproduction level $y$, the contribution to $D$ is\n$$\n\\frac{1}{2A}\\int_{a}^{b}(x-y)^{2}\\,dx.\n$$\nDifferentiating with respect to $y$ and setting the derivative to zero gives\n$$\n\\frac{\\partial}{\\partial y}\\left[\\int_{a}^{b}(x-y)^{2}\\,dx\\right]=\\int_{a}^{b}-2(x-y)\\,dx=0\n\\;\\;\\Longrightarrow\\;\\; y=\\frac{1}{b-a}\\int_{a}^{b}x\\,dx=\\frac{a+b}{2}.\n$$\nThus, in each cell, the optimal reproduction level is the conditional mean of $X$ restricted to that cell, which for a uniform density is simply the interval midpoint. Applying this to the three cells yields\n$$\ny_{1}=\\frac{-A+(-t)}{2}=\\frac{-A-t}{2},\\quad y_{2}=\\frac{-t+t}{2}=0,\\quad y_{3}=\\frac{t+A}{2}.\n$$\nWith symmetry $y_{1}=-y_{3}$, which is automatically satisfied by these expressions.\n\nOptimal thresholds for fixed reproduction levels. For the squared error criterion on the real line, the pointwise optimal decision is the nearest-neighbor rule: for any $x$, the quantizer should choose the $y_{k}$ minimizing $(x-y_{k})^{2}$, which is equivalent to minimizing $|x-y_{k}|$. The decision boundary between two adjacent reproduction levels $y_{i}$ and $y_{i+1}$ is the point $x$ where $(x-y_{i})^{2}=(x-y_{i+1})^{2}$, which simplifies to $x=\\frac{y_{i}+y_{i+1}}{2}$. Applying this to the symmetric structure, the positive threshold $t$ (boundary between $y_{2}=0$ and $y_{3}=\\frac{t+A}{2}$) must satisfy\n$$\nt=\\frac{y_{2}+y_{3}}{2}=\\frac{0+\\frac{t+A}{2}}{2}=\\frac{t+A}{4}.\n$$\nSolving gives\n$$\n4t=t+A\\;\\;\\Longrightarrow\\;\\; 3t=A\\;\\;\\Longrightarrow\\;\\; t=\\frac{A}{3}.\n$$\nThe reproduction levels are then\n$$\ny_{3}=\\frac{t+A}{2}=\\frac{\\frac{A}{3}+A}{2}=\\frac{2A}{3},\\quad y_{2}=0,\\quad y_{1}=-\\frac{2A}{3}.\n$$\nThus the optimal thresholds and reproduction levels are\n$$\nb_{1}=-\\frac{A}{3},\\quad b_{2}=\\frac{A}{3},\\quad y_{1}=-\\frac{2A}{3},\\quad y_{2}=0,\\quad y_{3}=\\frac{2A}{3}.\n$$\n\nResulting minimized distortion. Substitute these values into the distortion integral. Using $f_{X}(x)=\\frac{1}{2A}$ on $[-A,A]$, we have\n$$\nD^{\\star}=\\frac{1}{2A}\\left[\\int_{-A}^{-A/3}\\left(x+\\frac{2A}{3}\\right)^{2}\\,dx+\\int_{-A/3}^{A/3}x^{2}\\,dx+\\int_{A/3}^{A}\\left(x-\\frac{2A}{3}\\right)^{2}\\,dx\\right].\n$$\nA convenient general identity for a uniform subinterval $[a,b]$ with midpoint $m=\\frac{a+b}{2}$ is\n$$\n\\int_{a}^{b}(x-m)^{2}\\,dx=\\frac{(b-a)^{3}}{12}.\n$$\nEach of the three cells has length $\\ell=\\frac{2A}{3}$ and, with the optimal $y_{k}$ set to the midpoint of its cell, each cell’s contribution equals $\\frac{1}{2A}\\cdot \\frac{\\ell^{3}}{12}$. Therefore,\n$$\nD^{\\star}=3\\cdot \\frac{1}{2A}\\cdot \\frac{\\left(\\frac{2A}{3}\\right)^{3}}{12}\n=\\frac{3}{2A}\\cdot \\frac{8A^{3}}{27}\\cdot \\frac{1}{12}\n=\\frac{3}{2A}\\cdot \\frac{2A^{3}}{81}\n=\\frac{A^{2}}{27}.\n$$\nHence, the globally optimal $3$-level scalar quantizer for a bounded uniform source on $\\left[-A,A\\right]$ has thresholds at $\\pm \\frac{A}{3}$, reproduction levels at $\\left\\{-\\frac{2A}{3},0,\\frac{2A}{3}\\right\\}$, and minimized distortion $D^{\\star}=\\frac{A^{2}}{27}$.", "answer": "$$\\boxed{\\begin{pmatrix}-\\frac{A}{3} & \\frac{A}{3} & -\\frac{2A}{3} & 0 & \\frac{2A}{3} & \\frac{A^{2}}{27}\\end{pmatrix}}$$", "id": "2898106"}, {"introduction": "While optimal quantizers are theoretically important, practical systems often use fixed uniform quantizers. In this context, a critical design choice is setting the quantizer's dynamic range. This practice [@problem_id:2898089] delves into the essential trade-off between granular error, which arises from the finite step size within the quantizer's range, and overload error, which occurs when the input signal is clipped. By analyzing a Gaussian source, you will quantify both error contributions and see how the choice of a \"backoff\" factor balances them to minimize total distortion.", "problem": "Consider a real-valued, midtread, symmetric, uniform quantizer with saturation (clipping) at thresholds $\\pm X_{\\max}$ and a total of $2^{N}$ quantization intervals across the granular region $\\left[-X_{\\max},X_{\\max}\\right]$. The quantizer step size is therefore $\\Delta=2X_{\\max}/2^{N}$. The input signal $x$ is a zero-mean Gaussian random variable with variance $\\sigma^{2}$, that is, $x \\sim \\mathcal{N}(0,\\sigma^{2})$. The output $y$ equals the quantized value when $|x|\\leq X_{\\max}$ and equals $\\operatorname{sgn}(x)\\,X_{\\max}$ when $|x|>X_{\\max}$ (hard clipping in overload). Assume the standard high-resolution granular error model: conditioned on $|x|\\leq X_{\\max}$, the granular error $e_{g}=y-x$ is uniformly distributed over $\\left(-\\Delta/2,\\Delta/2\\right)$ and is independent of $x$; in overload, $y=\\operatorname{sgn}(x)\\,X_{\\max}$ and the overload error equals $e_{o}=y-x=\\operatorname{sgn}(x)\\left(X_{\\max}-|x|\\right)$.\n\nDefine the normalized backoff $\\alpha=X_{\\max}/\\sigma$. Use the Gaussian Probability Density Function (PDF) $\\varphi(z)=\\frac{1}{\\sqrt{2\\pi}}\\exp\\!\\left(-\\frac{z^{2}}{2}\\right)$ and the Gaussian tail (complementary cumulative distribution) $Q(\\alpha)=\\int_{\\alpha}^{\\infty}\\varphi(z)\\,dz$.\n\nStarting only from these definitions and modeling assumptions, and without introducing any additional approximations beyond the stated granular error model, do the following for a fixed $N$:\n- Compute the overload probability $P_{\\mathrm{ol}}=\\mathbb{P}(|x|>X_{\\max})$ in terms of $\\alpha$.\n- Determine the analytic expression that captures the trade-off between backoff $\\alpha$ (equivalently $X_{\\max}$) and granular distortion by deriving the exact total mean-squared error $D(\\alpha;N,\\sigma)=\\mathbb{E}\\!\\left[(y-x)^{2}\\right]$ as a closed-form function of $\\alpha$, $N$, and $\\sigma$ that combines granular and overload contributions.\n\nYour final answer must be a single closed-form analytic expression or a single row matrix containing the closed-form overload probability and the total mean-squared error as functions of $\\alpha$, $N$, and $\\sigma$. Do not introduce any numerical values. Do not provide an inequality or an equation to be solved; provide explicit expressions in terms of $\\alpha$, $N$, $\\sigma$, $\\varphi(\\cdot)$, and $Q(\\cdot)$ only. No rounding is required and no units are needed.", "solution": "The problem requires the calculation of two quantities: the overload probability $P_{\\mathrm{ol}}$ and the total mean-squared error (MSE) $D$.\n\n**1. Overload Probability, $P_{\\mathrm{ol}}$**\n\nThe overload probability is the probability that the input signal magnitude exceeds the quantizer's maximum threshold, $X_{\\max}$.\n$$P_{\\mathrm{ol}} = \\mathbb{P}(|x| > X_{\\max})$$\nGiven that the input $x$ is a zero-mean Gaussian random variable, its PDF $f_x(u)$ is symmetric about $u=0$. Therefore, $\\mathbb{P}(x > X_{\\max}) = \\mathbb{P}(x < -X_{\\max})$.\n$$P_{\\mathrm{ol}} = \\mathbb{P}(x > X_{\\max}) + \\mathbb{P}(x < -X_{\\max}) = 2\\mathbb{P}(x > X_{\\max})$$\nTo compute this probability, we standardize the random variable $x$. Let $z = x/\\sigma$. Then $z$ follows the standard normal distribution, $z \\sim \\mathcal{N}(0,1)$. The condition $x > X_{\\max}$ is equivalent to $z > X_{\\max}/\\sigma$. Using the provided definition $\\alpha = X_{\\max}/\\sigma$, this becomes $z > \\alpha$.\n$$\\mathbb{P}(x > X_{\\max}) = \\mathbb{P}(z > \\alpha) = \\int_{\\alpha}^{\\infty} \\frac{1}{\\sqrt{2\\pi}}\\exp\\left(-\\frac{v^2}{2}\\right) dv$$\nThis integral is the definition of the Gaussian Q-function, $Q(\\alpha)$.\nTherefore, the overload probability is:\n$$P_{\\mathrm{ol}} = 2Q(\\alpha)$$\n\n**2. Total Mean-Squared Error, $D(\\alpha; N, \\sigma)$**\n\nThe total MSE, $D$, is the expected value of the squared error $e^2 = (y-x)^2$. We can compute this by partitioning the expectation over the granular region ($|x| \\leq X_{\\max}$) and the overload region ($|x| > X_{\\max}$).\n$$D = \\mathbb{E}[e^2] = \\mathbb{E}[e^2 \\cdot \\mathbb{I}(|x| \\leq X_{\\max})] + \\mathbb{E}[e^2 \\cdot \\mathbb{I}(|x| > X_{\\max})]$$\nwhere $\\mathbb{I}(\\cdot)$ is the indicator function. Let's call these two terms the granular distortion contribution, $D_g$, and the overload distortion contribution, $D_o$.\n\n**Granular Distortion Contribution, $D_g$**:\n$$D_g = \\mathbb{E}[e_g^2 \\cdot \\mathbb{I}(|x| \\leq X_{\\max})]$$\nBy the law of total expectation, this is $\\mathbb{E}[e_g^2 | |x| \\leq X_{\\max}] \\cdot \\mathbb{P}(|x| \\leq X_{\\max})$.\nThe problem states that conditioned on $|x| \\leq X_{\\max}$, the granular error $e_g$ is uniform on $(-\\Delta/2, \\Delta/2)$. The second moment (and variance, since the mean is $0$) of a uniform distribution $U(a,b)$ is $\\frac{(b-a)^2}{12}$. For $e_g$, this is $\\frac{(\\Delta/2 - (-\\Delta/2))^2}{12} = \\frac{\\Delta^2}{12}$.\nSo, $\\mathbb{E}[e_g^2 | |x| \\leq X_{\\max}] = \\frac{\\Delta^2}{12}$.\nThe probability of being in the granular region is $\\mathbb{P}(|x| \\leq X_{\\max}) = 1 - P_{\\mathrm{ol}} = 1 - 2Q(\\alpha)$.\nSubstituting $\\Delta = \\frac{2X_{\\max}}{2^N} = \\frac{2\\alpha\\sigma}{2^N}$:\n$$D_g = \\frac{1}{12}\\left(\\frac{2\\alpha\\sigma}{2^N}\\right)^2 (1 - 2Q(\\alpha)) = \\frac{4\\alpha^2\\sigma^2}{12 \\cdot (2^N)^2} (1 - 2Q(\\alpha)) = \\frac{\\alpha^2\\sigma^2}{3 \\cdot 2^{2N}}(1 - 2Q(\\alpha))$$\n\n**Overload Distortion Contribution, $D_o$**:\n$$D_o = \\mathbb{E}[e_o^2 \\cdot \\mathbb{I}(|x| > X_{\\max})] = \\int_{|u| > X_{\\max}} (\\operatorname{sgn}(u)X_{\\max} - u)^2 f_x(u) du$$\nThe integrand is symmetric. For $u > X_{\\max}$, the squared error is $(X_{\\max}-u)^2$. For $u < -X_{\\max}$, it is $(-X_{\\max}-u)^2 = (X_{\\max}+u)^2$. Due to the symmetry of $f_x(u)$, the contributions from positive and negative overload regions are identical.\n$$D_o = 2 \\int_{X_{\\max}}^{\\infty} (u-X_{\\max})^2 f_x(u) du = 2 \\int_{X_{\\max}}^{\\infty} (u-X_{\\max})^2 \\frac{1}{\\sigma\\sqrt{2\\pi}} \\exp\\left(-\\frac{u^2}{2\\sigma^2}\\right) du$$\nWe perform a change of variable $z = u/\\sigma$, so $u = z\\sigma$ and $du = \\sigma dz$. The lower limit of integration becomes $\\alpha = X_{\\max}/\\sigma$.\n$$D_o = 2 \\int_{\\alpha}^{\\infty} (z\\sigma - \\alpha\\sigma)^2 \\frac{1}{\\sigma\\sqrt{2\\pi}} \\exp\\left(-\\frac{z^2}{2}\\right) \\sigma dz = 2\\sigma^2 \\int_{\\alpha}^{\\infty} (z-\\alpha)^2 \\varphi(z) dz$$\nWe expand the square: $(z-\\alpha)^2 = z^2 - 2\\alpha z + \\alpha^2$. The integral becomes:\n$$ \\int_{\\alpha}^{\\infty} (z^2 - 2\\alpha z + \\alpha^2) \\varphi(z) dz = \\int_{\\alpha}^{\\infty} z^2\\varphi(z)dz - 2\\alpha\\int_{\\alpha}^{\\infty} z\\varphi(z)dz + \\alpha^2\\int_{\\alpha}^{\\infty} \\varphi(z)dz $$\nWe evaluate each integral term:\n- The last term is by definition $\\alpha^2 Q(\\alpha)$.\n- For the middle term, $\\int z\\varphi(z)dz = \\int \\frac{z}{\\sqrt{2\\pi}}\\exp(-z^2/2)dz = -\\frac{1}{\\sqrt{2\\pi}}\\exp(-z^2/2) = -\\varphi(z)$. So, $\\int_{\\alpha}^{\\infty} z\\varphi(z)dz = [-\\varphi(z)]_{\\alpha}^{\\infty} = 0 - (-\\varphi(\\alpha)) = \\varphi(\\alpha)$.\n- For the first term, we use integration by parts $\\int z^2\\varphi(z)dz = \\int z(z\\varphi(z))dz$. Let $u=z, dv=z\\varphi(z)dz$, so $du=dz, v=-\\varphi(z)$.\n  $\\int_{\\alpha}^{\\infty} z^2\\varphi(z)dz = [-z\\varphi(z)]_{\\alpha}^{\\infty} - \\int_{\\alpha}^{\\infty} (-\\varphi(z))dz = (0 - (-\\alpha\\varphi(\\alpha))) + \\int_{\\alpha}^{\\infty}\\varphi(z)dz = \\alpha\\varphi(\\alpha) + Q(\\alpha)$.\nCombining these results:\n$$ \\int_{\\alpha}^{\\infty} (z-\\alpha)^2 \\varphi(z) dz = (\\alpha\\varphi(\\alpha) + Q(\\alpha)) - 2\\alpha(\\varphi(\\alpha)) + \\alpha^2 Q(\\alpha) = (\\alpha^2+1)Q(\\alpha) - \\alpha\\varphi(\\alpha) $$\nThus, the overload distortion contribution is:\n$$ D_o = 2\\sigma^2 \\left( (\\alpha^2+1)Q(\\alpha) - \\alpha\\varphi(\\alpha) \\right) $$\n\n**Total MSE**:\nThe total MSE is the sum $D = D_g + D_o$:\n$$ D(\\alpha; N, \\sigma) = \\frac{\\alpha^2\\sigma^2}{3 \\cdot 2^{2N}}(1 - 2Q(\\alpha)) + 2\\sigma^2 \\left( (\\alpha^2+1)Q(\\alpha) - \\alpha\\varphi(\\alpha) \\right) $$\nThis is the required closed-form expression.\n\n**Summary of Results**:\n- Overload Probability: $P_{\\mathrm{ol}} = 2Q(\\alpha)$.\n- Total MSE: $D(\\alpha; N, \\sigma) = \\frac{\\alpha^2\\sigma^2}{3 \\cdot 2^{2N}}(1 - 2Q(\\alpha)) + 2\\sigma^2 \\left( (\\alpha^2+1)Q(\\alpha) - \\alpha\\varphi(\\alpha) \\right)$.\n\nThese are the final expressions to be presented.", "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n2Q(\\alpha) & \\frac{\\alpha^2 \\sigma^2}{3 \\cdot 2^{2N}}(1 - 2Q(\\alpha)) + 2 \\sigma^2 \\left( (\\alpha^2+1)Q(\\alpha) - \\alpha \\varphi(\\alpha) \\right)\n\\end{pmatrix}\n}\n$$", "id": "2898089"}, {"introduction": "Moving beyond quantizing single samples, we now explore how to efficiently quantize correlated signals, which are ubiquitous in audio, image, and video processing. This advanced practice [@problem_id:2898103] contrasts direct quantization with Differential Pulse-Code Modulation (DPCM), a predictive coding scheme. You will first design a whitening filter to decorrelate an autoregressive source and then analyze how using it in a DPCM loop reduces the variance of the signal being quantized, ultimately leading to a significant reduction in the required bit rate for the same target fidelity.", "problem": "Consider a zero-mean, real, wide-sense stationary, first-order autoregressive source modeled by the causal, stable recursion $x[n] = a\\,x[n-1] + w[n]$, where $|a| &lt; 1$ and $\\{w[n]\\}$ is a zero-mean, white, Gaussian sequence with variance $\\sigma_{w}^{2}$. Let $S_{x}(\\omega)$ denote the power spectral density of $x[n]$.\n\n1) Design a causal, stable pre-filter $P(z)$ that whitens $x[n]$ in the sense that the output $y[n] = (P\\star x)[n]$ has a constant power spectral density. Your design must be justified from first principles by starting from the autoregressive definition and the factorization of $S_{x}(\\omega)$.\n\n2) Now compare two scalar quantization systems operated at the same resolution design policy. In both systems, a uniform midrise scalar quantizer with $L = 2^{B}$ reproduction levels is used together with subtractive dither (so that in the high-resolution regime the quantization error can be modeled as an additive, input-independent white noise of variance $\\Delta^{2}/12$). In both systems, the quantizer step size $\\Delta$ is chosen to cover the interval $\\pm c$ times the standard deviation of the quantizer input using the $L$ uniform steps, that is $\\Delta = 2 c\\,\\sigma_{\\text{in}}/L$, where $c &gt; 0$ is a fixed overload margin and $\\sigma_{\\text{in}}$ is the standard deviation of the signal at the quantizer input.\n\nSystem (i) is direct scalar quantization of $x[n]$ (no pre/post filtering), producing reconstruction $\\hat{x}_{\\text{dir}}[n]$.\n\nSystem (ii) is a Differential Pulse-Code Modulation (DPCM) architecture that employs the one-step linear predictor induced by your $P(z)$ design in a closed loop: the encoder forms the residual $u[n] = x[n] - a\\,\\hat{x}[n-1]$, quantizes $u[n]$ with the same uniform quantizer and subtractive dither, and the decoder reconstructs $\\hat{x}[n] = \\hat{u}[n] + a\\,\\hat{x}[n-1]$, where $\\hat{u}[n]$ is the quantizer output and the predictor uses reconstructed past samples. Assume the high-resolution additive-noise model holds and that all relevant processes are in steady state.\n\nFor a given target end-to-end mean-square error distortion $D = \\mathbb{E}\\{|x[n] - \\hat{x}[n]|^{2}\\}$ at the output of each system, derive from first principles an explicit, closed-form expression for the reduction in the required number of bits\n$$\\Delta B \\triangleq B_{\\text{dir}} - B_{\\text{dpcm}},$$\nas a function of $a$, $\\sigma_{w}^{2}$, and $D$. Your derivation must begin from the autoregressive source model, the whitening property of your $P(z)$, and the high-resolution additive-noise model for uniform quantization with subtractive dither. You must account for the feedback of quantization noise in the DPCM loop when determining the variance at the input of the residual quantizer. Express $\\Delta B$ in bits. No numerical substitution is required, and no rounding is necessary. The final answer must be a single closed-form analytic expression.", "solution": "The problem is divided into two parts. First, we design a whitening pre-filter for the specified autoregressive source. Second, we compare the performance of direct scalar quantization with a Differential Pulse-Code Modulation (DPCM) system that uses a predictor based on this filter, and derive the bit rate reduction for a fixed distortion.\n\n**Part 1: Whitening Pre-filter Design**\n\nThe source is a first-order autoregressive (AR($1$)) process given by the recursion:\n$$x[n] = a\\,x[n-1] + w[n]$$\nwhere $|a| < 1$ for stability, and $w[n]$ is a zero-mean white Gaussian noise with variance $\\sigma_{w}^{2}$. The power spectral density (PSD) of $w[n]$ is constant, $S_{w}(\\omega) = \\sigma_{w}^{2}$.\n\nTaking the Z-transform of the recursion, we obtain the system function $H(z)$ that generates $x[n]$ from $w[n]$:\n$$X(z) = a z^{-1} X(z) + W(z) \\implies X(z) (1 - a z^{-1}) = W(z) \\implies H(z) = \\frac{X(z)}{W(z)} = \\frac{1}{1 - a z^{-1}}$$\nThe PSD of the source $x[n]$ is given by $S_{x}(\\omega) = |H(e^{j\\omega})|^{2} S_{w}(\\omega)$. Substituting the expressions for $H(e^{j\\omega})$ and $S_{w}(\\omega)$:\n$$S_{x}(\\omega) = \\frac{1}{|1 - a e^{-j\\omega}|^{2}} \\sigma_{w}^{2} = \\frac{\\sigma_{w}^{2}}{1 - 2a\\cos(\\omega) + a^{2}}$$\nWe must design a causal and stable pre-filter $P(z)$ such that its output $y[n]$ has a constant PSD. Let the output sequence be $y[n]$, with Z-transform $Y(z) = P(z)X(z)$. The PSD of the output is $S_{y}(\\omega) = |P(e^{j\\omega})|^{2} S_{x}(\\omega)$. For $S_{y}(\\omega)$ to be constant, the filter's frequency response $|P(e^{j\\omega})|^{2}$ must be proportional to the inverse of $S_{x}(\\omega)$.\n$$|P(e^{j\\omega})|^{2} S_{x}(\\omega) = |P(e^{j\\omega})|^{2} \\frac{\\sigma_{w}^{2}}{|1 - a e^{-j\\omega}|^{2}} = \\text{constant}$$\nThe simplest choice that achieves this is to set the filter's response to cancel the denominator of $S_x(\\omega)$. Let us choose the filter with the system function:\n$$P(z) = 1 - a z^{-1}$$\nThis is a Finite Impulse Response (FIR) filter, which is always stable. Its coefficients are non-zero only for non-positive powers of $z$, so it is causal. With this choice, the frequency response is $P(e^{j\\omega}) = 1 - a e^{-j\\omega}$.\n\nThe PSD of the output $y[n]$ becomes:\n$$S_{y}(\\omega) = |1 - a e^{-j\\omega}|^{2} \\frac{\\sigma_{w}^{2}}{|1 - a e^{-j\\omega}|^{2}} = \\sigma_{w}^{2}$$\nThis is a constant, so the output signal $y[n]$ is white. The whitening filter is $P(z) = 1 - a z^{-1}$. This corresponds to the operation $y[n] = x[n] - a x[n-1]$, which, from the original source definition, is equal to $w[n]$, the driving white noise process. This confirms the validity of our filter design.\n\n**Part 2: Bit Rate Reduction Analysis**\n\nWe are given a uniform quantizer model where the quantization error variance is $\\sigma_{q}^{2} = \\Delta^{2}/12$. The step size is set by the rule $\\Delta = 2c\\,\\sigma_{\\text{in}}/L = 2c\\,\\sigma_{\\text{in}}/2^{B}$, where $\\sigma_{\\text{in}}$ is the standard deviation of the quantizer's input signal.\nSubstituting $\\Delta$ into the expression for $\\sigma_{q}^{2}$:\n$$\\sigma_{q}^{2} = \\frac{(2c\\,\\sigma_{\\text{in}}/2^{B})^{2}}{12} = \\frac{4c^{2}\\sigma_{\\text{in}}^{2}}{12 \\cdot 2^{2B}} = \\frac{c^{2}}{3} \\sigma_{\\text{in}}^{2} 2^{-2B}$$\nThis equation links the bit rate $B$ to the variance of the quantization error and the variance of the signal being quantized.\n\n**System (i): Direct Scalar Quantization (SQ)**\nIn this system, the signal $x[n]$ is directly quantized. The input to the quantizer is $x[n]$, so the input variance is $\\sigma_{\\text{in}}^{2} = \\sigma_{x}^{2}$. We must find the variance of the source $x[n]$. From the AR($1$) model, for a wide-sense stationary process:\n$$\\sigma_{x}^{2} = \\mathbb{E}[x[n]^{2}] = \\mathbb{E}[(a\\,x[n-1] + w[n])^{2}] = a^{2}\\mathbb{E}[x[n-1]^{2}] + \\sigma_{w}^{2} = a^{2}\\sigma_{x}^{2} + \\sigma_{w}^{2}$$\nwhere we used the fact that $w[n]$ is uncorrelated with past samples $x[n-1]$. Solving for $\\sigma_{x}^{2}$:\n$$\\sigma_{x}^{2}(1-a^{2}) = \\sigma_{w}^{2} \\implies \\sigma_{x}^{2} = \\frac{\\sigma_{w}^{2}}{1-a^{2}}$$\nThe reconstructed signal is $\\hat{x}_{\\text{dir}}[n] = x[n] + q_{\\text{dir}}[n]$. The end-to-end distortion is $D_{\\text{dir}} = \\mathbb{E}[(x[n] - \\hat{x}_{\\text{dir}}[n])^{2}] = \\mathbb{E}[(-q_{\\text{dir}}[n])^{2}] = \\sigma_{q,\\text{dir}}^{2}$.\nFor a target distortion $D$, we set $D_{\\text{dir}} = D$. Using the rate-distortion formula for the quantizer with $\\sigma_{\\text{in}}^{2} = \\sigma_{x}^{2}$:\n$$D = \\frac{c^{2}}{3} \\sigma_{x}^{2} 2^{-2B_{\\text{dir}}} = \\frac{c^{2}}{3} \\left(\\frac{\\sigma_{w}^{2}}{1-a^{2}}\\right) 2^{-2B_{\\text{dir}}}$$\nSolving for $2^{2B_{\\text{dir}}}$:\n$$2^{2B_{\\text{dir}}} = \\frac{c^{2}\\sigma_{w}^{2}}{3D(1-a^{2})}$$\n\n**System (ii): Differential Pulse-Code Modulation (DPCM)**\nThe DPCM system uses a predictor based on the whitening filter, with coefficient $a$. The loop equations are:\nEncoder residual: $u[n] = x[n] - a\\,\\hat{x}[n-1]$\nQuantized residual: $\\hat{u}[n] = u[n] + q_{\\text{dpcm}}[n]$\nDecoder reconstruction: $\\hat{x}[n] = \\hat{u}[n] + a\\,\\hat{x}[n-1]$\nThe end-to-end error is $e[n] = x[n] - \\hat{x}[n]$. Let's derive its expression:\n$$e[n] = x[n] - (\\hat{u}[n] + a\\,\\hat{x}[n-1]) = x[n] - (u[n] + q_{\\text{dpcm}}[n] + a\\,\\hat{x}[n-1])$$\nSubstituting $u[n]$:\n$$e[n] = x[n] - ((x[n] - a\\,\\hat{x}[n-1]) + q_{\\text{dpcm}}[n] + a\\,\\hat{x}[n-1]) = x[n] - (x[n] + q_{\\text{dpcm}}[n]) = -q_{\\text{dpcm}}[n]$$\nThe distortion is thus $D_{\\text{dpcm}} = \\mathbb{E}[e[n]^{2}] = \\mathbb{E}[(-q_{\\text{dpcm}}[n])^{2}] = \\sigma_{q,\\text{dpcm}}^{2}$. For the target distortion $D$, we set $D_{\\text{dpcm}} = D$.\nThe quantizer's input is the residual signal $u[n]$. We must find its variance, $\\sigma_{u}^{2}$.\n$$u[n] = x[n] - a\\,\\hat{x}[n-1] = x[n] - a(x[n-1] - e[n-1]) = (x[n] - a\\,x[n-1]) + a\\,e[n-1]$$\nUsing the source model $x[n] - a\\,x[n-1] = w[n]$ and the error relation $e[n-1] = -q_{\\text{dpcm}}[n-1]$, we get:\n$$u[n] = w[n] - a\\,q_{\\text{dpcm}}[n-1]$$\nThe variance of the residual is:\n$$\\sigma_{u}^{2} = \\mathbb{E}[(w[n] - a\\,q_{\\text{dpcm}}[n-1])^{2}] = \\mathbb{E}[w[n]^{2}] - 2a\\mathbb{E}[w[n]q_{\\text{dpcm}}[n-1]] + a^{2}\\mathbb{E}[q_{\\text{dpcm}}[n-1]^{2}]$$\nThe innovation $w[n]$ is uncorrelated with past quantization noise $q_{\\text{dpcm}}[n-1]$. Thus, the cross-term is zero.\n$$\\sigma_{u}^{2} = \\sigma_{w}^{2} + a^{2}\\sigma_{q,\\text{dpcm}}^{2}$$\nSince the target distortion is $D = \\sigma_{q,\\text{dpcm}}^{2}$, the variance of the signal at the DPCM quantizer input is:\n$$\\sigma_{u}^{2} = \\sigma_{w}^{2} + a^{2}D$$\nNow we use the rate equation for the DPCM quantizer. The input variance is $\\sigma_{\\text{in}}^{2} = \\sigma_{u}^{2}$, and the quantization noise variance is $\\sigma_{q,\\text{dpcm}}^{2} = D$.\n$$D = \\frac{c^{2}}{3} \\sigma_{u}^{2} 2^{-2B_{\\text{dpcm}}} = \\frac{c^{2}}{3}(\\sigma_{w}^{2} + a^{2}D) 2^{-2B_{\\text{dpcm}}}$$\nSolving for $2^{2B_{\\text{dpcm}}}$:\n$$2^{2B_{\\text{dpcm}}} = \\frac{c^{2}(\\sigma_{w}^{2} + a^{2}D)}{3D}$$\n\n**Computation of Bit Rate Reduction $\\Delta B$**\nWe need to find $\\Delta B = B_{\\text{dir}} - B_{\\text{dpcm}}$. We can write this as $\\Delta B = \\frac{1}{2}(2B_{\\text{dir}} - 2B_{\\text{dpcm}})$. Using the logarithm base $2$:\n$$2B = \\log_{2}(2^{2B})$$\n$$2\\Delta B = 2B_{\\text{dir}} - 2B_{\\text{dpcm}} = \\log_{2}(2^{2B_{\\text{dir}}}) - \\log_{2}(2^{2B_{\\text{dpcm}}}) = \\log_{2}\\left(\\frac{2^{2B_{\\text{dir}}}}{2^{2B_{\\text{dpcm}}}}\\right)$$\nSubstitute the expressions derived for $2^{2B_{\\text{dir}}}$ and $2^{2B_{\\text{dpcm}}}$:\n$$2\\Delta B = \\log_{2}\\left( \\frac{\\frac{c^{2}\\sigma_{w}^{2}}{3D(1-a^{2})}}{\\frac{c^{2}(\\sigma_{w}^{2} + a^{2}D)}{3D}} \\right)$$\nThe terms $c^{2}$, $3$, and $D$ cancel out:\n$$2\\Delta B = \\log_{2}\\left( \\frac{\\sigma_{w}^{2}}{(1-a^{2})(\\sigma_{w}^{2} + a^{2}D)} \\right)$$\nFinally, the reduction in the required number of bits is:\n$$\\Delta B = \\frac{1}{2} \\log_{2}\\left( \\frac{\\sigma_{w}^{2}}{(1-a^{2})(\\sigma_{w}^{2} + a^{2}D)} \\right)$$\nThis expression provides the bit-rate savings of DPCM over direct SQ for the same target distortion $D$, as a function of the source parameters $a$ and $\\sigma_{w}^{2}$.", "answer": "$$\n\\boxed{\\frac{1}{2} \\log_{2}\\left( \\frac{\\sigma_{w}^{2}}{(1-a^{2})(\\sigma_{w}^{2} + a^{2}D)} \\right)}\n$$", "id": "2898103"}]}