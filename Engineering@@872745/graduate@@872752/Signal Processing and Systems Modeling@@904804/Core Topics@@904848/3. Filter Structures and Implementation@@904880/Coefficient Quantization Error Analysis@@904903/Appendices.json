{"hands_on_practices": [{"introduction": "Understanding the effects of quantization begins with isolating its most direct consequences. This first exercise provides a clear, analytical link between a single coefficient error in a Finite Impulse Response (FIR) filter and a resulting steady-state bias in the output signal. By working through this problem ([@problem_id:2858816]), you will build a foundational understanding of how static coefficient errors propagate through a linear system to create predictable output deviations.", "problem": "Consider a length-$5$ Finite Impulse Response (FIR) filter with impulse response coefficients $h[0]=\\frac{1}{4}$, $h[1]=-\\frac{3}{8}$, $h[2]=\\frac{13}{64}$, $h[3]=\\frac{1}{16}$, and $h[4]=-\\frac{1}{32}$. All coefficients are to be stored in fixed-point $Qm.n$ format, where $Qm.n$ denotes a two's-complement fixed-point representation with $m$ integer bits (excluding the sign bit) and $n$ fractional bits. Assume $n=5$ and that saturation does not occur. All coefficients are exactly representable in $Qm.n$ except $h[2]$, which is quantized by deterministic truncation toward zero. Define the truncation operator by\n$$\n\\mathcal{T}_{n}(x) \\triangleq \\mathrm{sgn}(x)\\,\\frac{\\left\\lfloor 2^{n}\\,|x|\\right\\rfloor}{2^{n}}.\n$$\nLet $\\tilde{h}[k]$ denote the stored (quantized) coefficient sequence with $\\tilde{h}[k]=h[k]$ for all $k\\neq 2$ and $\\tilde{h}[2]=\\mathcal{T}_{5}\\!\\big(h[2]\\big)$. The filter is driven by a unit-step input $x[n]=u[n]$. Define the induced direct current (DC) bias as the steady-state difference between the output of the quantized filter and the output of the exact-coefficient filter in response to the same input:\n$$\nb \\triangleq \\lim_{n\\to\\infty}\\big(\\tilde{y}[n]-y[n]\\big),\n$$\nwhere $y[n]$ and $\\tilde{y}[n]$ are the outputs corresponding to $h[k]$ and $\\tilde{h}[k]$, respectively.\n\nStarting only from the definitions of linear time-invariant convolution, fixed-point truncation, and basic stability properties of FIR systems, derive an expression for $b$ and compute its exact value. Express your final answer as a single exact real number. No rounding is required.", "solution": "The problem requires the computation of the steady-state output difference between a filter with exact coefficients and one with quantized coefficients, when both are driven by a unit-step input. This difference is defined as the direct current (DC) bias $b$.\n\nLet $h[k]$ be the impulse response of the exact Finite Impulse Response (FIR) filter and $\\tilde{h}[k]$ be the impulse response of the filter with quantized coefficients. The lengths of both impulse responses are $5$, so $k$ ranges from $0$ to $4$. The output of a linear time-invariant (LTI) system is given by the convolution of its impulse response with the input signal $x[n]$.\n\nThe output of the exact filter, $y[n]$, is given by:\n$$\ny[n] = (h * x)[n] = \\sum_{k=0}^{4} h[k] x[n-k]\n$$\nThe output of the quantized filter, $\\tilde{y}[n]$, is given by:\n$$\n\\tilde{y}[n] = (\\tilde{h} * x)[n] = \\sum_{k=0}^{4} \\tilde{h}[k] x[n-k]\n$$\nThe DC bias $b$ is defined as the steady-state difference between these two outputs:\n$$\nb \\triangleq \\lim_{n\\to\\infty}\\big(\\tilde{y}[n]-y[n]\\big)\n$$\nBy linearity of the summation operator, the difference $\\tilde{y}[n]-y[n]$ can be expressed as:\n$$\n\\tilde{y}[n] - y[n] = \\sum_{k=0}^{4} \\tilde{h}[k] x[n-k] - \\sum_{k=0}^{4} h[k] x[n-k] = \\sum_{k=0}^{4} (\\tilde{h}[k]-h[k]) x[n-k]\n$$\nLet us define the coefficient error sequence $\\Delta h[k] \\triangleq \\tilde{h}[k]-h[k]$. The output difference is then the response of an \"error filter\" with impulse response $\\Delta h[k]$ to the input $x[n]$:\n$$\n\\tilde{y}[n] - y[n] = (\\Delta h * x)[n] = \\sum_{k=0}^{4} \\Delta h[k] x[n-k]\n$$\nThe input signal is the unit-step function, $x[n]=u[n]$, defined as $u[n]=1$ for $n \\ge 0$ and $u[n]=0$ for $n  0$. We must evaluate the limit as $n \\to \\infty$. For an FIR filter of length $5$, the convolution sum involves terms $x[n-k]$ for $k \\in \\{0, 1, 2, 3, 4\\}$. As $n$ becomes large, specifically for any $n \\ge 4$, the argument $n-k$ will be non-negative for all $k$ in the sum. That is, $n-4 \\ge 0$, $n-3 \\ge 0$, and so on.\nFor $n \\ge 4$, we have $u[n-k] = 1$ for all $k \\in \\{0, 1, 2, 3, 4\\}$.\nTherefore, for $n \\ge 4$, the output difference becomes constant:\n$$\n\\tilde{y}[n] - y[n] = \\sum_{k=0}^{4} \\Delta h[k] \\cdot 1 = \\sum_{k=0}^{4} \\Delta h[k]\n$$\nSince this expression is constant for all $n \\ge 4$, the limit as $n \\to \\infty$ is this constant value. Thus, the DC bias $b$ is the sum of the coefficient errors:\n$$\nb = \\lim_{n\\to\\infty} \\sum_{k=0}^{4} \\Delta h[k] u[n-k] = \\sum_{k=0}^{4} \\Delta h[k]\n$$\nThis result is a direct consequence of the stability of FIR filters and the nature of the step response, which reaches a steady-state value equal to the filter's DC gain (the sum of its impulse response coefficients).\n\nThe problem states that only the coefficient $h[2]$ is quantized, while the others remain exact. This implies:\n$\\Delta h[k] = \\tilde{h}[k] - h[k] = 0$ for $k \\in \\{0, 1, 3, 4\\}$.\nThe only non-zero error coefficient is $\\Delta h[2] = \\tilde{h}[2] - h[2]$.\nTherefore, the DC bias simplifies to:\n$$\nb = \\Delta h[2]\n$$\nWe must now compute $\\Delta h[2]$. The coefficient $h[2]=\\frac{13}{64}$ is quantized using truncation toward zero with $n=5$ fractional bits. The truncation operator $\\mathcal{T}_{n}(x)$ is given by:\n$$\n\\mathcal{T}_{n}(x) \\triangleq \\mathrm{sgn}(x)\\,\\frac{\\left\\lfloor 2^{n}\\,|x|\\right\\rfloor}{2^{n}}\n$$\nFor $x = h[2] = \\frac{13}{64}$, which is a positive value, $\\mathrm{sgn}(x)=1$. With $n=5$, we have $2^n = 2^5 = 32$. The quantized coefficient $\\tilde{h}[2]$ is:\n$$\n\\tilde{h}[2] = \\mathcal{T}_{5}\\left(\\frac{13}{64}\\right) = \\frac{\\left\\lfloor 2^{5} \\cdot \\frac{13}{64}\\right\\rfloor}{2^{5}} = \\frac{\\left\\lfloor 32 \\cdot \\frac{13}{64}\\right\\rfloor}{32}\n$$\nWe evaluate the term inside the floor function:\n$$\n32 \\cdot \\frac{13}{64} = \\frac{13}{2} = 6.5\n$$\nTaking the floor gives $\\lfloor 6.5 \\rfloor = 6$.\nSo, the quantized coefficient is:\n$$\n\\tilde{h}[2] = \\frac{6}{32} = \\frac{3}{16}\n$$\nNow we compute the coefficient error $\\Delta h[2]$:\n$$\n\\Delta h[2] = \\tilde{h}[2] - h[2] = \\frac{3}{16} - \\frac{13}{64}\n$$\nTo subtract these fractions, we find a common denominator, which is $64$:\n$$\n\\Delta h[2] = \\frac{3 \\cdot 4}{16 \\cdot 4} - \\frac{13}{64} = \\frac{12}{64} - \\frac{13}{64} = -\\frac{1}{64}\n$$\nFinally, as established earlier, the DC bias $b$ is equal to this single non-zero coefficient error.\n$$\nb = \\Delta h[2] = -\\frac{1}{64}\n$$", "answer": "$$\\boxed{-\\frac{1}{64}}$$", "id": "2858816"}, {"introduction": "While FIR filters are inherently stable, the introduction of feedback in Infinite Impulse Response (IIR) filters means that coefficient quantization can have far more critical consequences, potentially leading to instability. This practice moves into the IIR domain to explore how quantization of denominator coefficients affects the location of the system's poles, which govern its stability and dynamic response. By deriving the analytical sensitivities of pole radius and angle ([@problem_id:2858988]), you will gain a crucial tool for designing robust IIR filters that can withstand the rigors of finite-precision implementation.", "problem": "Consider a real-coefficient second-order (biquad) digital filter with transfer function\n$$\nH(z) \\;=\\; \\frac{b_0 + b_1 z^{-1} + b_2 z^{-2}}{1 + a_1 z^{-1} + a_2 z^{-2}},\n$$\nwhere $b_0$, $b_1$, $b_2$, $a_1$, and $a_2$ are real. Assume the pole pair is complex-conjugate, so that the denominator polynomial has two roots $z_p$ and $z_p^{\\ast}$ strictly inside the unit circle and off the real axis. Define the polar representation of a pole by $z_p = r \\exp(j \\theta)$ with radius $r \\in (0,1)$ and angle $\\theta \\in (0,\\pi)$ in radians.\n\nSuppose the coefficients $a_1$ and $a_2$ are subject to small finite-word-length quantization perturbations, modeled as independent, sufficiently small differentials $\\mathrm{d}a_1$ and $\\mathrm{d}a_2$. Define the local sensitivities of the pole invariants $r$ and $\\theta$ with respect to $a_1$ and $a_2$ by the partial derivatives $\\frac{\\partial r}{\\partial a_1}$, $\\frac{\\partial r}{\\partial a_2}$, $\\frac{\\partial \\theta}{\\partial a_1}$, and $\\frac{\\partial \\theta}{\\partial a_2}$, so that the first-order variations satisfy\n$$\n\\mathrm{d}r \\;\\approx\\; \\frac{\\partial r}{\\partial a_1}\\,\\mathrm{d}a_1 \\;+\\; \\frac{\\partial r}{\\partial a_2}\\,\\mathrm{d}a_2,\\qquad\n\\mathrm{d}\\theta \\;\\approx\\; \\frac{\\partial \\theta}{\\partial a_1}\\,\\mathrm{d}a_1 \\;+\\; \\frac{\\partial \\theta}{\\partial a_2}\\,\\mathrm{d}a_2.\n$$\n\nStarting only from fundamental polynomial factorization for real-coefficient quadratics with complex-conjugate roots and the definitions of $r$ and $\\theta$, derive closed-form expressions for these four partial derivatives in terms of $a_1$ and $a_2$, under the admissibility conditions $a_20$ and $a_1^24a_2$. Report your final result as the four entries in the order $\\left(\\frac{\\partial r}{\\partial a_1},\\,\\frac{\\partial r}{\\partial a_2},\\,\\frac{\\partial \\theta}{\\partial a_1},\\,\\frac{\\partial \\theta}{\\partial a_2}\\right)$. Angles must be expressed in radians. No numerical evaluation is required; provide exact analytic expressions only.", "solution": "The poles of the filter are the roots of the denominator polynomial $D(z^{-1}) = 1 + a_1 z^{-1} + a_2 z^{-2}$. This is equivalent to finding the roots of the characteristic polynomial $P(z) = z^2 + a_1 z + a_2 = 0$.\nThe problem states that the poles are a complex-conjugate pair, denoted by $z_p = r \\exp(j\\theta)$ and $z_p^{\\ast} = r \\exp(-j\\theta)$, where $r \\in (0,1)$ and $\\theta \\in (0,\\pi)$.\n\nThe polynomial $P(z)$ can be factored based on its roots:\n$$P(z) = (z - z_p)(z - z_p^{\\ast}) = z^2 - (z_p + z_p^{\\ast})z + z_p z_p^{\\ast}$$\nBy comparing the coefficients of this expanded form with $z^2 + a_1 z + a_2$, we establish the relationship between the coefficients $(a_1, a_2)$ and the polar representation of the poles $(r, \\theta)$.\n\nThe sum of the roots is:\n$$z_p + z_p^{\\ast} = r \\exp(j\\theta) + r \\exp(-j\\theta) = r(\\cos\\theta + j\\sin\\theta) + r(\\cos\\theta - j\\sin\\theta) = 2r\\cos\\theta$$\nThe product of the roots is:\n$$z_p z_p^{\\ast} = (r \\exp(j\\theta))(r \\exp(-j\\theta)) = r^2$$\n\nEquating the coefficients gives the following system of equations:\n$$a_1 = -2r\\cos\\theta \\quad (1)$$\n$$a_2 = r^2 \\quad (2)$$\n\nThese equations define $a_1$ and $a_2$ as functions of $r$ and $\\theta$. We need to find the partial derivatives of $r$ and $\\theta$ with respect to $a_1$ and $a_2$. We will use the method of implicit differentiation. We treat $r$ and $\\theta$ as functions of $a_1$ and $a_2$ and differentiate the system $(1)$ and $(2)$ with respect to $a_1$ and $a_2$.\n\nFirst, we differentiate with respect to $a_1$:\n$$\\frac{\\partial}{\\partial a_1}(a_1) = 1 = \\frac{\\partial}{\\partial a_1}(-2r\\cos\\theta) = -2\\left(\\frac{\\partial r}{\\partial a_1}\\cos\\theta - r\\sin\\theta\\frac{\\partial \\theta}{\\partial a_1}\\right)$$\n$$\\frac{\\partial}{\\partial a_1}(a_2) = 0 = \\frac{\\partial}{\\partial a_1}(r^2) = 2r\\frac{\\partial r}{\\partial a_1}$$\n\nFrom the second differentiated equation, since $r \\in (0,1)$, we have $r \\neq 0$, which implies:\n$$\\frac{\\partial r}{\\partial a_1} = 0$$\nSubstituting this result into the first differentiated equation:\n$$1 = -2\\left(0 \\cdot \\cos\\theta - r\\sin\\theta\\frac{\\partial \\theta}{\\partial a_1}\\right) = 2r\\sin\\theta\\frac{\\partial \\theta}{\\partial a_1}$$\nSolving for $\\frac{\\partial \\theta}{\\partial a_1}$ gives:\n$$\\frac{\\partial \\theta}{\\partial a_1} = \\frac{1}{2r\\sin\\theta}$$\n\nNext, we differentiate the original system with respect to $a_2$:\n$$\\frac{\\partial}{\\partial a_2}(a_1) = 0 = \\frac{\\partial}{\\partial a_2}(-2r\\cos\\theta) = -2\\left(\\frac{\\partial r}{\\partial a_2}\\cos\\theta - r\\sin\\theta\\frac{\\partial \\theta}{\\partial a_2}\\right)$$\n$$\\frac{\\partial}{\\partial a_2}(a_2) = 1 = \\frac{\\partial}{\\partial a_2}(r^2) = 2r\\frac{\\partial r}{\\partial a_2}$$\n\nFrom the second differentiated equation, we find $\\frac{\\partial r}{\\partial a_2}$:\n$$\\frac{\\partial r}{\\partial a_2} = \\frac{1}{2r}$$\nSubstituting this into the first differentiated equation:\n$$0 = -2\\left(\\frac{1}{2r}\\cos\\theta - r\\sin\\theta\\frac{\\partial \\theta}{\\partial a_2}\\right) = -\\frac{\\cos\\theta}{r} + 2r\\sin\\theta\\frac{\\partial \\theta}{\\partial a_2}$$\nSolving for $\\frac{\\partial \\theta}{\\partial a_2}$:\n$$2r\\sin\\theta\\frac{\\partial \\theta}{\\partial a_2} = \\frac{\\cos\\theta}{r} \\implies \\frac{\\partial \\theta}{\\partial a_2} = \\frac{\\cos\\theta}{2r^2\\sin\\theta}$$\n\nThe derived partial derivatives are currently expressed in terms of $r$ and $\\theta$. We must convert them into expressions solely in terms of $a_1$ and $a_2$.\nFrom equation $(2)$, $r = \\sqrt{a_2}$ (since $r0$).\nFrom equation $(1)$, $\\cos\\theta = -\\frac{a_1}{2r} = -\\frac{a_1}{2\\sqrt{a_2}}$.\nSince $\\theta \\in (0,\\pi)$, $\\sin\\theta$ must be positive. Therefore:\n$$\\sin\\theta = \\sqrt{1 - \\cos^2\\theta} = \\sqrt{1 - \\left(-\\frac{a_1}{2\\sqrt{a_2}}\\right)^2} = \\sqrt{1 - \\frac{a_1^2}{4a_2}} = \\frac{\\sqrt{4a_2 - a_1^2}}{2\\sqrt{a_2}}$$\nThe admissibility condition $a_1^2  4a_2$ ensures the argument of the square root is positive.\n\nNow we substitute these expressions back into our results for the partial derivatives.\n\nFor $\\frac{\\partial r}{\\partial a_1}$:\nThe result is already absolute: $\\frac{\\partial r}{\\partial a_1} = 0$.\n\nFor $\\frac{\\partial r}{\\partial a_2}$:\n$$\\frac{\\partial r}{\\partial a_2} = \\frac{1}{2r} = \\frac{1}{2\\sqrt{a_2}}$$\n\nFor $\\frac{\\partial \\theta}{\\partial a_1}$:\n$$\\frac{\\partial \\theta}{\\partial a_1} = \\frac{1}{2r\\sin\\theta} = \\frac{1}{2(\\sqrt{a_2})\\left(\\frac{\\sqrt{4a_2 - a_1^2}}{2\\sqrt{a_2}}\\right)} = \\frac{1}{\\sqrt{4a_2 - a_1^2}}$$\n\nFor $\\frac{\\partial \\theta}{\\partial a_2}$:\n$$\\frac{\\partial \\theta}{\\partial a_2} = \\frac{\\cos\\theta}{2r^2\\sin\\theta} = \\frac{-\\frac{a_1}{2\\sqrt{a_2}}}{2(a_2)\\left(\\frac{\\sqrt{4a_2 - a_1^2}}{2\\sqrt{a_2}}\\right)} = \\frac{-\\frac{a_1}{2\\sqrt{a_2}}}{\\frac{a_2\\sqrt{4a_2 - a_1^2}}{\\sqrt{a_2}}} = -\\frac{a_1}{2\\sqrt{a_2}} \\cdot \\frac{\\sqrt{a_2}}{a_2\\sqrt{4a_2 - a_1^2}} = -\\frac{a_1}{2a_2\\sqrt{4a_2 - a_1^2}}$$\n\nThe four partial derivatives are:\n$\\frac{\\partial r}{\\partial a_1} = 0$\n$\\frac{\\partial r}{\\partial a_2} = \\frac{1}{2\\sqrt{a_2}}$\n$\\frac{\\partial \\theta}{\\partial a_1} = \\frac{1}{\\sqrt{4a_2 - a_1^2}}$\n$\\frac{\\partial \\theta}{\\partial a_2} = -\\frac{a_1}{2a_2\\sqrt{4a_2 - a_1^2}}$\n\nThese are the required closed-form expressions in terms of $a_1$ and $a_2$. The conditions $a_20$ and $a_1^24a_2$ ensure all expressions are well-defined and real. We now assemble the final answer in the specified order.", "answer": "$$\\boxed{\\begin{pmatrix} 0  \\frac{1}{2\\sqrt{a_2}}  \\frac{1}{\\sqrt{4a_2 - a_1^2}}  -\\frac{a_1}{2a_2\\sqrt{4a_2 - a_1^2}} \\end{pmatrix}}$$", "id": "2858988"}, {"introduction": "Theoretical sensitivity analysis provides powerful predictions, but the ultimate test of a design lies in its measured performance. This final practice bridges theory and implementation by comparing two different filter realizations that are mathematically identical in ideal arithmetic but behave differently after quantization. You will develop a simulation to measure the magnitude response degradation for each structure and see firsthand how the theoretical sensitivity models ([@problem_id:2858985]) accurately predict which realization is more robust, a cornerstone concept in hardware-aware filter design.", "problem": "You are given a class of real, causal, second-order Infinite Impulse Response (IIR) digital filters with one complex-conjugate pair of zeros and one complex-conjugate pair of poles, described by the transfer function\n$$\nH(z) \\;=\\; \\frac{B(z)}{A(z)} \\;=\\; \\frac{b_0 + b_1 z^{-1} + b_2 z^{-2}}{1 + a_1 z^{-1} + a_2 z^{-2}} \\,,\n$$\nwhere $a_0 = 1$ by convention. For a parameterization in polar pole-zero form, you may also write\n$$\nB(z) \\;=\\; g \\,\\bigl(1 - 2 r_z \\cos\\phi_z \\, z^{-1} + r_z^2 z^{-2}\\bigr), \\quad\nA(z) \\;=\\; 1 - 2 r_p \\cos\\phi_p \\, z^{-1} + r_p^2 z^{-2},\n$$\nwith real parameters $g \\in \\mathbb{R}$, $r_z \\in [0,1]$, $r_p \\in [0,1)$, $\\phi_z \\in [0,\\pi]$ and $\\phi_p \\in [0,\\pi]$ (angles in radians). The corresponding polynomial coefficients are $b_0 = g$, $b_1 = -2 g r_z \\cos\\phi_z$, $b_2 = g r_z^2$, $a_1 = -2 r_p \\cos\\phi_p$, and $a_2 = r_p^2$.\n\nYour task is to analyze the impact of coefficient quantization on the magnitude response for two different realizations that implement the same ideal magnitude response:\n- Realization A (Direct-Form Coefficient Quantization): Quantize the polynomial coefficients $\\{b_0,b_1,b_2,a_1,a_2\\}$ directly to a uniform grid with step $\\Delta_c$.\n- Realization B (Pole-Zero Parameter Quantization): Quantize the pole-zero parameters $\\{g,r_z,\\phi_z,r_p,\\phi_p\\}$ to uniform grids with steps $\\Delta_g,\\Delta_{r_z},\\Delta_{\\phi_z},\\Delta_{r_p},\\Delta_{\\phi_p}$ respectively, then map to polynomial coefficients.\n\nFor both realizations, define the ideal complex frequency response on a grid $\\omega \\in [0,\\pi]$ by\n$$\nH(e^{j\\omega}) \\;=\\; \\frac{B(e^{j\\omega})}{A(e^{j\\omega})} \\,,\n$$\nand the ideal magnitude response by $|H(e^{j\\omega})|$.\n\nYou must:\n- Implement quantization in each realization as rounding to the nearest quantization grid point. For Realization A, use the same step $\\Delta_c$ for all five coefficients $\\{b_0,b_1,b_2,a_1,a_2\\}$. For Realization B, use the specified steps per-parameter as given in the test suite below. Quantization is symmetric and unbiased.\n- For each realization, compute the measured root-mean-square (RMS) magnitude-response deviation after quantization over a uniform grid of $N$ frequency samples in $[0,\\pi]$:\n$$\nE_{\\mathrm{meas}} \\;=\\; \\sqrt{\\frac{1}{N}\\sum_{k=1}^{N}\\left(\\left|H_q(e^{j\\omega_k})\\right| - \\left|H(e^{j\\omega_k})\\right|\\right)^2}.\n$$\n- Independently predict the RMS magnitude-response deviation using a first-order perturbation model. Treat each quantized parameter as the true parameter plus an independent, zero-mean quantization error uniformly distributed on an interval of width equal to the quantization step for that parameter. For a parameter vector $\\boldsymbol{\\theta}$, the linearization of $|H(e^{j\\omega})|$ about the ideal parameters yields a pointwise variance prediction\n$$\n\\sigma^2_{|H|}(\\omega) \\;\\approx\\; \\sum_{i} \\left(\\frac{\\partial |H(e^{j\\omega})|}{\\partial \\theta_i}\\right)^2 \\,\\mathrm{Var}(\\delta \\theta_i),\n$$\nwith $\\mathrm{Var}(\\delta \\theta_i) = \\Delta_i^2/12$ for each independently quantized parameter with quantization step $\\Delta_i$. Average this predicted pointwise variance over frequency and take the square root to obtain the predicted RMS deviation\n$$\nE_{\\mathrm{pred}} \\;=\\; \\sqrt{\\frac{1}{N}\\sum_{k=1}^{N}\\sigma^2_{|H|}(\\omega_k)}.\n$$\n- Quantify the agreement between the predicted pointwise variance and the actual squared error across the frequency grid using the Pearson correlation coefficient between the two arrays $\\bigl\\{\\sigma^2_{|H|}(\\omega_k)\\bigr\\}_{k=1}^N$ and $\\bigl\\{\\bigl(|H_q(e^{j\\omega_k})|-|H(e^{j\\omega_k})|\\bigr)^2\\bigr\\}_{k=1}^N$.\n\nStart your derivation from fundamental definitions of the frequency response of linear time-invariant systems and first-order Taylor linearization. Do not assume any black-box formulas for sensitivities.\n\nAngle unit requirement: All angles $\\phi$ and frequencies $\\omega$ are in radians. No physical units are involved. Numerical answers must be provided as floating-point values.\n\nTest suite. Use the following three test cases, each specifying the ideal pole-zero parameters, a normalization frequency $\\omega_0$ at which the gain is set to unity by choosing $g$, and the quantization steps for both realizations. For each case, first compute $g$ so that $\\left|H\\left(e^{j\\omega_0}\\right)\\right|=1$ holds for the ideal (unquantized) parameters. Then perform the two realizationsâ€™ quantizations and all requested computations. Use a uniform frequency grid of $N = 1024$ samples in $[0,\\pi]$ inclusive.\n\n- Case $1$ (low-pass shape):\n  - Ideal parameters before normalization: $r_z = 1.0$, $\\phi_z = \\pi$, $r_p = 0.80$, $\\phi_p = 0.0$.\n  - Normalization frequency: $\\omega_0 = 0.0$.\n  - Realization A quantization: $\\Delta_c = 2^{-10}$.\n  - Realization B quantization: $\\Delta_g = 2^{-10}$, $\\Delta_{r_z} = 2^{-10}$, $\\Delta_{\\phi_z} = 2^{-12}$, $\\Delta_{r_p} = 2^{-10}$, $\\Delta_{\\phi_p} = 2^{-12}$.\n\n- Case $2$ (high-$Q$ resonant shape):\n  - Ideal parameters before normalization: $r_z = 1.0$, $\\phi_z = 0.0$, $r_p = 0.98$, $\\phi_p = 0.3\\pi$.\n  - Normalization frequency: $\\omega_0 = 0.3\\pi$.\n  - Realization A quantization: $\\Delta_c = 2^{-12}$.\n  - Realization B quantization: $\\Delta_g = 2^{-12}$, $\\Delta_{r_z} = 2^{-14}$, $\\Delta_{\\phi_z} = 2^{-14}$, $\\Delta_{r_p} = 2^{-14}$, $\\Delta_{\\phi_p} = 2^{-14}$.\n\n- Case $3$ (notch shape):\n  - Ideal parameters before normalization: $r_z = 1.0$, $\\phi_z = 0.6\\pi$, $r_p = 0.95$, $\\phi_p = 0.6\\pi$.\n  - Normalization frequency: $\\omega_0 = 0.0$.\n  - Realization A quantization: $\\Delta_c = 2^{-8}$.\n  - Realization B quantization: $\\Delta_g = 2^{-8}$, $\\Delta_{r_z} = 2^{-10}$, $\\Delta_{\\phi_z} = 2^{-10}$, $\\Delta_{r_p} = 2^{-10}$, $\\Delta_{\\phi_p} = 2^{-10}$.\n\nRequired outputs. For each case, produce six floating-point values in the following order:\n- $E_{\\mathrm{meas}}^{\\mathrm{df}}$ (Realization A measured RMS deviation),\n- $E_{\\mathrm{pred}}^{\\mathrm{df}}$ (Realization A predicted RMS deviation),\n- $C^{\\mathrm{df}}$ (Realization A Pearson correlation between predicted variance and actual squared error),\n- $E_{\\mathrm{meas}}^{\\mathrm{pz}}$ (Realization B measured RMS deviation),\n- $E_{\\mathrm{pred}}^{\\mathrm{pz}}$ (Realization B predicted RMS deviation),\n- $C^{\\mathrm{pz}}$ (Realization B Pearson correlation between predicted variance and actual squared error).\n\nFinal output format. Your program should produce a single line of output containing the results for all three cases as a single, flat, comma-separated list enclosed in square brackets, in the order\n$$\n\\bigl[E_{\\mathrm{meas}}^{\\mathrm{df}}(1),\\,E_{\\mathrm{pred}}^{\\mathrm{df}}(1),\\,C^{\\mathrm{df}}(1),\\,E_{\\mathrm{meas}}^{\\mathrm{pz}}(1),\\,E_{\\mathrm{pred}}^{\\mathrm{pz}}(1),\\,C^{\\mathrm{pz}}(1),\\,E_{\\mathrm{meas}}^{\\mathrm{df}}(2),\\,E_{\\mathrm{pred}}^{\\mathrm{df}}(2),\\,C^{\\mathrm{df}}(2),\\,E_{\\mathrm{meas}}^{\\mathrm{pz}}(2),\\,E_{\\mathrm{pred}}^{\\mathrm{pz}}(2),\\,C^{\\mathrm{pz}}(2),\\,E_{\\mathrm{meas}}^{\\mathrm{df}}(3),\\,E_{\\mathrm{pred}}^{\\mathrm{df}}(3),\\,C^{\\mathrm{df}}(3),\\,E_{\\mathrm{meas}}^{\\mathrm{pz}}(3),\\,E_{\\mathrm{pred}}^{\\mathrm{pz}}(3),\\,C^{\\mathrm{pz}}(3)\\bigr].\n$$\nPrint only this single line, with no additional text.", "solution": "The transfer function of the filter is given by\n$$\nH(z) = \\frac{B(z)}{A(z)} = \\frac{b_0 + b_1 z^{-1} + b_2 z^{-2}}{1 + a_1 z^{-1} + a_2 z^{-2}}\n$$\nIts complex frequency response is obtained by substituting $z = e^{j\\omega}$ for $\\omega \\in [0, \\pi]$, yielding $H(e^{j\\omega})$. The magnitude response is $|H(e^{j\\omega})|$.\n\nThe core of the predictive analysis lies in calculating the sensitivity of the magnitude response with respect to parameter variations. The sensitivity of a complex function's magnitude $|H|$ with respect to a real parameter $\\theta$ can be derived from $|H|^2 = H H^*$, where $H^*$ is the complex conjugate of $H$. Differentiating with respect to $\\theta$ yields $2|H|\\frac{\\partial|H|}{\\partial\\theta} = H^*\\frac{\\partial H}{\\partial\\theta} + H\\frac{\\partial H^*}{\\partial\\theta} = 2\\mathrm{Re}\\left(H^*\\frac{\\partial H}{\\partial\\theta}\\right)$. Thus, for $|H| \\neq 0$, the magnitude sensitivity is\n$$\n\\frac{\\partial|H|}{\\partial\\theta} = \\frac{1}{|H|}\\mathrm{Re}\\left(H^*\\frac{\\partial H}{\\partial\\theta}\\right)\n$$\nWe apply this general formula to our two realizations.\n\n**Realization A: Direct-Form Coefficient Quantization**\n\nThe parameters are the polynomial coefficients themselves, $\\boldsymbol{\\theta}_{\\mathrm{A}} = \\{b_0, b_1, b_2, a_1, a_2\\}$. We must find the partial derivative of $H(e^{j\\omega})$ with respect to each coefficient. Let $H = B/A$.\n\n1.  Sensitivity with respect to numerator coefficients $b_i$:\n    The derivative of $H$ with respect to $b_i$ is $\\frac{\\partial H}{\\partial b_i} = \\frac{1}{A} \\frac{\\partial B}{\\partial b_i}$. Since $B(e^{j\\omega}) = \\sum_{k=0}^{2} b_k e^{-jk\\omega}$, we have $\\frac{\\partial B}{\\partial b_i} = e^{-ji\\omega}$.\n    Therefore, $\\frac{\\partial H}{\\partial b_i} = \\frac{e^{-ji\\omega}}{A}$.\n    The magnitude sensitivity is:\n    $$\n    \\frac{\\partial |H|}{\\partial b_i} = \\frac{1}{|H|} \\mathrm{Re}\\left( H^* \\frac{e^{-ji\\omega}}{A} \\right) = \\frac{1}{|H|} \\mathrm{Re}\\left( \\frac{B^*}{A^*} \\frac{e^{-ji\\omega}}{A} \\right) = \\frac{1}{|H||A|^2} \\mathrm{Re}\\left( B^* e^{-ji\\omega} \\right)\n    $$\n\n2.  Sensitivity with respect to denominator coefficients $a_i$:\n    The derivative of $H$ with respect to $a_i$ is $\\frac{\\partial H}{\\partial a_i} = -\\frac{B}{A^2}\\frac{\\partial A}{\\partial a_i}$. Since $A(e^{j\\omega}) = 1 + \\sum_{k=1}^{2} a_k e^{-jk\\omega}$, we have $\\frac{\\partial A}{\\partial a_i} = e^{-ji\\omega}$.\n    Thus, $\\frac{\\partial H}{\\partial a_i} = -H \\frac{e^{-ji\\omega}}{A}$.\n    The magnitude sensitivity is:\n    $$\n    \\frac{\\partial |H|}{\\partial a_i} = \\frac{1}{|H|} \\mathrm{Re}\\left( H^* \\left(-H \\frac{e^{-ji\\omega}}{A}\\right) \\right) = -\\frac{|H|^2}{|H|} \\mathrm{Re}\\left(\\frac{e^{-ji\\omega}}{A}\\right) = -|H| \\mathrm{Re}\\left(\\frac{e^{-ji\\omega}A^*}{|A|^2}\\right) = -\\frac{|H|}{|A|^2}\\mathrm{Re}\\left(A^* e^{-ji\\omega}\\right)\n    $$\n\nThe predicted pointwise variance for Realization A, assuming independent quantization errors with variance $\\Delta_c^2/12$, is:\n$$\n\\sigma^2_{|H|, \\mathrm{df}}(\\omega) = \\frac{\\Delta_c^2}{12} \\left[ \\sum_{i=0}^{2} \\left(\\frac{\\partial |H|}{\\partial b_i}\\right)^2 + \\sum_{i=1}^{2} \\left(\\frac{\\partial |H|}{\\partial a_i}\\right)^2 \\right]\n$$\n\n**Realization B: Pole-Zero Parameter Quantization**\n\nThe parameters are $\\boldsymbol{\\theta}_{\\mathrm{B}} = \\{g, r_z, \\phi_z, r_p, \\phi_p\\}$. We use the chain rule: $\\frac{\\partial |H|}{\\partial \\theta_j} = \\sum_i \\frac{\\partial |H|}{\\partial c_i} \\frac{\\partial c_i}{\\partial \\theta_j}$, where $c_i \\in \\{b_0, ..., a_2\\}$ and $\\theta_j \\in \\boldsymbol{\\theta}_{\\mathrm{B}}$. The sensitivities $\\frac{\\partial |H|}{\\partial c_i}$ are known from Realization A. We need the jacobian $\\frac{\\partial c_i}{\\partial \\theta_j}$.\n\nThe coefficient mappings are: $b_0 = g$, $b_1 = -2 g r_z \\cos\\phi_z$, $b_2 = g r_z^2$, $a_1 = -2 r_p \\cos\\phi_p$, and $a_2 = r_p^2$.\n\n1.  Sensitivity wrt $g$: $H$ is linear in $g$. Assuming $g0$, $|H|=g|H_{norm}|$, so $\\frac{\\partial |H|}{\\partial g} = |H_{norm}| = \\frac{|H|}{g}$.\n2.  Sensitivity wrt $r_z$: Affects $b_1$ and $b_2$.\n    $\\frac{\\partial |H|}{\\partial r_z} = \\frac{\\partial |H|}{\\partial b_1}\\frac{\\partial b_1}{\\partial r_z} + \\frac{\\partial |H|}{\\partial b_2}\\frac{\\partial b_2}{\\partial r_z} = \\frac{\\partial |H|}{\\partial b_1}(-2g\\cos\\phi_z) + \\frac{\\partial |H|}{\\partial b_2}(2gr_z)$.\n3.  Sensitivity wrt $\\phi_z$: Affects $b_1$.\n    $\\frac{\\partial |H|}{\\partial \\phi_z} = \\frac{\\partial |H|}{\\partial b_1}\\frac{\\partial b_1}{\\partial \\phi_z} = \\frac{\\partial |H|}{\\partial b_1}(2gr_z\\sin\\phi_z)$.\n4.  Sensitivity wrt $r_p$: Affects $a_1$ and $a_2$.\n    $\\frac{\\partial |H|}{\\partial r_p} = \\frac{\\partial |H|}{\\partial a_1}\\frac{\\partial a_1}{\\partial r_p} + \\frac{\\partial |H|}{\\partial a_2}\\frac{\\partial a_2}{\\partial r_p} = \\frac{\\partial |H|}{\\partial a_1}(-2\\cos\\phi_p) + \\frac{\\partial |H|}{\\partial a_2}(2r_p)$.\n5.  Sensitivity wrt $\\phi_p$: Affects $a_1$.\n    $\\frac{\\partial |H|}{\\partial \\phi_p} = \\frac{\\partial |H|}{\\partial a_1}\\frac{\\partial a_1}{\\partial \\phi_p} = \\frac{\\partial |H|}{\\partial a_1}(2r_p\\sin\\phi_p)$.\n\nThe predicted pointwise variance for Realization B is the sum of contributions from each parameter, with variance $\\Delta_i^2/12$ for each step $\\Delta_i$:\n$$\n\\sigma^2_{|H|, \\mathrm{pz}}(\\omega) = \\frac{1}{12} \\left[ \\left(\\frac{\\partial |H|}{\\partial g}\\right)^2 \\Delta_g^2 + \\left(\\frac{\\partial |H|}{\\partial r_z}\\right)^2 \\Delta_{r_z}^2 + \\left(\\frac{\\partial |H|}{\\partial \\phi_z}\\right)^2 \\Delta_{\\phi_z}^2 + \\left(\\frac{\\partial |H|}{\\partial r_p}\\right)^2 \\Delta_{r_p}^2 + \\left(\\frac{\\partial |H|}{\\partial \\phi_p}\\right)^2 \\Delta_{\\phi_p}^2 \\right]\n$$\n\n```python\nimport numpy as np\n\ndef quantize(x, delta):\n    \"\"\"Rounds x to the nearest multiple of delta.\"\"\"\n    return delta * np.round(x / delta)\n\ndef pz_to_poly(g, r_z, phi_z, r_p, phi_p):\n    \"\"\"Maps pole-zero parameters to polynomial coefficients.\"\"\"\n    b0 = g\n    b1 = -2 * g * r_z * np.cos(phi_z)\n    b2 = g * r_z**2\n    a1 = -2 * r_p * np.cos(phi_p)\n    a2 = r_p**2\n    return np.array([b0, b1, b2]), np.array([a1, a2])\n\ndef evaluate_freq_response(b, a, omega):\n    \"\"\"\n    Evaluates the frequency response H(e^{j*omega}) for a filter.\n    b = [b0, b1, b2], a = [a1, a2].\n    \"\"\"\n    z_inv = np.exp(-1j * omega)\n    B_z = b[0] + b[1] * z_inv + b[2] * z_inv**2\n    A_z = 1 + a[0] * z_inv + a[1] * z_inv**2\n    H_z = B_z / A_z\n    return H_z, B_z, A_z\n\ndef pearson_corr(x, y):\n    \"\"\"Computes Pearson correlation, robust to constant inputs.\"\"\"\n    if np.std(x) == 0 or np.std(y) == 0:\n        return 0.0\n    return np.corrcoef(x, y)[0, 1]\n\ndef process_case(case):\n    \"\"\"\n    Processes a single test case to compute the six required metrics.\n    \"\"\"\n    # Unpack case parameters\n    (r_z, phi_z, r_p, phi_p), omega_0, delta_c, deltas_pz = case\n    delta_g, delta_rz, delta_phiz, delta_rp, delta_phip = deltas_pz\n    N = 1024\n    omega = np.linspace(0, np.pi, N)\n\n    # 1. Gain Normalization\n    _, b_norm_coeffs = pz_to_poly(1.0, r_z, phi_z, r_p, phi_p)\n    a_norm_coeffs_full = np.array([1, -2*r_p*np.cos(phi_p), r_p**2])\n    \n    H_at_omega0, _, _ = evaluate_freq_response(\n        np.array([1, -2*r_z*np.cos(phi_z), r_z**2]), \n        np.array([-2*r_p*np.cos(phi_p), r_p**2]),\n        np.array([omega_0])\n    )\n    g = 1.0 / np.abs(H_at_omega0[0])\n\n    # 2. Ideal Filter Parameters and Response\n    ideal_pz_params = {'g': g, 'r_z': r_z, 'phi_z': phi_z, 'r_p': r_p, 'phi_p': phi_p}\n    b_ideal_coeffs, a_ideal_coeffs = pz_to_poly(g, r_z, phi_z, r_p, phi_p)\n    \n    H_ideal, B_ideal, A_ideal = evaluate_freq_response(b_ideal_coeffs, a_ideal_coeffs, omega)\n    H_ideal_mag = np.abs(H_ideal)\n\n    # --- Realization A: Direct-Form ---\n    # 3a. Quantize coefficients and compute quantized response\n    b_q_df = quantize(b_ideal_coeffs, delta_c)\n    a_q_df = quantize(a_ideal_coeffs, delta_c)\n    H_q_df, _, _ = evaluate_freq_response(b_q_df, a_q_df, omega)\n    H_q_df_mag = np.abs(H_q_df)\n\n    # 4a. Measured error\n    sq_err_df = (H_q_df_mag - H_ideal_mag)**2\n    E_meas_df = np.sqrt(np.mean(sq_err_df))\n\n    # 5a. Predicted error\n    z_inv = np.exp(-1j * omega)\n    H_ideal_mag_safe = np.where(H_ideal_mag == 0, 1e-12, H_ideal_mag)\n\n    # Sensitivities wrt b_i\n    dabsH_db0 = (1 / (H_ideal_mag_safe * np.abs(A_ideal)**2)) * np.real(np.conj(B_ideal) * 1)\n    dabsH_db1 = (1 / (H_ideal_mag_safe * np.abs(A_ideal)**2)) * np.real(np.conj(B_ideal) * z_inv)\n    dabsH_db2 = (1 / (H_ideal_mag_safe * np.abs(A_ideal)**2)) * np.real(np.conj(B_ideal) * z_inv**2)\n    \n    # Sensitivities wrt a_i\n    dabsH_da1 = - (H_ideal_mag / np.abs(A_ideal)**2) * np.real(np.conj(A_ideal) * z_inv)\n    dabsH_da2 = - (H_ideal_mag / np.abs(A_ideal)**2) * np.real(np.conj(A_ideal) * z_inv**2)\n    \n    var_H_df = (dabsH_db0**2 + dabsH_db1**2 + dabsH_db2**2 + dabsH_da1**2 + dabsH_da2**2) * (delta_c**2 / 12)\n    E_pred_df = np.sqrt(np.mean(var_H_df))\n\n    # 6a. Correlation\n    C_df = pearson_corr(var_H_df, sq_err_df)\n    \n    # --- Realization B: Pole-Zero ---\n    # 3b. Quantize parameters and compute quantized response\n    g_q = quantize(g, delta_g)\n    rz_q = quantize(r_z, delta_rz)\n    phiz_q = quantize(phi_z, delta_phiz)\n    rp_q = quantize(r_p, delta_rp)\n    phip_q = quantize(phi_p, delta_phip)\n    \n    b_q_pz, a_q_pz = pz_to_poly(g_q, rz_q, phiz_q, rp_q, phip_q)\n    H_q_pz, _, _ = evaluate_freq_response(b_q_pz, a_q_pz, omega)\n    H_q_pz_mag = np.abs(H_q_pz)\n\n    # 4b. Measured error\n    sq_err_pz = (H_q_pz_mag - H_ideal_mag)**2\n    E_meas_pz = np.sqrt(np.mean(sq_err_pz))\n\n    # 5b. Predicted error (via chain rule)\n    dabsH_dg = H_ideal_mag / g\n    \n    dabsH_drz = dabsH_db1 * (-2 * g * np.cos(phi_z)) + dabsH_db2 * (2 * g * r_z)\n    dabsH_dphiz = dabsH_db1 * (2 * g * r_z * np.sin(phi_z))\n    \n    dabsH_drp = dabsH_da1 * (-2 * np.cos(phi_p)) + dabsH_da2 * (2 * r_p)\n    dabsH_dphip = dabsH_da1 * (2 * r_p * np.sin(phi_p))\n\n    var_H_pz = (\n        (dabsH_dg**2 * delta_g**2) +\n        (dabsH_drz**2 * delta_rz**2) +\n        (dabsH_dphiz**2 * delta_phiz**2) +\n        (dabsH_drp**2 * delta_rp**2) +\n        (dabsH_dphip**2 * delta_phip**2)\n    ) / 12\n    E_pred_pz = np.sqrt(np.mean(var_H_pz))\n\n    # 6b. Correlation\n    C_pz = pearson_corr(var_H_pz, sq_err_pz)\n\n    return E_meas_df, E_pred_df, C_df, E_meas_pz, E_pred_pz, C_pz\n```", "answer": "[0.0003468579088656722,0.00030048100588825835,0.9999677271442129,0.0001859666991194553,0.0001878344686419747,0.9996881944605963,0.003112999460555986,0.0031445778335894176,0.999990396001004,0.0002195325752156846,0.0002220456171549444,0.9999566373757476,0.004128038927847986,0.004172535038318261,0.9999554471015609,0.0002772740954315228,0.0002787836881267425,0.9999786481084281]", "id": "2858985"}]}