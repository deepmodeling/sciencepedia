{"hands_on_practices": [{"introduction": "The transfer function $H(z)$ provides a concise frequency-domain description of an IIR system, but understanding its time-domain behavior requires finding the impulse response $h[n]$. This fundamental practice challenges you to derive the inverse Z-transform for a general IIR system from first principles, without relying on memorized transform pairs. By doing so, you will gain a deeper insight into how features of the transfer function, such as repeated poles, directly shape the structure of the impulse response [@problem_id:2878198].", "problem": "Consider a causal Linear Time-Invariant (LTI) discrete-time Infinite Impulse Response (IIR) system with transfer function given in partial-fraction form by\n$$\nH(z) \\;=\\; \\sum_{k=1}^{K} \\sum_{m=1}^{M_k} \\frac{c_{k,m}}{\\left(1 - p_k z^{-1}\\right)^{m}},\n$$\nwhere the distinct poles are $\\{p_k\\}_{k=1}^{K}$ with $|p_k|1$ for all $k$, each with multiplicity $M_k \\in \\mathbb{N}$, and complex coefficients $\\{c_{k,m}\\}$. Assume the region of convergence is $|z|\\max_k |p_k|$, so the system is causal and stable. Starting from first principles, namely the definition of the bilateral $Z$-transform $X(z) = \\sum_{n=-\\infty}^{\\infty} x[n] z^{-n}$ and fundamental series identities derivable from the geometric series $\\sum_{n=0}^{\\infty} r^{n} = \\frac{1}{1-r}$ for $|r|1$, derive the explicit time-domain impulse response $h[n]$ as a closed-form expression in terms of $\\{c_{k,m}\\}$, $\\{p_k\\}$, and $n$, making clear the polynomial-in-$n$ factors that arise from repeated poles (that is, $m1$). Your derivation should justify the appearance and the exact form of these polynomial factors from first principles, without invoking pre-memorized transform pairs for repeated poles.\n\nExpress your final answer as a single analytic expression for $h[n]$ that is valid for all integer $n$, using the unit-step sequence $u[n]$. Do not provide intermediate steps in the final answer. No numerical evaluation is required.", "solution": "The problem presented is a standard theoretical exercise in the analysis of discrete-time linear time-invariant systems. A rigorous validation of the problem statement is a non-negotiable prerequisite to any analytical work.\n\nFirst, we extract the given information verbatim.\n- **System**: Causal, Linear Time-Invariant (LTI), discrete-time, Infinite Impulse Response (IIR).\n- **Transfer Function**: $H(z) \\;=\\; \\sum_{k=1}^{K} \\sum_{m=1}^{M_k} \\frac{c_{k,m}}{\\left(1 - p_k z^{-1}\\right)^{m}}$.\n- **Poles**: $\\{p_k\\}_{k=1}^{K}$ are distinct complex numbers with $|p_k|1$.\n- **Multiplicities**: $M_k \\in \\mathbb{N}$ is the multiplicity of pole $p_k$.\n- **Coefficients**: $\\{c_{k,m}\\}$ are complex numbers.\n- **Region of Convergence (ROC)**: $|z|\\max_k |p_k|$.\n- **Fundamental Postulates**:\n    1.  Bilateral $Z$-transform: $X(z) = \\sum_{n=-\\infty}^{\\infty} x[n] z^{-n}$.\n    2.  Geometric series: $\\sum_{n=0}^{\\infty} r^{n} = \\frac{1}{1-r}$ for $|r|1$.\n- **Objective**: Derive the impulse response $h[n]$ from first principles, explaining the origin of polynomial factors for repeated poles. The result must be a closed-form expression using the unit-step sequence $u[n]$, defined as $1$ for $n \\ge 0$ and $0$ for $n  0$.\n\nNext, we validate the problem statement.\nThe problem is scientifically grounded in the established theory of digital signal processing. All terms and concepts, such as the $Z$-transform, LTI systems, causality, stability, and partial fraction expansion, are standard and well-defined. The structure of the problem is that of a direct mathematical derivation. The given conditions—$|p_k|1$ and an ROC of $|z|  \\max_k|p_k|$—correctly correspond to a causal and stable system. The problem is self-contained, consistent, and well-posed, asking for a unique and meaningful solution derivable from the premises. It is neither trivial nor pseudo-profound, as the derivation for repeated poles from first principles requires non-obvious steps. The problem is therefore valid.\n\nWe proceed with the derivation.\n\nThe objective is to find the impulse response $h[n]$, which is the inverse $Z$-transform of the transfer function $H(z)$. The $Z$-transform is a linear operator. Consequently, the inverse transform of the sum is the sum of the inverse transforms:\n$$ h[n] = \\mathcal{Z}^{-1}\\{H(z)\\} = \\mathcal{Z}^{-1}\\left\\{ \\sum_{k=1}^{K} \\sum_{m=1}^{M_k} \\frac{c_{k,m}}{\\left(1 - p_k z^{-1}\\right)^{m}} \\right\\} = \\sum_{k=1}^{K} \\sum_{m=1}^{M_k} c_{k,m} \\mathcal{Z}^{-1}\\left\\{ \\frac{1}{\\left(1 - p_k z^{-1}\\right)^{m}} \\right\\} $$\nOur task reduces to finding the inverse $Z$-transform of the general term $G_{k,m}(z) = \\left(1 - p_k z^{-1}\\right)^{-m}$.\n\nLet us begin with the fundamental case where $m=1$. We need to find the inverse transform of $G_{k,1}(z) = \\frac{1}{1-p_k z^{-1}}$. We are given the geometric series identity:\n$$ \\sum_{n=0}^{\\infty} r^n = \\frac{1}{1-r}, \\quad \\text{for } |r|1 $$\nLet us set $r = p_k z^{-1}$. The condition for convergence becomes $|p_k z^{-1}|  1$, or $|z|  |p_k|$. This is consistent with the given ROC for a causal system, as $|z|  \\max_j |p_j| \\ge |p_k|$. Substituting $r = p_k z^{-1}$ into the series identity gives:\n$$ G_{k,1}(z) = \\frac{1}{1-p_k z^{-1}} = \\sum_{n=0}^{\\infty} (p_k z^{-1})^n = \\sum_{n=0}^{\\infty} (p_k^n) z^{-n} $$\nBy definition, the $Z$-transform of a sequence $x[n]$ is $X(z) = \\sum_{n=-\\infty}^{\\infty} x[n] z^{-n}$. Comparing this definition with our series expansion, we identify the corresponding time-domain sequence. The sequence is $p_k^n$ for $n \\ge 0$ and $0$ otherwise. This is precisely $p_k^n u[n]$. Thus, we have the transform pair:\n$$ p_k^n u[n] \\quad \\overset{\\mathcal{Z}}{\\longleftrightarrow} \\quad \\frac{1}{1-p_k z^{-1}} $$\n\nNow, we must address the case of repeated poles, where $m1$. The problem forbids the use of pre-memorized transform pairs. We must derive the result from first principles. A rigorous method is to differentiate the geometric series identity with respect to the parameter $r$. Differentiation of a power series term-by-term is valid within its radius of convergence.\nStarting with the identity:\n$$ (1-r)^{-1} = \\sum_{n=0}^{\\infty} r^n $$\nDifferentiating both sides with respect to $r$ gives:\n$$ \\frac{d}{dr}(1-r)^{-1} = (-1)(1-r)^{-2}(-1) = (1-r)^{-2} $$\n$$ \\frac{d}{dr}\\sum_{n=0}^{\\infty} r^n = \\sum_{n=0}^{\\infty} n r^{n-1} = \\sum_{n=1}^{\\infty} n r^{n-1} $$\nLet's shift the index of summation by letting $j=n-1$, so $n=j+1$. The sum becomes $\\sum_{j=0}^{\\infty} (j+1) r^j$. Using $n$ as the index again, we have:\n$$ (1-r)^{-2} = \\sum_{n=0}^{\\infty} (n+1) r^n $$\nThis result can be generalized by repeated differentiation. The $(m-1)$-th derivative of $(1-r)^{-1}$ with respect to $r$ is:\n$$ \\frac{d^{m-1}}{dr^{m-1}}(1-r)^{-1} = (m-1)! (1-r)^{-m} $$\nApplying the same differentiation to the series side:\n$$ \\frac{d^{m-1}}{dr^{m-1}}\\sum_{n=0}^{\\infty} r^n = \\sum_{n=m-1}^{\\infty} n(n-1)\\cdots(n-m+2) r^{n-(m-1)} $$\nThe product of descending integers can be expressed using factorials and binomial coefficients:\n$$ n(n-1)\\cdots(n-m+2) = \\frac{n!}{(n-(m-1))!} = (m-1)! \\binom{n}{m-1} $$\nSo we have:\n$$ (m-1)! (1-r)^{-m} = \\sum_{n=m-1}^{\\infty} (m-1)! \\binom{n}{m-1} r^{n-m+1} $$\nDividing by $(m-1)!$ and changing the index of summation to $j = n-(m-1)$, so $n=j+m-1$:\n$$ (1-r)^{-m} = \\sum_{j=0}^{\\infty} \\binom{j+m-1}{m-1} r^j $$\nThe term $\\binom{j+m-1}{m-1} = \\frac{(j+m-1)!}{j!(m-1)!}$ is a polynomial in $j$ of degree $m-1$, which is the source of the polynomial factor requested in the problem statement.\nNow, we substitute $r = p_k z^{-1}$ back into this generalized identity. Using $n$ as the summation index:\n$$ \\frac{1}{(1-p_k z^{-1})^{m}} = \\sum_{n=0}^{\\infty} \\binom{n+m-1}{m-1} (p_k z^{-1})^n = \\sum_{n=0}^{\\infty} \\left[ \\binom{n+m-1}{m-1} p_k^n \\right] z^{-n} $$\nAgain, by comparison with the definition of the $Z$-transform, we deduce the inverse transform. The sequence is non-zero only for $n \\ge 0$.\n$$ \\binom{n+m-1}{m-1} p_k^n u[n] \\quad \\overset{\\mathcal{Z}}{\\longleftrightarrow} \\quad \\frac{1}{\\left(1-p_k z^{-1}\\right)^{m}} $$\nThe derivation from first principles is complete.\n\nFinally, we assemble the total impulse response $h[n]$ by summing the contributions from all terms in the partial fraction expansion:\n$$ h[n] = \\sum_{k=1}^{K} \\sum_{m=1}^{M_k} c_{k,m} \\left( \\binom{n+m-1}{m-1} p_k^n u[n] \\right) $$\nSince the unit step $u[n]$ is a common factor for all terms (a consequence of causality), it can be factored out of the summation:\n$$ h[n] = \\left( \\sum_{k=1}^{K} \\sum_{m=1}^{M_k} c_{k,m} \\binom{n+m-1}{m-1} p_k^n \\right) u[n] $$\nThis is the final closed-form expression for the impulse response, valid for all integers $n$.", "answer": "$$\n\\boxed{\nh[n] = \\left( \\sum_{k=1}^{K} \\sum_{m=1}^{M_k} c_{k,m} \\binom{n+m-1}{m-1} p_k^n \\right) u[n]\n}\n$$", "id": "2878198"}, {"introduction": "Transitioning from ideal theory to hardware implementation reveals that IIR systems can exhibit behaviors not predicted by linear analysis. This exercise explores the phenomenon of zero-input limit cycles, where small, persistent oscillations arise from rounding errors in the feedback path, even without any external input. You will analyze the conditions that create these cycles and derive the \"dead-band,\" a critical parameter that defines the region of state space within which the filter is guaranteed to settle to zero [@problem_id:2878204].", "problem": "Consider a causal, stable, second-order infinite impulse response (IIR) section implemented in fixed-point arithmetic with rounding-to-nearest. Let the rounding quantizer be denoted by $Q_{\\Delta}(\\cdot)$ with quantization step size $\\Deltagt;0$, defined by mapping any $x\\in\\mathbb{R}$ to the nearest integer multiple of $\\Delta$, with ties rounded away from zero. Assume zero input for all times. The implementation is described by the nonlinear recursion\n$$\nx[n] \\;=\\; Q_{\\Delta}\\!\\left(-a_{1}\\,x[n-1] \\;-\\; a_{2}\\,x[n-2]\\right), \\qquad y[n] \\;=\\; x[n],\n$$\nwhere $a_{1},a_{2}\\in\\mathbb{R}$ are such that the corresponding linear recursion without quantization is asymptotically stable, and where initial conditions $x[-1]$ and $x[-2]$ are representable fixed-point values (i.e., integer multiples of $\\Delta$).\n\n(1) Using only fundamental properties of fixed-point rounding quantizers and deterministic discrete-time dynamical systems on finite sets, argue from first principles why this IIR section can exhibit nontrivial zero-input limit cycles.\n\n(2) Define the symmetric dead-band as the largest radius $R(a_{1},a_{2},\\Delta)gt;0$ with the following property: for any initial fixed-point conditions satisfying $\\lvert x[-1]\\rvert\\leq R$ and $\\lvert x[-2]\\rvert\\leq R$, the output sequence satisfies $y[n]=0$ for all $n\\geq 0$. Derive, from first principles, an exact analytic expression for the supremal symmetric dead-band radius $R(a_{1},a_{2},\\Delta)$ as a function of $a_{1}$, $a_{2}$, and $\\Delta$. Your final answer must be a single closed-form expression. Do not assume any particular realization other than the given recursion, and do not invoke any precomputed formulas; start from the definitions and properties stated above.\n\nNo numerical approximation is required in this problem, and no units are involved. Express your final result as a symbolic function of $a_{1}$, $a_{2}$, and $\\Delta$.", "solution": "The problem as stated is scientifically grounded, well-posed, objective, and contains sufficient information for a rigorous solution. It is a standard problem in the analysis of quantization effects in digital filters. Thus, it is deemed valid. We proceed with the solution.\n\nThe system is described by the nonlinear difference equation:\n$$x[n] = Q_{\\Delta}(-a_1 x[n-1] - a_2 x[n-2])$$\nwhere $Q_{\\Delta}(\\cdot)$ is a quantizer with step size $\\Delta  0$ that rounds to the nearest integer multiple of $\\Delta$. The tie-breaking rule specifies rounding away from zero. This implies that for any a real value $v$, $Q_{\\Delta}(v) = 0$ if and only if $|v|  \\frac{\\Delta}{2}$. If $|v| \\ge \\frac{\\Delta}{2}$, then $|Q_{\\Delta}(v)| \\ge \\Delta$. The initial conditions $x[-1]$ and $x[-2]$ are integer multiples of $\\Delta$.\n\n(1) Argument for the existence of nontrivial zero-input limit cycles.\n\nThe state of the system at time $n$ is defined by the pair of previous values, $\\mathbf{s}[n] = (x[n-1], x[n-2])$. The recursion provides a deterministic rule for transitioning from state $\\mathbf{s}[n]$ to $\\mathbf{s}[n+1] = (x[n], x[n-1])$.\n\nThe underlying linear system, $x_{\\text{lin}}[n] = -a_1 x_{\\text{lin}}[n-1] - a_2 x_{\\text{lin}}[n-2]$, is stipulated to be asymptotically stable. This means that for any initial conditions, the state of the linear system converges to zero, i.e., $\\lim_{n \\to \\infty} x_{\\text{lin}}[n] = 0$. Consequently, the state trajectory is bounded.\n\nIn the nonlinear system with quantization, the state values $x[n]$ are always integer multiples of $\\Delta$. The stability of the linear counterpart suggests that for any given initial state, the trajectory of the nonlinear system will not diverge. The state will eventually enter and remain within a bounded region of the state space. Let this region be defined by $|x[n]| \\le M$ for some constant $M  0$.\n\nWithin this bounded region, the number of possible values for $x[n]$ is finite, as they must be integer multiples of $\\Delta$ in the interval $[-M, M]$. Specifically, the number of such values is $2\\lfloor \\frac{M}{\\Delta} \\rfloor + 1$. The number of possible states $\\mathbf{s}[n] = (x[n-1], x[n-2])$ is therefore also finite, bounded by $(2\\lfloor \\frac{M}{\\Delta} \\rfloor + 1)^2$.\n\nThe system's evolution is governed by a deterministic function on this finite state space. By the pigeonhole principle, any deterministic system evolving on a finite state space must eventually revisit a state. Once a state is repeated, the system's trajectory becomes periodic, as the sequence of subsequent states is uniquely determined. This periodic trajectory is, by definition, a limit cycle.\n\nSuch a limit cycle can be nontrivial (i.e., not the zero state where $x[n]=0$ for all $n$ in the cycle). The zero state $(0,0)$ is a fixed point, since $Q_{\\Delta}(-a_1 \\cdot 0 - a_2 \\cdot 0) = 0$. However, the system may not reach this state. Consider a small, non-zero state $(x[n-1], x[n-2])$. The argument of the quantizer is $v[n] = -a_1 x[n-1] - a_2 x[n-2]$. While the linear dynamics would drive $v[n]$ toward zero, the quantization introduces a \"floor\" effect. If at some point $|v[n]| \\ge \\frac{\\Delta}{2}$, the output $x[n]$ will be a non-zero multiple of $\\Delta$, with magnitude at least $\\Delta$. This can prevent the state from ever reaching zero, sustaining a small, persistent oscillation. The interplay between the contracting nature of the stable linear dynamics and the expanding/maintaining nature of the quantization for inputs of magnitude greater than or equal to $\\frac{\\Delta}{2}$ is what enables the existence of these nontrivial, self-sustaining oscillations.\n\n(2) Derivation of the supremal symmetric dead-band radius $R$.\n\nThe dead-band is the region of initial states for which the system converges to the zero state and remains there. We require that if the initial conditions $x[-1]$ and $x[-2]$ are fixed-point values satisfying $|x[-1]| \\le R$ and $|x[-2]| \\le R$, then $x[n] = 0$ for all $n \\ge 0$.\n\nFor the output to become and remain zero, the system must reach the state $(0,0)$. Let us analyze the first few steps.\nFor $n=0$, we require $x[0]=0$.\n$$x[0] = Q_{\\Delta}(-a_1 x[-1] - a_2 x[-2]) = 0$$\nBased on the quantizer property, this is equivalent to the condition:\n$$|a_1 x[-1] + a_2 x[-2]|  \\frac{\\Delta}{2} \\quad (*)$$\n\nFor $n=1$, if $x[0]=0$, the state is now $(x[0], x[-1]) = (0, x[-1])$. We require $x[1]=0$.\n$$x[1] = Q_{\\Delta}(-a_1 x[0] - a_2 x[-1]) = Q_{\\Delta}(-a_2 x[-1]) = 0$$\nThis is equivalent to the condition:\n$$|a_2 x[-1]|  \\frac{\\Delta}{2} \\quad (**)$$\n\nIf both conditions $(*)$ and $(**)$ are met, then $x[0]=0$ and $x[1]=0$. The state at time $n=2$ becomes $(x[1], x[0]) = (0, 0)$. Consequently, for all $n \\ge 2$:\n$$x[n] = Q_{\\Delta}(-a_1 x[n-1] - a_2 x[n-2]) = Q_{\\Delta}(0) = 0$$\nThus, the problem reduces to finding the supremal radius $R  0$ such that for any fixed-point values $x[-1], x[-2]$ with $|x[-1]| \\le R$ and $|x[-2]| \\le R$, conditions $(*)$ and $(**)$ are satisfied.\n\nA sufficient condition is to require that $(*)$ and $(**)$ hold for all *real* values $u, v$ in the continuous square region defined by $|u| \\le R$ and $|v| \\le R$. If this holds, it must also hold for the subset of fixed-point values within that region.\n\nLet us analyze the required inequalities for all $u,v$ such that $|u| \\le R$ and $|v| \\le R$:\n1. From condition $(*)$: $|a_1 u + a_2 v|  \\frac{\\Delta}{2}$.\nTo guarantee this for the entire region, the maximum value of the left-hand side must be less than $\\frac{\\Delta}{2}$. Using the triangle inequality, we find the maximum value:\n$$\\max_{|u|\\le R, |v|\\le R} |a_1 u + a_2 v| = \\max_{|u|\\le R, |v|\\le R} \\{|a_1||u| + |a_2||v|\\}$$\nThis maximum is achieved when $|u|=R$ and $|v|=R$, which gives $(|a_1| + |a_2|)R$. The condition thus becomes:\n$$(|a_1| + |a_2|)R  \\frac{\\Delta}{2} \\implies R  \\frac{\\Delta}{2(|a_1| + |a_2|)}$$\n\n2. From condition $(**)$: $|a_2 u|  \\frac{\\Delta}{2}$.\nSimilarly, the maximum value of the left-hand side is:\n$$\\max_{|u|\\le R} |a_2 u| = |a_2|R$$\nThe condition becomes:\n$$|a_2|R  \\frac{\\Delta}{2} \\implies R  \\frac{\\Delta}{2|a_2|}$$\nThis second condition is only relevant if $a_2 \\ne 0$. If $a_2=0$, it is trivially satisfied.\n\nTo satisfy both conditions, $R$ must be smaller than the minimum of the two derived upper bounds:\n$$R  \\min \\left( \\frac{\\Delta}{2(|a_1| + |a_2|)}, \\frac{\\Delta}{2|a_2|} \\right)$$\nWe compare the denominators of the two terms in the minimum. Since $|a_1| \\ge 0$, it follows that $|a_1| + |a_2| \\ge |a_2|$. Assuming the filter is non-trivial ($|a_1|+|a_2|  0$, which is implied by the second-order nature), taking the positive reciprocal reverses the inequality:\n$$\\frac{1}{2(|a_1| + |a_2|)} \\le \\frac{1}{2|a_2|}$$\nTherefore, the first term is always the more restrictive one. The comprehensive condition on $R$ simplifies to:\n$$R  \\frac{\\Delta}{2(|a_1| + |a_2|)}$$\nThe problem asks for the supremal radius $R$ with the specified property. The set of all radii $R$ that satisfy the property is the open interval $\\left(0, \\frac{\\Delta}{2(|a_1| + |a_2|)}\\right)$. The supremum (least upper bound) of this set is its right endpoint.\n\nTherefore, the supremal symmetric dead-band radius is given by the expression:\n$$R(a_1, a_2, \\Delta) = \\frac{\\Delta}{2(|a_1| + |a_2|)}$$\nAt this supremum value itself, a fixed-point value on the boundary of the region may exist which is mapped to a non-zero value due to the tie-breaking rule, but for any radius strictly smaller than this, all interior fixed-point values are guaranteed to be mapped to zero. The supremum is the limit of these valid radii.", "answer": "$$\n\\boxed{\\frac{\\Delta}{2(|a_1| + |a_2|)}}\n$$", "id": "2878204"}, {"introduction": "The practical implementation of an IIR filter requires quantizing not only the signals but also the filter coefficients themselves. This exercise investigates the critical issue of pole sensitivity, analyzing how small errors in coefficients can shift the system's poles and potentially compromise its stability or frequency response. By modeling the filter using a companion matrix, you will apply powerful results from eigenvalue perturbation theory to derive a guaranteed bound on pole movement, a vital skill for robust filter design [@problem_id:2878207].", "problem": "Consider a causal discrete-time linear time-invariant infinite impulse response (IIR) system with transfer function denominator specified by the monic polynomial\n$$\np(\\lambda) = \\lambda^{4} + a_{3}\\lambda^{3} + a_{2}\\lambda^{2} + a_{1}\\lambda + a_{0},\n$$\nwith nominal coefficients\n$$\na_{3} = -1.2,\\quad a_{2} = 0.65,\\quad a_{1} = -0.12,\\quad a_{0} = 0.006.\n$$\nThe poles of the system are the roots of $p(\\lambda)$ and coincide with the eigenvalues of the $4\\times 4$ controllable companion matrix\n$$\nC(a) =\n\\begin{pmatrix}\n0  1  0  0\\\\\n0  0  1  0\\\\\n0  0  0  1\\\\\n-a_{0}  -a_{1}  -a_{2}  -a_{3}\n\\end{pmatrix}.\n$$\nAssume $C(a)$ is diagonalizable over the complex field with eigenvector matrix $V$ whose spectral (matrix $2$-norm) condition number is $\\kappa_{2}(V) = 18.37$.\n\nSuppose the denominator coefficients are perturbed to $\\tilde{a}_{k} = a_{k} + \\delta a_{k}$, where the perturbations satisfy the componentwise bounds\n$$\n|\\delta a_{0}| \\leq 2\\times 10^{-4},\\quad\n|\\delta a_{1}| \\leq 1\\times 10^{-3},\\quad\n|\\delta a_{2}| \\leq 1.5\\times 10^{-3},\\quad\n|\\delta a_{3}| \\leq 2\\times 10^{-3}.\n$$\nModel the pole movement via the perturbation of the companion matrix $C(a)$ to $C(\\tilde{a})$ induced by $(\\delta a_{0},\\delta a_{1},\\delta a_{2},\\delta a_{3})$. Using only core definitions linking polynomial roots to eigenvalues of the companion matrix, standard eigenvalue perturbation results for diagonalizable matrices, and properties of the spectral norm, derive a guaranteed upper bound on the maximum possible displacement in the complex plane of any single pole. Then, evaluate this bound numerically under the given data.\n\nRound your final numerical answer to four significant figures. Express the final answer as a pure number (unitless).", "solution": "The problem requires the derivation of a guaranteed upper bound on the displacement of any pole of a discrete-time IIR system when the coefficients of its characteristic polynomial are perturbed. The poles are given as the roots of a polynomial $p(\\lambda)$, which are equivalent to the eigenvalues of a specific companion matrix $C(a)$. This allows us to reframe the problem of root-finding sensitivity as one of eigenvalue sensitivity in linear algebra.\n\nThe system's characteristic polynomial is given by:\n$$\np(\\lambda) = \\lambda^{4} + a_{3}\\lambda^{3} + a_{2}\\lambda^{2} + a_{1}\\lambda + a_{0}\n$$\nThe roots of $p(\\lambda)=0$ are the eigenvalues of the controllable companion matrix:\n$$\nC(a) =\n\\begin{pmatrix}\n0  1  0  0\\\\\n0  0  1  0\\\\\n0  0  0  1\\\\\n-a_{0}  -a_{1}  -a_{2}  -a_{3}\n\\end{pmatrix}\n$$\nThe nominal coefficients $a_k$ are perturbed to $\\tilde{a}_{k} = a_{k} + \\delta a_{k}$. This induces a perturbation of the companion matrix from $C(a)$ to $C(\\tilde{a}) = C(a+\\delta a)$. The perturbation matrix, which we denote as $E$, is the difference between the perturbed and nominal matrices:\n$$\nE = C(\\tilde{a}) - C(a) =\n\\begin{pmatrix}\n0  1  0  0\\\\\n0  0  1  0\\\\\n0  0  0  1\\\\\n-(a_{0} + \\delta a_{0})  -(a_{1} + \\delta a_{1})  -(a_{2} + \\delta a_{2})  -(a_{3} + \\delta a_{3})\n\\end{pmatrix}\n-\n\\begin{pmatrix}\n0  1  0  0\\\\\n0  0  1  0\\\\\n0  0  0  1\\\\\n-a_{0}  -a_{1}  -a_{2}  -a_{3}\n\\end{pmatrix}\n$$\nThis simplifies to:\n$$\nE = \\delta C =\n\\begin{pmatrix}\n0  0  0  0\\\\\n0  0  0  0\\\\\n0  0  0  0\\\\\n-\\delta a_{0}  -\\delta a_{1}  -\\delta a_{2}  -\\delta a_{3}\n\\end{pmatrix}\n$$\nThe problem states that the nominal matrix $C(a)$ is diagonalizable. This is a critical condition that allows the use of the Bauer-Fike theorem for bounding eigenvalue perturbations. The theorem states that for any eigenvalue $\\tilde{\\lambda}$ of the perturbed matrix $C(a) + E$, there is an eigenvalue $\\lambda$ of the nominal matrix $C(a)$ such that:\n$$\n|\\tilde{\\lambda} - \\lambda| \\leq \\kappa_{p}(V) \\|E\\|_{p}\n$$\nwhere $V$ is the matrix of eigenvectors of $C(a)$, $\\kappa_{p}(V) = \\|V\\|_{p}\\|V^{-1}\\|_{p}$ is the condition number of $V$ with respect to the matrix $p$-norm, and $\\|E\\|_p$ is the corresponding induced norm of the perturbation matrix.\n\nThe problem specifies the use of the spectral norm (the $2$-norm). Therefore, the bound on the maximum displacement of any pole, $\\max|\\delta \\lambda|$, is given by:\n$$\n\\max|\\delta \\lambda| \\leq \\kappa_{2}(V) \\|E\\|_{2}\n$$\nWe are given $\\kappa_{2}(V) = 18.37$. The remaining task is to find a guaranteed upper bound for the spectral norm $\\|E\\|_{2}$. The spectral norm of a matrix $E$ is defined as the square root of the largest eigenvalue of the matrix $E^{*}E$, where $E^{*}$ is the conjugate transpose of $E$.\nAssuming the perturbations $\\delta a_k$ are real numbers, $E^{*} = E^{T}$. We compute $E^{T}E$:\n$$\nE^{T}E =\n\\begin{pmatrix}\n0  0  0  -\\delta a_{0} \\\\\n0  0  0  -\\delta a_{1} \\\\\n0  0  0  -\\delta a_{2} \\\\\n0  0  0  -\\delta a_{3}\n\\end{pmatrix}\n\\begin{pmatrix}\n0  0  0  0\\\\\n0  0  0  0\\\\\n0  0  0  0\\\\\n-\\delta a_{0}  -\\delta a_{1}  -\\delta a_{2}  -\\delta a_{3}\n\\end{pmatrix}\n=\n\\begin{pmatrix}\n(\\delta a_{0})^{2}  \\delta a_{0}\\delta a_{1}  \\delta a_{0}\\delta a_{2}  \\delta a_{0}\\delta a_{3} \\\\\n\\delta a_{1}\\delta a_{0}  (\\delta a_{1})^{2}  \\delta a_{1}\\delta a_{2}  \\delta a_{1}\\delta a_{3} \\\\\n\\delta a_{2}\\delta a_{0}  \\delta a_{2}\\delta a_{1}  (\\delta a_{2})^{2}  \\delta a_{2}\\delta a_{3} \\\\\n\\delta a_{3}\\delta a_{0}  \\delta a_{3}\\delta a_{1}  \\delta a_{3}\\delta a_{2}  (\\delta a_{3})^{2}\n\\end{pmatrix}\n$$\nThis is a rank-$1$ matrix. If we define a vector $u = (\\delta a_{0}, \\delta a_{1}, \\delta a_{2}, \\delta a_{3})^{T}$, then $E^{T}E = u u^{T}$. The eigenvalues of such a matrix are $u^{T}u$ and $0$ with multiplicity $n-1=3$. The single non-zero eigenvalue is:\n$$\n\\lambda_{\\max}(E^{T}E) = u^{T}u = (\\delta a_{0})^{2} + (\\delta a_{1})^{2} + (\\delta a_{2})^{2} + (\\delta a_{3})^{2} = \\sum_{k=0}^{3} (\\delta a_{k})^{2}\n$$\nThe spectral norm is the square root of this value:\n$$\n\\|E\\|_{2} = \\sqrt{\\sum_{k=0}^{3} (\\delta a_{k})^{2}}\n$$\nThis is also the Euclidean norm of the single non-zero row of $E$. The result holds even if $\\delta a_k$ are complex, where the sum would be over $|\\delta a_k|^2$.\n\nTo find a guaranteed upper bound on $\\|E\\|_{2}$, we use the provided componentwise bounds on the perturbations:\n$|\\delta a_{0}| \\leq 2 \\times 10^{-4}$\n$|\\delta a_{1}| \\leq 1 \\times 10^{-3}$\n$|\\delta a_{2}| \\leq 1.5 \\times 10^{-3}$\n$|\\delta a_{3}| \\leq 2 \\times 10^{-3}$\n\nThe norm $\\|E\\|_{2}$ is maximized when each $|\\delta a_k|$ reaches its maximum allowed value. Therefore, an upper bound for the norm is:\n$$\n\\|E\\|_{2} \\leq \\sqrt{(2\\times 10^{-4})^{2} + (1\\times 10^{-3})^{2} + (1.5\\times 10^{-3})^{2} + (2\\times 10^{-3})^{2}}\n$$\nLet us compute this value:\n$$\n\\|E\\|_{2} \\leq \\sqrt{4\\times 10^{-8} + 1\\times 10^{-6} + 2.25\\times 10^{-6} + 4\\times 10^{-6}}\n$$\n$$\n\\|E\\|_{2} \\leq \\sqrt{(0.04\\times 10^{-6}) + (1\\times 10^{-6}) + (2.25\\times 10^{-6}) + (4\\times 10^{-6})}\n$$\n$$\n\\|E\\|_{2} \\leq \\sqrt{(0.04 + 1 + 2.25 + 4) \\times 10^{-6}} = \\sqrt{7.29 \\times 10^{-6}}\n$$\nSince $\\sqrt{7.29} = 2.7$, we have:\n$$\n\\|E\\|_{2} \\leq 2.7 \\times 10^{-3}\n$$\nNow we can compute the final upper bound on the pole/eigenvalue displacement:\n$$\n\\max|\\delta \\lambda| \\leq \\kappa_{2}(V) \\times (\\text{upper bound on } \\|E\\|_{2})\n$$\n$$\n\\max|\\delta \\lambda| \\leq 18.37 \\times (2.7 \\times 10^{-3})\n$$\n$$\n\\max|\\delta \\lambda| \\leq 49.599 \\times 10^{-3} = 0.049599\n$$\nThe problem requires this result to be rounded to four significant figures.\n$$\n0.049599 \\approx 0.04960\n$$\nThus, the guaranteed upper bound on the maximum possible displacement of any single pole is $0.04960$.", "answer": "$$\n\\boxed{0.04960}\n$$", "id": "2878207"}]}