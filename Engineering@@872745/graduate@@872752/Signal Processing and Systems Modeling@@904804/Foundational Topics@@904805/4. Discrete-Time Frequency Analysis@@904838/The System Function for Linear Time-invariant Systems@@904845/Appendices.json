{"hands_on_practices": [{"introduction": "While Laplace transform tables provide a quick route to finding an impulse response, a true mastery of LTI systems comes from understanding the underlying principles. This exercise guides you through a first-principles derivation using the inverse Laplace transform integral. By doing so, you will directly see how a system's poles in the $s$-plane and its region of convergence (ROC) fundamentally determine the exponential form and causal nature of its time-domain impulse response [@problem_id:2914300].", "problem": "Consider a continuous-time linear time-invariant (LTI) system whose system function (bilateral Laplace transform of its impulse response) is the strictly proper rational function\n$$\nH(s)=\\frac{2s+3}{(s+1)(s+2)}.\n$$\nAssume the system is causal, so that the Region of Convergence (ROC) of the bilateral Laplace transform is to the right of the rightmost pole. Starting only from the definitions of the bilateral Laplace transform and its inverse via the Bromwich integral, and from the causality condition that the impulse response $h(t)$ vanishes for $t0$, derive the explicit closed-form expression for the impulse response $h(t)$. Your derivation must make clear how the contributions from each pole of $H(s)$, through their residues, determine the time-domain form, and how the ROC implied by causality shapes the support of $h(t)$. Express your final answer as a single closed-form expression in terms of $t$ and the unit step $u(t)$, and do not use any memorized transform pairs or shortcut formulas.", "solution": "The problem requires the derivation of the impulse response $h(t)$ for a causal linear time-invariant (LTI) system with a given system function $H(s)$. The derivation must proceed from first principles, specifically the definition of the inverse bilateral Laplace transform, without recourse to standard transform pair tables.\n\nThe given system function is:\n$$\nH(s) = \\frac{2s+3}{(s+1)(s+2)}\n$$\nThe system is specified as causal, which implies two conditions:\n1. The impulse response $h(t)$ is zero for all time $t  0$.\n2. The Region of Convergence (ROC) of $H(s)$ is a right half-plane extending to the right of the rightmost pole.\n\nThe poles of $H(s)$ are the roots of the denominator, which are $s_1 = -1$ and $s_2 = -2$. The rightmost pole is at $s = -1$. Therefore, the ROC for the causal system is $\\mathrm{Re}(s)  -1$.\n\nThe impulse response $h(t)$ is obtained by computing the inverse bilateral Laplace transform of $H(s)$, which is defined by the Bromwich integral:\n$$\nh(t) = \\frac{1}{2\\pi j} \\int_{\\sigma - j\\infty}^{\\sigma + j\\infty} H(s) e^{st} ds\n$$\nwhere the path of integration is a vertical line in the $s$-plane, $s = \\sigma + j\\omega$, located within the ROC. For this problem, the real constant $\\sigma$ must satisfy $\\sigma  -1$.\n\nThe evaluation of this integral is performed by closing the integration contour and applying the residue theorem. The manner in which the contour is closed depends on the sign of the variable $t$.\n\nCase 1: $t  0$.\nFor the integral to converge, we must close the contour in the right half-plane where the real part of $s$ approaches $+\\infty$. This is because the term $e^{st}$ in the integrand decays to zero as $\\mathrm{Re}(s) \\to +\\infty$ when $t  0$. Let us consider a closed contour $C_R$ composed of the vertical line segment from $\\sigma - jR$ to $\\sigma + jR$ and a semicircle arc in the right half-plane, centered at $s=\\sigma$ with radius $R$. As $R \\to \\infty$, the Bromwich integral becomes the integral over the infinite vertical line.\n\nThe integrand is $H(s)e^{st}$. The function $H(s)$ is analytic in the region enclosed by $C_R$, as this region is to the right of the line of integration and thus contains no poles. Consequently, the integrand $H(s)e^{st}$ is analytic within and on the contour $C_R$. By Cauchy's Integral Theorem, the integral over this closed contour is zero:\n$$\n\\oint_{C_R} H(s) e^{st} ds = 0\n$$\nThe integral over the closed contour is the sum of the integral along the vertical line and the integral over the semicircular arc. The system function $H(s)$ is strictly proper, meaning that $|H(s)| \\to 0$ as $|s| \\to \\infty$ at least as fast as $1/|s|$. By Jordan's Lemma, for $t  0$, the integral over the right-hand semicircle vanishes as its radius $R \\to \\infty$.\n$$\n\\lim_{R\\to\\infty} \\int_{\\text{arc}} H(s) e^{st} ds = 0\n$$\nSince the integral over the closed path is zero, it follows that the integral along the infinite vertical line must also be zero.\n$$\nh(t) = \\frac{1}{2\\pi j} \\int_{\\sigma - j\\infty}^{\\sigma + j\\infty} H(s) e^{st} ds = 0 \\quad \\text{for } t  0\n$$\nThis result rigorously confirms the causality condition provided in the problem statement.\n\nCase 2: $t  0$.\nFor $t  0$, the term $e^{st}$ decays as $\\mathrm{Re}(s) \\to -\\infty$. Thus, we must close the contour with a semicircular arc in the left half-plane. Let this contour be $C_L$. As the radius $R$ of the arc tends to infinity, this contour $C_L$ (traversed counter-clockwise) encloses both poles of $H(s)$ at $s_1 = -1$ and $s_2 = -2$, because the line of integration $\\mathrm{Re}(s) = \\sigma$ has $\\sigma  -1$.\n\nBy the Residue Theorem, the integral over the closed contour $C_L$ is given by $2\\pi j$ times the sum of the residues of the integrand at the poles enclosed within the contour.\n$$\n\\oint_{C_L} H(s) e^{st} ds = 2\\pi j \\sum_{k} \\text{Res}\\left(H(s) e^{st}, s=s_k\\right)\n$$\nAgain, the integral over the closed contour is the sum of the integral along the vertical line and the integral over the left-hand semicircular arc. For $t  0$, and since $H(s)$ is strictly proper, Jordan's Lemma ensures that the integral over the left-hand arc vanishes as $R \\to \\infty$.\n$$\n\\lim_{R\\to\\infty} \\int_{\\text{arc}} H(s) e^{st} ds = 0\n$$\nTherefore, the Bromwich integral is equal to the value of the closed-loop integral.\n$$\n\\int_{\\sigma - j\\infty}^{\\sigma + j\\infty} H(s) e^{st} ds = \\oint_{C_L} H(s) e^{st} ds\n$$\nSo, for $t  0$, the impulse response is:\n$$\nh(t) = \\frac{1}{2\\pi j} \\left( 2\\pi j \\sum_{k} \\text{Res}\\left(H(s) e^{st}, s=s_k\\right) \\right) = \\sum_{k} \\text{Res}\\left(H(s) e^{st}, s=s_k\\right)\n$$\nWe now compute the residues of $F(s) = H(s)e^{st}$ at the simple poles $s_1 = -1$ and $s_2 = -2$.\n\nResidue at $s_1 = -1$:\n$$\n\\text{Res}_1 = \\lim_{s \\to -1} (s - (-1)) H(s) e^{st} = \\lim_{s \\to -1} (s+1) \\frac{2s+3}{(s+1)(s+2)} e^{st}\n$$\n$$\n\\text{Res}_1 = \\lim_{s \\to -1} \\frac{2s+3}{s+2} e^{st} = \\frac{2(-1)+3}{-1+2} e^{-t} = \\frac{1}{1} e^{-t} = e^{-t}\n$$\n\nResidue at $s_2 = -2$:\n$$\n\\text{Res}_2 = \\lim_{s \\to -2} (s - (-2)) H(s) e^{st} = \\lim_{s \\to -2} (s+2) \\frac{2s+3}{(s+1)(s+2)} e^{st}\n$$\n$$\n\\text{Res}_2 = \\lim_{s \\to -2} \\frac{2s+3}{s+1} e^{st} = \\frac{2(-2)+3}{-2+1} e^{-2t} = \\frac{-1}{-1} e^{-2t} = e^{-2t}\n$$\nFor $t  0$, the impulse response is the sum of these residues:\n$$\nh(t) = \\text{Res}_1 + \\text{Res}_2 = e^{-t} + e^{-2t}\n$$\n\nCombining the results for both cases ($t  0$ and $t  0$) using the unit step function $u(t)$, which is defined as $u(t)=1$ for $t0$ and $u(t)=0$ for $t0$, we obtain the complete expression for the impulse response:\n$$\nh(t) = (e^{-t} + e^{-2t}) u(t)\n$$\nThis derivation meticulously follows from the fundamental definition of the inverse Laplace transform and demonstrates how the causality condition and the ROC dictate the structure of the time-domain signal.", "answer": "$$\n\\boxed{(\\exp(-t) + \\exp(-2t))u(t)}\n$$", "id": "2914300"}, {"introduction": "The Final Value Theorem is a powerful shortcut for determining the long-term behavior of a system, but it is not universally applicable. This practice presents a crucial counterexample: an undamped oscillator, whose poles lie on the imaginary axis. By comparing the true, oscillating time-domain response to the incorrect constant value predicted by the theorem, you will gain a deeper appreciation for why the theorem's stability conditions are paramount and how pole locations directly reflect a system's physical behavior [@problem_id:2914336].", "problem": "Consider a continuous-time, causal, linear time-invariant (LTI) system with system function (transfer function) given by\n$$\nH(s) \\;=\\; \\frac{\\omega_{0}^{2}}{s^{2}+\\omega_{0}^{2}},\n$$\nwhere $\\omega_{0} \\gt 0$ is a fixed real parameter. The input is the unit step $x(t) = u(t)$, with one-sided Laplace transform $X(s) = \\mathcal{L}\\{x(t)\\}(s)$.\n\nUsing only the foundational definitions and properties of LTI systems in the Laplace domain (namely that the output transform satisfies $Y(s) = H(s)\\,X(s)$ and that inverse transforms are defined via partial fraction expansion when applicable), derive the output $y(t)$ and analyze its long-time behavior. Then, apply the final value theorem from Laplace theory to compute the quantity it would predict for $\\lim_{t\\to\\infty} y(t)$. Explain why the theorem fails in this case by identifying the relevant pole locations of $s\\,Y(s)$ and interpreting the corresponding physics of the system’s mode structure and its excitation by the step input.\n\nReport, as your final answer, only the value predicted by applying the final value theorem (not the true time-domain limit). No rounding is required. Express any constants symbolically (e.g., leave $\\omega_{0}$ as $\\omega_{0}$).", "solution": "We are given a continuous-time, causal, linear time-invariant (LTI) system with the system function:\n$$\nH(s) = \\frac{\\omega_{0}^{2}}{s^{2}+\\omega_{0}^{2}}\n$$\nwhere $\\omega_{0}  0$ is a real constant. The input to the system is the unit step function $x(t) = u(t)$. The one-sided Laplace transform of the input is:\n$$\nX(s) = \\mathcal{L}\\{u(t)\\}(s) = \\frac{1}{s}\n$$\nThe Laplace transform of the output, $Y(s)$, is given by the product of the system function and the input transform:\n$$\nY(s) = H(s)X(s) = \\left( \\frac{\\omega_{0}^{2}}{s^{2}+\\omega_{0}^{2}} \\right) \\left( \\frac{1}{s} \\right) = \\frac{\\omega_{0}^{2}}{s(s^{2}+\\omega_{0}^{2})}\n$$\nTo find the output $y(t)$, we must compute the inverse Laplace transform of $Y(s)$. This is achieved through partial fraction expansion. We express $Y(s)$ in the form:\n$$\nY(s) = \\frac{A}{s} + \\frac{Bs+C}{s^{2}+\\omega_{0}^{2}}\n$$\nTo find the coefficient $A$, we use the residue method:\n$$\nA = sY(s)\\Big|_{s=0} = \\frac{\\omega_{0}^{2}}{s^{2}+\\omega_{0}^{2}}\\Big|_{s=0} = \\frac{\\omega_{0}^{2}}{0^{2}+\\omega_{0}^{2}} = 1\n$$\nSubstituting $A=1$ back into the expansion gives:\n$$\n\\frac{\\omega_{0}^{2}}{s(s^{2}+\\omega_{0}^{2})} = \\frac{1}{s} + \\frac{Bs+C}{s^{2}+\\omega_{0}^{2}}\n$$\nTo find $B$ and $C$, we can clear the denominators:\n$$\n\\omega_{0}^{2} = (s^{2}+\\omega_{0}^{2}) + s(Bs+C) = s^{2}+\\omega_{0}^{2} + Bs^{2} + Cs = (1+B)s^{2} + Cs + \\omega_{0}^{2}\n$$\nBy equating the coefficients of the powers of $s$ on both sides of the identity, we find:\nFor the $s^{2}$ term: $0 = 1+B \\implies B = -1$.\nFor the $s^{1}$ term: $0 = C$.\nThus, the partial fraction expansion of $Y(s)$ is:\n$$\nY(s) = \\frac{1}{s} - \\frac{s}{s^{2}+\\omega_{0}^{2}}\n$$\nNow, we compute the inverse Laplace transform term by term. For a causal system, we have:\n$$\n\\mathcal{L}^{-1}\\left\\{\\frac{1}{s}\\right\\} = u(t)\n$$\n$$\n\\mathcal{L}^{-1}\\left\\{\\frac{s}{s^{2}+\\omega_{0}^{2}}\\right\\} = \\cos(\\omega_{0}t)u(t)\n$$\nCombining these results, the output $y(t)$ is:\n$$\ny(t) = (1 - \\cos(\\omega_{0}t))u(t)\n$$\nNext, we analyze the long-time behavior of this output. We must evaluate the limit of $y(t)$ as $t \\to \\infty$:\n$$\n\\lim_{t\\to\\infty} y(t) = \\lim_{t\\to\\infty} (1 - \\cos(\\omega_{0}t))\n$$\nSince $\\omega_{0}  0$, the term $\\cos(\\omega_{0}t)$ oscillates continuously between $-1$ and $1$ as $t$ increases. It does not approach a constant value. Therefore, the limit $\\lim_{t\\to\\infty} y(t)$ does not exist. The output signal comprises a DC offset of $1$ and a sustained sinusoidal oscillation of frequency $\\omega_{0}$.\n\nNow, we apply the final value theorem (FVT). The theorem states that if all poles of $sY(s)$ lie in the open left-half of the complex plane (i.e., their real parts are strictly negative), then $\\lim_{t\\to\\infty} y(t) = \\lim_{s\\to 0} sY(s)$. The problem asks us to apply the formula regardless of its applicability.\nThe predicted value is:\n$$\n\\lim_{s\\to 0} sY(s) = \\lim_{s\\to 0} s \\left( \\frac{\\omega_{0}^{2}}{s(s^{2}+\\omega_{0}^{2})} \\right) = \\lim_{s\\to 0} \\frac{\\omega_{0}^{2}}{s^{2}+\\omega_{0}^{2}} = \\frac{\\omega_{0}^{2}}{0 + \\omega_{0}^{2}} = 1\n$$\nThe theorem predicts a final value of $1$. This contradicts our direct analysis of $y(t)$, which showed that the limit does not exist.\n\nThe failure of the theorem is explained by examining its preconditions. The theorem's validity depends on the locations of the poles of the function $sY(s)$. In this case:\n$$\nsY(s) = \\frac{\\omega_{0}^{2}}{s^{2}+\\omega_{0}^{2}}\n$$\nThe poles are the roots of the denominator $s^{2}+\\omega_{0}^{2} = 0$. This gives $s^{2} = -\\omega_{0}^{2}$, so the poles are located at $s = \\pm j\\omega_{0}$. These are a pair of distinct poles located on the imaginary axis.\n\nThe strict condition for the final value theorem is that all poles of $sY(s)$ must have negative real parts. Here, the real parts of the poles are zero, which violates this condition. Therefore, the final value theorem is not applicable, and its result is invalid.\n\nThe physical interpretation is direct. The system function $H(s)$ with poles at $\\pm j\\omega_{0}$ represents an undamped second-order system, such as a frictionless mass-spring system or an ideal LC resonant circuit. These poles on the imaginary axis correspond to a natural mode of oscillation that does not decay over time. When this system is excited by a step input, which can be seen as introducing a permanent forcing term, this undamped mode is excited, resulting in a sustained oscillation in the output. The output $y(t) = 1 - \\cos(\\omega_{0}t)$ for $t \\ge 0$ shows exactly this: a steady-state response of $1$ to the DC input, superposed with an undying oscillation $-\\cos(\\omega_{0}t)$ at the system's natural frequency. Since the system never settles to a constant value, a theorem designed to predict such a value cannot possibly apply. The presence of poles on the $j\\omega$-axis is the mathematical signature of this non-decaying oscillatory behavior.", "answer": "$$\\boxed{1}$$", "id": "2914336"}, {"introduction": "Beyond analyzing systems, the system function is a key tool for design, such as creating a filter to reverse a system's effect—a process called deconvolution. This practice challenges you to determine if a stable, causal inverse system exists for a given LTI system. Your analysis will reveal how the locations of a system's poles and zeros govern not only its theoretical invertibility but also the practical feasibility of the inverse, particularly its sensitivity to noise [@problem_id:2914340].", "problem": "Consider a discrete-time Linear Time-Invariant (LTI) system with system function (the bilateral $z$-transform of its impulse response) given by $H(z)=\\frac{1-0.5z^{-1}}{1-0.9z^{-1}}$. Starting only from the fundamental definitions that: (i) for an LTI system with input $x[n]$ and output $y[n]$, $y[n]=x[n]*h[n]$ where $*$ denotes convolution, (ii) the $z$-transform of a convolution satisfies $Y(z)=H(z)X(z)$ within the common region of convergence, and (iii) causality and bounded-input bounded-output (BIBO) stability for rational $H(z)$ are characterized by the location of poles and the region of convergence relative to the unit circle, determine whether there exists a causal, BIBO-stable inverse system with system function $G(z)$ such that $G(z)H(z)=1$ within a nonempty annular region that includes the unit circle. If such an inverse exists, construct $G(z)$ explicitly and specify a region of convergence that makes $G(z)$ causal and BIBO-stable. Then, discuss the implications for deconvolution, with attention to the sensitivity of $x[n]$ recovery from noisy observations of $y[n]$ when implementing $G(z)$ as a filter.\n\nExpress your final answer as a single closed-form rational expression in $z^{-1}$ for the inverse system function $G(z)$. No numerical rounding is required. No physical units are involved. The angle unit is radians if any frequency-domain reasoning is invoked in your discussion, but the final answer must be a system function in $z$-domain.", "solution": "The condition for an inverse system with system function $G(z)$ is that its product with the original system function $H(z)$ must be unity.\n$$\nG(z)H(z) = 1\n$$\nThis relationship implies that we can find the algebraic form of $G(z)$ by taking the reciprocal of $H(z)$:\n$$\nG(z) = \\frac{1}{H(z)} = \\frac{1}{\\frac{1-0.5z^{-1}}{1-0.9z^{-1}}} = \\frac{1-0.9z^{-1}}{1-0.5z^{-1}}\n$$\nThis expression gives the system function of the inverse system. Now, we must determine if this system can be both causal and BIBO-stable. The properties of causality and stability are not determined by the algebraic expression of the system function alone, but by its associated Region of Convergence (ROC).\n\nA discrete-time LTI system is BIBO-stable if and only if its impulse response $g[n]$ is absolutely summable, i.e., $\\sum_{n=-\\infty}^{\\infty} |g[n]|  \\infty$. For a rational system function, this is equivalent to the condition that the ROC of $G(z)$ must include the unit circle, $|z|=1$.\n\nA discrete-time LTI system with a rational system function is causal if and only if its ROC is the exterior of a circle that passes through the pole with the largest magnitude, including the point $z=\\infty$. That is, the ROC is of the form $|z|  |p_{max}|$, where $p_{max}$ is the outermost pole of the system.\n\nFor a system to be both causal and BIBO-stable, both conditions must be met simultaneously. This means the ROC must be of the form $|z|  |p_{max}|$ and must also contain the unit circle $|z|=1$. This can only be true if $|p_{max}|  1$. In other words, a rational LTI system is both causal and BIBO-stable if and only if all of its poles lie inside the unit circle.\n\nLet us analyze the poles and zeros of the inverse system $G(z) = \\frac{1-0.9z^{-1}}{1-0.5z^{-1}}$.\nThe poles are the roots of the denominator polynomial:\n$$\n1-0.5z^{-1} = 0 \\implies 1 = 0.5z^{-1} \\implies z = 0.5\n$$\nThe system $G(z)$ has a single pole at $z=0.5$.\nThe zeros are the roots of the numerator polynomial:\n$$\n1-0.9z^{-1} = 0 \\implies 1 = 0.9z^{-1} \\implies z = 0.9\n$$\nThe system $G(z)$ has a single zero at $z=0.9$.\n\nTo check for the existence of a causal, BIBO-stable inverse system, we examine the location of the poles of $G(z)$. The only pole is at $z=0.5$. The magnitude of this pole is $|0.5|=0.5$. Since $0.5  1$, the pole lies strictly inside the unit circle. Therefore, it is possible to specify an ROC for $G(z)$ that makes the system both causal and stable.\n\nThe ROC for a causal system must be $|z|  |p_{max}|$. Here, $|p_{max}|=0.5$, so the ROC for causality is $|z|  0.5$.\nThis ROC, $|z|  0.5$, contains the unit circle $|z|=1$, which is the condition for BIBO stability.\nThus, a causal and BIBO-stable inverse system $G(z)$ exists, and its ROC is $|z|  0.5$. The requirement that the product $G(z)H(z)=1$ holds in a region including the unit circle is also satisfied, as the ROC for a causal and stable $H(z)$ is $|z|0.9$ and the ROC for a causal and stable $G(z)$ is $|z|0.5$, so their common ROC is $|z|0.9$, which includes the unit circle.\n\nFinally, we discuss the implications for deconvolution and sensitivity to noise.\nDeconvolution is the process of recovering an input signal $x[n]$ from a measured output signal $y[n]$, given knowledge of the system $H(z)$. In the $z$-domain, this is achieved by $X(z) = G(z)Y(z)$. Since we have found a causal and stable inverse filter $G(z)$, it is theoretically possible to recover $x[n]$ from $y[n]$ by filtering $y[n]$ with $g[n]$, the impulse response of $G(z)$.\n\nHowever, practical implementation is subject to noise. Let the observed output be $y_{obs}[n] = y[n] + w[n]$, where $w[n]$ is some additive noise. The recovered input will be:\n$$\n\\hat{x}[n] = g[n] * y_{obs}[n] = g[n] * (x[n]*h[n] + w[n]) = (g[n]*h[n])*x[n] + g[n]*w[n] = x[n] + g[n]*w[n]\n$$\nThe error in the reconstruction is the filtered noise, $g[n]*w[n]$. The severity of this error depends on the frequency response of the inverse filter, $G(e^{j\\omega})$. Let us examine it.\n$$\n|G(e^{j\\omega})| = \\left| \\frac{1-0.9e^{-j\\omega}}{1-0.5e^{-j\\omega}} \\right|\n$$\nThe original system $H(z)$ has a pole at $z=0.9$, which is close to the unit circle. This creates a large amplification for frequencies near $\\omega=0$ (DC). Specifically, $|H(e^{j0})| = \\frac{|1-0.5|}{|1-0.9|} = \\frac{0.5}{0.1} = 5$. $H(z)$ acts as a low-pass filter.\nConsequently, its inverse $G(z)$ must perform the opposite operation. It has a zero at $z=0.9$, which creates a deep null near $\\omega=0$. At DC, $|G(e^{j0})| = \\frac{|1-0.9|}{|1-0.5|} = \\frac{0.1}{0.5} = 0.2$. At high frequencies, for example $\\omega=\\pi$, $|G(e^{j\\pi})| = \\frac{|1-0.9(-1)|}{|1-0.5(-1)|} = \\frac{1.9}{1.5} \\approx 1.267$. The inverse filter $G(z)$ acts as a high-pass filter.\n\nThe implication is severe. The original system $H(z)$ strongly attenuates the high-frequency content of the input signal $x[n]$. To recover this content, the inverse filter $G(z)$ must provide significant amplification at high frequencies. If the measurement noise $w[n]$ is broadband (e.g., white noise), its high-frequency components will be greatly amplified by the inverse filter. This amplified noise can easily dominate the restored signal, rendering the deconvolution ineffective. This is a classic example of an ill-conditioned inverse problem. The sensitivity arises because the original system has a pole close to the unit circle, or equivalently, a frequency response that is far from flat. Any attempt to perfectly invert such a system will invariably lead to noise amplification in the frequency bands that the original system attenuated.", "answer": "$$\n\\boxed{\\frac{1-0.9z^{-1}}{1-0.5z^{-1}}}\n$$", "id": "2914340"}]}