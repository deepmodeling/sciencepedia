{"hands_on_practices": [{"introduction": "The foundation of many uncertainty quantification workflows is the Monte Carlo method, where a system is repeatedly simulated to generate a sample of possible outcomes. However, a raw collection of samples is not the end of the analysis. This practice guides you through the essential statistical reasoning required to turn simulation outputs into a meaningful engineering conclusion, deriving an asymptotic confidence interval for the mean response from first principles [@problem_id:2707385]. Mastering this derivation, which bridges the Central Limit Theorem with practical estimation, is fundamental to interpreting any sampling-based UQ study.", "problem": "A linear elastic cantilever beam with deterministic geometry and loading is made of a material whose Young’s modulus is random due to manufacturing variability. Let the compliance, defined as the work conjugate to the applied load, be the scalar quantity $C = \\mathbf{f}^{\\top}\\mathbf{u}$, where $\\mathbf{f}$ is the applied nodal force vector and $\\mathbf{u}$ is the resulting nodal displacement vector obtained by solving the deterministic equilibrium equations for a realization of the Young’s modulus field. Suppose that $C$ is a real-valued random variable with finite mean $\\mu_{C} = \\mathbb{E}[C]$ and finite, strictly positive variance $\\sigma_{C}^{2} = \\mathrm{Var}(C)$, and that independent and identically distributed realizations $\\{C_{i}\\}_{i=1}^{n}$ are obtained by repeated experiments or simulations under the same load and geometry.\n\nDefine the sample mean estimator of the compliance by $\\bar{C}_{n} = \\frac{1}{n}\\sum_{i=1}^{n} C_{i}$ and the sample variance by $s_{n}^{2} = \\frac{1}{n-1}\\sum_{i=1}^{n} (C_{i} - \\bar{C}_{n})^{2}$.\n\nStarting from the assumptions of independence, identical distribution, and the finiteness of $\\sigma_{C}^{2}$, derive the limiting distribution of the standardized sample mean $\\sqrt{n}\\left(\\bar{C}_{n} - \\mu_{C}\\right)$ as $n \\to \\infty$. Then, use this limiting distribution together with appropriate probability limit arguments to construct an asymptotic $(1-\\alpha)$ confidence interval for $\\mu_{C}$ in terms of $\\bar{C}_{n}$, $s_{n}$, $n$, and the $(1-\\alpha/2)$ quantile of the standard normal distribution. Clearly state any regularity condition you invoke.\n\nReport the final confidence interval endpoints as a row matrix with two entries in the following order: $[$lower endpoint, upper endpoint$]$. Do not include units. If you choose to use the standard normal quantile, denote it by $z_{1-\\alpha/2}$, where $z_{1-\\alpha/2}$ is the unique real number such that $\\Phi(z_{1-\\alpha/2}) = 1-\\alpha/2$ and $\\Phi$ is the cumulative distribution function of the standard normal distribution. No numerical rounding is required; provide a closed-form analytic expression.", "solution": "The problem statement is subjected to validation.\n\n**Step 1: Extract Givens**\n-   The quantity of interest is compliance, $C = \\mathbf{f}^{\\top}\\mathbf{u}$.\n-   The applied nodal force vector $\\mathbf{f}$ and the beam geometry are deterministic.\n-   The Young's modulus is a random variable, making the displacement vector $\\mathbf{u}$ and thus the compliance $C$ random variables.\n-   $C$ is a real-valued random variable with a finite mean $\\mu_{C} = \\mathbb{E}[C]$ and a finite, strictly positive variance $\\sigma_{C}^{2} = \\mathrm{Var}(C) > 0$.\n-   A set of observations $\\{C_{i}\\}_{i=1}^{n}$ are independent and identically distributed (i.i.d.) realizations of $C$.\n-   The sample mean estimator is $\\bar{C}_{n} = \\frac{1}{n}\\sum_{i=1}^{n} C_{i}$.\n-   The sample variance estimator is $s_{n}^{2} = \\frac{1}{n-1}\\sum_{i=1}^{n} (C_{i} - \\bar{C}_{n})^{2}$.\n-   The objective is to derive the limiting distribution of the standardized sample mean $\\sqrt{n}\\left(\\bar{C}_{n} - \\mu_{C}\\right)$ as $n \\to \\infty$.\n-   The second objective is to construct an asymptotic $(1-\\alpha)$ confidence interval for $\\mu_{C}$ using $\\bar{C}_{n}$, $s_{n}$, $n$, and the $(1-\\alpha/2)$ quantile of the standard normal distribution, denoted $z_{1-\\alpha/2}$.\n\n**Step 2: Validate Using Extracted Givens**\nThe problem is scientifically grounded, arising from the common practice of uncertainty quantification in mechanics using stochastic models. It is well-posed, providing the necessary and sufficient conditions to solve the problem using foundational statistical theorems. The language is objective and precise. The problem is self-contained, consistent, and does not contain any of the flaws listed in the validation criteria.\n\n**Step 3: Verdict and Action**\nThe problem is valid. A solution will be constructed.\n\n**Derivation**\n\nThe solution proceeds in two parts. First, we derive the limiting distribution of the standardized sample mean. Second, we use this result to construct the asymptotic confidence interval for the true mean $\\mu_{C}$.\n\n**Part 1: Limiting Distribution of the Standardized Sample Mean**\n\nWe are given a sequence of random variables $\\{C_{i}\\}_{i=1}^{n}$ that are independent and identically distributed (i.i.d.). The problem statement specifies that their common mean is $\\mathbb{E}[C_{i}] = \\mu_{C}$ and their common variance is $\\mathrm{Var}(C_{i}) = \\sigma_{C}^{2}$. Crucially, it is given that the mean $\\mu_{C}$ is finite and the variance $\\sigma_{C}^{2}$ is finite and strictly positive ($0  \\sigma_{C}^{2}  \\infty$).\n\nThese are the precise hypotheses of the Lindeberg-Lévy Central Limit Theorem (CLT). The theorem states that for a sequence of i.i.d. random variables $\\{C_{i}\\}$ with finite mean $\\mu_{C}$ and finite non-zero variance $\\sigma_{C}^{2}$, the standardized sample mean converges in distribution to a standard normal distribution as the sample size $n$ approaches infinity. Mathematically, this is expressed as:\n$$\n\\frac{\\bar{C}_{n} - \\mu_{C}}{\\sigma_{C} / \\sqrt{n}} = \\frac{\\sqrt{n}\\left(\\bar{C}_{n} - \\mu_{C}\\right)}{\\sigma_{C}} \\xrightarrow{d} \\mathcal{N}(0, 1) \\quad \\text{as } n \\to \\infty\n$$\nwhere $\\xrightarrow{d}$ denotes convergence in distribution, and $\\mathcal{N}(0, 1)$ is the standard normal distribution with mean $0$ and variance $1$.\n\nThe problem asks for the limiting distribution of the quantity $\\sqrt{n}\\left(\\bar{C}_{n} - \\mu_{C}\\right)$. Using the properties of convergence in distribution, if a random variable $X_{n} \\xrightarrow{d} X$, then for any constant $c$, $c X_{n} \\xrightarrow{d} c X$. Applying this with the constant $\\sigma_C$, we have:\n$$\n\\sqrt{n}\\left(\\bar{C}_{n} - \\mu_{C}\\right) = \\sigma_{C} \\left( \\frac{\\sqrt{n}\\left(\\bar{C}_{n} - \\mu_{C}\\right)}{\\sigma_{C}} \\right) \\xrightarrow{d} \\sigma_{C} \\cdot \\mathcal{N}(0, 1)\n$$\nA random variable $Y = cZ$, where $Z \\sim \\mathcal{N}(0, 1)$, is normally distributed with mean $\\mathbb{E}[Y] = c \\mathbb{E}[Z] = 0$ and variance $\\mathrm{Var}(Y) = c^2 \\mathrm{Var}(Z) = c^2$. Therefore, the limiting distribution is a normal distribution with mean $0$ and variance $\\sigma_{C}^{2}$.\n$$\n\\sqrt{n}\\left(\\bar{C}_{n} - \\mu_{C}\\right) \\xrightarrow{d} \\mathcal{N}(0, \\sigma_{C}^{2})\n$$\n\n**Part 2: Construction of the Asymptotic Confidence Interval**\n\nTo construct a confidence interval for $\\mu_{C}$, we need a pivotal quantity whose distribution is known and independent of unknown parameters. From Part 1, the quantity $\\frac{\\sqrt{n}\\left(\\bar{C}_{n} - \\mu_{C}\\right)}{\\sigma_{C}}$ converges to a standard normal distribution. However, the population standard deviation $\\sigma_{C}$ is unknown. We must replace it with a consistent estimator.\n\nThe problem provides the sample variance $s_{n}^{2} = \\frac{1}{n-1}\\sum_{i=1}^{n} (C_{i} - \\bar{C}_{n})^{2}$. For i.i.d. random variables with finite variance $\\sigma_{C}^{2}$, the sample variance $s_{n}^{2}$ is a consistent estimator of the population variance $\\sigma_{C}^{2}$. This is a standard result derived from the Law of Large Numbers. Formally:\n$$\ns_{n}^{2} \\xrightarrow{p} \\sigma_{C}^{2} \\quad \\text{as } n \\to \\infty\n$$\nwhere $\\xrightarrow{p}$ denotes convergence in probability.\n\nSince the square root function $g(x)=\\sqrt{x}$ is continuous for $x \\ge 0$, and $\\sigma_C^2 > 0$, the Continuous Mapping Theorem ensures that convergence in probability is preserved. Therefore, the sample standard deviation $s_{n}$ is a consistent estimator for the population standard deviation $\\sigma_{C}$:\n$$\ns_{n} = \\sqrt{s_{n}^{2}} \\xrightarrow{p} \\sqrt{\\sigma_{C}^{2}} = \\sigma_{C} \\quad \\text{as } n \\to \\infty\n$$\n\nWe now construct the studentized statistic by replacing the unknown $\\sigma_{C}$ with its consistent estimator $s_{n}$:\n$$\nT_{n} = \\frac{\\sqrt{n}\\left(\\bar{C}_{n} - \\mu_{C}\\right)}{s_{n}}\n$$\nTo find the limiting distribution of $T_{n}$, we invoke Slutsky's Theorem. The theorem states that if $X_{n} \\xrightarrow{d} X$ and $Y_{n} \\xrightarrow{p} c$ for some constant $c \\neq 0$, then $\\frac{X_{n}}{Y_{n}} \\xrightarrow{d} \\frac{X}{c}$. Let $X_{n} = \\sqrt{n}\\left(\\bar{C}_{n} - \\mu_{C}\\right)$ and $Y_{n} = s_{n}$. We have established that:\n1.  $X_{n} \\xrightarrow{d} \\mathcal{N}(0, \\sigma_{C}^{2})$\n2.  $Y_{n} \\xrightarrow{p} \\sigma_{C}$ (a non-zero constant, since $\\sigma_C^2 > 0$)\n\nApplying Slutsky's Theorem:\n$$\nT_{n} = \\frac{\\sqrt{n}\\left(\\bar{C}_{n} - \\mu_{C}\\right)}{s_{n}} \\xrightarrow{d} \\frac{\\mathcal{N}(0, \\sigma_{C}^{2})}{\\sigma_{C}}\n$$\nThe resulting distribution is $\\frac{1}{\\sigma_C}$ times a $\\mathcal{N}(0, \\sigma_C^2)$ random variable, which is $\\mathcal{N}(0, (\\frac{1}{\\sigma_C})^2 \\sigma_C^2) = \\mathcal{N}(0, 1)$. Thus, the studentized statistic converges in distribution to the standard normal distribution:\n$$\n\\frac{\\sqrt{n}\\left(\\bar{C}_{n} - \\mu_{C}\\right)}{s_{n}} \\xrightarrow{d} \\mathcal{N}(0, 1)\n$$\nFor a large sample size $n$, we can approximate the distribution of $T_{n}$ by the standard normal distribution. An asymptotic $(1-\\alpha)$ confidence interval for $\\mu_{C}$ is constructed by finding values that bound the middle $(1-\\alpha)$ probability mass of the standard normal distribution. Let $z_{1-\\alpha/2}$ be the $(1-\\alpha/2)$ quantile of the standard normal distribution, such that $P(Z \\le z_{1-\\alpha/2}) = 1-\\alpha/2$ where $Z \\sim \\mathcal{N}(0, 1)$. By the symmetry of the normal distribution, the lower quantile is $-z_{1-\\alpha/2}$.\n\nWe can write the following approximate probability statement for large $n$:\n$$\nP\\left(-z_{1-\\alpha/2} \\le \\frac{\\sqrt{n}\\left(\\bar{C}_{n} - \\mu_{C}\\right)}{s_{n}} \\le z_{1-\\alpha/2}\\right) \\approx 1-\\alpha\n$$\nTo obtain the confidence interval for $\\mu_{C}$, we isolate $\\mu_{C}$ in the inequality:\n$$\n-z_{1-\\alpha/2} \\frac{s_{n}}{\\sqrt{n}} \\le \\bar{C}_{n} - \\mu_{C} \\le z_{1-\\alpha/2} \\frac{s_{n}}{\\sqrt{n}}\n$$\nSubtracting $\\bar{C}_{n}$ from all parts:\n$$\n-\\bar{C}_{n} - z_{1-\\alpha/2} \\frac{s_{n}}{\\sqrt{n}} \\le - \\mu_{C} \\le -\\bar{C}_{n} + z_{1-\\alpha/2} \\frac{s_{n}}{\\sqrt{n}}\n$$\nMultiplying by $-1$ and reversing the direction of the inequalities gives:\n$$\n\\bar{C}_{n} - z_{1-\\alpha/2} \\frac{s_{n}}{\\sqrt{n}} \\le \\mu_{C} \\le \\bar{C}_{n} + z_{1-\\alpha/2} \\frac{s_{n}}{\\sqrt{n}}\n$$\nThis defines the endpoints of the asymptotic $(1-\\alpha)$ confidence interval for $\\mu_{C}$. The lower endpoint is $\\bar{C}_{n} - z_{1-\\alpha/2} \\frac{s_{n}}{\\sqrt{n}}$ and the upper endpoint is $\\bar{C}_{n} + z_{1-\\alpha/2} \\frac{s_{n}}{\\sqrt{n}}$.", "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n\\bar{C}_{n} - z_{1-\\alpha/2} \\frac{s_{n}}{\\sqrt{n}}  \\bar{C}_{n} + z_{1-\\alpha/2} \\frac{s_{n}}{\\sqrt{n}}\n\\end{pmatrix}\n}\n$$", "id": "2707385"}, {"introduction": "While powerful, Monte Carlo simulation can be computationally prohibitive for estimating the probability of rare failure events. The First-Order Reliability Method (FORM) offers an elegant and efficient alternative by approximating the failure surface in a transformed probability space. This exercise takes you into the core mathematical engine of FORM: the isoprobabilistic transformation, which maps random variables from their physical distributions to a standard normal space where analysis is simplified [@problem_id:2707508]. By deriving this mapping for a lognormal variable and computing the gradient of the limit-state function, you will perform the key steps required to locate the most probable point of failure.", "problem": "A straight prismatic bar of length $L$ and cross-sectional area $A$ is subjected to an axial tensile force $P$. The axial displacement at the loaded end under linear elasticity is $ \\delta = \\dfrac{P L}{A E} $, where $E$ is the Young’s modulus. Consider the serviceability limit-state function $g(E) = \\delta_{\\max} - \\dfrac{P L}{A E}$ with deterministic threshold $ \\delta_{\\max} $. The material Young’s modulus $E$ is uncertain and modeled as a lognormal random variable with mean $m_{E}$ and coefficient of variation $c_{E}$. Assume there is no correlation with any other variable.\n\nThe First-Order Reliability Method (FORM) is to be applied in the standard normal space. The isoprobabilistic mapping must be constructed from the fundamental definition of a lognormal distribution via its underlying normal variable and the probability integral transform. In particular, start from the definition that $Y = \\ln E$ is normally distributed and use the relationships implied by $m_{E} = \\mathbb{E}[E]$ and $\\mathrm{Var}[E] = c_{E}^{2} m_{E}^{2}$ to determine the parameters of $Y$. Then form the mapping to a standard normal variable $U$.\n\nParameters:\n- $L = 2\\,\\mathrm{m}$,\n- $A = 1.0 \\times 10^{-3}\\,\\mathrm{m}^{2}$,\n- $P = 1.0 \\times 10^{5}\\,\\mathrm{N}$,\n- $\\delta_{\\max} = 2.0 \\times 10^{-3}\\,\\mathrm{m}$,\n- $m_{E} = 2.10 \\times 10^{11}\\,\\mathrm{Pa}$,\n- $c_{E} = 0.10$.\n\nTasks:\n1) Using only the definition of a lognormal variable $E = \\exp(Y)$ with $Y$ normal and the properties $m_{E} = \\mathbb{E}[E]$ and $\\mathrm{Var}[E] = \\mathbb{E}[E^{2}] - (\\mathbb{E}[E])^{2}$, derive the isoprobabilistic mapping $U \\mapsto E(U)$ that transforms the standard normal variable $U \\sim \\mathcal{N}(0,1)$ to $E$. Clearly identify the intermediate normal parameters of $Y$ in terms of $m_{E}$ and $c_{E}$, and write the final mapping $E(U)$.\n\n2) Define $G(U) = g(E(U))$ and compute the scalar gradient mapping $\\dfrac{\\mathrm{d}G}{\\mathrm{d}U}$ evaluated at $U = 0$. Express your final numerical answer in millimeters and round to four significant figures. State the value as a single number as instructed. The angle unit is not applicable here.", "solution": "The problem statement has been evaluated and is found to be scientifically grounded, well-posed, and objective. It contains a complete and consistent set of givens, allowing for a unique and meaningful solution. The problem is a standard exercise in structural reliability and uncertainty quantification, based on fundamental principles of solid mechanics and probability theory. Therefore, I will proceed with the solution.\n\nThe task is divided into two parts. First, we must derive the isoprobabilistic transformation for the Young's modulus, $E$. Second, we must compute the gradient of the limit-state function in the standard normal space at the origin.\n\nPart 1: Derivation of the Isoprobabilistic Mapping $U \\mapsto E(U)$\n\nThe Young's modulus, $E$, is a lognormal random variable. This means its natural logarithm, $Y = \\ln E$, follows a normal distribution, denoted as $Y \\sim \\mathcal{N}(\\mu_{Y}, \\sigma_{Y}^{2})$, where $\\mu_{Y}$ and $\\sigma_{Y}$ are the mean and standard deviation of $Y$. The problem requires us to determine $\\mu_{Y}$ and $\\sigma_{Y}$ from the given mean $m_{E} = \\mathbb{E}[E]$ and coefficient of variation $c_{E}$ of $E$.\n\nThe fundamental relationships between the parameters of a lognormal variable $E$ and its underlying normal variable $Y$ are:\n$$\nm_{E} = \\mathbb{E}[E] = \\exp\\left(\\mu_{Y} + \\frac{1}{2}\\sigma_{Y}^{2}\\right)\n$$\n$$\n\\mathrm{Var}[E] = \\mathbb{E}[E^2] - (\\mathbb{E}[E])^2 = \\left(\\exp(\\sigma_{Y}^{2}) - 1\\right) \\exp\\left(2\\mu_{Y} + \\sigma_{Y}^{2}\\right) = \\left(\\exp(\\sigma_{Y}^{2}) - 1\\right) m_{E}^{2}\n$$\nThe coefficient of variation, $c_{E}$, is defined as the ratio of the standard deviation of $E$ to its mean:\n$$\nc_{E} = \\frac{\\sqrt{\\mathrm{Var}[E]}}{m_{E}}\n$$\nSquaring this expression and substituting the variance gives:\n$$\nc_{E}^{2} = \\frac{\\mathrm{Var}[E]}{m_{E}^{2}} = \\frac{\\left(\\exp(\\sigma_{Y}^{2}) - 1\\right) m_{E}^{2}}{m_{E}^{2}} = \\exp(\\sigma_{Y}^{2}) - 1\n$$\nFrom this, we solve for the parameter $\\sigma_{Y}^{2}$:\n$$\n\\sigma_{Y}^{2} = \\ln(c_{E}^{2} + 1)\n$$\nAnd consequently, the standard deviation $\\sigma_{Y}$ is:\n$$\n\\sigma_{Y} = \\sqrt{\\ln(c_{E}^{2} + 1)}\n$$\nNow, we use the expression for the mean $m_{E}$ to find $\\mu_{Y}$:\n$$\n\\ln(m_{E}) = \\mu_{Y} + \\frac{1}{2}\\sigma_{Y}^{2}\n$$\nSolving for $\\mu_{Y}$:\n$$\n\\mu_{Y} = \\ln(m_{E}) - \\frac{1}{2}\\sigma_{Y}^{2}\n$$\nSubstituting the expression for $\\sigma_{Y}^{2}$:\n$$\n\\mu_{Y} = \\ln(m_{E}) - \\frac{1}{2}\\ln(c_{E}^{2} + 1) = \\ln\\left(\\frac{m_{E}}{\\sqrt{c_{E}^{2} + 1}}\\right)\n$$\nThe isoprobabilistic mapping transforms a standard normal variable $U \\sim \\mathcal{N}(0,1)$ to the physical variable $E$. This is achieved by first transforming $U$ to the intermediate normal variable $Y$ and then to $E$. The transformation from $U$ to $Y$ is:\n$$\nY(U) = \\mu_{Y} + \\sigma_{Y} U\n$$\nThe transformation from $Y$ to $E$ is given by the definition of the lognormal distribution:\n$$\nE(U) = \\exp(Y(U)) = \\exp(\\mu_{Y} + \\sigma_{Y} U)\n$$\nThis is the final form of the isoprobabilistic mapping $U \\mapsto E(U)$, with the parameters $\\mu_{Y}$ and $\\sigma_{Y}$ fully defined in terms of the initial givens $m_{E}$ and $c_{E}$.\n\nPart 2: Computation of the Gradient $\\dfrac{\\mathrm{d}G}{\\mathrm{d}U}$ at $U=0$\n\nThe limit-state function in the physical space is $g(E) = \\delta_{\\max} - \\dfrac{P L}{A E}$. We transform this into the standard normal space by substituting the mapping $E(U)$:\n$$\nG(U) = g(E(U)) = \\delta_{\\max} - \\frac{P L}{A E(U)} = \\delta_{\\max} - \\frac{P L}{A \\exp(\\mu_{Y} + \\sigma_{Y} U)}\n$$\nTo facilitate differentiation, we rewrite the expression as:\n$$\nG(U) = \\delta_{\\max} - \\frac{PL}{A} \\exp(-\\mu_{Y} - \\sigma_{Y} U)\n$$\nNow, we compute the derivative of $G(U)$ with respect to $U$ using the chain rule:\n$$\n\\frac{\\mathrm{d}G}{\\mathrm{d}U} = \\frac{\\mathrm{d}}{\\mathrm{d}U} \\left( \\delta_{\\max} - \\frac{PL}{A} \\exp(-\\mu_{Y} - \\sigma_{Y} U) \\right)\n$$\n$$\n\\frac{\\mathrm{d}G}{\\mathrm{d}U} = 0 - \\frac{PL}{A} \\left[ \\exp(-\\mu_{Y} - \\sigma_{Y} U) \\cdot (-\\sigma_{Y}) \\right] = \\frac{PL\\sigma_{Y}}{A} \\exp(-\\mu_{Y} - \\sigma_{Y} U)\n$$\nWe must evaluate this gradient at $U=0$:\n$$\n\\left. \\frac{\\mathrm{d}G}{\\mathrm{d}U} \\right|_{U=0} = \\frac{PL\\sigma_{Y}}{A} \\exp(-\\mu_{Y})\n$$\nWe can substitute the expression for $\\exp(-\\mu_{Y})$ derived from $\\mu_{Y} = \\ln\\left(\\frac{m_{E}}{\\sqrt{c_{E}^{2} + 1}}\\right)$:\n$$\n\\exp(-\\mu_{Y}) = \\exp\\left(-\\ln\\left(\\frac{m_{E}}{\\sqrt{c_{E}^{2} + 1}}\\right)\\right) = \\frac{\\sqrt{c_{E}^{2} + 1}}{m_{E}}\n$$\nSubstituting this and the expression for $\\sigma_{Y}$ into the gradient equation:\n$$\n\\left. \\frac{\\mathrm{d}G}{\\mathrm{d}U} \\right|_{U=0} = \\frac{PL}{A} \\left( \\sqrt{\\ln(c_{E}^{2} + 1)} \\right) \\left( \\frac{\\sqrt{c_{E}^{2} + 1}}{m_{E}} \\right) = \\frac{PL}{A m_{E}} \\sqrt{(c_{E}^{2} + 1)\\ln(c_{E}^{2} + 1)}\n$$\nNow, we substitute the numerical values provided:\n$P = 1.0 \\times 10^{5}\\,\\mathrm{N}$, $L = 2\\,\\mathrm{m}$, $A = 1.0 \\times 10^{-3}\\,\\mathrm{m}^{2}$, $m_{E} = 2.10 \\times 10^{11}\\,\\mathrm{Pa}$, $c_{E} = 0.10$.\n\nFirst, compute the parameters for the underlying normal distribution:\n$$\nc_{E}^{2} = (0.10)^{2} = 0.01\n$$\n$$\n\\sigma_{Y} = \\sqrt{\\ln((0.10)^{2} + 1)} = \\sqrt{\\ln(1.01)} \\approx 0.0997513\\,\\text{(dimensionless)}\n$$\nNext, calculate the terms in the gradient expression:\n$$\n\\frac{PL}{A m_{E}} = \\frac{(1.0 \\times 10^{5}\\,\\mathrm{N}) (2\\,\\mathrm{m})}{(1.0 \\times 10^{-3}\\,\\mathrm{m}^2) (2.10 \\times 10^{11}\\,\\mathrm{N/m}^2)} = \\frac{2.0 \\times 10^{5}}{2.10 \\times 10^{8}}\\,\\mathrm{m} \\approx 9.52381 \\times 10^{-4}\\,\\mathrm{m}\n$$\nThe evaluation of $\\exp(-\\mu_Y)$ gives:\n$$\n\\exp(-\\mu_{Y}) = \\frac{\\sqrt{(0.10)^2 + 1}}{2.10 \\times 10^{11}\\,\\mathrm{Pa}} = \\frac{\\sqrt{1.01}}{2.10 \\times 10^{11}\\,\\mathrm{Pa}} \\approx \\frac{1.00498756}{2.10 \\times 10^{11}}\\,\\mathrm{Pa}^{-1} \\approx 4.785655 \\times 10^{-12}\\,\\mathrm{Pa}^{-1}\n$$\nCombining these results to find the gradient:\n$$\n\\left. \\frac{\\mathrm{d}G}{\\mathrm{d}U} \\right|_{U=0} = \\frac{PL\\sigma_{Y}}{A} \\exp(-\\mu_{Y})\n$$\nThe term $\\frac{PL}{A}$ is:\n$$\n\\frac{PL}{A} = \\frac{(1.0 \\times 10^{5}\\,\\mathrm{N}) (2\\,\\mathrm{m})}{1.0 \\times 10^{-3}\\,\\mathrm{m}^2} = 2.0 \\times 10^8\\,\\mathrm{N/m}\n$$\nSo the gradient is:\n$$\n(2.0 \\times 10^8\\,\\mathrm{N/m}) \\cdot (0.0997513) \\cdot (4.785655 \\times 10^{-12}\\,\\mathrm{Pa}^{-1})\n$$\nSince $1\\,\\mathrm{Pa} = 1\\,\\mathrm{N/m}^2$, the units are $\\mathrm{(N/m) \\cdot (m^2/N) = m}$.\n$$\n\\left. \\frac{\\mathrm{d}G}{\\mathrm{d}U} \\right|_{U=0} \\approx (2.0 \\times 10^8) \\cdot (0.0997513) \\cdot (4.785655 \\times 10^{-12}) \\,\\mathrm{m} \\approx 9.54756 \\times 10^{-5}\\,\\mathrm{m}\n$$\nThe problem requires the answer in millimeters. $1\\,\\mathrm{mm} = 10^{-3}\\,\\mathrm{m}$.\n$$\n9.54756 \\times 10^{-5}\\,\\mathrm{m} = 0.0954756\\,\\mathrm{mm}\n$$\nRounding to four significant figures gives $0.09548\\,\\mathrm{mm}$.", "answer": "$$\n\\boxed{0.09548}\n$$", "id": "2707508"}, {"introduction": "The previous practices represent \"non-intrusive\" methods, which treat the deterministic mechanics solver as a black box. We now explore a powerful \"intrusive\" approach, the Stochastic Galerkin Method, where uncertainty is woven directly into the fabric of the governing equations. This advanced exercise challenges you to reformulate the weak form of linear elasticity to accommodate a random Young's modulus represented by a Polynomial Chaos Expansion [@problem_id:2707533]. By performing a Galerkin projection in both the spatial and stochastic domains, you will derive the final coupled algebraic system, revealing how uncertainty transforms a standard finite element problem into a larger, interconnected system that solves for the stochastic response directly.", "problem": "Consider small-strain linear elasticity on a bounded Lipschitz domain $\\mathcal{D}\\subset\\mathbb{R}^{d}$ with $d\\in\\{2,3\\}$. Let $\\partial\\mathcal{D} = \\Gamma_{D}\\cup\\Gamma_{N}$, with prescribed displacement $\\mathbf{u}=\\mathbf{0}$ on $\\Gamma_{D}$ and prescribed traction $\\mathbf{t}(\\mathbf{x})$ on $\\Gamma_{N}$. The body force $\\mathbf{b}(\\mathbf{x})$ is deterministic. The displacement field is $\\mathbf{u}(\\mathbf{x},\\omega)$, the infinitesimal strain is $\\boldsymbol{\\varepsilon}(\\mathbf{u}) = \\tfrac{1}{2}(\\nabla\\mathbf{u} + \\nabla\\mathbf{u}^{\\top})$, and the Cauchy stress is $\\boldsymbol{\\sigma}(\\mathbf{x},\\omega) = \\mathbb{C}(\\mathbf{x},\\omega) : \\boldsymbol{\\varepsilon}(\\mathbf{u}(\\mathbf{x},\\omega))$, where the fourth-order elasticity tensor $\\mathbb{C}(\\mathbf{x},\\omega)$ is assumed isotropic with fixed Poisson ratio $\\nu\\in(-1,0.5)$ and random Young’s modulus $E(\\mathbf{x},\\omega)$. Under this assumption, write $\\mathbb{C}(\\mathbf{x},\\omega) = E(\\mathbf{x},\\omega)\\,\\mathbb{C}_{0}$, where $\\mathbb{C}_{0}$ depends only on $\\nu$ and the spatial dimension $d$.\n \nStarting from the balance of linear momentum and standard variational principles, derive the deterministic weak form and then formulate the Stochastic Galerkin (SG) method with a Polynomial Chaos Expansion (PCE) for the random fields. Assume that there exists a finite-dimensional random vector $\\boldsymbol{\\xi}(\\omega)\\in\\mathbb{R}^{m}$ with known joint probability density such that both the coefficient field and the displacement admit truncated PCEs in an orthonormal polynomial basis $\\{\\Psi_{\\alpha}(\\boldsymbol{\\xi})\\}_{\\alpha=0}^{P-1}$:\n- $E(\\mathbf{x},\\omega) \\approx \\displaystyle\\sum_{q=0}^{Q} E^{(q)}(\\mathbf{x})\\,\\Psi_{q}(\\boldsymbol{\\xi}(\\omega))$,\n- $\\mathbf{u}(\\mathbf{x},\\omega) \\approx \\displaystyle\\sum_{i=0}^{P-1} \\mathbf{u}_{i}(\\mathbf{x})\\,\\Psi_{i}(\\boldsymbol{\\xi}(\\omega))$,\nwith orthonormality $\\langle \\Psi_{i}\\Psi_{j}\\rangle = \\delta_{ij}$ with respect to the probability measure of $\\boldsymbol{\\xi}$. Here $\\langle\\cdot\\rangle$ denotes expectation, and $\\delta_{ij}$ is the Kronecker delta.\n\nThen, apply a conforming Finite Element (FE) discretization with vector-valued shape functions $\\{\\boldsymbol{\\varphi}_{a}(\\mathbf{x})\\}_{a=1}^{n_{h}}$ for the spatial approximation of $\\mathbf{u}_{i}(\\mathbf{x})$, leading to coefficient vectors $\\mathbf{U}_{i}\\in\\mathbb{R}^{n_{\\text{dof}}}$ for $i=0,\\dots,P-1$. Assemble the coupled algebraic SG system for the stacked vector $\\mathbf{U} = [\\mathbf{U}_{0}^{\\top}\\;\\mathbf{U}_{1}^{\\top}\\;\\cdots\\;\\mathbf{U}_{P-1}^{\\top}]^{\\top}\\in\\mathbb{R}^{Pn_{\\text{dof}}}$ by:\n- identifying the spatial stiffness contributions $K^{(q)}\\in\\mathbb{R}^{n_{\\text{dof}}\\times n_{\\text{dof}}}$ associated with each chaos mode $q$,\n- identifying the stochastic coupling (Gram) matrices $G^{(q)}\\in\\mathbb{R}^{P\\times P}$ with entries $G^{(q)}_{ij}=\\langle \\Psi_{i}\\Psi_{j}\\Psi_{q}\\rangle$,\n- expressing the global left-hand-side operator in Kronecker-product form.\n\nYou must show all steps from first principles: kinematics, constitutive relation, the deterministic weak form, insertion of PCEs, Galerkin projection in probability, and spatial FE discretization. Clearly define $K^{(q)}$ and $G^{(q)}$ in terms of integrals. The loading is deterministic, so the right-hand side structure should be deduced but you do not need to provide its final expression in the answer.\n\nProvide as your final answer the closed-form expression, in Kronecker-product notation, for the global stiffness operator that multiplies $\\mathbf{U}$ in the coupled SG-FE algebraic system. Do not include an equality sign in the final answer. No units are required. The final answer must be a single closed-form analytic expression.", "solution": "The problem statement is critically examined and found to be valid. It is a well-posed problem in the field of computational solid mechanics, specifically addressing uncertainty quantification using the Stochastic Galerkin Method. The physical model is based on standard linear elasticity, and the mathematical framework (variational principles, Polynomial Chaos Expansion, Finite Element Method) is sound and consistently described. All provided data and definitions are sufficient and non-contradictory. We may therefore proceed with the derivation.\n\nThe starting point is the strong form of the static linear elasticity problem defined on a domain $\\mathcal{D} \\subset \\mathbb{R}^{d}$. For a given realization of the random parameter $\\omega$, we must find the displacement field $\\mathbf{u}(\\mathbf{x}, \\omega)$ that satisfies the balance of linear momentum and the prescribed boundary conditions:\n$$\n\\begin{cases}\n    -\\nabla \\cdot \\boldsymbol{\\sigma}(\\mathbf{x}, \\omega) = \\mathbf{b}(\\mathbf{x})  \\text{in } \\mathcal{D} \\\\\n    \\mathbf{u}(\\mathbf{x}, \\omega) = \\mathbf{0}  \\text{on } \\Gamma_D \\\\\n    \\boldsymbol{\\sigma}(\\mathbf{x}, \\omega) \\cdot \\mathbf{n}(\\mathbf{x}) = \\mathbf{t}(\\mathbf{x})  \\text{on } \\Gamma_N\n\\end{cases}\n$$\nThe stress tensor $\\boldsymbol{\\sigma}$ is related to the strain tensor $\\boldsymbol{\\varepsilon}(\\mathbf{u}) = \\frac{1}{2}(\\nabla\\mathbf{u} + (\\nabla\\mathbf{u})^{\\top})$ via the constitutive relation $\\boldsymbol{\\sigma} = \\mathbb{C}(\\mathbf{x},\\omega) : \\boldsymbol{\\varepsilon}(\\mathbf{u})$, where the stochastic elasticity tensor is given as $\\mathbb{C}(\\mathbf{x},\\omega) = E(\\mathbf{x},\\omega)\\,\\mathbb{C}_{0}$.\n\nTo derive the weak form, we select an arbitrary vector-valued test function $\\mathbf{v}$ from the space of admissible variations $V = \\{ \\mathbf{v} \\in [H^1(\\mathcal{D})]^d \\mid \\mathbf{v} = \\mathbf{0} \\text{ on } \\Gamma_D \\}$. Multiplying the momentum equation by $\\mathbf{v}$ and integrating over $\\mathcal{D}$, we obtain:\n$$\n- \\int_{\\mathcal{D}} (\\nabla \\cdot \\boldsymbol{\\sigma}) \\cdot \\mathbf{v} \\, d\\mathcal{D} = \\int_{\\mathcal{D}} \\mathbf{b} \\cdot \\mathbf{v} \\, d\\mathcal{D}\n$$\nApplying the divergence theorem to the left-hand side and utilizing the symmetry of the stress tensor ($\\boldsymbol{\\sigma}=\\boldsymbol{\\sigma}^{\\top}$), we get:\n$$\n\\int_{\\mathcal{D}} \\boldsymbol{\\sigma} : \\nabla\\mathbf{v} \\, d\\mathcal{D} - \\int_{\\partial\\mathcal{D}} (\\boldsymbol{\\sigma}\\mathbf{n}) \\cdot \\mathbf{v} \\, dS = \\int_{\\mathcal{D}} \\mathbf{b} \\cdot \\mathbf{v} \\, d\\mathcal{D}\n$$\nThe boundary integral vanishes on $\\Gamma_D$ because $\\mathbf{v}=\\mathbf{0}$ and becomes $\\int_{\\Gamma_N} \\mathbf{t} \\cdot \\mathbf{v} \\, dS$ on $\\Gamma_N$. The term $\\boldsymbol{\\sigma} : \\nabla\\mathbf{v}$ can be rewritten as $\\boldsymbol{\\sigma} : \\boldsymbol{\\varepsilon}(\\mathbf{v})$. This leads to the stochastic weak form: for a given $\\omega$, find $\\mathbf{u}(\\cdot, \\omega) \\in V$ such that for all $\\mathbf{v} \\in V$:\n$$\n\\int_{\\mathcal{D}} \\left( E(\\mathbf{x},\\omega)\\,\\mathbb{C}_{0} : \\boldsymbol{\\varepsilon}(\\mathbf{u}(\\mathbf{x},\\omega)) \\right) : \\boldsymbol{\\varepsilon}(\\mathbf{v}(\\mathbf{x})) \\, d\\mathcal{D} = \\int_{\\mathcal{D}} \\mathbf{b} \\cdot \\mathbf{v} \\, d\\mathcal{D} + \\int_{\\Gamma_N} \\mathbf{t} \\cdot \\mathbf{v} \\, dS\n$$\nLet us define the bilinear form $a(\\mathbf{w}, \\mathbf{v}; \\omega) = \\int_{\\mathcal{D}} E(\\mathbf{x},\\omega)\\,\\left( \\mathbb{C}_{0} : \\boldsymbol{\\varepsilon}(\\mathbf{w})\\right) : \\boldsymbol{\\varepsilon}(\\mathbf{v}) \\, d\\mathcal{D}$ and the linear functional $l(\\mathbf{v}) = \\int_{\\mathcal{D}} \\mathbf{b} \\cdot \\mathbf{v} \\, d\\mathcal{D} + \\int_{\\Gamma_N} \\mathbf{t} \\cdot \\mathbf{v} \\, dS$. The weak form is $a(\\mathbf{u}, \\mathbf{v}; \\omega) = l(\\mathbf{v})$.\n\nNext, we apply the Stochastic Galerkin method. We substitute the given truncated Polynomial Chaos Expansions (PCE) for the random Young's modulus and the unknown displacement field into the weak form:\n$$\nE(\\mathbf{x},\\omega) \\approx \\sum_{q=0}^{Q} E^{(q)}(\\mathbf{x})\\,\\Psi_{q}(\\boldsymbol{\\xi}), \\quad \\mathbf{u}(\\mathbf{x},\\omega) \\approx \\sum_{i=0}^{P-1} \\mathbf{u}_{i}(\\mathbf{x})\\,\\Psi_{i}(\\boldsymbol{\\xi})\n$$\nThe weak form becomes an equation in terms of the random variable $\\boldsymbol{\\xi}$:\n$$\n\\sum_{i=0}^{P-1} \\sum_{q=0}^{Q} \\Psi_i(\\boldsymbol{\\xi})\\Psi_q(\\boldsymbol{\\xi}) \\int_{\\mathcal{D}} E^{(q)}(\\mathbf{x}) \\left( \\mathbb{C}_0 : \\boldsymbol{\\varepsilon}(\\mathbf{u}_i) \\right) : \\boldsymbol{\\varepsilon}(\\mathbf{v}) \\, d\\mathcal{D} = l(\\mathbf{v})\n$$\nThe Galerkin principle in the stochastic space requires the residual of this equation to be orthogonal to the basis functions spanning the approximation space. We project the equation onto each basis function $\\Psi_j(\\boldsymbol{\\xi})$ for $j=0,\\dots,P-1$ by taking the expectation, denoted $\\langle \\cdot \\rangle$:\n$$\n\\sum_{i=0}^{P-1} \\sum_{q=0}^{Q} \\langle \\Psi_j \\Psi_i \\Psi_q \\rangle \\int_{\\mathcal{D}} E^{(q)}(\\mathbf{x}) \\left( \\mathbb{C}_0 : \\boldsymbol{\\varepsilon}(\\mathbf{u}_i) \\right) : \\boldsymbol{\\varepsilon}(\\mathbf{v}) \\, d\\mathcal{D} = \\langle l(\\mathbf{v}) \\Psi_j \\rangle\n$$\nThe loading functional $l(\\mathbf{v})$ is deterministic. Using the orthonormality property $\\langle \\Psi_j \\rangle = \\langle \\Psi_j \\Psi_0 \\rangle = \\delta_{j0}$ (assuming $\\Psi_0=1$), the right-hand side simplifies to $l(\\mathbf{v})\\delta_{j0}$. We define the bilinear form $a^{(q)}(\\mathbf{w}, \\mathbf{v}) = \\int_{\\mathcal{D}} E^{(q)}(\\mathbf{x}) (\\mathbb{C}_0 : \\boldsymbol{\\varepsilon}(\\mathbf{w})) : \\boldsymbol{\\varepsilon}(\\mathbf{v}) \\, d\\mathcal{D}$ and use the provided definition for the stochastic coupling matrix entries $G^{(q)}_{ji} = \\langle \\Psi_j \\Psi_i \\Psi_q \\rangle$. This yields a coupled system of $P$ deterministic weak-form equations: for each $j = 0, \\dots, P-1$, find $\\{\\mathbf{u}_i\\}_{i=0}^{P-1}$ such that for all $\\mathbf{v} \\in V$:\n$$\n\\sum_{i=0}^{P-1} \\sum_{q=0}^{Q} G^{(q)}_{ji} a^{(q)}(\\mathbf{u}_i, \\mathbf{v}) = l(\\mathbf{v}) \\delta_{j0}\n$$\n\nThe final step is the spatial discretization via the Finite Element Method. We approximate each deterministic coefficient field $\\mathbf{u}_i(\\mathbf{x})$ in a finite-dimensional subspace spanned by vector-valued basis functions $\\{\\boldsymbol{\\varphi}_a(\\mathbf{x})\\}_{a=1}^{n_{\\text{dof}}}$:\n$$\n\\mathbf{u}_i(\\mathbf{x}) \\approx \\sum_{a=1}^{n_{\\text{dof}}} (\\mathbf{U}_i)_a \\boldsymbol{\\varphi}_a(\\mathbf{x})\n$$\nwhere $\\mathbf{U}_i \\in \\mathbb{R}^{n_{\\text{dof}}}$ is the vector of nodal coefficients for the $i$-th stochastic mode. The Galerkin method in space requires testing against each basis function $\\mathbf{v} = \\boldsymbol{\\varphi}_b(\\mathbf{x})$ for $b=1, \\dots, n_{\\text{dof}}$. Substituting this into the bilinear form $a^{(q)}$ gives:\n$$\na^{(q)}\\left(\\sum_{a=1}^{n_{\\text{dof}}} (\\mathbf{U}_i)_a \\boldsymbol{\\varphi}_a, \\boldsymbol{\\varphi}_b\\right) = \\sum_{a=1}^{n_{\\text{dof}}} \\left( \\underbrace{a^{(q)}(\\boldsymbol{\\varphi}_a, \\boldsymbol{\\varphi}_b)}_{:=(K^{(q)})_{ba}} \\right) (\\mathbf{U}_i)_a\n$$\nThis defines the spatial stiffness matrix $K^{(q)} \\in \\mathbb{R}^{n_{\\text{dof}} \\times n_{\\text{dof}}}$ associated with the chaos mode $q$. Its entries are given by:\n$$\n(K^{(q)})_{ba} = \\int_{\\mathcal{D}} E^{(q)}(\\mathbf{x}) \\left( \\mathbb{C}_{0} : \\boldsymbol{\\varepsilon}(\\boldsymbol{\\varphi}_{a}) \\right) : \\boldsymbol{\\varepsilon}(\\boldsymbol{\\varphi}_{b}) \\, d\\mathcal{D}\n$$\nThe fully discretized system becomes a set of coupled linear algebraic equations. For each $j=0, \\dots, P-1$ and $b=1, \\dots, n_{\\text{dof}}$:\n$$\n\\sum_{i=0}^{P-1} \\sum_{q=0}^{Q} G^{(q)}_{ji} \\sum_{a=1}^{n_{\\text{dof}}} (K^{(q)})_{ba} (\\mathbf{U}_i)_a = (F)_b \\delta_{j0}\n$$\nwhere $(F)_b = l(\\boldsymbol{\\varphi}_b)$. In matrix-vector notation for each $j$, this is $\\sum_{i=0}^{P-1} (\\sum_{q=0}^{Q} G^{(q)}_{ji} K^{(q)}) \\mathbf{U}_i = \\mathbf{F}\\delta_{j0}$.\n\nThis system can be written globally for the stacked vector $\\mathbf{U} = [\\mathbf{U}_{0}^{\\top} \\dots \\mathbf{U}_{P-1}^{\\top}]^{\\top}$. The global system is $\\mathbb{K}\\mathbf{U} = \\mathbb{F}$, where $\\mathbb{F} = [\\mathbf{F}^{\\top} \\mathbf{0}^{\\top} \\dots \\mathbf{0}^{\\top}]^{\\top}$. The global stiffness matrix $\\mathbb{K}$ is a $P \\times P$ block matrix, where the $(j,i)$-th block, $\\mathbb{K}_{ji} \\in \\mathbb{R}^{n_{\\text{dof}}\\times n_{\\text{dof}}}$, is given by:\n$$\n\\mathbb{K}_{ji} = \\sum_{q=0}^{Q} G^{(q)}_{ji} K^{(q)}\n$$\nWe want to express $\\mathbb{K}$ using the Kronecker product $\\otimes$. The contribution to the global matrix from a single stochastic mode $q$ is a block matrix with blocks $(G^{(q)})_{ji} K^{(q)}$. This is precisely the definition of the Kronecker product $G^{(q)} \\otimes K^{(q)}$, where $G^{(q)}$ is the $P \\times P$ matrix with entries $(G^{(q)})_{ji}$ and $K^{(q)}$ is the $n_{\\text{dof}} \\times n_{\\text{dof}}$ matrix. Summing the contributions from all modes $q=0, \\dots, Q$, we obtain the final expression for the global stiffness operator.", "answer": "$$\\boxed{\\sum_{q=0}^{Q} G^{(q)} \\otimes K^{(q)}}$$", "id": "2707533"}]}