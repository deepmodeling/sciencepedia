{"hands_on_practices": [{"introduction": "This exercise establishes the fundamental concept of a Physics-Informed Neural Network (PINN): translating a governing partial differential equation (PDE) and its boundary conditions into a computational loss function. By constructing the loss for the canonical Poisson's equation, you will practice the core mechanism of \"informing\" a neural network with physical laws. Mastering this step is essential before tackling more complex systems [@problem_id:2126324].", "problem": "A researcher is building a Physics-Informed Neural Network (PINN) to find an approximate solution for the electrostatic potential, $V(x,y)$, within a two-dimensional square region. The physical behavior of the potential is described by the Poisson equation:\n$$\n\\nabla^2 V(x,y) = -f(x,y)\n$$\nwhere $f(x,y)$ represents a given charge distribution density and $\\nabla^2 = \\frac{\\partial^2}{\\partial x^2} + \\frac{\\partial^2}{\\partial y^2}$ is the Laplace operator. The potential is defined over the domain $D = \\{(x,y) \\mid -L \\le x \\le L, -L \\le y \\le L\\}$. The boundary of this domain, $\\partial D$, is held at a zero potential (grounded), which imposes the boundary condition $V(x,y) = 0$ for all $(x,y) \\in \\partial D$.\n\nThe PINN model, denoted by $\\hat{V}(x,y; \\theta)$, learns to approximate $V(x,y)$ by minimizing a loss function $L(\\theta)$ that incorporates the physics of the problem. Here, $\\theta$ represents all the trainable parameters of the neural network. The loss function is calculated using two sets of discrete points:\n1.  A set of $N_{pde}$ collocation points, $S_{pde} = \\{(x_i, y_i) \\mid i=1, \\dots, N_{pde}\\}$, located in the interior of the domain $D$.\n2.  A set of $N_{bc}$ boundary points, $S_{bc} = \\{(x_j, y_j) \\mid j=1, \\dots, N_{bc}\\}$, located on the boundary $\\partial D$.\n\nThe total loss function, $L(\\theta)$, is the sum of two mean squared error terms: one for the governing partial differential equation ($L_{pde}$) and one for the boundary conditions ($L_{bc}$).\n\nConstruct the mathematical expression for the total loss function $L(\\theta) = L_{pde} + L_{bc}$. Your expression should be in terms of the network's output $\\hat{V}$, its second partial derivatives, the function $f$, the given point sets, and their respective sizes $N_{pde}$ and $N_{bc}$.", "solution": "We begin from the governing Poisson equation and boundary condition:\n$$\n\\nabla^{2}V(x,y)=-f(x,y), \\quad V(x,y)=0 \\text{ for } (x,y)\\in \\partial D.\n$$\nA Physics-Informed Neural Network approximates $V$ by $\\hat{V}(x,y;\\theta)$. The PDE residual at an interior collocation point $(x_{i},y_{i})\\in S_{pde}$ is defined by imposing the Poisson equation on $\\hat{V}$:\n$$\nr_{i}(\\theta)=\\nabla^{2}\\hat{V}(x_{i},y_{i};\\theta)+f(x_{i},y_{i}).\n$$\nUsing the definition of the Laplacian in two dimensions, this is equivalently\n$$\nr_{i}(\\theta)=\\frac{\\partial^{2}\\hat{V}}{\\partial x^{2}}(x_{i},y_{i};\\theta)+\\frac{\\partial^{2}\\hat{V}}{\\partial y^{2}}(x_{i},y_{i};\\theta)+f(x_{i},y_{i}).\n$$\nThe mean squared error enforcing the PDE over $S_{pde}$ is then\n$$\nL_{pde}(\\theta)=\\frac{1}{N_{pde}}\\sum_{i=1}^{N_{pde}}\\left(r_{i}(\\theta)\\right)^{2}=\\frac{1}{N_{pde}}\\sum_{i=1}^{N_{pde}}\\left(\\frac{\\partial^{2}\\hat{V}}{\\partial x^{2}}(x_{i},y_{i};\\theta)+\\frac{\\partial^{2}\\hat{V}}{\\partial y^{2}}(x_{i},y_{i};\\theta)+f(x_{i},y_{i})\\right)^{2}.\n$$\nThe boundary condition $V=0$ on $\\partial D$ is enforced by penalizing the deviation of $\\hat{V}$ from zero at boundary points $(x_{j},y_{j})\\in S_{bc}$:\n$$\nL_{bc}(\\theta)=\\frac{1}{N_{bc}}\\sum_{j=1}^{N_{bc}}\\left(\\hat{V}(x_{j},y_{j};\\theta)-0\\right)^{2}=\\frac{1}{N_{bc}}\\sum_{j=1}^{N_{bc}}\\left(\\hat{V}(x_{j},y_{j};\\theta)\\right)^{2}.\n$$\nTherefore, the total loss is the sum of the two mean squared error terms:\n$$\nL(\\theta)=L_{pde}(\\theta)+L_{bc}(\\theta)=\\frac{1}{N_{pde}}\\sum_{i=1}^{N_{pde}}\\left(\\frac{\\partial^{2}\\hat{V}}{\\partial x^{2}}(x_{i},y_{i};\\theta)+\\frac{\\partial^{2}\\hat{V}}{\\partial y^{2}}(x_{i},y_{i};\\theta)+f(x_{i},y_{i})\\right)^{2}+\\frac{1}{N_{bc}}\\sum_{j=1}^{N_{bc}}\\left(\\hat{V}(x_{j},y_{j};\\theta)\\right)^{2}.\n$$", "answer": "$$\\boxed{\\frac{1}{N_{pde}}\\sum_{i=1}^{N_{pde}}\\left(\\frac{\\partial^{2}\\hat{V}}{\\partial x^{2}}(x_{i},y_{i};\\theta)+\\frac{\\partial^{2}\\hat{V}}{\\partial y^{2}}(x_{i},y_{i};\\theta)+f(x_{i},y_{i})\\right)^{2}+\\frac{1}{N_{bc}}\\sum_{j=1}^{N_{bc}}\\left(\\hat{V}(x_{j},y_{j};\\theta)\\right)^{2}}$$", "id": "2126324"}, {"introduction": "Moving from a general principle to a specific application, this practice challenges you to derive the PINN residuals for linear elastic solid mechanics. You will start from the fundamental kinematic and constitutive laws to formulate the explicit components of the equilibrium equations in terms of displacement gradients. This exercise bridges the gap between continuum mechanics theory and the practical implementation of a PINN for structural analysis [@problem_id:2668927].", "problem": "Consider a two-dimensional, small-strain, linear elastic solid in a quasi-static setting with body force per unit volume $\\mathbf{b} = (b_x, b_y)$. Let the displacement field be $\\mathbf{u}(x,y) = (u_x(x,y), u_y(x,y))$. Starting only from the balance of linear momentum, the small-strain kinematic relation, and the linear isotropic constitutive law in terms of the Lamé parameters $(\\lambda, \\mu)$, do the following:\n\n1) Write the constitutive law for the Cauchy stress tensor $\\boldsymbol{\\sigma}$ in terms of the strain tensor $\\boldsymbol{\\varepsilon}$ and $(\\lambda,\\mu)$, and define the small-strain tensor in terms of the displacement field. Express all objects in Cartesian coordinates.\n\n2) Using your definitions, expand the interior equilibrium residual components that a Physics-Informed Neural Network (PINN) would enforce at interior collocation points, namely the two components of $\\nabla \\cdot \\boldsymbol{\\sigma} + \\mathbf{b}$, explicitly in Cartesian coordinates in terms of spatial derivatives of $u_x$ and $u_y$ and the Lamé parameters $(\\lambda,\\mu)$.\n\n3) Now consider a one-hidden-neuron neural network ansatz for the displacement field with hyperbolic tangent activation,\n$$\nz(x,y) = w_1 x + w_2 y + b_1,\\quad \\mathbf{u}(x,y) = \\mathbf{W}_2 \\,\\tanh\\!\\big(z(x,y)\\big) + \\mathbf{b}_2,\n$$\nwith $\\mathbf{W}_2 \\in \\mathbb{R}^{2 \\times 1}$ and $\\mathbf{b}_2 \\in \\mathbb{R}^{2}$. Take the specific parameters\n$$\nw_1 = 1,\\quad w_2 = 2,\\quad b_1 = 0,\\quad \\mathbf{W}_2 = \\begin{pmatrix} 2 \\\\ -1 \\end{pmatrix},\\quad \\mathbf{b}_2 = \\begin{pmatrix} 0 \\\\ 0 \\end{pmatrix},\n$$\nand assume zero body force $\\mathbf{b}=\\mathbf{0}$. Evaluate the two components of the interior equilibrium residual vector at the point $(x_0,y_0)=(1,0)$.\n\nAssume a nondimensionalized formulation so that all quantities are dimensionless. Express the final result as a single row vector containing the two residual components, written as a closed-form analytic expression. Do not approximate or round any constants; leave hyperbolic functions unevaluated (for example, write $\\tanh(1)$, $\\cosh(1)$ explicitly).", "solution": "The problem is validated as well-posed, scientifically grounded, and containing all necessary information for a unique solution. We proceed with the derivation.\n\nThe problem requires a step-by-step derivation, starting from fundamental principles of continuum mechanics, to evaluate the equilibrium residual for a given neural network ansatz for the displacement field.\n\nFirst, we address Task 1: defining the relevant kinematic and constitutive relations in Cartesian coordinates.\n\nIn a two-dimensional domain with coordinates $(x,y)$, the displacement field is $\\mathbf{u}(x,y) = (u_x(x,y), u_y(x,y))$. The small-strain (or infinitesimal strain) tensor $\\boldsymbol{\\varepsilon}$ is defined in terms of the gradient of the displacement field as:\n$$\n\\boldsymbol{\\varepsilon} = \\frac{1}{2} \\left[ \\nabla \\mathbf{u} + (\\nabla \\mathbf{u})^T \\right]\n$$\nIn Cartesian component form, this gives:\n$$\n\\varepsilon_{xx} = \\frac{\\partial u_x}{\\partial x}, \\quad \\varepsilon_{yy} = \\frac{\\partial u_y}{\\partial y}, \\quad \\varepsilon_{xy} = \\varepsilon_{yx} = \\frac{1}{2}\\left(\\frac{\\partial u_x}{\\partial y} + \\frac{\\partial u_y}{\\partial x}\\right)\n$$\nThe trace of the strain tensor, which represents the volumetric strain, is $\\text{tr}(\\boldsymbol{\\varepsilon}) = \\varepsilon_{kk} = \\varepsilon_{xx} + \\varepsilon_{yy}$.\n\nFor a linear, isotropic, and elastic material, the constitutive law relating the Cauchy stress tensor $\\boldsymbol{\\sigma}$ to the strain tensor $\\boldsymbol{\\varepsilon}$ is given by Hooke's Law, which can be expressed using the Lamé parameters $\\lambda$ and $\\mu$ (also known as the first and second Lamé parameters, where $\\mu$ is the shear modulus):\n$$\n\\boldsymbol{\\sigma} = \\lambda \\, \\text{tr}(\\boldsymbol{\\varepsilon}) \\, \\mathbf{I} + 2\\mu \\, \\boldsymbol{\\varepsilon}\n$$\nwhere $\\mathbf{I}$ is the second-order identity tensor. In Cartesian component form, the stress components are:\n$$\n\\sigma_{xx} = \\lambda(\\varepsilon_{xx} + \\varepsilon_{yy}) + 2\\mu \\varepsilon_{xx} = (\\lambda + 2\\mu)\\frac{\\partial u_x}{\\partial x} + \\lambda\\frac{\\partial u_y}{\\partial y}\n$$\n$$\n\\sigma_{yy} = \\lambda(\\varepsilon_{xx} + \\varepsilon_{yy}) + 2\\mu \\varepsilon_{yy} = \\lambda\\frac{\\partial u_x}{\\partial x} + (\\lambda + 2\\mu)\\frac{\\partial u_y}{\\partial y}\n$$\n$$\n\\sigma_{xy} = \\sigma_{yx} = 2\\mu \\varepsilon_{xy} = \\mu\\left(\\frac{\\partial u_x}{\\partial y} + \\frac{\\partial u_y}{\\partial x}\\right)\n$$\n\nNext, we address Task 2: deriving the explicit form of the interior equilibrium residual components. The balance of linear momentum in a quasi-static setting is the equilibrium equation $\\nabla \\cdot \\boldsymbol{\\sigma} + \\mathbf{b} = \\mathbf{0}$. A Physics-Informed Neural Network (PINN) seeks to minimize the residual of this equation, which is $\\mathbf{R} = \\nabla \\cdot \\boldsymbol{\\sigma} + \\mathbf{b}$. The components of this residual vector in Cartesian coordinates are:\n$$\nR_x = \\frac{\\partial \\sigma_{xx}}{\\partial x} + \\frac{\\partial \\sigma_{xy}}{\\partial y} + b_x\n$$\n$$\nR_y = \\frac{\\partial \\sigma_{yx}}{\\partial x} + \\frac{\\partial \\sigma_{yy}}{\\partial y} + b_y\n$$\nSubstituting the expressions for the stress components in terms of displacement derivatives yields the Navier-Cauchy equations. We assume the material is homogeneous, so $\\lambda$ and $\\mu$ are constants.\nFor the $x$-component of the residual:\n$$\nR_x = \\frac{\\partial}{\\partial x} \\left( (\\lambda + 2\\mu)\\frac{\\partial u_x}{\\partial x} + \\lambda\\frac{\\partial u_y}{\\partial y} \\right) + \\frac{\\partial}{\\partial y} \\left( \\mu\\left(\\frac{\\partial u_x}{\\partial y} + \\frac{\\partial u_y}{\\partial x}\\right) \\right) + b_x\n$$\n$$\nR_x = (\\lambda + 2\\mu)\\frac{\\partial^2 u_x}{\\partial x^2} + \\lambda\\frac{\\partial^2 u_y}{\\partial x \\partial y} + \\mu\\frac{\\partial^2 u_x}{\\partial y^2} + \\mu\\frac{\\partial^2 u_y}{\\partial y \\partial x} + b_x\n$$\nBy equality of mixed partials ($\\frac{\\partial^2 u_y}{\\partial x \\partial y} = \\frac{\\partial^2 u_y}{\\partial y \\partial x}$), we can group the terms:\n$$\nR_x = (\\lambda+2\\mu)\\frac{\\partial^2 u_x}{\\partial x^2} + \\mu \\frac{\\partial^2 u_x}{\\partial y^2} + (\\lambda+\\mu) \\frac{\\partial^2 u_y}{\\partial x \\partial y} + b_x\n$$\nFor the $y$-component of the residual:\n$$\nR_y = \\frac{\\partial}{\\partial x} \\left( \\mu\\left(\\frac{\\partial u_x}{\\partial y} + \\frac{\\partial u_y}{\\partial x}\\right) \\right) + \\frac{\\partial}{\\partial y} \\left( \\lambda\\frac{\\partial u_x}{\\partial x} + (\\lambda + 2\\mu)\\frac{\\partial u_y}{\\partial y} \\right) + b_y\n$$\n$$\nR_y = \\mu\\frac{\\partial^2 u_x}{\\partial x \\partial y} + \\mu\\frac{\\partial^2 u_y}{\\partial x^2} + \\lambda\\frac{\\partial^2 u_x}{\\partial y \\partial x} + (\\lambda + 2\\mu)\\frac{\\partial^2 u_y}{\\partial y^2} + b_y\n$$\nAgain, grouping terms:\n$$\nR_y = (\\lambda+\\mu) \\frac{\\partial^2 u_x}{\\partial x \\partial y} + \\mu \\frac{\\partial^2 u_y}{\\partial x^2} + (\\lambda+2\\mu) \\frac{\\partial^2 u_y}{\\partial y^2} + b_y\n$$\nThese are the explicit expressions for the residual components that a PINN would enforce.\n\nFinally, we address Task 3: evaluating these residuals for the specified neural network ansatz and parameters. The ansatz is given by:\n$z(x,y) = w_1 x + w_2 y + b_1$ and $\\mathbf{u}(x,y) = \\mathbf{W}_2 \\tanh(z(x,y)) + \\mathbf{b}_2$.\nWith the given parameters $w_1 = 1$, $w_2 = 2$, $b_1 = 0$, $\\mathbf{W}_2 = \\begin{pmatrix} 2 \\\\ -1 \\end{pmatrix}$, and $\\mathbf{b}_2 = \\begin{pmatrix} 0 \\\\ 0 \\end{pmatrix}$, we have:\n$z(x,y) = x + 2y$\nAnd the displacement components are:\n$$\nu_x(x,y) = 2 \\tanh(x+2y)\n$$\n$$\nu_y(x,y) = -1 \\tanh(x+2y)\n$$\nWe must compute the second-order partial derivatives of $u_x$ and $u_y$. Let $T(x,y) = \\tanh(x+2y)$ and $S(x,y) = \\text{sech}^2(x+2y) = 1-\\tanh^2(x+2y)$. We use the chain rule and the derivative identities $\\frac{d}{d\\alpha}\\tanh(\\alpha) = \\text{sech}^2(\\alpha)$ and $\\frac{d}{d\\alpha}\\text{sech}^2(\\alpha) = -2\\tanh(\\alpha)\\text{sech}^2(\\alpha)$.\n\nDerivatives of $u_x = 2T$:\n$\\frac{\\partial u_x}{\\partial x} = 2 \\frac{\\partial T}{\\partial x} = 2S \\cdot 1 = 2S$\n$\\frac{\\partial u_x}{\\partial y} = 2 \\frac{\\partial T}{\\partial y} = 2S \\cdot 2 = 4S$\n$\\frac{\\partial^2 u_x}{\\partial x^2} = \\frac{\\partial}{\\partial x}(2S) = 2(-2TS) \\cdot 1 = -4TS$\n$\\frac{\\partial^2 u_x}{\\partial y^2} = \\frac{\\partial}{\\partial y}(4S) = 4(-2TS) \\cdot 2 = -16TS$\n$\\frac{\\partial^2 u_x}{\\partial x \\partial y} = \\frac{\\partial}{\\partial y}(2S) = 2(-2TS) \\cdot 2 = -8TS$\n\nDerivatives of $u_y = -T$:\n$\\frac{\\partial u_y}{\\partial x} = -S \\cdot 1 = -S$\n$\\frac{\\partial u_y}{\\partial y} = -S \\cdot 2 = -2S$\n$\\frac{\\partial^2 u_y}{\\partial x^2} = \\frac{\\partial}{\\partial x}(-S) = -(-2TS) \\cdot 1 = 2TS$\n$\\frac{\\partial^2 u_y}{\\partial y^2} = \\frac{\\partial}{\\partial y}(-2S) = -2(-2TS) \\cdot 2 = 8TS$\n$\\frac{\\partial^2 u_y}{\\partial x \\partial y} = \\frac{\\partial}{\\partial y}(-S) = -(-2TS) \\cdot 2 = 4TS$\n\nWe are given zero body force, so $\\mathbf{b}=\\mathbf{0}$. We substitute these derivatives into the residual expressions:\n$$\nR_x = (\\lambda+2\\mu)(-4TS) + \\mu(-16TS) + (\\lambda+\\mu)(4TS)\n$$\n$$\nR_x = [-4(\\lambda+2\\mu) - 16\\mu + 4(\\lambda+\\mu)]TS = [-4\\lambda - 8\\mu - 16\\mu + 4\\lambda + 4\\mu]TS = -20\\mu TS\n$$\n$$\nR_y = (\\lambda+\\mu)(-8TS) + \\mu(2TS) + (\\lambda+2\\mu)(8TS)\n$$\n$$\nR_y = [-8(\\lambda+\\mu) + 2\\mu + 8(\\lambda+2\\mu)]TS = [-8\\lambda - 8\\mu + 2\\mu + 8\\lambda + 16\\mu]TS = 10\\mu TS\n$$\nThe residual vector is $\\mathbf{R}(x,y) = \\begin{pmatrix} -20\\mu & 10\\mu \\end{pmatrix} \\tanh(x+2y)\\text{sech}^2(x+2y)$.\n\nWe must evaluate this at the point $(x_0, y_0) = (1, 0)$. At this point, the argument of the hyperbolic functions is $z_0 = 1 + 2(0) = 1$.\nThe term $TS$ becomes $\\tanh(1)\\text{sech}^2(1)$. Using the identity $\\text{sech}^2(\\alpha) = 1/\\cosh^2(\\alpha)$, this is $\\frac{\\tanh(1)}{\\cosh^2(1)}$.\nThe residual components at $(1, 0)$ are:\n$$\nR_x(1,0) = -20\\mu \\frac{\\tanh(1)}{\\cosh^{2}(1)}\n$$\n$$\nR_y(1,0) = 10\\mu \\frac{\\tanh(1)}{\\cosh^{2}(1)}\n$$\nThe problem asks for the result as a single row vector.\n$$\n\\mathbf{R}(1,0) = \\begin{pmatrix} -20\\mu \\frac{\\tanh(1)}{\\cosh^{2}(1)} & 10\\mu \\frac{\\tanh(1)}{\\cosh^{2}(1)} \\end{pmatrix}\n$$\nThis is the final analytical expression.", "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n-20\\mu \\frac{\\tanh(1)}{\\cosh^{2}(1)} & 10\\mu \\frac{\\tanh(1)}{\\cosh^{2}(1)}\n\\end{pmatrix}\n}\n$$", "id": "2668927"}, {"introduction": "Advanced modeling often involves navigating numerical challenges, and this problem addresses a critical one in computational solid mechanics: volumetric locking. This exercise explores how the standard PINN formulation can become ill-conditioned when dealing with nearly incompressible materials, leading to poor training performance. By analyzing the behavior of Lamé parameters and considering alternative mixed formulations, you will develop a deeper understanding of how to build robust PINNs for challenging material models [@problem_id:2668960].", "problem": "Consider small-strain, static, isotropic linear elasticity in spatial dimension $d \\in \\{2,3\\}$. The Cauchy stress tensor $\\boldsymbol{\\sigma}$ and the small-strain tensor $\\boldsymbol{\\varepsilon}(\\mathbf{u}) = \\tfrac{1}{2}\\left(\\nabla \\mathbf{u} + \\nabla \\mathbf{u}^{\\top}\\right)$ are related by the isotropic Hooke law $\\boldsymbol{\\sigma} = 2\\,\\mu\\,\\boldsymbol{\\varepsilon} + \\lambda\\,\\mathrm{tr}(\\boldsymbol{\\varepsilon})\\,\\mathbf{I}$, where $(\\lambda,\\mu)$ are the Lamé parameters. The Young’s modulus $E$ and the Poisson’s ratio $\\nu$ are defined by a uniaxial test: prescribe a uniaxial Cauchy stress $\\sigma_{11} = \\sigma$ with lateral stresses $\\sigma_{22}=\\sigma_{33}=0$ (for $d=3$; adapt accordingly for $d=2$ plane stress), and define $E = \\sigma_{11}/\\varepsilon_{11}$ and $\\nu = -\\varepsilon_{22}/\\varepsilon_{11} = -\\varepsilon_{33}/\\varepsilon_{11}$ under this loading. Starting from these definitions and the constitutive law, derive $(\\lambda,\\mu)$ in terms of $(E,\\nu)$.\n\nNow consider training a physics-informed neural network (PINN; physics-informed neural network) that outputs the displacement field $\\mathbf{u}(\\mathbf{x})$ to solve the equilibrium partial differential equation (PDE; partial differential equation) $\\nabla \\cdot \\boldsymbol{\\sigma}(\\mathbf{u}) = \\mathbf{0}$ with given boundary conditions, using the above constitutive model. Discuss, from first principles, how the limit $\\nu \\to 0.5$ (nearly incompressible) impacts the conditioning of the PDE residual and the learnability of $\\mathbf{u}$ in a displacement-only PINN, and what modeling or loss-design changes can remedy this.\n\nWhich of the following statements are correct?\n\nA. The derived mapping yields $\\mu = \\dfrac{E}{2(1+\\nu)}$ and $\\lambda = \\dfrac{E\\,\\nu}{(1+\\nu)(1-2\\nu)}$.\n\nB. As $\\nu \\to 0.5$, the parameter $\\lambda$ remains bounded while $\\mu \\to \\infty$, so the shear term dominates the PDE residual; therefore near-incompressibility does not cause ill-conditioning in displacement-only PINNs.\n\nC. In the nearly incompressible regime, a displacement-only PINN commonly suffers from an ill-conditioned loss landscape dominated by volumetric contributions. Simply rescaling inputs and outputs or reweighting loss terms is, by itself, sufficient to fully resolve training pathologies for all $\\nu$ arbitrarily close to $0.5$.\n\nD. A robust remedy is a mixed displacement–pressure formulation in which one introduces $p$ as an additional unknown and writes $\\boldsymbol{\\sigma}(\\mathbf{u},p) = 2\\,\\mu\\,\\boldsymbol{\\varepsilon}^{\\mathrm{dev}}(\\mathbf{u}) - p\\,\\mathbf{I}$, together with a volumetric closure $p + \\kappa\\,\\nabla \\cdot \\mathbf{u} = 0$ where $\\kappa = \\lambda + \\tfrac{2}{3}\\mu$ is the bulk modulus. The momentum equation becomes $\\nabla \\cdot \\left(2\\,\\mu\\,\\boldsymbol{\\varepsilon}^{\\mathrm{dev}}(\\mathbf{u})\\right) - \\nabla p = \\mathbf{0}$, which avoids unbounded coefficients in the momentum residual as $\\nu \\to 0.5$ and can be stably enforced in a PINN by separately scaling the constraint.\n\nE. Adaptive loss balancing based on the Neural Tangent Kernel (NTK; neural tangent kernel) guarantees that a displacement-only PINN trained on the original momentum residual with $(\\lambda,\\mu)$ remains well-conditioned as $\\nu \\to 0.5$, obviating the need for mixed formulations.", "solution": "The problem statement will be validated before a solution is attempted.\n\n### Step 1: Extract Givens\n-   **Problem Domain**: Small-strain, static, isotropic linear elasticity.\n-   **Spatial Dimension**: $d \\in \\{2,3\\}$.\n-   **Strain Tensor Definition**: $\\boldsymbol{\\varepsilon}(\\mathbf{u}) = \\tfrac{1}{2}\\left(\\nabla \\mathbf{u} + \\nabla \\mathbf{u}^{\\top}\\right)$.\n-   **Constitutive Law (Hooke's Law)**: $\\boldsymbol{\\sigma} = 2\\,\\mu\\,\\boldsymbol{\\varepsilon} + \\lambda\\,\\mathrm{tr}(\\boldsymbol{\\varepsilon})\\,\\mathbf{I}$, where $(\\lambda,\\mu)$ are Lamé parameters.\n-   **Material Properties from Uniaxial Test**:\n    -   Loading condition: $\\sigma_{11} = \\sigma$, with lateral stresses $\\sigma_{22}=\\sigma_{33}=0$ (for $d=3$).\n    -   Young’s Modulus, $E$: $E = \\sigma_{11}/\\varepsilon_{11}$.\n    -   Poisson’s Ratio, $\\nu$: $\\nu = -\\varepsilon_{22}/\\varepsilon_{11} = -\\varepsilon_{33}/\\varepsilon_{11}$.\n-   **Task 1**: Derive $(\\lambda,\\mu)$ in terms of $(E,\\nu)$.\n-   **PINN Context**: Solve the equilibrium equation $\\nabla \\cdot \\boldsymbol{\\sigma}(\\mathbf{u}) = \\mathbf{0}$ using a physics-informed neural network (PINN) that outputs the displacement field $\\mathbf{u}(\\mathbf{x})$.\n-   **Task 2**: Analyze the impact of the nearly incompressible limit $\\nu \\to 0.5$ on a displacement-only PINN and discuss remedies.\n\n### Step 2: Validate Using Extracted Givens\n1.  **Scientifically Grounded**: The problem is based on the fundamental theory of linear elasticity, a cornerstone of continuum mechanics. All equations and definitions—Cauchy stress, small-strain tensor, isotropic Hooke's law, equilibrium equation, and the definitions of $E$ and $\\nu$—are standard and factually correct.\n2.  **Well-Posed**: The derivation of Lamé parameters from engineering constants is a standard, well-posed algebraic problem. The analysis of numerical ill-conditioning (volumetric locking) as $\\nu \\to 0.5$ is a classic topic in computational mechanics, and its application to PINNs is a relevant and formalizable modern research question.\n3.  **Objective**: The language is precise, technical, and free of ambiguity or subjective claims.\n\nThe problem statement is self-contained, scientifically sound, and well-posed. There are no contradictions, missing data, or other invalidating flaws.\n\n### Step 3: Verdict and Action\nThe problem is **valid**. A solution will be derived.\n\n### Derivation and Analysis\n\n**Part 1: Derivation of $(\\lambda, \\mu)$ in terms of $(E, \\nu)$**\n\nWe start with the isotropic Hooke's law:\n$$\n\\boldsymbol{\\sigma} = 2\\,\\mu\\,\\boldsymbol{\\varepsilon} + \\lambda\\,\\mathrm{tr}(\\boldsymbol{\\varepsilon})\\,\\mathbf{I}\n$$\nWe need to invert this relation to express $\\boldsymbol{\\varepsilon}$ as a function of $\\boldsymbol{\\sigma}$. Taking the trace of the equation (for dimension $d=3$):\n$$\n\\mathrm{tr}(\\boldsymbol{\\sigma}) = \\mathrm{tr}(2\\,\\mu\\,\\boldsymbol{\\varepsilon} + \\lambda\\,\\mathrm{tr}(\\boldsymbol{\\varepsilon})\\,\\mathbf{I}) = 2\\,\\mu\\,\\mathrm{tr}(\\boldsymbol{\\varepsilon}) + \\lambda\\,\\mathrm{tr}(\\boldsymbol{\\varepsilon})\\,\\mathrm{tr}(\\mathbf{I}) = (2\\mu + 3\\lambda)\\,\\mathrm{tr}(\\boldsymbol{\\varepsilon})\n$$\nThus, the volumetric strain is:\n$$\n\\mathrm{tr}(\\boldsymbol{\\varepsilon}) = \\frac{\\mathrm{tr}(\\boldsymbol{\\sigma})}{2\\mu + 3\\lambda}\n$$\nSubstituting this back into the first equation:\n$$\n\\boldsymbol{\\sigma} = 2\\,\\mu\\,\\boldsymbol{\\varepsilon} + \\lambda \\left(\\frac{\\mathrm{tr}(\\boldsymbol{\\sigma})}{2\\mu + 3\\lambda}\\right)\\mathbf{I}\n$$\nSolving for $\\boldsymbol{\\varepsilon}$:\n$$\n2\\,\\mu\\,\\boldsymbol{\\varepsilon} = \\boldsymbol{\\sigma} - \\frac{\\lambda\\,\\mathrm{tr}(\\boldsymbol{\\sigma})}{2\\mu + 3\\lambda}\\,\\mathbf{I} \\implies \\boldsymbol{\\varepsilon} = \\frac{1}{2\\mu}\\boldsymbol{\\sigma} - \\frac{\\lambda}{2\\mu(2\\mu + 3\\lambda)}\\mathrm{tr}(\\boldsymbol{\\sigma})\\,\\mathbf{I}\n$$\nNow, we apply the conditions of the uniaxial test: $\\sigma_{11} = \\sigma$ and all other $\\sigma_{ij}=0$. This gives $\\mathrm{tr}(\\boldsymbol{\\sigma}) = \\sigma$.\nThe strain components are:\n$$\n\\varepsilon_{11} = \\frac{1}{2\\mu}\\sigma_{11} - \\frac{\\lambda}{2\\mu(2\\mu + 3\\lambda)}\\sigma = \\frac{\\sigma}{2\\mu}\\left(1 - \\frac{\\lambda}{2\\mu + 3\\lambda}\\right) = \\frac{\\sigma}{2\\mu}\\left(\\frac{2\\mu + 3\\lambda - \\lambda}{2\\mu + 3\\lambda}\\right) = \\sigma\\frac{\\mu+\\lambda}{\\mu(2\\mu+3\\lambda)}\n$$\n$$\n\\varepsilon_{22} = \\frac{1}{2\\mu}\\sigma_{22} - \\frac{\\lambda}{2\\mu(2\\mu + 3\\lambda)}\\sigma = 0 - \\frac{\\lambda\\sigma}{2\\mu(2\\mu + 3\\lambda)}\n$$\nUsing the definitions of $E$ and $\\nu$:\n$$\nE = \\frac{\\sigma_{11}}{\\varepsilon_{11}} = \\frac{\\sigma}{\\sigma\\frac{\\mu+\\lambda}{\\mu(2\\mu+3\\lambda)}} = \\frac{\\mu(2\\mu+3\\lambda)}{\\mu+\\lambda}\n$$\n$$\n\\nu = -\\frac{\\varepsilon_{22}}{\\varepsilon_{11}} = -\\frac{-\\lambda\\sigma / [2\\mu(2\\mu+3\\lambda)]}{\\sigma(\\mu+\\lambda) / [\\mu(2\\mu+3\\lambda)]} = \\frac{\\lambda}{2(\\mu+\\lambda)}\n$$\nWe now solve the system of two equations for $\\mu$ and $\\lambda$. From the equation for $\\nu$:\n$2\\nu(\\mu+\\lambda) = \\lambda \\implies 2\\nu\\mu = \\lambda(1-2\\nu) \\implies \\lambda = \\frac{2\\nu\\mu}{1-2\\nu}$.\nSubstitute this into the equation for $E$:\n$E = 2\\mu(1+\\nu)$. To see this: $E = \\frac{\\mu(2\\mu+3\\lambda)}{\\mu+\\lambda} = \\frac{\\mu(2\\mu+3\\frac{2\\nu\\mu}{1-2\\nu})}{\\mu+\\frac{2\\nu\\mu}{1-2\\nu}} = \\mu \\frac{2(1-2\\nu)+6\\nu}{1-2\\nu+2\\nu} = \\mu(2-4\\nu+6\\nu) = 2\\mu(1+\\nu)$.\nFrom $E = 2\\mu(1+\\nu)$, we find the shear modulus $\\mu$:\n$$\n\\mu = \\frac{E}{2(1+\\nu)}\n$$\nNow substitute this $\\mu$ back into the expression for $\\lambda$:\n$$\n\\lambda = \\frac{2\\nu}{1-2\\nu}\\mu = \\frac{2\\nu}{1-2\\nu} \\frac{E}{2(1+\\nu)} = \\frac{E\\nu}{(1+\\nu)(1-2\\nu)}\n$$\nThe derivation is complete.\n\n**Part 2: Analysis of PINNs for Nearly Incompressible Elasticity ($\\nu \\to 0.5$)**\n\nThe equilibrium PDE in terms of displacement is the Navier-Cauchy equation:\n$$\n\\nabla \\cdot \\boldsymbol{\\sigma} = \\mu \\nabla^2 \\mathbf{u} + (\\lambda+\\mu) \\nabla(\\nabla \\cdot \\mathbf{u}) = \\mathbf{0}\n$$\nA displacement-only PINN minimizes a loss based on the residual of this equation. We examine the behavior of the coefficients as $\\nu \\to 0.5$:\n-   $\\mu = \\frac{E}{2(1+\\nu)} \\to \\frac{E}{2(1.5)} = \\frac{E}{3}$. The coefficient $\\mu$ remains bounded and well-behaved.\n-   $\\lambda = \\frac{E\\nu}{(1+\\nu)(1-2\\nu)} \\to \\infty$ because the denominator $(1-2\\nu) \\to 0$.\nThe coefficient of the volumetric term, $(\\lambda+\\mu)$, therefore also diverges: $(\\lambda+\\mu) \\to \\infty$.\n\nThe PDE becomes dominated by the term $(\\lambda+\\mu) \\nabla(\\nabla \\cdot \\mathbf{u})$. For the equation to hold, the network must learn a displacement field $\\mathbf{u}$ such that $\\nabla \\cdot \\mathbf{u} \\approx 0$ with extreme precision. The loss function becomes\n$\\mathcal{L}_{PDE} \\approx ||(\\lambda+\\mu) \\nabla(\\nabla \\cdot \\mathbf{u})||^2$. The extremely large pre-factor $(\\lambda+\\mu)$ creates an ill-conditioned loss landscape with enormous gradients related to any non-zero volumetric strain. This phenomenon, known as **volumetric locking**, makes it extremely difficult for gradient-based optimizers to find a good solution. The training stagnates, unable to resolve the shear behavior because the loss is completely dominated by the penalty on volumetric deformation.\n\n### Evaluation of Options\n\n**A. The derived mapping yields $\\mu = \\dfrac{E}{2(1+\\nu)}$ and $\\lambda = \\dfrac{E\\,\\nu}{(1+\\nu)(1-2\\nu)}$.**\nOur derivation in Part 1 confirms these expressions precisely.\n**Verdict: Correct.**\n\n**B. As $\\nu \\to 0.5$, the parameter $\\lambda$ remains bounded while $\\mu \\to \\infty$, so the shear term dominates the PDE residual; therefore near-incompressibility does not cause ill-conditioning in displacement-only PINNs.**\nThis statement is incorrect on multiple counts. As derived, when $\\nu \\to 0.5$, $\\mu$ remains bounded while $\\lambda \\to \\infty$. The term that dominates the PDE is the volumetric term containing $\\lambda$, not the shear term containing $\\mu$. Consequently, near-incompressibility is a classic cause of severe ill-conditioning (locking).\n**Verdict: Incorrect.**\n\n**C. In the nearly incompressible regime, a displacement-only PINN commonly suffers from an ill-conditioned loss landscape dominated by volumetric contributions. Simply rescaling inputs and outputs or reweighting loss terms is, by itself, sufficient to fully resolve training pathologies for all $\\nu$ arbitrarily close to $0.5$.**\nThe first part of the statement, describing the ill-conditioned loss landscape, is correct. However, the second part makes an overly strong claim. While simple techniques like reweighting loss terms can provide some relief for moderate values of $\\nu$, they are not a \"sufficient\" remedy to \"fully resolve\" the pathology for $\\nu$ arbitrarily close to $0.5$. The problem is fundamental to the displacement-only formulation, which becomes singular in the limit. Such simple fixes do not change the formulation and cannot robustly handle the singularity. A more profound change, such as a mixed formulation, is required for robust performance in the severe incompressible regime.\n**Verdict: Incorrect.**\n\n**D. A robust remedy is a mixed displacement–pressure formulation in which one introduces $p$ as an additional unknown and writes $\\boldsymbol{\\sigma}(\\mathbf{u},p) = 2\\,\\mu\\,\\boldsymbol{\\varepsilon}^{\\mathrm{dev}}(\\mathbf{u}) - p\\,\\mathbf{I}$, together with a volumetric closure $p + \\kappa\\,\\nabla \\cdot \\mathbf{u} = 0$ where $\\kappa = \\lambda + \\tfrac{2}{3}\\mu$ is the bulk modulus. The momentum equation becomes $\\nabla \\cdot \\left(2\\,\\mu\\,\\boldsymbol{\\varepsilon}^{\\mathrm{dev}}(\\mathbf{u})\\right) - \\nabla p = \\mathbf{0}$, which avoids unbounded coefficients in the momentum residual as $\\nu \\to 0.5$ and can be stably enforced in a PINN by separately scaling the constraint.**\nThis accurately describes the standard mixed $u-p$ formulation. The decomposition of stress into deviatoric and hydrostatic parts, $\\boldsymbol{\\sigma} = 2\\mu\\boldsymbol{\\varepsilon}^{\\mathrm{dev}} - p\\mathbf{I}$, with pressure $p = -\\kappa \\nabla \\cdot \\mathbf{u}$, is correct. The resulting equilibrium equation $\\nabla \\cdot (2\\mu\\boldsymbol{\\varepsilon}^{\\mathrm{dev}}) - \\nabla p = \\mathbf{0}$ involves only the bounded shear modulus $\\mu$. The unboundedness is isolated in the scalar constitutive relation for pressure, $p + \\kappa \\nabla \\cdot \\mathbf{u} = 0$, where the bulk modulus $\\kappa = E/(3(1-2\\nu)) \\to \\infty$. By treating the momentum equation and the pressure constraint as two separate residuals in the PINN loss, one can apply separate scaling or weighting to manage the stiff constraint, leading to a much more stable training process. This is the standard and effective approach to overcome volumetric locking.\n**Verdict: Correct.**\n\n**E. Adaptive loss balancing based on the Neural Tangent Kernel (NTK; neural tangent kernel) guarantees that a displacement-only PINN trained on the original momentum residual with $(\\lambda,\\mu)$ remains well-conditioned as $\\nu \\to 0.5$, obviating the need for mixed formulations.**\nThis is an overstatement. NTK-based weighting typically balances different loss *terms* (e.g., PDE residual vs. boundary condition residual). It does not address the ill-conditioning *within* the single PDE residual term caused by the diverging ratio of material parameters $(\\lambda+\\mu)/\\mu$. The gradients of the loss function would still be pathologically dominated by the volumetric component. Furthermore, no adaptive weighting scheme can \"guarantee\" a well-conditioned problem in a singular limit without changing the underlying physical formulation. Mixed formulations represent a change in the formulation itself, which is a more fundamental and robust solution than re-weighting the loss of an ill-posed system.\n**Verdict: Incorrect.**", "answer": "$$\\boxed{AD}$$", "id": "2668960"}]}