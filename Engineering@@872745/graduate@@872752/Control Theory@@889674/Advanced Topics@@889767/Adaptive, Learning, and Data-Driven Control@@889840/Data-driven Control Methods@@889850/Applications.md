## Applications and Interdisciplinary Connections

The preceding chapters have established the foundational principles of [data-driven control](@entry_id:178277), from Willems' behavioral approach and the concept of data informativity to the formulation of control problems directly from measurements. This chapter bridges theory and practice by exploring how these core principles are operationalized in a wide array of applications, spanning classical control engineering, advanced robotics, and other scientific disciplines. Our focus will shift from the derivation of fundamental results to the demonstration of their utility, extension, and integration in applied contexts. Rather than re-teaching the core concepts, we will showcase their power in solving complex, real-world problems, illustrating the versatility and growing importance of data-driven methodologies across science and engineering.

### Data-Driven System Identification and Modeling

At the heart of many data-driven methods lies the task of constructing a useful dynamical model from observed data. While the ultimate goal may be control, a reliable model often serves as an indispensable intermediate step for analysis, simulation, and prediction. Data-driven techniques offer powerful ways to construct such models, ranging from linear approximations of complex systems to the reconstruction of full state-space representations from external measurements.

#### Linear Approximations of Nonlinear Systems: The EDMD Framework

Many physical systems exhibit nonlinear behavior that complicates analysis and control design. A powerful data-driven paradigm, Dynamic Mode Decomposition (DMD) and its extensions, seeks to identify a best-fit linear operator that propagates measurements forward in time. Extended Dynamic Mode Decomposition (EDMD) elevates this concept by lifting the original [state variables](@entry_id:138790) into a higher-dimensional feature space using a dictionary of observable functions. The underlying premise is that even if the dynamics are nonlinear in the original state space, they may be well-approximated by a linear model in the lifted space.

Consider a general nonlinear system with control, $x_{k+1} = f(x_k, u_k)$. We select a vector of observable functions, $z_k = \psi(x_k)$, to represent the system's state. The goal is to find matrices $(A_l, B_l)$ that define a linear control-affine model in the lifted coordinates, $z_{k+1} \approx A_l z_k + B_l u_k$. Given a dataset of state transitions and control inputs, $\{(x_k, u_k, x_{k+1})\}_{k=1}^{N}$, we can construct the corresponding lifted data matrices. For instance, if we have data $Z = [z_1, \dots, z_{N-1}]$, the future states $Z' = [z_2, \dots, z_N]$, and inputs $U = [u_1, \dots, u_{N-1}]$, the matrices $(A_l, B_l)$ can be found by solving a standard least-squares problem that minimizes the one-step [prediction error](@entry_id:753692), $\sum_{k=1}^{N-1} \|z_{k+1} - (A_l z_k + B_l u_k)\|^2$. This regression problem yields a linear surrogate model that captures the [nonlinear dynamics](@entry_id:140844) as seen through the lens of the chosen observables. Even with a trivial dictionary, such as $\psi(x)=x$, this approach provides a direct method for identifying a [local linear approximation](@entry_id:263289) of the system from data [@problem_id:2698771].

#### State and Parameter Estimation from Input-Output Data

In many engineering systems, the [internal state variables](@entry_id:750754) are not directly measurable; only inputs and outputs are accessible. Subspace identification methods are a class of powerful techniques designed to recover a full linear state-space model—the matrices $(A, B, C, D)$—directly from input-output data. These methods are foundational in modern [system identification](@entry_id:201290) and rely on elegant linear algebra, particularly projections and [singular value](@entry_id:171660) decompositions of block Hankel matrices constructed from the data.

A key intermediate step in many subspace algorithms involves estimating the state sequence itself. Once the output map $(C,D)$ is identified (up to a similarity transformation), one can recover an estimate of the state trajectory, $\hat{X}$, by solving a [least-squares problem](@entry_id:164198) that minimizes the mismatch between the measured outputs and the outputs predicted by the estimated states: $\hat{X} = \arg\min_{X} \| Y - C X - D U \|_{F}^{2}$. A crucial theoretical and practical issue arises here: state-space realizations are not unique. Any invertible [similarity transformation](@entry_id:152935) $T$ yields a new realization $(\tilde{A}, \tilde{B}, \tilde{C}) = (TAT^{-1}, TB, CT^{-1})$ that produces identical input-output behavior. Consequently, any estimated state sequence $\hat{X}$ is only determined up to such a transformation relative to the true sequence $X$. To meaningfully compare them, one must find the optimal similarity transformation $T^{\star}$ that best aligns the two, typically by solving another [least-squares problem](@entry_id:164198): $T^{\star} = \arg\min_{T} \| X - T\hat{X} \|_{F}^{2}$. This procedure allows for a basis-independent assessment of the [state estimation](@entry_id:169668) quality and is fundamental for validating data-driven identification methods in simulation studies [@problem_id:2698796].

### Direct Data-Driven Control and Performance Certification

While system identification provides a pathway to [model-based control](@entry_id:276825), a distinct and powerful class of data-driven methods aims to design controllers or certify system properties *directly* from data, bypassing the intermediate step of explicit [model identification](@entry_id:139651). These approaches often reframe control and analysis problems as [optimization problems](@entry_id:142739) over data-based representations.

#### Direct Controller Synthesis via Virtual Reference Feedback Tuning (VRFT)

Virtual Reference Feedback Tuning (VRFT) is an elegant and practical method for direct data-driven [controller design](@entry_id:274982). The core idea is to transform the controller tuning problem into a system identification problem. The user first specifies a desired closed-loop performance in the form of a [reference model](@entry_id:272821), $M(q)$, which dictates the ideal response from a reference signal $r$ to the plant output $y$, i.e., $y = M(q)r$.

Given a set of open-loop input-output data, $\{u(t), y(t)\}$, VRFT constructs a "virtual reference" signal, $r_v(t)$, that would have produced the measured output $y(t)$ *if* the loop had been closed and performing perfectly according to the model $M(q)$. This is achieved by filtering the output data with the inverse of the [reference model](@entry_id:272821): $r_v(t) = M(q)^{-1} y(t)$. From this, a "virtual error" signal, $e_v(t) = r_v(t) - y(t)$, is computed. The controller tuning problem is then posed as follows: find the controller parameters $\theta$ from a chosen class $C(q, \theta)$ such that the controller's output, when fed the virtual error, best matches the measured input data. This becomes a standard [least-squares regression](@entry_id:262382) problem, minimizing the error between the actual input $u(t)$ and the hypothetical controller output $C(q, \theta) e_v(t)$ over the dataset. This approach allows one to find the controller that makes the real system "look like" the ideal [reference model](@entry_id:272821), using only open-loop data [@problem_id:2698800] [@problem_id:2698752].

#### Data-Driven Optimal Control

Building upon Willems' Fundamental Lemma, direct data-driven methods can also tackle classic optimal control problems like the Linear Quadratic Regulator (LQR). The lemma guarantees that, for a controllable linear system, any possible trajectory can be expressed as a [linear combination](@entry_id:155091) of time-shifts of a single, sufficiently long trajectory, provided its input is "persistently exciting." This implies that a dataset generated with such an input contains a complete, albeit implicit, characterization of the system's dynamics.

This principle allows the LQR problem to be reformulated as an optimization over the space of all system behaviors compatible with the collected data, without ever identifying the matrices $(A,B)$. Both this direct approach and the indirect approach (identify $(A,B)$ first, then solve the Riccati equation) are guaranteed to converge to the true, model-based optimal LQR gain $K_{\star}$ in the limit of large, noise-free data, provided two sets of conditions are met. First, the underlying control problem must be well-posed, requiring [stabilizability](@entry_id:178956) of $(A,B)$ and detectability of $(Q^{1/2}, A)$. Second, the data must be sufficiently informative to uniquely characterize the system's dynamics. This is ensured if the input signal is persistently exciting of a sufficiently high order (typically $n+1$ for a state of dimension $n$). The [persistent excitation](@entry_id:263834) condition is the critical link that guarantees that the data contain enough information to learn the control-relevant dynamics [@problem_id:2698773].

#### Data-Driven Performance and Stability Certification

Beyond [controller synthesis](@entry_id:261816), data-driven methods provide powerful tools for the [formal verification](@entry_id:149180) of system properties, such as stability and input-output gains, without requiring a precise model.

One such application is the computation of the induced $\mathcal{L}_2$-gain of a system, which bounds the amplification of input [signal energy](@entry_id:264743) to output [signal energy](@entry_id:264743). Based on [dissipativity](@entry_id:162959) theory, a system has an $\mathcal{L}_2$-gain less than or equal to $\gamma$ if there exists a positive definite "storage function" $V(x)$ satisfying the inequality $V(x_{k+1}) - V(x_k) \leq \gamma^2 \|u_k\|^2 - \|y_k\|^2$ along all trajectories. By restricting $V(x)$ to a parameterized class of functions (e.g., [quadratic forms](@entry_id:154578) $V(x) = x^{\top}P x$), this inequality becomes a constraint on the parameters (e.g., the matrix $P$). Given a dataset of transitions $\{(x_k, u_k, y_k, x_{k+1})\}$, each transition imposes a [linear inequality](@entry_id:174297) on the parameters. Finding the minimum $\gamma$ for which a feasible parameter set exists can be formulated as a [convex optimization](@entry_id:137441) problem, such as a semidefinite program (SDP). This allows one to compute a certified upper bound on the system's gain directly from experimental data [@problem_id:2698778].

For nonlinear systems, particularly those with polynomial dynamics, data-driven stability analysis can be performed using Sum-of-Squares (SOS) programming. The procedure involves first fitting a polynomial [surrogate model](@entry_id:146376) to the observed data. Then, a polynomial Lyapunov function candidate $V(x)$ is sought. The conditions for stability—positivity of $V(x)$ and negativity of its change along trajectories, $\Delta V(x) = V(f(x)) - V(x)$—are converted into algebraic constraints. Specifically, one requires that $V(x) - \epsilon \|x\|^2$ and $-\Delta V(x) - c \|x\|^2$ are SOS polynomials. Using results from [real algebraic geometry](@entry_id:156016) like Putinar's Positivstellensatz, these conditions can be translated into a set of LMI constraints solvable via [semidefinite programming](@entry_id:166778). This powerful combination of [data-driven modeling](@entry_id:184110) and SOS optimization enables rigorous stability certification for unknown [nonlinear systems](@entry_id:168347) [@problem_id:2698775].

### Safe and Robust Learning-Based Control

A critical challenge for deploying [data-driven control](@entry_id:178277) in the real world, especially in safety-critical applications, is ensuring robustness to [model uncertainty](@entry_id:265539) and guaranteeing that system constraints are never violated, even during the learning process.

#### Safe Exploration and Initialization

When learning to control a new system, a "cold start" problem arises: how can one safely gather informative data without prior knowledge of the system's stability or constraints? A key strategy in safe learning is to use initial, limited data to compute a "Robustly Positively Invariant" (RPI) set. First, a few safe experiments are conducted to construct a set-membership uncertainty model, which is a set of all possible system parameters consistent with the data and known disturbance bounds. Then, for a given stabilizing feedback controller, one can compute the largest state set $\mathcal{S}$ such that for any state within $\mathcal{S}$, the next state is guaranteed to remain in $\mathcal{S}$ for all possible models in the [uncertainty set](@entry_id:634564) and for all bounded disturbances. This RPI set, if it also satisfies all state and input constraints, provides a guaranteed "safe envelope." The system can then explore and collect new data within this region without risk of becoming unsafe or unstable, providing a rigorous foundation for [online learning](@entry_id:637955) and adaptation [@problem_id:2698793].

#### Robust Model Predictive Control (MPC) with Data-Driven Models

Model Predictive Control (MPC) is an advanced control strategy that uses a model to optimize control actions over a future horizon while respecting system constraints. When the model is derived from data, it inevitably contains uncertainty, which must be handled to ensure robust [constraint satisfaction](@entry_id:275212). Tube-based MPC is a powerful framework for this purpose.

The core idea is to design a nominal controller for a nominal model and then construct a "tube" around the nominal state trajectory that is guaranteed to contain the true state of the system, despite [model uncertainty](@entry_id:265539) and disturbances. To guarantee that the true state $x_k$ and input $u_k$ satisfy their constraints, the constraints on the nominal state $z_k$ and input $v_k$ are tightened by an amount related to the size of this tube.

A critical component of any stabilizing MPC scheme is the [terminal set](@entry_id:163892), an RPI set where a simple, stabilizing terminal controller is applied. For this set to be valid, it must be ensured that for any state within it, the terminal control law does not violate input constraints. Given a data-driven model with bounded uncertainty and a corresponding Lyapunov function $V(x)=x^\top P x$ that defines the [terminal set](@entry_id:163892) $\{x : V(x) \le c\}$, one can calculate the largest level $c$ for which the input constraints are satisfied for all states in the set. This involves solving an optimization problem to find the maximum control effort exerted by the terminal controller over the [ellipsoid](@entry_id:165811) defined by $P$ and $c$ [@problem_id:2698811].

The radius of the error tube itself is determined by the [propagation of uncertainty](@entry_id:147381). The error dynamics, $e_{k+1} = x_{k+1} - z_{k+1}$, are driven by model mismatch and disturbances. By bounding the magnitude of these driving terms based on the data-derived [uncertainty sets](@entry_id:634516) (e.g., set-membership bounds), one can compute the radius $r$ of an invariant ball $\|e_k\| \le r$. This radius depends on the contraction rate of the error dynamics and the size of the uncertainties. The minimal radius can be found by solving a [fixed-point equation](@entry_id:203270), providing a direct link between the quality of the data-driven model and the degree of [constraint tightening](@entry_id:174986) required for robust safety. As learning progresses and [model uncertainty](@entry_id:265539) decreases, this tube radius can be reduced, leading to less conservative and higher-performance control [@problem_id:2698825] [@problem_id:2698776].

### Interdisciplinary Connections

The principles and techniques of [data-driven control](@entry_id:178277) are not confined to traditional control applications. They represent a versatile paradigm for modeling, analysis, and decision-making under uncertainty that is finding transformative applications across a diverse range of scientific and engineering domains.

#### Process Control and Manufacturing

In industrial [process control](@entry_id:271184), the Proportional-Integral-Derivative (PID) controller remains the undisputed workhorse. Data-driven methods provide a systematic way to tune and robustify these controllers under practical constraints. For instance, in chemical processes with significant and uncertain transport delays, open-loop tests are often unsafe. A robust tuning procedure can be designed in two stages: first, a conservative initial controller is found using a safe, closed-loop identification method (like the Ziegler-Nichols [ultimate sensitivity method](@entry_id:266302)). Then, with this safe controller in place, small-signal [frequency response](@entry_id:183149) experiments are conducted in closed loop. By measuring both the reference-to-output and reference-to-error responses, the full [loop transfer function](@entry_id:274447) can be reconstructed. The PID parameters can then be refined to shape the loop and guarantee a desired [phase margin](@entry_id:264609) across the entire range of delay uncertainty, systematically balancing performance and robustness [@problem_id:2731963].

At the cutting edge of manufacturing, particularly in high-value areas like biopharmaceutical production and cell therapy, data-driven methods are enabling the concept of the "[digital twin](@entry_id:171650)." For a complex process like differentiating stem cells in a bioreactor, a purely mechanistic model based on differential equations is often inaccurate due to biological variability. A purely data-driven model (e.g., a neural network) may not be robust or interpretable. The most effective digital twins are hybrid models that fuse these two approaches. A mechanistic model forms the core, capturing known mass balances and reaction kinetics. This core is augmented by a data-driven residual model (e.g., a Gaussian Process) that learns to correct for systemic model errors. This hybrid model is then integrated into a Bayesian filtering framework (like an Extended Kalman Filter), which assimilates real-time sensor data to continuously update its estimate of the hidden states (like [cell differentiation](@entry_id:274891) fraction) and uncertain parameters. This provides a live, probabilistic "twin" of the physical process, enabling real-time prediction of final product quality and [adaptive control](@entry_id:262887) to steer the process toward desired outcomes [@problem_id:2684657].

#### Computational Mechanics and Materials Science

Data-driven methods are also revolutionizing the field of [computational mechanics](@entry_id:174464) by enabling the discovery of material constitutive laws directly from experimental or simulation data. A major challenge in learning these models is ensuring that they obey fundamental physical principles. For [hyperelastic materials](@entry_id:190241), the [stored energy function](@entry_id:166355) must satisfy a mathematical property known as [polyconvexity](@entry_id:185154) to guarantee the existence of stable solutions. Polyconvexity requires the energy function to be a [convex function](@entry_id:143191) of its arguments and their matrix minors. Directly enforcing this property in a standard machine learning model is difficult. However, by leveraging architectural innovations like Input Convex Neural Networks (ICNNs), it is possible to design models that are guaranteed to be polyconvex by construction. An ICNN can be designed to learn an energy function that is explicitly convex in the [deformation gradient](@entry_id:163749), its [cofactor matrix](@entry_id:154168), and its determinant, thus automatically satisfying [polyconvexity](@entry_id:185154) and providing a physically consistent, data-driven [constitutive model](@entry_id:747751) [@problem_id:2629320].

Beyond elasticity, data-driven models are being used to capture more complex, history-dependent material behaviors like [viscoplasticity](@entry_id:165397). A learned [flow rule](@entry_id:177163) can describe the rate of plastic strain as a function of the current stress, capturing phenomena like [yield strength](@entry_id:162154) and rate-dependence. Once such a surrogate model is trained, it can be integrated into finite element simulations to predict the material's response under complex loading conditions. A key performance metric for structures under cyclic loading is the energy dissipated per cycle, which corresponds to the area of the [stress-strain hysteresis](@entry_id:189261) loop. By numerically integrating the learned viscoplastic model over a loading cycle, one can accurately predict this dissipation, providing critical insights into [material fatigue](@entry_id:260667) and failure that would be difficult to obtain from purely analytical models [@problem_id:2898921]. This demonstrates the power of data-driven surrogates to act as plug-in components within larger physics-based simulation frameworks.