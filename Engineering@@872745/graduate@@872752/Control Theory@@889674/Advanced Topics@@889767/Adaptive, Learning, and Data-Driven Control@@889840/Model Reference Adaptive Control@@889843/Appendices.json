{"hands_on_practices": [{"introduction": "The cornerstone of modern adaptive control is the guarantee of stability. This first practice provides a hands-on derivation of an adaptation law using the Lyapunov direct method, the most powerful tool for proving stability in MRAC systems. By working through the thermal control of a hypothetical chemical reactor, you will construct a Lyapunov function and use it to derive an update rule that ensures the tracking error converges to zero, providing rigorous stability guarantees. [@problem_id:1591800]", "problem": "Consider the problem of controlling the temperature, $y(t)$, of a simple chemical reactor. The thermal dynamics of the reactor are described by the first-order linear differential equation:\n$$ \\dot{y}(t) = -a y(t) + b u(t) $$\nwhere $u(t)$ is the rate of heat supplied by a heater (the control input), $b$ is a known positive constant representing the heater's efficiency, and $a$ is an unknown but constant positive parameter representing the rate of heat dissipation to the environment.\n\nThe objective is to design a controller that makes the reactor's temperature $y(t)$ asymptotically track the temperature profile $y_m(t)$ of a stable reference model. The reference model is given by:\n$$ \\dot{y}_m(t) = -a_m y_m(t) + b_m r(t) $$\nwhere $a_m$ and $b_m$ are known positive constants, and $r(t)$ is a bounded reference command signal.\n\nA Model Reference Adaptive Control (MRAC) strategy is employed. The control input $u(t)$ is structured as:\n$$ u(t) = \\frac{\\hat{a}(t) - a_m}{b} y(t) + \\frac{b_m}{b} r(t) $$\nHere, $\\hat{a}(t)$ is the real-time estimate of the unknown parameter $a$. The key to this control strategy is to find an *adaptation law*, a differential equation for $\\dot{\\hat{a}}(t)$, that guarantees the stability of the system and ensures the tracking error $e(t) = y(t) - y_m(t)$ converges to zero.\n\nYour task is to derive this adaptation law using a Lyapunov-based design procedure. First, derive the differential equation that governs the tracking error $e(t)$. Then, construct a quadratic Lyapunov function candidate using the tracking error $e(t)$ and the parameter estimation error $\\tilde{a}(t) = \\hat{a}(t) - a$. Finally, use this Lyapunov function to derive the update rule for $\\dot{\\hat{a}}(t)$ that ensures stability.\n\nPresent your final answer as an expression for $\\dot{\\hat{a}}(t)$. The expression should be in terms of the tracking error $e(t)$, the plant output $y(t)$, and a positive constant $\\gamma$, which serves as the adaptation gain and should be introduced in your Lyapunov function.", "solution": "The plant is $\\dot{y}(t)=-a y(t)+b u(t)$ and the reference model is $\\dot{y}_{m}(t)=-a_{m} y_{m}(t)+b_{m} r(t)$, with $a0$, $b0$, $a_{m}0$, and $b_{m}0$. The control is\n$$\nu(t)=\\frac{\\hat{a}(t)-a_{m}}{b}y(t)+\\frac{b_{m}}{b}r(t).\n$$\nSubstituting $u(t)$ into the plant yields\n$$\n\\dot{y}(t)=-a y(t)+b\\left(\\frac{\\hat{a}(t)-a_{m}}{b}y(t)+\\frac{b_{m}}{b}r(t)\\right)=-a y(t)+(\\hat{a}(t)-a_{m})y(t)+b_{m}r(t).\n$$\nHence\n$$\n\\dot{y}(t)=-(a+a_{m}-\\hat{a}(t))y(t)+b_{m}r(t).\n$$\nDefine the tracking error $e(t)=y(t)-y_{m}(t)$. Its derivative is\n$$\n\\dot{e}(t)=\\dot{y}(t)-\\dot{y}_{m}(t)=\\bigl(-(a+a_{m}-\\hat{a}(t))y(t)+b_{m}r(t)\\bigr)-\\bigl(-a_{m}y_{m}(t)+b_{m}r(t)\\bigr).\n$$\nThis simplifies to\n$$\n\\dot{e}(t)=-(a+a_{m}-\\hat{a}(t))y(t)+a_{m}y_{m}(t).\n$$\nUsing $y_{m}(t)=y(t)-e(t)$, we obtain\n$$\n\\dot{e}(t)=-(a+a_{m}-\\hat{a}(t))y(t)+a_{m}(y(t)-e(t))=-a y(t)+\\hat{a}(t)y(t)-a_{m}e(t).\n$$\nIntroduce the parameter estimation error $\\tilde{a}(t)=\\hat{a}(t)-a$. Then the error dynamics become\n$$\n\\dot{e}(t)=-a_{m}e(t)+\\tilde{a}(t)\\,y(t).\n$$\n\nChoose the Lyapunov function candidate\n$$\nV(t)=\\frac{1}{2}e^{2}(t)+\\frac{1}{2\\gamma}\\tilde{a}^{2}(t),\n$$\nwhere $\\gamma0$ is the adaptation gain. Since $a$ is constant, $\\dot{\\tilde{a}}(t)=\\dot{\\hat{a}}(t)$. The time derivative of $V$ along trajectories is\n$$\n\\dot{V}(t)=e(t)\\dot{e}(t)+\\frac{1}{\\gamma}\\tilde{a}(t)\\dot{\\tilde{a}}(t)=e(t)\\bigl(-a_{m}e(t)+\\tilde{a}(t)\\,y(t)\\bigr)+\\frac{1}{\\gamma}\\tilde{a}(t)\\dot{\\hat{a}}(t).\n$$\nTherefore\n$$\n\\dot{V}(t)=-a_{m}e^{2}(t)+e(t)\\tilde{a}(t)\\,y(t)+\\frac{1}{\\gamma}\\tilde{a}(t)\\dot{\\hat{a}}(t).\n$$\nTo ensure $\\dot{V}(t)\\leq 0$, choose $\\dot{\\hat{a}}(t)$ to cancel the cross term $e(t)\\tilde{a}(t)\\,y(t)$. Selecting\n$$\n\\dot{\\hat{a}}(t)=-\\gamma\\,e(t)\\,y(t)\n$$\ngives\n$$\n\\dot{V}(t)=-a_{m}e^{2}(t)\\leq 0.\n$$\nThus $V(t)$ is nonincreasing, $e(t)$ and $\\tilde{a}(t)$ are bounded, and by standard Lyapunov arguments (e.g., LaSalle or Barbalat’s lemma with bounded signals), the tracking error $e(t)$ converges to zero asymptotically. The required adaptation law is the gradient update\n$$\n\\dot{\\hat{a}}(t)=-\\gamma\\,e(t)\\,y(t).\n$$", "answer": "$$\\boxed{-\\gamma\\,e(t)\\,y(t)}$$", "id": "1591800"}, {"introduction": "While theoretical models are often continuous, practical control systems are implemented on digital computers that operate in discrete time steps. This exercise bridges the gap between continuous-time theory and digital application by exploring a discrete-time MRAC system for satellite thermal regulation. You will derive the adaptation laws for controller gains using a gradient-descent method, offering insight into how these algorithms are realized in a sampled-data environment. [@problem_id:1591827]", "problem": "A crucial component in a next-generation communication satellite requires precise thermal regulation. Its temperature dynamics can be simplified and modeled by the following first-order discrete-time system:\n$$y_p(k+1) = a_p y_p(k) + b_p u(k)$$\nHere, $k$ is the discrete time index, $y_p(k)$ represents the temperature deviation of the component from its nominal operating point, and $u(k)$ is the control signal sent to the thermoelectric cooler. The system parameters $a_p$ and $b_p$ are unknown but constant, representing the thermal inertia and the cooler effectiveness, respectively. It is known from physical principles that $b_p  0$.\n\nTo ensure stable and predictable thermal behavior, the component's temperature response is required to follow a specified reference model:\n$$y_m(k+1) = a_m y_m(k) + b_m r(k)$$\nIn this model, $y_m(k)$ is the desired temperature deviation, $r(k)$ is the external command signal, and $a_m$ and $b_m$ are known, fixed parameters defining the ideal response, with $|a_m|  1$ to guarantee stability.\n\nA direct Model Reference Adaptive Control (MRAC) scheme is employed to achieve this. The control law has the form:\n$$u(k) = \\theta_1(k) y_p(k) + \\theta_2(k) r(k)$$\nwhere $\\theta_1(k)$ and $\\theta_2(k)$ are the adaptive gains. These gains are updated at each time step based on a gradient-descent method aimed at minimizing the squared tracking error at the subsequent time step, defined by the cost function $J = \\frac{1}{2}e(k+1)^2$, where the tracking error is $e(k+1) = y_p(k+1) - y_m(k+1)$. The update rule is given by:\n$$\\theta_i(k+1) = \\theta_i(k) - \\gamma_0 \\frac{\\partial J}{\\partial \\theta_i(k)} \\quad \\text{for } i \\in \\{1, 2\\}$$\nwhere $\\gamma_0$ is a base positive adaptation rate. For the final expressions, the unknown physical parameter $b_p$ that appears in the derivation must be absorbed into a new, single positive adaptation gain denoted by $\\gamma$.\n\nDerive the explicit update expressions for the adaptive gains $\\theta_1(k+1)$ and $\\theta_2(k+1)$. Your final answer should be presented as a $1 \\times 2$ row matrix containing the complete expression for $\\theta_1(k+1)$ in the first column and $\\theta_2(k+1)$ in the second.", "solution": "The goal is to find the adaptation laws for the controller parameters $\\theta_1(k)$ and $\\theta_2(k)$. The adaptation is based on a gradient-descent minimization of the cost function $J = \\frac{1}{2}e(k+1)^2$, where $e(k+1) = y_p(k+1) - y_m(k+1)$ is the tracking error.\n\nThe update rule is given as:\n$$\\theta_i(k+1) = \\theta_i(k) - \\gamma_0 \\frac{\\partial J}{\\partial \\theta_i(k)}$$\n\nFirst, we apply the chain rule to compute the partial derivative of the cost function $J$ with respect to each parameter $\\theta_i(k)$:\n$$\\frac{\\partial J}{\\partial \\theta_i(k)} = \\frac{\\partial}{\\partial \\theta_i(k)} \\left( \\frac{1}{2} e(k+1)^2 \\right) = e(k+1) \\frac{\\partial e(k+1)}{\\partial \\theta_i(k)}$$\n\nNext, we need to find the sensitivity derivative, which describes how the error $e(k+1)$ changes with respect to the controller parameters at the previous time step, $\\theta_i(k)$.\nThe error is defined as $e(k+1) = y_p(k+1) - y_m(k+1)$. The reference model output $y_m(k+1)$ is generated by $y_m(k+1) = a_m y_m(k) + b_m r(k)$ and does not depend on the controller parameters $\\theta_1(k)$ and $\\theta_2(k)$. Therefore, the derivative of the error is simply the derivative of the plant output:\n$$\\frac{\\partial e(k+1)}{\\partial \\theta_i(k)} = \\frac{\\partial}{\\partial \\theta_i(k)} \\left( y_p(k+1) - y_m(k+1) \\right) = \\frac{\\partial y_p(k+1)}{\\partial \\theta_i(k)}$$\n\nNow, we compute the derivative of the plant output $y_p(k+1)$ with respect to each parameter. The plant dynamics are given by $y_p(k+1) = a_p y_p(k) + b_p u(k)$. We substitute the control law $u(k) = \\theta_1(k) y_p(k) + \\theta_2(k) r(k)$ into the plant equation:\n$$y_p(k+1) = a_p y_p(k) + b_p \\left( \\theta_1(k) y_p(k) + \\theta_2(k) r(k) \\right)$$\n\nWe can now calculate the partial derivatives with respect to $\\theta_1(k)$ and $\\theta_2(k)$. Note that $y_p(k)$ and $r(k)$ are treated as constants in this differentiation as they are values from the previous time step.\nFor $\\theta_1(k)$:\n$$\\frac{\\partial y_p(k+1)}{\\partial \\theta_1(k)} = \\frac{\\partial}{\\partial \\theta_1(k)} \\left[ a_p y_p(k) + b_p \\theta_1(k) y_p(k) + b_p \\theta_2(k) r(k) \\right] = b_p y_p(k)$$\nFor $\\theta_2(k)$:\n$$\\frac{\\partial y_p(k+1)}{\\partial \\theta_2(k)} = \\frac{\\partial}{\\partial \\theta_2(k)} \\left[ a_p y_p(k) + b_p \\theta_1(k) y_p(k) + b_p \\theta_2(k) r(k) \\right] = b_p r(k)$$\n\nNow we substitute these sensitivity derivatives back into the expressions for $\\frac{\\partial J}{\\partial \\theta_i(k)}$:\n$$\\frac{\\partial J}{\\partial \\theta_1(k)} = e(k+1) \\frac{\\partial y_p(k+1)}{\\partial \\theta_1(k)} = e(k+1) b_p y_p(k)$$\n$$\\frac{\\partial J}{\\partial \\theta_2(k)} = e(k+1) \\frac{\\partial y_p(k+1)}{\\partial \\theta_2(k)} = e(k+1) b_p r(k)$$\n\nFinally, we substitute these gradients into the given update rule $\\theta_i(k+1) = \\theta_i(k) - \\gamma_0 \\frac{\\partial J}{\\partial \\theta_i(k)}$:\nFor $\\theta_1(k+1)$:\n$$\\theta_1(k+1) = \\theta_1(k) - \\gamma_0 \\left( e(k+1) b_p y_p(k) \\right)$$\nFor $\\theta_2(k+1)$:\n$$\\theta_2(k+1) = \\theta_2(k) - \\gamma_0 \\left( e(k+1) b_p r(k) \\right)$$\n\nThe problem states that the unknown constant $b_p$ must be absorbed into a single adaptation gain $\\gamma$. We define a new gain $\\gamma = \\gamma_0 b_p$. Since $\\gamma_0  0$ and it is given that $b_p  0$, the combined adaptation gain $\\gamma$ is also positive.\n\nThe final adaptation laws are:\n$$\\theta_1(k+1) = \\theta_1(k) - \\gamma e(k+1) y_p(k)$$\n$$\\theta_2(k+1) = \\theta_2(k) - \\gamma e(k+1) r(k)$$\n\nThese expressions provide the explicit update rules for the adaptive gains. The error $e(k+1)$ is calculated at each step using the measured plant output $y_p(k+1)$ and the calculated model output $y_m(k+1)$. The gains are then updated using this error and the signal values from the previous step, $y_p(k)$ and $r(k)$.\n\nThe answer is to be presented as a $1 \\times 2$ row matrix. The first element is the expression for $\\theta_1(k+1)$ and the second element is the expression for $\\theta_2(k+1)$.", "answer": "$$\\boxed{\\begin{pmatrix} \\theta_1(k) - \\gamma e(k+1) y_p(k)  \\theta_2(k) - \\gamma e(k+1) r(k) \\end{pmatrix}}$$", "id": "1591827"}, {"introduction": "The stability proofs for Lyapunov-based MRAC, such as the one explored in our first practice, often depend on a critical system property: the error dynamics transfer function must be Strictly Positive Real (SPR). This advanced computational exercise delves into this fundamental requirement, guiding you to write a program that verifies the SPR condition using the celebrated Kalman-Yakubovich-Popov (KYP) lemma. This practice connects high-level control theory with practical, numerical verification, demonstrating how to check if the theoretical stability conditions for an adaptive system are met. [@problem_id:2725781]", "problem": "Consider single-input single-output linear time-invariant state-space systems defined by matrices $A \\in \\mathbb{R}^{2 \\times 2}$, $B \\in \\mathbb{R}^{2 \\times 1}$, and $C \\in \\mathbb{R}^{1 \\times 2}$, with input $u \\in \\mathbb{R}$, state $x \\in \\mathbb{R}^{2}$, and output $y \\in \\mathbb{R}$. The transfer function is $G(s) = C (s I - A)^{-1} B$. A rational function $G(s)$ is strictly positive real (SPR) if it is real-rational, has no poles in $\\operatorname{Re}(s) \\ge 0$, and satisfies $\\operatorname{Re}[G(j \\omega)]  0$ for all $\\omega \\in \\mathbb{R}$. A standard route in model reference adaptive control (MRAC) is to verify strict positive realness via a Lyapunov inequality consistent with the Kalman-Yakubovich-Popov lemma, by finding a symmetric positive definite matrix $P \\in \\mathbb{R}^{2 \\times 2}$ that satisfies the following constraints:\n- $P = P^\\top$,\n- $P B = C^\\top$,\n- $A^\\top P + P A \\prec 0$ (strict negative definiteness),\n- $C B  0$.\n\nWhen such a matrix $P$ exists, the function $V(x) = \\tfrac{1}{2} x^\\top P x$ is a storage function demonstrating passivity with a strict margin, which implies that $G(s)$ is strictly positive real. This storage function interpretation is central in adaptive control Lyapunov analyses.\n\nTask: Write a program that, for each given triple $(A,B,C)$, determines whether there exists a symmetric positive definite matrix $P$ that satisfies $P B = C^\\top$, $A^\\top P + P A \\prec 0$, and $C B  0$. Your program must return a boolean for each test case: $\\,\\text{True}\\,$ if such a $P$ exists, and $\\,\\text{False}\\,$ otherwise. The search should be performed in a mathematically sound and numerically robust way and must not rely on any external user input.\n\nYour program must implement the decision for the following test suite of parameter values (all entries are real and dimensionally consistent):\n- Test case $1$ (happy path, Hurwitz $A$ and feasible constraints):\n  - $A = \\begin{bmatrix} -1  0 \\\\ 0  -1 \\end{bmatrix}$,\n  - $B = \\begin{bmatrix} 1 \\\\ 2 \\end{bmatrix}$,\n  - $C = \\begin{bmatrix} 3  3.5 \\end{bmatrix}$.\n- Test case $2$ (violates $C B  0$):\n  - $A = \\begin{bmatrix} -1  0 \\\\ 0  -1 \\end{bmatrix}$,\n  - $B = \\begin{bmatrix} 1 \\\\ 2 \\end{bmatrix}$,\n  - $C = \\begin{bmatrix} -3  -3.5 \\end{bmatrix}$.\n- Test case $3$ (unstable $A$):\n  - $A = \\begin{bmatrix} 0.2  0 \\\\ 0  -1 \\end{bmatrix}$,\n  - $B = \\begin{bmatrix} 1 \\\\ 2 \\end{bmatrix}$,\n  - $C = \\begin{bmatrix} 3  3.5 \\end{bmatrix}$.\n- Test case $4$ (marginally stable $A$ with a zero eigenvalue):\n  - $A = \\begin{bmatrix} 0  0 \\\\ 0  -1 \\end{bmatrix}$,\n  - $B = \\begin{bmatrix} 1 \\\\ 2 \\end{bmatrix}$,\n  - $C = \\begin{bmatrix} 3  3.5 \\end{bmatrix}$.\n- Test case $5$ (happy path with different parameters):\n  - $A = \\begin{bmatrix} -2  0 \\\\ 0  -2 \\end{bmatrix}$,\n  - $B = \\begin{bmatrix} 2 \\\\ -1 \\end{bmatrix}$,\n  - $C = \\begin{bmatrix} 1.8  -0.4 \\end{bmatrix}$.\n\nImportant details and constraints you must enforce in your program’s logic:\n- $P$ must be symmetric and positive definite.\n- The equality $P B = C^\\top$ must hold exactly for the candidate $P$ used to check the strict inequality.\n- The strict matrix inequality $A^\\top P + P A \\prec 0$ must be verified via eigenvalues being strictly negative.\n- The scalar inequality $C B  0$ must be verified directly.\n- All numeric thresholds used to judge definiteness must be explicitly justified and implemented consistently.\n\nFinal output format:\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (e.g., $[result_1,result_2,\\dots]$), where each $result_i$ is either $\\text{True}$ or $\\text{False}$.\n- No angles or physical units are involved in this problem.\n\nYour program must be fully deterministic and self-contained, with no user input, and it must compute and output the results for the five test cases described above in the exact order given, as a single list on one line.", "solution": "The problem as stated is valid. It is scientifically grounded in the principles of Lyapunov stability theory and the Kalman-Yakubovich-Popov (KYP) lemma from control theory, which provides conditions for a system's transfer function to be strictly positive real (SPR). The problem is well-posed, objective, and contains all necessary information to arrive at a deterministic solution.\n\nThe task is to determine, for a given single-input single-output (SISO) linear time-invariant (LTI) system defined by matrices $(A, B, C)$, whether there exists a symmetric positive definite matrix $P$ that satisfies a set of conditions. These conditions are:\n1.  $P = P^\\top$ (Symmetry)\n2.  $P \\succ 0$ (Positive Definiteness)\n3.  $C B  0$\n4.  $P B = C^\\top$\n5.  $A^\\top P + P A \\prec 0$ (Negative Definiteness)\n\nLet us analyze these conditions systematically.\n\nFirst, a crucial necessary condition for the existence of a positive definite matrix $P$ satisfying $A^\\top P + P A \\prec 0$ is that the matrix $A$ must be Hurwitz. A matrix is Hurwitz if all of its eigenvalues have strictly negative real parts. Let us prove this by contradiction. Suppose there exists an eigenvector $v$ of $A$ with corresponding eigenvalue $\\lambda$ such that $\\operatorname{Re}(\\lambda) \\ge 0$. Then $Av = \\lambda v$. If $A^\\top P + P A$ were negative definite, it must be that $v^* (A^\\top P + P A) v  0$. Evaluating this expression gives:\n$$v^* (A^\\top P + P A) v = (Av)^* P v + v^* P (Av) = (\\lambda v)^* P v + v^* P (\\lambda v) = \\bar{\\lambda} v^* P v + \\lambda v^* P v$$\n$$= (\\bar{\\lambda} + \\lambda) v^* P v = 2 \\operatorname{Re}(\\lambda) v^* P v$$\nSince $P$ is required to be positive definite, $v^* P v  0$. Given our assumption that $\\operatorname{Re}(\\lambda) \\ge 0$, the entire expression $2 \\operatorname{Re}(\\lambda) v^* P v$ must be greater than or equal to $0$. This contradicts the requirement that $v^* (A^\\top P + P A) v  0$. Therefore, $A$ must be Hurwitz. This provides a simple initial check.\n\nSecond, the scalar condition $C B  0$ is a direct and simple calculation. If it is not met, no solution exists.\n\nIf both of these necessary conditions are satisfied, we proceed to find if a matrix $P$ exists that satisfies the remaining constraints. The matrix $P$ is a symmetric $2 \\times 2$ matrix, so it can be written as:\n$$P = \\begin{bmatrix} p_{11}  p_{12} \\\\ p_{12}  p_{22} \\end{bmatrix}$$\nThis matrix has three unknown elements: $p_{11}$, $p_{12}$, and $p_{22}$. The constraint $P B = C^\\top$ provides a system of two linear equations in these three unknowns:\n$$\\begin{bmatrix} p_{11}  p_{12} \\\\ p_{12}  p_{22} \\end{bmatrix} \\begin{bmatrix} b_1 \\\\ b_2 \\end{bmatrix} = \\begin{bmatrix} c_1 \\\\ c_2 \\end{bmatrix}$$\nThis expands to:\n$$p_{11} b_1 + p_{12} b_2 = c_1$$\n$$p_{12} b_1 + p_{22} b_2 = c_2$$\nSince $B$ is not the zero vector in any meaningful control problem (or the given test cases), this system is underdetermined. This implies that if a solution exists, there is a one-parameter family of solutions. We can express the elements of $P$ in terms of a single free parameter, which we shall call $\\alpha$. For instance, if $b_1 \\neq 0$ and $b_2 \\neq 0$, we can set $p_{12} = \\alpha$ and solve for $p_{11}$ and $p_{22}$:\n$$p_{11}(\\alpha) = \\frac{c_1 - \\alpha b_2}{b_1}$$\n$$p_{22}(\\alpha) = \\frac{c_2 - \\alpha b_1}{b_2}$$\nIf one component of $B$ is zero, we choose a different free parameter, but the principle remains the same. The matrix $P(\\alpha)$ is now a linear function of $\\alpha$.\n\nThe problem is now reduced to finding if there exists a real number $\\alpha$ for which $P(\\alpha)$ satisfies the two matrix inequalities:\n1.  $P(\\alpha) \\succ 0$\n2.  $Q(\\alpha) = A^\\top P(\\alpha) + P(\\alpha) A \\prec 0$\n\nFor a $2 \\times 2$ symmetric matrix $M = \\begin{bmatrix} m_{11}  m_{12} \\\\ m_{12}  m_{22} \\end{bmatrix}$, positive definiteness ($M \\succ 0$) is equivalent to $m_{11}  0$ and $\\det(M)  0$. Negative definiteness ($M \\prec 0$) is equivalent to $m_{11}  0$ and $\\det(M)  0$.\n\nApplying this to $P(\\alpha)$:\n-   $p_{11}(\\alpha)  0$: This is a linear inequality in $\\alpha$.\n-   $\\det(P(\\alpha))  0$: As shown in detailed derivation, substituting the expressions for $p_{ij}(\\alpha)$ yields $\\det(P(\\alpha)) = \\frac{c_1c_2 - \\alpha(CB)}{b_1b_2}$. This is also a linear inequality in $\\alpha$.\nThese two linear inequalities define an open interval $(\\alpha_{\\min,P}, \\alpha_{\\max,P})$ for $\\alpha$.\n\nApplying this to $Q(\\alpha)$:\nThe elements of $Q(\\alpha)$ are linear functions of $\\alpha$, as $P(\\alpha)$ is linear in $\\alpha$. Let $Q(\\alpha) = \\begin{bmatrix} q_{11}(\\alpha)  q_{12}(\\alpha) \\\\ q_{12}(\\alpha)  q_{22}(\\alpha) \\end{bmatrix}$.\n-   $q_{11}(\\alpha)  0$: This is a linear inequality in $\\alpha$.\n-   $\\det(Q(\\alpha))  0$: Since $q_{ij}(\\alpha)$ are linear, $\\det(Q(\\alpha)) = q_{11}(\\alpha)q_{22}(\\alpha) - q_{12}(\\alpha)^2$ is a quadratic function of $\\alpha$, say $f(\\alpha) = k_2\\alpha^2 + k_1\\alpha + k_0$. We require $f(\\alpha)  0$.\n\nThe final step is to determine if there exists an $\\alpha$ that satisfies all these inequalities simultaneously. First, we find the intersection of all the linear inequalities, which results in a single open interval $(\\alpha_{\\min}, \\alpha_{\\max})$. If this interval is empty (i.e., $\\alpha_{\\min} \\ge \\alpha_{\\max}$), no solution exists. Otherwise, we must check if this interval has a non-empty intersection with the set of $\\alpha$ for which the quadratic inequality $f(\\alpha)  0$ holds. This is a standard analysis of the roots and sign of the quadratic polynomial $f(\\alpha)$.\n\nThe overall algorithm is:\n1.  Verify that $A$ is Hurwitz. If not, the answer is False.\n2.  Verify that $C B  0$. If not, the answer is False.\n3.  Parameterize $P$ with a single variable $\\alpha$ based on the constraint $P B = C^\\top$.\n4.  Derive the set of linear inequalities on $\\alpha$ from $P(\\alpha) \\succ 0$ and the trace condition for $Q(\\alpha) \\prec 0$ (i.e., $q_{11}(\\alpha)  0$). Find the intersection of these, an interval $(\\alpha_{\\min}, \\alpha_{\\max})$. If this interval is empty, return False.\n5.  Derive the quadratic inequality $\\det(Q(\\alpha))  0$.\n6.  Analytically determine if the solution set for the quadratic inequality has a non-empty intersection with the interval $(\\alpha_{\\min}, \\alpha_{\\max})$. If it does, a valid $P$ exists; return True. Otherwise, return False. Numerical tolerance must be used for all comparisons.", "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the problem for the given test cases.\n    \"\"\"\n    test_cases = [\n        # Test case 1\n        {'A': np.array([[-1., 0.], [0., -1.]]),\n         'B': np.array([[1.], [2.]]),\n         'C': np.array([[3., 3.5]])},\n        # Test case 2\n        {'A': np.array([[-1., 0.], [0., -1.]]),\n         'B': np.array([[1.], [2.]]),\n         'C': np.array([[-3., -3.5]])},\n        # Test case 3\n        {'A': np.array([[0.2, 0.], [0., -1.]]),\n         'B': np.array([[1.], [2.]]),\n         'C': np.array([[3., 3.5]])},\n        # Test case 4\n        {'A': np.array([[0., 0.], [0., -1.]]),\n         'B': np.array([[1.], [2.]]),\n         'C': np.array([[3., 3.5]])},\n        # Test case 5\n        {'A': np.array([[-2., 0.], [0., -2.]]),\n         'B': np.array([[2.], [-1.]]),\n         'C': np.array([[1.8, -0.4]])}\n    ]\n\n    results = [_check_spr_conditions(**case) for case in test_cases]\n    print(f\"[{','.join(map(str, results))}]\")\n\ndef _check_spr_conditions(A, B, C):\n    \"\"\"\n    Checks if a symmetric positive definite P exists for the given (A, B, C).\n    \"\"\"\n    TOL = 1e-9\n\n    # Condition 1: A must be Hurwitz (all eigenvalues have negative real parts)\n    eigs_A = np.linalg.eigvals(A)\n    if np.max(np.real(eigs_A)) = -TOL:\n        return False\n\n    # Condition 2: CB  0\n    if (C @ B)[0, 0] = TOL:\n        return False\n\n    # Parameterize P using PB = C^T. Let P = [p11, p12; p12, p22].\n    # The elements p_ij are expressed as linear functions of a free parameter 'alpha'.\n    # p_ij(alpha) = m_ij * alpha + c_ij\n    b1, b2 = B[0, 0], B[1, 0]\n    c1, c2 = C[0, 0], C[0, 1]\n    \n    p_coeffs = {} # Stores (m, c) for each p_ij\n\n    if abs(b1)  TOL:\n        if abs(b2)  TOL: # General case, let p12 be the free parameter\n            p_coeffs['p12'] = (1.0, 0.0)\n            # p11 = (c1 - alpha * b2) / b1\n            p_coeffs['p11'] = (-b2 / b1, c1 / b1)\n            # p22 = (c2 - alpha * b1) / b2\n            p_coeffs['p22'] = (-b1 / b2, c2 / b2)\n        else: # b2 is zero, let p22 be the free parameter\n            p_coeffs['p22'] = (1.0, 0.0)\n            p_coeffs['p11'] = (0.0, c1 / b1)\n            p_coeffs['p12'] = (0.0, c2 / b1)\n    else: # b1 is zero, so b2 must be non-zero, let p11 be the free parameter\n        p_coeffs['p11'] = (1.0, 0.0)\n        p_coeffs['p12'] = (0.0, c1 / b2)\n        p_coeffs['p22'] = (0.0, c2 / b2)\n\n    p11_m, p11_c = p_coeffs['p11']\n    p12_m, p12_c = p_coeffs['p12']\n    p22_m, p22_c = p_coeffs['p22']\n\n    # Aggregate linear inequalities to find the feasible interval for alpha\n    alpha_min, alpha_max = -np.inf, np.inf\n\n    # Helper function to update the interval [alpha_min, alpha_max]\n    def update_interval(m, c, is_gt):\n        nonlocal alpha_min, alpha_max\n        # m*alpha + c  0 if is_gt, else m*alpha + c  0\n        if abs(m)  TOL:\n            return c  TOL if is_gt else c  -TOL\n        \n        root = -c / m\n        if is_gt: # m*alpha  -c\n            if m  0: alpha_min = max(alpha_min, root)\n            else: alpha_max = min(alpha_max, root)\n        else: # m*alpha  -c\n            if m  0: alpha_max = min(alpha_max, root)\n            else: alpha_min = max(alpha_min, root)\n        return True\n\n    # From P  0: p11  0\n    if not update_interval(p11_m, p11_c, is_gt=True): return False\n\n    # From P  0: det(P)  0. This is linear in alpha.\n    det_P_m = p11_m * p22_c + p11_c * p22_m - 2 * p12_m * p12_c\n    det_P_c = p11_c * p22_c - p12_c**2\n    if not update_interval(det_P_m, det_P_c, is_gt=True): return False\n\n    # From Q = A'P + PA  0.\n    a11, a12, a21, a22 = A[0,0], A[0,1], A[1,0], A[1,1]\n    \n    # Coefficients for q_ij(alpha) = m * alpha + c\n    q11_m = 2 * (a11 * p11_m + a21 * p12_m)\n    q11_c = 2 * (a11 * p11_c + a21 * p12_c)\n    q22_m = 2 * (a12 * p12_m + a22 * p22_m)\n    q22_c = 2 * (a12 * p12_c + a22 * p22_c)\n    q12_m = a11 * p12_m + a12 * p11_m + a21 * p22_m + a22 * p12_m\n    q12_c = a11 * p12_c + a12 * p11_c + a21 * p22_c + a22 * p12_c\n\n    # From Q  0: q11  0\n    if not update_interval(q11_m, q11_c, is_gt=False): return False\n\n    # Check if a consistent interval for linear constraints exists\n    if alpha_min = alpha_max - TOL:\n        return False\n        \n    # From Q  0: det(Q)  0. This is a quadratic inequality.\n    # f(alpha) = k2*alpha^2 + k1*alpha + k0  0\n    k2 = q11_m * q22_m - q12_m**2\n    k1 = q11_m * q22_c + q11_c * q22_m - 2 * q12_m * q12_c\n    k0 = q11_c * q22_c - q12_c**2\n\n    if abs(k2)  TOL: # Linear or constant case for det(Q)\n        dummy_m, dummy_c = k1, k0\n        if abs(dummy_m)  TOL:\n            return dummy_c  TOL\n        \n        root = -dummy_c / dummy_m\n        if dummy_m  0: # alpha  root\n            return max(alpha_min, root)  alpha_max - TOL\n        else: # alpha  root\n            return alpha_min  min(alpha_max, root) - TOL\n    else: # Quadratic case\n        delta = k1**2 - 4 * k2 * k0\n        if delta  -TOL:\n            return k2  0\n        else:\n            delta = max(0, delta) # Handle small negative delta from precision loss\n            sqrt_delta = np.sqrt(delta)\n            r1 = (-k1 - sqrt_delta) / (2 * k2)\n            r2 = (-k1 + sqrt_delta) / (2 * k2)\n            if r1  r2: r1, r2 = r2, r1\n            \n            if k2  0: # f  0 outside roots\n                overlap1 = alpha_min  min(alpha_max, r1) - TOL\n                overlap2 = max(alpha_min, r2)  alpha_max - TOL\n                return overlap1 or overlap2\n            else: # f  0 between roots\n                intersect_min = max(alpha_min, r1)\n                intersect_max = min(alpha_max, r2)\n                return intersect_min  intersect_max - TOL\n\nif __name__ == '__main__':\n    solve()\n```", "id": "2725781"}]}