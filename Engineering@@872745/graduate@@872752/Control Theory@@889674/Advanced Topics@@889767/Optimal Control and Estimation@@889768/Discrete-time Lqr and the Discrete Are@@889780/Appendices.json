{"hands_on_practices": [{"introduction": "Before diving into complex matrix equations, it is essential to grasp the derivation of the Discrete Algebraic Riccati Equation (DARE) from first principles. This exercise [@problem_id:2700966] provides a perfect starting point by focusing on a simple scalar system. By working through this problem, you will see exactly how the Bellman optimality principle and a quadratic cost function lead to a solvable algebraic equation for the optimal cost, building a solid foundation for more general cases.", "problem": "Consider the discrete-time, single-input, single-state linear system described by the recursion $x_{k+1} = A x_{k} + B u_{k}$ with $A = \\begin{bmatrix}0.9\\end{bmatrix}$ and $B = \\begin{bmatrix}1\\end{bmatrix}$. The performance index is the infinite-horizon quadratic cost\n$$\nJ(x_{0}, \\{u_{k}\\}) = \\sum_{k=0}^{\\infty} \\left( x_{k}^{\\top} Q x_{k} + 2 x_{k}^{\\top} N u_{k} + u_{k}^{\\top} R u_{k} \\right),\n$$\nwith $Q = \\begin{bmatrix}1\\end{bmatrix}$, $R = \\begin{bmatrix}2\\end{bmatrix}$, and $N = 0$. Assume the standard standing assumptions for the discrete-time Linear Quadratic Regulator (LQR), namely stabilizability of $(A,B)$ and detectability of $(A,Q^{1/2})$, and use only the Bellman optimality principle and the quadratic ansatz for the value function as your fundamental starting point.\n\n1. Starting from the Bellman optimality principle and positing a quadratic value function $V(x) = x^{\\top} P x$ with unknown symmetric $P$, derive the fixed-point equation that $P$ must satisfy by explicitly minimizing over $u$ and equating coefficients.\n\n2. Specialize your result to the given scalar data and determine all real solutions for $P$. Select the unique solution that is positive semidefinite and produces a stabilizing feedback law.\n\n3. Using the optimal feedback law obtained from the minimization step, compute the scalar state-feedback gain $K$ in $u_{k} = -K x_{k}$ corresponding to the selected $P$.\n\nProvide your final answer as exact closed-form expressions for $P$ and $K$; do not approximate numerically. Express the final answer as a pair in a single row vector. No rounding is required or permitted.", "solution": "The problem as stated is a standard exercise in discrete-time optimal control theory. It is self-contained, mathematically consistent, and scientifically grounded in the principles of the Linear Quadratic Regulator (LQR). It is well-posed under the given assumptions of stabilizability and detectability, which guarantee the existence of a unique, positive semidefinite, stabilizing solution. The problem is therefore valid and will be solved as requested.\n\nThe solution proceeds in three parts as specified by the problem statement.\n\nPart 1: Derivation of the Fixed-Point Equation for $P$\n\nThe foundation of this problem is the Bellman principle of optimality applied to the infinite-horizon, discrete-time LQR problem. The optimal value function, $V(x) = \\min_{\\{u_k\\}} J(x, \\{u_k\\})$, must satisfy the Bellman equation:\n$$\nV(x_{k}) = \\min_{u_{k}} \\left\\{ x_{k}^{\\top} Q x_{k} + u_{k}^{\\top} R u_{k} + V(x_{k+1}) \\right\\}\n$$\nwhere the cost-to-go term uses the state transition $x_{k+1} = A x_{k} + B u_{k}$. Note that the problem sets the cross-term weight $N=0$. We postulate a time-invariant quadratic form for the value function, $V(x) = x^{\\top} P x$, where $P$ is a symmetric positive semidefinite matrix to be determined. Substituting this ansatz into the Bellman equation gives:\n$$\nx_{k}^{\\top} P x_{k} = \\min_{u_{k}} \\left\\{ x_{k}^{\\top} Q x_{k} + u_{k}^{\\top} R u_{k} + (A x_{k} + B u_{k})^{\\top} P (A x_{k} + B u_{k}) \\right\\}\n$$\nLet us drop the time index $k$ for clarity. Expanding the quadratic term in the right-hand side yields:\n$$\n(A x + B u)^{\\top} P (A x + B u) = x^{\\top}A^{\\top}PAx + 2x^{\\top}A^{\\top}PBu + u^{\\top}B^{\\top}PBu\n$$\nThe expression to be minimized with respect to $u$ is:\n$$\n\\mathcal{H}(x, u) = x^{\\top} Q x + u^{\\top} R u + x^{\\top}A^{\\top}PAx + 2x^{\\top}A^{\\top}PBu + u^{\\top}B^{\\top}PBu\n$$\nTo find the optimal control $u^*$, we compute the gradient of $\\mathcal{H}$ with respect to $u$ and set it to zero.\n$$\n\\nabla_{u} \\mathcal{H}(x, u) = 2Ru + 2B^{\\top}PAx + 2B^{\\top}PBu = 0\n$$\nThis gives $Ru = -B^{\\top}PAx$. The second derivative, $\\nabla_{uu}^{2} \\mathcal{H}(x, u) = 2(R + B^{\\top}PB)$, is positive definite since $R$ is positive definite (here, $R=20$) and $B^{\\top}PB$ is positive semidefinite. Thus, the solution is a minimum. The optimal control is:\n$$\nu^*(x) = -(R + B^{\\top}PB)^{-1}B^{\\top}PAx\n$$\nSubstituting this optimal control $u^*$ back into the Bellman equation:\n$$\nx^{\\top} P x = x^{\\top}Qx + (u^*)^{\\top}Ru^* + (Ax+Bu^*)^{\\top}P(Ax+Bu^*)\n$$\nAfter algebraic manipulation, the right-hand side simplifies. An efficient method is to substitute $u^*$ into the expression for $\\mathcal{H}(x, u)$:\n$$\nx^{\\top} P x = x^{\\top}(Q+A^{\\top}PA)x + 2x^{\\top}A^{\\top}PB u^* + (u^*)^{\\top}(R+B^{\\top}PB)u^*\n$$\nSubstituting $u^*=-(R+B^{\\top}PB)^{-1}B^{\\top}PAx$:\n$$\nx^{\\top}Px = x^{\\top}(Q+A^{\\top}PA)x - 2x^{\\top}A^{\\top}PB(R+B^{\\top}PB)^{-1}B^{\\top}PAx + x^{\\top}A^{\\top}PB(R+B^{\\top}PB)^{-1}(R+B^{\\top}PB)(R+B^{\\top}PB)^{-1}B^{\\top}PAx\n$$\nThis simplifies to:\n$$\nx^{\\top}Px = x^{\\top}(Q+A^{\\top}PA)x - x^{\\top}A^{\\top}PB(R+B^{\\top}PB)^{-1}B^{\\top}PAx\n$$\nSince this equality must hold for any state $x$, we can equate the matrix coefficients, which gives the Discrete Algebraic Riccati Equation (DARE):\n$$\nP = A^{\\top}PA + Q - A^{\\top}PB(R+B^{\\top}PB)^{-1}B^{\\top}PA\n$$\nThis is the required fixed-point equation for $P$.\n\nPart 2: Solution for $P$ for the Scalar Case\n\nWe now specialize this general result to the given scalar data: $A=0.9$, $B=1$, $Q=1$, $R=2$. The matrix $P$ is also a scalar.\n$$\nP = (0.9)P(0.9) + 1 - (0.9)P(1)(2 + (1)P(1))^{-1}(1)P(0.9)\n$$\n$$\nP = 0.81P + 1 - \\frac{0.81P^2}{2+P}\n$$\nTo solve for $P$, we rearrange the equation:\n$$\nP - 0.81P - 1 = -\\frac{0.81P^2}{2+P}\n$$\n$$\n0.19P - 1 = -\\frac{0.81P^2}{2+P}\n$$\n$$\n(0.19P - 1)(2+P) = -0.81P^2\n$$\n$$\n0.38P + 0.19P^2 - 2 - P = -0.81P^2\n$$\n$$\nP^2 - 0.62P - 2 = 0\n$$\nThis is a quadratic equation for $P$. To find an exact solution, we work with fractions. $0.62 = \\frac{62}{100} = \\frac{31}{50}$.\n$$\nP^2 - \\frac{31}{50}P - 2 = 0\n$$\n$$\n50P^2 - 31P - 100 = 0\n$$\nUsing the quadratic formula, $P = \\frac{-b \\pm \\sqrt{b^2 - 4ac}}{2a}$:\n$$\nP = \\frac{31 \\pm \\sqrt{(-31)^2 - 4(50)(-100)}}{2(50)}\n$$\n$$\nP = \\frac{31 \\pm \\sqrt{961 + 20000}}{100}\n$$\n$$\nP = \\frac{31 \\pm \\sqrt{20961}}{100}\n$$\nThe two real roots are $P_1 = \\frac{31 + \\sqrt{20961}}{100}$ and $P_2 = \\frac{31 - \\sqrt{20961}}{100}$. Since $\\sqrt{20961} \\approx 144.78$, we have $P_1  0$ and $P_2  0$. The LQR theory guarantees, under the given assumptions of stabilizability of $(A,B)$ and detectability of $(A, Q^{1/2})$, that there exists a unique symmetric positive semidefinite solution $P \\ge 0$ to the DARE, and this solution yields a stabilizing feedback law. We therefore must select the positive root.\n$$\nP = \\frac{31 + \\sqrt{20961}}{100}\n$$\n\nPart 3: Computation of the Feedback Gain $K$\n\nThe optimal control is given by $u_k = -K x_k$. From Part 1, the optimal control law has the form $u^*(x) = -(R+B^{\\top}PB)^{-1}B^{\\top}PAx$. By comparing these two expressions, we identify the state-feedback gain matrix $K$:\n$$\nK = (R + B^{\\top}PB)^{-1}B^{\\top}PA\n$$\nSubstituting the scalar values:\n$$\nK = (2 + (1)^2 P)^{-1} (1) P (0.9) = \\frac{0.9P}{2+P}\n$$\nNow, we substitute the value of $P$ found in Part 2:\n$$\nP = \\frac{31 + \\sqrt{20961}}{100}\n$$\nThe term $2+P$ is:\n$$\n2+P = 2 + \\frac{31 + \\sqrt{20961}}{100} = \\frac{200 + 31 + \\sqrt{20961}}{100} = \\frac{231 + \\sqrt{20961}}{100}\n$$\nThe expression for $K$ becomes:\n$$\nK = \\frac{0.9 \\left(\\frac{31 + \\sqrt{20961}}{100}\\right)}{\\left(\\frac{231 + \\sqrt{20961}}{100}\\right)} = \\frac{0.9(31 + \\sqrt{20961})}{231 + \\sqrt{20961}}\n$$\nTo simplify, we rationalize the denominator, and also write $0.9$ as $\\frac{9}{10}$:\n$$\nK = \\frac{9}{10} \\frac{(31 + \\sqrt{20961})}{(231 + \\sqrt{20961})} \\times \\frac{(231 - \\sqrt{20961})}{(231 - \\sqrt{20961})}\n$$\nThe denominator becomes $10 \\times (231^2 - 20961) = 10 \\times (53361 - 20961) = 10 \\times 32400 = 324000$.\nThe numerator becomes $9 \\times [31 \\times 231 - 31\\sqrt{20961} + 231\\sqrt{20961} - 20961] = 9 \\times [7161 - 20961 + 200\\sqrt{20961}] = 9 \\times [-13800 + 200\\sqrt{20961}]$.\n$$\nK = \\frac{9(-13800 + 200\\sqrt{20961})}{324000} = \\frac{-124200 + 1800\\sqrt{20961}}{324000}\n$$\nDividing the numerator and denominator by $1800$:\n$$\nK = \\frac{-69 + \\sqrt{20961}}{180}\n$$\nThis is the final exact expression for the optimal state-feedback gain.\n\nThe final answer consists of the pair $(P, K)$.\n$P = \\frac{31 + \\sqrt{20961}}{100}$\n$K = \\frac{-69 + \\sqrt{20961}}{180}$", "answer": "$$\n\\boxed{\\begin{pmatrix} \\frac{31 + \\sqrt{20961}}{100}  \\frac{-69 + \\sqrt{20961}}{180} \\end{pmatrix}}\n$$", "id": "2700966"}, {"introduction": "Having mastered the scalar case, we now apply the DARE to a more complex and practically significant system: the discrete-time double integrator. This problem [@problem_id:2700994] requires you to handle matrix algebra to find the stabilizing solution $P$ and the corresponding optimal feedback gain $K$. The final step, verifying that the closed-loop system is Schur stable, directly connects the abstract solution of the Riccati equation to the concrete performance goal of stabilization.", "problem": "Consider the discrete-time, time-invariant linear system with state update equation $x_{k+1} = A x_{k} + B u_{k}$, where $A = \\begin{bmatrix} 1  1 \\\\ 0  1 \\end{bmatrix}$ and $B = \\begin{bmatrix} 0 \\\\ 1 \\end{bmatrix}$. The infinite-horizon quadratic performance index is\n$$\nJ(x_{0}, \\{u_{k}\\}) = \\sum_{k=0}^{\\infty} \\left( x_{k}^{\\top} Q x_{k} + u_{k}^{\\top} R u_{k} \\right),\n$$\nwith $Q = I_{2}$, $R = 1$, and cross-weight $N = 0$. Assume that $(A,B)$ is stabilizable and $(Q^{1/2}, A)$ is detectable.\n\nStarting from the Bellman optimality principle and the quadratic value function ansatz $V(x) = x^{\\top} P x$ with $P = P^{\\top} \\succeq 0$, derive the Discrete Algebraic Riccati Equation (DARE) that characterizes the optimal cost-to-go matrix $P$ and the corresponding optimal state feedback law $u_{k} = -K x_{k}$. Then use this equation to compute the stabilizing solution $P$ and the associated optimal gain $K$. Finally, verify from first principles (without appealing to external results beyond those derived and standard properties of second-order polynomials) that the closed-loop matrix $A - B K$ is Schur (all eigenvalues strictly inside the unit disk).\n\nAnswer specification:\n- Provide the final result as a single row matrix containing, in order, the two components of the optimal gain vector $K = \\begin{bmatrix} k_{1}  k_{2} \\end{bmatrix}$ followed by the three independent entries of $P = \\begin{bmatrix} p_{11}  p_{12} \\\\ p_{12}  p_{22} \\end{bmatrix}$, i.e., $[\\,k_{1},\\, k_{2},\\, p_{11},\\, p_{12},\\, p_{22}\\,]$.\n- Express each entry in exact closed form. Do not approximate or round.\n- No units are required.", "solution": "The problem presented is a standard exercise in discrete-time optimal control theory and is well-posed, scientifically sound, and complete. All conditions for the existence of a unique, stabilizing, positive semi-definite solution to the Discrete Algebraic Riccati Equation (DARE) are met. We shall proceed with the solution.\n\nThe Bellman equation for the infinite-horizon, time-invariant optimal control problem is given by the principle of optimality. The optimal cost-to-go, or value function, $V(x)$, must satisfy:\n$$V(x) = \\min_{u} \\{ x^{\\top} Q x + u^{\\top} R u + V(x_{k+1}) \\}$$\nwhere $x_{k+1} = Ax+Bu$. We are given the quadratic ansatz for the value function, $V(x) = x^{\\top} P x$, where $P$ is a symmetric positive semi-definite matrix ($P = P^{\\top} \\succeq 0$). Substituting this into the Bellman equation yields:\n$$x^{\\top} P x = \\min_{u} \\{ x^{\\top} Q x + u^{\\top} R u + (Ax+Bu)^{\\top} P (Ax+Bu) \\}$$\nThe right-hand side is a quadratic function of the control input $u$. To find the minimum, we differentiate with respect to $u$ and set the result to zero. The term to be minimized is:\n$$J(u) = x^{\\top} Q x + u^{\\top} R u + x^{\\top} A^{\\top} P A x + 2u^{\\top} B^{\\top} P A x + u^{\\top} B^{\\top} P B u$$\nThe gradient with respect to $u$ is:\n$$\\nabla_{u} J(u) = 2R u + 2B^{\\top} P A x + 2B^{\\top} P B u = 0$$\nSolving for the optimal control $u_{k}^*$:\n$$(R + B^{\\top} P B)u_{k}^* = -B^{\\top} P A x_{k}$$\n$$u_{k}^* = -(R + B^{\\top} P B)^{-1} B^{\\top} P A x_{k}$$\nThis implies the optimal control law is a linear state feedback $u_{k} = -K x_{k}$ with the gain matrix:\n$$K = (R + B^{\\top} P B)^{-1} B^{\\top} P A$$\nSubstituting $u_{k}^* = -Kx_k$ back into the Bellman equation:\n$$x^{\\top} P x = x^{\\top} Q x + (-Kx)^{\\top} R (-Kx) + ((A-BK)x)^{\\top} P (A-BK)x$$\nSince this must hold for any state $x$, we obtain the matrix equation:\n$$P = Q + K^{\\top} R K + (A-BK)^{\\top} P (A-BK)$$\nSubstituting the expression for $K$ into this equation gives the Discrete Algebraic Riccati Equation (DARE):\n$$P = A^{\\top} P A + Q - (A^{\\top} P B)(R + B^{\\top} P B)^{-1}(B^{\\top} P A)$$\nThis equation characterizes the optimal cost matrix $P$.\n\nNow, we solve this equation for the given system parameters:\n$A = \\begin{bmatrix} 1  1 \\\\ 0  1 \\end{bmatrix}$, $B = \\begin{bmatrix} 0 \\\\ 1 \\end{bmatrix}$, $Q = \\begin{bmatrix} 1  0 \\\\ 0  1 \\end{bmatrix}$, $R=1$. Let $P = \\begin{bmatrix} p_{11}  p_{12} \\\\ p_{12}  p_{22} \\end{bmatrix}$.\n\nWe compute the required terms:\n$A^{\\top}PA = \\begin{bmatrix} p_{11}  p_{11}+p_{12} \\\\ p_{11}+p_{12}  p_{11}+2p_{12}+p_{22} \\end{bmatrix}$\n$A^{\\top}PB = \\begin{bmatrix} p_{12} \\\\ p_{12}+p_{22} \\end{bmatrix}$\n$B^{\\top}PA = \\begin{bmatrix} p_{12}  p_{12}+p_{22} \\end{bmatrix}$\n$R+B^{\\top}PB = 1+p_{22}$\n$(A^{\\top} P B)(R + B^{\\top} P B)^{-1}(B^{\\top} P A) = \\frac{1}{1+p_{22}}\\begin{bmatrix} p_{12}^{2}  p_{12}(p_{12}+p_{22}) \\\\ p_{12}(p_{12}+p_{22})  (p_{12}+p_{22})^2 \\end{bmatrix}$\n\nSubstituting these into the DARE leads to a system of scalar equations:\n(1,1): $p_{11} = p_{11} + 1 - \\frac{p_{12}^2}{1+p_{22}} \\implies p_{12}^2 = 1+p_{22}$\n(1,2): $p_{12} = p_{11}+p_{12} - \\frac{p_{12}(p_{12}+p_{22})}{1+p_{22}} \\implies p_{11} = \\frac{p_{12}(p_{12}+p_{22})}{1+p_{22}}$\n(2,2): $p_{22} = p_{11}+2p_{12}+p_{22}+1 - \\frac{(p_{12}+p_{22})^2}{1+p_{22}} \\implies 0 = p_{11}+2p_{12}+1 - \\frac{(p_{12}+p_{22})^2}{1+p_{22}}$\n\nFrom (1), $p_{22} = p_{12}^2 - 1$. For $P \\succeq 0$, we require $p_{22} \\ge 0$, so $|p_{12}| \\ge 1$.\nSubstitute $p_{22}$ into (2): $p_{11} = \\frac{p_{12}(p_{12}+p_{12}^2-1)}{1+p_{12}^2-1} = \\frac{p_{12}(p_{12}^2+p_{12}-1)}{p_{12}^2} = p_{12}+1-\\frac{1}{p_{12}}$.\nSubstitute $p_{11}$ and $p_{22}$ into (3):\n$0 = (p_{12}+1-\\frac{1}{p_{12}}) + 2p_{12} + 1 - \\frac{(p_{12}+p_{12}^2-1)^2}{p_{12}^2}$\nMultiplying by $p_{12}^2$ yields:\n$0 = 3p_{12}^3+2p_{12}^2-p_{12} - (p_{12}^2+p_{12}-1)^2$\n$0 = 3p_{12}^3+2p_{12}^2-p_{12} - (p_{12}^4+2p_{12}^3-p_{12}^2-2p_{12}+1)$\n$0 = -p_{12}^4 + p_{12}^3 + 3p_{12}^2 + p_{12} - 1$\nThis is equivalent to the reciprocal equation $p_{12}^4 - p_{12}^3 - 3p_{12}^2 - p_{12} + 1 = 0$.\nDividing by $p_{12}^2$ and letting $y = p_{12}+\\frac{1}{p_{12}}$, we get:\n$(p_{12}^2+\\frac{1}{p_{12}^2}) - (p_{12}+\\frac{1}{p_{12}}) - 3 = 0 \\implies (y^2-2) - y - 3 = 0 \\implies y^2-y-5=0$.\nThe solutions are $y = \\frac{1 \\pm \\sqrt{1 - 4(-5)}}{2} = \\frac{1 \\pm \\sqrt{21}}{2}$.\n\nNext, we verify stability. The closed-loop matrix is $A_{cl} = A-BK$. The gain is $K = (1+p_{22})^{-1} B^{\\top} P A = (p_{12}^2)^{-1} [p_{12} \\quad p_{12}+p_{22}] = [1/p_{12} \\quad 1/p_{12}+1-1/p_{12}^2]$.\n$A_{cl} = \\begin{bmatrix} 1  1 \\\\ -k_1  1-k_2 \\end{bmatrix}$. The characteristic polynomial is $\\lambda^2 - \\text{tr}(A_{cl})\\lambda + \\det(A_{cl}) = 0$.\n$\\text{tr}(A_{cl}) = 2-k_2 = 2-(1/p_{12}+1-1/p_{12}^2) = 1-1/p_{12}+1/p_{12}^2$.\n$\\det(A_{cl}) = 1-k_2+k_1 = 1-(1/p_{12}+1-1/p_{12}^2) + 1/p_{12} = 1/p_{12}^2$.\nThe characteristic polynomial is $\\lambda^2 - (1-1/p_{12}+1/p_{12}^2)\\lambda + 1/p_{12}^2 = 0$.\nFor the system to be Schur stable, the roots must lie inside the unit disk. For a second-order polynomial $\\lambda^2+a_1\\lambda+a_0=0$, the Jury stability conditions are: (i) $1+a_1+a_0  0$, (ii) $1-a_1+a_00$, (iii) $|a_0|1$.\n(iii) $|1/p_{12}^2|  1 \\implies p_{12}^2  1$, which aligns with $p_{22} \\ge 0$.\n(i) $1 - (1-1/p_{12}+1/p_{12}^2) + 1/p_{12}^2 = 1/p_{12}  0 \\implies p_{12}0$.\n(ii) $1 + (1-1/p_{12}+1/p_{12}^2) + 1/p_{12}^2 = 2-1/p_{12}+2/p_{12}^2  0$. Multiplying by $p_{12}^20$ gives $2p_{12}^2-p_{12}+20$. The discriminant of this quadratic is $(-1)^2-4(2)(2)=-150$, so it is always positive.\nThus, stability requires $p_{12}1$. This implies $y = p_{12}+1/p_{12}  2$.\nWe must select $y = \\frac{1+\\sqrt{21}}{2} \\approx 2.79  2$.\nThe values of $p_{12}$ are the roots of $p_{12}^2-yp_{12}+1=0$. To satisfy $p_{12}1$, we must choose the larger root:\n$p_{12} = \\frac{y+\\sqrt{y^2-4}}{2}$.\n\nWith $y = \\frac{1+\\sqrt{21}}{2}$, we have $y^2-4 = (\\frac{1+\\sqrt{21}}{2})^2-4 = \\frac{1+21+2\\sqrt{21}}{4}-4 = \\frac{11+\\sqrt{21}}{2}-4 = \\frac{3+\\sqrt{21}}{2}$.\nLet $\\Delta = \\sqrt{y^2-4} = \\sqrt{\\frac{3+\\sqrt{21}}{2}}$.\nThe required quantities are:\n$p_{12} = \\frac{y+\\Delta}{2} = \\frac{1}{2}\\left(\\frac{1+\\sqrt{21}}{2} + \\sqrt{\\frac{3+\\sqrt{21}}{2}}\\right)$\n$p_{11} = p_{12}+1-\\frac{1}{p_{12}}$. Since $1/p_{12} = \\frac{y-\\Delta}{2}$, we have $p_{11} = \\frac{y+\\Delta}{2}+1-\\frac{y-\\Delta}{2} = 1+\\Delta = 1+\\sqrt{\\frac{3+\\sqrt{21}}{2}}$.\n$p_{22} = p_{12}^2-1$. From $p_{12}^2=yp_{12}-1$, we get $p_{22}=yp_{12}-2 = \\frac{y(y+\\Delta)}{2}-2 = \\frac{y^2+y\\Delta-4}{2} = \\frac{\\Delta^2+y\\Delta}{2} = \\frac{1}{2}\\left(\\frac{3+\\sqrt{21}}{2} + \\frac{1+\\sqrt{21}}{2}\\sqrt{\\frac{3+\\sqrt{21}}{2}}\\right)$.\n$k_1 = \\frac{1}{p_{12}} = \\frac{y-\\Delta}{2} = \\frac{1}{2}\\left(\\frac{1+\\sqrt{21}}{2} - \\sqrt{\\frac{3+\\sqrt{21}}{2}}\\right)$.\n$k_2 = k_1+1-k_1^2$. Since $k_1^2 = y k_1 - 1$, then $k_2 = k_1+1-(yk_1-1) = (1-y)k_1+2$.\n$k_2 = (1-y)\\frac{y-\\Delta}{2}+2 = \\frac{y-y^2-(1-y)\\Delta+4}{2} = \\frac{y-(y+5)-(1-y)\\Delta+4}{2} = \\frac{-1-(1-y)\\Delta}{2} = \\frac{-1+(y-1)\\Delta}{2} = \\frac{1}{2}\\left(-1 + \\frac{\\sqrt{21}-1}{2}\\sqrt{\\frac{3+\\sqrt{21}}{2}}\\right)$.\n\nThe final results are collected as specified.", "answer": "$$\n\\boxed{\n\\begin{pmatrix} \\frac{1}{2}\\left(\\frac{1+\\sqrt{21}}{2} - \\sqrt{\\frac{3+\\sqrt{21}}{2}}\\right)  \\frac{1}{2}\\left(-1 + \\frac{\\sqrt{21}-1}{2}\\sqrt{\\frac{3+\\sqrt{21}}{2}}\\right)  1+\\sqrt{\\frac{3+\\sqrt{21}}{2}}  \\frac{1}{2}\\left(\\frac{1+\\sqrt{21}}{2} + \\sqrt{\\frac{3+\\sqrt{21}}{2}}\\right)  \\frac{1}{2}\\left(\\frac{3+\\sqrt{21}}{2} + \\frac{1+\\sqrt{21}}{2}\\sqrt{\\frac{3+\\sqrt{21}}{2}}\\right) \\end{pmatrix}\n}\n$$", "id": "2700994"}, {"introduction": "The LQR framework is powerful, but its guarantees of stability and optimality are not unconditional. This practice [@problem_id:2701007] shifts our focus from computation to preconditions, asking a critical question: does a stabilizing solution even exist for a given system? You will use the fundamental concept of stabilizability to analyze a system with an unstable mode, learning to diagnose when the LQR controller can and cannot achieve its objective.", "problem": "Consider the discrete-time linear time-invariant system and quadratic performance index defined by\n$$\nx_{k+1} = A x_{k} + B u_{k}, \\quad \\ell(x_{k},u_{k}) = x_{k}^{\\top} Q x_{k} + 2 x_{k}^{\\top} N u_{k} + u_{k}^{\\top} R u_{k},\n$$\nwith\n$$\nA=\\begin{bmatrix}1  0\\\\ 0  1.2\\end{bmatrix}, \\quad B=\\begin{bmatrix}1\\\\ 0\\end{bmatrix}, \\quad Q=I, \\quad R=1, \\quad N=0,\n$$\nand the infinite-horizon cost\n$$\nJ(x_{0}, \\{u_{k}\\}) = \\sum_{k=0}^{\\infty} \\ell(x_{k},u_{k}).\n$$\nA symmetric matrix $P$ is called a stabilizing solution of the discrete-time Algebraic Riccati Equation (DARE) for this problem if it is the value function Hessian for the infinite-horizon Linear Quadratic Regulator (LQR) problem and the corresponding optimal closed-loop matrix has spectral radius strictly less than $1$. Using only core definitions and well-tested facts about stabilizability and detectability for discrete-time LQR, determine whether such a stabilizing solution exists for the given data. Justify your conclusion by analyzing the controllability of eigenvalues of $A$ with modulus at least $1$ and the detectability of the pair $(A,Q^{1/2})$.\n\nTo provide a concrete numerical deliverable, define\n$$\ns := \\max\\left\\{\\,|\\lambda| \\;:\\; \\lambda \\in \\sigma(A),\\ \\mathrm{rank}\\!\\begin{bmatrix}\\lambda I - A  B\\end{bmatrix}  2 \\,\\right\\},\n$$\nwith the convention that the maximum of the empty set equals $0$. Report the value of $s$ as your final answer. No rounding is required, and the answer is unitless.", "solution": "The problem requires an analysis of the existence of a stabilizing solution to a discrete-time Algebraic Riccati Equation (DARE) for a given linear time-invariant system. The existence of a unique positive semi-definite stabilizing solution $P$ to the DARE is contingent upon two fundamental properties of the system matrices: stabilizability of the pair $(A, B)$ and detectability of the pair $(C, A)$, where the state weighting matrix $Q$ is factored as $Q=C^{\\top}C$.\n\nLet us analyze these two conditions for the given system. The system matrices are:\n$$ A=\\begin{bmatrix}1  0\\\\ 0  1.2\\end{bmatrix}, \\quad B=\\begin{bmatrix}1\\\\ 0\\end{bmatrix}, \\quad Q=I = \\begin{bmatrix}1  0\\\\ 0  1\\end{bmatrix} $$\n\nFirst, we address the stabilizability of the pair $(A, B)$. A discrete-time system is stabilizable if and only if all of its unstable modes are controllable. A mode is considered unstable if its corresponding eigenvalue $\\lambda$ of the matrix $A$ has a modulus $|\\lambda| \\ge 1$. The controllability of a specific mode can be checked using the Popov-Hautus-Belevitch (PBH) test. An eigenvalue $\\lambda$ is controllable if and only if the matrix $[\\lambda I - A \\quad B]$ has full row rank, which is $n$ for an $n$-dimensional state space. In this problem, the state dimension is $n=2$.\n\nThe eigenvalues of the matrix $A$ are its diagonal elements, as $A$ is a diagonal matrix. The eigenvalues are $\\lambda_1 = 1$ and $\\lambda_2 = 1.2$. We must check their controllability since both satisfy the condition $|\\lambda| \\ge 1$.\n\nFor the eigenvalue $\\lambda_1 = 1$:\nWe form the PBH test matrix:\n$$ \\begin{bmatrix} \\lambda_1 I - A  B \\end{bmatrix} = \\begin{bmatrix} 1 \\cdot I - A  B \\end{bmatrix} = \\begin{bmatrix} 1\\begin{bmatrix}10\\\\01\\end{bmatrix} - \\begin{bmatrix}1  0\\\\ 0  1.2\\end{bmatrix}  \\begin{bmatrix}1\\\\ 0\\end{bmatrix} \\end{bmatrix} $$\n$$ = \\begin{bmatrix} 0  0  1 \\\\ 0  -0.2  0 \\end{bmatrix} $$\nThe rank of this $2 \\times 3$ matrix is $2$, as the second and third columns are linearly independent. Thus, the rank is equal to the state dimension $n=2$. This means the mode corresponding to the eigenvalue $\\lambda_1 = 1$ is controllable.\n\nFor the eigenvalue $\\lambda_2 = 1.2$:\nWe form the PBH test matrix:\n$$ \\begin{bmatrix} \\lambda_2 I - A  B \\end{bmatrix} = \\begin{bmatrix} 1.2 \\cdot I - A  B \\end{bmatrix} = \\begin{bmatrix} 1.2\\begin{bmatrix}10\\\\01\\end{bmatrix} - \\begin{bmatrix}1  0\\\\ 0  1.2\\end{bmatrix}  \\begin{bmatrix}1\\\\ 0\\end{bmatrix} \\end{bmatrix} $$\n$$ = \\begin{bmatrix} 0.2  0  1 \\\\ 0  0  0 \\end{bmatrix} $$\nThe rank of this $2 \\times 3$ matrix is $1$, because the second row is composed entirely of zeros. The rank is less than the state dimension $n=2$. This implies that the mode corresponding to the eigenvalue $\\lambda_2 = 1.2$ is uncontrollable.\n\nSince the system has an unstable eigenvalue, $\\lambda_2 = 1.2$, that is uncontrollable, the pair $(A, B)$ is not stabilizable. The failure of this condition is sufficient to conclude that a stabilizing solution to the DARE does not exist.\n\nFor completeness, we also verify the detectability condition. A system is detectable if all its unobservable modes are stable (i.e., correspond to eigenvalues $\\lambda$ with $|\\lambda|  1$). The pair $(C, A)$ is detectable if and only if the pair $(A^\\top, C^\\top)$ is stabilizable. Equivalently, by the dual of the PBH test, detectability requires that for every eigenvalue $\\lambda$ with $|\\lambda| \\ge 1$, the matrix $\\begin{bmatrix} A - \\lambda I \\\\ C \\end{bmatrix}$ has full column rank ($n=2$).\nWe are given $Q=I$. We can choose $C = Q^{1/2} = I^{1/2} = I$. So we test the detectability of the pair $(I, A)$.\nFor any complex number $\\lambda$, the test matrix is:\n$$ \\begin{bmatrix} A - \\lambda I \\\\ I \\end{bmatrix} = \\begin{bmatrix} 1-\\lambda  0 \\\\ 0  1.2-\\lambda \\\\ 1  0 \\\\ 0  1 \\end{bmatrix} $$\nThis is a $4 \\times 2$ matrix. The rank of this matrix is determined by the linear independence of its two columns. The bottom two rows, which constitute the identity matrix $I$, guarantee that the two columns are always linearly independent for any value of $\\lambda$. Therefore, the rank is always $2$. This means no eigenvalue is unobservable. The system is observable, which is a stronger condition than detectability. The detectability condition is satisfied.\n\nHowever, the existence of a stabilizing DARE solution requires both stabilizability and detectability. Since the stabilizability condition failed, we conclude that no such stabilizing solution exists for the given problem.\n\nThe final part of the problem asks for the computation of the value $s$:\n$$ s := \\max\\left\\{\\,|\\lambda| \\;:\\; \\lambda \\in \\sigma(A),\\ \\mathrm{rank}\\!\\begin{bmatrix}\\lambda I - A  B\\end{bmatrix}  2 \\,\\right\\} $$\nThis quantity $s$ is the maximum modulus of all uncontrollable eigenvalues of $A$. Based on our PBH tests:\n- For $\\lambda_1 = 1$, $\\mathrm{rank}\\!\\begin{bmatrix}\\lambda_1 I - A  B\\end{bmatrix} = 2$. This eigenvalue is not in the set.\n- For $\\lambda_2 = 1.2$, $\\mathrm{rank}\\!\\begin{bmatrix}\\lambda_2 I - A  B\\end{bmatrix} = 1  2$. This eigenvalue is in the set.\n\nThe set of eigenvalues $\\lambda$ for which the rank condition holds is $\\{1.2\\}$. The corresponding set of moduli is $\\{|1.2|\\} = \\{1.2\\}$. The maximum element of this set is $1.2$.\nTherefore, $s = 1.2$.", "answer": "$$\n\\boxed{1.2}\n$$", "id": "2701007"}]}