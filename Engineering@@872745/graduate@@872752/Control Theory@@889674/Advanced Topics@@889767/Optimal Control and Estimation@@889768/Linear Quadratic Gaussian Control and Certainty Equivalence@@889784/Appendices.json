{"hands_on_practices": [{"introduction": "The heart of the Linear Quadratic Regulator (LQR) is the algebraic Riccati equation. This practice is a foundational exercise that takes you through the analytical derivation of the optimal controller gain from first principles, starting with the Bellman equation. By solving the discrete-time algebraic Riccati equation (DARE) for a specific system and calculating the gain matrix $K$, you will gain a deep, concrete understanding of the mechanics behind optimal control.", "problem": "Consider the discrete-time linear time-invariant system with state update $x_{k+1} = A x_{k} + B u_{k}$ and infinite-horizon quadratic cost $J = \\sum_{k=0}^{\\infty} \\left( x_{k}^{\\mathsf{T}} Q x_{k} + u_{k}^{\\mathsf{T}} R u_{k} \\right)$, where\n$$\nA = \\begin{bmatrix} 1  1 \\\\ 0  1 \\end{bmatrix},\\quad\nB = \\begin{bmatrix} 0 \\\\ 1 \\end{bmatrix},\\quad\nQ = I_{2},\\quad\nR = 1.\n$$\nStarting from the principle of optimality for the dynamic programming formulation of the infinite-horizon discrete-time Linear Quadratic Regulator (LQR) problem, let the stationary value function be quadratic $V(x) = x^{\\mathsf{T}} P x$ with $P = P^{\\mathsf{T}} \\succeq 0$. Derive the matrix relation that $P$ must satisfy and solve analytically for the optimal state-feedback gain $K$ such that the optimal control is $u_{k} = - K x_{k}$. Then verify that the closed-loop matrix $A - B K$ is Schur stable by characterizing its eigenvalues. Finally, briefly explain how the same $K$ would be used with a state estimate in a Linear Quadratic Gaussian (LQG) controller by the certainty equivalence principle. Express your final answer as the exact row vector $K$ using radicals; do not approximate or round.", "solution": "The problem requires the derivation and solution of a discrete-time infinite-horizon Linear Quadratic Regulator (LQR) problem, followed by a stability analysis and a conceptual explanation of its connection to Linear Quadratic Gaussian (LQG) control.\n\n**Step 1: Problem Validation**\n\nThe problem statement provides the following givens: a discrete-time linear time-invariant system and a cost function.\n- State update equation: $x_{k+1} = A x_{k} + B u_{k}$\n- Infinite-horizon quadratic cost: $J = \\sum_{k=0}^{\\infty} \\left( x_{k}^{\\mathsf{T}} Q x_{k} + u_{k}^{\\mathsf{T}} R u_{k} \\right)$\n- System matrices:\n$$\nA = \\begin{bmatrix} 1  1 \\\\ 0  1 \\end{bmatrix},\\quad\nB = \\begin{bmatrix} 0 \\\\ 1 \\end{bmatrix},\\quad\nQ = I_{2} = \\begin{bmatrix} 1  0 \\\\ 0  1 \\end{bmatrix},\\quad\nR = 1\n$$\n- The value function is assumed to be of the form $V(x) = x^{\\mathsf{T}} P x$ where $P = P^{\\mathsf{T}} \\succeq 0$.\n- The optimal control law is of the form $u_k = -K x_k$.\n\nThe problem is scientifically grounded in control theory, well-posed, and stated objectively. The controllability matrix for the pair $(A, B)$ is $\\mathcal{C} = \\begin{bmatrix} B  AB \\end{bmatrix} = \\begin{bmatrix} 0  1 \\\\ 1  1 \\end{bmatrix}$, which has a determinant of $-1$ and is thus full rank. This means the system is controllable, which is a sufficient condition for stabilizability. The pair $(A, \\sqrt{Q}) = (A, I)$ is observable, as the observability matrix $\\mathcal{O} = \\begin{bmatrix} I \\\\ A^{\\mathsf{T}} \\end{bmatrix}$ has full column rank. Since $Q \\succeq 0$ and $R > 0$, and the system is stabilizable and detectable, a unique, positive semi-definite, stabilizing solution $P$ to the associated algebraic Riccati equation exists. The problem is valid.\n\n**Step 2: Derivation of the Discrete Algebraic Riccati Equation (DARE)**\n\nThe principle of optimality leads to the Bellman equation for the infinite-horizon value function $V(x)$:\n$$ V(x) = \\min_{u} \\left\\{ x^{\\mathsf{T}} Q x + u^{\\mathsf{T}} R u + V(Ax + Bu) \\right\\} $$\nSubstituting the quadratic value function $V(x) = x^{\\mathsf{T}} P x$:\n$$ x^{\\mathsf{T}} P x = \\min_{u} \\left\\{ x^{\\mathsf{T}} Q x + u^{\\mathsf{T}} R u + (Ax + Bu)^{\\mathsf{T}} P (Ax + Bu) \\right\\} $$\nTo find the optimal control $u$, we minimize the term in the braces. We take its derivative with respect to $u$ and set it to zero.\n$$ \\frac{\\partial}{\\partial u} \\left( u^{\\mathsf{T}} R u + 2u^{\\mathsf{T}}B^{\\mathsf{T}}PAx + u^{\\mathsf{T}}B^{\\mathsf{T}}PBu \\right) = 2Ru + 2B^{\\mathsf{T}}PAx = 0 $$\nSolving for the optimal control $u_k^*$ at time step $k$:\n$$ u_{k}^* = -(R + B^{\\mathsf{T}} P B)^{-1} B^{\\mathsf{T}} P A x_{k} $$\nThis gives the optimal state-feedback gain matrix $K = (R + B^{\\mathsf{T}} P B)^{-1} B^{\\mathsf{T}} P A$. Substituting $u_k^* = -K x_k$ back into the Bellman equation yields:\n$$ x^{\\mathsf{T}} P x = x^{\\mathsf{T}} Q x + (-Kx)^{\\mathsf{T}} R (-Kx) + (A-BK)x^{\\mathsf{T}} P (A-BK)x $$\nSince this must hold for all $x$, we obtain the relation $P = Q + K^{\\mathsf{T}} R K + (A-BK)^{\\mathsf{T}} P (A-BK)$. A more direct form, the Discrete Algebraic Riccati Equation (DARE), is obtained by substituting $u^*$ back into the minimized expression:\n$$ P = Q + A^{\\mathsf{T}} P A - A^{\\mathsf{T}} P B (R + B^{\\mathsf{T}} P B)^{-1} B^{\\mathsf{T}} P A $$\n\n**Step 3: Solving the DARE for P**\n\nLet $P = \\begin{bmatrix} p_{11}  p_{12} \\\\ p_{12}  p_{22} \\end{bmatrix}$ be the symmetric positive semi-definite solution. We calculate the terms in the DARE:\n- $A^{\\mathsf{T}} P A = \\begin{bmatrix} 1  0 \\\\ 1  1 \\end{bmatrix} \\begin{bmatrix} p_{11}  p_{12} \\\\ p_{12}  p_{22} \\end{bmatrix} \\begin{bmatrix} 1  1 \\\\ 0  1 \\end{bmatrix} = \\begin{bmatrix} p_{11}  p_{11}+p_{12} \\\\ p_{11}+p_{12}  p_{11}+2p_{12}+p_{22} \\end{bmatrix}$\n- $B^{\\mathsf{T}} P B = \\begin{bmatrix} 0  1 \\end{bmatrix} \\begin{bmatrix} p_{11}  p_{12} \\\\ p_{12}  p_{22} \\end{bmatrix} \\begin{bmatrix} 0 \\\\ 1 \\end{bmatrix} = p_{22}$\n- $A^{\\mathsf{T}} P B = \\begin{bmatrix} 1  0 \\\\ 1  1 \\end{bmatrix} \\begin{bmatrix} p_{11}  p_{12} \\\\ p_{12}  p_{22} \\end{bmatrix} \\begin{bmatrix} 0 \\\\ 1 \\end{bmatrix} = \\begin{bmatrix} p_{12} \\\\ p_{12}+p_{22} \\end{bmatrix}$\n- The correction term is $\\frac{1}{1+p_{22}} (A^{\\mathsf{T}} P B)(B^{\\mathsf{T}} P A) = \\frac{1}{1+p_{22}} \\begin{bmatrix} p_{12}^2  p_{12}(p_{12}+p_{22}) \\\\ p_{12}(p_{12}+p_{22})  (p_{12}+p_{22})^2 \\end{bmatrix}$\n\nSubstituting these into the DARE $P = Q + A^{\\mathsf{T}}PA - (\\text{correction term})$ gives a system of three nonlinear equations:\n1. ($1,1$)-entry: $p_{11} = 1 + p_{11} - \\frac{p_{12}^2}{1+p_{22}} \\implies p_{12}^2 = 1+p_{22}$.\n2. ($1,2$)-entry: $p_{12} = 0 + p_{11}+p_{12} - \\frac{p_{12}(p_{12}+p_{22})}{1+p_{22}} \\implies p_{11} = \\frac{p_{12}(p_{12}+p_{22})}{1+p_{22}}$.\n3. ($2,2$)-entry: $p_{22} = 1 + p_{11}+2p_{12}+p_{22} - \\frac{(p_{12}+p_{22})^2}{1+p_{22}} \\implies 0 = 1+p_{11}+2p_{12} - \\frac{(p_{12}+p_{22})^2}{1+p_{22}}$.\n\nUsing $p_{12}^2 = 1+p_{22}$ from (1), we simplify (2): $p_{11} = \\frac{p_{12}(p_{12} + p_{12}^2-1)}{p_{12}^2} = 1+p_{12}-\\frac{1}{p_{12}}$. For the stabilizing solution to be positive definite, we require $p_{22} \\ge 0$, so $p_{12}^2 \\ge 1$.\nSubstituting this into (3):\n$0 = 1 + (1+p_{12}-\\frac{1}{p_{12}}) + 2p_{12} - \\frac{(p_{12}+p_{12}^2-1)^2}{p_{12}^2} = 2+3p_{12}-\\frac{1}{p_{12}} - (p_{12}+1-\\frac{1}{p_{12}})^2$\nLet $z=p_{12}$. $0 = 2+3z-\\frac{1}{z} - (z^2+1+\\frac{1}{z^2}+2z-2-\\frac{2}{z}) = 3+z+\\frac{1}{z}-z^2-1-\\frac{1}{z^2}$.\nMultiplying by $-z^2$ yields the quartic equation: $z^4 - z^3 - 3z^2 - z + 1 = 0$.\nThis is a reciprocal equation. Dividing by $z^2$: $(z^2+\\frac{1}{z^2}) - (z+\\frac{1}{z}) - 3 = 0$.\nLet $w = z+\\frac{1}{z}$. Then $w^2-2 = z^2+\\frac{1}{z^2}$. The equation becomes $(w^2-2) - w - 3 = 0 \\implies w^2-w-5=0$.\nThe solutions for $w$ are $w = \\frac{1 \\pm \\sqrt{1 - 4(1)(-5)}}{2} = \\frac{1 \\pm \\sqrt{21}}{2}$.\nFor a stabilizing solution, the closed-loop eigenvalues must be inside the unit disk. This corresponds to the positive definite solution $P$, which requires $p_{12}=z$ to be chosen appropriately. $P$ must be positive definite. The condition $p_{22} = z^2-1 \\ge 0$ implies $|z| \\ge 1$. If $|z| \\ge 1$, then $|w| = |z+1/z| \\ge | |z|-|1/z| | \\ge 0$, but for real roots of $z^2-wz+1=0$ we need $|w| \\ge 2$.\n$w_1 = (1+\\sqrt{21})/2 \\approx 2.79 > 2$. $w_2 = (1-\\sqrt{21})/2 \\approx -1.79$, $|w_2|2$.\nThis implies we must choose $w_1 = (1+\\sqrt{21})/2$, which yields real roots for $z$. The solution $z$ must satisfy $|z| \\ge 1$. The two roots for $z$ from $z+1/z=w_1$ are $z_a>1$ and $z_b=1/z_a1$. So we must choose $p_{12} = z_a > 1$, the larger root.\nFurthermore, we found $p_{11}=1+z-1/z$. With $w=z+1/z$, $z-1/z = \\pm\\sqrt{w^2-4}$. So $p_{11}=1\\pm\\sqrt{w^2-4}$. For $P$ to be positive definite, all principal minors must be positive. This requires $p_{11} > 0$. The condition on $p_{11}$ is satisfied for the appropriate branch.\n\n**Step 4: Computing the Optimal Gain K**\n\nThe optimal gain is $K = (R + B^{\\mathsf{T}} P B)^{-1} B^{\\mathsf{T}} P A = \\frac{1}{1+p_{22}} [p_{12}, p_{12}+p_{22}]$.\nUsing $1+p_{22} = p_{12}^2$, we have $K = \\frac{1}{p_{12}^2}[p_{12}, p_{12}+p_{12}^2-1] = [\\frac{1}{p_{12}}, 1+\\frac{1}{p_{12}}-\\frac{1}{p_{12}^2}]$.\nLet $k_1 = 1/p_{12}$ and $k_2 = 1+1/p_{12}-1/p_{12}^2 = 1+k_1-k_1^2$.\nSince $p_{12}$ is the larger root of $z^2-w_1 z+1=0$, $k_1=1/p_{12}$ is the smaller root.\n$k_1 = \\frac{w_1 - \\sqrt{w_1^2-4}}{2}$, where $w_1 = \\frac{1+\\sqrt{21}}{2}$.\n$w_1^2-4 = (\\frac{1+\\sqrt{21}}{2})^2 - 4 = \\frac{1+2\\sqrt{21}+21}{4}-4 = \\frac{22+2\\sqrt{21}-16}{4} = \\frac{6+2\\sqrt{21}}{4} = \\frac{3+\\sqrt{21}}{2}$.\nSo, $k_1 = \\frac{\\frac{1+\\sqrt{21}}{2} - \\sqrt{\\frac{3+\\sqrt{21}}{2}}}{2} = \\frac{1+\\sqrt{21} - \\sqrt{2(3+\\sqrt{21})}}{4} = \\frac{1+\\sqrt{21} - \\sqrt{6+2\\sqrt{21}}}{4}$.\nNow we find $k_2 = 1+k_1-k_1^2$. From $k_1^2-w_1 k_1+1=0$, we have $k_1^2=w_1 k_1-1$.\n$k_2 = 1+k_1-(w_1 k_1-1) = 2+(1-w_1)k_1$.\n$1-w_1 = 1-\\frac{1+\\sqrt{21}}{2} = \\frac{1-\\sqrt{21}}{2}$.\n$k_2 = 2+\\frac{1-\\sqrt{21}}{2}k_1 = 2+\\frac{1-\\sqrt{21}}{2}\\left(\\frac{1+\\sqrt{21}-\\sqrt{6+2\\sqrt{21}}}{4}\\right) = 2+\\frac{1-21-(1-\\sqrt{21})\\sqrt{6+2\\sqrt{21}}}{8}$.\n$k_2 = 2 - \\frac{20}{8} - \\frac{1-\\sqrt{21}}{8}\\sqrt{6+2\\sqrt{21}} = -\\frac{1}{2} + \\frac{\\sqrt{21}-1}{8}\\sqrt{6+2\\sqrt{21}}$.\nSo, $K = \\begin{bmatrix} k_1  k_2 \\end{bmatrix}$.\n\n**Step 5: Stability Verification**\n\nThe closed-loop system matrix is $A_{cl} = A - BK = \\begin{bmatrix} 1  1 \\\\ 0  1 \\end{bmatrix} - \\begin{bmatrix} 0 \\\\ 1 \\end{bmatrix} \\begin{bmatrix} k_1  k_2 \\end{bmatrix} = \\begin{bmatrix} 1  1 \\\\ -k_1  1-k_2 \\end{bmatrix}$.\nThe characteristic polynomial is $\\det(\\lambda I - A_{cl}) = 0$:\n$\\det \\begin{bmatrix} \\lambda-1  -1 \\\\ k_1  \\lambda-(1-k_2) \\end{bmatrix} = (\\lambda-1)(\\lambda-1+k_2) + k_1 = 0$.\n$\\lambda^2 + (k_2-2)\\lambda + (1-k_2+k_1) = 0$.\nUsing the relations $k_2-2=(1-w_1)k_1$ and $1-k_2+k_1 = k_1^2$, the polynomial becomes:\n$\\lambda^2 + (1-w_1)k_1 \\lambda + k_1^2 = 0$.\nThe roots are $\\lambda = \\frac{-(1-w_1)k_1 \\pm \\sqrt{(1-w_1)^2k_1^2 - 4k_1^2}}{2} = \\frac{k_1}{2} \\left( -(1-w_1) \\pm \\sqrt{(1-w_1)^2 - 4} \\right)$.\nThe term under the square root is $(1-w_1)^2-4 = (\\frac{1-\\sqrt{21}}{2})^2-4 = \\frac{1-2\\sqrt{21}+21}{4}-4 = \\frac{22-2\\sqrt{21}-16}{4} = \\frac{6-2\\sqrt{21}}{4} = \\frac{3-\\sqrt{21}}{2}  0$.\nThe roots are complex conjugates. The magnitude squared of the roots is:\n$|\\lambda|^2 = \\left( \\frac{k_1(w_1-1)}{2} \\right)^2 + \\left( \\frac{k_1\\sqrt{4-(w_1-1)^2}}{2} \\right)^2 = \\frac{k_1^2}{4} \\left( (w_1-1)^2 + 4-(w_1-1)^2 \\right) = k_1^2$.\nSo, $|\\lambda| = |k_1|$. Since $p_{12} > 1$, we have $0  k_1 = 1/p_{12}  1$. The eigenvalues of the closed-loop system are strictly inside the unit circle, confirming that $A-BK$ is Schur stable.\n\n**Step 6: Certainty Equivalence Principle**\n\nThe Linear Quadratic Gaussian (LQG) control problem extends the LQR framework to systems affected by Gaussian noise. For a system described by $x_{k+1} = Ax_k + Bu_k + w_k$ and $y_k = Cx_k + v_k$, where $w_k$ and $v_k$ are zero-mean Gaussian white noise processes, the goal is to minimize the expected value of the same quadratic cost functional.\nThe solution to the LQG problem famously separates into an optimal state estimation problem and an optimal control problem. This is known as the **separation principle**.\nFirst, a Kalman filter is designed to produce an optimal estimate of the state, $\\hat{x}_k$, based on the history of measurements.\nThen, the **certainty equivalence principle** states that the optimal control law is obtained by simply using this state estimate $\\hat{x}_k$ in place of the true (and unknown) state $x_k$ in the deterministic LQR control law.\nTherefore, the LQG controller would be $u_k = -K \\hat{x}_k$, using the very same gain matrix $K$ derived in this problem. The design of the controller $(K)$ and the observer (Kalman filter) are independent. This property is a cornerstone of modern control theory but holds specifically for linear systems with Gaussian noise and quadratic costs.", "answer": "$$\n\\boxed{\\begin{pmatrix} \\frac{1+\\sqrt{21} - \\sqrt{6+2\\sqrt{21}}}{4}  -\\frac{1}{2} + \\frac{\\sqrt{21}-1}{8}\\sqrt{6+2\\sqrt{21}} \\end{pmatrix}}\n$$", "id": "2719578"}, {"introduction": "Solving the Riccati equation is only part of the battle; we must ensure the solution yields a stable system. This practice [@problem_id:2719585] challenges you to move beyond calculation and engage in critical verification, applying the correct spectral radius criterion to identify stabilizing controller and observer gains. It reinforces your understanding of discrete-time stability and the separation principle, which states that the controller and observer eigenvalues collectively determine the overall LQG system stability.", "problem": "Consider a discrete-time linear time-invariant system subject to Gaussian process and measurement noise, given by $x_{k+1} = A x_k + B u_k + w_k$ and $y_k = C x_k + v_k$, where $x_k \\in \\mathbb{R}^2$, $u_k \\in \\mathbb{R}$, $y_k \\in \\mathbb{R}$, and $w_k$, $v_k$ are zero-mean Gaussian noises with appropriate covariances. Assume $(A,B)$ is stabilizable and $(A,C)$ is detectable. You are given \n$$A = \\begin{bmatrix} 1.2  0.1 \\\\ 0  0.9 \\end{bmatrix}, \\quad B = \\begin{bmatrix} 0.5 \\\\ 0.2 \\end{bmatrix}, \\quad C = \\begin{bmatrix} 1  0 \\end{bmatrix}.$$\nSuppose two candidate state-feedback gains $K_1$ and $K_2$ have been computed from two distinct symmetric solutions to the discrete algebraic Riccati equation associated with a quadratic cost, and two candidate observer gains $L_1$ and $L_2$ have been computed from two distinct symmetric solutions to the estimator Riccati equation for a steady-state Kalman filter:\n$$K_1 = \\begin{bmatrix} 1.8  0.4 \\end{bmatrix}, \\quad K_2 = \\begin{bmatrix} 0.2  0.05 \\end{bmatrix},$$\n$$L_1 = \\begin{bmatrix} 0.6 \\\\ 0.1 \\end{bmatrix}, \\quad L_2 = \\begin{bmatrix} 1.2 \\\\ 0.5 \\end{bmatrix}.$$\nYou are asked to determine which statements correctly describe how to verify that a computed Riccati solution corresponds to the stabilizing branch using spectral properties and how this relates to certainty equivalence in Linear Quadratic Gaussian (LQG) control.\n\nUse as fundamental base the following well-tested facts: for a discrete-time linear time-invariant system $x_{k+1} = F x_k$, asymptotic stability is equivalent to all eigenvalues of $F$ lying strictly inside the open unit disk in the complex plane, that is, the spectral radius $\\rho(F) = \\max_i |\\lambda_i(F)|$ is strictly less than $1$; for the steady-state Kalman filter, detectability of $(A,C)$ guarantees existence of a stabilizing solution; and the separation principle for LQG states that, under stabilizability and detectability, the controller and observer can be designed independently and combined without loss of internal stability.\n\nWhich of the following statements are correct?\n\nA. In discrete time, the stabilizing branch of the control Riccati equation is the one whose feedback gain $K$ yields a closed-loop matrix $A - B K$ with spectral radius strictly less than $1$. For the given data, $K_1$ is stabilizing while $K_2$ is not.\n\nB. In discrete time, to verify that an estimator Riccati solution is stabilizing, it suffices to check that all eigenvalues of $A - L C$ have strictly negative real parts. For the given $L_1$ and $L_2$, this condition holds, hence both are stabilizing.\n\nC. By the separation principle (certainty equivalence), the eigenvalues of the overall LQG closed-loop realized by $u_k = -K_1 \\hat{x}_k$ and a steady-state Kalman filter with gain $L_1$ are the union of the eigenvalues of $A - B K_1$ and $A - L_1 C$. Therefore, if both $A - B K_1$ and $A - L_1 C$ have spectral radius strictly less than $1$, the overall closed loop is mean-square stable.\n\nD. Any symmetric positive semidefinite solution of the discrete algebraic Riccati equation yields a stabilizing feedback gain, so spectral checks on $A - B K$ are unnecessary.\n\nE. For continuous-time problems, the correct analogue of the discrete-time verification is to require that the spectral radius of $A - B K$ be strictly less than $1$; this is the proper test for the stabilizing branch in continuous time as well.\n\nSelect all that apply. Justify your choice from first principles, without appealing to unproven shortcuts beyond the stated base facts.", "solution": "The problem requires an evaluation of several statements related to the design and verification of a discrete-time Linear Quadratic Gaussian (LQG) controller. The foundation for this analysis rests upon the principles of stability for discrete-time linear systems and the separation theorem.\n\nThe system is described by the discrete-time linear time-invariant (LTI) equations:\n$$x_{k+1} = A x_k + B u_k + w_k$$\n$$y_k = C x_k + v_k$$\nwith given matrices:\n$$A = \\begin{bmatrix} 1.2  0.1 \\\\ 0  0.9 \\end{bmatrix}, \\quad B = \\begin{bmatrix} 0.5 \\\\ 0.2 \\end{bmatrix}, \\quad C = \\begin{bmatrix} 1  0 \\end{bmatrix}$$\nThe candidate gains are:\nState-feedback: $K_1 = \\begin{bmatrix} 1.8  0.4 \\end{bmatrix}$, $K_2 = \\begin{bmatrix} 0.2  0.05 \\end{bmatrix}$\nObserver: $L_1 = \\begin{bmatrix} 0.6 \\\\ 0.1 \\end{bmatrix}$, $L_2 = \\begin{bmatrix} 1.2 \\\\ 0.5 \\end{bmatrix}$\n\nThe fundamental criterion for asymptotic stability of a discrete-time system $x_{k+1} = F x_k$ is that all eigenvalues of the matrix $F$ must lie strictly inside the open unit disk of the complex plane. This is equivalent to the spectral radius of $F$, $\\rho(F) = \\max_i |\\lambda_i(F)|$, being strictly less than $1$. We shall use this criterion to evaluate each statement.\n\n**Analysis of Statement A**\n\nThe statement posits that for a discrete-time system, a feedback gain $K$ is stabilizing if the closed-loop matrix $A - B K$ has a spectral radius strictly less than $1$. It then claims that $K_1$ is stabilizing while $K_2$ is not.\n\nThe first part of the statement is the definition of stability for a discrete-time state-feedback system. With the control law $u_k = -K x_k$, the closed-loop dynamics become $x_{k+1} = (A - B K) x_k$. This system is asymptotically stable if and only if $\\rho(A - B K)  1$. This is correct.\n\nNow, we must verify this for the given gains.\n\nFor $K_1 = \\begin{bmatrix} 1.8  0.4 \\end{bmatrix}$:\nThe closed-loop matrix is $A_{cl,1} = A - B K_1$.\n$$B K_1 = \\begin{bmatrix} 0.5 \\\\ 0.2 \\end{bmatrix} \\begin{bmatrix} 1.8  0.4 \\end{bmatrix} = \\begin{bmatrix} 0.9  0.2 \\\\ 0.36  0.08 \\end{bmatrix}$$\n$$A_{cl,1} = \\begin{bmatrix} 1.2  0.1 \\\\ 0  0.9 \\end{bmatrix} - \\begin{bmatrix} 0.9  0.2 \\\\ 0.36  0.08 \\end{bmatrix} = \\begin{bmatrix} 0.3  -0.1 \\\\ -0.36  0.82 \\end{bmatrix}$$\nThe characteristic equation is $\\det(A_{cl,1} - \\lambda I) = 0$:\n$$(0.3 - \\lambda)(0.82 - \\lambda) - (-0.1)(-0.36) = 0$$\n$$\\lambda^2 - 1.12 \\lambda + 0.246 - 0.036 = 0$$\n$$\\lambda^2 - 1.12 \\lambda + 0.21 = 0$$\nThe eigenvalues are $\\lambda = \\frac{1.12 \\pm \\sqrt{1.12^2 - 4(1)(0.21)}}{2} = \\frac{1.12 \\pm \\sqrt{1.2544 - 0.84}}{2} = \\frac{1.12 \\pm \\sqrt{0.4144}}{2}$.\n$\\lambda_1 \\approx \\frac{1.12 + 0.6437}{2} \\approx 0.8819$ and $\\lambda_2 \\approx \\frac{1.12 - 0.6437}{2} \\approx 0.2382$.\nSince $|\\lambda_1|  1$ and $|\\lambda_2|  1$, the spectral radius $\\rho(A - B K_1)  1$. Thus, $K_1$ is a stabilizing gain.\n\nFor $K_2 = \\begin{bmatrix} 0.2  0.05 \\end{bmatrix}$:\nThe closed-loop matrix is $A_{cl,2} = A - B K_2$.\n$$B K_2 = \\begin{bmatrix} 0.5 \\\\ 0.2 \\end{bmatrix} \\begin{bmatrix} 0.2  0.05 \\end{bmatrix} = \\begin{bmatrix} 0.1  0.025 \\\\ 0.04  0.01 \\end{bmatrix}$$\n$$A_{cl,2} = \\begin{bmatrix} 1.2  0.1 \\\\ 0  0.9 \\end{bmatrix} - \\begin{bmatrix} 0.1  0.025 \\\\ 0.04  0.01 \\end{bmatrix} = \\begin{bmatrix} 1.1  0.075 \\\\ -0.04  0.89 \\end{bmatrix}$$\nThe characteristic equation is $\\det(A_{cl,2} - \\lambda I) = 0$:\n$$(1.1 - \\lambda)(0.89 - \\lambda) - (0.075)(-0.04) = 0$$\n$$\\lambda^2 - 1.99 \\lambda + 0.979 + 0.003 = 0$$\n$$\\lambda^2 - 1.99 \\lambda + 0.982 = 0$$\nThe eigenvalues are $\\lambda = \\frac{1.99 \\pm \\sqrt{1.99^2 - 4(1)(0.982)}}{2} = \\frac{1.99 \\pm \\sqrt{3.9601 - 3.928}}{2} = \\frac{1.99 \\pm \\sqrt{0.0321}}{2}$.\n$\\lambda_1 \\approx \\frac{1.99 + 0.1792}{2} \\approx 1.0846$ and $\\lambda_2 \\approx \\frac{1.99 - 0.1792}{2} \\approx 0.9054$.\nSince $|\\lambda_1|  1$, the spectral radius $\\rho(A - B K_2)  1$. Thus, $K_2$ is not a stabilizing gain.\n\nThe statement is entirely correct.\nVerdict for A: **Correct**.\n\n**Analysis of Statement B**\n\nThis statement claims that an estimator gain $L$ is stabilizing if all eigenvalues of $A - L C$ have strictly negative real parts. This is fundamentally incorrect. The dynamics of the estimation error $e_k = x_k - \\hat{x}_k$ are given by $e_{k+1} = (A - L C)e_k + w_k - L v_k$. This is a discrete-time system. For the error to converge to zero (in the mean-square sense), the deterministic part of the system must be stable, which requires the spectral radius of the matrix $A - L C$ to be strictly less than $1$, i.e., $\\rho(A - L C)  1$.\n\nThe condition that eigenvalues must have strictly negative real parts is the stability criterion for continuous-time systems of the form $\\dot{x} = Fx$. It is not applicable to discrete-time systems. An eigenvalue such as $\\lambda = -1.5$ has a negative real part but lies outside the unit circle, corresponding to an unstable, oscillating mode in a discrete-time system. Therefore, the premise of the statement is false.\n\nAlthough the premise is false, for completeness, we check the actual stability of the given observer gains using the correct criterion.\n\nFor $L_1 = \\begin{bmatrix} 0.6 \\\\ 0.1 \\end{bmatrix}$: The estimator error matrix is $A_{est,1} = A - L_1 C$.\n$$L_1 C = \\begin{bmatrix} 0.6 \\\\ 0.1 \\end{bmatrix} \\begin{bmatrix} 1  0 \\end{bmatrix} = \\begin{bmatrix} 0.6  0 \\\\ 0.1  0 \\end{bmatrix}$$\n$$A_{est,1} = \\begin{bmatrix} 1.2  0.1 \\\\ 0  0.9 \\end{bmatrix} - \\begin{bmatrix} 0.6  0 \\\\ 0.1  0 \\end{bmatrix} = \\begin{bmatrix} 0.6  0.1 \\\\ -0.1  0.9 \\end{bmatrix}$$\nThe characteristic equation is $\\lambda^2 - 1.5\\lambda + 0.54 + 0.01 = \\lambda^2 - 1.5\\lambda + 0.55 = 0$.\nThe eigenvalues are $\\lambda = \\frac{1.5 \\pm \\sqrt{2.25 - 2.2}}{2} = \\frac{1.5 \\pm \\sqrt{0.05}}{2}$.\n$\\lambda_1 \\approx 0.8618$, $\\lambda_2 \\approx 0.6382$. Both are inside the unit circle, so $L_1$ is stabilizing. Note that their real parts are positive, contradicting the statement's conclusion.\n\nFor $L_2 = \\begin{bmatrix} 1.2 \\\\ 0.5 \\end{bmatrix}$: The estimator error matrix is $A_{est,2} = A - L_2 C$.\n$$L_2 C = \\begin{bmatrix} 1.2 \\\\ 0.5 \\end{bmatrix} \\begin{bmatrix} 1  0 \\end{bmatrix} = \\begin{bmatrix} 1.2  0 \\\\ 0.5  0 \\end{bmatrix}$$\n$$A_{est,2} = \\begin{bmatrix} 1.2  0.1 \\\\ 0  0.9 \\end{bmatrix} - \\begin{bmatrix} 1.2  0 \\\\ 0.5  0 \\end{bmatrix} = \\begin{bmatrix} 0  0.1 \\\\ -0.5  0.9 \\end{bmatrix}$$\nThe characteristic equation is $\\lambda^2 - 0.9\\lambda + 0.05 = 0$.\nThe eigenvalues are $\\lambda = \\frac{0.9 \\pm \\sqrt{0.81 - 0.2}}{2} = \\frac{0.9 \\pm \\sqrt{0.61}}{2}$.\n$\\lambda_1 \\approx 0.8405$, $\\lambda_2 \\approx 0.0595$. Both are inside the unit circle, so $L_2$ is also stabilizing. Their real parts are also positive.\n\nThe statement proposes an incorrect stability criterion for discrete-time systems.\nVerdict for B: **Incorrect**.\n\n**Analysis of Statement C**\n\nThis statement describes the separation principle for LQG control. The overall closed-loop system, using the state $x_k$ and the estimation error $e_k = x_k - \\hat{x}_k$, has dynamics described by the augmented state vector $\\begin{bmatrix} x_k \\\\ e_k \\end{bmatrix}$. The state evolution is:\n$$x_{k+1} = A x_k + B u_k + w_k = A x_k - B K \\hat{x}_k + w_k = A x_k - B K(x_k - e_k) + w_k = (A-BK)x_k + (BK)e_k + w_k$$\n$$e_{k+1} = (A-LC)e_k + w_k - Lv_k$$\nIn matrix form, the homogeneous part of the system is:\n$$\\begin{bmatrix} x_{k+1} \\\\ e_{k+1} \\end{bmatrix} = \\begin{bmatrix} A - B K  B K \\\\ 0  A - L C \\end{bmatrix} \\begin{bmatrix} x_k \\\\ e_k \\end{bmatrix}$$\nThe system matrix of the combined system is block upper triangular. A property of such matrices is that their set of eigenvalues is the union of the sets of eigenvalues of the diagonal blocks. Therefore, the eigenvalues of the overall closed-loop system are precisely the eigenvalues of $(A - BK)$ combined with the eigenvalues of $(A - LC)$. This is the essence of the separation principle.\n\nThe stability of the overall system is determined by the spectral radius of this combined matrix. For stability, all eigenvalues must lie inside the unit circle. This will be true if and only if all eigenvalues of $(A - BK)$ are inside the unit circle AND all eigenvalues of $(A - LC)$ are inside the unit circle. This is equivalent to $\\rho(A - BK)  1$ and $\\rho(A - LC)  1$.\nIf these conditions hold, the deterministic part of the closed-loop system is asymptotically stable. For a system driven by zero-mean, finite-variance noise, this ensures that the state covariance remains bounded, which corresponds to mean-square stability. The statement is a correct and precise articulation of the separation principle for discrete-time LQG systems.\nVerdict for C: **Correct**.\n\n**Analysis of Statement D**\n\nThis statement claims that any symmetric positive semidefinite solution of the discrete algebraic Riccati equation (DARE) yields a stabilizing feedback gain, making spectral checks unnecessary. This is false.\nThe DARE may have multiple symmetric solutions. Under the standard assumptions of stabilizability of $(A,B)$ and detectability of $(A, Q^{1/2})$, there exists a unique stabilizing solution, which is also the unique positive semidefinite solution. However, if the detectability condition is not met, multiple positive semidefinite solutions can exist, not all of which are stabilizing. Furthermore, DAREs can possess non-stabilizing symmetric solutions that are not positive semidefinite.\n\nThe problem itself provides a counterexample. $K_1$ and $K_2$ are stated to originate from two distinct symmetric solutions of the DARE. Our analysis of statement A has proven that $K_1$ is stabilizing while $K_2$ is not. This directly refutes the claim that any such solution is stabilizing. Consequently, performing a spectral check on the resulting closed-loop matrix $A - BK$ is a crucial and mandatory step to ensure that the controller obtained from a Riccati solver is indeed the desired stabilizing controller. The statement that such checks are \"unnecessary\" is incorrect and reflects a dangerous misunderstanding of control theory.\nVerdict for D: **Incorrect**.\n\n**Analysis of Statement E**\n\nThis statement makes a claim about the stability criterion for continuous-time systems, suggesting it is the same as for discrete-time systems. It claims stability is determined by requiring the spectral radius of $A - B K$ to be strictly less than $1$.\nThis is false. For a continuous-time LTI system $\\dot{x} = F x$, asymptotic stability requires all eigenvalues of $F$ to have strictly negative real parts, i.e., $\\text{Re}(\\lambda_i(F))  0$ for all $i$.\nThe condition $\\rho(F)  1$ is neither necessary nor sufficient for the stability of a continuous-time system.\n- Counterexample (sufficiency): If $F = \\text{diag}(0.5, 0.5)$, then $\\rho(F) = 0.5  1$, but the eigenvalues have positive real parts, so the system is unstable.\n- Counterexample (necessity): If $F = \\text{diag}(-2, -2)$, then the eigenvalues have negative real parts, so the system is stable. However, $\\rho(F) = 2  1$.\n\nThe statement incorrectly generalizes the discrete-time stability criterion to the continuous-time domain. The two domains have fundamentally different stability boundaries in the complex plane: the unit circle for discrete time and the open left-half plane for continuous time.\nVerdict for E: **Incorrect**.\n\nIn conclusion, only statements A and C are scientifically and mathematically correct.", "answer": "$$\\boxed{AC}$$", "id": "2719585"}, {"introduction": "Theory comes to life through implementation. This final practice [@problem_id:2719583] bridges the gap between analytical derivations and real-world application by having you numerically solve the control and estimation Riccati equations for several systems. You will compute the LQR gain $K$ and the Kalman gain $L$, then programmatically verify that the closed-loop dynamics of both the controller ($A-BK$) and the estimator ($A-LC$) are stable, confirming the power and reliability of the LQG design methodology in a computational setting.", "problem": "Consider a discrete-time, linear time-invariant system with state update and noisy measurement given by $x_{k+1} = A x_k + B u_k + w_k$ and $y_k = C x_k + v_k$, where $x_k \\in \\mathbb{R}^n$, $u_k \\in \\mathbb{R}^m$, $y_k \\in \\mathbb{R}^p$, and the process noise $w_k$ and measurement noise $v_k$ are zero-mean, independent Gaussian sequences with covariances $W \\succeq 0$ and $V \\succ 0$, respectively. For the infinite-horizon Linear Quadratic Gaussian (LQG) control problem with quadratic performance index $J = \\sum_{k=0}^{\\infty} \\left( x_k^\\top Q x_k + u_k^\\top R u_k \\right)$, where $Q \\succeq 0$ and $R \\succ 0$, the certainty-equivalence principle states that the optimal controller is the state-feedback law $u_k = -K \\hat{x}_k$ where $\\hat{x}_k$ is the state estimate produced by the steady-state Kalman filter. The controller gain $K$ is constructed from the stabilizing solution $P \\succeq 0$ of the discrete-time Algebraic Riccati Equation (ARE) for the control problem, and the steady-state Kalman filter gain $L$ is constructed from the stabilizing solution $S \\succeq 0$ of the dual discrete-time ARE for the estimation problem. Under standard stabilizability and detectability assumptions, the closed-loop matrix $A - B K$ must be Schur (all eigenvalues strictly inside the unit circle), and the estimation error dynamics matrix $A - L C$ must also be Schur. Your task is to compute these stabilizing solutions numerically and verify the Schur property for each.\n\nUse only mathematically sound facts as the starting point: the definitions of the discrete-time system, quadratic cost, stabilizing solution of the discrete-time Algebraic Riccati Equation, and the definitions of the Linear Quadratic Regulator (LQR) and steady-state Kalman filter in the Linear Quadratic Gaussian (LQG) framework. Do not assume any special structure beyond what is explicitly given.\n\nImplement a program that, for each test case below, performs the following steps:\n- Numerically computes the stabilizing solution $P$ to the discrete-time Algebraic Riccati Equation for the control problem and constructs the state-feedback gain $K$.\n- Numerically computes the stabilizing solution $S$ to the dual discrete-time Algebraic Riccati Equation for the estimation problem and constructs the steady-state Kalman gain $L$.\n- Verifies that all eigenvalues of $A - B K$ have magnitude strictly less than $1$.\n- Verifies that all eigenvalues of $A - L C$ have magnitude strictly less than $1$.\n\nThe program must use a small numerical tolerance $0  \\varepsilon \\ll 1$ to implement the strict inequality, declaring stability if $\\max_i |\\lambda_i|  1 - \\varepsilon$ for the relevant eigenvalues $\\{\\lambda_i\\}$.\n\nTest Suite:\nProvide results for the following three cases. All matrices and scalars are real-valued.\n\n- Case $1$ (unstable $2 \\times 2$ system, single input, single output):\n  - $A_1 = \\begin{bmatrix} 1.2  0.5 \\\\ 0  1.1 \\end{bmatrix}$,\n    $B_1 = \\begin{bmatrix} 1.0 \\\\ 0.3 \\end{bmatrix}$,\n    $Q_1 = \\begin{bmatrix} 1.0  0 \\\\ 0  1.0 \\end{bmatrix}$,\n    $R_1 = \\begin{bmatrix} 0.5 \\end{bmatrix}$,\n    $C_1 = \\begin{bmatrix} 1.0  0.0 \\end{bmatrix}$,\n    $W_1 = 0.1 \\cdot I_2$,\n    $V_1 = \\begin{bmatrix} 0.5 \\end{bmatrix}$.\n\n- Case $2$ (unstable $3 \\times 3$ system, full input, full state measurement):\n  - $A_2 = \\begin{bmatrix} 1.1  0.2  0.0 \\\\ 0.0  1.05  0.3 \\\\ 0.1  0.0  1.2 \\end{bmatrix}$,\n    $B_2 = I_3$,\n    $Q_2 = \\mathrm{diag}(2.0, 1.0, 3.0)$,\n    $R_2 = 0.8 \\cdot I_3$,\n    $C_2 = I_3$,\n    $W_2 = 0.05 \\cdot I_3$,\n    $V_2 = 0.2 \\cdot I_3$.\n\n- Case $3$ (nearly marginally unstable $2 \\times 2$ system, single input, full state measurement):\n  - $A_3 = \\begin{bmatrix} 1.000001  0.01 \\\\ 0.0  1.000001 \\end{bmatrix}$,\n    $B_3 = \\begin{bmatrix} 0.0 \\\\ 1.0 \\end{bmatrix}$,\n    $Q_3 = \\mathrm{diag}(0.0001, 1.0)$,\n    $R_3 = \\begin{bmatrix} 0.1 \\end{bmatrix}$,\n    $C_3 = I_2$,\n    $W_3 = 0.0001 \\cdot I_2$,\n    $V_3 = 0.001 \\cdot I_2$.\n\nFinal Output Format:\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets. The list must contain six boolean values in the following order:\n- First three entries: for Cases $1$, $2$, $3$, whether all eigenvalues of $A - B K$ lie strictly inside the unit circle.\n- Next three entries: for Cases $1$, $2$, $3$, whether all eigenvalues of $A - L C$ lie strictly inside the unit circle.\n\nFor example, the output should look like $[\\text{result}_1,\\text{result}_2,\\text{result}_3,\\text{result}_4,\\text{result}_5,\\text{result}_6]$, where each $\\text{result}_i$ is either $\\text{True}$ or $\\text{False}$.\n\nNo physical units or angle units are involved, so no unit conversions are required. All computations must be carried out numerically with appropriate conditioning safeguards. The output must be deterministic and reproducible without randomness.", "solution": "The problem presented is a standard exercise in modern control theory, specifically within the domain of Linear Quadratic Gaussian (LQG) control for discrete-time, linear time-invariant (LTI) systems. Before proceeding to the numerical solution, it is imperative to establish the theoretical foundation upon which the calculations are based. The problem is scientifically grounded, well-posed, and contains all necessary information for a unique solution.\n\nThe system is described by the state-space equations:\n$$x_{k+1} = A x_k + B u_k + w_k$$\n$$y_k = C x_k + v_k$$\nwhere $w_k$ and $v_k$ are independent, zero-mean Gaussian white noise processes with covariance matrices $W \\succeq 0$ and $V \\succ 0$, respectively.\n\nThe objective is to design a controller that minimizes the infinite-horizon quadratic cost function:\n$$J = \\sum_{k=0}^{\\infty} \\left( x_k^\\top Q x_k + u_k^\\top R u_k \\right)$$\nwith weighting matrices $Q \\succeq 0$ and $R \\succ 0$.\n\nThe LQG framework, under the certainty equivalence principle, separates the problem into two independent components: an optimal state feedback controller (Linear Quadratic Regulator or LQR) and an optimal state estimator (Kalman filter).\n\nFirst, we design the LQR controller, assuming full state availability. The optimal control law is a linear state feedback $u_k = -K x_k$. The gain matrix $K$ is determined by the unique, stabilizing, positive semi-definite solution $P$ to the discrete-time Algebraic Riccati Equation (DARE) for control:\n$$P = A^\\top P A - (A^\\top P B)(R + B^\\top P B)^{-1}(B^\\top P A) + Q$$\nThe existence of such a stabilizing solution $P \\succeq 0$ is guaranteed if the pair $(A, B)$ is stabilizable and the pair $(A, \\sqrt{Q})$ is detectable. The optimal feedback gain is then calculated as:\n$$K = (R + B^\\top P B)^{-1} B^\\top P A$$\nThe resulting closed-loop system dynamics, $x_{k+1} = (A - B K) x_k$, are guaranteed to be stable. That is, the matrix $A - B K$ is Schur, meaning all its eigenvalues lie strictly inside the unit circle in the complex plane.\n\nSecond, we design a state estimator. Since the state $x_k$ is not measured directly but is observed through the noisy measurement $y_k$, we use a steady-state Kalman filter to generate an optimal estimate of the state, $\\hat{x}_k$. The design of this filter is dual to the LQR problem. The steady-state prediction error covariance, $S$, is the unique, stabilizing, positive semi-definite solution to the DARE for estimation:\n$$S = A S A^\\top - A S C^\\top (V + C S C^\\top)^{-1} C S A^\\top + W$$\nThe existence of such a stabilizing solution $S \\succeq 0$ is guaranteed if the pair $(A, \\sqrt{W})$ is stabilizable and the pair $(A, C)$ is detectable.\n\nThe problem specifies the construction of a gain matrix $L$ as follows:\n$$L = S C^\\top (V + C S C^\\top)^{-1}$$\nThis gain $L$ is known as the Kalman corrector gain. Standard Kalman filter theory establishes that the eigenvalues of the matrix $A(I - LC)$ (which is equivalent to $A - L_p C$, where $L_p = AL$ is the predictor gain) govern the error dynamics and are strictly inside the unit circle. The problem, however, directs us to verify the Schur stability of the matrix $A - LC$. This matrix arises in the dynamics of a Luenberger-style observer of the form $\\hat{x}_{k+1} = A\\hat{x}_k + Bu_k + L(y_k - C\\hat{x}_k)$, whose error dynamics are described by $e_{k+1} = (A - LC)e_k$. We will proceed with the numerical verification as instructed.\n\nThe task is to numerically solve for $P$ and $S$ for three distinct test cases, compute the corresponding gains $K$ and $L$, and then verify the Schur stability of the matrices $A - B K$ and $A - L C$. The stability check is performed by computing the eigenvalues $\\{\\lambda_i\\}$ of the respective matrix and ensuring that $\\max_i |\\lambda_i|  1 - \\varepsilon$ for a small tolerance $\\varepsilon > 0$. We will use $\\varepsilon = 10^{-9}$. All provided test cases satisfy the required stabilizability and detectability conditions, ensuring that stabilizing solutions to the Riccati equations exist.\n\nThe computational procedure for each test case is as follows:\n1.  Solve the control DARE for $P$ using the provided matrices $A$, $B$, $Q$, and $R$.\n2.  Compute the control gain $K$ and verify if the matrix $A - B K$ is Schur.\n3.  Solve the estimation DARE for $S$ by applying the duality principle, i.e., solving the control DARE with substitutions $A \\to A^\\top$, $B \\to C^\\top$, $Q \\to W$, and $R \\to V$.\n4.  Compute the filter gain $L$ and verify if the matrix $A - L C$ is Schur.\n5.  The results of these verifications (boolean values) are collected and presented in the required format.", "answer": "```python\nimport numpy as np\nfrom scipy.linalg import solve_discrete_are\n\ndef solve():\n    \"\"\"\n    Solves for LQR and Kalman gains for given systems and verifies\n    the stability of the resulting closed-loop and observer dynamics.\n    \"\"\"\n    epsilon = 1e-9\n\n    # Case 1 (unstable 2x2 system, single input, single output)\n    A1 = np.array([[1.2, 0.5], [0, 1.1]])\n    B1 = np.array([[1.0], [0.3]])\n    Q1 = np.array([[1.0, 0], [0, 1.0]])\n    R1 = np.array([[0.5]])\n    C1 = np.array([[1.0, 0.0]])\n    W1 = 0.1 * np.identity(2)\n    V1 = np.array([[0.5]])\n\n    # Case 2 (unstable 3x3 system, full input, full state measurement)\n    A2 = np.array([[1.1, 0.2, 0.0], [0.0, 1.05, 0.3], [0.1, 0.0, 1.2]])\n    B2 = np.identity(3)\n    Q2 = np.diag([2.0, 1.0, 3.0])\n    R2 = 0.8 * np.identity(3)\n    C2 = np.identity(3)\n    W2 = 0.05 * np.identity(3)\n    V2 = 0.2 * np.identity(3)\n\n    # Case 3 (nearly marginally unstable 2x2 system, single input, full state measurement)\n    A3 = np.array([[1.000001, 0.01], [0.0, 1.000001]])\n    B3 = np.array([[0.0], [1.0]])\n    Q3 = np.diag([0.0001, 1.0])\n    R3 = np.array([[0.1]])\n    C3 = np.identity(2)\n    W3 = 0.0001 * np.identity(2)\n    V3 = 0.001 * np.identity(2)\n\n    test_cases = [\n        (A1, B1, Q1, R1, C1, W1, V1),\n        (A2, B2, Q2, R2, C2, W2, V2),\n        (A3, B3, Q3, R3, C3, W3, V3)\n    ]\n\n    k_stability_results = []\n    l_stability_results = []\n\n    for A, B, Q, R, C, W, V in test_cases:\n        # --- LQR Controller Analysis ---\n        # Solve the discrete-time Algebraic Riccati Equation for P\n        P = solve_discrete_are(A, B, Q, R)\n\n        # Compute the LQR gain K\n        inv_term_K = np.linalg.inv(R + B.T @ P @ B)\n        K = inv_term_K @ (B.T @ P @ A)\n        \n        # Form the closed-loop matrix A - BK\n        A_cl = A - B @ K\n        \n        # Check if A - BK is Schur stable\n        eigs_K = np.linalg.eigvals(A_cl)\n        is_stable_K = np.max(np.abs(eigs_K))  1.0 - epsilon\n        k_stability_results.append(is_stable_K)\n\n        # --- Kalman Filter Analysis ---\n        # Solve the dual DARE for S\n        # This is done by solving for A.T, C.T, W, V\n        S = solve_discrete_are(A.T, C.T, W, V)\n        \n        # Compute the Kalman gain L\n        inv_term_L = np.linalg.inv(V + C @ S @ C.T)\n        L = (S @ C.T) @ inv_term_L\n        \n        # Form the estimator dynamics matrix A - LC\n        A_est = A - L @ C\n        \n        # Check if A - LC is Schur stable\n        eigs_L = np.linalg.eigvals(A_est)\n        is_stable_L = np.max(np.abs(eigs_L))  1.0 - epsilon\n        l_stability_results.append(is_stable_L)\n        \n    final_results = k_stability_results + l_stability_results\n    \n    print(f\"[{','.join(map(str, final_results))}]\")\n\nsolve()\n```", "id": "2719583"}]}