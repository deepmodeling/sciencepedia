{"hands_on_practices": [{"introduction": "We begin our hands-on exploration with the cornerstone of optimal control: the deterministic Linear-Quadratic Regulator (LQR) problem. This exercise asks you to apply the Hamilton-Jacobi-Bellman (HJB) equation to a simple scalar system, using the standard ansatz of a quadratic value function. By working through this foundational problem [@problem_id:2699184], you will derive the celebrated Algebraic Riccati Equation (ARE) and learn how its solution directly yields a stabilizing optimal feedback control law, providing a crucial first step into the world of HJB-based design.", "problem": "Consider the scalar linear time-invariant system governed by $\\dot{x}(t) = a\\,x(t) + b\\,u(t)$ with the infinite-horizon quadratic performance index $J = \\int_{0}^{\\infty} \\big(q\\,x(t)^{2} + r\\,u(t)^{2}\\big)\\,dt$. Start from Bellman’s principle of optimality leading to the stationary Hamilton–Jacobi–Bellman (HJB) equation for the infinite-horizon case, and use a quadratic value function ansatz $V(x) = P\\,x^{2}$ with $P$ constant. By minimizing the HJB Hamiltonian with respect to $u$, derive the scalar continuous-time algebraic Riccati equation (ARE) satisfied by $P$. Then, for the specific data $a=1$, $b=1$, $q=2$, and $r=1$, solve the resulting scalar equation explicitly and select the stabilizing solution that renders the closed-loop system $\\dot{x}(t) = \\big(a - b\\,r^{-1}b\\,P\\big)\\,x(t)$ asymptotically stable. Express your final answer as a single closed-form analytic expression for the stabilizing $P$. No rounding is required.", "solution": "The starting point is the infinite-horizon stationary Hamilton–Jacobi–Bellman (HJB) equation for the optimal value function $V(x)$,\n$$\n0 \\;=\\; \\min_{u}\\,\\Big\\{\\, q\\,x^{2} + r\\,u^{2} + V_{x}(x)\\,\\big(a\\,x + b\\,u\\big) \\Big\\},\n$$\nwhere $V_{x}(x)$ denotes the derivative of $V$ with respect to $x$. We postulate a quadratic value function ansatz $V(x) = P\\,x^{2}$ with constant $P$. Then $V_{x}(x) = 2\\,P\\,x$, and the HJB Hamiltonian becomes\n$$\n\\mathcal{H}(x,u) \\;=\\; q\\,x^{2} + r\\,u^{2} + 2\\,P\\,x\\,(a\\,x + b\\,u).\n$$\nTo obtain the optimal input, minimize $\\mathcal{H}(x,u)$ with respect to $u$. The first-order optimality condition is\n$$\n\\frac{\\partial \\mathcal{H}}{\\partial u} \\;=\\; 2\\,r\\,u + 2\\,P\\,x\\,b \\;=\\; 0,\n$$\nwhich yields the optimal control law\n$$\nu^{\\star}(x) \\;=\\; -\\,\\frac{b\\,P}{r}\\,x.\n$$\nSubstitute $u^{\\star}(x)$ back into the Hamiltonian and enforce the HJB equation. First compute each term:\n- The state penalty is $q\\,x^{2}$.\n- The input penalty is $r\\,(u^{\\star})^{2} = r\\,\\Big(\\frac{b^{2}P^{2}}{r^{2}}\\,x^{2}\\Big) = \\frac{b^{2}}{r}\\,P^{2}\\,x^{2}$.\n- The coupling term is $V_{x}\\,(a\\,x + b\\,u^{\\star}) = 2\\,P\\,x\\,\\Big(a\\,x + b\\big(-\\frac{b\\,P}{r}\\,x\\big)\\Big) = \\big(2\\,a\\,P - \\frac{2\\,b^{2}}{r}\\,P^{2}\\big)\\,x^{2}$.\nTherefore,\n$$\n0 \\;=\\; q\\,x^{2} + \\frac{b^{2}}{r}\\,P^{2}\\,x^{2} + \\Big(2\\,a\\,P - \\frac{2\\,b^{2}}{r}\\,P^{2}\\Big)\\,x^{2}\n\\;=\\; \\Big(q + 2\\,a\\,P - \\frac{b^{2}}{r}\\,P^{2}\\Big)\\,x^{2}.\n$$\nBecause this must hold for all $x$, the scalar continuous-time algebraic Riccati equation (ARE) for $P$ is\n$$\nq + 2\\,a\\,P - \\frac{b^{2}}{r}\\,P^{2} \\;=\\; 0.\n$$\n\nFor the given data $a=1$, $b=1$, $q=2$, and $r=1$, the equation becomes\n$$\n2 + 2\\,P - P^{2} \\;=\\; 0,\n$$\nor equivalently\n$$\nP^{2} - 2\\,P - 2 \\;=\\; 0.\n$$\nSolving this quadratic yields\n$$\nP \\;=\\; \\frac{2 \\pm \\sqrt{4 + 8}}{2} \\;=\\; 1 \\pm \\sqrt{3}.\n$$\n\nTo select the stabilizing solution, examine the closed-loop scalar dynamics under the optimal controller. The optimal feedback is $u^{\\star}(x) = -\\frac{b\\,P}{r}\\,x$, so the closed-loop system is\n$$\n\\dot{x}(t) \\;=\\; \\Big(a - \\frac{b^{2}}{r}\\,P\\Big)\\,x(t) \\;=\\; \\big(1 - P\\big)\\,x(t).\n$$\nAsymptotic stability requires $1 - P < 0$, i.e., $P > 1$. Among the two roots $1 \\pm \\sqrt{3}$, only $1 + \\sqrt{3}$ satisfies $P > 1$ and is nonnegative. Hence the stabilizing solution is\n$$\nP^{\\star} \\;=\\; 1 + \\sqrt{3}.\n$$", "answer": "$$\\boxed{1+\\sqrt{3}}$$", "id": "2699184"}, {"introduction": "Building upon the deterministic case, we now introduce the reality of noise by considering a stochastic linear system. This practice [@problem_id:3001633] extends the HJB framework to an Ornstein-Uhlenbeck process, a common model for mean-reverting phenomena in finance and physics. You will see how the HJB equation naturally incorporates stochasticity through a second-derivative term arising from the diffusion's generator, leading to a solution that not only minimizes cost but also actively stabilizes the system against random perturbations.", "problem": "Consider the infinite-horizon discounted stochastic control problem for the one-dimensional controlled Ornstein–Uhlenbeck (OU) diffusion. The state process $\\{X_{t}\\}_{t \\ge 0}$ evolves according to the controlled stochastic differential equation\n$$\n\\mathrm{d}X_{t} = \\big(-\\theta X_{t} + \\beta u_{t}\\big)\\,\\mathrm{d}t + \\sigma\\,\\mathrm{d}W_{t}, \\quad X_{0}=x,\n$$\nwhere $W_{t}$ is a standard Brownian motion, and $\\theta>0$, $\\beta\\neq 0$, $\\sigma>0$ are given constants. The control process $\\{u_{t}\\}_{t \\ge 0}$ is progressively measurable with respect to the filtration of $W_{t}$ and takes values in $\\mathbb{R}$. The objective is to minimize the discounted cost functional\n$$\nJ^{u}(x) \\equiv \\mathbb{E}\\!\\left[\\int_{0}^{\\infty} \\exp(-\\rho t)\\big(q X_{t}^{2} + r u_{t}^{2}\\big)\\,\\mathrm{d}t\\right],\n$$\nover all admissible controls, where $\\rho>0$, $q>0$, and $r>0$ are given constants. Let $V(x)\\equiv \\inf_{u} J^{u}(x)$ denote the value function.\n\nStarting from the dynamic programming principle and the definitions of the diffusion generator and the discounted expected cost, derive the Hamilton–Jacobi–Bellman (HJB) equation for $V(x)$, solve it explicitly in closed form, and obtain the optimal stationary Markov feedback $u^{\\ast}(x)$. Explain how the optimal feedback modifies the linear drift and why this yields stabilization of the closed-loop OU dynamics. Your final answer must be given as a single analytic expression containing both the closed-form value function $V(x)$ and the optimal feedback $u^{\\ast}(x)$, written as a $1\\times 2$ row matrix with the first entry equal to $V(x)$ and the second entry equal to $u^{\\ast}(x)$. No numerical evaluation is required, and no rounding is to be performed.", "solution": "We begin with the controlled diffusion\n$$\n\\mathrm{d}X_{t} = b(X_{t},u_{t})\\,\\mathrm{d}t + \\sigma\\,\\mathrm{d}W_{t}, \\quad b(x,u) \\equiv -\\theta x + \\beta u,\n$$\nand the infinite-horizon discounted cost\n$$\nJ^{u}(x) = \\mathbb{E}\\!\\left[\\int_{0}^{\\infty}\\exp(-\\rho t)\\,\\ell(X_{t},u_{t})\\,\\mathrm{d}t\\right], \\quad \\ell(x,u) \\equiv q x^{2} + r u^{2},\n$$\nwith $\\rho>0$, $\\theta>0$, $q>0$, $r>0$, $\\sigma>0$, and $\\beta\\neq 0$. The dynamic programming principle asserts that if $V$ is the value function, then under sufficient regularity $V$ satisfies the Hamilton–Jacobi–Bellman (HJB) equation. For a twice continuously differentiable $V$ and a discount factor $\\rho>0$, the HJB for this diffusion control problem is\n$$\n\\rho V(x) = \\inf_{u\\in\\mathbb{R}}\\Big\\{\\ell(x,u) + \\mathcal{L}^{u}V(x)\\Big\\},\n$$\nwhere $\\mathcal{L}^{u}$ is the controlled generator acting on smooth test functions $f$ by\n$$\n\\mathcal{L}^{u} f(x) \\equiv b(x,u) f'(x) + \\tfrac{1}{2}\\sigma^{2} f''(x) = \\big(-\\theta x + \\beta u\\big) f'(x) + \\tfrac{1}{2}\\sigma^{2} f''(x).\n$$\nThus the HJB takes the explicit form\n$$\n\\rho V(x) = \\inf_{u\\in\\mathbb{R}}\\left\\{q x^{2} + r u^{2} + \\big(-\\theta x + \\beta u\\big)V'(x) + \\tfrac{1}{2}\\sigma^{2} V''(x)\\right\\}.\n$$\n\nWe now solve this equation. The structure is linear-quadratic in $(x,u)$, and it is natural to look for a solution of the form\n$$\nV(x) = P x^{2} + C,\n$$\nwith constants $P$ and $C$ to be determined. We compute the derivatives $V'(x) = 2 P x$ and $V''(x) = 2 P$. Substituting into the HJB gives\n$$\n\\rho \\big(P x^{2} + C\\big) = \\inf_{u\\in\\mathbb{R}}\\left\\{q x^{2} + r u^{2} + \\big(-\\theta x + \\beta u\\big)\\,2 P x + \\tfrac{1}{2}\\sigma^{2}\\cdot 2 P\\right\\}.\n$$\nThe minimization over $u$ involves the quadratic function\n$$\n\\Phi(u;x) \\equiv r u^{2} + 2 P \\beta x\\, u + \\big(q x^{2} - 2\\theta P x^{2} + \\sigma^{2} P\\big).\n$$\nFor each fixed $x$, the minimizer $u^{\\ast}(x)$ satisfies the first-order condition\n$$\n\\frac{\\partial \\Phi}{\\partial u}(u;x) = 2 r u + 2 P \\beta x = 0,\n$$\nwhich yields the stationary feedback\n$$\nu^{\\ast}(x) = -\\frac{\\beta P}{r}\\,x.\n$$\nThe second derivative $\\frac{\\partial^{2}\\Phi}{\\partial u^{2}} = 2 r>0$ confirms that this is indeed the global minimizer. Substituting $u^{\\ast}$ back, we evaluate at the minimum:\n\n$$\n\\begin{aligned}\nr \\big(u^{\\ast}(x)\\big)^{2} &= r \\left(\\frac{\\beta^{2} P^{2}}{r^{2}} x^{2}\\right) = \\frac{\\beta^{2} P^{2}}{r} x^{2},\\\\\n\\big(-\\theta x + \\beta u^{\\ast}(x)\\big) V'(x) &= \\big(-\\theta x - \\beta \\tfrac{\\beta P}{r} x\\big)\\,2 P x = \\big(-2\\theta P - \\tfrac{2\\beta^{2} P^{2}}{r}\\big) x^{2},\\\\\n\\tfrac{1}{2}\\sigma^{2} V''(x) &= \\sigma^{2} P.\n\\end{aligned}\n$$\n\nTherefore the HJB becomes, after minimization,\n$$\n\\rho P x^{2} + \\rho C = \\left[q - 2\\theta P - \\frac{\\beta^{2}}{r} P^{2}\\right] x^{2} + \\sigma^{2} P.\n$$\nMatching the coefficients of $x^{2}$ and the constants gives the coupled algebraic equations\n\n$$\n\\begin{cases}\n\\rho P = q - 2\\theta P - \\dfrac{\\beta^{2}}{r} P^{2}, \\\\\n\\rho C = \\sigma^{2} P.\n\\end{cases}\n$$\n\nThe first is an algebraic Riccati equation for $P$:\n$$\n\\frac{\\beta^{2}}{r} P^{2} + (\\rho + 2\\theta) P - q = 0.\n$$\nIts two roots are\n$$\nP_{\\pm} = \\frac{ -(\\rho + 2\\theta) \\pm \\sqrt{(\\rho + 2\\theta)^{2} + \\dfrac{4\\beta^{2}}{r} q} }{ 2 \\dfrac{\\beta^{2}}{r} } = \\frac{r}{2\\beta^{2}}\\left( -(\\rho + 2\\theta) \\pm \\sqrt{(\\rho + 2\\theta)^{2} + \\frac{4\\beta^{2}}{r} q} \\right).\n$$\nBecause $q>0$, $r>0$, and $\\beta\\neq 0$, the discriminant is strictly greater than $(\\rho + 2\\theta)^{2}$, so the square root exceeds $\\rho + 2\\theta$. Hence $P_{-}<0$ and\n$$\nP_{+} = \\frac{r}{2\\beta^{2}}\\left( -(\\rho + 2\\theta) + \\sqrt{(\\rho + 2\\theta)^{2} + \\frac{4\\beta^{2}}{r} q} \\right) > 0.\n$$\nConvexity of $V$ and finiteness of the value function select the positive stabilizing solution, so we take $P=P_{+}$. The constant $C$ is then\n$$\nC = \\frac{\\sigma^{2}}{\\rho}\\,P_{+}.\n$$\n\nCollecting, the value function and optimal feedback are\n\n$$\n\\begin{aligned}\nV(x) &= P_{+} x^{2} + \\frac{\\sigma^{2}}{\\rho}\\,P_{+},\\\\\nu^{\\ast}(x) &= -\\frac{\\beta P_{+}}{r}\\,x = \\frac{(\\rho + 2\\theta) - \\sqrt{(\\rho + 2\\theta)^{2} + \\dfrac{4\\beta^{2}}{r} q}}{2\\beta}\\,x.\n\\end{aligned}\n$$\n\nThe equality for $u^{\\ast}(x)$ follows by substituting the expression for $P_{+}$. To interpret stabilization, observe that under $u^{\\ast}$ the closed-loop drift becomes\n$$\n-\\theta x + \\beta u^{\\ast}(x) = -\\left(\\theta + \\frac{\\beta^{2}}{r} P_{+}\\right) x,\n$$\nwith $\\theta + \\dfrac{\\beta^{2}}{r} P_{+} > \\theta > 0$. Thus the linear drift coefficient in the closed loop is strictly more negative than in open loop, yielding an Ornstein–Uhlenbeck process with stronger mean reversion to the origin. This negative linear feedback is precisely the stabilizing action that minimizes the long-run discounted quadratic cost in the presence of diffusion noise.", "answer": "$$\\boxed{\\begin{pmatrix}\n\\frac{r}{2\\beta^{2}}\\!\\left(\\! -(\\rho+2\\theta)+\\sqrt{(\\rho+2\\theta)^{2}+\\frac{4\\beta^{2}}{r}q}\\,\\right) x^{2}+\\frac{\\sigma^{2}}{\\rho}\\cdot \\frac{r}{2\\beta^{2}}\\!\\left(\\! -(\\rho+2\\theta)+\\sqrt{(\\rho+2\\theta)^{2}+\\frac{4\\beta^{2}}{r}q}\\,\\right)\n&\n\\frac{(\\rho+2\\theta)-\\sqrt{(\\rho+2\\theta)^{2}+\\frac{4\\beta^{2}}{r}q}}{2\\beta}\\,x\n\\end{pmatrix}}$$", "id": "3001633"}, {"introduction": "While quadratic costs lead to elegant, smooth solutions, many optimal control problems are not so forgiving. This exercise [@problem_id:2752646] shifts our focus to a minimum time problem, where the value function is often not differentiable everywhere. By testing a smooth candidate function against the HJB equation, you will discover that it fails to be a classical solution, revealing a non-zero residual. This insightful failure demonstrates why the classical interpretation of the HJB equation is insufficient and motivates the more powerful and general framework of viscosity solutions.", "problem": "Consider the deterministic control system on the domain $\\Omega := (-1,1)$ given by the dynamics $\\dot{x}(t) = u(t)$ with control constraint $u(t) \\in [-1,1]$ for all $t \\geq 0$. Let the exit time be $\\tau := \\inf\\{ t \\geq 0 : |x(t)| = 1 \\}$ and the cost functional be $J(x_{0};u(\\cdot)) := \\int_{0}^{\\tau} 1 \\, dt$, where $x(0)=x_{0} \\in \\Omega$. Define the value function $V(x_{0})$ as the infimum of $J(x_{0};u(\\cdot))$ over all measurable controls $u(\\cdot)$ with values in $[-1,1]$. \n\nStart from the dynamic programming principle and derive the pointwise consistency condition for any sufficiently smooth candidate function $W:\\Omega \\to \\mathbb{R}$ that agrees with the boundary condition $W(x)=0$ for $|x|=1$, showing how, in the interior of $\\Omega$, the Hamilton-Jacobi-Bellman (HJB) equation constrains $W$ through an appropriate residual. Then, take the specific smooth candidate $W(x) := 1 - x^{2}$, which satisfies the boundary condition $W(\\pm 1)=0$. Using your derived HJB consistency condition, evaluate the pointwise residual at $x=0$.\n\nYour final answer must be a single real number corresponding to the value of this residual at $x=0$. No rounding is required.", "solution": "The problem asks for the derivation of the Hamilton-Jacobi-Bellman (HJB) consistency condition, starting from the dynamic programming principle (DPP), and then its application to a specific candidate function.\n\nThe system dynamics are given by $\\dot{x}(t) = u(t)$, with state $x(t) \\in \\Omega := (-1,1)$ and control $u(t) \\in [-1,1]$. The cost functional represents the time to exit the domain $\\Omega$:\n$$J(x_{0};u(\\cdot)) := \\int_{0}^{\\tau} 1 \\, dt$$\nwhere $\\tau := \\inf\\{t \\geq 0 : |x(t)| = 1\\}$. The value function $V(x)$ is the infimum of this cost over all admissible controls: $V(x) = \\inf_{u(\\cdot)} J(x; u(\\cdot))$. The running cost is $L(x,u) = 1$. The boundary condition is $V(x) = 0$ for $x \\in \\partial\\Omega$, i.e., for $|x|=1$.\n\nThe dynamic programming principle states that for any small time interval $h > 0$, the value function satisfies:\n$$V(x) = \\inf_{u(\\cdot):[0,h]\\to[-1,1]} \\left\\{ \\int_0^h L(x(t), u(t)) \\, dt + V(x(h)) \\right\\}$$\nFor this specific problem, this becomes:\n$$V(x) = \\inf_{u(\\cdot):[0,h]\\to[-1,1]} \\left\\{ h + V(x(h)) \\right\\}$$\nAssuming the control $u(t)$ is a constant value $u \\in [-1,1]$ over the interval $[0, h]$, the state evolves as $x(h) = x(0) + \\int_0^h u \\, ds = x + hu$.\nIf the value function $V$ is assumed to be continuously differentiable ($C^1$), we can expand $V(x(h))$ in a Taylor series around $x$:\n$$V(x(h)) = V(x+hu) = V(x) + V'(x)(hu) + O(h^2)$$\nwhere $V'(x)$ denotes the derivative of $V$ with respect to $x$. Substituting this into the DPP equation:\n$$V(x) = \\inf_{u \\in [-1,1]} \\left\\{ h + V(x) + hV'(x)u + O(h^2) \\right\\}$$\nWe subtract $V(x)$ from both sides and divide by $h > 0$:\n$$0 = \\inf_{u \\in [-1,1]} \\left\\{ 1 + V'(x)u + O(h) \\right\\}$$\nTaking the limit as $h \\to 0$, the $O(h)$ term vanishes, yielding the stationary Hamilton-Jacobi-Bellman equation that the value function $V(x)$ must satisfy in the interior of the domain $\\Omega$:\n$$0 = \\inf_{u \\in [-1,1]} \\left\\{ 1 + V'(x)u \\right\\}$$\nThis equation provides the pointwise consistency condition. For any sufficiently smooth candidate function $W(x)$, we define the HJB residual, $R_W(x)$, as the value of the HJB expression:\n$$R_W(x) := \\inf_{u \\in [-1,1]} \\left\\{ 1 + W'(x)u \\right\\}$$\nFor a candidate function to be the true value function, its residual must be zero for all $x \\in \\Omega$ and it must satisfy the boundary conditions.\n\nWe are given the candidate function $W(x) := 1 - x^2$.\nFirst, we verify the boundary condition: $W(\\pm 1) = 1 - (\\pm 1)^2 = 1 - 1 = 0$. The condition is satisfied.\nNext, we compute the derivative of $W(x)$:\n$$W'(x) = \\frac{d}{dx}(1 - x^2) = -2x$$\nWe now substitute this derivative into the expression for the residual:\n$$R_W(x) = \\inf_{u \\in [-1,1]} \\left\\{ 1 + (-2x)u \\right\\} = \\inf_{u \\in [-1,1]} \\left\\{ 1 - 2xu \\right\\}$$\nThe expression to be minimized, $1 - 2xu$, is a linear function of the control variable $u$ on the compact set $[-1,1]$. The minimum must occur at one of the endpoints, $u=-1$ or $u=1$. The choice depends on the sign of the coefficient of $u$, which is $-2x$.\nSpecifically, the control $u^*(x)$ that minimizes the expression is $u^*(x) = \\text{sgn}(-2x) = -\\text{sgn}(x)$ for $x \\neq 0$.\nThe infimum can be written as $1 - \\sup_{u \\in [-1,1]} \\{2xu\\}$. The supremum is $2|x|$, so the residual is:\n$$R_W(x) = 1 - 2|x|$$\nThe problem asks for the value of this pointwise residual at the point $x=0$. We evaluate the residual function at $x=0$:\n$$R_W(0) = 1 - 2|0| = 1$$\nAlternatively, one can directly evaluate the infimum expression at $x=0$:\n$$R_W(0) = \\inf_{u \\in [-1,1]} \\{ 1 - 2(0)u \\} = \\inf_{u \\in [-1,1]} \\{ 1 \\} = 1$$\nThe residual at $x=0$ is $1$.", "answer": "$$\\boxed{1}$$", "id": "2752646"}]}