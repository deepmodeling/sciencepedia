{"hands_on_practices": [{"introduction": "The Rosenbrock system matrix provides a powerful, state-space-based tool for analyzing the structural properties of a multivariable system. This exercise offers direct practice in applying its fundamental definition to locate invariant zeros. By finding the specific complex frequencies $s$ where this matrix loses its normal rank, you will perform the core algebraic procedure for identifying a system's transmission-blocking capabilities, a foundational skill for understanding performance limitations. [@problem_id:2726476]", "problem": "Consider the linear time-invariant multiple-input multiple-output system with state-space realization given by the quadruple $\\left(A,B,C,D\\right)$, where\n$$\nA \\;=\\; \\begin{bmatrix}\n0  1  0\\\\\n0  -1  0\\\\\n0  0  -3\n\\end{bmatrix},\\quad\nB \\;=\\; \\begin{bmatrix}\n0  0\\\\\n1  0\\\\\n0  1\n\\end{bmatrix},\\quad\nC \\;=\\; \\begin{bmatrix}\n-1  1  0\\\\\n0  0  -1\n\\end{bmatrix},\\quad\nD \\;=\\; \\begin{bmatrix}\n0  0\\\\\n0  1\n\\end{bmatrix}.\n$$\nLet the Rosenbrock system matrix be defined by\n$$\nP(s) \\;=\\; \\begin{bmatrix}\ns I - A  -B \\\\\nC  D\n\\end{bmatrix},\n$$\nwhere $s \\in \\mathbb{C}$ and $I$ is the identity matrix of dimension matching $A$.\n\nUsing only foundational definitions, determine all finite invariant zeros of the system by identifying the complex numbers $s$ at which the normal rank of $P(s)$ drops below its normal rank (i.e., where $P(s)$ loses rank). You must proceed by directly analyzing $P(s)$ to locate such values of $s$.\n\nProvide your final answer as the distinct invariant zeros listed in increasing real order. Express the result as a single row vector using exact values, with no rounding.", "solution": "The problem requires the determination of the finite invariant zeros of a linear time-invariant system specified by the state-space realization $(A, B, C, D)$. The definition provided for these zeros is based on the rank properties of the Rosenbrock system matrix, $P(s)$. We shall adhere strictly to this definition.\n\nFirst, we must construct the Rosenbrock system matrix $P(s)$, which is defined as:\n$$\nP(s) \\;=\\; \\begin{bmatrix}\ns I - A  -B\\\\\nC  D\n\\end{bmatrix}\n$$\nThe state-space matrices are given as:\n$$\nA \\;=\\; \\begin{bmatrix}\n0  1  0\\\\\n0  -1  0\\\\\n0  0  -3\n\\end{bmatrix},\\quad\nB \\;=\\; \\begin{bmatrix}\n0  0\\\\\n1  0\\\\\n0  1\n\\end{bmatrix},\\quad\nC \\;=\\; \\begin{bmatrix}\n-1  1  0\\\\\n0  0  -1\n\\end{bmatrix},\\quad\nD \\;=\\; \\begin{bmatrix}\n0  0\\\\\n0  1\n\\end{bmatrix}\n$$\nThe dimension of the state vector is $n=3$, the number of inputs is $m=2$, and the number of outputs is $p=2$. The identity matrix $I$ is of dimension $3 \\times 3$. The matrix $sI - A$ is:\n$$\nsI - A = s\\begin{bmatrix} 1  0  0 \\\\ 0  1  0 \\\\ 0  0  1 \\end{bmatrix} - \\begin{bmatrix} 0  1  0 \\\\ 0  -1  0 \\\\ 0  0  -3 \\end{bmatrix} = \\begin{bmatrix} s  -1  0 \\\\ 0  s+1  0 \\\\ 0  0  s+3 \\end{bmatrix}\n$$\nThe matrix $-B$ is:\n$$\n-B = \\begin{bmatrix} 0  0 \\\\ -1  0 \\\\ 0  -1 \\end{bmatrix}\n$$\nCombining these blocks, the Rosenbrock system matrix $P(s)$ is a square matrix of dimension $(n+p) \\times (n+m)$, which is $(3+2) \\times (3+2) = 5 \\times 5$:\n$$\nP(s) \\;=\\; \\begin{bmatrix}\ns  -1  0  0  0 \\\\\n0  s+1  0  -1  0 \\\\\n0  0  s+3  0  -1 \\\\\n-1  1  0  0  0 \\\\\n0  0  -1  0  1\n\\end{bmatrix}\n$$\nThe finite invariant zeros are the values of $s \\in \\mathbb{C}$ for which the rank of $P(s)$ drops below its normal rank. The normal rank of a polynomial matrix is its rank at a generic value of $s$, which is the maximum rank achieved for any $s \\in \\mathbb{C}$. For a square polynomial matrix, the normal rank is its full dimension if and only if its determinant is a non-zero polynomial in $s$. We must therefore calculate the determinant of $P(s)$.\n\nWe compute $\\det(P(s))$ using cofactor expansion along the third column, which contains the most zero entries, to simplify the computation.\n$$\n\\det(P(s)) = (s+3) \\cdot C_{33} + (-1) \\cdot C_{53}\n$$\nwhere $C_{ij}$ is the cofactor of the entry at row $i$ and column $j$.\n\nThe cofactor $C_{33}$ is given by $(-1)^{3+3}$ times the determinant of the minor matrix $M_{33}$:\n$$\nC_{33} = \\det\\begin{bmatrix} s  -1  0  0 \\\\ 0  s+1  -1  0 \\\\ -1  1  0  0 \\\\ 0  0  0  1 \\end{bmatrix}\n$$\nExpanding this $4 \\times 4$ determinant along its fourth row gives:\n$$\nC_{33} = 1 \\cdot (-1)^{4+4} \\det\\begin{bmatrix} s  -1  0 \\\\ 0  s+1  -1 \\\\ -1  1  0 \\end{bmatrix} = s((s+1)(0) - (1)(-1)) - (-1)((0)(0) - (-1)(-1)) = s(1) + 1(-1) = s-1\n$$\nThe cofactor $C_{53}$ is given by $(-1)^{5+3}$ times the determinant of the minor matrix $M_{53}$:\n$$\nC_{53} = \\det\\begin{bmatrix} s  -1  0  0 \\\\ 0  s+1  -1  0 \\\\ 0  0  0  -1 \\\\ -1  1  0  0 \\end{bmatrix}\n$$\nExpanding this $4 \\times 4$ determinant along its third row gives:\n$$\nC_{53} = (-1) \\cdot (-1)^{3+4} \\det\\begin{bmatrix} s  -1  0 \\\\ 0  s+1  -1 \\\\ -1  1  0 \\end{bmatrix} = (-1)(-1)(s-1) = s-1\n$$\nSubstituting these cofactors back into the expression for $\\det(P(s))$:\n$$\n\\det(P(s)) = (s+3)(s-1) + (-1)(s-1) = (s-1) \\left[ (s+3) - 1 \\right] = (s-1)(s+2)\n$$\nThe determinant of $P(s)$ is the polynomial $(s-1)(s+2)$, which is not identically zero. Therefore, the normal rank of the $5 \\times 5$ matrix $P(s)$ is $5$.\n\nThe invariant zeros are the values of $s$ where the rank of $P(s)$ drops. For a square matrix, this occurs precisely when its determinant is zero.\n$$\n\\det(P(s)) = (s-1)(s+2) = 0\n$$\nThe roots of this equation are $s=1$ and $s=-2$. These are the finite invariant zeros of the system.\n\nThe problem requires the answer to be presented as a single row vector of the distinct zeros in increasing real order. The zeros are $-2$ and $1$. The correctly ordered vector is therefore $\\begin{pmatrix} -2  1 \\end{pmatrix}$.", "answer": "$$\n\\boxed{\\begin{pmatrix} -2  1 \\end{pmatrix}}\n$$", "id": "2726476"}, {"introduction": "An invariant zero $s_0$ is more than just an algebraic curiosity; it signifies that the system can block the transmission of an input signal related to the exponential $\\exp(s_0 t)$. This exercise connects the abstract concept of a rank drop to the physical world of inputs by challenging you to find the specific *input zero direction*. You will compute the basis for the subspace of inputs that, when paired with an appropriate internal state trajectory, result in zero output, thereby uncovering the precise structure of the input signal the system blocks. [@problem_id:2726520]", "problem": "Consider the linear time-invariant multivariable system defined in state-space form by the matrices\n$$\nA=\\begin{bmatrix}\n0  1  0 \\\\\n0  0  1 \\\\\n-6  -11  -6\n\\end{bmatrix},\\quad\nB=\\begin{bmatrix}\n1  0 \\\\\n0  1 \\\\\n0  0\n\\end{bmatrix},\\quad\nC=\\begin{bmatrix}\n1  0  0\n\\end{bmatrix},\\quad\nD=\\begin{bmatrix}\n0  0\n\\end{bmatrix}.\n$$\nWork over the field of complex numbers but note that all data are real. An invariant zero is defined via the Rosenbrock system matrix as follows: a complex number $s_0$ is an invariant zero if there exists a nonzero pair $(x,u)$ satisfying\n$$\n\\begin{bmatrix}\ns_0 I - A  -B \\\\\nC  D\n\\end{bmatrix}\n\\begin{bmatrix}\nx \\\\ u\n\\end{bmatrix}\n=0,\n$$\nequivalently,\n$$\n(s_0 I - A)x - B u = 0,\\quad Cx + Du = 0.\n$$\nThe set of input zero directions at $s_0$ is the set of all $u$ for which there exists some $x$ such that the above equations hold; it is the projection onto the input space of the null space of the Rosenbrock system matrix at $s_0$.\n\nUsing only these definitions as the starting point, and no pre-derived formulas, determine the unique scalar ratio $r = \\frac{u_2}{u_1}$ that characterizes the one-dimensional subspace of input zero directions at $s_0=0$ for the system above. Express the final answer as an exact rational number. No rounding is needed and no units are required.", "solution": "We begin from the core definitions. The Rosenbrock system matrix is\n$$\nP(s)=\\begin{bmatrix}\nsI - A  -B \\\\\nC  D\n\\end{bmatrix}.\n$$\nA complex number $s_0$ is an invariant zero if there exists a nonzero pair $(x,u)$ with $x\\in\\mathbb{C}^{3}$ and $u\\in\\mathbb{C}^{2}$ such that\n$$\n(s_0 I - A) x - B u = 0,\\quad C x + D u = 0.\n$$\nFor $s_0=0$ and the given $D=0$, these equations reduce to\n$$\n-A x - B u = 0,\\quad C x = 0.\n$$\nMultiplying the first equation by $-1$ yields the equivalent system\n$$\nA x + B u = 0,\\quad C x = 0.\n$$\nLet $x = \\begin{bmatrix} x_1 \\\\ x_2 \\\\ x_3 \\end{bmatrix}$ and $u = \\begin{bmatrix} u_1 \\\\ u_2 \\end{bmatrix}$. The output constraint $C x = 0$ gives\n$$\nx_1 = 0.\n$$\nCompute $A x$ for $x_1=0$:\n$$\nA x\n=\n\\begin{bmatrix}\n0  1  0 \\\\\n0  0  1 \\\\\n-6  -11  -6\n\\end{bmatrix}\n\\begin{bmatrix}\n0 \\\\ x_2 \\\\ x_3\n\\end{bmatrix}\n=\n\\begin{bmatrix}\nx_2 \\\\ x_3 \\\\ -11 x_2 - 6 x_3\n\\end{bmatrix}.\n$$\nCompute $B u$:\n$$\nB u\n=\n\\begin{bmatrix}\n1  0 \\\\\n0  1 \\\\\n0  0\n\\end{bmatrix}\n\\begin{bmatrix}\nu_1 \\\\ u_2\n\\end{bmatrix}\n=\n\\begin{bmatrix}\nu_1 \\\\ u_2 \\\\ 0\n\\end{bmatrix}.\n$$\nThe equation $A x + B u = 0$ therefore becomes the componentwise system\n$$\n\\begin{cases}\nx_2 + u_1 = 0, \\\\\nx_3 + u_2 = 0, \\\\\n-11 x_2 - 6 x_3 + 0 = 0.\n\\end{cases}\n$$\nThe third equation imposes a linear relation between $x_2$ and $x_3$:\n$$\n-11 x_2 - 6 x_3 = 0 \\quad\\Longleftrightarrow\\quad 11 x_2 + 6 x_3 = 0 \\quad\\Longleftrightarrow\\quad x_3 = -\\frac{11}{6}\\,x_2.\n$$\nFrom the first two equations we express $u$ in terms of $x_2$ and $x_3$:\n$$\nu_1 = -x_2,\\quad u_2 = -x_3.\n$$\nSubstituting $x_3 = -\\frac{11}{6} x_2$ gives\n$$\nu_2 = -\\left(-\\frac{11}{6} x_2\\right) = \\frac{11}{6}\\,x_2.\n$$\nThus any nonzero input direction $u$ that satisfies the invariant-zero constraints at $s_0=0$ is proportional to\n$$\nu = \\begin{bmatrix} -x_2 \\\\ \\tfrac{11}{6} x_2 \\end{bmatrix} = x_2 \\begin{bmatrix} -1 \\\\ \\tfrac{11}{6} \\end{bmatrix},\\quad x_2\\neq 0.\n$$\nTherefore the subspace of input zero directions is one-dimensional, spanned by $\\begin{bmatrix} -1 \\\\ \\tfrac{11}{6} \\end{bmatrix}$. The ratio $r=\\frac{u_2}{u_1}$ is invariant over this subspace (for any nonzero $x_2$):\n$$\nr = \\frac{u_2}{u_1} = \\frac{\\tfrac{11}{6} x_2}{-x_2} = -\\frac{11}{6}.\n$$\nThis completes the computation directly from the defining equations without recourse to any pre-derived formula. The exact rational value of the ratio is $-\\frac{11}{6}$.", "answer": "$$\\boxed{-\\frac{11}{6}}$$", "id": "2726520"}, {"introduction": "Perhaps the most profound insight into a system's zeros comes from studying its internal behavior when the output is actively held at zero. This practice guides you through the characterization of a system's *zero dynamics*. By deriving the specific input required to nullify the output, you will uncover the hidden internal trajectory that the state must follow, revealing the system modes that are rendered unobservable from the output under this condition. [@problem_id:2726480]", "problem": "Consider the linear time-invariant Multiple-Input Multiple-Output (MIMO) state-space system\n$$\n\\dot{x}(t)=A\\,x(t)+B\\,u(t),\\qquad y(t)=C\\,x(t)+D\\,u(t),\n$$\nwith square transfer matrix $G(s)$ and\n$$\nA=\\begin{bmatrix}\n0  1  0\\\\\n0  0  1\\\\\n-6  -11  -6\n\\end{bmatrix},\\quad\nB=\\begin{bmatrix}\n0  1\\\\\n1  0\\\\\n0  1\n\\end{bmatrix},\\quad\nC=\\begin{bmatrix}\n1  0  1\\\\\n0  1  0\n\\end{bmatrix},\\quad\nD=\\begin{bmatrix}\n0  0\\\\\n0  0\n\\end{bmatrix}.\n$$\nUsing only fundamental definitions of zero dynamics (that is, internal trajectories attainable under some input that render the output identically zero), construct an input $u(t)$ that renders $y(t)\\equiv 0$ for all $t\\ge 0$. Then compute the resulting internal trajectory $x(t)$ that evolves under this condition, thereby characterizing the zero dynamics for the initial condition\n$$\nx(0)=\\begin{bmatrix}1\\\\0\\\\-1\\end{bmatrix}.\n$$\nExpress your final result as a single row vector whose entries are the components $\\big(x_{1}(t),\\,x_{2}(t),\\,x_{3}(t),\\,u_{1}(t),\\,u_{2}(t)\\big)$, simplified to exact closed-form expressions in $t$. No rounding is required, and no physical units are needed.", "solution": "The problem requires the determination of the state trajectory $x(t)$ and the corresponding control input $u(t)$ that maintain the system output $y(t)$ at zero for all time $t \\ge 0$, starting from a specified initial condition $x(0)$. This is the fundamental definition of the system's zero dynamics.\n\nFirst, we validate the problem statement. The system is described by the linear time-invariant state-space equations:\n$$\n\\dot{x}(t) = A x(t) + B u(t)\n$$\n$$\ny(t) = C x(t) + D u(t)\n$$\nwith matrices given as:\n$$\nA=\\begin{bmatrix}\n0  1  0\\\\\n0  0  1\\\\\n-6  -11  -6\n\\end{bmatrix},\\quad\nB=\\begin{bmatrix}\n0  1\\\\\n1  0\\\\\n0  1\n\\end{bmatrix},\\quad\nC=\\begin{bmatrix}\n1  0  1\\\\\n0  1  0\n\\end{bmatrix},\\quad\nD=\\begin{bmatrix}\n0  0\\\\\n0  0\n\\end{bmatrix}.\n$$\nThe initial condition is $x(0) = \\begin{bmatrix} 1 \\\\ 0 \\\\ -1 \\end{bmatrix}$.\n\nThe problem is scientifically grounded within linear control theory and is well-posed. The condition for zero output is $y(t) \\equiv 0$. Since the direct feedthrough matrix $D$ is the zero matrix, this condition simplifies to:\n$$\ny(t) = C x(t) = 0 \\quad \\forall t \\ge 0.\n$$\nThis defines a subspace in which the state must reside. For a trajectory to start in this subspace, the initial condition $x(0)$ must satisfy $C x(0) = 0$. Let us verify this:\n$$\nC x(0) = \\begin{bmatrix} 1  0  1\\\\ 0  1  0 \\end{bmatrix} \\begin{bmatrix} 1 \\\\ 0 \\\\ -1 \\end{bmatrix} = \\begin{bmatrix} 1(1) + 0(0) + 1(-1) \\\\ 0(1) + 1(0) + 0(-1) \\end{bmatrix} = \\begin{bmatrix} 0 \\\\ 0 \\end{bmatrix}.\n$$\nThe initial condition lies on the zero-output subspace, so the problem is valid and a solution can be sought.\n\nTo ensure the state remains in this subspace, all time derivatives of the output must also be zero. We compute the first derivative:\n$$\n\\dot{y}(t) = \\frac{d}{dt}(C x(t)) = C \\dot{x}(t) = C (A x(t) + B u(t)) = 0.\n$$\nThis gives the equation for the required input $u(t)$:\n$$\nC B u(t) = -C A x(t).\n$$\nTo solve for $u(t)$, the matrix $CB$ must be invertible. Let us compute the matrices $CA$ and $CB$:\n$$\nCA = \\begin{bmatrix} 1  0  1\\\\ 0  1  0 \\end{bmatrix} \\begin{bmatrix} 0  1  0\\\\ 0  0  1\\\\ -6  -11  -6 \\end{bmatrix} = \\begin{bmatrix} -6  -10  -6 \\\\ 0  0  1 \\end{bmatrix}.\n$$\n$$\nCB = \\begin{bmatrix} 1  0  1\\\\ 0  1  0 \\end{bmatrix} \\begin{bmatrix} 0  1\\\\ 1  0\\\\ 0  1 \\end{bmatrix} = \\begin{bmatrix} 0  2 \\\\ 1  0 \\end{bmatrix}.\n$$\nThe determinant of $CB$ is $\\det(CB) = (0)(0) - (2)(1) = -2$, which is non-zero. Thus, $CB$ is invertible. The inverse is:\n$$\n(CB)^{-1} = \\frac{1}{-2} \\begin{bmatrix} 0  -2 \\\\ -1  0 \\end{bmatrix} = \\begin{bmatrix} 0  1 \\\\ \\frac{1}{2}  0 \\end{bmatrix}.\n$$\nWe can now express the input $u(t)$ in terms of the state $x(t)$:\n$$\nu(t) = -(CB)^{-1} C A x(t).\n$$\nSubstituting this into the state equation yields the dynamics restricted to the zero-output subspace, known as the zero dynamics:\n$$\n\\dot{x}(t) = A x(t) + B \\left( -(CB)^{-1} C A x(t) \\right) = \\left( A - B (CB)^{-1} C A \\right) x(t).\n$$\nLet $A_z = A - B(CB)^{-1}CA$ be the matrix governing the zero dynamics. We compute this matrix.\nFirst, $B(CB)^{-1}$:\n$$\nB(CB)^{-1} = \\begin{bmatrix} 0  1\\\\ 1  0\\\\ 0  1 \\end{bmatrix} \\begin{bmatrix} 0  1 \\\\ \\frac{1}{2}  0 \\end{bmatrix} = \\begin{bmatrix} \\frac{1}{2}  0 \\\\ 0  1 \\\\ \\frac{1}{2}  0 \\end{bmatrix}.\n$$\nThen, $B(CB)^{-1}CA$:\n$$\nB(CB)^{-1}CA = \\begin{bmatrix} \\frac{1}{2}  0 \\\\ 0  1 \\\\ \\frac{1}{2}  0 \\end{bmatrix} \\begin{bmatrix} -6  -10  -6 \\\\ 0  0  1 \\end{bmatrix} = \\begin{bmatrix} -3  -5  -3 \\\\ 0  0  1 \\\\ -3  -5  -3 \\end{bmatrix}.\n$$\nNow we find $A_z$:\n$$\nA_z = A - B(CB)^{-1}CA = \\begin{bmatrix} 0  1  0\\\\ 0  0  1\\\\ -6  -11  -6 \\end{bmatrix} - \\begin{bmatrix} -3  -5  -3 \\\\ 0  0  1 \\\\ -3  -5  -3 \\end{bmatrix} = \\begin{bmatrix} 3  6  3 \\\\ 0  0  0 \\\\ -3  -6  -3 \\end{bmatrix}.\n$$\nThe state trajectory $x(t)$ is the solution to $\\dot{x}(t) = A_z x(t)$ with $x(0) = \\begin{bmatrix} 1 \\\\ 0 \\\\ -1 \\end{bmatrix}$. The solution is given by $x(t) = \\exp(A_z t) x(0)$. To compute the matrix exponential, we find the eigenvalues of $A_z$ by solving $\\det(A_z - \\lambda I) = 0$:\n$$\n\\det\\begin{pmatrix} 3-\\lambda  6  3 \\\\ 0  -\\lambda  0 \\\\ -3  -6  -3-\\lambda \\end{pmatrix} = -\\lambda \\det\\begin{pmatrix} 3-\\lambda  3 \\\\ -3  -3-\\lambda \\end{pmatrix} = -\\lambda((3-\\lambda)(-3-\\lambda) - (3)(-3)) = -\\lambda(\\lambda^2 - 9 + 9) = -\\lambda^3.\n$$\nAll three eigenvalues are $\\lambda = 0$. This indicates that $A_z$ is a nilpotent matrix. Let's compute its powers:\n$$\nA_z^2 = \\begin{bmatrix} 3  6  3 \\\\ 0  0  0 \\\\ -3  -6  -3 \\end{bmatrix} \\begin{bmatrix} 3  6  3 \\\\ 0  0  0 \\\\ -3  -6  -3 \\end{bmatrix} = \\begin{bmatrix} 9-9  18-18  9-9 \\\\ 0  0  0 \\\\ -9+9  -18+18  -9+9 \\end{bmatrix} = \\begin{bmatrix} 0  0  0 \\\\ 0  0  0 \\\\ 0  0  0 \\end{bmatrix}.\n$$\nSince $A_z^2 = 0$, the series for the matrix exponential truncates:\n$$\n\\exp(A_z t) = I + A_z t + \\frac{(A_z t)^2}{2!} + \\dots = I + t A_z.\n$$\n$$\n\\exp(A_z t) = \\begin{bmatrix} 1  0  0 \\\\ 0  1  0 \\\\ 0  0  1 \\end{bmatrix} + t \\begin{bmatrix} 3  6  3 \\\\ 0  0  0 \\\\ -3  -6  -3 \\end{bmatrix} = \\begin{bmatrix} 1+3t  6t  3t \\\\ 0  1  0 \\\\ -3t  -6t  1-3t \\end{bmatrix}.\n$$\nNow we compute the state trajectory $x(t)$:\n$$\nx(t) = \\exp(A_z t) x(0) = \\begin{bmatrix} 1+3t  6t  3t \\\\ 0  1  0 \\\\ -3t  -6t  1-3t \\end{bmatrix} \\begin{bmatrix} 1 \\\\ 0 \\\\ -1 \\end{bmatrix} = \\begin{bmatrix} (1+3t)(1) + (3t)(-1) \\\\ 0 \\\\ (-3t)(1) + (1-3t)(-1) \\end{bmatrix} = \\begin{bmatrix} 1+3t-3t \\\\ 0 \\\\ -3t-1+3t \\end{bmatrix} = \\begin{bmatrix} 1 \\\\ 0 \\\\ -1 \\end{bmatrix}.\n$$\nThe state trajectory is constant, $x(t) = x(0)$. This is because $x(0)$ is an eigenvector of $A_z$ corresponding to the eigenvalue $\\lambda=0$, as $A_z x(0) = 0$.\n\nFinally, we find the input $u(t)$ that generates this trajectory:\n$$\nu(t) = -(CB)^{-1} C A x(t) = -(CB)^{-1} C A x(0).\n$$\nSince $x(t)$ is constant, $u(t)$ is also constant. We have already computed $CA$. We now compute $CAx(0)$:\n$$\nCAx(0) = \\begin{bmatrix} -6  -10  -6 \\\\ 0  0  1 \\end{bmatrix} \\begin{bmatrix} 1 \\\\ 0 \\\\ -1 \\end{bmatrix} = \\begin{bmatrix} -6(1) + (-6)(-1) \\\\ 1(-1) \\end{bmatrix} = \\begin{bmatrix} 0 \\\\ -1 \\end{bmatrix}.\n$$\nNow we compute $u(t)$:\n$$\nu(t) = u = - \\begin{bmatrix} 0  1 \\\\ \\frac{1}{2}  0 \\end{bmatrix} \\begin{bmatrix} 0 \\\\ -1 \\end{bmatrix} = - \\begin{bmatrix} -1 \\\\ 0 \\end{bmatrix} = \\begin{bmatrix} 1 \\\\ 0 \\end{bmatrix}.\n$$\nSo, the components of the input are $u_1(t) = 1$ and $u_2(t) = 0$.\n\nThe resulting state and input components are:\n$x_1(t) = 1$\n$x_2(t) = 0$\n$x_3(t) = -1$\n$u_1(t) = 1$\n$u_2(t) = 0$\n\nWe assemble these into the required final row vector $(x_1(t), x_2(t), x_3(t), u_1(t), u_2(t))$.", "answer": "$$\n\\boxed{\\begin{pmatrix} 1  0  -1  1  0 \\end{pmatrix}}\n$$", "id": "2726480"}]}