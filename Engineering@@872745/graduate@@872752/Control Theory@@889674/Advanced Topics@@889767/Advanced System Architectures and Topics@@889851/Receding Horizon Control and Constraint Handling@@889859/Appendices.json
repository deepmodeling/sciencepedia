{"hands_on_practices": [{"introduction": "The core of Receding Horizon Control for linear systems involves repeatedly solving an optimization problem. The first critical skill is translating the problem—defined by system dynamics, a cost function, and constraints—into a standard mathematical format that numerical solvers can process. For the common case of linear dynamics and quadratic costs, this format is a Quadratic Program (QP). This exercise [@problem_id:2736366] provides hands-on practice in this fundamental translation, guiding you through the algebraic steps to construct the Hessian matrix, linear cost vector, and constraint matrices that define the QP.", "problem": "Consider the discrete-time linear time-invariant system used in Model Predictive Control (MPC) also known as Receding Horizon Control (RHC), given by the state-update equation $x_{k+1}=A x_k + B u_k$, where $A=\\begin{bmatrix}1&1\\\\0&1\\end{bmatrix}$ and $B=\\begin{bmatrix}0\\\\1\\end{bmatrix}$, with state $x_k\\in\\mathbb{R}^2$ and input $u_k\\in\\mathbb{R}$. Let the stage cost be $x_k^{\\top} Q x_k + u_k^{\\top} R u_k$ with $Q=I_2$ and $R=1$, and the terminal cost be $x_N^{\\top} P x_N$ with $P=I_2$, where $I_2$ denotes the $2\\times 2$ identity matrix. The prediction horizon is $N=3$. The hard constraints are the input magnitude bound $|u_k|\\le 1$ and the state infinity-norm bound $\\lVert x_k\\rVert_{\\infty}\\le 5$ for all $k\\in\\{0,1,2\\}$. Assume the initial condition $x_0=\\begin{bmatrix}x_{01}\\\\x_{02}\\end{bmatrix}$ is given and satisfies the state bound at $k=0$. Use the standard stacked decision $U=\\begin{bmatrix}u_0&u_1&u_2\\end{bmatrix}^{\\top}$.\n\nStarting from the fundamental definitions of predicted states under an affine input sequence and the quadratic performance index, derive the explicit finite-horizon optimization in standard Quadratic Program (QP) form\n$$\n\\min_{U}\\ \\frac{1}{2} U^{\\top} H U + f(x_0)^{\\top} U + c(x_0)\\quad\\text{subject to}\\quad G U \\le h(x_0),\n$$\nwhere $H\\in\\mathbb{R}^{3\\times 3}$, $f(x_0)\\in\\mathbb{R}^{3}$, $c(x_0)\\in\\mathbb{R}$, $G\\in\\mathbb{R}^{m\\times 3}$, and $h(x_0)\\in\\mathbb{R}^{m}$ for an appropriate $m$. Your derivation must make clear how the predicted states $x_1$, $x_2$, and $x_3$ depend on $x_0$ and $U$, and how the state and input constraints are mapped to linear inequalities in $U$.\n\nAfter you have written the optimization problem in this standard QP form with explicit numeric matrices and vectors (expressing the dependence on $x_0$ where appropriate), compute the determinant of the Hessian matrix $H$. Provide the exact value of the determinant as your final answer. Do not round. The final answer must be a single real number with no units.", "solution": "We begin from the discrete-time linear dynamics $x_{k+1}=A x_k + B u_k$ with $A=\\begin{bmatrix}1&1\\\\0&1\\end{bmatrix}$ and $B=\\begin{bmatrix}0\\\\1\\end{bmatrix}$. The prediction horizon is $N=3$. The cost is the quadratic performance index\n$$\nJ=\\sum_{k=0}^{N-1}\\big(x_k^{\\top} Q x_k + u_k^{\\top} R u_k\\big) + x_N^{\\top} P x_N,\n$$\nwith $Q=I_2$, $R=1$, $P=I_2$. The constraints are $|u_k|\\le 1$ and $\\lVert x_k\\rVert_{\\infty}\\le 5$ for $k\\in\\{0,1,2\\}$.\n\nWe first construct the predicted states as affine functions of the decision vector $U=\\begin{bmatrix}u_0&u_1&u_2\\end{bmatrix}^{\\top}$ and the initial condition $x_0=\\begin{bmatrix}x_{01}\\\\x_{02}\\end{bmatrix}$. Using the powers of $A$, which for this $A$ satisfy $A^n=\\begin{bmatrix}1&n\\\\0&1\\end{bmatrix}$, and the propagated input effects $A^j B$, we obtain\n$$\nx_1 = A x_0 + B u_0,\\qquad\nx_2 = A^2 x_0 + A B\\, u_0 + B u_1,\\qquad\nx_3 = A^3 x_0 + A^2 B\\, u_0 + A B\\, u_1 + B u_2.\n$$\nWe compute the needed matrices:\n$$\nA^2=\\begin{bmatrix}1&2\\\\0&1\\end{bmatrix},\\quad A^3=\\begin{bmatrix}1&3\\\\0&1\\end{bmatrix},\\quad\nB=\\begin{bmatrix}0\\\\1\\end{bmatrix},\\quad A B=\\begin{bmatrix}1\\\\1\\end{bmatrix},\\quad A^2 B=\\begin{bmatrix}2\\\\1\\end{bmatrix}.\n$$\nHence,\n$$\nx_1 = \\begin{bmatrix}x_{01}+x_{02}\\\\ x_{02}\\end{bmatrix} + \\begin{bmatrix}0\\\\1\\end{bmatrix} u_0,\\quad\nx_2 = \\begin{bmatrix}x_{01}+2x_{02}\\\\ x_{02}\\end{bmatrix} + \\begin{bmatrix}1\\\\1\\end{bmatrix} u_0 + \\begin{bmatrix}0\\\\1\\end{bmatrix} u_1,\n$$\n$$\nx_3 = \\begin{bmatrix}x_{01}+3x_{02}\\\\ x_{02}\\end{bmatrix} + \\begin{bmatrix}2\\\\1\\end{bmatrix} u_0 + \\begin{bmatrix}1\\\\1\\end{bmatrix} u_1 + \\begin{bmatrix}0\\\\1\\end{bmatrix} u_2.\n$$\nIntroduce the affine decomposition $x_k = c_k + D_k U$ with $c_1=A x_0$, $c_2=A^2 x_0$, $c_3=A^3 x_0$, and\n$$\nD_1=\\begin{bmatrix}0&0&0\\\\ 1&0&0\\end{bmatrix},\\quad\nD_2=\\begin{bmatrix}1&0&0\\\\ 1&1&0\\end{bmatrix},\\quad\nD_3=\\begin{bmatrix}2&1&0\\\\ 1&1&1\\end{bmatrix}.\n$$\nThe objective can be written as\n$$\nJ(U) = x_0^{\\top} Q x_0 + \\sum_{k=1}^{3} \\big\\|c_k + D_k U\\big\\|_2^2 + \\sum_{k=0}^{2} u_k^2.\n$$\nExpanding the quadratic terms yields\n$$\nJ(U) = U^{\\top}\\!\\Big(I_3 + \\sum_{k=1}^{3} D_k^{\\top} D_k\\Big) U + 2 \\sum_{k=1}^{3} c_k^{\\top} D_k\\, U + \\Big(x_0^{\\top} Q x_0 + \\sum_{k=1}^{3} \\|c_k\\|_2^2\\Big),\n$$\nwhere $I_3$ is the $3\\times 3$ identity matrix. Therefore, in the standard Quadratic Program (QP) form\n$$\n\\min_{U}\\ \\frac{1}{2} U^{\\top} H U + f(x_0)^{\\top} U + c(x_0),\n$$\nthe Hessian is $H=2\\Big(I_3 + \\sum_{k=1}^{3} D_k^{\\top} D_k\\Big)$, the linear term is $f(x_0)=2\\sum_{k=1}^{3} D_k^{\\top} c_k$, and the constant term is $c(x_0)=x_0^{\\top} Q x_0 + \\sum_{k=1}^{3} \\|c_k\\|_2^2$.\n\nWe now compute the matrices $D_k^{\\top} D_k$:\n$$\nD_1^{\\top} D_1=\\begin{bmatrix}1&0&0\\\\ 0&0&0\\\\ 0&0&0\\end{bmatrix},\\quad\nD_2^{\\top} D_2=\\begin{bmatrix}2&1&0\\\\ 1&1&0\\\\ 0&0&0\\end{bmatrix},\\quad\nD_3^{\\top} D_3=\\begin{bmatrix}5&3&1\\\\ 3&2&1\\\\ 1&1&1\\end{bmatrix}.\n$$\nSumming and adding $I_3$ gives\n$$\nI_3 + \\sum_{k=1}^{3} D_k^{\\top} D_k\n= \\begin{bmatrix}1&0&0\\\\ 0&1&0\\\\ 0&0&1\\end{bmatrix}\n+ \\begin{bmatrix}1&0&0\\\\ 0&0&0\\\\ 0&0&0\\end{bmatrix}\n+ \\begin{bmatrix}2&1&0\\\\ 1&1&0\\\\ 0&0&0\\end{bmatrix}\n+ \\begin{bmatrix}5&3&1\\\\ 3&2&1\\\\ 1&1&1\\end{bmatrix}\n= \\begin{bmatrix}9&4&1\\\\ 4&4&1\\\\ 1&1&2\\end{bmatrix}.\n$$\nThus the Hessian is\n$$\nH=2\\begin{bmatrix}9&4&1\\\\ 4&4&1\\\\ 1&1&2\\end{bmatrix}\n= \\begin{bmatrix}18&8&2\\\\ 8&8&2\\\\ 2&2&4\\end{bmatrix}.\n$$\nNext, compute the linear term $f(x_0)=2\\sum_{k=1}^{3} D_k^{\\top} c_k$, with $c_1=A x_0=\\begin{bmatrix}x_{01}+x_{02}\\\\ x_{02}\\end{bmatrix}$, $c_2=A^2 x_0=\\begin{bmatrix}x_{01}+2x_{02}\\\\ x_{02}\\end{bmatrix}$, $c_3=A^3 x_0=\\begin{bmatrix}x_{01}+3x_{02}\\\\ x_{02}\\end{bmatrix}$. Using $D_1^{\\top}=\\begin{bmatrix}0&1\\\\ 0&0\\\\ 0&0\\end{bmatrix}$, $D_2^{\\top}=\\begin{bmatrix}1&1\\\\ 0&1\\\\ 0&0\\end{bmatrix}$, $D_3^{\\top}=\\begin{bmatrix}2&1\\\\ 1&1\\\\ 0&1\\end{bmatrix}$, we obtain\n$$\nD_1^{\\top} c_1=\\begin{bmatrix}x_{02}\\\\ 0\\\\ 0\\end{bmatrix},\\quad\nD_2^{\\top} c_2=\\begin{bmatrix}x_{01}+3x_{02}\\\\ x_{02}\\\\ 0\\end{bmatrix},\\quad\nD_3^{\\top} c_3=\\begin{bmatrix}2x_{01}+7x_{02}\\\\ x_{01}+4x_{02}\\\\ x_{02}\\end{bmatrix},\n$$\nso that\n$$\n\\sum_{k=1}^{3} D_k^{\\top} c_k=\\begin{bmatrix}3x_{01}+11x_{02}\\\\ x_{01}+5x_{02}\\\\ x_{02}\\end{bmatrix},\\qquad\nf(x_0)=2\\begin{bmatrix}3x_{01}+11x_{02}\\\\ x_{01}+5x_{02}\\\\ x_{02}\\end{bmatrix}=\\begin{bmatrix}6x_{01}+22x_{02}\\\\ 2x_{01}+10x_{02}\\\\ 2x_{02}\\end{bmatrix}.\n$$\nThe constant term $c(x_0)$ collects all parts independent of $U$:\n$$\nc(x_0)=x_0^{\\top} x_0 + \\|A x_0\\|_2^2 + \\|A^2 x_0\\|_2^2 + \\|A^3 x_0\\|_2^2\n= \\sum_{k=0}^{3}\\big((x_{01}+k x_{02})^2 + x_{02}^2\\big).\n$$\n\nWe now express the constraints $|u_k|\\le 1$ and $\\lVert x_k\\rVert_{\\infty}\\le 5$ for $k\\in\\{0,1,2\\}$ as linear inequalities $G U\\le h(x_0)$. The input constraints yield\n$$\n\\begin{bmatrix}\n1&0&0\\\\ -1&0&0\\\\ 0&1&0\\\\ 0&-1&0\\\\ 0&0&1\\\\ 0&0&-1\n\\end{bmatrix}\n\\begin{bmatrix}u_0\\\\ u_1\\\\ u_2\\end{bmatrix}\n\\le\n\\begin{bmatrix}1\\\\ 1\\\\ 1\\\\ 1\\\\ 1\\\\ 1\\end{bmatrix}.\n$$\nFor the state constraints at $k=0$, $\\lVert x_0\\rVert_{\\infty}\\le 5$ is a feasibility condition on $x_0$ and can be expressed as constant inequalities with zero rows in $G$:\n$$\n\\begin{bmatrix}\n0&0&0\\\\ 0&0&0\\\\ 0&0&0\\\\ 0&0&0\n\\end{bmatrix}\nU \\le\n\\begin{bmatrix}\n5 - x_{01}\\\\ 5 + x_{01}\\\\ 5 - x_{02}\\\\ 5 + x_{02}\n\\end{bmatrix}.\n$$\nFor $k=1$, we have $x_1=\\begin{bmatrix}x_{01}+x_{02}\\\\ x_{02}\\end{bmatrix}+\\begin{bmatrix}0\\\\1\\end{bmatrix} u_0$, hence\n$$\n\\begin{aligned}\n&-5 \\le x_{01}+x_{02} \\le 5 \\quad\\Rightarrow\\quad \\begin{bmatrix}0&0&0\\\\ 0&0&0\\end{bmatrix} U \\le \\begin{bmatrix}5-(x_{01}+x_{02})\\\\ 5+(x_{01}+x_{02})\\end{bmatrix},\\\\\n&-5 \\le x_{02}+u_0 \\le 5 \\quad\\Rightarrow\\quad \\begin{bmatrix}1&0&0\\\\ -1&0&0\\end{bmatrix} U \\le \\begin{bmatrix}5 - x_{02}\\\\ 5 + x_{02}\\end{bmatrix}.\n\\end{aligned}\n$$\nFor $k=2$, we have $x_2=\\begin{bmatrix}x_{01}+2x_{02}\\\\ x_{02}\\end{bmatrix}+\\begin{bmatrix}1\\\\1\\end{bmatrix} u_0 + \\begin{bmatrix}0\\\\1\\end{bmatrix} u_1$, hence\n$$\n\\begin{aligned}\n&-5 \\le x_{01}+2x_{02}+u_0 \\le 5 \\ \\Rightarrow\\\n\\begin{bmatrix}1&0&0\\\\ -1&0&0\\end{bmatrix} U \\le \\begin{bmatrix}5 - x_{01} - 2x_{02}\\\\ 5 + x_{01} + 2x_{02}\\end{bmatrix},\\\\\n&-5 \\le x_{02}+u_0+u_1 \\le 5 \\ \\Rightarrow\\\n\\begin{bmatrix}1&1&0\\\\ -1&-1&0\\end{bmatrix} U \\le \\begin{bmatrix}5 - x_{02}\\\\ 5 + x_{02}\\end{bmatrix}.\n\\end{aligned}\n$$\nStacking all the inequalities produces $G\\in\\mathbb{R}^{18\\times 3}$ and $h(x_0)\\in\\mathbb{R}^{18}$:\n$$\nG=\n\\begin{bmatrix}\n1&0&0\\\\ -1&0&0\\\\ 0&1&0\\\\ 0&-1&0\\\\ 0&0&1\\\\ 0&0&-1\\\\\n0&0&0\\\\ 0&0&0\\\\ 0&0&0\\\\ 0&0&0\\\\\n0&0&0\\\\ 0&0&0\\\\ 1&0&0\\\\ -1&0&0\\\\\n1&0&0\\\\ -1&0&0\\\\ 1&1&0\\\\ -1&-1&0\n\\end{bmatrix},\\quad\nh(x_0)=\n\\begin{bmatrix}\n1\\\\ 1\\\\ 1\\\\ 1\\\\ 1\\\\ 1\\\\\n5 - x_{01}\\\\ 5 + x_{01}\\\\ 5 - x_{02}\\\\ 5 + x_{02}\\\\\n5 - (x_{01}+x_{02})\\\\ 5 + (x_{01}+x_{02})\\\\ 5 - x_{02}\\\\ 5 + x_{02}\\\\\n5 - x_{01} - 2x_{02}\\\\ 5 + x_{01} + 2x_{02}\\\\ 5 - x_{02}\\\\ 5 + x_{02}\n\\end{bmatrix}.\n$$\nThis yields the requested explicit QP form with decision $U$.\n\nFinally, we compute the determinant of the Hessian $H$. Recall\n$$\nH=\\begin{bmatrix}18&8&2\\\\ 8&8&2\\\\ 2&2&4\\end{bmatrix}\n= 2 \\begin{bmatrix}9&4&1\\\\ 4&4&1\\\\ 1&1&2\\end{bmatrix}.\n$$\nLet $M=\\begin{bmatrix}9&4&1\\\\ 4&4&1\\\\ 1&1&2\\end{bmatrix}$. Then $\\det(H)=2^3 \\det(M)=8\\,\\det(M)$. Compute $\\det(M)$ by cofactor expansion along the first row:\n$$\n\\det(M)=9\\begin{vmatrix}4&1\\\\ 1&2\\end{vmatrix} - 4\\begin{vmatrix}4&1\\\\ 1&2\\end{vmatrix} + 1\\begin{vmatrix}4&4\\\\ 1&1\\end{vmatrix}\n= 9(8-1) - 4(8-1) + 1(4-4) = 9\\cdot 7 - 4\\cdot 7 + 0 = 35.\n$$\nTherefore,\n$$\n\\det(H)=8\\times 35 = 280.\n$$\nThis is an exact integer, so no rounding is needed.", "answer": "$$\\boxed{280}$$", "id": "2736366"}, {"introduction": "A key challenge in RHC is ensuring long-term stability and guaranteeing that the optimization problem remains feasible at every time step. This is achieved by incorporating a well-designed terminal constraint set, $\\mathcal{X}_{f}$, and an associated terminal cost. This practice [@problem_id:2736381] delves into the design of such a terminal set from first principles, connecting the theoretical concept of a predecessor set, $\\mathrm{Pre}(\\mathcal{S})$, to the concrete task of ensuring positive invariance and constraint satisfaction under a simple, local feedback law.", "problem": "Consider the discrete-time linear system $x_{k+1} = a x_k + b u_k$ with $a = 1.3$ and $b = 0.7$. The state is constrained to the compact set $\\mathcal{X} = \\{ x \\in \\mathbb{R} : |x| \\leq x_{\\max} \\}$ with $x_{\\max} = 0.6$, and the control input is constrained to the compact set $\\mathcal{U} = \\{ u \\in \\mathbb{R} : |u| \\leq u_{\\max} \\}$ with $u_{\\max} = 0.9$. Define the one-step predecessor operator of a set $\\mathcal{S} \\subset \\mathbb{R}$ by $\\mathrm{Pre}(\\mathcal{S}) = \\{ x \\in \\mathbb{R} : \\exists u \\in \\mathcal{U} \\text{ such that } a x + b u \\in \\mathcal{S} \\}$. Let $\\mathcal{S}_{\\alpha} = \\{ x \\in \\mathbb{R} : |x| \\leq \\alpha \\}$ denote a symmetric interval with radius $\\alpha \\geq 0$.\n\n1. Starting from the definition of $\\mathrm{Pre}(\\mathcal{S})$ and the given constraints, derive an explicit expression of $\\mathrm{Pre}(\\mathcal{S}_{\\alpha})$ in terms of $\\alpha$, $a$, $b$, and $u_{\\max}$.\n\n2. For Model Predictive Control (MPC), one common terminal set construction is to select a linear local control law $u = K x$ and enforce positive invariance of the terminal set under this law while respecting the input and state constraints. Consider the stabilizing feedback $K = -2$. Using the predecessor concept specialized to the closed-loop map $x^{+} = (a + b K) x$, derive conditions on $\\alpha$ such that the set $\\mathcal{X}_{f} = \\{ x \\in \\mathbb{R} : |x| \\leq \\alpha \\}$ satisfies:\n   - closed-loop positive invariance: for all $x \\in \\mathcal{X}_{f}$, the next state satisfies $(a + b K) x \\in \\mathcal{X}_{f}$,\n   - input admissibility: for all $x \\in \\mathcal{X}_{f}$, the input satisfies $K x \\in \\mathcal{U}$,\n   - state admissibility: $\\mathcal{X}_{f} \\subseteq \\mathcal{X}$.\n\n3. Compute the largest $\\alpha$ that satisfies all these conditions. Round your final numerical answer for $\\alpha$ to four significant figures. Do not include units.", "solution": "**Part 1: Derivation of the predecessor set $\\mathrm{Pre}(\\mathcal{S}_{\\alpha})$**\n\nThe system dynamics are given by $x_{k+1} = a x_k + b u_k$. The state $x_k$ and input $u_k$ are constrained by $|x_k| \\leq x_{\\max}$ and $|u_k| \\leq u_{\\max}$, respectively. The set $\\mathcal{S}_{\\alpha}$ is defined as $\\mathcal{S}_{\\alpha} = \\{ x \\in \\mathbb{R} : |x| \\leq \\alpha \\}$ for some $\\alpha \\geq 0$.\n\nThe one-step predecessor set, $\\mathrm{Pre}(\\mathcal{S}_{\\alpha})$, is the set of all states $x$ from which the state can be steered into $\\mathcal{S}_{\\alpha}$ in one step by some admissible control input $u \\in \\mathcal{U} = \\{ u \\in \\mathbb{R} : |u| \\leq u_{\\max} \\}$.\nFormally, a state $x$ belongs to $\\mathrm{Pre}(\\mathcal{S}_{\\alpha})$ if there exists a $u \\in \\mathcal{U}$ such that $a x + b u \\in \\mathcal{S}_{\\alpha}$. This can be expressed as:\n$$ x \\in \\mathrm{Pre}(\\mathcal{S}_{\\alpha}) \\iff \\exists u \\in \\mathbb{R} \\text{ such that } |u| \\leq u_{\\max} \\text{ and } |ax+bu| \\leq \\alpha $$\nThe condition $|ax+bu| \\leq \\alpha$ is equivalent to the interval membership $ax+bu \\in [-\\alpha, \\alpha]$.\nSince $b=0.7 \\neq 0$, we can express the range of required inputs $u$ as:\n$$ \\frac{-\\alpha-ax}{b} \\leq u \\leq \\frac{\\alpha-ax}{b} $$\nFor such a $u$ to exist within the admissible set $\\mathcal{U} = [-u_{\\max}, u_{\\max}]$, the interval $\\left[ \\frac{-\\alpha-ax}{b}, \\frac{\\alpha-ax}{b} \\right]$ must have a non-empty intersection with the interval $[-u_{\\max}, u_{\\max}]$.\nThe intersection of two closed intervals $[c_{1}, d_{1}]$ and $[c_{2}, d_{2}]$ is non-empty if and only if $c_{1} \\leq d_{2}$ and $c_{2} \\leq d_{1}$.\nApplying this condition with $b=0.7 > 0$, we have:\n1. $\\frac{-\\alpha-ax}{b} \\leq u_{\\max} \\implies -\\alpha-ax \\leq b u_{\\max} \\implies -ax \\leq \\alpha+b u_{\\max} \\implies ax \\geq -(\\alpha+b u_{\\max})$\n2. $-u_{\\max} \\leq \\frac{\\alpha-ax}{b} \\implies -b u_{\\max} \\leq \\alpha-ax \\implies ax \\leq \\alpha+b u_{\\max}$\nThese two inequalities can be combined into a single expression:\n$$ |ax| \\leq \\alpha+b u_{\\max} $$\nSince $a=1.3 > 0$, we can write $|a||x| = a|x|$, thus:\n$$ |x| \\leq \\frac{\\alpha+b u_{\\max}}{a} $$\nTherefore, the explicit expression for the predecessor set is:\n$$ \\mathrm{Pre}(\\mathcal{S}_{\\alpha}) = \\left\\{ x \\in \\mathbb{R} : |x| \\leq \\frac{\\alpha + b u_{\\max}}{a} \\right\\} $$\n\n**Part 2: Conditions on $\\alpha$ for the terminal set $\\mathcal{X}_{f}$**\n\nThe terminal set is defined as $\\mathcal{X}_{f} = \\{x \\in \\mathbb{R} : |x| \\leq \\alpha\\}$. The local control law is $u = Kx$ with $K = -2$. The conditions for $\\mathcal{X}_f$ to be a valid terminal set are analyzed below.\n\nCondition 1: Closed-loop positive invariance.\nThe set $\\mathcal{X}_{f}$ is positively invariant under the closed-loop dynamics $x_{k+1} = (a+bK)x_k$ if for any $x \\in \\mathcal{X}_{f}$, the subsequent state $x_{k+1}$ is also in $\\mathcal{X}_{f}$. This means that if $|x| \\leq \\alpha$, then $|(a+bK)x| \\leq \\alpha$.\nThis inequality can be written as $|a+bK| \\cdot |x| \\leq \\alpha$. This must hold for all $|x| \\leq \\alpha$. The most restrictive case is when $|x|$ reaches its maximum value, $|x|=\\alpha$. Substituting this into the inequality gives:\n$$ |a+bK|\\alpha \\leq \\alpha $$\nFor $\\alpha > 0$, we can divide by $\\alpha$ to obtain the standard stability condition $|a+bK| \\leq 1$. If $\\alpha=0$, the inequality $0 \\leq 0$ is trivially true.\nWe compute the value of the closed-loop pole $a_{cl} = a+bK$ using the given parameters $a=1.3$, $b=0.7$, and $K=-2$:\n$$ a_{cl} = 1.3 + (0.7)(-2) = 1.3 - 1.4 = -0.1 $$\nThe condition becomes $|-0.1| \\leq 1$, which is $0.1 \\leq 1$. This is true. Therefore, the positive invariance condition holds for all $\\alpha \\geq 0$.\n\nCondition 2: Input admissibility.\nFor any state $x \\in \\mathcal{X}_{f}$, the control input $u = Kx$ must be admissible, i.e., $u \\in \\mathcal{U}$. This translates to the condition $|Kx| \\leq u_{\\max}$ for all $x$ such that $|x| \\leq \\alpha$.\nThis is equivalent to $|K| \\cdot |x| \\leq u_{\\max}$. This must hold for all $|x| \\leq \\alpha$, so we must check the worst case, which is $|x|=\\alpha$. The condition is:\n$$ |K|\\alpha \\leq u_{\\max} $$\nSubstituting the values $K=-2$ and $u_{\\max}=0.9$:\n$$ |-2|\\alpha \\leq 0.9 \\implies 2\\alpha \\leq 0.9 $$\nThis gives the constraint on $\\alpha$:\n$$ \\alpha \\leq \\frac{0.9}{2} = 0.45 $$\n\nCondition 3: State admissibility.\nThe terminal set $\\mathcal{X}_{f}$ must be a subset of the state constraint set $\\mathcal{X}$. That is, $\\mathcal{X}_{f} \\subseteq \\mathcal{X}$.\nGiven $\\mathcal{X}_{f} = \\{ x \\in \\mathbb{R} : |x| \\leq \\alpha \\}$ and $\\mathcal{X} = \\{ x \\in \\mathbb{R} : |x| \\leq x_{\\max} \\}$, the subset condition $\\mathcal{X}_{f} \\subseteq \\mathcal{X}$ is satisfied if and only if $\\alpha \\leq x_{\\max}$.\nSubstituting the value $x_{\\max}=0.6$:\n$$ \\alpha \\leq 0.6 $$\n\n**Part 3: Computation of the largest $\\alpha$**\n\nTo find the largest possible value of $\\alpha$ for which $\\mathcal{X}_{f}$ is a valid terminal set, we must find the largest $\\alpha$ that satisfies all three conditions simultaneously. The derived conditions are:\n1. $\\alpha \\geq 0$\n2. $\\alpha \\leq 0.45$\n3. $\\alpha \\leq 0.6$\nCombining these yields $0 \\leq \\alpha \\leq \\min(0.45, 0.6)$. Thus, we have:\n$$ 0 \\leq \\alpha \\leq 0.45 $$\nThe largest value of $\\alpha$ satisfying this condition is the upper bound of the interval.\n$$ \\alpha_{\\max} = 0.45 $$\nThe problem requires the answer to be given to four significant figures. Therefore, the result is $0.4500$.", "answer": "$$\n\\boxed{0.4500}\n$$", "id": "2736381"}, {"introduction": "Theory and pen-and-paper design are essential, but the ultimate validation of a control strategy comes from its implementation and performance. This final practice [@problem_id:2736384] serves as a capstone exercise, integrating the preceding concepts into a complete numerical simulation. You will implement a full RHC loop—from designing the terminal controller and set to repeatedly solving the constrained optimization problem—to verify recursive feasibility, a non-negotiable property for any real-world MPC application.", "problem": "Consider the discrete-time, linear time-invariant system with state update equation $x_{k+1} = A x_k + B u_k$, where $x_k \\in \\mathbb{R}^2$ and $u_k \\in \\mathbb{R}$. The matrices are given by\n$$\nA = \\begin{bmatrix} 1 & 0.2 \\\\ 0 & 1 \\end{bmatrix}, \\quad B = \\begin{bmatrix} 0.02 \\\\ 0.2 \\end{bmatrix}.\n$$\nState and input constraints are componentwise box constraints\n$$\n|x_{1,k}| \\le 4,\\quad |x_{2,k}| \\le 4,\\quad |u_k| \\le 2,\n$$\nfor all time indices $k \\in \\mathbb{N}$. Define a quadratic stage cost and terminal cost using symmetric positive-definite matrices\n$$\nQ = \\begin{bmatrix} 1 & 0 \\\\ 0 & 0.1 \\end{bmatrix},\\quad R = \\begin{bmatrix} 0.05 \\end{bmatrix}.\n$$\nLet $P \\succ 0$ be the stabilizing solution of the discrete-time algebraic Riccati equation associated with $(A,B,Q,R)$, and let $K \\in \\mathbb{R}^{1 \\times 2}$ denote the corresponding linear quadratic regulator gain. The terminal set is chosen as the ellipsoid\n$$\n\\mathcal{X}_f := \\{ x \\in \\mathbb{R}^2 \\mid x^\\top P x \\le \\alpha \\},\n$$\nwith scalar $\\alpha > 0$ designed so that $\\mathcal{X}_f$ is contained within the above box constraints and also respects the input bound under the terminal controller $u = K x$.\n\nAt each time step, define a finite-horizon, constrained model predictive control problem with horizon length $N$:\n- Decision variable sequence $u_0, u_1, \\dots, u_{N-1}$,\n- Predicted states $x_0$ (given), $x_{k+1} = A x_k + B u_k$ for $k = 0,\\dots,N-1$,\n- Objective function\n$$\nJ = \\sum_{k=0}^{N-1} \\left( x_k^\\top Q x_k + u_k^\\top R u_k \\right) + x_N^\\top P x_N,\n$$\n- Subject to the box constraints on $x_k$ and $u_k$ for $k = 0,\\dots,N-1$ and the terminal constraint $x_N \\in \\mathcal{X}_f$.\n\nYou are to numerically verify recursive feasibility of the resulting receding horizon controller by simulating the closed-loop from multiple initial conditions in the feasible set as follows:\n- At each time step, solve the above optimization problem,\n- Apply only the first control input to the system,\n- Shift forward one step and repeat, for a fixed closed-loop simulation horizon of $T_{\\text{cl}}$ steps,\n- Declare the closed-loop run recursively feasible if the optimization problem is feasible at every time step and all constraints are satisfied by the applied inputs and resulting states.\n\nUse the following parameters:\n- Horizon length $N = 20$,\n- Closed-loop simulation length $T_{\\text{cl}} = 20$,\n- Terminal cost matrix $P$ as the stabilizing discrete-time algebraic Riccati solution for $(A,B,Q,R)$,\n- Terminal set $\\mathcal{X}_f = \\{ x \\mid x^\\top P x \\le \\alpha \\}$, with $\\alpha$ chosen such that $\\mathcal{X}_f$ is contained in the above state box constraints and, for all $x \\in \\mathcal{X}_f$, the terminal control $u = K x$ satisfies $|u| \\le 2$.\n\nYour program must implement the above receding horizon control law and report, for each initial condition listed below, whether the closed-loop run is recursively feasible across all $T_{\\text{cl}}$ steps. The initial conditions are:\n- $x_0^{(1)} = \\begin{bmatrix} 0.05 \\\\ -0.05 \\end{bmatrix}$,\n- $x_0^{(2)} = \\begin{bmatrix} 1.0 \\\\ 0.5 \\end{bmatrix}$,\n- $x_0^{(3)} = \\begin{bmatrix} -1.5 \\\\ 1.0 \\end{bmatrix}$,\n- $x_0^{(4)} = \\begin{bmatrix} 2.5 \\\\ -1.0 \\end{bmatrix}$,\n- $x_0^{(5)} = \\begin{bmatrix} -2.0 \\\\ 2.0 \\end{bmatrix}$.\n\nFundamental base and constraints to use:\n- Use the definition of receding horizon control: at each step solve a finite-horizon constrained optimization with the system model and constraints, then apply the first control action and repeat.\n- Use linear time-invariant dynamics $x_{k+1} = A x_k + B u_k$ and quadratic costs with $(Q \\succeq 0, R \\succ 0)$.\n- Enforce state and input constraints at each prediction step and a terminal state constraint $x_N \\in \\mathcal{X}_f$.\n- The terminal pair $(P,\\mathcal{X}_f)$ should be designed using standard linear quadratic regulator techniques so that $\\mathcal{X}_f$ is a positively invariant set under the terminal controller $u=Kx$ and is contained in the constraints.\n\nTest suite and required output:\n- Use the above $5$ initial conditions and the parameter values specified.\n- For each initial condition, return a boolean indicating whether recursive feasibility held for all $T_{\\text{cl}}$ steps.\n- Your program should produce a single line of output containing the results as a comma-separated list of booleans enclosed in square brackets (e.g., \"[True,False,True,True,False]\").\n\nNo physical units are involved, so none are required. All angles, if any are used, must be in radians, but no angles are used in this problem. The final output is the single line described above; do not print any additional text.", "solution": "The core of the methodology is receding horizon control (RHC), where at each time step $k$, a finite-horizon optimal control problem is solved using the current state $x_k$ as the initial state. The first element of the resulting optimal control sequence is applied to the system, and the process is repeated at the next time step. The recursive feasibility of this scheme, which is central to its practical application, is guaranteed by the proper design of a terminal cost and a terminal constraint set.\n\nThe solution is structured into three parts: first, the design of the terminal components; second, the formulation of the finite-horizon optimization problem; and third, the closed-loop simulation to verify recursive feasibility.\n\n**Part 1: Terminal Controller and Set Design**\n\nThe stability and recursive feasibility of the MPC scheme are ensured by a terminal cost matrix $P$ and a terminal constraint set $\\mathcal{X}_f$. These are derived from Linear Quadratic Regulator (LQR) theory for the given system.\n\n1.  **Terminal Cost Matrix $P$**: The matrix $P$ is the unique, symmetric, positive-definite solution to the discrete-time algebraic Riccati equation (DARE):\n    $$\n    A^\\top P A - P - (A^\\top P B)(R + B^\\top P B)^{-1}(B^\\top P A) + Q = 0\n    $$\n    This matrix $P$ serves as the terminal cost weighting matrix, defining a Lyapunov function for the local terminal controller.\n\n2.  **Terminal Controller Gain $K$**: The associated stabilizing LQR feedback gain is given by:\n    $$\n    K = (R + B^\\top P B)^{-1}B^\\top P A\n    $$\n    The terminal control law is $u_k = Kx_k$. For any state $x$ within the terminal set $\\mathcal{X}_f$, the evolution under this controller, $x_{k+1} = (A+BK)x_k$, is guaranteed to drive the state to the origin while respecting constraints. The solution $P$ of the DARE ensures that $V(x) = x^\\top P x$ is a Lyapunov function for the closed-loop system $x_{k+1} = (A+BK)x_k$.\n\n3.  **Terminal Set $\\mathcal{X}_f$**: The terminal set is defined as a level set of the Lyapunov function:\n    $$\n    \\mathcal{X}_f = \\{ x \\in \\mathbb{R}^2 \\mid x^\\top P x \\le \\alpha \\}\n    $$\n    The parameter $\\alpha > 0$ must be chosen to ensure that for any state $x \\in \\mathcal{X}_f$, both the state and the corresponding control input $u = Kx$ satisfy the specified constraints. That is, $\\mathcal{X}_f$ must be a subset of the polytopic constraint set $\\mathcal{X} \\cap \\mathcal{U}_K$, where $\\mathcal{X} = \\{x \\mid |x_1| \\le 4, |x_2| \\le 4\\}$ and $\\mathcal{U}_K = \\{x \\mid |Kx| \\le 2\\}$.\n    \n    The condition that the ellipsoid $x^\\top P x \\le \\alpha$ is contained within a half-space $\\{x \\mid c^\\top x \\le d\\}$ (with $d>0$) is equivalent to $\\alpha \\le d^2 / (c^\\top P^{-1} c)$. We apply this to all facets of the constraint polyhedra:\n    -   State constraint $|x_1| \\le 4$: This gives two inequalities, $x_1 \\le 4$ ($c=[1, 0]^\\top$) and $-x_1 \\le 4$ ($c=[-1, 0]^\\top$). This requires $\\alpha \\le 4^2 / ([1,0]P^{-1}[1,0]^\\top) = 16 / (P^{-1})_{11}$.\n    -   State constraint $|x_2| \\le 4$: Similarly, this requires $\\alpha \\le 16 / (P^{-1})_{22}$.\n    -   Input constraint $|Kx| \\le 2$: With $K$ being a $1 \\times 2$ row vector, this requires $\\alpha \\le 2^2 / (K P^{-1} K^\\top)$.\n\n    To satisfy all constraints simultaneously, $\\alpha$ must be chosen as the minimum of these upper bounds:\n    $$\n    \\alpha = \\min \\left( \\frac{16}{(P^{-1})_{11}}, \\frac{16}{(P^{-1})_{22}}, \\frac{4}{K P^{-1} K^\\top} \\right)\n    $$\n    This choice of $\\alpha$ guarantees that any state trajectory entering $\\mathcal{X}_f$ can be kept within the state and input constraints for all future time by applying the terminal controller $u=Kx$.\n\n**Part 2: Finite-Horizon Optimal Control Problem**\n\nAt each time step of the RHC procedure, we solve the following optimization problem for the current state $x_{curr}$:\n\nFind the control sequence $U = \\{u_0, \\dots, u_{N-1}\\}$ that minimizes the cost function:\n$$\nJ(U, x_{curr}) = \\sum_{k=0}^{N-1} \\left( x_k^\\top Q x_k + u_k^\\top R u_k \\right) + x_N^\\top P x_N\n$$\nsubject to:\n1.  System dynamics: $x_0 = x_{curr}$, $x_{k+1} = A x_k + B u_k$ for $k=0, \\dots, N-1$.\n2.  Input constraints: $|u_k| \\le 2$ for $k=0, \\dots, N-1$.\n3.  State path constraints: $|x_{i,k}| \\le 4$ for component $i \\in \\{1,2\\}$ and time $k=1, \\dots, N-1$.\n4.  Terminal constraint: $x_N \\in \\mathcal{X}_f$, which is $x_N^\\top P x_N \\le \\alpha$.\n\nThis problem is a convex Quadratically Constrained Quadratic Program (QCQP), as the objective is quadratic, dynamics are linear, and constraints are linear or convex quadratic. It can be solved using standard numerical optimization techniques, such as the Sequential Least Squares Programming (SLSQP) algorithm.\n\n**Part 3: Recursive Feasibility Verification**\n\nWe numerically verify recursive feasibility by simulating the closed-loop system for $T_{\\text{cl}}=20$ steps for each of the given initial conditions. The procedure is as follows:\n\n1.  Initialize the state $x_{current}$ with the given initial condition $x_0^{(i)}$.\n2.  For each time step $t = 0, \\dots, T_{\\text{cl}}-1$:\n    a.  Solve the finite-horizon optimal control problem defined in Part 2, with $x_{curr} = x_{current}$.\n    b.  If the optimizer fails to find a feasible solution (indicated by a failure flag from the solver), the simulation is declared not recursively feasible, and the procedure for this initial condition terminates.\n    c.  If a solution $U^* = \\{u_0^*, \\dots, u_{N-1}^*\\}$ is found, apply the first control input $u_{apply} = u_0^*$ to the system.\n    d.  Update the state: $x_{current} \\leftarrow A x_{current} + B u_{apply}$.\n3.  If the simulation completes all $T_{\\text{cl}}$ steps without any solver failure, the run is declared recursively feasible.\n\nThe provided Python code implements this algorithm precisely. It first computes $P$, $K$, and $\\alpha$. Then, for each initial state, it enters the simulation loop, calling a numerical optimizer at each step to solve the constrained MPC problem. The boolean feasibility result is recorded for each case.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy import linalg\nfrom scipy.optimize import minimize\n\ndef solve():\n    \"\"\"\n    Implements and simulates a receding horizon controller to verify recursive feasibility\n    for a given discrete-time LTI system and a set of initial conditions.\n    \"\"\"\n    # System and MPC parameters\n    A = np.array([[1, 0.2], [0, 1]])\n    B = np.array([[0.02], [0.2]])\n    Q = np.array([[1, 0], [0, 0.1]])\n    R = np.array([[0.05]])\n    N = 20\n    T_cl = 20\n    x_max_abs = 4.0\n    u_max_abs = 2.0\n\n    # Test cases: initial conditions\n    test_cases = [\n        np.array([0.05, -0.05]),\n        np.array([1.0, 0.5]),\n        np.array([-1.5, 1.0]),\n        np.array([2.5, -1.0]),\n        np.array([-2.0, 2.0])\n    ]\n\n    # --- Part 1: Terminal Controller and Set Design ---\n\n    # Solve the Discrete-time Algebraic Riccati Equation (DARE) for P\n    P = linalg.solve_discrete_are(A, B, Q, R)\n\n    # Compute the LQR gain K\n    K = np.linalg.inv(R + B.T @ P @ B) @ B.T @ P @ A\n\n    # Compute alpha for the terminal set X_f = {x | x'Px <= alpha}\n    def calculate_alpha(P_mat, K_mat, x_max, u_max):\n        P_inv = np.linalg.inv(P_mat)\n        \n        # From state constraints: |x_i| <= x_max\n        # alpha <= x_max^2 / (e_i' * P_inv * e_i)\n        alpha_x1 = x_max**2 / P_inv[0, 0]\n        alpha_x2 = x_max**2 / P_inv[1, 1]\n\n        # From input constraint: |Kx| <= u_max\n        # alpha <= u_max^2 / (K * P_inv * K')\n        alpha_u = u_max**2 / (K_mat @ P_inv @ K_mat.T)[0, 0]\n        \n        return min(alpha_x1, alpha_x2, alpha_u)\n\n    alpha = calculate_alpha(P, K, x_max_abs, u_max_abs)\n\n    # --- Part 2: Finite-Horizon Optimal Control Problem ---\n\n    def mpc_objective(U, x0, A_sys, B_sys, Q_cost, R_cost, P_cost, N_horizon):\n        cost = 0.0\n        x = x0.copy()\n        for k in range(N_horizon):\n            u_scalar = U[k]\n            cost += (x.T @ Q_cost @ x + u_scalar * R_cost[0, 0] * u_scalar)[0, 0]\n            x = A_sys @ x + B_sys * u_scalar\n        cost += (x.T @ P_cost @ x)[0, 0]\n        return cost\n\n    def mpc_constraints(U, x0, A_sys, B_sys, P_cost, alpha_term, x_max, N_horizon):\n        # Constraints are formulated as g(x) >= 0\n        cons = []\n        x = x0.copy()\n        for k in range(N_horizon):\n            u = U[k]\n            x_next = A_sys @ x + B_sys * u\n            \n            if k < N_horizon - 1:  # Path constraints for x_1, ..., x_{N-1}\n                cons.extend([\n                    x_max - x_next[0, 0], x_max + x_next[0, 0],\n                    x_max - x_next[1, 0], x_max + x_next[1, 0]\n                ])\n            else:  # Terminal constraint for x_N\n                cons.append(alpha_term - (x_next.T @ P_cost @ x_next)[0, 0])\n            \n            x = x_next\n        return np.array(cons)\n\n    # --- Part 3: Recursive Feasibility Verification ---\n\n    def check_recursive_feasibility(x0_vec):\n        x_current = x0_vec.reshape(2, 1)\n        U_warm_start = np.zeros(N)\n\n        for _ in range(T_cl):\n            if np.any(np.abs(x_current) > x_max_abs + 1e-9): # Safety check\n                return False\n\n            bounds = [(-u_max_abs, u_max_abs)] * N\n            \n            constraints_dict = {\n                'type': 'ineq',\n                'fun': mpc_constraints,\n                'args': (x_current, A, B, P, alpha, x_max_abs, N)\n            }\n\n            res = minimize(mpc_objective, U_warm_start,\n                           args=(x_current, A, B, Q, R, P, N),\n                           method='SLSQP',\n                           bounds=bounds,\n                           constraints=[constraints_dict],\n                           options={'ftol': 1e-6, 'maxiter': 200})\n\n            if not res.success:\n                return False\n\n            U_optimal = res.x\n            u0_optimal = U_optimal[0]\n\n            x_next = A @ x_current + B * u0_optimal\n            x_current = x_next\n            \n            # Use warm start for the next iteration\n            U_warm_start = np.roll(U_optimal, -1)\n            U_warm_start[-1] = 0.0\n\n        return True\n\n    results = []\n    for x0 in test_cases:\n        is_feasible = check_recursive_feasibility(x0)\n        results.append(is_feasible)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "2736384"}]}