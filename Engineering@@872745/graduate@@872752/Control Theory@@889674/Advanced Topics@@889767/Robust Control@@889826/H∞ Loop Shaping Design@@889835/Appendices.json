{"hands_on_practices": [{"introduction": "The state-space approach to $\\mathcal{H}_{\\infty}$ control provides a powerful algorithmic framework for controller synthesis. Before a controller can be designed for a given performance level $\\gamma$, we must first verify that such a controller exists, a check which hinges on solving a pair of Algebraic Riccati Equations (AREs) linked by a spectral radius condition. This practice [@problem_id:2711244] will guide you through the numerical verification of this fundamental feasibility test, connecting the abstract theory to concrete computation.", "problem": "You are given a strictly proper, stable, single-input single-output linear time-invariant system with state-space realization specified by the matrices $A \\in \\mathbb{R}^{2 \\times 2}$, $B \\in \\mathbb{R}^{2 \\times 1}$, $C \\in \\mathbb{R}^{1 \\times 2}$, and $D \\in \\mathbb{R}^{1 \\times 1}$:\n$$\nA = \\begin{bmatrix}0  1\\\\ -2  -3\\end{bmatrix},\\quad\nB = \\begin{bmatrix}0\\\\ 1\\end{bmatrix},\\quad\nC = \\begin{bmatrix}1  0\\end{bmatrix},\\quad\nD = 0.\n$$\nIn the context of $\\mathcal{H}_{\\infty}$ loop shaping design, a key feasibility condition involves the existence of stabilizing solutions to a pair of continuous-time Algebraic Riccati Equations (AREs), and a spectral radius inequality. The fundamental base for this problem is:\n- The continuous-time Algebraic Riccati Equation (ARE), defined for $A \\in \\mathbb{R}^{n \\times n}$, $B \\in \\mathbb{R}^{n \\times m}$, $Q = Q^{\\top} \\in \\mathbb{R}^{n \\times n}$, and $R = R^{\\top} \\in \\mathbb{R}^{m \\times m}$ with $R \\succ 0$, as the matrix equation\n$$\nA^{\\top} X + X A - X B R^{-1} B^{\\top} X + Q = 0,\n$$\nwhose stabilizing solution $X = X^{\\top} \\succeq 0$ is the unique solution such that the closed-loop matrix $A - B R^{-1} B^{\\top} X$ is Hurwitz.\n- The spectral radius $\\rho(M)$ of a square matrix $M$ is defined as the maximum modulus among the eigenvalues of $M$.\n\nFor a given $\\gamma \\in \\mathbb{R}_{0}$, define the two CAREs to be solved for $X = X^{\\top} \\in \\mathbb{R}^{2 \\times 2}$ and $Y = Y^{\\top} \\in \\mathbb{R}^{2 \\times 2}$:\n1. The $X$-equation\n$$\nA^{\\top} X + X A - X B \\left(\\gamma^{2} I_{1}\\right)^{-1} B^{\\top} X + C^{\\top} C = 0,\n$$\nwhich is of the standard form with $Q_{X} = C^{\\top} C$ and $R_{X} = \\gamma^{2} I_{1}$.\n2. The $Y$-equation\n$$\nA Y + Y A^{\\top} - Y C^{\\top} \\left(\\gamma^{2} I_{1}\\right)^{-1} C Y + B B^{\\top} = 0,\n$$\nwhich can be computed by applying the standard ARE to the dual data $(A^{\\top}, C^{\\top}, Q_{Y} = B B^{\\top}, R_{Y} = \\gamma^{2} I_{1})$.\n\nFor each tested $\\gamma$, compute the stabilizing solutions $X$ and $Y$, then evaluate the spectral radius inequality\n$$\n\\rho(X Y)  \\gamma^{2}.\n$$\nYou must implement the computation using the standard continuous-time Algebraic Riccati Equation solver consistent with the definition above and compute the spectral radius using the eigenvalues of $X Y$.\n\nTest suite:\n- Use the following list of values for $\\gamma$: $[0.25, 0.35, 0.60, 1.00, 3.00]$.\n- For each $\\gamma$ in this list, produce a boolean indicating whether the inequality $\\rho(XY)  \\gamma^{2}$ holds for the computed stabilizing Riccati solutions.\n\nFinal output format:\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets. For example, if there are five booleans, the output format must be exactly of the form `[True,False,True,True,False]` with no spaces.\n- No physical units are involved in this problem.\n- All angles, if any, are irrelevant to this problem.\n\nYour implementation must be a complete, runnable program that performs the calculations and prints the required single-line output for the specified test suite.", "solution": "The problem statement is valid. It presents a well-posed and scientifically grounded problem from the field of $\\mathcal{H}_{\\infty}$ control theory. The task is to verify a fundamental feasibility condition for the existence of a suboptimal $\\mathcal{H}_{\\infty}$ controller for a given linear time-invariant (LTI) system and a set of performance levels $\\gamma$. All necessary data and definitions are provided, and there are no contradictions or ambiguities.\n\nThe system is defined by the state-space matrices:\n$$\nA = \\begin{bmatrix}0  1\\\\ -2  -3\\end{bmatrix},\\quad\nB = \\begin{bmatrix}0\\\\ 1\\end{bmatrix},\\quad\nC = \\begin{bmatrix}1  0\\end{bmatrix},\\quad\nD = 0.\n$$\nThe eigenvalues of the matrix $A$ are the roots of the characteristic equation $\\det(A - \\lambda I) = \\lambda^2 + 3\\lambda + 2 = 0$, which are $\\lambda_1 = -1$ and $\\lambda_2 = -2$. Since both eigenvalues have negative real parts, the open-loop system is stable, as stated. Furthermore, the system is both controllable and observable, which are standard assumptions ensuring the existence and uniqueness of stabilizing solutions to the relevant Algebraic Riccati Equations (AREs).\n\nThe core of the problem lies in the analysis of two continuous-time Algebraic Riccati Equations (CAREs) and a coupling condition for each specified positive scalar $\\gamma$.\n\nFirst CARE, the $X$-equation:\nThis equation is given by:\n$$\nA^{\\top} X + X A - X B (\\gamma^2 I_1)^{-1} B^{\\top} X + C^{\\top} C = 0\n$$\nTo solve this using a standard numerical routine that computes the stabilizing solution for $A^{\\top} P + P A - P B R^{-1} B^{\\top} P + Q = 0$, we identify the corresponding matrices. In this context, the system matrix is $A$, the input matrix is $B$, the state-weighting matrix is $Q_X = C^{\\top} C$, and the control-weighting matrix is $R_X = \\gamma^2 I_1$. Numerically, we have:\n$$\nQ_X = C^{\\top} C = \\begin{bmatrix}1\\\\ 0\\end{bmatrix} \\begin{bmatrix}1  0\\end{bmatrix} = \\begin{bmatrix}1  0\\\\ 0  0\\end{bmatrix}\n$$\n$$\nR_X = \\gamma^2\n$$\nFor each $\\gamma$ in the test suite, we must find the unique symmetric positive semi-definite solution $X$ such that the closed-loop matrix $A_{cl,X} = A - B R_X^{-1} B^{\\top} X = A - \\frac{1}{\\gamma^2} B B^{\\top} X$ is Hurwitz (i.e., all its eigenvalues lie in the open left-half of the complex plane).\n\nSecond CARE, the $Y$-equation:\nThis equation is given by:\n$$\nA Y + Y A^{\\top} - Y C^{\\top} (\\gamma^2 I_1)^{-1} C Y + B B^{\\top} = 0\n$$\nThis is often called the \"dual\" Riccati equation. To solve it using the same standard solver, we can transpose the equation and rearrange terms to match the standard form. The equation is equivalent to:\n$$\n(A^{\\top})^{\\top} Y + Y A^{\\top} - Y C^{\\top} (\\gamma^2 I_1)^{-1} (C^{\\top})^{\\top} Y + B B^{\\top} = 0\n$$\nThis structure corresponds to a CARE for a dual system. We identify the matrices for the standard solver as: system matrix $A_d = A^{\\top}$, input matrix $B_d = C^{\\top}$, state-weighting matrix $Q_Y = B B^{\\top}$, and control-weighting matrix $R_Y = \\gamma^2 I_1$. Numerically, we have:\n$$\nQ_Y = B B^{\\top} = \\begin{bmatrix}0\\\\ 1\\end{bmatrix} \\begin{bmatrix}0  1\\end{bmatrix} = \\begin{bmatrix}0  0\\\\ 0  1\\end{bmatrix}\n$$\n$$\nR_Y = \\gamma^2\n$$\nFor each $\\gamma$, we find the unique symmetric positive semi-definite solution $Y$ such that the matrix $A_{cl,Y} = A_d - B_d R_Y^{-1} B_d^{\\top} Y = A^{\\top} - \\frac{1}{\\gamma^2} C^{\\top} C Y$ is Hurwitz.\n\nThe Spectral Radius Condition:\nAfter finding the stabilizing solutions $X \\succeq 0$ and $Y \\succeq 0$ for a given $\\gamma$, a necessary and sufficient condition for the existence of an $\\mathcal{H}_{\\infty}$ controller of order $n$ that achieves the performance level $\\gamma$ is the spectral radius inequality:\n$$\n\\rho(XY)  \\gamma^2\n$$\nHere, $\\rho(M)$ denotes the spectral radius of a matrix $M$, defined as the maximum of the absolute values of its eigenvalues. If, for a given $\\gamma$, a stabilizing positive semi-definite solution to either CARE does not exist, the condition is not met, and the conclusion is 'false'. Numerical solvers will typically raise an error in such cases.\n\nThe computational procedure is therefore as follows:\nFor each value of $\\gamma$ from the test suite $[0.25, 0.35, 0.60, 1.00, 3.00]$:\n1. Define the matrices $A$, $B$, $C$.\n2. Define the CARE parameters for the $X$-equation: $A_X=A$, $B_X=B$, $Q_X=C^{\\top}C$, $R_X=\\gamma^2$.\n3. Attempt to solve for the stabilizing solution $X$. If the solver fails, the condition for this $\\gamma$ is false.\n4. Define the CARE parameters for the $Y$-equation: $A_Y=A^{\\top}$, $B_Y=C^{\\top}$, $Q_Y=B B^{\\top}$, $R_Y=\\gamma^2$.\n5. Attempt to solve for the stabilizing solution $Y$. If the solver fails, the condition for this $\\gamma$ is false.\n6. If both solutions $X$ and $Y$ are successfully computed, calculate the matrix product $M = XY$.\n7. Compute the eigenvalues of $M$.\n8. Calculate the spectral radius $\\rho(M)$ as the maximum modulus of these eigenvalues.\n9. Evaluate the boolean expression $\\rho(M)  \\gamma^2$ and record the result.\n\nThis procedure will be implemented to generate the final list of boolean outcomes.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.linalg import solve_continuous_are\n\ndef solve():\n    \"\"\"\n    Computes H-infinity feasibility condition for a given LTI system and a suite of gamma values.\n    \"\"\"\n    # Define the state-space matrices of the LTI system from the problem statement.\n    A = np.array([[0., 1.], [-2., -3.]])\n    B = np.array([[0.], [1.]])\n    C = np.array([[1., 0.]])\n    \n    # Test suite of gamma values.\n    test_cases = [0.25, 0.35, 0.60, 1.00, 3.00]\n    \n    results = []\n    \n    for gamma in test_cases:\n        gamma_sq = gamma**2\n        \n        # --- Solve the X-Riccati Equation ---\n        # A'X + XA - X B R^{-1} B'X + Q = 0\n        # For the X-equation, Qx = C'C, Rx = gamma^2 * I\n        Qx = C.T @ C\n        Rx = np.array([[gamma_sq]])\n        \n        try:\n            X = solve_continuous_are(A, B, Qx, Rx)\n        except np.linalg.LinAlgError:\n            # If a stabilizing solution does not exist, the condition fails.\n            results.append(False)\n            continue\n\n        # --- Solve the Y-Riccati Equation ---\n        # AY + YA' - Y C' R^{-1} C Y + B B' = 0\n        # This is a dual ARE, solved by applying the standard solver to the dual system.\n        # Ad'Y + YAd - Y Bd Rd^{-1} Bd'Y + Qd = 0\n        # where Ad = A', Bd = C', Qd = B B', Rd = gamma^2 * I\n        Ad = A.T\n        Bd = C.T\n        Qy = B @ B.T\n        Ry = np.array([[gamma_sq]])\n        \n        try:\n            Y = solve_continuous_are(Ad, Bd, Qy, Ry)\n        except np.linalg.LinAlgError:\n            # If a stabilizing solution does not exist, the condition fails.\n            results.append(False)\n            continue\n            \n        # --- Check the Spectral Radius Condition ---\n        # rho(XY)  gamma^2\n        XY = X @ Y\n        \n        # Compute eigenvalues of the product matrix XY\n        eigenvalues = np.linalg.eigvals(XY)\n        \n        # Compute the spectral radius (max of absolute values of eigenvalues)\n        rho = np.max(np.abs(eigenvalues))\n        \n        # Evaluate the inequality\n        is_condition_met = rho  gamma_sq\n        results.append(is_condition_met)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "2711244"}, {"introduction": "A central theme in robust control is quantifying stability in the face of uncertainty, but the answer depends critically on how we model that uncertainty. Two of the most important models are multiplicative uncertainty and normalized coprime factor (NCF) uncertainty. This exercise [@problem_id:2711266] challenges you to directly compare these two frameworks by calculating the guaranteed stability margin for each, providing a clear, quantitative insight into the concept of model conservatism and its practical implications.", "problem": "Consider the unity negative-feedback interconnection of a single-input/single-output (SISO) nominal plant and controller within the framework of H-infinity ($H_{\\infty}$) loop-shaping design. Let the nominal plant be $G(s) = \\dfrac{1}{s+1}$ and the controller be a static gain $K(s) = 1$. Assume zero exogenous inputs (regulation).\n\nTwo uncertainty descriptions are considered:\n\n1. Multiplicative output uncertainty: the true plant is $G_{\\Delta}(s) = \\bigl(1 + \\Delta(s)\\bigr) G(s)$, where $\\Delta(s)$ is stable and satisfies $\\|\\Delta\\|_{\\infty} \\leq \\delta$, with $H_{\\infty}$-norm defined by $\\|F\\|_{\\infty} = \\sup_{\\omega \\in \\mathbb{R}} \\bar{\\sigma}\\bigl(F(\\mathrm{j}\\omega)\\bigr)$, where $\\bar{\\sigma}$ denotes the largest singular value. The complementary sensitivity is $T(s) = G(s)K(s)\\bigl(I + G(s)K(s)\\bigr)^{-1}$. Use the Small Gain Theorem as the fundamental starting point to obtain the largest admissible radius $\\delta$ guaranteeing robust internal stability in this description, expressed in terms of $T(s)$.\n\n2. Normalized right coprime factor (NCF) plant uncertainty: the nominal plant admits a normalized right coprime factorization $G(s) = N(s)M(s)^{-1}$ with $M(s)$, $N(s)$ stable and satisfying the standard normalization. The true plant is $(N(s) + \\Delta_{N}(s))\\bigl(M(s) + \\Delta_{M}(s)\\bigr)^{-1}$, where $\\Delta_{N}(s)$ and $\\Delta_{M}(s)$ are stable and stacked as $\\Delta(s) = \\bigl[\\Delta_{M}(s)\\ \\ \\Delta_{N}(s)\\bigr]$ with constraint $\\|\\Delta\\|_{\\infty} \\leq \\varepsilon$. Starting from the Small Gain Theorem and the normalized coprime-uncertainty interconnection, express the largest admissible radius $\\varepsilon$ guaranteeing robust internal stability in terms of a closed-loop transfer matrix that depends only on $G(s)$ and $K(s)$ (no explicit dependence on a particular choice of coprime factors should remain in the final expression).\n\nSpecialize both robustness margins to the given $G(s)$ and $K(s)$, compute their exact values, and then quantify the conservatism of the normalized coprime factor robustness relative to the multiplicative output uncertainty by computing the ratio\n$$\nR \\equiv \\frac{\\text{multiplicative margin}}{\\text{NCF margin}}.\n$$\nProvide your final answer for $R$ as a single exact real number (no units). Do not introduce any additional weights; take the multiplicative output weight to be the identity ($W(s) = 1$). Do not approximate; no rounding is required.", "solution": "The problem as stated is subjected to rigorous validation.\n\nStep 1: Extracted Givens.\n-   System Configuration: Unity negative-feedback, single-input/single-output (SISO).\n-   Nominal Plant: $G(s) = \\dfrac{1}{s+1}$.\n-   Controller: $K(s) = 1$.\n-   Inputs: Zero exogenous inputs.\n-   Uncertainty Model 1 (Multiplicative Output):\n    -   Perturbed Plant: $G_{\\Delta}(s) = \\bigl(1 + \\Delta(s)\\bigr) G(s)$.\n    -   Uncertainty: $\\Delta(s)$ is stable and $\\|\\Delta\\|_{\\infty} \\leq \\delta$.\n    -   Target: Find the largest $\\delta$ for robust stability.\n-   Uncertainty Model 2 (Normalized Right Coprime Factor - NCF):\n    -   Nominal Factorization: $G(s) = N(s)M(s)^{-1}$, where $N(s)$, $M(s)$ are stable and satisfy the normalization condition.\n    -   Perturbed Plant: $(N(s) + \\Delta_{N}(s))\\bigl(M(s) + \\Delta_{M}(s)\\bigr)^{-1}$.\n    -   Uncertainty: $\\Delta(s) = \\bigl[\\Delta_{M}(s)\\ \\ \\Delta_{N}(s)\\bigr]$ is stable and $\\|\\Delta\\|_{\\infty} \\leq \\varepsilon$.\n    -   Target: Find the largest $\\varepsilon$ for robust stability.\n-   Final Calculation: Compute the ratio $R = \\frac{\\delta}{\\varepsilon}$.\n\nStep 2: Validation.\n-   **Scientifically Grounded**: The problem is based on fundamental concepts in robust control theory, namely the Small Gain Theorem, multiplicative uncertainty, and normalized coprime factor uncertainty. These are standard and well-established topics. The problem is scientifically sound.\n-   **Well-Posed**: The problem provides a completely specified nominal system ($G(s)$, $K(s)$) and two well-defined uncertainty structures. It asks for the computation of unique, meaningful quantities (robustness margins $\\delta$ and $\\varepsilon$) and their ratio.\n-   **Objective**: The language is precise, technical, and free of subjective content.\n\nStep 3: Verdict.\nThe problem is scientifically valid, well-posed, and objective. It contains a complete and consistent set of data and constraints. A solution will be provided.\n\nThe solution proceeds in three parts: first, the calculation of the multiplicative uncertainty margin; second, the calculation of the normalized coprime factor uncertainty margin; and third, the computation of their ratio.\n\nPart 1: Multiplicative Output Uncertainty Margin\nThe unity negative-feedback loop containing the perturbed plant $G_{\\Delta}(s) = (1+\\Delta(s))G(s)$ and controller $K(s)$ must be analyzed for robust stability. The standard approach is to rearrange the block diagram to isolate the uncertainty $\\Delta(s)$. This arrangement results in a feedback connection between the stable nominal closed-loop transfer function and the uncertainty block $\\Delta(s)$. The transfer function 'seen' by the uncertainty block, from its output to its input, is the complementary sensitivity function $T(s) = G(s)K(s)\\bigl(1 + G(s)K(s)\\bigr)^{-1}$.\n\nAccording to the Small Gain Theorem, the closed-loop system remains internally stable for all stable uncertainties $\\Delta(s)$ satisfying $\\|\\Delta\\|_{\\infty} \\leq \\delta$ if and only if $\\|T(s)\\Delta(s)\\|_{\\infty}  1$. This condition is guaranteed if $\\|T\\|_{\\infty} \\|\\Delta\\|_{\\infty}  1$. The largest admissible radius $\\delta$ is therefore given by the inverse of the $H_{\\infty}$-norm of the complementary sensitivity function:\n$$\n\\delta = \\frac{1}{\\|T(s)\\|_{\\infty}}\n$$\nFor the given nominal plant $G(s) = \\frac{1}{s+1}$ and controller $K(s) = 1$, the loop transfer function is $L(s) = G(s)K(s) = \\frac{1}{s+1}$.\nThe complementary sensitivity function is:\n$$\nT(s) = \\frac{L(s)}{1+L(s)} = \\frac{\\frac{1}{s+1}}{1+\\frac{1}{s+1}} = \\frac{1}{(s+1)+1} = \\frac{1}{s+2}\n$$\nThe $H_{\\infty}$-norm is the peak magnitude of the frequency response:\n$$\n\\|T\\|_{\\infty} = \\sup_{\\omega \\in \\mathbb{R}} |T(j\\omega)| = \\sup_{\\omega \\in \\mathbb{R}} \\left|\\frac{1}{j\\omega+2}\\right| = \\sup_{\\omega \\in \\mathbb{R}} \\frac{1}{\\sqrt{\\omega^2 + 2^2}} = \\sup_{\\omega \\in \\mathbb{R}} \\frac{1}{\\sqrt{\\omega^2 + 4}}\n$$\nThe supremum is achieved when the denominator is minimized, which occurs at $\\omega = 0$.\n$$\n\\|T\\|_{\\infty} = \\frac{1}{\\sqrt{0^2+4}} = \\frac{1}{2}\n$$\nThus, the multiplicative uncertainty margin is:\n$$\n\\delta = \\frac{1}{1/2} = 2\n$$\n\nPart 2: Normalized Coprime Factor (NCF) Uncertainty Margin\nFor NCF uncertainty, the condition for robust stability is also derived from the Small Gain Theorem applied to the standard interconnection for this uncertainty structure. The problem requires the result to be expressed in a form that is independent of any particular coprime factorization. The standard result for the largest admissible uncertainty radius $\\varepsilon$ is:\n$$\n\\varepsilon = \\left\\| \\begin{pmatrix} K(s) \\\\ I \\end{pmatrix} \\bigl(I+G(s)K(s)\\bigr)^{-1} \\bigl( I \\ \\ G(s) \\bigr) \\right\\|_{\\infty}^{-1}\n$$\nLet us define the transfer matrix $\\mathcal{M}(s)$:\n$$\n\\mathcal{M}(s) = \\begin{pmatrix} K(s) \\\\ 1 \\end{pmatrix} \\frac{1}{1+G(s)K(s)} \\begin{pmatrix} 1  G(s) \\end{pmatrix} = \\frac{1}{1+L(s)} \\begin{pmatrix} K(s)  K(s)G(s) \\\\ 1  G(s) \\end{pmatrix}\n$$\nUsing the definitions for the sensitivity function $S(s) = (1+L(s))^{-1}$ and complementary sensitivity function $T(s) = L(s)(1+L(s))^{-1}$, the matrix can be written as:\n$$\n\\mathcal{M}(s) = \\begin{pmatrix} K(s)S(s)  T(s) \\\\ S(s)  G(s)S(s) \\end{pmatrix}\n$$\nFor the given $G(s) = \\frac{1}{s+1}$ and $K(s) = 1$:\n$$\nS(s) = \\frac{1}{1+\\frac{1}{s+1}} = \\frac{s+1}{s+2}\n$$\n$$\nT(s) = \\frac{\\frac{1}{s+1}}{1+\\frac{1}{s+1}} = \\frac{1}{s+2}\n$$\nAnd $G(s)S(s) = \\frac{1}{s+1} \\frac{s+1}{s+2} = \\frac{1}{s+2} = T(s)$.\nSubstituting these into the expression for $\\mathcal{M}(s)$:\n$$\n\\mathcal{M}(s) = \\begin{pmatrix} S(s)  T(s) \\\\ S(s)  T(s) \\end{pmatrix} = \\begin{pmatrix} \\frac{s+1}{s+2}  \\frac{1}{s+2} \\\\ \\frac{s+1}{s+2}  \\frac{1}{s+2} \\end{pmatrix}\n$$\nThe $H_{\\infty}$-norm of $\\mathcal{M}(s)$ is $\\sup_{\\omega} \\bar{\\sigma}(\\mathcal{M}(j\\omega))$, where $\\bar{\\sigma}$ is the largest singular value. The frequency-dependent matrix is:\n$$\n\\mathcal{M}(j\\omega) = \\begin{pmatrix} \\frac{j\\omega+1}{j\\omega+2}  \\frac{1}{j\\omega+2} \\\\ \\frac{j\\omega+1}{j\\omega+2}  \\frac{1}{j\\omega+2} \\end{pmatrix}\n$$\nThis is a rank-$1$ matrix, which can be expressed as an outer product of two vectors $u = \\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix}$ and $v^H = \\begin{pmatrix} \\frac{j\\omega+1}{j\\omega+2}  \\frac{1}{j\\omega+2} \\end{pmatrix}^*$. Let's use $u v^T$ form with $v^T = \\begin{pmatrix} \\frac{j\\omega+1}{j\\omega+2}  \\frac{1}{j\\omega+2} \\end{pmatrix}$. The largest singular value is given by $\\bar{\\sigma} = \\|u\\|_2 \\|v\\|_2$.\n$$\n\\|u\\|_2 = \\sqrt{1^2+1^2} = \\sqrt{2}\n$$\n$$\n\\|v\\|_2^2 = \\left|\\frac{j\\omega+1}{j\\omega+2}\\right|^2 + \\left|\\frac{1}{j\\omega+2}\\right|^2 = \\frac{|j\\omega+1|^2}{|j\\omega+2|^2} + \\frac{|1|^2}{|j\\omega+2|^2} = \\frac{\\omega^2+1}{\\omega^2+4} + \\frac{1}{\\omega^2+4} = \\frac{\\omega^2+2}{\\omega^2+4}\n$$\nSo, the largest singular value as a function of $\\omega$ is:\n$$\n\\bar{\\sigma}(\\mathcal{M}(j\\omega)) = \\sqrt{2} \\sqrt{\\frac{\\omega^2+2}{\\omega^2+4}} = \\sqrt{\\frac{2\\omega^2+4}{\\omega^2+4}}\n$$\nTo find the $H_{\\infty}$-norm, we must find the supremum of this function over all $\\omega \\in \\mathbb{R}$. Let $x = \\omega^2$, where $x \\ge 0$. We need to find the supremum of $f(x) = \\sqrt{\\frac{2x+4}{x+4}}$. The derivative of the argument of the square root is $g'(x) = \\frac{d}{dx}\\left(\\frac{2x+4}{x+4}\\right) = \\frac{2(x+4) - (2x+4)}{(x+4)^2} = \\frac{4}{(x+4)^2}  0$ for all $x \\ge 0$. Thus, the function is monotonically increasing. The supremum is its limit as $x \\to \\infty$.\n$$\n\\|\\mathcal{M}\\|_{\\infty}^2 = \\lim_{x \\to \\infty} \\frac{2x+4}{x+4} = 2\n$$\nTherefore, $\\|\\mathcal{M}\\|_{\\infty} = \\sqrt{2}$. The NCF uncertainty margin is:\n$$\n\\varepsilon = \\frac{1}{\\|\\mathcal{M}\\|_{\\infty}} = \\frac{1}{\\sqrt{2}}\n$$\n\nPart 3: Ratio of Margins\nThe problem asks for the ratio of the multiplicative margin to the NCF margin.\n$$\nR = \\frac{\\delta}{\\varepsilon} = \\frac{2}{1/\\sqrt{2}} = 2\\sqrt{2}\n$$\nThis ratio quantifies the relative conservatism of the NCF uncertainty model compared to the multiplicative output uncertainty model for this specific plant and controller. A value greater than $1$ indicates that the NCF stability margin is smaller (more conservative).", "answer": "$$\n\\boxed{2\\sqrt{2}}\n$$", "id": "2711266"}, {"introduction": "Effective control design, especially for multi-input, multi-output (MIMO) systems, involves shaping the loop's singular values to balance performance and robustness, which is the essence of $\\mathcal{H}_{\\infty}$ loop shaping. This final practice [@problem_id:2711299] immerses you in a practical design analysis scenario where you will apply shaping compensators to a MIMO plant and evaluate the impact on key metrics. Through this computational exercise, you will develop a tangible feel for the art and science of managing these critical engineering trade-offs.", "problem": "Consider a continuous-time, linear time-invariant, strictly proper, stable, multi-input multi-output plant with two inputs and two outputs. The plant transfer matrix is given by\n$$\nG(s) \\;=\\; \\begin{bmatrix}\n\\dfrac{1}{s + 1}  \\dfrac{0.5}{s + 2} \\\\\n\\dfrac{-0.3}{s + 3}  \\dfrac{1.5}{s + 1}\n\\end{bmatrix}.\n$$\nLet the open-loop transfer matrix be defined, for each angular frequency $\\omega \\in \\mathbb{R}_{\\ge 0}$ in radians per second, as $L(j\\omega) = G(j\\omega)$. For shaping, consider stable, minimum-phase diagonal pre- and post-compensators $W_1(s)\\in\\mathbb{C}^{2\\times 2}$ and $W_2(s)\\in\\mathbb{C}^{2\\times 2}$, and define the shaped open-loop transfer matrix\n$$\nL_s(j\\omega) \\;=\\; W_2(j\\omega)\\,G(j\\omega)\\,W_1(j\\omega).\n$$\nFor any square complex matrix $M$, let $\\bar{\\sigma}(M)$ denote its largest singular value and $\\underline{\\sigma}(M)$ its smallest singular value. Define the sensitivity matrix $S(j\\omega) = \\big(I + L(j\\omega)\\big)^{-1}$ and the complementary sensitivity matrix $T(j\\omega) = L(j\\omega)\\big(I + L(j\\omega)\\big)^{-1}$, and analogously $S_s(j\\omega)$ and $T_s(j\\omega)$ with $L$ replaced by $L_s$. In the context of $\\mathcal{H}_{\\infty}$ (H-infinity) loop shaping design, the following frequency-domain scalars are of interest:\n- Low-frequency loop gain proxy: $g_{\\mathrm{low}} = \\bar{\\sigma}\\big(L(j\\omega_{\\min})\\big)$ and $g_{\\mathrm{low},s} = \\bar{\\sigma}\\big(L_s(j\\omega_{\\min})\\big)$, where $\\omega_{\\min}$ is the smallest frequency sample.\n- Return-difference margin proxy: $m_{\\mathrm{rd}} = \\displaystyle \\min_{\\omega\\in\\Omega}\\,\\underline{\\sigma}\\big(I + L(j\\omega)\\big)$ and $m_{\\mathrm{rd},s} = \\displaystyle \\min_{\\omega\\in\\Omega}\\,\\underline{\\sigma}\\big(I + L_s(j\\omega)\\big)$.\n- Complementary sensitivity peak: $\\|T\\|_{\\infty,\\mathrm{grid}} = \\displaystyle \\max_{\\omega\\in\\Omega}\\,\\bar{\\sigma}\\big(T(j\\omega)\\big)$ and $\\|T_s\\|_{\\infty,\\mathrm{grid}} = \\displaystyle \\max_{\\omega\\in\\Omega}\\,\\bar{\\sigma}\\big(T_s(j\\omega)\\big)$, evaluated over a finite frequency grid $\\Omega$.\n\nYour task is to compute and compare these quantities before and after shaping for the plant $G(s)$ using the following specifications.\n\nFundamental definitions to be used:\n- Frequency response evaluation: for any proper rational transfer function $H(s) = \\dfrac{b_0 s^n + b_1 s^{n-1} + \\cdots + b_n}{a_0 s^m + a_1 s^{m-1} + \\cdots + a_m}$ with $m \\ge n$, the frequency response at $j\\omega$ is obtained by complex evaluation $H(j\\omega) = \\dfrac{b_0 (j\\omega)^n + \\cdots + b_n}{a_0 (j\\omega)^m + \\cdots + a_m}$.\n- Singular values: for any complex matrix $M$, the singular values are the nonnegative square roots of the eigenvalues of $M^* M$.\n- Sensitivity and complementary sensitivity: $S(j\\omega) = \\big(I + L(j\\omega)\\big)^{-1}$ and $T(j\\omega) = L(j\\omega)\\big(I + L(j\\omega)\\big)^{-1}$.\n\nFrequency grid:\n- Use a logarithmically spaced grid $\\Omega$ of $N = 400$ points from $\\omega_{\\min} = 10^{-2}$ to $\\omega_{\\max} = 10^{3}$ radians per second.\n\nTest suite:\nFor each test case, compute the following scalars for both the unshaped loop $L(j\\omega)$ and the shaped loop $L_s(j\\omega)$:\n- $g_{\\mathrm{low}}$, $g_{\\mathrm{low},s}$,\n- $m_{\\mathrm{rd}}$, $m_{\\mathrm{rd},s}$,\n- $\\|T\\|_{\\infty,\\mathrm{grid}}$, $\\|T_s\\|_{\\infty,\\mathrm{grid}}$.\n\nThen assess:\n- Performance improvement boolean $b_{\\mathrm{perf}} = 1$ if $g_{\\mathrm{low},s} > g_{\\mathrm{low}}$, otherwise $0$.\n- Robustness improvement boolean $b_{\\mathrm{rob}} = 1$ if $m_{\\mathrm{rd},s} > m_{\\mathrm{rd}}$ and $\\|T_s\\|_{\\infty,\\mathrm{grid}}  \\|T\\|_{\\infty,\\mathrm{grid}}$, otherwise $0$.\n\nUse the following three shaping configurations for $W_1(s)$ and $W_2(s)$:\n- Test case $1$:\n  - $W_1(s) = \\mathrm{diag}\\!\\left(\\dfrac{50}{s + 5},\\,\\dfrac{40}{s + 5}\\right)$,\n  - $W_2(s) = \\mathrm{diag}\\!\\left(\\dfrac{20}{s + 20},\\,\\dfrac{30}{s + 30}\\right)$.\n- Test case $2$:\n  - $W_1(s) = \\mathrm{diag}\\!\\left(\\dfrac{100}{s + 5},\\,\\dfrac{75}{s + 5}\\right)$,\n  - $W_2(s) = \\mathrm{diag}\\!\\left(\\dfrac{10}{s + 10},\\,\\dfrac{15}{s + 15}\\right)$.\n- Test case $3$:\n  - $W_1(s) = \\mathrm{diag}\\!\\left(1,\\,1\\right)$,\n  - $W_2(s) = \\mathrm{diag}\\!\\left(1,\\,1\\right)$.\n\nNumerical and output requirements:\n- All frequency-domain quantities must be computed using the grid $\\Omega$ specified above in radians per second.\n- For each test case, produce the list\n$$\n\\Big[ g_{\\mathrm{low}},\\, g_{\\mathrm{low},s},\\, m_{\\mathrm{rd}},\\, m_{\\mathrm{rd},s},\\, \\|T\\|_{\\infty,\\mathrm{grid}},\\, \\|T_s\\|_{\\infty,\\mathrm{grid}},\\, b_{\\mathrm{perf}},\\, b_{\\mathrm{rob}} \\Big],\n$$\nwhere floating-point results must be rounded to three decimal places. The booleans must be reported as integers $0$ or $1$. The final program output must be a single line containing a list of the three such lists, comma-separated, enclosed in a single pair of square brackets without any additional whitespace or text, for example: `[[...],[...],[...]]`.", "solution": "The problem presented is valid. It is a well-posed, scientifically grounded problem in the domain of multi-input multi-output (MIMO) control theory. All necessary data, models, and metric definitions are provided, and there are no internal contradictions or logical flaws. The task is to perform a numerical analysis of a control system's properties before and after applying loop shaping, which is a standard procedure in robust control system design. We shall proceed with a complete, reasoned solution.\n\nThe core of the task is to evaluate the effect of loop shaping on a given linear time-invariant (LTI) plant $G(s)$ by comparing frequency-domain performance and robustness metrics. The analysis is conducted over a specified frequency grid $\\Omega$. The methodology involves the following steps for each of the three test cases.\n\nFirst, we establish the frequency domain context. The analysis is based on the frequency response of the system, which is obtained by evaluating the system's transfer function matrix at $s = j\\omega$ for a range of angular frequencies $\\omega$. The specified frequency grid $\\Omega$ consists of $N=400$ points logarithmically spaced from $\\omega_{\\min} = 10^{-2}$ to $\\omega_{\\max} = 10^{3}$ radians per second. This choice of a logarithmic scale is standard, as it allows for detailed examination of system behavior across several decades of frequency, capturing both low-frequency (performance) and high-frequency (robustness, noise sensitivity) phenomena.\n\nFor each frequency $\\omega \\in \\Omega$, we compute the complex-valued transfer matrices. The unshaped open-loop system is given by $L(j\\omega) = G(j\\omega)$, where the plant is\n$$\nG(s) = \\begin{bmatrix} \\dfrac{1}{s + 1}  \\dfrac{0.5}{s + 2} \\\\ \\dfrac{-0.3}{s + 3}  \\dfrac{1.5}{s + 1} \\end{bmatrix}.\n$$\nLoop shaping is introduced via stable, minimum-phase diagonal pre-compensator $W_1(s)$ and post-compensator $W_2(s)$. These shape the open-loop singular values to achieve desired performance and robustness characteristics. The shaped open-loop system is then $L_s(j\\omega) = W_2(j\\omega)G(j\\omega)W_1(j\\omega)$. The analysis compares the properties derived from $L(j\\omega)$ with those from $L_s(j\\omega)$.\n\nThe key quantities for assessing the system are derived from singular value decomposition (SVD). For a MIMO system represented by a matrix $M$, the largest singular value, $\\bar{\\sigma}(M)$, and the smallest singular value, $\\underline{\\sigma}(M)$, provide a measure of the maximum and minimum \"gain\" of the system across all input directions.\n\nThe following metrics are computed:\n$1$. Low-Frequency Performance Proxy: The metric $g_{\\mathrm{low}} = \\bar{\\sigma}\\big(L(j\\omega_{\\min})\\big)$ approximates the DC gain of the system. High open-loop gain at low frequencies is crucial for good command following and rejection of low-frequency disturbances. The shaping aims to increase this gain, so an improvement is indicated when $g_{\\mathrm{low},s} = \\bar{\\sigma}\\big(L_s(j\\omega_{\\min})\\big)  g_{\\mathrm{low}}$. This condition determines the boolean flag $b_{\\mathrm{perf}}$.\n\n$2$. Robustness Metrics: Robustness to uncertainty is assessed using two main quantities.\n   - The return-difference margin proxy, $m_{\\mathrm{rd}} = \\min_{\\omega\\in\\Omega}\\,\\underline{\\sigma}\\big(I + L(j\\omega)\\big)$, is related to the stability margin. A larger value of $m_{\\mathrm{rd}}$ implies a larger stability margin against unstructured multiplicative uncertainty at the plant input.\n   - The complementary sensitivity peak, $\\|T\\|_{\\infty,\\mathrm{grid}} = \\max_{\\omega\\in\\Omega}\\,\\bar{\\sigma}\\big(T(j\\omega)\\big)$. The matrix $T(j\\omega) = L(j\\omega)\\big(I + L(j\\omega)\\big)^{-1}$ is the complementary sensitivity function, which represents the closed-loop transfer function from reference to output. A large peak in its maximum singular value indicates poor damping and sensitivity to modeling errors.\n   - A simultaneous improvement in robustness is achieved if the shaped system exhibits a larger stability margin ($m_{\\mathrm{rd},s}  m_{\\mathrm{rd}}$) and a smaller sensitivity peak ($\\|T_s\\|_{\\infty,\\mathrm{grid}}  \\|T\\|_{\\infty,\\mathrm{grid}}$). This joint condition determines the boolean flag $b_{\\mathrm{rob}}$.\n\nThe algorithm proceeds as follows. For each of the three test cases, we iterate over every frequency $\\omega_k$ in the grid $\\Omega$. At each frequency, we:\n- Evaluate the complex matrices $G(j\\omega_k)$, $W_1(j\\omega_k)$, and $W_2(j\\omega_k)$.\n- Construct the unshaped loop $L_k = G(j\\omega_k)$ and the shaped loop $L_{s,k} = W_2(j\\omega_k)G(j\\omega_k)W_1(j\\omega_k)$.\n- Compute the complementary sensitivity matrices $T_k$ and $T_{s,k}$. This is done by solving the numerically stable linear systems $(I+L_k)T_k = L_k$ and $(I+L_{s,k})T_{s,k} = L_{s,k}$ rather than by explicit matrix inversion.\n- Compute the singular values for $L_k, L_{s,k}, (I+L_k), (I+L_{s,k}), T_k$, and $T_{s,k}$ using a standard SVD algorithm.\n- Store the largest and smallest singular values as required by the metric definitions.\n\nAfter the frequency sweep is complete, the stored arrays of singular values are used to calculate the final metrics. The low-frequency gains ($g_{\\mathrm{low}}, g_{\\mathrm{low},s}$) are taken from the first frequency point $\\omega_{\\min}$. The robustness margins ($m_{\\mathrm{rd}}, m_{\\mathrm{rd},s}$) and sensitivity peaks ($\\|T\\|_{\\infty,\\mathrm{grid}}, \\|T_s\\|_{\\infty,\\mathrm{grid}}$) are found by taking the minimum or maximum over the entire frequency grid, respectively. Finally, the boolean flags $b_{\\mathrm{perf}}$ and $b_{\\mathrm{rob}}$ are evaluated based on their specified conditions. The resulting set of eight values for each test case is then formatted and presented.", "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the H-infinity loop shaping analysis problem for three test cases.\n    \"\"\"\n    # 1. Setup\n    N = 400\n    omega_min = 1e-2\n    omega_max = 1e3\n    omega_grid = np.logspace(np.log10(omega_min), np.log10(omega_max), N)\n    \n    # Define Plant G(s)\n    def G_func(s: complex) - np.ndarray:\n        \"\"\"Evaluates the plant transfer matrix G(s) at a given complex frequency s.\"\"\"\n        return np.array([\n            [1.0 / (s + 1.0), 0.5 / (s + 2.0)],\n            [-0.3 / (s + 3.0), 1.5 / (s + 1.0)]\n        ], dtype=complex)\n\n    # Define Test Cases for Compensators W1(s), W2(s)\n    test_cases = [\n        {  # Case 1\n            \"W1\": lambda s: np.diag([50.0 / (s + 5.0), 40.0 / (s + 5.0)]),\n            \"W2\": lambda s: np.diag([20.0 / (s + 20.0), 30.0 / (s + 30.0)])\n        },\n        {  # Case 2\n            \"W1\": lambda s: np.diag([100.0 / (s + 5.0), 75.0 / (s + 5.0)]),\n            \"W2\": lambda s: np.diag([10.0 / (s + 10.0), 15.0 / (s + 15.0)])\n        },\n        {  # Case 3\n            \"W1\": lambda s: np.eye(2, dtype=complex),\n            \"W2\": lambda s: np.eye(2, dtype=complex)\n        }\n    ]\n\n    all_results = []\n    I = np.eye(2, dtype=complex)\n\n    # 2. Main Loop over test cases\n    for case_spec in test_cases:\n        W1_func = case_spec[\"W1\"]\n        W2_func = case_spec[\"W2\"]\n\n        # Storage for frequency-dependent singular values\n        sigma_bar_L_list = np.zeros(N)\n        sigma_bar_Ls_list = np.zeros(N)\n        sigma_under_I_L_list = np.zeros(N)\n        sigma_under_I_Ls_list = np.zeros(N)\n        sigma_bar_T_list = np.zeros(N)\n        sigma_bar_Ts_list = np.zeros(N)\n\n        # 3. Frequency Sweep\n        for i, omega in enumerate(omega_grid):\n            s = 1j * omega\n            \n            # Evaluate matrices at s=j*omega\n            Gm = G_func(s)\n            W1m = W1_func(s)\n            W2m = W2_func(s)\n\n            # Unshaped loop calculations\n            L = Gm\n            I_plus_L = I + L\n            T = np.linalg.solve(I_plus_L, L)\n\n            # Shaped loop calculations\n            Ls = W2m @ Gm @ W1m\n            I_plus_Ls = I + Ls\n            Ts = np.linalg.solve(I_plus_Ls, Ls)\n\n            # Singular value computations\n            sv_L = np.linalg.svd(L, compute_uv=False)\n            sv_Ls = np.linalg.svd(Ls, compute_uv=False)\n            sv_I_L = np.linalg.svd(I_plus_L, compute_uv=False)\n            sv_I_Ls = np.linalg.svd(I_plus_Ls, compute_uv=False)\n            sv_T = np.linalg.svd(T, compute_uv=False)\n            sv_Ts = np.linalg.svd(Ts, compute_uv=False)\n\n            # Store the required singular values\n            sigma_bar_L_list[i] = sv_L[0]\n            sigma_bar_Ls_list[i] = sv_Ls[0]\n            sigma_under_I_L_list[i] = sv_I_L[-1]\n            sigma_under_I_Ls_list[i] = sv_I_Ls[-1]\n            sigma_bar_T_list[i] = sv_T[0]\n            sigma_bar_Ts_list[i] = sv_Ts[0]\n\n        # 4. Post-processing to calculate final metrics\n        g_low = sigma_bar_L_list[0]\n        g_low_s = sigma_bar_Ls_list[0]\n\n        m_rd = np.min(sigma_under_I_L_list)\n        m_rd_s = np.min(sigma_under_I_Ls_list)\n\n        T_inf_grid = np.max(sigma_bar_T_list)\n        Ts_inf_grid = np.max(sigma_bar_Ts_list)\n\n        # 5. Boolean flags evaluation\n        b_perf = 1 if g_low_s  g_low else 0\n        b_rob = 1 if (m_rd_s  m_rd and Ts_inf_grid  T_inf_grid) else 0\n\n        # 6. Format and store results for this case\n        case_result = [\n            round(g_low, 3),\n            round(g_low_s, 3),\n            round(m_rd, 3),\n            round(m_rd_s, 3),\n            round(T_inf_grid, 3),\n            round(Ts_inf_grid, 3),\n            b_perf,\n            b_rob,\n        ]\n        all_results.append(case_result)\n\n    # 7. Final output formatting\n    output_parts = []\n    for res in all_results:\n        part = \"[\" + \",\".join(map(str, res)) + \"]\"\n        output_parts.append(part)\n    final_string = \"[\" + \",\".join(output_parts) + \"]\"\n    \n    print(final_string)\n\nsolve()\n```", "id": "2711299"}]}