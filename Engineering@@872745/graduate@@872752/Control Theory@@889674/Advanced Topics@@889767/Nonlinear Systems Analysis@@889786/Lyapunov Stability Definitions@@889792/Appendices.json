{"hands_on_practices": [{"introduction": "To truly grasp the nuances between different types of stability, it is essential to move from abstract definitions to concrete calculations. This first exercise provides a direct path to doing so by analyzing a simple scalar system whose behavior can be solved for explicitly. By comparing the solution's long-term behavior to the formal definitions, you will build a solid foundation for understanding Lyapunov, asymptotic, and exponential stability [@problem_id:2722252].", "problem": "Consider the scalar autonomous system defined on $\\mathbb{R}$ by $\\dot{x} = -x^{3}$. The equilibrium $x^* = 0$ is under examination for the following properties: Lyapunov stability, asymptotic stability, exponential stability, and global asymptotic stability (GAS). Work directly from first principles and core definitions of stability; do not invoke linearization-based conclusions. You may derive and use closed-form solutions if you justify them from the differential equation. Justify each property by tracing the logical implications of the definitions.\n\nEncode your final conclusions as a single row vector $\\begin{pmatrix} s  a  e  g \\end{pmatrix}$, where each entry is either $1$ (the property holds) or $0$ (the property does not hold), in the following order:\n- $s$: Lyapunov stability of $x^* = 0$,\n- $a$: asymptotic stability of $x^* = 0$,\n- $e$: exponential stability of $x^* = 0$,\n- $g$: global asymptotic stability of $x^* = 0$.\n\nYour final answer must be only this row vector. No rounding is required. Do not include units.", "solution": "The problem statement is parsed and validated. It is found to be scientifically sound, well-posed, and free of ambiguity. The task is a standard exercise in nonlinear dynamical systems theory, requiring the application of fundamental definitions of stability. We shall proceed with the analysis.\n\nThe system under consideration is the scalar autonomous ordinary differential equation on $\\mathbb{R}$:\n$$\n\\dot{x} = -x^{3}\n$$\nThe equilibrium point to be analyzed is $x^* = 0$, as $\\dot{x} = 0$ when $x=0$. The analysis will be conducted by examining the properties of the explicit solution to the differential equation, as permitted by the instructions.\n\nFirst, we derive the closed-form solution for an initial condition $x(0) = x_0$. For $x_0 \\neq 0$, the equation is separable:\n$$\n\\frac{dx}{x^3} = -dt\n$$\nIntegrating both sides from the initial state $(0, x_0)$ to a state $(t, x(t))$:\n$$\n\\int_{x_0}^{x(t)} \\xi^{-3} d\\xi = \\int_{0}^{t} -1 d\\tau\n$$\n$$\n\\left[ -\\frac{1}{2\\xi^2} \\right]_{x_0}^{x(t)} = -t\n$$\n$$\n-\\frac{1}{2x(t)^2} + \\frac{1}{2x_0^2} = -t\n$$\nRearranging for $x(t)^2$:\n$$\n\\frac{1}{2x(t)^2} = t + \\frac{1}{2x_0^2} = \\frac{2tx_0^2 + 1}{2x_0^2}\n$$\n$$\nx(t)^2 = \\frac{x_0^2}{1 + 2tx_0^2}\n$$\nSince the solution $x(t)$ must have the same sign as the initial condition $x_0$ (because $\\dot{x}$ has the opposite sign of $x$, the trajectory cannot cross the origin), we take the square root preserving the sign:\n$$\nx(t) = \\frac{x_0}{\\sqrt{1 + 2tx_0^2}}\n$$\nThis solution is valid for all $t \\ge 0$ as the denominator is always positive. If $x_0=0$, the solution is trivially $x(t)=0$ for all $t \\ge 0$.\n\nWe now examine each stability property based on its formal definition.\n\n1.  **Lyapunov Stability ($s$)**: The equilibrium $x^*=0$ is Lyapunov stable if for every $\\epsilon  0$, there exists a $\\delta = \\delta(\\epsilon)  0$ such that if $|x_0 - x^*|  \\delta$, then $|x(t) - x^*|  \\epsilon$ for all $t \\ge 0$.\n    For our system, this means if $|x_0|  \\delta$, then $|x(t)|  \\epsilon$ for all $t \\ge 0$.\n    From the solution, we can analyze its magnitude:\n    $$\n    |x(t)| = \\frac{|x_0|}{\\sqrt{1 + 2tx_0^2}}\n    $$\n    For any $t \\ge 0$ and any $x_0 \\in \\mathbb{R}$, the term in the denominator satisfies $\\sqrt{1 + 2tx_0^2} \\ge \\sqrt{1} = 1$.\n    Therefore, for all $t \\ge 0$, we have the inequality:\n    $$\n    |x(t)| \\le |x_0|\n    $$\n    Given any $\\epsilon  0$, we can choose $\\delta = \\epsilon$. If an initial condition satisfies $|x_0|  \\delta = \\epsilon$, it follows directly that $|x(t)| \\le |x_0|  \\epsilon$ for all $t \\ge 0$. The condition for Lyapunov stability is satisfied. Thus, $s=1$.\n\n2.  **Asymptotic Stability ($a$)**: The equilibrium $x^*=0$ is asymptotically stable if it is Lyapunov stable and attractive. Attractivity requires that there exists a $\\delta_{attr}  0$ such that if $|x_0 - x^*|  \\delta_{attr}$, then $\\lim_{t \\to \\infty} x(t) = x^*$.\n    We have already established Lyapunov stability. We now check for attractivity. We compute the limit of the solution as $t \\to \\infty$:\n    $$\n    \\lim_{t \\to \\infty} x(t) = \\lim_{t \\to \\infty} \\frac{x_0}{\\sqrt{1 + 2tx_0^2}}\n    $$\n    For any $x_0 \\neq 0$, the denominator $\\sqrt{1+2tx_0^2}$ grows without bound as $t \\to \\infty$. Consequently, the fraction approaches zero. For $x_0=0$, the limit is trivially $0$.\n    $$\n    \\lim_{t \\to \\infty} x(t) = 0\n    $$\n    This convergence to the origin occurs for any initial condition $x_0 \\in \\mathbb{R}$. We can therefore choose any $\\delta_{attr}  0$. The equilibrium is attractive.\n    Since the equilibrium is both Lyapunov stable and attractive, it is asymptotically stable. Thus, $a=1$.\n\n3.  **Exponential Stability ($e$)**: The equilibrium $x^*=0$ is exponentially stable if it is asymptotically stable and there exist constants $\\alpha  0$, $\\lambda  0$, and $\\delta_{exp}  0$ such that for any initial condition satisfying $|x_0 - x^*|  \\delta_{exp}$, the solution satisfies $|x(t) - x^*| \\le \\alpha |x_0 - x^*| \\exp(-\\lambda t)$ for all $t \\ge 0$.\n    For our system, this translates to finding $\\alpha  0$, $\\lambda  0$, $\\delta_{exp}  0$ such that for all $|x_0|  \\delta_{exp}$:\n    $$\n    |x(t)| \\le \\alpha |x_0| \\exp(-\\lambda t)\n    $$\n    Substituting the solution $|x(t)| = |x_0| / \\sqrt{1 + 2tx_0^2}$:\n    $$\n    \\frac{|x_0|}{\\sqrt{1 + 2tx_0^2}} \\le \\alpha |x_0| \\exp(-\\lambda t)\n    $$\n    For $x_0 \\neq 0$, we can divide by $|x_0|$:\n    $$\n    \\frac{1}{\\sqrt{1 + 2tx_0^2}} \\le \\alpha \\exp(-\\lambda t)\n    $$\n    $$\n    \\exp(\\lambda t) \\le \\alpha \\sqrt{1 + 2tx_0^2}\n    $$\n    To establish a contradiction, let us assume such positive constants $\\alpha, \\lambda, \\delta_{exp}$ exist. Choose a fixed initial condition $x_0$ such that $0  |x_0|  \\delta_{exp}$. The inequality must hold for this $x_0$ for all $t \\ge 0$. Let us examine the behavior of both sides as $t \\to \\infty$. The left side, $\\exp(\\lambda t)$, grows exponentially. The right side, $\\alpha \\sqrt{1 + 2tx_0^2}$, grows proportionally to $\\sqrt{t}$. An exponential function will always eventually dominate a square-root function.\n    Formally, consider the limit of the ratio:\n    $$\n    \\lim_{t \\to \\infty} \\frac{\\alpha \\sqrt{1 + 2tx_0^2}}{\\exp(\\lambda t)} = 0\n    $$\n    This implies that for any sufficiently large $t$, $\\exp(\\lambda t)  \\alpha \\sqrt{1 + 2tx_0^2}$, which contradicts the inequality required for exponential stability. The rate of convergence to the origin is algebraic, not exponential. Therefore, the equilibrium is not exponentially stable. Thus, $e=0$.\n\n4.  **Global Asymptotic Stability (GAS) ($g$)**: The equilibrium $x^*=0$ is globally asymptotically stable if it is Lyapunov stable and globally attractive. Global attractivity means that for any initial condition $x_0$ in the entire state space (here, $\\mathbb{R}$), the solution converges to the equilibrium: $\\lim_{t \\to \\infty} x(t) = x^*$.\n    We have already established Lyapunov stability. In our analysis for asymptotic stability, we demonstrated that $\\lim_{t \\to \\infty} x(t) = 0$ for *any* initial condition $x_0 \\in \\mathbb{R}$. This is precisely the definition of global attractivity.\n    Since the equilibrium is Lyapunov stable and globally attractive, it is globally asymptotically stable. Thus, $g=1$.\n\nThe conclusions for each property are:\n-   Lyapunov stability ($s$): Holds. $s=1$.\n-   Asymptotic stability ($a$): Holds. $a=1$.\n-   Exponential stability ($e$): Does not hold. $e=0$.\n-   Global asymptotic stability ($g$): Holds. $g=1$.\n\nThe resulting vector $\\begin{pmatrix} s  a  e  g \\end{pmatrix}$ is $\\begin{pmatrix} 1  1  0  1 \\end{pmatrix}$.", "answer": "$$\n\\boxed{\\begin{pmatrix} 1  1  0  1 \\end{pmatrix}}\n$$", "id": "2722252"}, {"introduction": "A common misconception is that a non-increasing Lyapunov function guarantees a system will return to its equilibrium. This practice presents a fundamental counterexample—the simple harmonic oscillator—to dismantle that notion [@problem_id:2722281]. By showing that trajectories are stable periodic orbits where $\\dot{V}(x) = 0$, you will learn why the condition $\\dot{V}(x) \\le 0$ is sufficient only for Lyapunov stability and not, in general, for asymptotic stability.", "problem": "Consider the autonomous linear system in the plane with state $x \\in \\mathbb{R}^{2}$ and parameter $\\omega0$:\n$$\n\\dot{x} = A x, \\quad A \\triangleq \\omega \\begin{bmatrix} 0  1 \\\\ -1  0 \\end{bmatrix}.\n$$\nWork only from the core definitions of Lyapunov stability, asymptotic stability, exponential stability, and the LaSalle invariance principle, without invoking any result that presupposes the conclusion. In particular, use the following foundational facts: (i) a continuously differentiable function $V:\\mathbb{R}^{2}\\to\\mathbb{R}$ is said to be positive definite if $V(0)=0$ and $V(x)0$ for all $x\\neq 0$, (ii) the orbital derivative of $V$ along $\\dot{x}=f(x)$ is $\\dot{V}(x) = \\nabla V(x)^{\\top} f(x)$, (iii) the origin is Lyapunov stable if for every $\\varepsilon0$ there exists $\\delta0$ such that $\\|x(0)\\|\\delta$ implies $\\|x(t)\\|\\varepsilon$ for all $t\\ge 0$, (iv) the origin is asymptotically stable if it is Lyapunov stable and, in addition, $\\|x(0)\\|$ sufficiently small implies $\\lim_{t\\to\\infty}x(t)=0$, and (v) the LaSalle invariance principle asserts that if $V$ is positive definite and $\\dot{V}\\le 0$ in a compact forward-invariant set, then all trajectories starting in that set approach the largest invariant subset of $\\{\\dot{V}=0\\}$ contained in it as $t\\to\\infty$. The notion of \"globally asymptotically stable (GAS)\" refers to asymptotic stability with a domain of attraction equal to $\\mathbb{R}^{2}$.\n\nTasks:\n1. Identify an explicit continuously differentiable positive definite function $V(x)$ for the system and compute its orbital derivative $\\dot{V}(x)$ along trajectories. Prove directly from the definitions that the origin is Lyapunov stable for this system.\n2. Using only the LaSalle invariance principle and the structure of the set $\\{\\dot{V}=0\\}$ you obtained, characterize the largest invariant subset of $\\{\\dot{V}=0\\}$ within the closed ball $\\{x\\in\\mathbb{R}^{2}:\\|x\\|\\le R\\}$ for any fixed $R0$. Show rigorously that this largest invariant set contains a nontrivial periodic orbit. Conclude that the origin is not asymptotically stable and hence not globally asymptotically stable.\n3. Let $x(0)=\\begin{bmatrix} r \\\\ 0 \\end{bmatrix}$ with $r0$. Determine the minimal positive period $T$ of the corresponding nontrivial solution $x(t)$ as an exact analytic expression in terms of $\\omega$. Provide only this minimal period as your final answer, in exact form, with no rounding and no units.", "solution": "The problem as stated is scientifically grounded, well-posed, and objective. It is a standard problem in the analysis of linear dynamical systems and presents no internal contradictions or ambiguities. We proceed to the solution.\n\nThe system dynamics are given by $\\dot{x} = Ax$ with $x = \\begin{bmatrix} x_1 \\\\ x_2 \\end{bmatrix} \\in \\mathbb{R}^2$ and $A = \\omega \\begin{bmatrix} 0  1 \\\\ -1  0 \\end{bmatrix}$ for a constant $\\omega  0$. This corresponds to the system of first-order ordinary differential equations:\n$$\n\\begin{cases}\n\\dot{x}_1 = \\omega x_2 \\\\\n\\dot{x}_2 = -\\omega x_1\n\\end{cases}\n$$\n\n**1. Lyapunov Stability Analysis**\n\nTo investigate the stability of the equilibrium at the origin $x=0$, we select a Lyapunov function candidate. A natural choice, motivated by the concept of energy in an analogous physical system (a simple harmonic oscillator), is the quadratic function $V(x) = x_1^2 + x_2^2$.\n\nFirst, it must be verified that this function $V: \\mathbb{R}^2 \\to \\mathbb{R}$ is continuously differentiable and positive definite.\n- The function $V(x) = x_1^2 + x_2^2$ is a polynomial in $x_1$ and $x_2$, so it is continuously differentiable everywhere on $\\mathbb{R}^2$.\n- At the origin, $V(0) = 0^2 + 0^2 = 0$.\n- For any $x \\neq 0$, at least one of its components, $x_1$ or $x_2$, is non-zero. Since the square of any non-zero real number is positive, $V(x) = x_1^2 + x_2^2  0$ for all $x \\neq 0$.\nThus, $V(x)$ is a valid positive definite function.\n\nNext, we compute the orbital derivative, $\\dot{V}(x)$, along the trajectories of the system. The orbital derivative is given by $\\dot{V}(x) = \\nabla V(x)^{\\top} f(x)$, where $f(x) = Ax$.\nThe gradient of $V(x)$ is $\\nabla V(x) = \\begin{bmatrix} 2x_1 \\\\ 2x_2 \\end{bmatrix}$.\nThe vector field is $f(x) = Ax = \\begin{bmatrix} \\omega x_2 \\\\ -\\omega x_1 \\end{bmatrix}$.\nThe orbital derivative is therefore:\n$$\n\\dot{V}(x) = \\begin{bmatrix} 2x_1  2x_2 \\end{bmatrix} \\begin{bmatrix} \\omega x_2 \\\\ -\\omega x_1 \\end{bmatrix} = (2x_1)(\\omega x_2) + (2x_2)(-\\omega x_1) = 2\\omega x_1 x_2 - 2\\omega x_1 x_2 = 0\n$$\nThe orbital derivative $\\dot{V}(x)$ is identically zero for all $x \\in \\mathbb{R}^2$. This means that $V(x(t))$ is constant along any trajectory of the system. Specifically, $V(x(t)) = V(x(0))$ for all $t \\ge 0$. As $V(x) = \\|x\\|^2_2$, this implies that the Euclidean norm of the state vector is conserved: $\\|x(t)\\|_2 = \\|x(0)\\|_2$.\n\nWith this result, we can prove Lyapunov stability of the origin directly from the definition. The definition requires that for every $\\varepsilon  0$, there exists a $\\delta  0$ such that if $\\|x(0)\\|\\delta$, then $\\|x(t)\\|\\varepsilon$ for all $t \\ge 0$.\nLet an arbitrary $\\varepsilon  0$ be given. We must find a suitable $\\delta$. Let us choose $\\delta = \\varepsilon$.\nIf an initial state $x(0)$ satisfies $\\|x(0)\\|  \\delta$, then by our choice of $\\delta$, $\\|x(0)\\|  \\varepsilon$.\nSince we have established that $\\|x(t)\\| = \\|x(0)\\|$ for all $t \\ge 0$, it follows immediately that $\\|x(t)\\|  \\varepsilon$ for all $t \\ge 0$.\nThis satisfies the definition of Lyapunov stability. Therefore, the origin is a stable equilibrium.\n\n**2. Asymptotic Stability and the LaSalle Invariance Principle**\n\nThe origin is asymptotically stable if it is Lyapunov stable and, in addition, trajectories starting sufficiently close to the origin converge to the origin as $t \\to \\infty$. We will use the LaSalle invariance principle to show this is not the case.\n\nThe principle is applied to a compact, forward-invariant set. Let us consider the closed ball of radius $R  0$, defined as $K_R = \\{x \\in \\mathbb{R}^2 : \\|x\\| \\le R\\}$.\n- This set is compact.\n- It is forward-invariant because any trajectory starting in $K_R$ (i.e., $\\|x(0)\\| \\le R$) will satisfy $\\|x(t)\\| = \\|x(0)\\| \\le R$ for all $t \\ge 0$, and thus $x(t)$ remains in $K_R$.\n\nLet $E \\subseteq K_R$ be the set where $\\dot{V}(x) = 0$. Since we found $\\dot{V}(x) = 0$ for all $x \\in \\mathbb{R}^2$, we have $E = K_R$.\nLaSalle's invariance principle states that any trajectory starting in $K_R$ must approach the largest invariant set $M$ contained in $E = K_R$.\n\nWe must characterize this set $M$. An invariant set is a union of complete trajectories. The trajectories of the system are the equilibrium point at the origin $\\{0\\}$ and circles of constant radius $c  0$ centered at the origin, described by $\\{x \\in \\mathbb{R}^2 : \\|x\\| = c\\}$. The largest set composed of such trajectories that is contained within $K_R = \\{x:\\|x\\|\\le R\\}$ is $K_R$ itself. Thus, $M = K_R$.\n\nThe principle implies that trajectories starting in $K_R$ converge to the set $M=K_R$. This set $M=K_R$, for any $R0$, contains infinite nontrivial periodic orbits, namely the circles $\\{x : \\|x\\| = c\\}$ for any $c \\in (0, R]$. For example, the boundary circle $\\{x : \\|x\\| = R\\}$ is a nontrivial periodic orbit within $M$.\n\nFor the origin to be asymptotically stable, any trajectory starting at $x(0)$ in a sufficiently small neighborhood of the origin must satisfy $\\lim_{t \\to \\infty} x(t) = 0$. This would imply that the largest invariant set contained in any sufficiently small neighborhood of the origin is just the singleton set $\\{0\\}$.\nHowever, our analysis shows that for any initial condition $x(0) \\neq 0$, the trajectory remains on the circle of radius $\\|x(0)\\|  0$. The state vector $x(t)$ never approaches the origin. The limit set for such a trajectory is the circle $\\{x : \\|x\\| = \\|x(0)\\|\\}$, not the point $\\{0\\}$. This contradicts the condition for asymptotic stability.\nTherefore, the origin is not asymptotically stable, and by extension, it is not globally asymptotically stable (GAS).\n\n**3. Minimal Period of a Nontrivial Solution**\n\nWe are asked to find the minimal period $T$ of the solution corresponding to the initial condition $x(0) = \\begin{bmatrix} r \\\\ 0 \\end{bmatrix}$ with $r  0$.\nThe system of differential equations is:\n$$\n\\dot{x}_1 = \\omega x_2\n$$\n$$\n\\dot{x}_2 = -\\omega x_1\n$$\nDifferentiating the first equation with respect to time gives $\\ddot{x}_1 = \\omega \\dot{x}_2$. Substituting the second equation yields $\\ddot{x}_1 = \\omega(-\\omega x_1) = -\\omega^2 x_1$. This is the equation of simple harmonic motion, $\\ddot{x}_1 + \\omega^2 x_1 = 0$.\nThe general solution for $x_1(t)$ is $x_1(t) = C_1 \\cos(\\omega t) + C_2 \\sin(\\omega t)$.\nFrom $\\dot{x}_1 = \\omega x_2$, we find $x_2(t) = \\frac{1}{\\omega} \\dot{x}_1(t) = -C_1 \\sin(\\omega t) + C_2 \\cos(\\omega t)$.\nWe apply the initial condition $x(0) = \\begin{bmatrix} r \\\\ 0 \\end{bmatrix}$ to find the constants $C_1$ and $C_2$.\nAt $t=0$:\n$x_1(0) = C_1 \\cos(0) + C_2 \\sin(0) = C_1 = r$.\n$x_2(0) = -C_1 \\sin(0) + C_2 \\cos(0) = C_2 = 0$.\nSo, the particular solution for the given initial condition is:\n$$\nx(t) = \\begin{bmatrix} x_1(t) \\\\ x_2(t) \\end{bmatrix} = \\begin{bmatrix} r \\cos(\\omega t) \\\\ -r \\sin(\\omega t) \\end{bmatrix}\n$$\nThe state $x(t)$ is periodic. We seek the minimal positive period $T$ such that $x(t+T) = x(t)$ for all $t$. This requires:\n$$\n\\cos(\\omega(t+T)) = \\cos(\\omega t) \\quad \\text{and} \\quad \\sin(\\omega(t+T)) = \\sin(\\omega t)\n$$\nThe fundamental period of the standard sine and cosine functions is $2\\pi$. For the above equalities to hold for all $t$, the argument of the functions must differ by an integer multiple of $2\\pi$. That is, $\\omega T = 2\\pi k$ for some non-zero integer $k$.\nThe minimal positive period $T$ corresponds to $k=1$.\n$$\n\\omega T = 2\\pi\n$$\nGiven that $\\omega  0$, we can solve for $T$:\n$$\nT = \\frac{2\\pi}{\\omega}\n$$\nThis is the minimal positive period of the solution.", "answer": "$$\\boxed{\\frac{2\\pi}{\\omega}}$$", "id": "2722281"}, {"introduction": "When $\\dot{V}(x)$ is not strictly negative definite, how can we determine the ultimate fate of system trajectories? This is where the LaSalle Invariance Principle becomes an indispensable tool. This exercise challenges you to apply the principle to a multidimensional system where trajectories converge not to a single point, but to a larger invariant set, demonstrating a more powerful and nuanced application of Lyapunov's second method [@problem_id:2722299].", "problem": "Consider the autonomous nonlinear system in three dimensions\n$$\n\\dot{x}_{1}=-x_{1},\\qquad \\dot{x}_{2}=-x_{2}^{3},\\qquad \\dot{x}_{3}=-x_{1}^{2}x_{3},\n$$\nwith state $x=\\begin{pmatrix}x_{1}x_{2}x_{3}\\end{pmatrix}^{\\top}\\in\\mathbb{R}^{3}$. Let the candidate Lyapunov function be\n$$\nV(x)=\\frac{1}{2}\\left(x_{1}^{2}+x_{2}^{2}+x_{3}^{2}\\right).\n$$\nStarting from the definitions of Lyapunov stability, asymptotic stability, exponential stability, and global asymptotic stability (GAS), and using only fundamental properties of positive definiteness, radial unboundedness, and invariance, do the following:\n\n1) Prove that $V(x)$ is positive definite and radially unbounded, and compute $\\dot{V}(x)$ along trajectories to show that $\\dot{V}(x)\\le 0$ for all $x\\in\\mathbb{R}^{3}$.\n\n2) Characterize the set $\\mathcal{S}=\\{x\\in\\mathbb{R}^{3}:\\dot{V}(x)=0\\}$ as a manifold. Identify the largest invariant subset $\\mathcal{M}\\subseteq\\mathcal{S}$.\n\n3) Using only the core definitions and invariance arguments (without quoting any specific formula), conclude the stability properties of the origin and of the subset $\\mathcal{M}$, in the senses of stability, asymptotic stability, exponential stability, and global asymptotic stability.\n\nAnswer specification: For grading, report only the dimension of the largest invariant subset $\\mathcal{M}$ as a single integer. No units are required. Do not provide any additional text. No rounding is needed.", "solution": "The problem as stated is scientifically grounded, well-posed, objective, and self-contained. It is a valid problem in the domain of control theory, specifically concerning Lyapunov stability analysis. We shall proceed with a formal solution.\n\nThe system dynamics are given by the set of ordinary differential equations:\n$$\n\\dot{x}_{1}=-x_{1}\n$$\n$$\n\\dot{x}_{2}=-x_{2}^{3}\n$$\n$$\n\\dot{x}_{3}=-x_{1}^{2}x_{3}\n$$\nThe state vector is $x=\\begin{pmatrix}x_{1}x_{2}x_{3}\\end{pmatrix}^{\\top}\\in\\mathbb{R}^{3}$. The candidate Lyapunov function is $V(x)=\\frac{1}{2}\\left(x_{1}^{2}+x_{2}^{2}+x_{3}^{2}\\right)$. The origin $x=0$ is clearly an equilibrium point of the system, since $\\dot{x}=0$ when $x=0$.\n\nPart 1: Analysis of the Lyapunov function $V(x)$ and its time derivative $\\dot{V}(x)$.\n\nFirst, we establish that $V(x)$ is positive definite. By its definition, $V(x) = \\frac{1}{2}(x_{1}^{2}+x_{2}^{2}+x_{3}^{2})$. At the origin, $V(0) = \\frac{1}{2}(0^{2}+0^{2}+0^{2}) = 0$. For any state $x \\neq 0$, at least one component $x_i$ is non-zero. Since $x_{i}^{2} \\ge 0$ for any real number $x_i$, the sum $x_{1}^{2}+x_{2}^{2}+x_{3}^{2}$ is strictly positive. Therefore, $V(x)  0$ for all $x \\in \\mathbb{R}^{3} \\setminus \\{0\\}$. This satisfies the definition of a positive definite function.\n\nSecond, we establish that $V(x)$ is radially unbounded. The function is $V(x) = \\frac{1}{2}\\|x\\|_{2}^{2}$, where $\\|x\\|_{2}$ is the Euclidean norm. As $\\|x\\|_{2} \\to \\infty$, it is clear that $V(x) \\to \\infty$. This satisfies the definition of a radially unbounded function.\n\nThird, we compute the time derivative of $V(x)$ along the trajectories of the system. Using the chain rule, $\\dot{V}(x) = \\frac{\\partial V}{\\partial x} \\dot{x} = \\nabla V(x) \\cdot f(x)$, where $f(x)$ is the vector field of the system.\n$$\n\\nabla V(x) = \\begin{pmatrix} \\frac{\\partial V}{\\partial x_{1}}  \\frac{\\partial V}{\\partial x_{2}}  \\frac{\\partial V}{\\partial x_{3}} \\end{pmatrix} = \\begin{pmatrix} x_{1}  x_{2}  x_{3} \\end{pmatrix}\n$$\nThe time derivative is then:\n$$\n\\dot{V}(x) = (x_{1})(\\dot{x}_{1}) + (x_{2})(\\dot{x}_{2}) + (x_{3})(\\dot{x}_{3})\n$$\n$$\n\\dot{V}(x) = (x_{1})(-x_{1}) + (x_{2})(-x_{2}^{3}) + (x_{3})(-x_{1}^{2}x_{3})\n$$\n$$\n\\dot{V}(x) = -x_{1}^{2} - x_{2}^{4} - x_{1}^{2}x_{3}^{2}\n$$\nThe terms $x_{1}^{2}$, $x_{2}^{4}$, and $x_{1}^{2}x_{3}^{2}$ are all non-negative for any $x \\in \\mathbb{R}^{3}$. Thus, their sum is non-negative, and the negative of their sum is non-positive.\n$$\n\\dot{V}(x) = -(x_{1}^{2} + x_{2}^{4} + x_{1}^{2}x_{3}^{2}) \\le 0, \\quad \\forall x \\in \\mathbb{R}^{3}\n$$\nSince $V(x)$ is positive definite and $\\dot{V}(x)$ is negative semi-definite, we can conclude from Lyapunov's second method that the origin is a stable equilibrium point.\n\nPart 2: Characterization of the set where $\\dot{V}(x)=0$ and its largest invariant subset.\n\nWe define the set $\\mathcal{S}$ as the set of all points where the time derivative of the Lyapunov function is zero: $\\mathcal{S} = \\{x \\in \\mathbb{R}^{3} : \\dot{V}(x)=0\\}$.\n$$\n\\dot{V}(x) = -x_{1}^{2} - x_{2}^{4} - x_{1}^{2}x_{3}^{2} = 0\n$$\nSince this is a sum of non-negative terms equalling zero, each term must individually be zero.\n1. $x_{1}^{2} = 0 \\implies x_{1}=0$.\n2. $x_{2}^{4} = 0 \\implies x_{2}=0$.\n3. $x_{1}^{2}x_{3}^{2} = 0$. Since we have already established that $x_{1}=0$, this condition becomes $0 \\cdot x_{3}^{2} = 0$, which is true for any value of $x_{3} \\in \\mathbb{R}$.\n\nThus, the set $\\mathcal{S}$ is characterized by:\n$$\n\\mathcal{S} = \\{x \\in \\mathbb{R}^{3} : x_{1}=0 \\text{ and } x_{2}=0\\}\n$$\nThis set is the $x_{3}$-axis, which is a one-dimensional linear subspace (a manifold) of $\\mathbb{R}^{3}$.\n\nNext, we must find the largest invariant subset $\\mathcal{M}$ contained in $\\mathcal{S}$. A set is invariant if any trajectory that starts in the set remains in the set for all time. Let us consider a trajectory $x(t)$ that starts in $\\mathcal{S}$, i.e., $x(0) = (0, 0, c)$ for some constant $c \\in \\mathbb{R}$. We examine the system dynamics for such a point:\n$$\n\\dot{x}_{1} = -x_{1} \\implies \\dot{x}_{1} = 0 \\text{ if } x_{1}=0\n$$\n$$\n\\dot{x}_{2} = -x_{2}^{3} \\implies \\dot{x}_{2} = 0 \\text{ if } x_{2}=0\n$$\n$$\n\\dot{x}_{3} = -x_{1}^{2}x_{3} \\implies \\dot{x}_{3} = -(0)^{2}x_{3} = 0\n$$\nFor any point on the $x_3$-axis, the vector field is identically zero. This means that any point in $\\mathcal{S}$ is an equilibrium point. A trajectory starting at a point in $\\mathcal{S}$ remains at that point for all time. Consequently, any subset of $\\mathcal{S}$ is an invariant set. The largest invariant subset of $\\mathcal{S}$ is therefore the set $\\mathcal{S}$ itself.\n$$\n\\mathcal{M} = \\mathcal{S} = \\{x \\in \\mathbb{R}^{3} : x_{1}=0, x_{2}=0\\}\n$$\n\nPart 3: Conclusion on stability properties.\n\nSince $V(x)$ is positive definite and radially unbounded, and $\\dot{V}(x) \\le 0$, the Invariance Principle (such as that of LaSalle) applies globally. The principle states that all trajectories in $\\mathbb{R}^{3}$ must converge to the largest invariant set $\\mathcal{M}$ within $\\mathcal{S}$. As we have found, $\\mathcal{M}$ is the entire $x_{3}$-axis.\n\nStability of the origin $x=0$:\n- **Stability**: The origin is stable in the sense of Lyapunov, as established in Part 1.\n- **Asymptotic Stability**: For the origin to be asymptotically stable, trajectories starting near the origin must converge to the origin. However, the invariance principle only guarantees convergence to the set $\\mathcal{M}$. A trajectory may converge to any point on the $x_{3}$-axis, not necessarily the origin $(0,0,0)$. For example, solving the system equations shows that a trajectory starting at $x(0)=(x_{10}, x_{20}, x_{30})$ converges to a point on the $x_3$-axis that is generally not the origin unless $x_{30}=0$. Thus, the origin is **not** asymptotically stable.\n- **Exponential Stability**: Since the origin is not asymptotically stable, it cannot be exponentially stable, which is a stronger condition.\n- **Global Asymptotic Stability (GAS)**: Since the origin is not even locally asymptotically stable, it is not GAS.\n\nStability of the set $\\mathcal{M}$:\nThe invariance principle states that for any initial condition $x(0) \\in \\mathbb{R}^{3}$, the resulting trajectory $x(t)$ approaches $\\mathcal{M}$ as $t \\to \\infty$. This means the set $\\mathcal{M}$ is globally attractive. Furthermore, trajectories do not move away from the set $\\mathcal{M}$. The distance from a point $x$ to the set $\\mathcal{M}$ is $d(x,\\mathcal{M}) = \\sqrt{x_{1}^{2}+x_{2}^{2}}$. The derivative of the squared distance is $\\frac{d}{dt}(x_{1}^{2}+x_{2}^{2}) = 2x_{1}\\dot{x}_{1} + 2x_{2}\\dot{x}_{2} = -2x_{1}^{2} - 2x_{2}^{4} \\le 0$. This confirms that the distance to the set $\\mathcal{M}$ is non-increasing, which implies that $\\mathcal{M}$ is stable in the sense of Lyapunov. Since $\\mathcal{M}$ is Lyapunov stable and globally attractive, the set $\\mathcal{M}$ is globally asymptotically stable.\n\nThe problem asks for the dimension of the largest invariant subset $\\mathcal{M}$. As determined, $\\mathcal{M}$ is the $x_{3}$-axis, which is a line. A line is a manifold of dimension $1$.", "answer": "$$\\boxed{1}$$", "id": "2722299"}]}