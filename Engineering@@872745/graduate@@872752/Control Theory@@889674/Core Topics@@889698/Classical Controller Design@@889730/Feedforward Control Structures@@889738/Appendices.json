{"hands_on_practices": [{"introduction": "In many control systems, the response to reference commands and the response to disturbances are governed by different transfer functions. This practice explores a fundamental two-degree-of-freedom control strategy where a prefilter, or feedforward controller, is designed to shape the reference tracking response independently of the feedback controller. You will derive a prefilter that forces a closed-loop system to mimic a canonical second-order response, a core technique for achieving desired performance metrics like rise time and overshoot [@problem_id:2708599].", "problem": "Consider a unity-feedback single-input single-output loop with a prefilter. The plant is given by the strictly proper, stable transfer function $G(s)=\\dfrac{10}{(s+1)(s+2)}$. The controller is purely proportional, $C(s)=k$ with $k>0$, and the prefilter $F(s)$ is placed in series with the external reference signal before the summing junction. Assume internal stability of the feedback interconnection with $k>0$.\n\nStarting from first principles (the Laplace-domain interconnection equations for the standard unity-feedback loop with a prefilter), derive the reference-to-output transfer function $Y(s)/R(s)$ and use it to design a proper, causal prefilter $F(s)$ such that the overall reference-to-output transfer function equals the canonical second-order form with prescribed positive damping ratio $\\zeta$ and natural frequency $\\omega_n>0$, namely\n$$\n\\frac{Y(s)}{R(s)}=\\frac{\\omega_n^2}{s^2+2\\zeta \\omega_n s+\\omega_n^2}.\n$$\nExpress your final $F(s)$ as a single rational function of $s$ in closed form in terms of $k$, $\\zeta$, and $\\omega_n$. State any conditions on the parameters that ensure $F(s)$ is causal and internally stabilizing when interconnected with the given loop. No numerical evaluation is required. The final answer must be a single closed-form analytic expression for $F(s)$.", "solution": "The problem statement is subjected to validation and is found to be valid. It is a well-posed problem in classical control theory, free of scientific or logical inconsistencies. We shall proceed with the derivation.\n\nThe system described is a single-input, single-output (SISO) feedback control loop with a prefilter. The interconnections between the components are defined by the following Laplace-domain equations, which constitute the first principles of this system's analysis:\n$1$. The output of the plant is $Y(s) = G(s)U(s)$, where $Y(s)$ is the Laplace transform of the output signal and $U(s)$ is the transform of the control input.\n$2$. The control input is generated by the controller, $U(s) = C(s)E(s)$, where $E(s)$ is the transform of the error signal.\n$3$. The error signal is formed at the summing junction, $E(s) = R'(s) - Y(s)$, where the system has unity feedback.\n$4$. The signal $R'(s)$ is the output of the prefilter $F(s)$ acting on the external reference signal $R(s)$, so $R'(s) = F(s)R(s)$.\n\nTo derive the reference-to-output transfer function, $\\frac{Y(s)}{R(s)}$, we substitute these equations systematically.\nStarting with $Y(s)=G(s)U(s)$, we substitute the expression for $U(s)$:\n$$Y(s) = G(s)C(s)E(s)$$\nNext, we substitute the expression for $E(s)$:\n$$Y(s) = G(s)C(s) \\left( F(s)R(s) - Y(s) \\right)$$\nExpanding the right-hand side gives:\n$$Y(s) = G(s)C(s)F(s)R(s) - G(s)C(s)Y(s)$$\nTo solve for $Y(s)$ in terms of $R(s)$, we group all terms involving $Y(s)$ on one side of the equation:\n$$Y(s) + G(s)C(s)Y(s) = G(s)C(s)F(s)R(s)$$\n$$Y(s) \\left( 1 + G(s)C(s) \\right) = G(s)C(s)F(s)R(s)$$\nThe overall transfer function from the reference $R(s)$ to the output $Y(s)$ is therefore:\n$$\\frac{Y(s)}{R(s)} = \\frac{C(s)G(s)}{1 + C(s)G(s)} F(s)$$\nThis equation shows that the overall system response is the product of the closed-loop transfer function of the feedback system (without the prefilter) and the prefilter transfer function. Let us denote the closed-loop transfer function as $T_{CL}(s) = \\frac{C(s)G(s)}{1 + C(s)G(s)}$.\n\nNow, we substitute the given expressions for the plant $G(s) = \\frac{10}{(s+1)(s+2)}$ and the controller $C(s)=k$.\nThe loop transfer function is $L(s) = C(s)G(s) = \\frac{10k}{(s+1)(s+2)} = \\frac{10k}{s^2+3s+2}$.\nThe closed-loop transfer function $T_{CL}(s)$ is:\n$$T_{CL}(s) = \\frac{L(s)}{1+L(s)} = \\frac{\\frac{10k}{s^2+3s+2}}{1 + \\frac{10k}{s^2+3s+2}} = \\frac{10k}{s^2+3s+2 + 10k}$$\nThe problem requires the overall reference-to-output transfer function to match the canonical second-order form:\n$$\\frac{Y(s)}{R(s)} = \\frac{\\omega_n^2}{s^2+2\\zeta \\omega_n s+\\omega_n^2}$$\nwhere $\\zeta>0$ and $\\omega_n>0$. Let this target transfer function be denoted by $T_{target}(s)$.\nWe have the relationship $T_{target}(s) = T_{CL}(s) F(s)$. To find the prefilter $F(s)$ that achieves this, we solve for $F(s)$:\n$$F(s) = \\frac{T_{target}(s)}{T_{CL}(s)}$$\nSubstituting the expressions for $T_{target}(s)$ and $T_{CL}(s)$:\n$$F(s) = \\frac{\\frac{\\omega_n^2}{s^2+2\\zeta \\omega_n s+\\omega_n^2}}{\\frac{10k}{s^2+3s+2+10k}}$$\nThis simplifies to:\n$$F(s) = \\frac{\\omega_n^2}{10k} \\cdot \\frac{s^2+3s+2+10k}{s^2+2\\zeta \\omega_n s+\\omega_n^2}$$\nThis is the required expression for the prefilter $F(s)$.\n\nWe must now analyze the conditions for causality and stability.\nA rational transfer function is causal if the degree of its numerator polynomial is less than or equal to the degree of its denominator polynomial. For our derived $F(s)$, the numerator is a second-degree polynomial in $s$, and the denominator is also a second-degree polynomial in $s$. Since the degrees are equal, the transfer function is proper, and therefore causal. This holds for all finite, non-zero values of the parameters, so no additional conditions are required for causality.\n\nFor stability, we must consider the stability of the entire system. The prefilter $F(s)$ is in a feedforward path and does not alter the characteristic equation of the feedback loop. The stability of the overall system is determined by the poles of the feedback loop and the poles of the prefilter itself.\nThe poles of the feedback loop are the roots of its characteristic equation, $1+L(s)=0$, which is $s^2+3s+2+10k=0$. For this quadratic polynomial, the poles are in the left-half of the complex plane if and only if all coefficients are positive. The coefficients are $1$, $3$, and $2+10k$. Given the constraint $k>0$, the coefficient $2+10k$ is strictly positive. Thus, the feedback loop is internally stable for all $k>0$, as assumed in the problem statement.\nThe poles of the prefilter $F(s)$ are the roots of its denominator, $s^2+2\\zeta \\omega_n s+\\omega_n^2=0$. The problem specifies that $\\zeta>0$ and $\\omega_n>0$. Consequently, all coefficients of this polynomial ($1$, $2\\zeta\\omega_n$, and $\\omega_n^2$) are strictly positive. Therefore, the poles of $F(s)$ are in the left-half plane, and $F(s)$ is a stable transfer function.\nThe prefilter cancels the stable poles of the closed-loop system and replaces them with the desired stable poles of the canonical second-order system. Since the canceled poles are stable, this cancellation does not introduce internal instability.\nIn summary, the conditions given in the problem statement, namely $k>0$, $\\zeta>0$, and $\\omega_n>0$, are sufficient to ensure both the causality of $F(s)$ and the stability of the overall interconnected system. No further conditions are necessary.\nThe final closed-form expression for $F(s)$ is:\n$$F(s) = \\frac{\\omega_n^2(s^2+3s+2+10k)}{10k(s^2+2\\zeta \\omega_n s+\\omega_n^2)}$$", "answer": "$$ \\boxed{ \\frac{\\omega_n^2(s^2+3s+2+10k)}{10k(s^2+2\\zeta \\omega_n s+\\omega_n^2)} } $$", "id": "2708599"}, {"introduction": "Beyond shaping reference responses, a primary application of feedforward control is to counteract the effects of measurable disturbances before they can corrupt the system output. This practice challenges you to distinguish between a true feedforward structure for disturbance rejection and a feedback structure for dead-time compensation, the Smith predictor, which is often a source of confusion. By analyzing the system's block diagram and transfer functions, you will identify the correct design for a disturbance-canceling feedforward controller and grapple with the fundamental constraint of causality [@problem_id:2708598].", "problem": "Consider a single-input single-output linear time-invariant (LTI) plant with a pure input-output dead-time. The true plant from the actuator effort to the measured output is modeled as $P(s) = P_0(s)\\,e^{-s\\theta}$, where $P_0(s)$ is a strictly proper, stable, minimum-phase transfer function and $\\theta > 0$ is a known constant dead-time. A controller $C(s)$ is implemented using the Smith predictor architecture with an internal model $\\hat P_0(s)$ and the same known delay $e^{-s\\theta}$. The Smith predictor constructs a delay-free pseudo-output by combining the measured output and the model response so that the controller $C(s)$ operates as if the delay were not present in the feedback path.\n\nAdditionally, an input disturbance enters additively at the same physical summing node as the controller output before the plant dynamics. Specifically, the actuator input is $u_{\\mathrm{act}}(s) = u(s) + H(s)\\,d(s)$, where $u(s)$ is the control signal, $d(s)$ is an exogenous disturbance, and $H(s)$ is a known, stable transfer function modeling the disturbance path to the actuator summing node. A measured disturbance proxy $d_m(s)$ is available and related to $d(s)$ by $d_m(s) = M(s)\\,e^{-s\\theta_m}\\,d(s)$, where $M(s)$ is a known, stable, invertible transfer function and $\\theta_m \\ge 0$ is a known sensor/transport delay in the measurement channel. You may assume that $M(s)$ and $H(s)$ are proper and that $M(s)$ is minimum-phase so that $M(s)^{-1}$ is stable.\n\nA measured-disturbance feedforward path $u_f(s) = F(s)\\,d_m(s)$ is to be added in parallel with the feedback controller, summed at the same actuator summing node as $u(s)$ and $H(s)\\,d(s)$. The design objective for $F(s)$ is to cancel, as nearly as possible, the effect of $d(s)$ on the output $y(s)$, while preserving the nominal Smith predictor properties of the feedback loop.\n\nFrom first principles of block-diagram algebra, the Laplace-domain representation of time delay by $e^{-s\\theta}$, and the standard definition of the closed-loop characteristic equation as the denominator of the reference-to-output transfer function under unity feedback interconnection, select all statements below that are correct.\n\nA. A Smith predictor is a feedforward controller because it uses a process model to predict the delayed output and injects a control signal that cancels the delay ahead of time; therefore, it replaces feedback rather than restructuring it.\n\nB. Under exact model matching $\\hat P_0(s) = P_0(s)$, the Smith predictor removes the explicit factor $e^{-s\\theta}$ from the closed-loop characteristic equation of the feedback loop, but the reference-to-output transfer function still contains the true plant delay $e^{-s\\theta}$ as a factor in its numerator.\n\nC. To cancel the disturbance at the plant output using the measured proxy $d_m(s)$, the ideal feedforward is $F(s) = -\\,P_0(s)^{-1}\\,e^{+s\\theta}\\,H(s)\\,M(s)^{-1}\\,e^{+s\\theta_m}$ so that the feedforward path inverts the dead-time and the delay-free plant to align and cancel the disturbance downstream.\n\nD. If the control and disturbance enter at the same actuator summing node upstream of the same plant dead-time, and if model knowledge is exact, then ignoring the feedback loop for the purpose of feedforward design, the disturbance-canceling choice is $F(s) = -\\,H(s)\\,M(s)^{-1}\\,e^{+s\\theta_m}$; this is causal only if the measured proxy provides at least $\\theta_m$ seconds of preview relative to the disturbance reaching the actuator summing node.\n\nE. Adding a properly summed measured-disturbance feedforward path $u_f(s) = F(s)\\,d_m(s)$ to a Smith-predictor-regulated system necessarily alters the closed-loop characteristic equation by reintroducing $e^{-s\\theta}$ into the denominator, with a risk of destabilizing the predictor.\n\nSelect all correct options.", "solution": "The problem statement will first be validated, and then a solution will be derived from first principles.\n\n### Problem Validation\n\n**Step 1: Extract Givens**\n\n-   Plant model: $P(s) = P_0(s)e^{-s\\theta}$\n-   Plant properties: $P_0(s)$ is a strictly proper, stable, minimum-phase transfer function. $\\theta > 0$ is a known constant dead-time.\n-   Controller: $C(s)$ in a Smith predictor architecture.\n-   Internal model: $\\hat{P}(s) = \\hat{P}_0(s)e^{-s\\theta}$.\n-   Disturbance model: Input disturbance $d(s)$ enters at the actuator. Total actuator input is $u_{\\mathrm{act}}(s) = u(s) + H(s)d(s)$, where $u(s)$ is the control signal. $H(s)$ is a known, stable transfer function.\n-   Measured disturbance proxy: $d_m(s) = M(s)e^{-s\\theta_m}d(s)$.\n-   Measurement channel properties: $M(s)$ is a known, stable, invertible, minimum-phase transfer function. $M(s)$ and $H(s)$ are proper. $\\theta_m \\ge 0$ is a known delay.\n-   Feedforward controller: $u_f(s) = F(s)d_m(s)$ is added at the actuator summing node.\n-   Final actuator input: $u_{\\mathrm{act}}(s) = u(s) + u_f(s) + H(s)d(s)$.\n-   Design objective: $F(s)$ should cancel the effect of $d(s)$ on the output $y(s)$.\n-   Characteristic equation definition: The denominator of the reference-to-output transfer function.\n\n**Step 2: Validate Using Extracted Givens**\n\nThe problem describes a classic, albeit advanced, control systems design scenario involving a Smith predictor for dead-time compensation and a feedforward controller for disturbance rejection. All components and concepts—LTI systems, transfer functions, dead-time, Smith predictors, feedforward control, stability, causality—are standard elements of control theory.\n\n-   **Scientifically Grounded:** The problem is firmly based on established principles of linear control theory. The setup is realistic for process control applications. No scientific or factual unsoundness is present.\n-   **Well-Posed:** The problem provides sufficient information to derive the required transfer functions and analyze the system's properties. The questions posed in the options are specific and can be answered rigorously.\n-   **Objective:** The language is precise and technical. No subjective or ambiguous statements are used in the problem setup.\n-   **Other Flaws:** The problem is self-contained, consistent, and does not exhibit any of the other invalidity flags (unrealistic, ill-posed, trivial, etc.).\n\n**Step 3: Verdict and Action**\n\nThe problem statement is **valid**. A solution can be derived.\n\n### Derivation and Option Analysis\n\nLet $r(s)$ be the reference input. In a Smith predictor architecture, the feedback controller $C(s)$ acts on an error signal $e_{sp}(s) = r(s) - y_{sp}(s)$, where $y_{sp}(s)$ is a delay-compensated pseudo-output. The control signal from the feedback path is $u(s) = C(s)(r(s) - y_{sp}(s))$. The pseudo-output is constructed as $y_{sp}(s) = y(s) + (\\hat{P}_0(s) - \\hat{P}(s))u(s) = y(s) + \\hat{P}_0(s)(1 - e^{-s\\theta})u(s)$.\n\nThe plant output is $y(s) = P(s)u_{\\mathrm{act}}(s) = P_0(s)e^{-s\\theta}[u(s) + u_f(s) + H(s)d(s)]$.\n\nWe are given to assume exact model matching, so $\\hat{P}_0(s) = P_0(s)$. Substituting this and the expression for $y(s)$ into the equation for $u(s)$:\n$u(s) = C(s) \\left[ r(s) - \\left( P_0(s)e^{-s\\theta}[u(s) + u_f(s) + H(s)d(s)] + P_0(s)(1 - e^{-s\\theta})u(s) \\right) \\right]$\n$u(s) = C(s) \\left[ r(s) - P_0(s)e^{-s\\theta}u(s) - P_0(s)e^{-s\\theta}(u_f(s) + H(s)d(s)) - P_0(s)u(s) + P_0(s)e^{-s\\theta}u(s) \\right]$\n$u(s) = C(s) \\left[ r(s) - P_0(s)u(s) - P_0(s)e^{-s\\theta}(u_f(s) + H(s)d(s)) \\right]$\nSolving for $u(s)$:\n$u(s) [1 + C(s)P_0(s)] = C(s)r(s) - C(s)P_0(s)e^{-s\\theta}[u_f(s) + H(s)d(s)]$\n$u(s) = \\frac{C(s)}{1 + C(s)P_0(s)}r(s) - \\frac{C(s)P_0(s)e^{-s\\theta}}{1 + C(s)P_0(s)}[u_f(s) + H(s)d(s)]$\n\nNow we find the plant output $y(s)$:\n$y(s) = P_0(s)e^{-s\\theta}[u(s) + u_f(s) + H(s)d(s)]$\nSubstitute the expression for $u(s)$:\n$y(s) = P_0(s)e^{-s\\theta}\\left[ \\frac{C(s)}{1+C(s)P_0(s)}r(s) - \\frac{C(s)P_0(s)e^{-s\\theta}}{1+C(s)P_0(s)}[u_f(s) + H(s)d(s)] + [u_f(s) + H(s)d(s)] \\right]$\n$y(s) = \\frac{C(s)P_0(s)e^{-s\\theta}}{1+C(s)P_0(s)}r(s) + P_0(s)e^{-s\\theta}\\left[1 - \\frac{C(s)P_0(s)e^{-s\\theta}}{1+C(s)P_0(s)}\\right][u_f(s) + H(s)d(s)]$\n\n**A. Evaluation of Option A**\nThe statement claims a Smith predictor is a feedforward controller that replaces feedback. This is fundamentally incorrect. The Smith predictor is a model-based *feedback* control strategy. Its structure is explicitly a feedback loop, where the controller output $u(s)$ depends on the error between the reference $r(s)$ and a signal $y_{sp}(s)$ derived from the plant output $y(s)$. It does not replace feedback; it restructures the feedback loop to improve performance for systems with dead-time. The \"prediction\" is internal to the feedback compensator to effectively remove the delay from the characteristic equation, not to operate in an open-loop fashion.\n**Verdict: Incorrect**\n\n**B. Evaluation of Option B**\nFrom the derived expression for $y(s)$, the reference-to-output transfer function $G_{yr}(s)$ is:\n$$G_{yr}(s) = \\frac{y(s)}{r(s)} = \\frac{C(s)P_0(s)e^{-s\\theta}}{1+C(s)P_0(s)}$$\nThe closed-loop characteristic equation is obtained by setting the denominator of this transfer function to zero:\n$$1 + C(s)P_0(s) = 0$$\nThis equation does not contain the dead-time term $e^{-s\\theta}$, which confirms the first part of the statement. The Smith predictor effectively makes the feedback loop behave as if it were controlling the delay-free plant $P_0(s)$.\nHowever, the numerator of the transfer function $G_{yr}(s)$ clearly contains the factor $e^{-s\\theta}$. This means the overall closed-loop response to a reference change will still exhibit the full plant dead-time $\\theta$, which is physically unavoidable. Both parts of the statement are true.\n**Verdict: Correct**\n\n**C. Evaluation of Option C**\nThe objective of the feedforward controller $F(s)$ is to cancel the effect of the disturbance $d(s)$ on the output $y(s)$. A standard principle in feedforward design is to analyze the disturbance paths independent of the feedback loop, as feedback is intended to correct for residual errors. The disturbance $d(s)$ affects the output $y(s)$ through two paths:\n1. The direct disturbance path: $d(s) \\rightarrow H(s) \\rightarrow u_{\\mathrm{act}}(s) \\rightarrow P(s) \\rightarrow y(s)$. Contribution: $P(s)H(s)d(s)$.\n2. The feedforward control path: $d(s) \\rightarrow M(s)e^{-s\\theta_m} \\rightarrow d_m(s) \\rightarrow F(s) \\rightarrow u_f(s) \\rightarrow u_{\\mathrm{act}}(s) \\rightarrow P(s) \\rightarrow y(s)$. Contribution: $P(s)F(s)M(s)e^{-s\\theta_m}d(s)$.\n\nFor perfect cancellation, the sum of these contributions must be zero:\n$P(s)H(s)d(s) + P(s)F(s)M(s)e^{-s\\theta_m}d(s) = 0$\nAs $P(s)$ is not identically zero, we can divide by it:\n$H(s) + F(s)M(s)e^{-s\\theta_m} = 0$\nSolving for the ideal feedforward controller $F(s)$:\n$$F(s) = -H(s)M(s)^{-1}e^{+s\\theta_m}$$\nThe formula presented in option C, $F(s) = -P_0(s)^{-1}e^{+s\\theta}H(s)M(s)^{-1}e^{+s\\theta_m}$, is incorrect. It attempts to invert the plant dynamics $P_0(s)e^{-s\\theta}$, which is not necessary since both the disturbance and the control action pass through the same plant. Furthermore, because $P_0(s)$ is strictly proper, its inverse $P_0(s)^{-1}$ is improper and thus not physically realizable. The term $e^{+s\\theta}$ is also non-causal.\n**Verdict: Incorrect**\n\n**D. Evaluation of Option D**\nThis option correctly states the principle of ignoring the feedback loop for feedforward design. As derived for option C, the ideal disturbance-canceling choice of $F(s)$ is indeed:\n$$F(s) = -H(s)M(s)^{-1}e^{+s\\theta_m}$$\nThis confirms the first part of the statement. The second part discusses causality. The transfer function $F(s)$ contains the term $e^{+s\\theta_m}$. In the time domain, this corresponds to a time advance of $\\theta_m$. If $\\theta_m > 0$, this operation is non-causal, as it requires future values of its input signal. An LTI system with transfer function $F(s)$ is causal if and only if its impulse response $f(t)$ is zero for all $t  0$. The presence of $e^{+s\\theta_m}$ for $\\theta_m > 0$ will make $f(t)$ non-zero for $t  0$. Therefore, for $\\theta_m > 0$, $F(s)$ is a non-causal transfer function. Such a controller can only be implemented if a preview of its input signal is available. The statement says that $F(s)$ is causal \"only if the measured proxy provides at least $\\theta_m$ seconds of preview relative to the disturbance reaching the actuator summing node\". A non-causal controller is made implementable with preview. The phrasing is slightly informal but captures the correct physical requirement.\n**Verdict: Correct**\n\n**E. Evaluation of Option E**\nThe characteristic equation of the closed-loop system determines its stability. As defined in the problem and derived for option B, the characteristic equation is the denominator of the reference-to-output transfer function, which is $1+C(s)P_0(s)=0$. This derivation was performed on the full system including the feedforward path $u_f(s)=F(s)d_m(s)$. The feedforward controller $F(s)$ and the disturbance signal $d_m(s)$ do not appear in the characteristic equation. This is a fundamental property of LTI systems: a feedforward path, which takes an external signal and adds its output to the control signal, does not alter the poles of the closed-loop system and therefore does not affect its stability. The stability is determined by the feedback loop structure itself. The statement that adding the feedforward path \"necessarily alters the closed-loop characteristic equation\" is false.\n**Verdict: Incorrect**", "answer": "$$\\boxed{BD}$$", "id": "2708598"}, {"introduction": "The theoretical ideal for a feedforward controller is often the inverse of the plant dynamics, which would perfectly cancel the plant's effect and allow direct command of the output. This hands-on programming exercise guides you through the practical task of computing a stable, approximate inverse using a Finite Impulse Response (FIR) filter for a discrete-time system. By formulating and solving the least-squares problem, you will not only design the controller but also investigate crucial real-world issues such as numerical stability and the fundamental limitations imposed by non-minimum phase systems [@problem_id:2708583].", "problem": "Consider a single-input single-output discrete-time linear time-invariant system with transfer function $G(z)$ given in the $z^{-1}$-polynomial form $G(z) = \\dfrac{B(z^{-1})}{A(z^{-1})}$, where $B(z^{-1}) = \\sum_{k=0}^{n_b} b_k z^{-k}$ and $A(z^{-1}) = \\sum_{k=0}^{n_a} a_k z^{-k}$ with $a_0 = 1$. Let $g[n]$ denote the causal impulse response of $G(z)$ for $n \\ge 0$, defined by applying the unit impulse input $u[n]$ to the system and assuming zero initial conditions, where $u[0] = 1$ and $u[n] = 0$ for $n \\ge 1$. The impulse response is generated by the linear difference equation $y[n] = - \\sum_{i=1}^{n_a} a_i y[n-i] + \\sum_{j=0}^{n_b} b_j u[n-j]$ for $n \\ge 0$ with $y[n] = 0$ for $n  0$.\n\nYou are to design a finite impulse response (FIR) feedforward inverse $H(z) = \\sum_{m=0}^{M-1} h_m z^{-m}$ that approximates a pure delay of $d$ samples over a finite time horizon $\\{0,1,\\dots,N\\}$ in the least-squares sense. Specifically, let $y[n] = (g * h)[n]$ be the convolution of $g[n]$ and $h[n] = \\sum_{m=0}^{M-1} h_m \\delta[n-m]$, and let $r[n] = \\delta[n-d]$ for $n \\in \\{0,1,\\dots,N\\}$. Formulate the least-squares problem to choose $h_0,\\dots,h_{M-1}$ that minimizes $\\sum_{n=0}^{N} (y[n] - r[n])^2$, derive the first-order optimality conditions from this objective using standard calculus of variations for quadratic forms, and show that the resulting linear system has a Toeplitz structure that stems from time-invariance and convolution. Your program must then implement the following computational steps from first principles:\n\n- Given coefficient arrays $\\{b_k\\}_{k=0}^{n_b}$ and $\\{a_k\\}_{k=0}^{n_a}$ with $a_0 = 1$, compute the causal impulse response samples $\\{g[n]\\}_{n=0}^{N}$ using the linear difference equation with the impulse input, in double precision.\n- Construct the convolution matrix $\\mathbf{C} \\in \\mathbb{R}^{(N+1) \\times M}$ that maps the FIR coefficients $\\mathbf{h} \\in \\mathbb{R}^{M}$ to the truncated convolution output $\\mathbf{y} \\in \\mathbb{R}^{N+1}$, where $\\mathbf{C}[n,m] = g[n-m]$ for $n \\ge m$ and $\\mathbf{C}[n,m] = 0$ otherwise, for all $n \\in \\{0,\\dots,N\\}$ and all $m \\in \\{0,\\dots,M-1\\}$.\n- Form the desired vector $\\mathbf{r} \\in \\mathbb{R}^{N+1}$ with $\\mathbf{r}[n] = 1$ if $n = d$ and $\\mathbf{r}[n] = 0$ otherwise.\n- Solve the system implied by the stationarity conditions for the least-squares objective using the Toeplitz normal equations associated with $\\mathbf{C}$ to obtain $\\mathbf{h}$.\n- Compute and report the following quantitative diagnostics for each test case:\n  - The Euclidean norm of the residual $\\lVert \\mathbf{C}\\mathbf{h} - \\mathbf{r} \\rVert_2$.\n  - The $2$-norm condition number of $\\mathbf{C}$, denoted $\\kappa_2(\\mathbf{C})$.\n  - The $2$-norm condition number of the normal matrix $\\mathbf{C}^\\top \\mathbf{C}$, denoted $\\kappa_2(\\mathbf{C}^\\top \\mathbf{C})$.\n  - A boolean indicating whether $G(z)$ is minimum-phase, determined by checking that all zeros of $G(z)$ lie strictly inside the open unit disk in the $z$-plane. Compute the zeros in the $z$-plane by first finding the roots $\\{q_i\\}$ of $B(q)$ with $q = z^{-1}$ and then mapping to $z_i = 1/q_i$ for each root. Treat the case of a constant $B$ (no zeros) as minimum-phase by convention.\n\nYour program must use the following fixed test suite of parameter values, listed as tuples $\\big(\\{b_k\\}, \\{a_k\\}, N, M, d\\big)$:\n\n- Test $1$: $\\big([1.0, 0.5], [1.0, -0.6], 60, 10, 5\\big)$.\n- Test $2$: $\\big([1.0, -1.1], [1.0, -0.5], 60, 10, 5\\big)$.\n- Test $3$: $\\big([1.0, -0.99], [1.0, -0.6], 60, 10, 5\\big)$.\n- Test $4$: $\\big([1.0, 0.0, 0.4], [1.0, -1.5, 0.7], 80, 12, 6\\big)$.\n- Test $5$: $\\big([1.0, 0.2], [1.0, -0.3], 5, 1, 0\\big)$.\n\nFor each test, compute the requested diagnostics using double precision and produce the following outputs:\n\n- The residual norm $\\lVert \\mathbf{C}\\mathbf{h} - \\mathbf{r} \\rVert_2$, rounded to six decimal places.\n- The condition number $\\kappa_2(\\mathbf{C})$, rounded to six decimal places.\n- The condition number $\\kappa_2(\\mathbf{C}^\\top \\mathbf{C})$, rounded to six decimal places.\n- The minimum-phase boolean for $G(z)$.\n\nYour program should produce a single line of output containing the results as a comma-separated list of per-test sublists in the exact order of the test suite, where each sublist has the form $[\\text{residual\\_norm}, \\text{cond\\_C}, \\text{cond\\_normal}, \\text{is\\_min\\_phase}]$. For example, the output format must be of the form $[[x_{1},y_{1},z_{1},b_{1}],[x_{2},y_{2},z_{2},b_{2}],\\dots]$. No physical units are involved in this problem, and all angles are to be treated as pure numbers in radians if they arise internally.", "solution": "The problem statement constitutes a well-posed and standard task in the field of digital control and signal processing: the design of a Finite Impulse Response (FIR) filter to approximate the inverse of a given Linear Time-Invariant (LTI) system. The problem is scientifically grounded, objective, and provides all necessary information for a unique solution. Therefore, it is deemed valid, and we proceed with the derivation and solution.\n\nThe core of the problem is to find the coefficients $\\mathbf{h} = [h_0, h_1, \\dots, h_{M-1}]^\\top$ of an FIR filter $H(z) = \\sum_{m=0}^{M-1} h_m z^{-m}$ that minimizes a least-squares error criterion. The goal is for the combination of the system $G(z)$ and the filter $H(z)$ to behave like a pure delay of $d$ samples.\n\nLet $g[n]$ be the impulse response of the system $G(z) = \\frac{B(z^{-1})}{A(z^{-1})}$. The output of the cascaded system $G(z)H(z)$ to a unit impulse input is given by the convolution $y[n] = (g * h)[n]$, where $h[n]$ are the FIR filter coefficients. This can be written as:\n$$\ny[n] = \\sum_{m=0}^{M-1} h_m g[n-m]\n$$\nThe desired response is a delayed impulse, $r[n] = \\delta[n-d]$. We seek to minimize the sum of squared errors over a finite horizon $n \\in \\{0, 1, \\dots, N\\}$:\n$$\nJ(\\mathbf{h}) = \\sum_{n=0}^{N} (y[n] - r[n])^2\n$$\nThis problem can be formulated in matrix-vector terms. Let $\\mathbf{y} = [y[0], \\dots, y[N]]^\\top \\in \\mathbb{R}^{N+1}$ be the output vector, $\\mathbf{r} = [r[0], \\dots, r[N]]^\\top \\in \\mathbb{R}^{N+1}$ be the target vector, and $\\mathbf{h} = [h_0, \\dots, h_{M-1}]^\\top \\in \\mathbb{R}^{M}$ be the vector of filter coefficients. The convolution operation can be expressed as a matrix-vector product $\\mathbf{y} = \\mathbf{C}\\mathbf{h}$, where $\\mathbf{C}$ is the convolution matrix of size $(N+1) \\times M$. The elements of $\\mathbf{C}$ are given by $\\mathbf{C}[n, m] = g[n-m]$ for $n \\ge m$ and $0$ otherwise, reflecting the causality of the system $G(z)$ and the convolution operation.\n$$\n\\mathbf{C} =\n\\begin{pmatrix}\ng[0]  0  \\cdots  0 \\\\\ng[1]  g[0]  \\cdots  0 \\\\\n\\vdots  \\vdots  \\ddots  \\vdots \\\\\ng[M-1]  g[M-2]  \\cdots  g[0] \\\\\ng[M]  g[M-1]  \\cdots  g[1] \\\\\n\\vdots  \\vdots   \\vdots \\\\\ng[N]  g[N-1]  \\cdots  g[N-M+1]\n\\end{pmatrix}\n$$\nThe cost function becomes the squared Euclidean norm of the residual vector:\n$$\nJ(\\mathbf{h}) = \\lVert \\mathbf{C}\\mathbf{h} - \\mathbf{r} \\rVert_2^2 = (\\mathbf{C}\\mathbf{h} - \\mathbf{r})^\\top (\\mathbf{C}\\mathbf{h} - \\mathbf{r})\n$$\nExpanding this quadratic form yields:\n$$\nJ(\\mathbf{h}) = \\mathbf{h}^\\top\\mathbf{C}^\\top\\mathbf{C}\\mathbf{h} - 2\\mathbf{r}^\\top\\mathbf{C}\\mathbf{h} + \\mathbf{r}^\\top\\mathbf{r}\n$$\nTo find the optimal coefficient vector $\\mathbf{h}$ that minimizes $J$, we compute the gradient of $J(\\mathbf{h})$ with respect to $\\mathbf{h}$ and set it to the zero vector.\n$$\n\\nabla_{\\mathbf{h}} J(\\mathbf{h}) = 2\\mathbf{C}^\\top\\mathbf{C}\\mathbf{h} - 2\\mathbf{C}^\\top\\mathbf{r} = \\mathbf{0}\n$$\nThis yields the celebrated normal equations:\n$$\n(\\mathbf{C}^\\top\\mathbf{C})\\mathbf{h} = \\mathbf{C}^\\top\\mathbf{r}\n$$\nThe optimal vector of FIR coefficients $\\mathbf{h}$ is found by solving this linear system. The matrix $\\mathbf{A}_{\\text{norm}} = \\mathbf{C}^\\top\\mathbf{C}$ is an $M \\times M$ symmetric matrix, and the right-hand side is the vector $\\mathbf{b}_{\\text{norm}} = \\mathbf{C}^\\top\\mathbf{r}$.\n\nThe problem states that the resulting system has a Toeplitz structure. Let us examine the $(i,j)$-th element of $\\mathbf{A}_{\\text{norm}}$:\n$$\n(\\mathbf{A}_{\\text{norm}})_{ij} = \\sum_{k=0}^{N} \\mathbf{C}_{ki} \\mathbf{C}_{kj} = \\sum_{k=\\max(i,j)}^{N} g[k-i] g[k-j]\n$$\nThis sum is a finite-window approximation of the autocorrelation of the impulse response $g[n]$. If the summation horizon $N$ were infinite, the element $(\\mathbf{A}_{\\text{norm}})_{ij}$ would depend only on the difference $k = |i-j|$, which is the defining property of a Toeplitz matrix. The time-invariance of the system $G(z)$ is the fundamental reason for this structure. However, the finite summation limit $N$ introduces boundary effects, causing the matrix to be only approximately Toeplitz. Specifically, $(\\mathbf{A}_{\\text{norm}})_{i+1,j+1}$ is not identical to $(\\mathbf{A}_{\\text{norm}})_{ij}$, differing by a term related to $g[N-i]g[N-j]$. For large $N$ where $g[n]$ has decayed, this difference is negligible, and the matrix is near-Toeplitz.\n\nThe computational procedure is as follows:\n1.  **Compute Impulse Response**: For each test case, the impulse response $g[n]$ for $n=0, \\dots, N$ is computed by simulating the difference equation $A(z^{-1})g[n] = B(z^{-1})\\delta[n]$, which translates to $g[n] = -\\sum_{i=1}^{n_a} a_i g[n-i] + \\sum_{j=0}^{n_b} b_j \\delta[n-j]$. This is performed using `scipy.signal.lfilter`, a standard tool for this exact task.\n\n2.  **Construct Matrices**: The convolution matrix $\\mathbf{C}$ and the target vector $\\mathbf{r}$ are constructed according to their definitions.\n\n3.  **Solve for h**: The normal equations $(\\mathbf{C}^\\top\\mathbf{C})\\mathbf{h} = \\mathbf{C}^\\top\\mathbf{r}$ are formed and solved for $\\mathbf{h}$ using a standard linear algebra solver. Using the normal equations is numerically less stable than methods like QR decomposition or SVD on $\\mathbf{C}$ directly, as it squares the condition number. However, the problem explicitly instructs this approach to demonstrate the structure of the optimality conditions.\n\n4.  **Compute Diagnostics**:\n    -   The residual norm $\\lVert \\mathbf{C}\\mathbf{h} - \\mathbf{r} \\rVert_2$ quantifies the quality of the approximation.\n    -   The condition numbers $\\kappa_2(\\mathbf{C})$ and $\\kappa_2(\\mathbf{C}^\\top\\mathbf{C})$ measure the sensitivity of the solution to perturbations in the data. The expected relationship $\\kappa_2(\\mathbf{C}^\\top\\mathbf{C}) \\approx (\\kappa_2(\\mathbf{C}))^2$ highlights the numerical cost of forming the normal equations.\n    -   The minimum-phase property of $G(z)$ is determined by its zeros. A system is minimum-phase if all its zeros lie strictly inside the unit circle in the $z$-plane. This is equivalent to all roots of the polynomial $B(q) = \\sum_{k=0}^{n_b} b_k q^k$ (where $q=z^{-1}$) having magnitude strictly greater than $1$. Systems that are not minimum-phase are notoriously more difficult to invert with a causal, stable filter.\n\nThe following Python code implements this procedure for the specified test cases.", "answer": "```python\nimport numpy as np\nfrom scipy.signal import lfilter\n\ndef solve():\n    \"\"\"\n    Solves for the FIR feedforward inverse for a set of test cases and computes diagnostics.\n    \"\"\"\n    test_cases = [\n        ([1.0, 0.5], [1.0, -0.6], 60, 10, 5),      # Test 1\n        ([1.0, -1.1], [1.0, -0.5], 60, 10, 5),     # Test 2\n        ([1.0, -0.99], [1.0, -0.6], 60, 10, 5),    # Test 3\n        ([1.0, 0.0, 0.4], [1.0, -1.5, 0.7], 80, 12, 6), # Test 4\n        ([1.0, 0.2], [1.0, -0.3], 5, 1, 0)          # Test 5\n    ]\n\n    all_results = []\n\n    for case in test_cases:\n        b_coeffs, a_coeffs, N, M, d = case\n        \n        b = np.array(b_coeffs, dtype=np.float64)\n        a = np.array(a_coeffs, dtype=np.float64)\n\n        # 1. Compute causal impulse response g[n] up to n=N\n        impulse_input = np.zeros(N + 1, dtype=np.float64)\n        impulse_input[0] = 1.0\n        g = lfilter(b, a, impulse_input)\n        \n        # 2. Construct the convolution matrix C\n        C = np.zeros((N + 1, M), dtype=np.float64)\n        for m in range(M):\n            # This can be done more efficiently with slicing, but loop is clear\n            if m  N + 1:\n                C[m:, m] = g[:N + 1 - m]\n\n        # 3. Construct the desired response vector r\n        r = np.zeros(N + 1, dtype=np.float64)\n        if 0 = d = N:\n            r[d] = 1.0\n\n        # 4. Solve the normal equations (C^T C)h = C^T r\n        C_T_C = C.T @ C\n        C_T_r = C.T @ r\n        h = np.linalg.solve(C_T_C, C_T_r)\n\n        # 5. Compute quantitative diagnostics\n        # Residual norm\n        residual_vector = C @ h - r\n        residual_norm = np.linalg.norm(residual_vector, 2)\n        \n        # Condition numbers\n        cond_C = np.linalg.cond(C, 2)\n        cond_normal = np.linalg.cond(C_T_C, 2)\n\n        # Minimum-phase check\n        # A system G(z) is minimum-phase if all its zeros have magnitude  1.\n        # This is equivalent to roots of the polynomial B(q) (where q=z^-1) having magnitude > 1.\n        # np.roots finds roots of a polynomial with coeffs from high power to low.\n        is_min_phase = True\n        if len(b) > 1: # Constant B(z^-1) has no zeros, min-phase by convention\n            # Roots of B(q) = b0 + b1*q + ... = 0\n            # np.roots needs coeffs for b_nb*q^nb + ... + b1*q + b0\n            q_roots = np.roots(b[::-1])\n            # zeros of G(z) are z_i = 1/q_i.\n            # |z_i|  1  => |1/q_i|  1 => 1  |q_i|\n            if not np.all(np.abs(q_roots) > 1.0):\n                is_min_phase = False\n        \n        # Format results for printing\n        res_list = [\n            round(residual_norm, 6),\n            round(cond_C, 6),\n            round(cond_normal, 6),\n            is_min_phase\n        ]\n        \n        all_results.append(res_list)\n\n    # Final print statement in the exact required format\n    # This format is required by the problem: [[...],[...],...]\n    print(str(all_results).replace(\" \", \"\").replace(\"True\",\"True\").replace(\"False\",\"False\"))\n\nif __name__ == '__main__':\n    solve()\n```", "id": "2708583"}]}