{"hands_on_practices": [{"introduction": "任何遗传学研究的基石都是准确的基因型数据。随着新一代测序技术的发展，我们获得了前所未有的海量数据，但同时也引入了固有的不确定性，尤其是在处理低覆盖度数据或罕见变异时。这个动手实践练习 [@problem_id:2830588] 将引导您通过编程模拟这一过程，并实证地证明为何概率性的“软”基因型（即整合的基因型剂量）通过最小化估计误差，在校准方面优于确定性的“硬”基因型判读。", "problem": "要求您实现一个独立的模拟和分析，以评估在数量性状基因座 (QTL) 定位和全基因组关联研究 (GWAS) 的稀有变异检测背景下，整合基因型似然相对于硬性基因型调用如何改善校准。您的程序必须模拟具有真实覆盖度变异和碱基识别错误的新一代测序数据，然后计算并比较在使用两种基因型剂量估计量的情况下的校准。\n\n使用的基本依据和假设：\n- Hardy–Weinberg 平衡 (HWE)：给定一个二倍体生物中的次要等位基因频率 $p \\in (0,1)$，在随机交配的条件下，基因型 $G \\in \\{0,1,2\\}$ 的先验概率为 $P(G=0) = (1-p)^2$、$P(G=1) = 2p(1-p)$ 和 $P(G=2) = p^2$。\n- 测序读数的二项采样：给定总覆盖度 $N \\in \\{0,1,2,\\dots\\}$ 和由真实基因型和测序错误决定的单次读取的备择等位基因概率 $q \\in [0,1]$，备择等位基因的读取计数 $K$ 服从分布 $K \\sim \\mathrm{Binomial}(N,q)$。\n- 过离散覆盖度：为模拟样本和基因座之间的覆盖度变异，假设 $N$ 服从负二项分布，其均值为 $\\mu > 0$，整数离散参数为 $r \\in \\{1,2,3,\\dots\\}$，参数化后使得 $\\mathbb{E}[N] = \\mu$ 且 $\\mathrm{Var}[N] = \\mu + \\mu^2/r$。\n- 对称碱基识别错误：设单碱基错误率为 $\\varepsilon \\in (0,1/2)$，并假设各次读取之间独立。在备择等位基因与任何非备择等位基因调用的二元区分下，一次读取报告备择等位基因的概率为\n  - 如果 $G=0$，则 $q = \\varepsilon$，\n  - 如果 $G=1$，则 $q = 1/2$，\n  - 如果 $G=2$，则 $q = 1-\\varepsilon$。\n- 基因型似然和贝叶斯法则：对于一个基因座和样本的观测对 $(N,K)$，基因型似然满足 $P(D \\mid G=g) \\propto q_g^K (1-q_g)^{N-K}$（不考虑在归一化中会抵消的组合因子），后验概率遵循 $P(G=g \\mid D) \\propto P(D \\mid G=g) P(G=g)$。\n\n待计算目标：\n- 两种剂量（次要等位基因计数）估计量：\n  - 硬性调用剂量 $\\hat{d}_{\\mathrm{hard}}$：后验概率的众数，映射到 $\\{0,1,2\\}$。\n  - 整合剂量 $\\hat{d}_{\\mathrm{soft}}$：后验均值 $\\sum_{g \\in \\{0,1,2\\}} g \\, P(G=g \\mid D)$。\n- 设真实剂量为 $d_{\\mathrm{true}} \\in \\{0,1,2\\}$。将每个估计量下的均方误差定义为在所有样本和基因座上 $(\\hat{d} - d_{\\mathrm{true}})^2$ 的平均值。将改善量定义为\n$$\n\\Delta = \\mathrm{MSE}(\\hat{d}_{\\mathrm{hard}}) - \\mathrm{MSE}(\\hat{d}_{\\mathrm{soft}}).\n$$\n您的程序必须为每个测试用例输出 $\\Delta$。\n\n需实现的模拟设计：\n- 对于每个测试用例，模拟 $L$ 个具有相同次要等位基因频率 $p$ 的独立基因座，以及每个基因座的 $N_{\\mathrm{samples}}$ 个独立的二倍体个体。\n- 对于每个个体和基因座，从 $G \\sim \\mathrm{Binomial}(2,p)$（满足 HWE）中抽取真实基因型，然后从均值为 $\\mu$、离散参数为 $r$ 的 $\\mathrm{NegBin}(r, \\mu)$ 中抽取覆盖度 $N$，再使用上述对称错误模型（错误率为 $\\varepsilon$）从 $K \\sim \\mathrm{Binomial}(N, q_G)$ 中抽取备择等位基因的读取计数。\n- 使用贝叶斯法则、HWE 先验和二项似然，计算 $g \\in \\{0,1,2\\}$ 的后验概率 $P(G=g \\mid D)$；然后计算 $\\hat{d}_{\\mathrm{soft}}$ 和 $\\hat{d}_{\\mathrm{hard}}$，最后计算如上定义的 $\\Delta$。\n\n待证明的原理：\n- 在整个测试套件中，通过经验证明，使用 $\\hat{d}_{\\mathrm{soft}}$ 相对于 $\\hat{d}_{\\mathrm{hard}}$ 减少了平方误差（即 $\\Delta \\ge 0$），从而改善校准。\n\n实现要求：\n- 使用固定的伪随机种子 $1337$ 以确保可复现性。\n- 不要假设存在任何外部文件；所有内容必须在内存中模拟。\n- 避免在覆盖度为零时出现未定义行为；当 $N=0$ 时，后验概率应退化为先验概率。\n\n测试套件：\n精确实现以下四个测试用例，每个用例为一个元组 $(N_{\\mathrm{samples}}, L, p, \\mu, r, \\varepsilon)$：\n- 用例 1：$(2000, 50, 0.01, 12.0, 5, 0.005)$\n- 用例 2：$(2000, 50, 0.005, 3.0, 3, 0.01)$\n- 用例 3：$(4000, 80, 0.001, 8.0, 4, 0.02)$\n- 用例 4：$(3000, 40, 0.0005, 1.0, 2, 0.02)$\n\n输出内容：\n- 对于每个用例，计算 $\\Delta$ 并以小数值表示。报告结果时四舍五入到 $6$ 位小数。\n- 您的程序应生成单行输出，其中包含四个结果，以逗号分隔的列表形式，并用方括号括起来，顺序与上述用例一致。例如：\"[0.012345,0.000678,0.001234,0.000056]\"。", "solution": "问题陈述已经过严格验证，并被确定为是适定的、有科学依据且内部一致的。它提出了一个统计遗传学中的标准（尽管是简化的）模型，并要求对估计量的性能进行计算分析。我们现在将提供一个正式的解决方案。\n\n目标是通过使用后验均值估计量（软调用）而非后验众数估计量（硬调用）来量化基因型剂量估计的改善程度。这种改善通过均方误差（MSE）的减少来衡量，记为 $\\Delta = \\mathrm{MSE}(\\hat{d}_{\\mathrm{hard}}) - \\mathrm{MSE}(\\hat{d}_{\\mathrm{soft}})$。其背景是分析来自新一代测序数据的稀有变异，其中低的等位基因频率和可变的读取覆盖度带来了显著的不确定性。\n\n该分析通过蒙特卡洛模拟进行。对于由参数 $(N_{\\mathrm{samples}}, L, p, \\mu, r, \\varepsilon)$ 定义的每个测试用例，我们为一个二倍体群体模拟总共 $N_{\\mathrm{total}} = N_{\\mathrm{samples}} \\times L$ 个独立的基因座。\n\n**1. 数据模拟**\n\n对 $N_{\\mathrm{total}}$ 个数据点中的每一个进行的模拟都分三步进行，模拟了生物学和技术过程：\n\n- **真实基因型生成：** 真实基因型 $G$ 代表次要等位基因的数量，是为每个个体在每个基因座上抽取的。在 Hardy-Weinberg 平衡 (HWE) 的假设下，基因型服从二项分布，试验次数为 $2$（对于二倍体生物），成功概率等于次要等位基因频率 (MAF) $p$。\n$$\nd_{\\mathrm{true}} = G \\sim \\mathrm{Binomial}(2, p)\n$$\n\n- **测序覆盖度模拟：** 读取覆盖度 $N$ 在个体和基因座之间是可变的。这种过离散现象使用负二项分布进行建模，其参数为均值 $\\mu$ 和整数离散参数 $r$。其概率质量函数满足 $\\mathbb{E}[N] = \\mu$ 和 $\\mathrm{Var}[N] = \\mu + \\mu^2/r$。这对应于一个标准参数化，其中成功次数为 $n=r$，成功概率为 $p_{\\mathrm{NB}} = r / (r+\\mu)$。\n$$\nN \\sim \\mathrm{NegativeBinomial}(n=r, p=r/(r+\\mu))\n$$\n\n- **备择等位基因读取计数模拟：** 给定真实基因型 $G$ 和总覆盖度 $N$，支持备择等位基因的读取次数 $K$ 从二项分布中抽样。在任何给定读取上观察到备择等位基因的概率 $q_G$ 取决于真实基因型 $G$ 和对称碱基识别错误率 $\\varepsilon$。\n$$\nK \\sim \\mathrm{Binomial}(N, q_G)\n$$\n其中，单次读取的备择等位基因概率 $q_G$ 由下式给出：\n$$\nq_G = \\begin{cases} \\varepsilon  \\text{如果 } G=0 \\\\ 1/2  \\text{如果 } G=1 \\\\ 1-\\varepsilon  \\text{如果 } G=2 \\end{cases}\n$$\n\n**2. 基因型的贝叶斯推断**\n\n对于每个模拟数据点 $(N, K)$，我们应用贝叶斯定理来计算每个可能基因型 $g \\in \\{0, 1, 2\\}$ 的后验概率。后验概率与似然和先验概率的乘积成正比。\n\n- **先验概率：** 关于基因型的先验信念由从群体的 MAF $p$ 推导出的 HWE 概率给出：\n$$\nP(G=g) = \\begin{cases} (1-p)^2  \\text{如果 } g=0 \\\\ 2p(1-p)  \\text{如果 } g=1 \\\\ p^2  \\text{如果 } g=2 \\end{cases}\n$$\n\n- **似然函数：** 在给定真实基因型 $g$ 的情况下，从 $N$ 个总读取中观察到 $K$ 个备择等位基因读取的似然由二项概率质量函数给出：\n$$\nP(D \\mid G=g) = \\binom{N}{K} q_g^K (1-q_g)^{N-K}\n$$\n其中 $D$ 表示数据 $(N,K)$。\n\n- **后验概率：** 那么基因型 $g$ 的后验概率为：\n$$\nP(G=g \\mid D) = \\frac{P(D \\mid G=g) P(G=g)}{\\sum_{i=0}^{2} P(D \\mid G=i) P(G=i)}\n$$\n为确保数值稳定性，计算在对数空间中进行。对数后验概率计算如下：\n$$\n\\log P(G=g \\mid D) = \\left( \\log P(D \\mid G=g) + \\log P(G=g) \\right) - \\mathrm{logsumexp}_{i=0}^{2} \\left( \\log P(D \\mid G=i) + \\log P(G=i) \\right)\n$$\n覆盖度为零（$N=0$）的特殊情况在此公式中自然得到处理。如果 $N=0$，那么 $K=0$，似然项 $P(D \\mid G=g)$ 对所有 $g$ 都变为 $1$，导致后验概率恢复为先验概率，这是正确的。\n\n**3. 剂量估计和误差计算**\n\n根据后验分布 $P(G=g \\mid D)$，我们计算两种不同的剂量估计量：\n\n- **硬性调用剂量 ($\\hat{d}_{\\mathrm{hard}}$):** 这是最大后验 (MAP) 估计，对应于具有最高后验概率的基因型。\n$$\n\\hat{d}_{\\mathrm{hard}} = \\underset{g \\in \\{0,1,2\\}}{\\mathrm{argmax}} \\, P(G=g \\mid D)\n$$\n该估计量丢弃了所有关于不确定性的信息。\n\n- **整合剂量 ($\\hat{d}_{\\mathrm{soft}}$):** 这是基因型分布的后验均值，它对不确定性进行了积分。\n$$\n\\hat{d}_{\\mathrm{soft}} = \\mathbb{E}[G \\mid D] = \\sum_{g=0}^{2} g \\cdot P(G=g \\mid D)\n$$\n根据贝叶斯决策理论，后验均值是最小化均方误差 (MSE) 的最优估计量。\n\n最后，通过对所有 $N_{\\mathrm{total}}$ 次模拟中，估计值与真实模拟剂量 $d_{\\mathrm{true}}$ 之间差值的平方进行平均，来计算每个估计量的 MSE。\n$$\n\\mathrm{MSE}(\\hat{d}) = \\frac{1}{N_{\\mathrm{total}}} \\sum_{j=1}^{N_{\\mathrm{total}}} (\\hat{d}_j - d_{\\mathrm{true}, j})^2\n$$\n最终的度量指标 $\\Delta = \\mathrm{MSE}(\\hat{d}_{\\mathrm{hard}}) - \\mathrm{MSE}(\\hat{d}_{\\mathrm{soft}})$ 被计算出来。我们期望 $\\Delta \\ge 0$，这表明整合剂量估计量在平方误差方面校准得更好。\n\n整个过程使用固定的伪随机种子 $1337$ 实现，以确保可复现性。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.stats import nbinom, binom\nfrom scipy.special import logsumexp\n\ndef compute_delta_for_case(n_samples, l_loci, p_maf, mu, r, epsilon, rng):\n    \"\"\"\n    Simulates sequencing data and computes the improvement in MSE from using\n    soft vs. hard genotype calls.\n\n    Args:\n        n_samples (int): Number of diploid individuals.\n        l_loci (int): Number of independent loci.\n        p_maf (float): Minor allele frequency.\n        mu (float): Mean coverage.\n        r (int): Dispersion parameter for coverage.\n        epsilon (float): Symmetric base-calling error rate.\n        rng (np.random.Generator): A numpy random number generator instance.\n\n    Returns:\n        float: The calculated improvement, Delta = MSE(hard) - MSE(soft).\n    \"\"\"\n\n    n_total = n_samples * l_loci\n    \n    # 1. Priors and Genotype-dependent probabilities\n    # HWE prior probabilities P(G=g) for g in {0, 1, 2}\n    prior_probs = np.array([(1 - p_maf)**2, 2 * p_maf * (1 - p_maf), p_maf**2])\n    log_priors = np.log(prior_probs)\n\n    # Per-read alternate allele probability q_g, given genotype g\n    q_vec = np.array([epsilon, 0.5, 1 - epsilon])\n\n    # 2. Simulation steps\n    # Step 2.1: Simulate true genotypes (dosages) from Binomial(2, p)\n    # This correctly models diploid genotypes under HWE.\n    d_true = rng.binomial(2, p_maf, size=n_total)\n\n    # Step 2.2: Simulate overdispersed read coverage N from Negative Binomial\n    # Parameterize for scipy.stats.nbinom using mean (mu) and dispersion (r)\n    p_nb = r / (r + mu)\n    # n_nb = r\n    N = nbinom.rvs(n=r, p=p_nb, size=n_total, random_state=rng)\n    \n    # Step 2.3: Simulate alternate read counts K from Binomial(N, q_G)\n    # The probability of success q_G depends on the true genotype G.\n    q_true = q_vec[d_true]\n    K = rng.binomial(N, q_true)\n\n    # 3. Bayesian Inference\n    # Calculate log-likelihoods P(K|N, G=g) for each g in {0, 1, 2}\n    # This creates a (3, N_total) array where rows correspond to G=0, 1, 2.\n    # The calculation is vectorized over all N_total data points.\n    log_likelihoods = np.zeros((3, n_total))\n    for g in range(3):\n        # binom.logpmf is numerically stable and handles N=0 cases correctly.\n        log_likelihoods[g, :] = binom.logpmf(K, N, q_vec[g])\n\n    # Combine with log-priors to get unnormalized log-posteriors\n    # Broadcasting log_priors of shape (3,1) over log_likelihoods of shape (3, n_total)\n    log_unnorm_posterior = log_likelihoods + log_priors[:, np.newaxis]\n\n    # Normalize using the log-sum-exp trick to get log-posteriors\n    log_marginal_likelihood = logsumexp(log_unnorm_posterior, axis=0)\n    log_posterior = log_unnorm_posterior - log_marginal_likelihood\n    \n    # Convert back to linear scale for posterior probabilities\n    posterior_probs = np.exp(log_posterior)\n\n    # 4. Compute Dosage Estimators\n    # Hard call dosage (MAP estimate)\n    d_hat_hard = np.argmax(posterior_probs, axis=0)\n\n    # Soft call dosage (posterior mean)\n    genotypes = np.array([0, 1, 2])\n    d_hat_soft = genotypes @ posterior_probs\n\n    # 5. Calculate Mean Squared Error and Delta\n    mse_hard = np.mean((d_hat_hard - d_true)**2)\n    mse_soft = np.mean((d_hat_soft - d_true)**2)\n    \n    delta = mse_hard - mse_soft\n    return delta\n\ndef solve():\n    \"\"\"\n    Main solver function to run all test cases and print results.\n    \"\"\"\n    # Initialize a single random number generator for reproducibility.\n    rng = np.random.default_rng(1337)\n\n    # Define the test cases from the problem statement:\n    # (N_samples, L, p, mu, r, epsilon)\n    test_cases = [\n        (2000, 50, 0.01, 12.0, 5, 0.005),\n        (2000, 50, 0.005, 3.0, 3, 0.01),\n        (4000, 80, 0.001, 8.0, 4, 0.02),\n        (3000, 40, 0.0005, 1.0, 2, 0.02),\n    ]\n\n    results = []\n    for case in test_cases:\n        delta = compute_delta_for_case(*case, rng=rng)\n        results.append(delta)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(f'{res:.6f}' for res in results)}]\")\n\nsolve()\n```", "id": "2830588"}, {"introduction": "在获得基因型矩阵后，下一个关键步骤是严格的质量控制（QC）。这并非一个“一刀切”的过程，而是需要对数据的分布进行仔细检查，以做出明智的决策。这项练习 [@problem_id:2830645] 将您置于数据分析师的角色，利用一个假设研究中的真实经验汇总数据来设计一个稳健的QC流程，从而在保留高质量数据和移除潜在的技术偏差之间取得平衡。", "problem": "给定一个全基因组关联研究 (GWAS) 数据集，其中包含 $n = 12{,}000$ 名已进行基因分型的个体（病例 $= 5{,}000$，对照 $= 7{,}000$）和 $m = 700{,}000$ 个常染色体单核苷酸多态性 (SNP)，这些数据是在经过标准的芯片聚类和基因型检出后得到的。您计划使用常见的 GWAS 指标进行关联分析前的质量控制 (QC)：个体检出率和缺失率、SNP检出率和缺失率、常染色体杂合率、基于X染色体的性别推断、亲缘关系和哈迪-温伯格平衡 (HWE)。为具体起见，假设从原始数据中得出以下经验性总结：\n\n- 个体缺失率（未检出基因型的比例）的主众数接近 $0.003$，第 $95$ 百分位数为 $0.012$，并有一个长右尾延伸至 $0.12$。另有一个由大约 $150$ 个个体组成的次级聚类，其缺失率在 $0.06$ 到 $0.10$ 之间。\n- SNP缺失率的众数接近 $0.002$，第 $95$ 百分位数为 $0.015$，并有一个长尾延伸至 $0.25$。在 $0.06$ 附近有一个涉及约 $12{,}000$ 个SNP的次要众数。\n- 常染色体杂合率是在一个经过连锁不平衡 (LD) 剪枝的包含 $100{,}000$ 个近似独立SNP的集合上计算的，其分布近似为正态分布，均值为 $0.315$，标准差为 $0.012$。在 $0.36$ (约 $30$ 个个体) 和 $0.28$ (约 $20$ 个个体) 处存在离群聚类。\n- 使用非伪常染色体X染色体上的近交系数 ($F_X$)进行的X染色体性别推断显示，报告性别为男性 ($n \\approx 5{,}800$) 的个体 $F_X$ 分布在均值 $0.95$、标准差 $0.05$ 左右；报告性别为女性 ($n \\approx 6{,}200$) 的个体 $F_X$ 分布在均值 $0.02$、标准差 $0.03$ 左右。大约有 $40$ 名报告为女性的个体 $F_X > 0.85$，以及 $25$ 名报告为男性的个体 $F_X  0.15$。\n- 通过同源遗传 (IBD) 比例 $\\hat{\\pi}$ 估计的两两之间的亲缘关系显示，大约有 $60$ 对重复样本或同卵 (MZ) 双胞胎对，其 $\\hat{\\pi} > 0.98$；$220$ 对推定的一级亲属对，其 $\\hat{\\pi} \\in [0.40, 0.60]$；以及 $300$ 对推定的二级亲属对，其 $\\hat{\\pi} \\in [0.18, 0.25]$。其余的配对的 $\\hat{\\pi}  0.05$。\n- 在对照组中计算的HWE精确检验 $p$ 值显示出近乎均匀的分布，但小 $p$ 值存在富集：约 $25{,}000$ 个SNP的 $p  10^{-4}$，$1{,}200$ 个SNP的 $p  10^{-6}$。$p  10^{-6}$ 的SNP在较高缺失率中富集（缺失率中位数约为 $0.06$）。\n\n定义：个体检出率是指一个个体在所有SNP中非缺失基因型检出的比例；SNP检出率是指一个SNP在所有个体中非缺失基因型检出的比例。常染色体杂合率是指一个个体在一组剪枝后的常染色体SNP中杂合基因型的比例。X染色体近交系数 $F_X$ 对于男性（半合子）接近 $1$，对于具有典型二倍体女性X基因型的女性接近 $0$。IBD比例 $\\hat{\\pi}$ 是一对个体间基因组共享IBD的估计比例，对于重复样本/同卵双胞胎，其典型期望值接近 $1.0$，一级亲属为 $0.5$，二级亲属为 $0.25$。在哈迪-温伯格平衡下，给定等位基因频率 $p$ 和 $q = 1 - p$，基因型频率满足 $p^2$、$2pq$、$q^2$；在具有随机交配的大型远交群体中，HWE检验的 $p$ 值在原假设下近似服从均匀分布。\n\n您必须选择一个QC方案，该方案既能正确定义这些指标，又能设定阈值，在保留高质量数据和移除可能的假象之间取得平衡，且仅使用上述经验性总结和GWAS QC的基本原则。哪个选项最能满足这一目标？\n\nA. 个体：如果缺失率 $> 0.02$（等同于检出率 $ 0.98$）则排除；SNP：如果缺失率 $> 0.02$（等同于检出率 $ 0.98$）则排除；杂合率：标记并排除在经过LD剪枝的SNP上计算出的均值 $\\pm 3$ 标准差之外的常染色体离群值；性别检查：如果 $F_X \\ge 0.80$ 则判定遗传性别为男性，如果 $F_X \\le 0.20$ 则判定为女性，并排除性别不一致或模糊的个体；亲缘关系：从每对 $\\hat{\\pi} > 0.185$ 的配对中移除一个个体，以将亲缘关系限制在最多为三级；HWE：在对照组中计算，并排除 $p  10^{-6}$ 的SNP。\n\nB. 个体：如果缺失率 $> 0.005$ 则排除；SNP：如果缺失率 $> 0.005$ 则排除；杂合率：排除在均值 $\\pm 2$ 标准差之外的个体；性别检查：通过 $F_X \\ge 0.50$ 判定为男性，$F_X  0.50$ 判定为女性；亲缘关系：仅使用 $\\hat{\\pi} > 0.35$ 移除重复样本和一级亲属；HWE：在所有样本中计算，并排除 $p  10^{-4}$ 的SNP。\n\nC. 个体：如果缺失率 $> 0.08$ 则排除；SNP：如果缺失率 $> 0.08$ 则排除；杂合率：排除在均值 $\\pm 5$ 标准差之外的个体；性别检查：跳过基于X染色体的性别推断以最大化保留样本；亲缘关系：从每对 $\\hat{\\pi} > 0.10$ 的配对中移除一个个体；HWE：在对照组中计算，并排除 $p  10^{-2}$ 的SNP。\n\nD. 个体：如果缺失率 $> 0.02$ 则排除；SNP：当次要等位基因频率 (MAF) $\\ge 0.01$ 时，如果缺失率 $> 0.02$ 则排除，但当 MAF $ 0.01$ 时允许高达 $0.05$；杂合率：排除在均值 $\\pm 3$ 标准差之外的个体；性别检查：使用 $F_X \\ge 0.80$ 判定男性，$F_X \\le 0.20$ 判定女性，并移除性别不一致或模糊的个体；亲缘关系：从每对 $\\hat{\\pi} > 0.125$ 的配对中移除一个个体；HWE：在对照组中计算，并排除 $p  10^{-6}$ 的SNP。\n\nE. 个体：如果缺失率 $> 0.02$ 则排除；SNP：如果缺失率 $> 0.02$ 则排除；杂合率：排除在均值 $\\pm 3$ 标准差之外的个体；性别检查：同A选项；亲缘关系：从每对 $\\hat{\\pi} > 0.185$ 的配对中移除一个个体；HWE：在对照组中计算，并使用 $m = 700{,}000$ 进行Bonferroni校正，排除 $p  7.1 \\times 10^{-8}$ 的SNP。\n\n选择唯一最佳选项。", "solution": "任务是评估几种为全基因组关联研究 (GWAS) 提出的质量控制 (QC) 方案，并选择最佳方案。评估必须基于已建立的GWAS QC原则以及问题陈述中提供的具体经验数据摘要。\n\n首先，我将验证问题陈述。\n\n### 步骤1：提取已知信息\n- 样本：$n = 12,000$ 名个体（病例 $= 5,000$，对照 $= 7,000$）。\n- 遗传数据：$m = 700,000$ 个常染色体单核苷酸多态性 (SNP)。\n- 个体缺失率：众数 $\\approx 0.003$，第 $95$ 百分位数为 $0.012$，长尾延伸至 $0.12$。一个由约 $150$ 个个体组成的次级聚类，其缺失率在 $[0.06, 0.10]$ 区间内。\n- SNP缺失率：众数 $\\approx 0.002$，第 $95$ 百分位数为 $0.015$，长尾延伸至 $0.25$。在 $\\approx 0.06$ 处有一个次要众数，涉及约 $12,000$ 个SNP。\n- 常染色体杂合率：在 $100,000$ 个经过LD剪枝的SNP上计算，近似服从正态分布，均值 $\\mu = 0.315$，标准差 $\\sigma = 0.012$。存在位于 $0.36$ (约 $30$ 个个体) 和 $0.28$ (约 $20$ 个个体) 的离群聚类。\n- X染色体性别推断 ($F_X$)：对于报告性别为男性的个体，$F_X$ 分布在均值 $0.95$，$\\sigma = 0.05$ 附近。对于报告性别为女性的个体，$F_X$ 分布在均值 $0.02$，$\\sigma = 0.03$ 附近。约有 $40$ 名报告为女性的个体 $F_X > 0.85$，约有 $25$ 名报告为男性的个体 $F_X  0.15$。\n- 两两之间的亲缘关系 ($\\hat{\\pi}$): 约 $60$ 对重复样本/同卵双胞胎对 ($\\hat{\\pi} > 0.98$)，约 $220$ 对一级亲属对 ($\\hat{\\pi} \\in [0.40, 0.60]$)，约 $300$ 对二级亲属对 ($\\hat{\\pi} \\in [0.18, 0.25]$)。\n- 哈迪-温伯格平衡 (HWE)：对照组中的 $p$ 值在低端富集。约 $25,000$ 个SNP的 $p  10^{-4}$，约 $1,200$ 个SNP的 $p  10^{-6}$。这些低 $p$ 值的SNP在高缺失率中富集。\n- 所有指标的定义均已提供且为标准定义。\n\n### 步骤2：使用提取的已知信息进行验证\n这个问题在科学上是成立的。所有指标及其描述的经验分布对于大型人类GWAS数据集都是现实的。该问题设定良好，要求根据所提供的数据选择最佳的QC方案，这是生物信息学中的一项标准任务。其语言客观而精确。问题本身是自洽的，没有矛盾。所提供的数据足以做出有原则的选择。\n\n### 步骤3：结论和行动\n问题有效。我将继续进行分析。\n\n### 基于基本原则和数据推导合理的QC方案\n\n一个合理的QC方案必须移除可能的假象，同时尽可能多地保留高质量数据。每个阈值都应由所提供的经验分布来证明其合理性。\n\n1.  **个体缺失率**：大多数个体的缺失率非常低（众数在 $0.003$，第 $95$ 百分位数在 $0.012$）。在 $0.06-0.10$ 附近有一个明显的劣质样本聚类。标准的阈值是 $0.02$ 或 $0.05$。$0.02$ 的阈值将移除长尾中的低质量样本和整个离群聚类，同时保留超过 $95\\%$ 的个体。这是一个合理的选择。\n\n2.  **SNP缺失率**：情况与个体缺失率类似。绝大多数SNP的缺失率很低（众数 $0.002$，第 $95$ 百分位数 $0.015$）。在 $0.06$ 附近存在一个有问题的SNP的次要众数。$0.02$ 的阈值是合理的，因为它移除了长尾，同时保留了超过 $95\\%$ 的SNP，并针对了有问题的众数。\n\n3.  **常染色体杂合率**：数据服从均值为 $\\mu=0.315$、标准差为 $\\sigma=0.012$ 的正态分布，并带有离群聚类。我们以标准差为单位检查这些聚类的偏差。\n    -   位于 $0.36$ 的高杂合率聚类：$z = (0.36 - 0.315) / 0.012 = 0.045 / 0.012 = 3.75$。\n    -   位于 $0.28$ 的低杂合率聚类：$z = (0.28 - 0.315) / 0.012 = -0.035 / 0.012 \\approx -2.92$。\n    一个均值 $\\pm 3\\sigma$ 的阈值对应于区间 $[0.315 - 3(0.012), 0.315 + 3(0.012)] = [0.279, 0.351]$。这是一个极佳的选择，因为它正确地将高杂合率个体识别为离群值（$0.36 > 0.351$）。它也正确地标记了位于低杂合率聚类边缘的个体（$0.28$ 接近边界 $0.279$）。$\\pm 3\\sigma$ 法则是识别正态分布数据中离群值的标准方法。\n\n4.  **性别检查**：X染色体近交系数 $F_X$ 的分布明显是双峰的。对于男性，均值为 $0.95$ ($\\sigma=0.05$)。对于女性，均值为 $0.02$ ($\\sigma=0.03$)。需要明确定义的阈值来对个体进行分类并识别不一致情况。让我们考虑 $\\mu \\pm 3\\sigma$ 的区间：\n    -   男性范围：$[0.95 - 3(0.05), 0.95 + 3(0.05)] = [0.80, 1.10]$。\n    -   女性范围：$[0.02 - 3(0.03), 0.02 + 3(0.03)] = [-0.07, 0.11]$。\n    基于此，设定遗传男性 $F_X \\ge 0.80$ 和遗传女性 $F_X \\le 0.20$ 的阈值是一个稳健的选择。$0.20$ 和 $0.80$ 之间的空间可作为模糊情况（例如，性染色体非整倍体）的缓冲区。问题提到有报告为女性的个体 $F_X > 0.85$ 和报告为男性的个体 $F_X  0.15$。这些阈值将正确地将他们识别为性别不一致，必须予以排除。\n\n5.  **亲缘关系**：GWAS需要一个（大部分）无亲缘关系的个体样本。重复样本、同卵双胞胎和一级亲属必须被移除。移除二级亲属以确保独立性也是标准做法。数据显示，存在一个二级亲属聚类，其 $\\hat{\\pi}$ 在 $[0.18, 0.25]$ 范围内。$\\hat{\\pi} > 0.185$ 的阈值是经过精心选择的，可以移除这个群体中的配对以及更近的关系（一级、重复样本）。这是一个由数据驱动的阈值，它针对观测到的分布。\n\n6.  **哈迪-温伯格平衡 (HWE)**：HWE检验是检测基因分型错误的工具。a) 在病例-对照研究中，它必须 **仅在对照组中** 进行，因为真正的关联可能导致病例组或合并样本中的HWE偏离。b) $p$ 值阈值应足够严格以移除可能的错误，但又不能过于严格以至于无效。数据显示，极低 $p$ 值的SNP富集（$1,200$ 个SNP的 $p  10^{-6}$），这些SNP还与高缺失率相关。这强烈表明这些SNP是假象。因此，用 $p  10^{-6}$ 的阈值来专门针对这一劣质SNP聚类，是数据充分支持的。应用Bonferroni校正（例如，$p  0.05/700,000 \\approx 7 \\times 10^{-8}$）不适用于QC筛选；它过于严格，将无法移除许多在 $p  10^{-6}$ 观察到的问题SNP。\n\n基于此分析，最优方案结合了这些有原则且由数据驱动的选择。我现在将对照这个理想方案来评估每个选项。\n\n###逐项分析\n\n**A. 个体：如果缺失率 $> 0.02$ 则排除；SNP：如果缺失率 $> 0.02$ 则排除；杂合率：标记并排除在均值 $\\pm 3$ 标准差之外的常染色体离群值；性别检查：如果 $F_X \\ge 0.80$ 则判定遗传性别为男性，如果 $F_X \\le 0.20$ 则判定为女性，并排除性别不一致或模糊的个体；亲缘关系：从每对 $\\hat{\\pi} > 0.185$ 的配对中移除一个个体；HWE：在对照组中计算，并排除 $p  10^{-6}$ 的SNP。**\n\n- **评估：** 该选项中的每一步都与从经验数据和基本原则推导出的最优方案完美契合。缺失率、杂合率、性别检查、亲缘关系和HWE的阈值都是正确的，并且由提供的数据充分证明其合理性。\n- **结论：** **正确**。\n\n**B. 个体：如果缺失率 $> 0.005$ 则排除；SNP：如果缺失率 $> 0.005$ 则排除；杂合率：排除在均值 $\\pm 2$ 标准差之外的个体；性别检查：通过 $F_X \\ge 0.50$ 判定为男性，$F_X  0.50$ 判定为女性；亲缘关系：仅使用 $\\hat{\\pi} > 0.35$ 移除重复样本和一级亲属；HWE：在所有样本中计算，并排除 $p  10^{-4}$ 的SNP。**\n\n- **评估：** 该方案存在严重缺陷。缺失率 ($>0.005$) 和杂合率 ($\\pm 2\\sigma$) 的阈值过于严格，会丢弃过多有效数据。性别检查阈值 ($F_X=0.5$) 过于粗糙且不够稳健。亲缘关系筛选 ($\\hat{\\pi} > 0.35$) 过于宽松，会保留二级亲属。关键在于，在所有样本中计算HWE对于病例-对照研究是错误的。\n- **结论：** **不正确**。\n\n**C. 个体：如果缺失率 $> 0.08$ 则排除；SNP：如果缺失率 $> 0.08$ 则排除；杂合率：排除在均值 $\\pm 5$ 标准差之外的个体；性别检查：跳过基于X染色体的性别推断以最大化保留样本；亲缘关系：从每对 $\\hat{\\pi} > 0.10$ 的配对中移除一个个体；HWE：在对照组中计算，并排除 $p  10^{-2}$ 的SNP。**\n\n- **评估：** 该方案过于宽松，会保留低质量数据。$>0.08$ 的缺失率阈值会保留已知的离群样本和SNP。$\\pm 5\\sigma$ 的杂合率规则是无效的。跳过性别检查是重大的程序性错误。$p  10^{-2}$ 的HWE阈值过于宽容。亲缘关系阈值 ($\\hat{\\pi} > 0.10$) 反而过于严格，移除了比标准做法更远的亲属。\n- **结论：** **不正确**。\n\n**D. 个体：如果缺失率 $> 0.02$ 则排除；SNP：当次要等位基因频率 (MAF) $\\ge 0.01$ 时，如果缺失率 $> 0.02$ 则排除，但当 MAF $ 0.01$ 时允许高达 $0.05$；杂合率：排除在均值 $\\pm 3$ 标准差之外的个体；性别检查：使用 $F_X \\ge 0.80$ 判定男性，$F_X \\le 0.20$ 判定女性，并移除性别不一致或模糊的个体；亲缘关系：从每对 $\\hat{\\pi} > 0.125$ 的配对中移除一个个体；HWE：在对照组中计算，并排除 $p  10^{-6}$ 的SNP。**\n\n- **评估：** 这是一个强有力的方案，与A非常相似。然而，相对于A，*在问题陈述的背景下*，它有两个微妙的弱点。首先，依赖MAF的SNP缺失率规则虽然是良好实践，但引入了经验总结中未提供的信息 (MAF)，违反了“仅使用上述经验总结”的指令。其次，亲缘关系阈值 $\\hat{\\pi} > 0.125$ 是三级亲属的理论值，而选项A中的阈值 $\\hat{\\pi} > 0.185$ 更贴合观察到的数据，恰好在二级亲属聚类的边界处进行切割。因此，A更直接地得到问题数据的支持。\n- **结论：** **不正确**。\n\n**E. 个体：如果缺失率 $> 0.02$ 则排除；SNP：如果缺失率 $> 0.02$ 则排除；杂合率：排除在均值 $\\pm 3$ 标准差之外的个体；性别检查：同A选项；亲缘关系：从每对 $\\hat{\\pi} > 0.185$ 的配对中移除一个个体；HWE：在对照组中计算，并使用 $m = 700{,}000$ 进行Bonferroni校正，排除 $p  7.1 \\times 10^{-8}$ 的SNP。**\n\n- **评估：** 除了HWE阈值外，该选项与A相同。将严格的Bonferroni校正阈值 ($p  7.1 \\times 10^{-8}$) 用于HWE作为QC筛选，在概念上是错误的。它过于严格，将无法移除在 $p  10^{-6}$ 处观察到的约 $1,200$ 个问题SNP集群，从而违背了这一QC步骤的目的。\n- **结论：** **不正确**。\n\n### 总结\n选项A提出了一个完整且一致的QC方案，其中每一步都逻辑合理，每个阈值都直接由问题陈述中提供的经验数据分布所支持。它代表了在移除假象和保留高质量数据之间的最佳平衡。", "answer": "$$\\boxed{A}$$", "id": "2830645"}, {"introduction": "准备好高质量的数据集后，选择合适的统计模型至关重要。线性混合模型（LMM）是控制群体结构和亲缘关系的黄金标准，但其应用中存在一个被称为“近端污染”的微妙而关键的问题。这个思维练习 [@problem_id:2830658] 旨在挑战您去理解这种统计偏差的内在机制，并推导出广泛应用的“留一染色体法”（LOCO）策略，以确保关联检验的有效性和统计功效。", "problem": "在一项使用线性混合模型进行的数量性状的全基因组关联研究中，您分析了 $n$ 个个体，其表型向量为 $y \\in \\mathbb{R}^{n}$。标准的线性混合模型将表型描述为固定协变量效应、待检验的单个变异效应、多基因背景和残差噪声的总和。多基因背景被建模为一个均值为零的高斯分布，其协方差与一个根据全基因组单核苷酸多态性计算出的遗传相关性（亲缘）矩阵成正比。令 $s \\in \\mathbb{R}^{n}$ 表示待检验变异的标准化的基因型向量。该模型既用于原假设检验，也用于估计变异效应。一个核心要求是，在原假设下，关联 $p$ 值是经过校准的，即当变异没有效应时，它们具有正确的分布。\n\n从关于线性混合模型的经过充分检验的事实以及多元高斯向量的性质（例如，高斯向量的条件化和线性投影仍然是高斯的，且协方差定义了随机效应可以吸收信号的方向）出发，解释“近端污染”（proximal contamination）的机制：当亲缘矩阵由包含待检验变异（或在同一染色体上处于强连锁不平衡的变异）的全基因组标记构建时，随机多基因效应会吸收一部分待检验变异的信号，从而压低检验统计量并使效应估计产生偏差。然后，推导出一个对亲缘矩阵构建的有原则的修正方法，该方法能打破这种吸收，同时保留对亲缘关系和群体结构的控制，并论证为什么这种修正方法能在全基因组范围内恢复原假设下检验统计量的校准。\n\n以下哪种策略可以从您的推导中得出，并且在存在连锁不平衡的情况下，既能保持校准又能控制亲缘关系和群体结构？\n\nA. 一次性使用所有标记（包括每个变异）构建一个单一的亲缘矩阵，并将其用于所有检验。\n\nB. 对每个待检验的变异，在移除该确切变异后重新计算亲缘矩阵，并保留所有其他标记。\n\nC. 对给定染色体上的每个待检验变异，在排除该染色体上的所有标记后重新计算亲缘矩阵，并将此针对特定染色体的排除法用于该染色体上的检验。\n\nD. 用来自全基因组标记的少数几个主成分替换混合模型中的随机效应，并使用普通最小二乘法将这些主成分作为协变量进行所有检验。", "solution": "在尝试任何解决方案之前，对问题陈述进行验证。\n\n### 步骤 1：提取已知条件\n-   该研究是一项数量性状的全基因组关联研究（GWAS）。\n-   个体数量为 $n$。\n-   表型由向量 $y \\in \\mathbb{R}^{n}$ 表示。\n-   统计模型是线性混合模型（LMM）。\n-   表型 $y$ 的 LMM 包括：固定协变量效应、单个变异效应、多基因背景和残差噪声。\n-   多基因背景是一个随机效应，被建模为均值为零的高斯分布，其协方差与一个遗传相关性（亲缘）矩阵 $K$ 成正比。\n-   亲缘矩阵 $K$ 由全基因组范围的单核苷酸多态性（SNP）计算得出。\n-   待检验变异的标准化的基因型向量用 $s \\in \\mathbb{R}^{n}$ 表示。\n-   一个关键要求是在原假设下关联 $p$ 值的校准（即它们遵循均匀分布）。\n-   问题假设存在“近端污染”：当 $K$ 是使用包含待检验变异或处于强连锁不平衡（LD）的变异的标记构建时，随机多基因效应会吸收一部分待检验变异的信号。\n-   据称这种吸收会压低检验统计量并使效应估计产生偏差。\n-   任务是解释这一机制，推导出一个有原则的修正方法来解决它，并从给定选项中确定正确的策略。\n\n### 步骤 2：使用提取的已知条件进行验证\n对问题陈述的有效性进行评估。\n\n-   **科学上合理：** 线性混合模型的描述在数量遗传学和GWAS应用中是标准且准确的。模型结构、使用亲缘矩阵建模多基因效应和控制群体结构/亲缘关系，以及“近端污染”现象，都是统计遗传学领域公认的基本概念。该问题基于可靠的统计学和遗传学原理。\n-   **定义明确：** 问题定义清晰。它要求解释一个已知的统计伪影，并推导一个标准的、公认的解决方案。问题的结构旨在引出一个在现代GWAS软件中广泛实施的、独特的概念性结论。\n-   **客观性：** 语言技术性强、精确，没有主观性或歧义。“线性混合模型”、“亲缘矩阵”、“连锁不平衡”和“$p$值校准”等术语都是标准术语，在此上下文中具有明确的含义。\n\n### 步骤 3：结论与行动\n问题陈述是有效的。这是一个关于统计遗传学中一个关键方法论问题的、表述清晰的问题。将推导解决方案。\n\n### 解题推导\n\n在一个包含 $n$ 个个体的样本中，数量性状 $y$ 的标准线性混合模型由下式给出：\n$$\ny = X\\beta + s\\gamma + u + \\epsilon\n$$\n其中：\n-   $y$ 是表型值的 $n \\times 1$ 向量。\n-   $X$ 是一个 $n \\times c$ 的矩阵，包含 $c$ 个固定效应协变量（例如，年龄、性别和用于表示血统的主成分）。\n-   $\\beta$ 是协变量的相应效应大小的 $c \\times 1$ 向量。\n-   $s$ 是待检验SNP的标准化的基因型 $n \\times 1$ 向量。\n-   $\\gamma$ 是待检验SNP的标量固定效应，是关注的参数。\n-   $u$ 是一个 $n \\times 1$ 的随机向量，代表了来自全基因组所有其他变异的聚合多基因效应。它被建模为从一个多元正态分布中抽样，$u \\sim \\mathcal{N}(0, \\sigma_g^2 K)$，其中 $\\sigma_g^2$ 是多基因方差分量，$K$ 是 $n \\times n$ 的遗传相关性（亲缘）矩阵。\n-   $\\epsilon$ 是一个 $n \\times 1$ 的非遗传和环境残差的随机向量，建模为 $\\epsilon \\sim \\mathcal{N}(0, \\sigma_e^2 I)$，其中 $\\sigma_e^2$ 是残差方差，$I$ 是 $n \\times n$ 的单位矩阵。\n\n关联检验的原假设是 $H_0: \\gamma = 0$。检验统计量（通常来自似然比检验或得分检验）评估在模型中包含 $s\\gamma$ 项的显著性。为使此检验有效，当 $H_0$ 为真时，检验统计量必须遵循其理论零分布（例如，$\\chi^2_1$ 分布）。\n\n**近端污染的机制**\n\n亲缘矩阵 $K$ 通常由一大组 $M$ 个全基因组标记估计得出。一个标准的估计量是 $K = \\frac{1}{M} \\sum_{j=1}^M s_j s_j^T$，其中 $s_j$ 是第 $j$ 个标记的标准化的基因型向量。\n\n当用于构建 $K$ 的标记集 $\\{s_j\\}_{j=1}^M$ 包含待检验的 SNP $s$ 或与 $s$ 处于强连锁不平衡（LD）的 SNP 时，问题就出现了。假设待检验的 SNP 是某个索引为 $k$ 的 $s_k$。\n\n通过在创建 $K$ 的求和中包含 $s_k$，我们明确地将项 $\\frac{1}{M} s_k s_k^T$ 包含在随机效应 $u$ 的协方差结构中。这意味着模型先验地假设，任何投影到向量 $s_k$ 方向上的表型方差都可以是随机多基因背景的一部分。\n\n当我们接着检验同一个 SNP $s_k$ 的*固定*效应 $\\gamma$ 时，我们制造了一个冲突。模型必须将与 $s_k$ 相关的表型信号划分到固定效应项 $s_k\\gamma$ 和随机效应项 $u$ 之间。由于 $u$ 的协方差被明确设计为包含沿 $s_k$ 方向的变异，随机效应 $u$ 将会“吸收”或“吸纳”一部分真实的固定效应信号。这是当固定效应和随机效应的定义向量不正交时，两者之间发生混淆的一个典型案例。\n\n这种吸收有两个主要后果：\n1.  **有偏的效应估计：** 估计值 $\\hat{\\gamma}$ 将会偏向于零，因为部分效应被错误地归因于随机项 $u$。\n2.  **被压低的检验统计量：** $\\gamma$ 的检验统计量将小于其应有值，导致统计功效的损失。在原假设下，这也会导致全基因组范围内检验统计量出现微小但系统性的压低，从而导致校准失效（即，$p$ 值系统性地大于原假设下的预期值）。这是因为即使在待检验SNP的原假设下，与附近真实致病变异的LD会产生一个局部信号，这个信号被受污染的随机效应吸收，再次压低了检验统计量。\n\n如果我们检验SNP $s_k$，但亲缘矩阵 $K$ 包含另一个与 $s_k$ 处于强LD的SNP $s_j$，也会发生同样的问题。在这种情况下，它们的基因型向量高度相关（$s_k \\approx \\rho s_j$），因此在构建 $K$ 时包含 $s_j$ 会在 $u$ 的协方差中提供一个与待检验的固定效应向量 $s_k$ 几乎共线的向量，导致同样的吸收现象。这就是“近端污染”，因为污染源自于遗传上接近（因此与待检验标记处于LD）的标记。\n\n**对亲缘矩阵构建的有原则的修正**\n\n为了消除这种混淆，我们必须确保随机效应 $u$ 和固定效应 $s\\gamma$ 不是使用重叠信息定义的。用于检验固定效应的向量 $s$ 必须与为随机多基因背景定义的变异空间正交。\n\n实现这一点的直接方法是仅使用与待检验标记 $s$ 不处于LD的标记来构建亲缘矩阵 $K$。由于减数分裂和重组的性质，不同染色体上的标记通常不处于LD（除了由群体结构引起的远距离相关性，而LMM的设计初衷正是为了全局性地捕捉这一点）。在同一条染色体内，LD在邻近标记间很强，并随距离增加而衰减。\n\n因此，一个有原则且稳健的策略是按染色体划分基因组。当检验特定染色体（比如染色体 $i$）上的任何SNP时，我们应该使用一个*仅*由所有其他染色体上的标记构建的亲缘矩阵来建模多基因背景。\n\n令 $K_{(-i)}$ 是由*不*在染色体 $i$ 上的所有SNP计算出的亲缘矩阵。当检验位于染色体 $i$ 上的一个SNP $s$ 时，模型变为：\n$$\ny = X\\beta + s\\gamma + u_{(-i)} + \\epsilon\n$$\n其中 $u_{(-i)} \\sim \\mathcal{N}(0, \\sigma_g^2 K_{(-i)})$。\n\n这种方法被称为“留一染色体法”（Leave-One-Chromosome-Out, LOCO），它确保了待检验的固定效应 $s\\gamma$ 不与随机效应 $u_{(-i)}$ 混淆。随机效应对来自染色体 $1, 2, ..., i-1, i+1, ...$ 的背景进行建模，而固定效应则对染色体 $i$ 上的局部信号进行建模。这正确地将检验信号从背景模型中分离出来，打破了近端污染的机制。这恢复了检验统计量的校准，并为染色体 $i$ 上的变异提供了无偏的效应估计，同时仍然控制了来自基因组其余部分的群体结构和多基因背景。对每条染色体都重复此过程。\n\n### 选项评估\n\n**A. 一次性使用所有标记（包括每个变异）构建一个单一的亲缘矩阵，并将其用于所有检验。**\n这是导致“近端污染”的标准方法。如上文所推导，在亲缘矩阵的构建中包含待检验变异（或处于LD的变异）会导致检验统计量被压低和估计有偏。该策略未能保持校准。\n**结论：不正确**\n\n**B. 对每个待检验的变异，在移除该确切变异后重新计算亲缘矩阵，并保留所有其他标记。**\n这种修正是不足的。虽然它移除了待检验变异 $s$ 的直接包含，但未能解释LD。紧邻 $s$ 且与其处于强LD的标记仍将保留在亲缘矩阵的计算中。它们与 $s$ 的高度相关性意味着随机效应仍将吸收 $s$ 的信号，“近端污染”将持续存在。这种方法在计算上也是不可行的，需要为每个SNP检验重新计算一次亲缘矩阵。\n**结论：不正确**\n\n**C. 对给定染色体上的每个待检验变异，在排除该染色体上的所有标记后重新计算亲缘矩阵，并将此针对特定染色体的排除法用于该染色体上的检验。**\n这就是上面推导出的“留一染色体法”（LOCO）策略。它正确地将被检验的信号（在一条染色体上）与多基因背景模型（由所有其他染色体构建）分离开来，从而消除了“近端污染”。它保留了对亲缘关系和群体结构的控制，因为这些是由其余染色体捕捉到的全基因组属性。该策略恢复了检验统计量的校准。\n**结论：正确**\n\n**D. 用来自全基因组标记的少数几个主成分替换混合模型中的随机效应，并使用普通最小二乘法将这些主成分作为协变量进行所有检验。**\n这描述的是一种替代的建模策略（PCA + OLS），而不是对LMM亲缘矩阵构建的修正。当性状存在显著的多基因成分时，其功效不如LMM，因为它没有显式地建模由隐性亲缘关系和数千个微小效应变异引起的协方差。问题要求的是*在LMM框架内对亲缘矩阵构建*的有原则的修正，而不是替换整个模型。此外，当亲缘关系未被完全捕捉时，带有主成分的OLS可能会遭受其自身形式的检验统计量膨胀。该选项不是从推导中得出的。\n**结论：不正确**", "answer": "$$\\boxed{C}$$", "id": "2830658"}]}