{"hands_on_practices": [{"introduction": "任何数量性状响应选择的潜力都取决于其可遗传的变异量。因此，量化遗传和环境因素对表型变异的贡献，是定量遗传学研究的基石。本练习将指导您使用线性混合模型（LMM）和约束性最大似然法（REML）来剖分表型方差，这两种方法是现代遗传学中估算遗传力的黄金标准 [@problem_id:2744356]。通过亲手实现这一核心统计方法，您将深入理解如何从观测数据中提取驱动演化的关键参数，例如狭义遗传力 $h^2$。", "problem": "给定多个独立群体，其规模不相关，表达一个由许多小效应位点（多基因）形成的数量性状。假设以下基本前提：个体的数量性状值遵循一个线性混合模型，该模型包含一个加性遗传随机效应（通过亲缘矩阵捕捉共享的祖先关系）和一个独立的环境残差。在此基础上，对于一个在固定效应设计中包含截距的、大小为 $n$ 的样本，性状向量的分布是多元正态的，并且性状的方差可以分解为一个与亲缘矩阵成比例的加性遗传分量和一个与单位矩阵成比例的环境分量。目标是通过最大化限制性似然来联合估计加性遗传方差和环境方差，然后计算窄义遗传力，其定义为可归因于加性遗传效应的表型方差的比例。您的任务是实现一个程序，通过对限制性似然进行数值优化来执行此估计，并使用稳定的线性代数方法。\n\n使用以下模型定义和约束：\n- 令性状向量表示为 $y \\in \\mathbb{R}^{n}$，固定效应设计矩阵为 $X \\in \\mathbb{R}^{n \\times p}$，且仅包含截距（因此 $p = 1$ 且 $X$ 是一个全为1的列向量）。令亲缘矩阵为 $K \\in \\mathbb{R}^{n \\times n}$，该矩阵为对称半正定矩阵。\n- 方差分量为加性遗传方差 $\\sigma_{g}^{2}$ 和环境方差 $\\sigma_{e}^{2}$，两者均为严格为正的实数。\n- $y$ 的协方差是加性遗传协方差和环境协方差之和。您必须使用一种能够保证方差分量为正的数值稳定方法，来最大化关于 $\\sigma_{g}^{2}$ 和 $\\sigma_{e}^{2}$ 的限制性似然。\n- 在估计出 $\\widehat{\\sigma}_{g}^{2}$ 和 $\\widehat{\\sigma}_{e}^{2}$ 后，计算窄义遗传力 $h^{2}$，即总表型方差中可归因于加性遗传效应的比例。报告每个测试用例的 $h^{2}$。\n- 所有计算都必须使用浮点数算术进行。不涉及角度。不需要物理单位。最终数值答案以小数形式表示（而非分数），并四舍五入到四位小数。\n\n测试套件的输入数据如下所示。对于每个用例，给定一个因子矩阵 $B$（必须通过 $K = B B^{\\top}$ 来构建亲缘矩阵 $K$ 以确保其半正定性）和一个观测到的性状向量 $y$。在所有用例中，使用仅含截距的设计矩阵 $X$，其元素均为1。实现一个对条件数稳健的限制性似然数值优化，使用重参数化方法强制 $\\sigma_{g}^{2}  0$ 和 $\\sigma_{e}^{2}  0$，并使用稳定的求解器来处理线性系统和对数行列式。\n\n测试套件：\n- 用例 A（中等遗传力）：\n  - $B = \\begin{bmatrix}\n  1.2  0.0  0.0 \\\\\n  0.6  0.3  0.0 \\\\\n  0.4  0.8  0.2 \\\\\n  0.0  0.5  0.7 \\\\\n  0.0  0.2  1.0 \\\\\n  0.0  0.0  0.9\n  \\end{bmatrix}$\n  - $y = \\begin{bmatrix} 1.04  0.61  0.82  0.25  -0.04  -0.20 \\end{bmatrix}^{\\top}$\n- 用例 B（近零遗传力）：\n  - $B$ 与用例 A 相同。\n  - $y = \\begin{bmatrix} 0.30  -0.70  0.20  -0.10  0.05  -0.30 \\end{bmatrix}^{\\top}$\n- 用例 C（高遗传力）：\n  - $B = \\begin{bmatrix}\n  1.0  0.0 \\\\\n  0.8  0.2 \\\\\n  0.6  0.4 \\\\\n  0.4  0.6 \\\\\n  0.2  0.8\n  \\end{bmatrix}$\n  - $y = \\begin{bmatrix} 1.01  0.79  0.605  0.395  0.20 \\end{bmatrix}^{\\top}$\n- 用例 D（中等遗传力，不同结构和大小）：\n  - $B = \\begin{bmatrix}\n  1.0  0.0  0.0 \\\\\n  0.7  0.2  0.0 \\\\\n  0.5  0.4  0.1 \\\\\n  0.3  0.6  0.2 \\\\\n  0.1  0.8  0.3 \\\\\n  0.0  0.6  0.5 \\\\\n  0.0  0.3  0.9\n  \\end{bmatrix}$\n  - $y = \\begin{bmatrix} 0.55  0.40  0.45  0.42  0.47  0.32  0.33 \\end{bmatrix}^{\\top}$\n\n要求和输出格式：\n- 为每个用例通过 $K = B B^{\\top}$ 构建 $K$。\n- 给定 $y$、$X$ 和 $K$，通过最大化关于 $\\widehat{\\sigma}_{g}^{2}$ 和 $\\widehat{\\sigma}_{e}^{2}$ 的限制性似然来估计它们。使用数值稳定的线性代数方法（例如，避免显式矩阵求逆的分解方法）和确保方差分量为正的无约束重参数化方法。\n- 对每个用例，根据估计的方差分量计算窄义遗传力 $h^{2}$。\n- 您的程序应生成单行输出，其中包含四个遗传力估计值的逗号分隔列表，每个值四舍五入到四位小数，并用方括号括起来，顺序为用例 A、用例 B、用例 C、用例 D。例如，正确格式的输出是 $[\\;0.5023,0.0311,0.9120,0.4722\\;]$（这些是示例值，不是要求的答案）。", "solution": "所提出的问题是统计遗传学中的一个标准且定义明确的任务：使用限制性最大似然（REML）估计线性混合模型（LMM）中的方差分量。该问题具有科学依据，没有矛盾，并包含了解决问题所需的所有信息。因此，我将提供一个完整的解决方案。\n\n数量性状向量 $y \\in \\mathbb{R}^n$ 的基本模型是LMM：\n$$ y = X\\beta + u + \\epsilon $$\n其中：\n- $X \\in \\mathbb{R}^{n \\times p}$ 是固定效应的设计矩阵，在本问题中是一个全为1的单列向量（$p=1$），代表全局截距。\n- $\\beta \\in \\mathbb{R}^p$ 是固定效应向量。\n- $u \\in \\mathbb{R}^n$ 是随机遗传效应向量，假设服从多元正态分布 $u \\sim \\mathcal{N}(0, \\sigma_g^2 K)$，其中 $\\sigma_g^2$ 是加性遗传方差， $K$ 是源于祖先关系的亲缘矩阵。\n- $\\epsilon \\in \\mathbb{R}^n$ 是随机环境和非遗传效应向量，假设服从 $\\epsilon \\sim \\mathcal{N}(0, \\sigma_e^2 I)$，其中 $\\sigma_e^2$ 是环境方差， $I$ 是 $n \\times n$ 的单位矩阵。\n\n假设随机效应 $u$ 和 $\\epsilon$ 是独立的。因此，性状向量 $y$ 服从多元正态分布：\n$$ y \\sim \\mathcal{N}(X\\beta, V) $$\n其中总协方差矩阵 $V$ 由下式给出：\n$$ V(\\sigma_g^2, \\sigma_e^2) = \\sigma_g^2 K + \\sigma_e^2 I $$\n目标是估计方差分量 $\\sigma_g^2$ 和 $\\sigma_e^2$。一个简单的最大似然估计会产生有偏估计，因为它没有考虑因估计固定效应 $\\beta$ 而损失的自由度。REML通过最大化一组不依赖于 $\\beta$ 的 $n-p$ 个线性无关的 $y$ 的对比的似然来纠正这一点。\n\n忽略常数项，需要就 $\\sigma_g^2$ 和 $\\sigma_e^2$ 进行最大化的REML对数似然函数为：\n$$ \\ell_{\\text{REML}}(\\sigma_g^2, \\sigma_e^2 | y) = -\\frac{1}{2} \\log\\det(V) - \\frac{1}{2} \\log\\det(X^\\top V^{-1} X) - \\frac{1}{2} y^\\top P y $$\n其中 $P$ 是投影矩阵 $P = V^{-1} - V^{-1}X(X^\\top V^{-1}X)^{-1}X^\\top V^{-1}$。\n\n由于需要显式计算矩阵逆（$V^{-1}$）和行列式，直接最大化此函数在数值上是有问题的。必须采用数值稳定的方法。此外，方差分量必须严格为正，即 $\\sigma_g^2  0$ 和 $\\sigma_e^2  0$。处理这种约束优化的最佳方法是将其重参数化为一个无约束问题。我们定义新的参数：\n$$ \\theta_g = \\log(\\sigma_g^2) \\quad \\text{和} \\quad \\theta_e = \\log(\\sigma_e^2) $$\n然后对 $(\\theta_g, \\theta_e) \\in \\mathbb{R}^2$ 进行优化。方差分量通过 $\\sigma_g^2 = \\exp(\\theta_g)$ 和 $\\sigma_e^2 = \\exp(\\theta_e)$ 恢复，从而保证其为正。\n\nREML似然的各分量将使用稳定的矩阵分解来计算。由于 $K$ 是半正定的且 $\\sigma_e^2  0$，矩阵 $V = \\sigma_g^2 K + \\sigma_e^2 I$ 保证是对称正定的。因此，它允许进行Cholesky分解 $V = LL^\\top$，其中 $L$ 是一个下三角矩阵。这种分解是稳定实现方法的基石。\n\n负对数似然函数（我们将最小化该函数）中的各项计算如下：\n1.  **$V$ 的对数行列式**：$\\log\\det(V) = \\log\\det(LL^\\top) = 2 \\log\\det(L) = 2 \\sum_{i=1}^{n} \\log(L_{ii})$。\n2.  **求解线性系统**：我们不计算 $V^{-1}$，而是求解线性系统。对于一个向量 $z$，乘积 $V^{-1}z$ 通过求解 $Vw = z$ 来得到 $w$。使用Cholesky因子，这通过两次三角求解来完成：首先求解 $Lq = z$ 得到 $q$（前向替换），然后求解 $L^\\top w = q$ 得到 $w$（后向替换）。\n3.  **$X^\\top V^{-1} X$ 的对数行列式**：我们来计算矩阵 $A = X^\\top V^{-1} X$。其第 $j$ 列是 $X^\\top V^{-1} X_j$，其中 $X_j$ 是 $X$ 的第 $j$ 列。我们首先用上面描述的Cholesky方法求解 $W_j = V^{-1}X_j$。然后计算 $X^\\top W_j$。对于本问题，$p=1$ 且 $X$ 是一个全为1的列向量，所以 $X^\\top V^{-1} X$ 是一个标量。我们求解 $Vw_x = X$ 得到 $w_x$，然后计算标量 $s_{xx} = X^\\top w_x$。对数行列式项就是 $\\log(s_{xx})$。\n4.  **二次型 $y^\\top P y$**：\n    $$ y^\\top P y = y^\\top V^{-1} y - y^\\top V^{-1} X (X^\\top V^{-1} X)^{-1} X^\\top V^{-1} y $$\n    我们求解 $Vw_y = y$ 得到 $w_y$。那么 $y^\\top V^{-1} y = y^\\top w_y$。项 $X^\\top V^{-1} y$ 就是 $X^\\top w_y$。我们称这个标量为 $s_{xy}$。二次型变为 $y^\\top w_y - s_{xy}^2 / s_{xx}$。\n\n需要通过数值优化算法（例如，Nelder-Mead 或 L-BFGS）最小化的目标函数是负的REML对数似然：\n$$ f(\\theta_g, \\theta_e) = \\frac{1}{2} \\left[ \\log\\det(V) + \\log(s_{xx}) + (y^\\top w_y - s_{xy}^2 / s_{xx}) \\right] $$\n其中 $V$、$s_{xx}$、$s_{xy}$ 和 $w_y$ 都依赖于 $\\theta_g$ 和 $\\theta_e$。\n\n在找到最小化 $f$ 的最优参数 $(\\widehat{\\theta}_g, \\widehat{\\theta}_e)$ 后，估计的方差分量为：\n$$ \\widehat{\\sigma}_g^2 = \\exp(\\widehat{\\theta}_g) \\quad \\text{和} \\quad \\widehat{\\sigma}_e^2 = \\exp(\\widehat{\\theta}_e) $$\n最后，窄义遗传力 $h^2$ 被计算为总方差中可归因于加性遗传效应的比例：\n$$ h^2 = \\frac{\\widehat{\\sigma}_g^2}{\\widehat{\\sigma}_g^2 + \\widehat{\\sigma}_e^2} $$\n\n实现过程将通过定义一个Python函数来计算给定数据集 $(y, K)$ 的 $f(\\theta_g, \\theta_e)$。然后将此函数传递给 `scipy.optimize` 库中的优化器。对每个测试用例重复此过程。", "answer": "```python\nimport numpy as np\nfrom scipy.linalg import cho_factor, cho_solve\nfrom scipy.optimize import minimize\n\ndef solve():\n    \"\"\"\n    Solves the heritability estimation problem for all test cases.\n    \"\"\"\n\n    # Test suite data\n    B_A = np.array([\n        [1.2, 0.0, 0.0],\n        [0.6, 0.3, 0.0],\n        [0.4, 0.8, 0.2],\n        [0.0, 0.5, 0.7],\n        [0.0, 0.2, 1.0],\n        [0.0, 0.0, 0.9]\n    ])\n    y_A = np.array([1.04, 0.61, 0.82, 0.25, -0.04, -0.20])\n\n    B_B = B_A\n    y_B = np.array([0.30, -0.70, 0.20, -0.10, 0.05, -0.30])\n    \n    B_C = np.array([\n        [1.0, 0.0],\n        [0.8, 0.2],\n        [0.6, 0.4],\n        [0.4, 0.6],\n        [0.2, 0.8]\n    ])\n    y_C = np.array([1.01, 0.79, 0.605, 0.395, 0.20])\n\n    B_D = np.array([\n        [1.0, 0.0, 0.0],\n        [0.7, 0.2, 0.0],\n        [0.5, 0.4, 0.1],\n        [0.3, 0.6, 0.2],\n        [0.1, 0.8, 0.3],\n        [0.0, 0.6, 0.5],\n        [0.0, 0.3, 0.9]\n    ])\n    y_D = np.array([0.55, 0.40, 0.45, 0.42, 0.47, 0.32, 0.33])\n\n    test_cases = [\n        (B_A, y_A),\n        (B_B, y_B),\n        (B_C, y_C),\n        (B_D, y_D),\n    ]\n\n    results = []\n    \n    for B, y in test_cases:\n        n = y.shape[0]\n        K = B @ B.T\n        X = np.ones((n, 1))\n\n        def neg_reml_log_likelihood(log_vars):\n            \"\"\"\n            Computes the negative REML log-likelihood for given log-variances.\n            Parameters are log(sigma_g^2) and log(sigma_e^2).\n            \"\"\"\n            sigma2_g = np.exp(log_vars[0])\n            sigma2_e = np.exp(log_vars[1])\n\n            # Form the covariance matrix V = sigma_g^2 * K + sigma_e^2 * I\n            V = sigma2_g * K + sigma2_e * np.identity(n)\n\n            try:\n                # Cholesky decomposition of V\n                # This is numerically stable and efficient for SPD matrices.\n                L, lower = cho_factor(V, lower=True)\n            except np.linalg.LinAlgError:\n                # V is not positive definite, return a large value\n                # to guide the optimizer away.\n                return 1e10\n            \n            # log(det(V)) = 2 * sum(log(diag(L)))\n            log_det_V = 2 * np.sum(np.log(np.diag(L)))\n\n            # Solve linear systems to avoid explicit inversion of V\n            # Find w_x = V^{-1} * X\n            w_x = cho_solve((L, lower), X)\n            # Find w_y = V^{-1} * y\n            w_y = cho_solve((L, lower), y)\n\n            # Compute terms for the REML likelihood\n            s_xx = X.T @ w_x\n            # For p=1, s_xx is a 1x1 matrix.\n            s_xx_scalar = s_xx[0, 0]\n            log_det_S_xx = np.log(s_xx_scalar)\n\n            s_xy = X.T @ w_y\n            y_T_w_y = y.T @ w_y\n            \n            # Quadratic form y^T * P * y\n            y_P_y = y_T_w_y - (s_xy[0] ** 2) / s_xx_scalar\n            \n            # The negative REML log-likelihood (to be minimized)\n            # We ignore constant terms like log(2*pi)\n            neg_ll = 0.5 * (log_det_V + log_det_S_xx + y_P_y)\n            return neg_ll\n\n        # Initial guess for the optimizer\n        # A reasonable guess is that genetic and environmental variances\n        # are each half of the total phenotypic variance.\n        var_y = np.var(y, ddof=1)\n        initial_sigma2 = var_y / 2.0\n        # If variance is zero or negative (unlikely but possible with weird data)\n        if initial_sigma2 = 0:\n            initial_sigma2 = 1.0\n            \n        x0 = np.array([np.log(initial_sigma2), np.log(initial_sigma2)])\n\n        # Perform the optimization using a robust method like Nelder-Mead\n        opt_result = minimize(\n            neg_reml_log_likelihood, \n            x0, \n            method='Nelder-Mead',\n            options={'xatol': 1e-8, 'fatol': 1e-8}\n        )\n        \n        # Extract estimated log variances\n        opt_log_vars = opt_result.x\n        \n        # Convert back to variance components\n        opt_sigma2_g = np.exp(opt_log_vars[0])\n        opt_sigma2_e = np.exp(opt_log_vars[1])\n\n        # Compute narrow-sense heritability\n        h2 = opt_sigma2_g / (opt_sigma2_g + opt_sigma2_e)\n        \n        # Handle potential boundary case where h2 is effectively zero\n        if h2  1e-8:\n             h2 = 0.0\n\n        results.append(round(h2, 4))\n\n    # Format the final output as a single string\n    formatted_results = f\"[{','.join(f'{r:.4f}' for r in results)}]\"\n    print(formatted_results)\n\nsolve()\n```", "id": "2744356"}, {"introduction": "在掌握了如何量化可遗传变异后，下一步便是预测性状在选择压力下的演化轨迹。本练习聚焦于经典的 Lande-Arnold 框架，它将性状均值的演化响应 $\\Delta \\bar{\\mathbf{z}}$ 与加性遗传方差-协方差矩阵 $\\mathbf{G}$ 及选择梯度 $\\boldsymbol{\\beta}$ 精确地联系起来 [@problem_id:2744372]。您将推导并实现一个模型，模拟在移动的最适表型值（moving optimum）作用下，种群如何通过稳定化选择（stabilizing selection）进行适应，这是理解种群适应环境变化的核心场景。", "problem": "你需要编写一个完整的程序，该程序利用“方向性选择源于对数适应度相对于性状均值的梯度”以及“连锁平衡下的标准数量遗传选择响应”这两个原理，计算一个数量多基因性状向量均值在具有潜在移动最适值的稳定性选择下的确定性演化响应。\n\n起始基础：\n- 仅使用以下基础元素：\n  1. 马尔萨斯适应度的定义，即绝对适应度的自然对数。如果绝对适应度是 $W(\\mathbf{z})$，那么马尔萨斯适应度是 $m(\\mathbf{z}) = \\ln W(\\mathbf{z})$。\n  2. 选择梯度的定义，即马尔萨斯适应度相对于性状向量的梯度，即 $\\boldsymbol{\\beta}(\\mathbf{z}) = \\nabla_{\\mathbf{z}} m(\\mathbf{z})$。\n  3. 在标准数量遗传假设（弱选择、加性效应、连锁平衡（LE）以及近似恒定的加性遗传方差-协方差）下，一代内性状均值的变化与选择梯度成正比，其比例关系通过加性遗传方差-协方差矩阵确定。你必须从这些基础推导出明确的比例关系。\n  4. 一种广泛使用且有经验基础的、作用于多变量数量性状（性状向量为 $\\mathbf{z} \\in \\mathbb{R}^n$）的稳定性选择形式，由以下形式的绝对适应度函数给出：\n     $$W(\\mathbf{z}; \\boldsymbol{\\theta}_t) = \\exp\\!\\left(-\\tfrac{1}{2}(\\mathbf{z}-\\boldsymbol{\\theta}_t)^{\\mathsf{T}} \\boldsymbol{\\Omega}^{-1} (\\mathbf{z}-\\boldsymbol{\\theta}_t)\\right),$$\n     其中 $\\boldsymbol{\\theta}_t \\in \\mathbb{R}^n$ 是第 $t$ 代的最适值，$\\boldsymbol{\\Omega} \\in \\mathbb{R}^{n \\times n}$ 是对称正定矩阵，其元素指定了稳定性选择的强度和相关结构。\n- 你必须使用以上元素作为基本依据，推导出一个确定性的离散时间更新公式，用于计算在 $T$ 代中均值性状向量 $\\overline{\\mathbf{z}}_t$ 的变化。给定一个恒定的加性遗传方差-协方差矩阵 $\\mathbf{G} \\in \\mathbb{R}^{n \\times n}$，一个线性最适值路径 $\\boldsymbol{\\theta}_t = \\boldsymbol{\\theta}_0 + t\\,\\mathbf{v}$（其中速度 $\\mathbf{v} \\in \\mathbb{R}^n$ 固定），以及初始均值 $\\overline{\\mathbf{z}}_0$。\n\n任务：\n- 通过结合上述基础元素，推导出 $\\overline{\\mathbf{z}}_{t+1}$ 关于 $\\overline{\\mathbf{z}}_t$、$\\boldsymbol{\\theta}_t$、$\\boldsymbol{\\Omega}$ 和 $\\mathbf{G}$ 的明确确定性更新公式。实现该更新并在 $T$ 代中进行迭代，以获得 $\\overline{\\mathbf{z}}_T$。\n- 你可以假设在所有测试用例中 $\\boldsymbol{\\Omega}$ 都是对称正定的，因此 $\\boldsymbol{\\Omega}^{-1}$ 存在。但不能假设 $\\mathbf{G}$ 是可逆的。\n\n输入和测试套件规范：\n- 程序没有外部输入；请在程序中硬编码以下测试套件。对于每个测试用例 $i$，给定性状维度 $n$、初始均值 $\\overline{\\mathbf{z}}_0^{(i)}$、加性遗传方差-协方差 $\\mathbf{G}^{(i)}$、稳定性选择矩阵 $\\boldsymbol{\\Omega}^{(i)}$、初始最适值 $\\boldsymbol{\\theta}_0^{(i)}$、最适值速度 $\\mathbf{v}^{(i)}$ 以及世代数 $T^{(i)}$。对于每个测试用例，计算 $\\overline{\\mathbf{z}}_{T^{(i)}}^{(i)}$。\n\n测试用例：\n1. 一维，静态最适值：\n   - $n = 1$\n   - $\\overline{\\mathbf{z}}_0^{(1)} = (0.0)$\n   - $\\mathbf{G}^{(1)} = \\begin{bmatrix} 0.2 \\end{bmatrix}$\n   - $\\boldsymbol{\\Omega}^{(1)} = \\begin{bmatrix} 1.0 \\end{bmatrix}$\n   - $\\boldsymbol{\\theta}_0^{(1)} = (1.5)$\n   - $\\mathbf{v}^{(1)} = (0.0)$\n   - $T^{(1)} = 5$\n\n2. 二维，相关的 $\\mathbf{G}$，静态最适值：\n   - $n = 2$\n   - $\\overline{\\mathbf{z}}_0^{(2)} = (0.0, 0.0)$\n   - $\\mathbf{G}^{(2)} = \\begin{bmatrix} 0.1  0.05 \\\\ 0.05  0.2 \\end{bmatrix}$\n   - $\\boldsymbol{\\Omega}^{(2)} = \\begin{bmatrix} 1.0  0.0 \\\\ 0.0  1.5 \\end{bmatrix}$\n   - $\\boldsymbol{\\theta}_0^{(2)} = (1.0, -0.5)$\n   - $\\mathbf{v}^{(2)} = (0.0, 0.0)$\n   - $T^{(2)} = 10$\n\n3. 一维，零加性方差（无响应）：\n   - $n = 1$\n   - $\\overline{\\mathbf{z}}_0^{(3)} = (0.0)$\n   - $\\mathbf{G}^{(3)} = \\begin{bmatrix} 0.0 \\end{bmatrix}$\n   - $\\boldsymbol{\\Omega}^{(3)} = \\begin{bmatrix} 0.5 \\end{bmatrix}$\n   - $\\boldsymbol{\\theta}_0^{(3)} = (1.0)$\n   - $\\mathbf{v}^{(3)} = (0.0)$\n   - $T^{(3)} = 7$\n\n4. 二维，弱稳定性选择：\n   - $n = 2$\n   - $\\overline{\\mathbf{z}}_0^{(4)} = (0.2, -0.2)$\n   - $\\mathbf{G}^{(4)} = \\begin{bmatrix} 0.05  0.0 \\\\ 0.0  0.05 \\end{bmatrix}$\n   - $\\boldsymbol{\\Omega}^{(4)} = \\begin{bmatrix} 100.0  0.0 \\\\ 0.0  100.0 \\end{bmatrix}$\n   - $\\boldsymbol{\\theta}_0^{(4)} = (1.0, 1.0)$\n   - $\\mathbf{v}^{(4)} = (0.0, 0.0)$\n   - $T^{(4)} = 10$\n\n5. 二维，具有相关稳定性选择的移动最适值：\n   - $n = 2$\n   - $\\overline{\\mathbf{z}}_0^{(5)} = (0.0, 0.0)$\n   - $\\mathbf{G}^{(5)} = \\begin{bmatrix} 0.05  0.0 \\\\ 0.0  0.05 \\end{bmatrix}$\n   - $\\boldsymbol{\\Omega}^{(5)} = \\begin{bmatrix} 1.0  0.2 \\\\ 0.2  1.0 \\end{bmatrix}$\n   - $\\boldsymbol{\\theta}_0^{(5)} = (0.0, 0.0)$\n   - $\\mathbf{v}^{(5)} = (0.1, -0.05)$\n   - $T^{(5)} = 20$\n\n输出要求：\n- 对于每个测试用例 $i$，计算 $\\overline{\\mathbf{z}}_{T^{(i)}}^{(i)}$。\n- 将每个结果向量的每个分量四舍五入到恰好 $6$ 位小数。\n- 你的程序应生成单行输出，其中包含结果，形式为逗号分隔的向量列表，每个向量用方括号括起来，整个集合也用方括号括起来。例如，格式应类似于 $[\\,[a_{1,1},a_{1,2}],\\,[a_{2,1},a_{2,2}]\\,]$，但用实际数字代替符号，且没有空格。\n- 不涉及物理单位。\n\n科学真实性约束：\n- 假设在模拟时间内为弱选择和加性效应，$\\mathbf{G}$ 近似恒定，且满足连锁平衡（LE）。确保在所有计算中 $\\boldsymbol{\\Omega}$ 都是对称正定的，以便 $\\boldsymbol{\\Omega}^{-1}$ 存在。\n\n你的程序必须是自包含的，并且不得读取任何外部输入。", "solution": "所呈现的问题是演化数量遗传学中一个定义明确且具有科学依据的练习。它要求推导并实现一个离散时间模型，用于描述多变量多基因性状在具有线性移动最适值的稳定性选择下的演化。问题陈述提供了所有必要的组成部分，并遵循了该领域的既定原则。因此，该问题被认为是有效的。\n\n目标是推导出均值性状向量 $\\overline{\\mathbf{z}}_t$ 的确定性离散时间更新方程，并将该方程迭代指定的世代数 $T$，以找到最终的均值性状向量 $\\overline{\\mathbf{z}}_T$。推导将从所提供的基础元素开始。\n\n首先，给定第 $t$ 代具有性状向量 $\\mathbf{z} \\in \\mathbb{R}^n$ 的个体的绝对适应度函数：\n$$W(\\mathbf{z}; \\boldsymbol{\\theta}_t) = \\exp\\!\\left(-\\tfrac{1}{2}(\\mathbf{z}-\\boldsymbol{\\theta}_t)^{\\mathsf{T}} \\boldsymbol{\\Omega}^{-1} (\\mathbf{z}-\\boldsymbol{\\theta}_t)\\right)$$\n这里，$\\boldsymbol{\\theta}_t$ 是第 $t$ 代的最适性状向量，$\\boldsymbol{\\Omega}$ 是一个对称正定矩阵，描述了稳定性选择的强度。较大的 $\\boldsymbol{\\Omega}$ 对应于较弱的选择。\n\n马尔萨斯适应度 $m(\\mathbf{z})$ 是绝对适应度 $W(\\mathbf{z})$ 的自然对数。\n$$m(\\mathbf{z}; \\boldsymbol{\\theta}_t) = \\ln W(\\mathbf{z}; \\boldsymbol{\\theta}_t) = -\\frac{1}{2}(\\mathbf{z}-\\boldsymbol{\\theta}_t)^{\\mathsf{T}} \\boldsymbol{\\Omega}^{-1} (\\mathbf{z}-\\boldsymbol{\\theta}_t)$$\n这个函数是一个二次曲面，简化了后续分析。\n\n接下来，我们定义选择梯度，它衡量作用于性状上的方向性选择力。马尔萨斯适应度相对于性状向量 $\\mathbf{z}$ 的梯度是：\n$$\\boldsymbol{\\beta}(\\mathbf{z}) = \\nabla_{\\mathbf{z}} m(\\mathbf{z}; \\boldsymbol{\\theta}_t)$$\n使用二次型微分的标准法则，对于对称矩阵 $\\mathbf{A}$，$\\nabla_{\\mathbf{x}} (\\mathbf{x}-\\mathbf{c})^{\\mathsf{T}}\\mathbf{A}(\\mathbf{x}-\\mathbf{c}) = 2\\mathbf{A}(\\mathbf{x}-\\mathbf{c})$，并注意到由于 $\\boldsymbol{\\Omega}$ 是对称的，$\\boldsymbol{\\Omega}^{-1}$ 也是对称的，我们得到：\n$$\\boldsymbol{\\beta}(\\mathbf{z}) = -\\frac{1}{2} \\cdot 2\\boldsymbol{\\Omega}^{-1}(\\mathbf{z}-\\boldsymbol{\\theta}_t) = -\\boldsymbol{\\Omega}^{-1}(\\mathbf{z}-\\boldsymbol{\\theta}_t)$$\n\n群体均值性状的演化响应 $\\Delta \\overline{\\mathbf{z}}_t = \\overline{\\mathbf{z}}_{t+1} - \\overline{\\mathbf{z}}_t$ 受多变量育种家方程的支配。这个数量遗传学的基本结果指出，均值的变化是加性遗传方差-协方差矩阵 $\\mathbf{G}$ 与作用于群体均值上的选择梯度 $\\boldsymbol{\\beta}_t$ 的乘积：\n$$\\Delta \\overline{\\mathbf{z}}_t = \\mathbf{G} \\boldsymbol{\\beta}_t$$\n均值上的选择梯度 $\\boldsymbol{\\beta}_t$ 在形式上是均值对数适应度相对于均值性状的梯度，即 $\\boldsymbol{\\beta}_t = \\nabla_{\\overline{\\mathbf{z}}} \\overline{m(\\mathbf{z})}$。在表型围绕均值 $\\overline{\\mathbf{z}}_t$ 对称分布（例如，多维正态分布）的标准假设下，对于给定的二次适应度曲面，这个群体水平的梯度恰好是在群体均值性状值处评估的个体水平梯度：\n$$\\boldsymbol{\\beta}_t = \\boldsymbol{\\beta}(\\overline{\\mathbf{z}}_t) = -\\boldsymbol{\\Omega}^{-1}(\\overline{\\mathbf{z}}_t - \\boldsymbol{\\theta}_t)$$\n这个近似是 Lande-Arnold 框架的核心，并且由问题的结构所隐含要求，该结构省略了完整的表型协方差矩阵。\n\n将这个 $\\boldsymbol{\\beta}_t$ 的表达式代入育种家方程，我们得到一代内均值性状向量的变化：\n$$\\Delta \\overline{\\mathbf{z}}_t = \\mathbf{G} \\left( -\\boldsymbol{\\Omega}^{-1}(\\overline{\\mathbf{z}}_t - \\boldsymbol{\\theta}_t) \\right) = -\\mathbf{G} \\boldsymbol{\\Omega}^{-1}(\\overline{\\mathbf{z}}_t - \\boldsymbol{\\theta}_t)$$\n\n由此，我们推导出从第 $t$ 代到第 $t+1$ 代均值性状向量的明确、确定性更新规则：\n$$\\overline{\\mathbf{z}}_{t+1} = \\overline{\\mathbf{z}}_t + \\Delta \\overline{\\mathbf{z}}_t = \\overline{\\mathbf{z}}_t - \\mathbf{G} \\boldsymbol{\\Omega}^{-1}(\\overline{\\mathbf{z}}_t - \\boldsymbol{\\theta}_t)$$\n\n问题指定了一个线性变化的最适值：\n$$\\boldsymbol{\\theta}_t = \\boldsymbol{\\theta}_0 + t\\,\\mathbf{v}$$\n其中 $\\boldsymbol{\\theta}_0$ 是初始最适值，$\\mathbf{v}$ 是最适值移动的恒定速度，而 $t$ 是从 $t=0$ 开始的世代数。\n\n完整的迭代算法如下：\n1. 初始化第 $t=0$ 代的均值性状向量：$\\overline{\\mathbf{z}} \\leftarrow \\overline{\\mathbf{z}}_0$。\n2. 对于从 $0$ 到 $T-1$ 的每一代 $t$：\n   a. 计算当前最适值：$\\boldsymbol{\\theta}_t = \\boldsymbol{\\theta}_0 + t\\,\\mathbf{v}$。\n   b. 计算均值与最适值之间的差异向量：$\\mathbf{d}_t = \\overline{\\mathbf{z}}_t - \\boldsymbol{\\theta}_t$。\n   c. 计算演化响应：$\\Delta \\overline{\\mathbf{z}}_t = - \\mathbf{G} \\boldsymbol{\\Omega}^{-1} \\mathbf{d}_t$。\n   d. 更新均值性状向量：$\\overline{\\mathbf{z}}_{t+1} = \\overline{\\mathbf{z}}_t + \\Delta \\overline{\\mathbf{z}}_t$。\n3. $T$ 代后的最终结果是向量 $\\overline{\\mathbf{z}}_T$。\n\n此过程将为提供的每个测试用例实现。实现涉及基本的矩阵-向量运算：$\\boldsymbol{\\Omega}$ 的矩阵求逆，以及矩阵-向量乘法。问题保证了 $\\boldsymbol{\\Omega}$ 是可逆的。加性遗传矩阵 $\\mathbf{G}$ 可能是奇异的，这在推导的方程中得到了正确处理，因为不需要对 $\\mathbf{G}$ 求逆。例如，如果 $\\mathbf{G}$ 是零矩阵，则 $\\Delta \\overline{\\mathbf{z}}_t$ 为零，群体均值不发生演化，这与预期相符。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Computes the deterministic evolutionary response of a quantitative polygenic\n    trait vector under stabilizing selection with a potentially moving optimum.\n    \"\"\"\n    \n    # Define the test cases from the problem statement.\n    test_cases = [\n        # Case 1: 1D, stationary optimum\n        {\n            \"n\": 1,\n            \"z0\": np.array([0.0]),\n            \"G\": np.array([[0.2]]),\n            \"Omega\": np.array([[1.0]]),\n            \"theta0\": np.array([1.5]),\n            \"v\": np.array([0.0]),\n            \"T\": 5\n        },\n        # Case 2: 2D, correlated G, stationary optimum\n        {\n            \"n\": 2,\n            \"z0\": np.array([0.0, 0.0]),\n            \"G\": np.array([[0.1, 0.05], [0.05, 0.2]]),\n            \"Omega\": np.array([[1.0, 0.0], [0.0, 1.5]]),\n            \"theta0\": np.array([1.0, -0.5]),\n            \"v\": np.array([0.0, 0.0]),\n            \"T\": 10\n        },\n        # Case 3: 1D, zero additive variance\n        {\n            \"n\": 1,\n            \"z0\": np.array([0.0]),\n            \"G\": np.array([[0.0]]),\n            \"Omega\": np.array([[0.5]]),\n            \"theta0\": np.array([1.0]),\n            \"v\": np.array([0.0]),\n            \"T\": 7\n        },\n        # Case 4: 2D, weak stabilizing selection\n        {\n            \"n\": 2,\n            \"z0\": np.array([0.2, -0.2]),\n            \"G\": np.array([[0.05, 0.0], [0.0, 0.05]]),\n            \"Omega\": np.array([[100.0, 0.0], [0.0, 100.0]]),\n            \"theta0\": np.array([1.0, 1.0]),\n            \"v\": np.array([0.0, 0.0]),\n            \"T\": 10\n        },\n        # Case 5: 2D, moving optimum, correlational selection\n        {\n            \"n\": 2,\n            \"z0\": np.array([0.0, 0.0]),\n            \"G\": np.array([[0.05, 0.0], [0.0, 0.05]]),\n            \"Omega\": np.array([[1.0, 0.2], [0.2, 1.0]]),\n            \"theta0\": np.array([0.0, 0.0]),\n            \"v\": np.array([0.1, -0.05]),\n            \"T\": 20\n        },\n    ]\n\n    results = []\n    for case in test_cases:\n        # Extract parameters for the current test case\n        z_mean = case[\"z0\"]\n        G = case[\"G\"]\n        Omega = case[\"Omega\"]\n        theta0 = case[\"theta0\"]\n        v = case[\"v\"]\n        T = case[\"T\"]\n        \n        # Pre-compute the inverse of Omega and the product G * Omega_inv\n        # The problem statement guarantees Omega is invertible.\n        Omega_inv = np.linalg.inv(Omega)\n        G_Omega_inv = G @ Omega_inv\n\n        # Iterate the discrete-time update equation for T generations\n        for t in range(T):\n            # Calculate the optimum at the current generation t\n            theta_t = theta0 + t * v\n            \n            # Calculate the evolutionary response delta_z\n            # delta_z = -G * Omega_inv * (z_mean - theta_t)\n            delta_z = -G_Omega_inv @ (z_mean - theta_t)\n            \n            # Update the mean trait vector\n            z_mean = z_mean + delta_z\n            \n        # Round the final vector components to 6 decimal places\n        z_T = np.round(z_mean, 6)\n        \n        # Format the result vector as a string '[c1,c2,...]' ensuring 6 decimal places\n        result_str = f\"[{','.join(f'{x:.6f}' for x in z_T)}]\"\n        results.append(result_str)\n\n    # Final print statement in the exact required format: [[...],[...],...]\n    print(f\"[{','.join(results)}]\")\n\nsolve()\n```", "id": "2744372"}, {"introduction": "经典的育种家方程通常假设遗传方差 $\\mathbf{G}$ 在多代中保持不变，但这只是一个近似。选择过程本身会改变其作用的遗传结构，形成一个至关重要的反馈循环。本练习将带您深入探讨“布尔默效应”（Bulmer effect），即选择如何在影响性状的等位基因之间产生负向连锁不平衡（linkage disequilibrium），从而暂时性地降低加性遗传方差 [@problem_id:2744369]。通过实现描述该效应的递归方程，您将洞悉遗传方差的动态变化，并理解为何持续选择下的演化响应率常常会逐渐减缓。", "problem": "你需要在数量性状的无穷小模型下，形式化并计算由选择引起的连锁不平衡（连锁不平衡 (LD)）导致的加性遗传方差的减少——即Bulmer效应。在离散世代中进行，并遵循以下假设，你必须将这些假设作为推导和算法的基础：\n\n- 表型 $P$ 是加性育种值 $G$ 和一个独立的环境偏差 $E$ 的和，即 $P = G + E$，其中 $\\mathrm{Var}(G) = V_A$ 且 $\\mathrm{Var}(E) = V_E$。通过中心化，假设 $P$ 的种群均值初始为 $0$。\n- 种群是无限大的，交配是随机的，基因座是不连锁的（自由重组），没有显性或上位性，也没有突变。无穷小模型成立：$G$ 近似呈正态分布，每个基因座的等位基因频率变化可以忽略不计，因此基因方差 $V_g$（即在LD为 $0$ 时应有的加性方差）可以视为在世代间是恒定的。\n- 选择是对 $P$ 进行的截断选择，每代保留最高的 $\\pi$ 比例的个体。对于一个正态分布的性状，截断正态随机变量的条件矩有明确的结论：如果 $Z \\sim \\mathcal{N}(0,1)$ 并且我们以 $Z  z_\\pi$ 为条件（其中 $\\pi = 1 - \\Phi(z_\\pi)$），那么 $\\mathbb{E}[Z \\mid Z  z_\\pi] = \\lambda$ 且 $\\mathrm{Var}(Z \\mid Z  z_\\pi) = 1 + z_\\pi \\lambda - \\lambda^2$，其中 $\\lambda = \\phi(z_\\pi)/\\pi$，$\\phi$ 和 $\\Phi$ 分别是标准正态概率密度函数和累积分布函数。\n\n你的目标：\n\n- 从第一性原理以及全期望和全方差定律出发，推导被选父母的加性方差 $V_A^{(S)}$ 作为 $V_A$、$V_E$ 和 $\\pi$ 的函数表达式。你的推导必须从 $G$ 和 $P$ 之间的二元正态关系开始，并且除了已给出的关于截断正态分布的统计事实外，不能假设任何目标公式。\n- 在不连锁的极限下，利用随机交配和自由重组，用基因方差 $V_g$ 和被选父母的加性方差 $V_A^{(S)}$ 来表示子代的加性方差 $V_A^{\\text{next}}$。从加性方差分解为基因方差加上由LD贡献的部分以及重组对LD的影响这一角度，解释当选择导致非零LD时，为什么 $V_A^{\\text{next}}$ 严格介于 $V_g$ 和 $V_A^{(S)}$ 之间。\n- 设计并实现一个算法，在给定 $V_A(0)$、$V_E$、$\\pi$ 和一个整数世代数 $T$ 的情况下，迭代方差递归式来计算比率 $\\rho(T) = V_A(T)/V_g$。\n\n科学现实性约束：\n\n- 在无穷小模型下，将 $V_g$ 视为常数且等于 $V_A(0)$。\n- 使用上述精确的截断正态矩来计算每代的被选表型方差。\n- 确保你的实现能够处理 $\\pi = 1$（无选择）的边界情况。在这种情况下，对于所有的 $T$，正确的极限是 $\\rho(T) = 1$。\n\n输入不是从用户读取的。相反，你的程序必须运行以下硬编码在程序中的测试套件，并按规定格式输出结果：\n\n测试套件（每个测试案例是一个元组 $(V_A(0), V_E, \\pi, T)$）：\n\n- 案例A（中等选择，中等遗传力）：$(1.0, 1.0, 0.1, 5)$。\n- 案例B（无环境方差，强遗传力）：$(1.0, 0.0, 0.2, 10)$。\n- 案例C（无选择边界）：$(0.5, 1.5, 1.0, 50)$。\n- 案例D（极强选择，低遗传力，接近平衡）：$(1.0, 3.0, 0.01, 100)$。\n\n所有实数都必须以无量纲形式处理；不涉及物理单位。你的程序应为每个案例计算单个浮点数值 $\\rho(T) = V_A(T)/V_g$，并将其四舍五入到 $6$ 位小数。不使用角度。百分比必须表示为小数；参数 $\\pi$ 已按此形式提供。\n\n最终输出格式：\n\n- 你的程序应生成单行输出，其中包含按测试套件顺序排列的结果，形式为一个用方括号括起来的逗号分隔列表，例如 $[\\rho_A,\\rho_B,\\rho_C,\\rho_D]$，每个条目四舍五入到 $6$ 位小数。", "solution": "该问题陈述是在数量遗传学的无穷小模型下对Bulmer效应的一个定义明确且有科学依据的表述。它提供了获得唯一解所需的全部假设和参数。该问题是有效的，其解的推导和实现如下。\n\n问题的核心在于对加性遗传方差 $V_A$ 在离散世代中进行递归迭代。这需要推导 $V_A$ 在一个世代内的变化，该过程包含两个步骤：选择对亲代的影响，以及随机交配和重组对子代的影响。\n\n首先，我们推导被选父母中的加性遗传方差 $V_A^{(S)}$。\n表型 $P$ 是育种值 $G$ 和一个独立的环境偏差 $E$ 的和，因此 $P = G + E$。给定 $G \\sim \\mathcal{N}(0, V_A)$ 且 $E \\sim \\mathcal{N}(0, V_E)$。它们的独立性意味着 $(G, P)$ 的联合分布是一个二元正态分布，其均值向量为 $(0, 0)$，协方差矩阵为：\n$$\n\\boldsymbol{\\Sigma} = \\begin{pmatrix} \\mathrm{Var}(G)  \\mathrm{Cov}(G, P) \\\\ \\mathrm{Cov(G, P)}  \\mathrm{Var}(P) \\end{pmatrix} = \\begin{pmatrix} V_A  V_A \\\\ V_A  V_A + V_E \\end{pmatrix}\n$$\n其中 $\\mathrm{Cov}(G, P) = \\mathrm{Cov}(G, G+E) = \\mathrm{Var}(G) + \\mathrm{Cov}(G, E) = V_A$。总的表型方差为 $V_P = V_A + V_E$。\n\n在给定特定表型值 $P=p$ 的条件下，$G$ 的条件分布是正态的。二元正态分布的标准结果给出了条件均值和方差：\n$$\n\\mathbb{E}[G \\mid P=p] = \\frac{\\mathrm{Cov}(G, P)}{\\mathrm{Var}(P)} p = \\frac{V_A}{V_P} p = h^2 p\n$$\n$$\n\\mathrm{Var}(G \\mid P=p) = \\mathrm{Var}(G) - \\frac{\\mathrm{Cov}(G, P)^2}{\\mathrm{Var}(P)} = V_A - \\frac{V_A^2}{V_P} = V_A \\left(1 - \\frac{V_A}{V_P}\\right) = V_A (1 - h^2)\n$$\n其中 $h^2 = V_A / V_P$ 是狭义遗传力。请注意，这个条件方差与 $p$ 的值无关。\n\n我们寻求被选个体中 $G$ 的方差，这些个体的表型 $P$ 超过一个截断阈值 $P_t$，即 $V_A^{(S)} = \\mathrm{Var}(G \\mid P  P_t)$。我们应用全方差定律：\n$$\nV_A^{(S)} = \\mathrm{Var}(G \\mid P  P_t) = \\mathbb{E}[\\mathrm{Var}(G \\mid P) \\mid P  P_t] + \\mathrm{Var}(\\mathbb{E}[G \\mid P] \\mid P  P_t)\n$$\n第一项是一个常数的期望：\n$$\n\\mathbb{E}[\\mathrm{Var}(G \\mid P) \\mid P  P_t] = \\mathbb{E}[V_A(1 - h^2) \\mid P  P_t] = V_A(1 - h^2)\n$$\n第二项是条件期望的方差：\n$$\n\\mathrm{Var}(\\mathbb{E}[G \\mid P] \\mid P  P_t) = \\mathrm{Var}(h^2 P \\mid P  P_t) = (h^2)^2 \\mathrm{Var}(P \\mid P  P_t) = (h^2)^2 V_P^{(S)}\n$$\n其中 $V_P^{(S)}$ 是被选群体中的表型方差。为了找到 $V_P^{(S)}$，我们将 $P$ 标准化为 $Z = P / \\sqrt{V_P}$，其中 $Z \\sim \\mathcal{N}(0, 1)$。选择条件 $P  P_t$ 变为 $Z  z_\\pi$，其中 $z_\\pi = P_t / \\sqrt{V_P}$。问题给出了截断标准正态变量的方差：$\\mathrm{Var}(Z \\mid Z  z_\\pi) = 1 + z_\\pi \\lambda - \\lambda^2$，其中 $\\lambda = \\phi(z_\\pi)/\\pi$。\n因此，截断表型的方差为 $V_P^{(S)} = \\mathrm{Var}(\\sqrt{V_P} Z \\mid Z  z_\\pi) = V_P \\mathrm{Var}(Z \\mid Z  z_\\pi) = V_P (1 + z_\\pi \\lambda - \\lambda^2)$。\n代入回去，我们得到：\n$$\nV_A^{(S)} = V_A(1 - h^2) + (h^2)^2 V_P (1 + z_\\pi \\lambda - \\lambda^2)\n$$\n替换 $h^2 = V_A/V_P$ 并化简：\n$$\nV_A^{(S)} = V_A\\left(1 - \\frac{V_A}{V_P}\\right) + \\left(\\frac{V_A}{V_P}\\right)^2 V_P (1 + z_\\pi \\lambda - \\lambda^2) = V_A - \\frac{V_A^2}{V_P} + \\frac{V_A^2}{V_P}(1 + z_\\pi \\lambda - \\lambda^2)\n$$\n$$\nV_A^{(S)} = V_A + \\frac{V_A^2}{V_P}(z_\\pi \\lambda - \\lambda^2) = V_A\\left(1 - \\frac{V_A}{V_P}(\\lambda^2 - z_\\pi \\lambda)\\right)\n$$\n我们定义选择强度系数 $k = \\lambda(\\lambda - z_\\pi)$。该表达式简化为著名的结果：\n$$\nV_A^{(S)} = V_A(1 - k h^2)\n$$\n对于任何非平凡选择（$0  \\pi  1$），可以证明 $k>0$，这意味着 $V_A^{(S)}  V_A$。选择通过诱导负向连锁不平衡来减少加性遗传方差。\n\n其次，我们推导下一代的加性方差 $V_A^{\\text{next}}$。被选父母随机交配。一个子代的育种值是其父母育种值的平均值，外加一个孟德尔抽样项 $\\delta$：$G_{\\text{offspring}} = \\frac{1}{2}(G_{\\text{father}} + G_{\\text{mother}}) + \\delta$。\n其方差为 $V_A^{\\text{next}} = \\mathrm{Var}(G_{\\text{offspring}}) = \\mathrm{Var}(\\frac{1}{2}(G_{\\text{father}} + G_{\\text{mother}})) + \\mathrm{Var}(\\delta)$。由于父母是从被选群体中随机选择的，所以 $\\mathrm{Var}(G_{\\text{father}}) = \\mathrm{Var}(G_{\\text{mother}}) = V_A^{(S)}$。它们的协方差为 $0$。\n$$\nV_A^{\\text{next}} = \\frac{1}{4}(\\mathrm{Var}(G_{\\text{father}}) + \\mathrm{Var}(G_{\\text{mother}})) + \\mathrm{Var}(\\delta) = \\frac{1}{2}V_A^{(S)} + \\mathrm{Var}(\\delta)\n$$\n孟德尔抽样方差 $\\mathrm{Var}(\\delta)$ 源于等位基因的分离。在自由重组（不连锁基因座）的情况下，所有由选择诱导的连锁不平衡都会在一代内消散。分离产生的方差取决于潜在的等位基因频率，而在无穷小模型下，这些频率不发生改变。该方差等于基因方差的一半，即 $\\mathrm{Var}(\\delta) = \\frac{1}{2}V_g$。基因方差 $V_g$ 是在种群处于连锁平衡时应有的加性方差；根据问题的假设，它是恒定的，并等于 $V_A(0)$。\n这就得出了最终的递归关系：\n$$\nV_A^{\\text{next}} = \\frac{1}{2}V_A^{(S)} + \\frac{1}{2}V_g\n$$\n该表达式表明，$V_A^{\\text{next}}$ 是选择后方差 $V_A^{(S)}$ 和恒定基因方差 $V_g$ 的算术平均值。因此，在任何 $V_A^{(S)} \\neq V_g$ 的情况下（这对任何非平凡选择都成立），$V_A^{\\text{next}}$ 必定严格介于 $V_A^{(S)}$ 和 $V_g$ 之间。选择将 $V_A$ 推向一个低于 $V_g$ 的平衡值，而重组则通过打破负向连锁不平衡来部分恢复它。\n\n计算算法的步骤如下：\n1.  初始化 $V_A = V_A(0)$ 和 $V_g = V_A(0)$。\n2.  如果 $\\pi=1$，则没有选择，$k=0$，$V_A^{(S)}=V_A$。递归式变为 $V_A^{\\text{next}} = \\frac{1}{2}V_A + \\frac{1}{2}V_g$。由于 $V_A(0)=V_g$，因此 $V_A$ 在所有世代中都保持等于 $V_g$。因此，$\\rho(T)=1$。\n3.  如果 $\\pi1$，计算常数 $z_\\pi$、$\\lambda$ 和 $k$。\n4.  迭代 $T$ 个世代。在每个世代 $t$ 中：\n    a. 计算 $V_P(t) = V_A(t) + V_E$ 和 $h^2(t) = V_A(t) / V_P(t)$。\n    b. 计算 $V_A^{(S)}(t) = V_A(t)(1 - k \\cdot h^2(t))$。\n    c. 计算 $V_A(t+1) = \\frac{1}{2}V_A^{(S)}(t) + \\frac{1}{2}V_g$。\n5.  在 $T$ 次迭代后，计算最终比率 $\\rho(T) = V_A(T) / V_g$。\n实施此程序以解决给定的测试案例。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.stats import norm\n\ndef solve():\n    \"\"\"\n    Computes the reduction of additive genetic variance due to the Bulmer effect.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # Case A (moderate selection, intermediate heritability)\n        (1.0, 1.0, 0.1, 5),\n        # Case B (no environmental variance, strong heritability)\n        (1.0, 0.0, 0.2, 10),\n        # Case C (no selection boundary)\n        (0.5, 1.5, 1.0, 50),\n        # Case D (very strong selection, low heritability, near-equilibrium)\n        (1.0, 3.0, 0.01, 100),\n    ]\n\n    results = []\n    for case in test_cases:\n        Va0, Ve, pi, T = case\n        \n        # Under the infinitesimal model, genic variance is constant and equals\n        # the initial additive variance before selection begins.\n        Vg = Va0\n        \n        # Handle the boundary case of no selection (pi = 1).\n        if pi == 1.0:\n            # With no selection, V_A remains at V_g.\n            # The recursion V_A(t+1) = 0.5 * V_A(t) + 0.5 * V_g with V_A(0) = V_g\n            # yields V_A(t) = V_g for all t.\n            # Therefore, the ratio V_A(T) / V_g is always 1.\n            rho_T = 1.0\n            results.append(f\"{rho_T:.6f}\")\n            continue\n\n        # Pre-calculate selection-related constants that do not change over generations.\n        # z_pi is the truncation point on a standard normal distribution.\n        z_pi = norm.ppf(1.0 - pi)\n        # lambda_val is the mean of the truncated standard normal distribution.\n        # Note: 'lambda' is a reserved keyword in Python.\n        lambda_val = norm.pdf(z_pi) / pi\n        # k is the selection intensity coefficient related to variance reduction.\n        k = lambda_val * (lambda_val - z_pi)\n        \n        # Initialize the additive genetic variance for the first generation.\n        Va_t = Va0\n        \n        # Iterate the recursion for T generations.\n        for _ in range(T):\n            # Phenotypic variance in the current generation.\n            Vp_t = Va_t + Ve\n            \n            # Heritability in the current generation.\n            # We assume Vp_t > 0, which is true for the given test cases.\n            h2_t = Va_t / Vp_t if Vp_t > 0 else 0.0\n            \n            # Additive variance among selected parents (after selection).\n            Va_s = Va_t * (1.0 - k * h2_t)\n            \n            # Additive variance in the next generation (Bulmer's recursion).\n            # This accounts for recombination breaking down linkage disequilibrium.\n            Va_next = 0.5 * Va_s + 0.5 * Vg\n            \n            # Update the variance for the next iteration.\n            Va_t = Va_next\n            \n        # The final ratio is rho(T) = V_A(T) / V_g.\n        rho_T = Va_t / Vg\n        results.append(f\"{rho_T:.6f}\")\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(results)}]\")\n\nsolve()\n```", "id": "2744369"}]}