{"hands_on_practices": [{"introduction": "在拟合一个复杂的进化模型之前，首要任务是透彻理解其结构和复杂性。这项练习旨在训练您将模型的文字描述精确地转化为其自由参数的数量，这是使用诸如赤池信息准则（$AIC$）等模型选择标准进行比较的基础技能。通过这个实践[@problem_id:2722636]，您将建立起关于模型不同组成部分如何影响其整体复杂性的直观认识。", "problem": "一个关于离散性状在固定的、经时间校准的系统发育树上进行演化的隐藏状态模型，被表述为一个连续时间马尔可夫链（CTMC）。观测到的性状有 $k$ 个离散状态，其演化取决于一个有 $H$ 个水平的未观测（隐藏）分类变量。因此，联合过程有 $kH$ 个复合状态，每个状态由一个有序对 $(i,h)$ 表示，其中 $i \\in \\{1,\\dots,k\\}$ 且 $h \\in \\{1,\\dots,H\\}$。假设采用以下建模选择，这些选择在基于CTMC的性状演化系统发育模型中都是标准的：\n\n1. 在每个隐藏类别 $h$ 内部，观测性状在 $k$ 个观测状态之间的转换遵循等速率（ER）模型。也就是说，对于一个给定的隐藏类别 $h$，从任何观测状态 $i$ 到任何其他观测状态 $j \\neq i$ 的瞬时速率等于一个特定于该类别的常数 $\\alpha_{h} > 0$。ER速率常数 $\\alpha_{h}$ 在不同隐藏类别之间可以不同。\n2. 隐藏状态的转换独立于观测状态发生，并且不改变观测状态。也就是说，对于 $h' \\neq h$，从 $(i,h)$ 到 $(i,h')$ 的转换由一个无对称性约束的通用 $H \\times H$ 隐藏状态速率矩阵决定，并且不允许观测状态和隐藏状态同时发生变化。\n3. 完整的 $kH \\times kH$ 联合速率矩阵的对角线元素由CTMC定义所蕴含的行和为零的约束确定。\n4. 系统发育树及其枝长以绝对时间单位固定，参数在这些单位下是可识别的。根部分布假定为联合CTMC的平稳分布，因此没有为初始状态频率分配自由参数。\n\n在这些假设下，确定需要估计的自由速率参数总数，作为 $k$ 和 $H$ 的函数，然后计算在 $k=3$ 和 $H=2$ 的特定情况下的该数值。仅报告 $k=3$ 和 $H=2$ 的最终计数，以单个整数形式表示，不带单位。无需四舍五入。", "solution": "所述问题具有科学依据，提法恰当，并包含足够信息以获得唯一解。我们开始进行分析。\n\n该系统由一个在包含 $kH$ 个复合状态的状态空间上的连续时间马尔可夫链（CTMC）描述。设一个状态由有序对 $(i, h)$ 表示，其中 $i \\in \\{1, \\dots, k\\}$ 是观测状态， $h \\in \\{1, \\dots, H\\}$ 是隐藏状态。该系统的演化由一个 $kH \\times kH$ 的瞬时速率矩阵（我们称之为 $Q$）控制。对于 $(i_1, h_1) \\neq (i_2, h_2)$，条目 $Q_{(i_1, h_1), (i_2, h_2)}$ 代表从状态 $(i_1, h_1)$ 到状态 $(i_2, h_2)$ 的瞬时转换速率。对角线元素由每行总和为零的约束定义。我们的任务是计算自由、非零、非对角线速率参数的数量。\n\n我们根据所提供的假设来分析矩阵 $Q$ 的结构。\n\n1.  **观测性状的转换：** 根据假设1，在任何给定的隐藏类别 $h$ 内， $k$ 个观测状态之间的转换遵循等速率（ER）模型。这意味着从任何观测状态 $i$ 到任何其他状态 $j \\neq i$ 的转换速率是一个常数 $\\alpha_h > 0$。这个常数的值仅取决于隐藏类别 $h$。\n    $$Q_{(i, h), (j, h)} = \\alpha_h \\quad \\text{for } i \\neq j$$\n    由于这些速率在 $H$ 个隐藏类别之间可以不同，这引入了一组参数 $\\{\\alpha_1, \\alpha_2, \\dots, \\alpha_H\\}$。由于每个 $\\alpha_h$ 都是一个独立的参数，该假设为模型贡献了恰好 $H$ 个自由参数。\n\n2.  **隐藏状态的转换：** 根据假设2，隐藏状态的转换发生时，观测状态 $i$ 保持不变。从隐藏状态 $h$ 到另一个隐藏状态 $h'$ 的转换速率由一个通用的 $H \\times H$ 速率矩阵（我们记为 $R$）的条目给出。设 $R$ 的非对角线元素为 $r_{hh'}$，其中 $h \\neq h'$。问题指出这些转换独立于观测状态 $i$。因此，对于任何 $i$：\n    $$Q_{(i, h), (i, h')} = r_{hh'} \\quad \\text{for } h \\neq h'$$\n    问题指定了一个无对称性约束的通用 $H \\times H$ 隐藏状态速率矩阵。对于这样一个矩阵，所有 $H(H-1)$ 个非对角线元素都是自由参数。这为模型贡献了 $H(H-1)$ 个自由参数。\n\n3.  **同时转换：** 假设2还明确禁止观测状态和隐藏状态同时发生变化。这意味着：\n    $$Q_{(i_1, h_1), (i_2, h_2)} = 0 \\quad \\text{for } i_1 \\neq i_2 \\text{ and } h_1 \\neq h_2$$\n    这个规则不引入新的参数；它将大量潜在的速率设置为零。\n\n4.  **对角线元素：** 假设3指出，对角线元素由行和为零的约束确定。对于任何状态 $(i, h)$，对角线元素是其所在行中所有非对角线速率之和的负值：\n    $$Q_{(i, h), (i, h)} = - \\sum_{(j, h') \\neq (i, h)} Q_{(i, h), (j, h')}$$\n    $$Q_{(i, h), (i, h)} = - \\left( \\sum_{j \\neq i} Q_{(i, h), (j, h)} + \\sum_{h' \\neq h} Q_{(i, h), (i, h')} \\right)$$\n    代入我们上面分析得到的速率：\n    $$Q_{(i, h), (i, h)} = - \\left( \\sum_{j \\neq i} \\alpha_h + \\sum_{h' \\neq h} r_{hh'} \\right) = - \\left( (k-1)\\alpha_h + \\sum_{h' \\neq h} r_{hh'} \\right)$$\n    这证实了对角线元素是已定义的非对角线速率的函数，不会引入新的自由参数。\n\n5.  **根频率：** 假设4指定根状态分布是CTMC的平稳分布。这意味着根状态频率由速率矩阵 $Q$ 决定，本身不是自由参数。\n\n**自由参数总数：**\n自由速率参数的总数 $N_{\\text{params}}$ 是来自观测性状转换和隐藏状态转换的参数之和。\n$$N_{\\text{params}}(k, H) = (\\text{Number of } \\alpha_h \\text{ parameters}) + (\\text{Number of } r_{hh'} \\text{ parameters})$$\n$$N_{\\text{params}}(k, H) = H + H(H-1)$$\n$$N_{\\text{params}}(k, H) = H + H^2 - H$$\n$$N_{\\text{params}}(k, H) = H^2$$\n值得注意的是，自由参数的数量与观测状态的数量 $k$ 无关。这是因为在每个隐藏类别内对观测性状采用ER模型的直接结果，因为这要求每个类别只有一个参数（$\\alpha_h$），而与 $k$ 的大小无关。\n\n**特定情况的计算：**\n问题要求计算 $k=3$ 和 $H=2$ 情况下的参数数量。使用推导出的公式：\n$$N_{\\text{params}}(3, 2) = 2^2 = 4$$\n自由参数是 $\\alpha_1$, $\\alpha_2$, $r_{12}$ 和 $r_{21}$。总数为 $4$。", "answer": "$$\\boxed{4}$$", "id": "2722636"}, {"introduction": "在掌握了如何定义模型之后，下一个关键挑战是模型的解释。这项练习将引导您探索模型等价性（model equivalence）这一核心概念，它揭示了两种截然不同的生物学假说如何能产生数学上完全相同的模型。通过完成这个思想实验[@problem_id:2722560]，您将更深刻地理解非唯一识别性（non-identifiability）问题，并学会在从统计结果中推断生物学结论时保持必要的审慎。", "problem": "考虑两个二元观测性状，记为 $X \\in \\{0,1\\}$ 和 $Y \\in \\{0,1\\}$，它们沿着一个谱系根据一个连续时间马尔可夫链 (CTMC) 联合演化。该 CTMC 的状态空间为 $\\{00,01,10,11\\}$，其中第一位是 $X$，第二位是 $Y$。相关模型的无穷小生成元（速率矩阵）$Q_{\\mathrm{dep}}$ 的参数化方式如下：(i) 不允许 $X$ 和 $Y$ 同时翻转，(ii) $X$ 的翻转速率取决于 $Y$ 的当前值，以及 (iii) $Y$ 的翻转速率取决于 $X$ 的当前值。具体来说，在状态排序为 $(00,01,10,11)$ 时，\n$$\nQ_{\\mathrm{dep}} \\;=\\;\n\\begin{pmatrix}\n-(a + r_{0})  r_{0}  a  0 \\\\\nr_{0}  -(b + r_{0})  0  b \\\\\na  0  -(a + r_{1})  r_{1} \\\\\n0  b  r_{1}  -(b + r_{1})\n\\end{pmatrix},\n$$\n其中 $a>0$ 和 $b>0$ 分别是当 $Y=0$ 和 $Y=1$ 时 $X$ 的翻转速率，而 $r_{0}>0$ 和 $r_{1}>0$ 分别是当 $X=0$ 和 $X=1$ 时 $Y$ 的翻转速率。\n\n现在，转而考虑一个单一的可观测二元性状 $Z \\in \\{0,1\\}$，它随着隐藏速率类别 $H \\in \\{\\mathrm{A},\\mathrm{B}\\}$ 演化（一个隐藏状态模型）。联合隐藏状态过程的状态空间为 $\\{0\\mathrm{A},0\\mathrm{B},1\\mathrm{A},1\\mathrm{B}\\}$，其无穷小生成元 $Q_{\\mathrm{hid}}$ 的解释如下：(i) 在隐藏类别 $\\mathrm{A}$ 中 $Z$ 的翻转速率为 $a$，在隐藏类别 $\\mathrm{B}$ 中为 $b$；(ii) 当 $Z=0$ 时，隐藏类别 $H$ 的翻转速率为 $r_{0}$，当 $Z=1$ 时，速率为 $r_{1}$；以及 (iii) 不允许 $Z$ 和 $H$ 同时翻转。在状态排序为 $(0\\mathrm{A},0\\mathrm{B},1\\mathrm{A},1\\mathrm{B})$ 时，\n$$\nQ_{\\mathrm{hid}} \\;=\\;\n\\begin{pmatrix}\n-(a + r_{0})  r_{0}  a  0 \\\\\nr_{0}  -(b + r_{0})  0  b \\\\\na  0  -(a + r_{1})  r_{1} \\\\\n0  b  r_{1}  -(b + r_{1})\n\\end{pmatrix}.\n$$\n因此，在重新标记 $00 \\leftrightarrow 0\\mathrm{A}$、$01 \\leftrightarrow 0\\mathrm{B}$、$10 \\leftrightarrow 1\\mathrm{A}$ 和 $11 \\leftrightarrow 1\\mathrm{B}$ 后，$Q_{\\mathrm{dep}} = Q_{\\mathrm{hid}}$。\n\n设该谱系为一个长度为 $t>0$ 的单个分支，从根部一个已知的祖先状态到一个单一的观测尖端。假设在相关模型下，根部的祖先状态是 $00$，而在隐藏状态模型下是 $0\\mathrm{A}$（即，在上述重新标记下的对应状态）。在尖端，相关模型下的观测状态是 $11$，而隐藏状态模型下的观测状态是 $1\\mathrm{B}$（同样，在重新标记下是对应的）。你可以使用的基本依据包括：(i) CTMC 的定义，其无穷小生成元为 $Q$，转移矩阵为 $P(t) = \\exp(Qt)$，其中 $\\exp(\\cdot)$ 表示矩阵指数；以及 (ii) 沿着长度为 $t$ 的单个分支，观测到从已知初始状态 $i$ 到已知最终状态 $j$ 的转移的似然是 $P(t)$ 的 $(i,j)$ 元素。\n\n仅使用这些基础，不引入或假设任何额外的捷径，确定对于指定的单分支观测，相关模型和隐藏状态模型之间的对数似然差，将其表示为 $t$、$a$、$b$、$r_{0}$ 和 $r_{1}$ 的函数。你的最终答案必须是一个实数或一个封闭形式的解析表达式。不需要单位。如果你发现表达式可以简化为一个精确的常数，请报告该常数。最后，在计算出所要求的差值后，用文字简要解释这种等价性对更大多样性树上的推断所带来的可识别性后果。\n\n你最终报告的量应该是针对指定观测的 $\\ln L_{\\mathrm{dep}} - \\ln L_{\\mathrm{hid}}$ 的单一值。不需要四舍五入。", "solution": "我们从连续时间马尔可夫链（CTMC）的基础知识开始。一个在有限状态空间上、具有无穷小生成元（速率矩阵）$Q$ 的 CTMC，其在时间 $t>0$ 内的转移概率矩阵由 $P(t) = \\exp(Qt)$ 给出，其中 $\\exp(\\cdot)$ 是由收敛级数 $\\exp(Qt) = \\sum_{k=0}^{\\infty} \\frac{(Qt)^{k}}{k!}$ 定义的矩阵指数。对于沿长度为 $t$ 的单个分支的已知初始状态 $i$ 和已知最终状态 $j$，观测到 $i \\to j$ 转变的似然是 $[P(t)]_{ij}$，即 $P(t)$ 的 $(i,j)$ 元素。\n\n在问题中，相关模型 $Q_{\\mathrm{dep}}$ 在四个状态 $(00,01,10,11)$ 上的定义如下：\n$$\nQ_{\\mathrm{dep}} \\;=\\;\n\\begin{pmatrix}\n-(a + r_{0})  r_{0}  a  0 \\\\\nr_{0}  -(b + r_{0})  0  b \\\\\na  0  -(a + r_{1})  r_{1} \\\\\n0  b  r_{1}  -(b + r_{1})\n\\end{pmatrix}.\n$$\n隐藏状态单性状模型 $Q_{\\mathrm{hid}}$ 在四个状态 $(0\\mathrm{A},0\\mathrm{B},1\\mathrm{A},1\\mathrm{B})$ 上的指定如下：\n$$\nQ_{\\mathrm{hid}} \\;=\\;\n\\begin{pmatrix}\n-(a + r_{0})  r_{0}  a  0 \\\\\nr_{0}  -(b + r_{0})  0  b \\\\\na  0  -(a + r_{1})  r_{1} \\\\\n0  b  r_{1}  -(b + r_{1})\n\\end{pmatrix}.\n$$\n根据构造，一旦我们确定重新标记 $00 \\leftrightarrow 0\\mathrm{A}$、$01 \\leftrightarrow 0\\mathrm{B}$、$10 \\leftrightarrow 1\\mathrm{A}$ 和 $11 \\leftrightarrow 1\\mathrm{B}$，这两个矩阵就是相同的。更一般地，如果排序不同，则会存在一个置换矩阵 $S$ 使得 $Q_{\\mathrm{hid}} = S^{\\top} Q_{\\mathrm{dep}} S$，这意味着对于所有 $t \\ge 0$ 都有 $\\exp(Q_{\\mathrm{hid}} t) = S^{\\top} \\exp(Q_{\\mathrm{dep}} t) S$，因为矩阵指数在相似变换下保持不变。\n\n对于指定的长度为 $t$ 的单个分支，在相关模型下观测到从已知的根状态 $00$ 到尖端状态 $11$ 的转移的似然为\n$$\nL_{\\mathrm{dep}} \\;=\\; \\left[\\exp\\!\\left(Q_{\\mathrm{dep}} \\, t\\right)\\right]_{(00),(11)}.\n$$\n在隐藏状态模型下，观测是从已知的根状态 $0\\mathrm{A}$ 到尖端状态 $1\\mathrm{B}$，其似然为\n$$\nL_{\\mathrm{hid}} \\;=\\; \\left[\\exp\\!\\left(Q_{\\mathrm{hid}} \\, t\\right)\\right]_{(0\\mathrm{A}),(1\\mathrm{B})}.\n$$\n因为在将 $(00,01,10,11)$ 按相同顺序映射到 $(0\\mathrm{A},0\\mathrm{B},1\\mathrm{A},1\\mathrm{B})$ 的重新标记下，$Q_{\\mathrm{hid}}$ 和 $Q_{\\mathrm{dep}}$ 是相同的，所以我们有\n$$\n\\exp\\!\\left(Q_{\\mathrm{hid}} \\, t\\right) \\;=\\; \\exp\\!\\left(Q_{\\mathrm{dep}} \\, t\\right),\n$$\n当状态排序对齐时，按元素相等。因此，\n$$\nL_{\\mathrm{hid}} \\;=\\; \\left[\\exp\\!\\left(Q_{\\mathrm{hid}} \\, t\\right)\\right]_{(0\\mathrm{A}),(1\\mathrm{B})}\n\\;=\\; \\left[\\exp\\!\\left(Q_{\\mathrm{dep}} \\, t\\right)\\right]_{(00),(11)}\n\\;=\\; L_{\\mathrm{dep}}.\n$$\n取自然对数，\n$$\n\\ln L_{\\mathrm{dep}} - \\ln L_{\\mathrm{hid}} \\;=\\; \\ln\\!\\left(\\frac{L_{\\mathrm{dep}}}{L_{\\mathrm{hid}}}\\right) \\;=\\; \\ln(1) \\;=\\; 0.\n$$\n这个等式对所有 $t>0$ 和所有正速率参数 $a$、$b$、$r_{0}$ 和 $r_{1}$ 都成立，因为它是生成元完全相等（或置换相似）以及矩阵指数在相似性下的不变性的结果。\n\n可识别性后果。所构造的例子表明，同一个 4 状态 CTMC 既可以解释为两个观测到的二元性状 $(X,Y)$ 之间相关演化的模型，也可以解释为单个观测到的二元性状 $Z$ 随着两个隐藏速率类别 $H$ 演化的模型。在任何系统发育树上，从 4 状态过程计算出的似然仅取决于生成元 $Q$ 和观测到的尖端状态；保持 $Q$ 不变的状态重新标记会使似然保持不变。因此，在没有外部约束的情况下，数据不足以识别 4 状态过程的第二个分量是代表一个观测性状还是一个隐藏速率类别：在生成 CTMC 的层面上，这两种解释在观测上是等价的。在实践中，这意味着两个性状之间相关演化的明显支持可以被单个隐藏速率异质性的性状所模仿，导致因果解释的不可识别性，除非附加信息、约束或实验设计元素打破这种等价性（例如，通过约束特定的非对角线速率相等，通过固定或测试嵌套子模型，或通过利用隐藏过程的独立数据源）。此外，在隐藏状态的表述中，存在隐藏类别的内在标签切换对称性，这会产生具有相同似然的多种参数化，进一步强调了进行仔细的可识别性分析的必要性。", "answer": "$$\\boxed{0}$$", "id": "2722560"}, {"introduction": "最后的这项练习将前面的概念整合到一个完整的数据分析流程中。您将通过编程实现并比较两个模型，以探究一个表观上的相关性，从而展示系统发育隐状态模型如何能够解释简单模型可能误读的混杂进化历史。这项实践[@problem_id:2722598]将为您提供应用这些模型来解析复杂进化模式并避免虚假结论的具体经验。", "problem": "您需要构建并分析一个人工设定的系统发育情景，以证明在树梢处观察到的二元性状与多样化代理指标之间的明显相关性，可以完全由树上演化的隐藏速率类别来解释。您将实现两个基于似然的模型，并使用赤池信息准则（AIC）对它们进行比较。\n\n基本原理和定义：\n- 一个速率矩阵为 $Q=\\begin{pmatrix} -q_{01}  q_{01} \\\\ q_{10}  -q_{10} \\end{pmatrix}$ 的二元连续时间马尔可夫链（CTMC）在长度为 $t$ 的分支上产生转移矩阵 $P(t)=\\exp(Qt)$。对于一个二状态 CTMC，当 $q_{01}+q_{10}>0$ 时，其平稳分布为 $\\boldsymbol{\\pi}=(\\pi_0,\\pi_1)$，其中 $\\pi_0=\\dfrac{q_{10}}{q_{01}+q_{10}}$ 且 $\\pi_1=\\dfrac{q_{01}}{q_{01}+q_{10}}$。\n- 树上的隐马尔可夫模型（HMM）使用 Felsenstein 剪枝算法，通过对内部节点的隐藏状态进行积分来计算树梢数据的似然。对于每个具有观测数据 $y_i$ 的树梢，在隐藏状态 $s\\in\\{0,1\\}$ 下的发射密度由一个高斯密度 $\\phi(y_i\\mid \\mu_s,\\sigma)$ 给出，其均值为 $\\mu_s$，标准差为 $\\sigma$。对于内部节点，条件似然向量通过使用沿每个分支的 CTMC 转移概率组合子节点的似然来计算。树的似然是使用平稳分布 $\\boldsymbol{\\pi}$ 对条件似然向量进行根部加权求和。\n\n您将对所提供的测试套件拟合并比较以下两个模型：\n\n- 模型 A（仅考虑性状的高斯混合模型，不含系统发育）：树梢处的观测二元性状 $X_i\\in\\{0,1\\}$ 将树梢数据 $y_i$ 划分为两组。似然是所有树梢上 $\\phi(y_i\\mid \\mu_{X_i},\\sigma)$ 的乘积，参数为 $(\\mu_0,\\mu_1,\\sigma)$。您必须计算 $(\\mu_0,\\mu_1,\\sigma)$ 的最大似然估计和最大化对数似然 $\\ell_A$。赤池信息准则为 $\\mathrm{AIC}_A=2k_A-2\\ell_A$，其中 $k_A=3$。\n\n- 模型 B（树-隐藏状态高斯隐马尔可夫模型）：一个具有速率 $(q_{01},q_{10})$ 的二状态隐藏 CTMC 在树上演化。每个树梢的多样化代理指标 $y_i$ 从一个高斯分布中发射，其均值为 $\\mu_{H_i}$，标准差为 $\\sigma$，其中 $H_i\\in\\{0,1\\}$ 是该树梢未观测到的隐藏状态。参数为 $(\\mu_0,\\mu_1,\\sigma,q_{01},q_{10})$。您必须使用 Felsenstein 剪枝算法计算最大化对数似然 $\\ell_B$，以及 $\\mathrm{AIC}_B=2k_B-2\\ell_B$，其中 $k_B=5$。\n\n决策标准：对于每个测试用例，返回一个布尔值，指示是否 $\\mathrm{AIC}_B  \\mathrm{AIC}_A$。\n\n树的规格（所有测试用例通用）：\n- 有根的、严格二分的树，树梢索引为 $0$ 到 $7$，内部节点为 $8$ 到 $14$。所有分支长度均为 $0.5$。有向边 $(\\text{父节点},\\text{子节点},\\ell)$ 如下：\n  - $(14,12,0.5)$, $(14,13,0.5)$,\n  - $(12,10,0.5)$, $(12,11,0.5)$,\n  - $(10,0,0.5)$, $(10,1,0.5)$, $(11,2,0.5)$, $(11,3,0.5)$,\n  - $(13,9,0.5)$, $(13,8,0.5)$,\n  - $(9,4,0.5)$, $(9,5,0.5)$, $(8,6,0.5)$, $(8,7,0.5)$。\n- 根节点为 $14$。\n\n三个测试用例的数据：\n- 用例 1（隐藏速率聚类产生了明显的性状相关性）：\n  - 按树梢索引 $i=0,\\dots,7$ 排列的观测性状向量：$X^{(1)}=[0,0,1,1,1,1,0,1]$。\n  - 按树梢索引排列的多样化代理指标（实值）：$y^{(1)}=[0.45,0.55,0.52,0.48,1.22,1.18,1.25,1.15]$。\n\n- 用例 2（树梢间无实际差异）：\n  - 观测性状向量：$X^{(2)}=[0,1,0,1,1,0,1,0]$。\n  - 多样化代理指标：$y^{(2)}=[1.02,0.98,1.01,1.00,0.99,1.03,1.00,0.97]$。\n\n- 用例 3（频繁的隐藏状态切换；与性状几乎对齐但存在不匹配）：\n  - 观测性状向量：$X^{(3)}=[0,1,0,1,0,1,1,1]$。\n  - 多样化代理指标：$y^{(3)}=[0.49,1.21,0.52,1.19,0.51,1.18,0.50,1.22]$。\n\n您的任务：\n1. 实现模型 A 的最大似然估计，以获得 $\\ell_A$ 和 $\\mathrm{AIC}_A$。\n2. 在给定的树上使用 Felsenstein 剪枝算法实现模型 B 的最大似然估计，以获得 $\\ell_B$ 和 $\\mathrm{AIC}_B$。\n3. 对于每个用例 $j\\in\\{1,2,3\\}$，返回一个布尔值 $\\mathrm{AIC}_B  \\mathrm{AIC}_A$。\n\n最终输出规格：\n- 您的程序应生成一行输出，其中包含三个布尔结果，格式为方括号括起来的逗号分隔列表，例如 $\\texttt{[True,False,True]}$。\n\n测试套件覆盖预期：\n- 用例 1 是一个“理想路径”，其中隐藏速率模型应被优先选择，因为隐藏状态在系统发育上是聚类的，并驱动多样化代理指标，从而产生一种在对系统发育和隐藏状态建模时是伪相关的明显性状相关性。\n- 用例 2 是一个没有显著差异的边界情况；由于简约性原则，更复杂的隐藏状态模型不应优于仅考虑性状的模型。\n- 用例 3 通过频繁的隐藏状态切换和与性状的近乎对齐来考验算法；当树结构提供的解释能力超出性状划分所能提供的有限能力时，由于对额外参数的惩罚，隐藏状态模型可能不会被优先选择。\n\n此问题中的所有数值均为无单位实数。不使用角度。不出现百分比。要求的输出是布尔值。", "solution": "所提出的问题要求比较两种统计模型，用于解释二元性状、连续性状和系统发育之间的关系。首先评估问题陈述的有效性。\n\n### 问题验证\n\n**步骤 1：提取已知条件**\n- **模型 A（仅考虑性状的高斯混合模型）**：\n  - 数据：树梢 $i$ 处观测到的二元性状 $X_i \\in \\{0,1\\}$ 和连续代理指标 $y_i$。\n  - 似然：高斯密度 $\\phi(y_i|\\mu_{X_i}, \\sigma)$ 的乘积。\n  - 参数：$(\\mu_0, \\mu_1, \\sigma)$，$k_A=3$。\n  - 标准：赤池信息准则，$\\mathrm{AIC}_A = 2k_A - 2\\ell_A$，其中 $\\ell_A$ 是最大化对数似然。\n\n- **模型 B（树-隐藏状态高斯隐马尔可夫模型）**：\n  - 模型：一个在树上具有速率 $(q_{01}, q_{10})$ 的二状态隐藏连续时间马尔可夫链（CTMC）。\n  - 发射：$y_i$ 从 $\\phi(y_i|\\mu_{H_i}, \\sigma)$ 中抽取，其中 $H_i \\in \\{0,1\\}$ 是隐藏状态。\n  - 参数：$(\\mu_0, \\mu_1, \\sigma, q_{01}, q_{10})$，$k_B=5$。\n  - 标准：$\\mathrm{AIC}_B = 2k_B - 2\\ell_B$，其中 $\\ell_B$ 通过 Felsenstein 剪枝算法最大化。\n\n- **CTMC 定义**：\n  - 速率矩阵：$Q=\\begin{pmatrix} -q_{01}  q_{01} \\\\ q_{10}  -q_{10} \\end{pmatrix}$。\n  - 转移矩阵：$P(t) = \\exp(Qt)$。\n  - 平稳分布：$\\boldsymbol{\\pi}=(\\pi_0, \\pi_1)$，其中当 $q_{01}+q_{10}0$ 时，$\\pi_0=\\frac{q_{10}}{q_{01}+q_{10}}$ 且 $\\pi_1=\\frac{q_{01}}{q_{01}+q_{10}}$。\n\n- **树结构**：\n  - 一个固定的、有根的、二分的树，有 $8$ 个树梢（索引 $0-7$）和内部节点 $8-14$。\n  - 根节点：节点 $14$。所有分支长度均为 $0.5$。\n  - 拓扑由有向边给出：$(14,12,0.5), (14,13,0.5), (12,10,0.5), (12,11,0.5), (10,0,0.5), (10,1,0.5), (11,2,0.5), (11,3,0.5), (13,9,0.5), (13,8,0.5), (9,4,0.5), (9,5,0.5), (8,6,0.5), (8,7,0.5)$。\n\n- **测试数据**：提供了三个用例，每个用例都有一个观测性状向量 $X$ 和连续代理指标 $y$。\n  - 用例 1：$X^{(1)}=[0,0,1,1,1,1,0,1]$, $y^{(1)}=[0.45,0.55,0.52,0.48,1.22,1.18,1.25,1.15]$。\n  - 用例 2：$X^{(2)}=[0,1,0,1,1,0,1,0]$, $y^{(2)}=[1.02,0.98,1.01,1.00,0.99,1.03,1.00,0.97]$。\n  - 用例 3：$X^{(3)}=[0,1,0,1,0,1,1,1]$, $y^{(3)}=[0.49,1.21,0.52,1.19,0.51,1.18,0.50,1.22]$。\n\n- **任务**：对于每个用例，判断是否 $\\mathrm{AIC}_B  \\mathrm{AIC}_A$。\n\n**步骤 2：使用提取的已知条件进行验证**\n- **科学依据**：该问题使用了计算系统发育学中已建立的概念，包括 CTMC、树上的隐马尔可夫模型、Felsenstein 剪枝算法和用于模型比较的 AIC。这些都是标准工具。该问题在科学上是合理的。\n- **良态问题**：模型、数据、树结构和目标都已明确定义。任务需要通过数值优化来找到最大似然估计，这在此类问题中是标准做法，并不会使其成为病态问题。每个用例都期望一个唯一的布尔答案。\n- **客观性**：问题以精确的数学和算法术语陈述，没有主观性。对测试用例的“预期”仅作为预期行为的指南，不改变客观任务。\n- **完整性和一致性**：问题提供了构建解决方案所需的所有必要组件。没有矛盾之处。\n\n**步骤 3：结论与行动**\n该问题被判定为**有效**。这是一个定义明确的、关于实现和比较系统发育统计模型的练习。因此，有必要提供完整的解决方案。\n\n### 基于原则的解决方案设计\n\n问题的核心是计算并比较两个模型的赤池信息准则（AIC）。\n$\\mathrm{AIC} = 2k - 2\\ell_{max}$，其中 $k$ 是参数数量，$\\ell_{max}$ 是最大对数似然。\n\n**模型 A：仅考虑性状的高斯混合模型**\n该模型假设连续数据 $y_i$ 从两个高斯分布中的一个抽取，由观测到的二元性状 $X_i$ 决定。系统发育被忽略。对数似然为：\n$$ \\ell_A(\\mu_0, \\mu_1, \\sigma) = \\sum_{i=0}^{N-1} \\log \\phi(y_i | \\mu_{X_i}, \\sigma) $$\n其中 $N=8$ 是树梢的数量，$\\phi(y | \\mu, \\sigma)$ 是高斯概率密度函数。参数为 $k_A=3$：$(\\mu_0, \\mu_1, \\sigma)$。\n\n这些参数的最大似然估计（MLE）具有解析解。令 $S_s = \\{y_i | X_i = s\\}$ 且 $n_s = |S_s|$，对于 $s \\in \\{0,1\\}$。\n均值的 MLE 是每组的样本均值：\n$$ \\hat{\\mu}_0 = \\frac{1}{n_0} \\sum_{y \\in S_0} y, \\quad \\hat{\\mu}_1 = \\frac{1}{n_1} \\sum_{y \\in S_1} y $$\n方差 $\\sigma^2$ 的 MLE 是合并样本方差：\n$$ \\hat{\\sigma}^2 = \\frac{1}{N} \\left( \\sum_{y \\in S_0} (y - \\hat{\\mu}_0)^2 + \\sum_{y \\in S_1} (y - \\hat{\\mu}_1)^2 \\right) $$\n将这些 MLE 代入对数似然函数即可获得最大化对数似然 $\\ell_A$。一种数值上稳定的计算方法是：\n$$ \\ell_A = \\sum_{y \\in S_0} \\log \\phi(y | \\hat{\\mu}_0, \\hat{\\sigma}) + \\sum_{y \\in S_1} \\log \\phi(y | \\hat{\\mu}_1, \\hat{\\sigma}) $$\n最后，$\\mathrm{AIC}_A = 2(3) - 2\\ell_A = 6 - 2\\ell_A$。\n\n**模型 B：树-隐藏状态高斯隐马尔可夫模型**\n该模型假设连续数据 $y_i$ 从一个高斯分布中发射，其均值由一个隐藏的二元状态 $H_i$ 决定，该状态根据 CTMC 沿系统发育树演化。参数为 $k_B=5$：$(\\mu_0, \\mu_1, \\sigma, q_{01}, q_{10})$。\n\n对数似然 $\\ell_B$ 没有封闭形式解，必须通过数值方法最大化。对于给定的一组参数，似然是使用 Felsenstein 剪枝算法计算的。\n\n1.  **转移概率**：沿长度为 $t$ 的分支从状态 $i$ 转移到状态 $j$ 的概率由矩阵 $P(t) = \\exp(Qt)$ 给出。对于二状态模型，设 $\\lambda = q_{01} + q_{10}$：\n    $$ P(t) = \\frac{1}{\\lambda} \\begin{pmatrix} q_{10} + q_{01}e^{-\\lambda t}   q_{01}(1 - e^{-\\lambda t}) \\\\ q_{10}(1 - e^{-\\lambda t})   q_{01} + q_{10}e^{-\\lambda t} \\end{pmatrix} $$\n    此问题中所有分支长度均为 $t=0.5$。\n\n2.  **Felsenstein 剪枝算法**：该算法通过对树进行后序遍历来计算树梢数据的似然。令 $L_u(s)$ 为从节点 $u$ 下降的分支中数据的似然，假定 $u$ 处于状态 $s$。\n    - **初始化（树梢）**：对于树梢节点 $i$，似然向量由发射概率给出：\n      $$ \\mathbf{L}_i = [L_i(0), L_i(1)] = [\\phi(y_i | \\mu_0, \\sigma), \\phi(y_i | \\mu_1, \\sigma)] $$\n    - **递归（内部节点）**：对于一个内部节点 $u$，其子节点为 $v$ 和 $w$，连接分支长度为 $t_v$ 和 $t_w$，其似然向量通过组合其子节点的似然来计算：\n      $$ L_u(s) = \\left( \\sum_{s_v=0}^1 P(t_v)_{s,s_v} L_v(s_v) \\right) \\times \\left( \\sum_{s_w=0}^1 P(t_w)_{s,s_w} L_w(s_w) \\right) $$\n      以矩阵形式表示为 $\\mathbf{L}_u = (P(t_v)^T \\mathbf{L}_v) \\odot (P(t_w)^T \\mathbf{L}_w)$，其中 $\\odot$ 是逐元素乘积。\n    - **终止（根）**：在根节点 $r$ 处，总似然是根似然向量的加权和，权重为平稳分布 $\\boldsymbol{\\pi}$：\n      $$ \\mathcal{L} = \\boldsymbol{\\pi} \\cdot \\mathbf{L}_r = \\pi_0 L_r(0) + \\pi_1 L_r(1) $$\n    由于许多小概率的乘积，此计算容易出现数值下溢。需要一个缩放程序。在计算每个 $\\mathbf{L}_u$ 后，通过其总和对其进行重新缩放，并累加缩放因子的对数。最终的对数似然是所有对数缩放因子的总和，加上根部最终缩放似然的对数。\n\n3.  **优化**：使用数值优化器（例如 `scipy.optimize` 中的 Nelder-Mead）最小化函数 $-\\ell_B(\\mu_0, \\mu_1, \\sigma, q_{01}, q_{10})$。通过对其对数进行优化来处理 $\\sigma, q_{01}, q_{10}$ 的正值约束。模型 A 的 MLE 为 $\\mu_0, \\mu_1, \\sigma$ 提供了一个良好的初始猜测值。\n\n一旦找到最大化对数似然 $\\ell_B$，AIC 计算为 $\\mathrm{AIC}_B = 2(5) - 2\\ell_B = 10 - 2\\ell_B$。\n\n每个测试用例的最后一步是比较两个 AIC 值，并返回 $\\mathrm{AIC}_B  \\mathrm{AIC}_A$ 的布尔结果。", "answer": "```python\nimport numpy as np\nfrom scipy.optimize import minimize\nfrom scipy.stats import norm\n\ndef solve():\n    \"\"\"\n    Main function to solve the problem for all test cases.\n    It orchestrates the fitting of Model A and Model B, compares their AIC values,\n    and prints the final results in the specified format.\n    \"\"\"\n    # Tree specification, fixed for all cases\n    tree_spec = {\n        'children': {\n            14: [12, 13], 13: [9, 8], 12: [10, 11], 11: [2, 3],\n            10: [0, 1], 9: [4, 5], 8: [6, 7]\n        },\n        'post_order': [0, 1, 10, 2, 3, 11, 4, 5, 9, 6, 7, 8, 12, 13, 14],\n        'tips': list(range(8)),\n        'branch_length': 0.5,\n        'root': 14\n    }\n\n    test_cases = [\n        {\n            \"X\": [0, 0, 1, 1, 1, 1, 0, 1],\n            \"y\": [0.45, 0.55, 0.52, 0.48, 1.22, 1.18, 1.25, 1.15]\n        },\n        {\n            \"X\": [0, 1, 0, 1, 1, 0, 1, 0],\n            \"y\": [1.02, 0.98, 1.01, 1.00, 0.99, 1.03, 1.00, 0.97]\n        },\n        {\n            \"X\": [0, 1, 0, 1, 0, 1, 1, 1],\n            \"y\": [0.49, 1.21, 0.52, 1.19, 0.51, 1.18, 0.50, 1.22]\n        }\n    ]\n\n    results = []\n    for case in test_cases:\n        y, X = case[\"y\"], case[\"X\"]\n        \n        # Fit Model A\n        aic_A, model_A_params = _fit_model_A(y, X)\n        \n        # Fit Model B\n        aic_B = _fit_model_B(y, tree_spec, model_A_params)\n\n        results.append(aic_B  aic_A)\n\n    print(f\"[{','.join(map(str, results))}]\")\n\n\ndef _fit_model_A(y, X):\n    \"\"\"\n    Computes AIC and MLE parameters for Model A.\n    \"\"\"\n    k_A = 3\n    y = np.array(y)\n    X = np.array(X)\n\n    y_0 = y[X == 0]\n    y_1 = y[X == 1]\n    n_0 = len(y_0)\n    n_1 = len(y_1)\n    N = n_0 + n_1\n\n    if n_0 == 0 or n_1 == 0:\n        mu = np.mean(y)\n        sigma2 = np.var(y)\n        if sigma2  1e-12: sigma2 = 1e-12\n        sigma = np.sqrt(sigma2)\n        ll = np.sum(norm.logpdf(y, loc=mu, scale=sigma))\n        k_A = 2\n        aic_A = 2 * k_A - 2 * ll\n        # Assign means to avoid unpacking error, though one is irrelevant\n        mu_0 = mu if n_1 == 0 else 0.0\n        mu_1 = mu if n_0 == 0 else 0.0\n        return aic_A, (mu_0, mu_1, sigma)\n\n    mu_0 = np.mean(y_0)\n    mu_1 = np.mean(y_1)\n\n    ss_0 = np.sum((y_0 - mu_0)**2)\n    ss_1 = np.sum((y_1 - mu_1)**2)\n    sigma2 = (ss_0 + ss_1) / N\n    if sigma2  1e-12: sigma2 = 1e-12\n    sigma = np.sqrt(sigma2)\n    \n    ll_0 = np.sum(norm.logpdf(y_0, loc=mu_0, scale=sigma))\n    ll_1 = np.sum(norm.logpdf(y_1, loc=mu_1, scale=sigma))\n    ll_A = ll_0 + ll_1\n    \n    aic_A = 2 * k_A - 2 * ll_A\n    return aic_A, (mu_0, mu_1, sigma)\n\n\ndef _fit_model_B(y_data, tree, initial_params):\n    \"\"\"\n    Computes AIC for Model B using numerical optimization.\n    \"\"\"\n    k_B = 5\n    y = np.array(y_data)\n    \n    def neg_log_likelihood(params, y, tree_spec):\n        mu0, mu1, log_sigma, log_q01, log_q10 = params\n        sigma = np.exp(log_sigma)\n        q01 = np.exp(log_q01)\n        q10 = np.exp(log_q10)\n\n        # Numerical stability checks\n        if sigma  1e-9: return np.inf\n\n        # CTMC calculations\n        q_sum = q01 + q10\n        if q_sum  1e-9:\n            pi = np.array([0.5, 0.5])\n            P_t = np.identity(2)\n        else:\n            pi = np.array([q10 / q_sum, q01 / q_sum])\n            exp_term = np.exp(-q_sum * tree_spec['branch_length'])\n            P_t = np.array([\n                [pi[0] + pi[1] * exp_term, pi[1] * (1 - exp_term)],\n                [pi[0] * (1 - exp_term), pi[1] + pi[0] * exp_term]\n            ])\n        \n        # Felsenstein's pruning algorithm with scaling\n        likelihood_vectors = {}\n        total_log_scale = 0.0\n\n        for node in tree_spec['post_order']:\n            if node in tree_spec['tips']:\n                log_L0 = norm.logpdf(y[node], mu0, sigma)\n                log_L1 = norm.logpdf(y[node], mu1, sigma)\n                L_node = np.array([np.exp(log_L0), np.exp(log_L1)])\n            else:\n                child1, child2 = tree_spec['children'][node]\n                L1 = likelihood_vectors[child1]\n                L2 = likelihood_vectors[child2]\n                L_prime1 = P_t.T @ L1\n                L_prime2 = P_t.T @ L2\n                L_node = L_prime1 * L_prime2 # Element-wise product\n            \n            scale = np.sum(L_node)\n            if scale > 1e-300: # Prevent underflow\n                likelihood_vectors[node] = L_node / scale\n                total_log_scale += np.log(scale)\n            else:\n                return np.inf\n\n        # Final likelihood at root\n        L_root = likelihood_vectors[tree_spec['root']]\n        final_L = pi @ L_root\n        \n        if final_L = 1e-300: return np.inf\n\n        log_L = np.log(final_L) + total_log_scale\n        return -log_L\n\n    # Initial guess for optimization from Model A's results\n    mu0_init, mu1_init, sigma_init = initial_params\n    x0 = np.array([mu0_init, mu1_init, np.log(sigma_init), np.log(1.0), np.log(1.0)])\n\n    # Run optimizer\n    result = minimize(\n        neg_log_likelihood, \n        x0, \n        args=(y, tree), \n        method='Nelder-Mead', \n        options={'maxiter': 2000, 'adaptive': True}\n    )\n\n    max_ll_B = -result.fun\n    aic_B = 2 * k_B - 2 * max_ll_B\n    return aic_B\n\nif __name__ == '__main__':\n    solve()\n```", "id": "2722598"}]}