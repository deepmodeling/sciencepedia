{"hands_on_practices": [{"introduction": "要理解好基因和代价原则，核心在于掌握诚实信号得以维持的数学机理。通过一个经典的指示机制模型，我们将亲手推导出一个分离均衡，即不同品质的个体如何通过选择不同的信号水平来诚实地展示自身品质。这个练习将为你展示信号成本和收益如何相互作用，从而确保了信号的诚实性，是后续更复杂模型的基础。[@problem_id:2726702]", "problem": "在演化生物学的Grafen风格指示模型中，个体质量由一个连续性状 $q \\in [\\underline{q}, \\overline{q}]$ 表示，其中 $\\underline{q}  0$。一个质量为 $q$ 的个体选择一个非负信号 $s \\in \\mathbb{R}_{+}$ 来影响接收者的反应。该个体的适应度收益为 $U(s,q) = B(s) - c(s,q)$，其中收益与信号成线性关系，$B(s) = a s$ 且 $a  0$，而信号成本随质量的增加而减少，并且是信号的凸函数，$c(s,q) = k s^{2}/q$ 且 $k  0$。假设对于所有 $q \\in [\\underline{q}, \\overline{q}]$，信号 $s$ 的选择是可微的且为内点解。\n\n考虑一个分离均衡，其中不同类型的个体根据一个关于 $q$ 可微且严格递增的函数 $s^{*}(q)$ 选择不同的信号，并满足激励相容性：对于 $[\\underline{q}, \\overline{q}]$ 中的所有 $q$ 和 $\\tilde{q}$，$U(s^{*}(q), q) \\geq U(s^{*}(\\tilde{q}), q)$。仅从这些基本设定以及信号博弈中激励相容性和分离均衡的定义出发，推导出在激励相容性约束下使 $U(s,q)$ 最大化的分离均衡信号 $s^{*}(q)$ 的闭式表达式。将最终答案表示为 $a$、$k$ 和 $q$ 的函数。无需四舍五入，不涉及单位。", "solution": "该问题是有效的。它在演化信号理论的背景下提出了一个定义明确的数学问题，基于已建立的模型和原则。提供了所有必要的信息，术语清晰，设定在科学和数学上是一致的。\n\n目标是为质量为 $q \\in [\\underline{q}, \\overline{q}]$ 的个体推导出分离均衡信号函数 $s^{*}(q)$。个体的适应度收益由 $U(s,q) = B(s) - c(s,q)$ 给出，其中收益为 $B(s) = as$，成本为 $c(s,q) = \\frac{k s^{2}}{q}$。参数 $a$ 和 $k$ 是正常数。信号选择为 $s \\in \\mathbb{R}_{+}$。\n\n分离均衡的特征是一个单射信号函数 $s^{*}(q)$，其中不同类型 $q$ 的个体选择不同的信号。问题陈述 $s^{*}(q)$ 是可微且严格递增的，这意味着 $\\frac{ds^{*}}{dq}  0$。这种均衡的基本条件是激励相容性（IC），它指出，任何类型 $q$ 的个体通过发送其真实信号 $s^{*}(q)$ 所获得的适应度，必须高于（或至少等于）发送对应于另一类型 $\\tilde{q}$ 的任何其他信号 $s^{*}(\\tilde{q})$ 所获得的适应度。数学上表示为：\n$$ U(s^{*}(q), q) \\geq U(s^{*}(\\tilde{q}), q) \\quad \\forall q, \\tilde{q} \\in [\\underline{q}, \\overline{q}] $$\n这个条件意味着，对于任何给定的类型 $q$，函数 $f(\\tilde{q}) = U(s^{*}(\\tilde{q}), q)$ 必须在 $\\tilde{q} = q$ 处达到全局最大值。既然我们已知 $s^{*}(q)$ 是可微的且选择是内点解，我们可以使用微积分来分析该函数的局部行为。在 $\\tilde{q} = q$ 处取得最大值的一阶必要条件是，$f(\\tilde{q})$ 关于 $\\tilde{q}$ 的导数在 $\\tilde{q} = q$ 处的值必须为零。\n$$ \\frac{d}{d\\tilde{q}} U(s^{*}(\\tilde{q}), q) \\Big|_{\\tilde{q}=q} = 0 $$\n我们应用链式法则对 $U(s^{*}(\\tilde{q}), q)$ 关于 $\\tilde{q}$ 求导：\n$$ \\frac{d}{d\\tilde{q}} U(s^{*}(\\tilde{q}), q) = \\frac{\\partial U(s,q)}{\\partial s}\\Bigg|_{s=s^{*}(\\tilde{q})} \\cdot \\frac{ds^{*}(\\tilde{q})}{d\\tilde{q}} $$\n在 $\\tilde{q} = q$ 处计算此导数，得到一阶条件：\n$$ \\frac{\\partial U(s,q)}{\\partial s}\\Bigg|_{s=s^{*}(q)} \\cdot \\frac{ds^{*}(q)}{dq} = 0 $$\n问题指定了一个分离均衡，其中 $s^{*}(q)$ 是严格递增的。这意味着导数 $\\frac{ds^{*}(q)}{dq}$ 是严格为正的。由于两项的乘积为零，且其中一项严格为正，另一项必须为零。这就给出了关键的局部激励相容性条件：\n$$ \\frac{\\partial U(s,q)}{\\partial s}\\Bigg|_{s=s^{*}(q)} = 0 $$\n这个条件表明，在均衡状态下，每种类型 $q$ 都必须选择一个信号水平 $s^*(q)$，以局部最大化其自身的适应度函数。我们现在为给定的适应度函数 $U(s,q) = as - \\frac{ks^{2}}{q}$ 计算这个偏导数：\n$$ \\frac{\\partial U}{\\partial s} = \\frac{\\partial}{\\partial s} \\left( as - \\frac{ks^{2}}{q} \\right) = a - \\frac{2ks}{q} $$\n在均衡信号 $s = s^{*}(q)$ 处将此导数设为零：\n$$ a - \\frac{2ks^{*}(q)}{q} = 0 $$\n这是一个关于函数 $s^{*}(q)$ 的代数方程。我们求解 $s^{*}(q)$：\n$$ a = \\frac{2ks^{*}(q)}{q} $$\n$$ s^{*}(q) = \\frac{aq}{2k} $$\n这个表达式给出了候选的分离均衡信号，作为质量 $q$ 以及先验参数 $a$ 和 $k$ 的函数。我们必须验证此解是否与初始假设一致。关于 $q$ 的导数是 $\\frac{ds^{*}}{dq} = \\frac{a}{2k}$。由于 $a  0$ 且 $k  0$，该导数为正，这证实了信号函数是严格递增的，而这是分离均衡所要求的。此外，全局激励相容性也得到满足。对于一个固定的 $q$，效用函数 $U(s,q)$ 是关于 $s$ 的开口向下的抛物线，其唯一最大值点在 $s = \\frac{aq}{2k}$。因此，对于任何其他信号 $s$，包括任何 $s = s^{*}(\\tilde{q}) = \\frac{a\\tilde{q}}{2k}$，都有 $U\\left(\\frac{aq}{2k}, q\\right) \\ge U(s, q)$。因此，激励相容性条件在全局范围内成立。\n\n推导出的函数 $s^{*}(q) = \\frac{aq}{2k}$ 是该模型唯一的、可微的分离均衡。", "answer": "$$\\boxed{\\frac{aq}{2k}}$$", "id": "2726702"}, {"introduction": "理论模型是理解世界的起点，但现实世界充满了各种噪音。此练习将理论模型与定量遗传学相结合，探讨一个核心问题：信号在多大程度上能真正反映个体的遗传品质？我们将把“信号诚实度”量化为一个可计算的指标，并分析环境变异如何“稀释”信号中包含的遗传信息，让你更深刻地理解信号在演化中的信噪比问题。[@problem_id:2726691]", "problem": "一个由雄性产生的性选择信号，记为 $s$，是其生理状况 $C$ 的函数。状况是一个数量性状，由加性遗传组分 $G$ 和环境组分 $E$ 构成，因此 $C = G + E$。假设以下标准数量遗传学性质：$\\operatorname{Var}(G) = V_{A}(C)$，$\\operatorname{Var}(E) = V_{E}(C)$，且 $G$ 和 $E$ 相互独立。信号的产生与状况呈线性关系，并带有独立的产生误差，因此 $s = \\beta C + \\eta$，其中 $\\beta  0$ 是一个固定的响应参数，$\\eta$ 是独立的产生噪音，其方差为 $\\operatorname{Var}(\\eta) = V_{\\eta}$。接收者使用信号 $s$ 来推断加性遗传品质 $G$。将信号诚实度定义为 $s$ 和 $G$ 之间的决定系数，即 $H = \\operatorname{corr}(s, G)^{2}$。\n\n仅从这些定义和独立性假设出发，推导 $H$ 作为 $V_{E}(C)$ 的显式函数，同时保持 $V_{A}(C)$、$\\beta$ 和 $V_{\\eta}$ 固定不变。然后，计算偏导数 $\\partial H / \\partial V_{E}(C)$ 并在 $V_{A}(C) = 0.6$，$V_{E}(C) = 0.4$，$\\beta = 1.0$ 和 $V_{\\eta} = 0.2$ 时对其求值。将这些参数值下 $\\partial H / \\partial V_{E}(C)$ 的值作为一个实数报告。将您的答案四舍五入到四位有效数字。不需要单位。", "solution": "该问题要求推导信号诚实度 $H$ 作为状况的环境方差组分 $V_{E}(C)$ 的函数，并在一组特定的参数值下计算其关于 $V_{E}(C)$ 的偏导数。该问题陈述在科学上是合理的，问题提法是适定的，并包含了获得唯一解所需的所有信息。\n\n首先，我们确定所给出的定义。\n生理状况 $C$ 由加性模型 $C = G + E$ 给出，其中 $G$ 是加性遗传组分，$E$ 是环境组分。规定 $G$ 和 $E$ 是相互独立的随机变量。\n方差定义为 $\\operatorname{Var}(G) = V_{A}(C)$ 和 $\\operatorname{Var}(E) = V_{E}(C)$。\n性选择信号 $s$ 是作为状况的线性函数产生的：$s = \\beta C + \\eta$，其中 $\\beta  0$ 是一个常数，$\\eta$ 是一个独立的产生噪音项，其方差为 $\\operatorname{Var}(\\eta) = V_{\\eta}$。$\\eta$ 的独立性意味着它独立于 $C$，因此也独立于 $G$ 和 $E$。\n\n信号诚实度 $H$ 定义为信号 $s$ 和加性遗传品质 $G$ 之间的决定系数：\n$$H = \\operatorname{corr}(s, G)^{2}$$\n根据相关系数的定义，这可以写为：\n$$H = \\left( \\frac{\\operatorname{Cov}(s, G)}{\\sqrt{\\operatorname{Var}(s) \\operatorname{Var}(G)}} \\right)^2 = \\frac{\\operatorname{Cov}(s, G)^2}{\\operatorname{Var}(s) \\operatorname{Var}(G)}$$\n我们现在必须使用给定的定义和统计性质来推导此方程中每一项的表达式。\n\n遗传组分的方差是直接给出的：\n$$\\operatorname{Var}(G) = V_{A}(C)$$\n\n接下来，我们推导协方差项 $\\operatorname{Cov}(s, G)$。我们代入 $s$ 和 $C$ 的表达式：\n$$\\operatorname{Cov}(s, G) = \\operatorname{Cov}(\\beta C + \\eta, G) = \\operatorname{Cov}(\\beta (G+E) + \\eta, G)$$\n利用协方差的线性性质：\n$$\\operatorname{Cov}(s, G) = \\beta \\operatorname{Cov}(G, G) + \\beta \\operatorname{Cov}(E, G) + \\operatorname{Cov}(\\eta, G)$$\n根据定义，$\\operatorname{Cov}(G, G) = \\operatorname{Var}(G) = V_{A}(C)$。\n由于 $G$ 和 $E$ 是独立的，它们的协方差为零：$\\operatorname{Cov}(E, G) = 0$。\n由于 $\\eta$ 独立于 $C = G+E$，它也独立于 $G$，所以它们的协方差为零：$\\operatorname{Cov}(\\eta, G) = 0$。\n代入这些结果，协方差项简化为：\n$$\\operatorname{Cov}(s, G) = \\beta V_{A}(C)$$\n\n最后，我们推导信号的方差 $\\operatorname{Var}(s)$：\n$$\\operatorname{Var}(s) = \\operatorname{Var}(\\beta C + \\eta)$$\n因为 $C$ 和 $\\eta$ 是独立的，所以它们和的方差是它们方差的和：\n$$\\operatorname{Var}(s) = \\operatorname{Var}(\\beta C) + \\operatorname{Var}(\\eta) = \\beta^2 \\operatorname{Var}(C) + V_{\\eta}$$\n为了求 $\\operatorname{Var}(C)$，我们使用其定义 $C = G + E$。由于 $G$ 和 $E$ 是独立的：\n$$\\operatorname{Var(C)} = \\operatorname{Var}(G) + \\operatorname{Var}(E) = V_{A}(C) + V_{E}(C)$$\n将此结果代回 $\\operatorname{Var}(s)$ 的表达式：\n$$\\operatorname{Var}(s) = \\beta^2 (V_{A}(C) + V_{E}(C)) + V_{\\eta}$$\n\n现在我们通过代入推导出的 $\\operatorname{Var}(G)$、$\\operatorname{Cov}(s, G)$ 和 $\\operatorname{Var}(s)$ 的项来组合出 $H$ 的表达式：\n$$H = \\frac{(\\beta V_{A}(C))^2}{[\\beta^2 (V_{A}(C) + V_{E}(C)) + V_{\\eta}] V_{A}(C)}$$\n假设 $V_{A}(C)  0$（对于给定的参数这是成立的），我们可以简化这个表达式：\n$$H = \\frac{\\beta^2 V_{A}(C)}{\\beta^2 (V_{A}(C) + V_{E}(C)) + V_{\\eta}}$$\n这就是 $H$ 关于所需参数的显式函数。\n\n下一步是计算偏导数 $\\frac{\\partial H}{\\partial V_{E}(C)}$。我们将 $V_{A}(C)$、$\\beta$ 和 $V_{\\eta}$ 视为常数。为清晰起见，设 $x = V_{E}(C)$。$H$ 的表达式形式为 $f(x) = \\frac{A}{B + C x}$，其中 $A = \\beta^2 V_{A}(C)$，$B = \\beta^2 V_{A}(C) + V_{\\eta}$，以及 $C = \\beta^2$。\n使用商法则或链式法则进行微分：\n$$\\frac{\\partial H}{\\partial V_{E}(C)} = \\frac{d}{dx} \\left( A(B+Cx)^{-1} \\right) = A \\cdot (-1)(B+Cx)^{-2} \\cdot C = - \\frac{AC}{(B+Cx)^2}$$\n代回原始变量：\n$$\\frac{\\partial H}{\\partial V_{E}(C)} = - \\frac{(\\beta^2 V_{A}(C))(\\beta^2)}{[\\beta^2 V_{A}(C) + V_{\\eta} + \\beta^2 V_{E}(C)]^2} = - \\frac{\\beta^4 V_{A}(C)}{[\\beta^2 (V_{A}(C) + V_{E}(C)) + V_{\\eta}]^2}$$\n\n最后一步是在指定的参数值下计算这个导数：$V_{A}(C) = 0.6$，$V_{E}(C) = 0.4$，$\\beta = 1.0$，和 $V_{\\eta} = 0.2$。\n我们将这些值代入偏导数的表达式中：\n$$\\frac{\\partial H}{\\partial V_{E}(C)} = - \\frac{(1.0)^4 (0.6)}{[(1.0)^2 (0.6 + 0.4) + 0.2]^2}$$\n首先，我们计算分子：\n$$\\text{分子} = - (1.0)^4 (0.6) = -0.6$$\n接下来，我们计算分母括号内的项：\n$$\\text{分母项} = (1.0)^2 (0.6 + 0.4) + 0.2 = 1.0(1.0) + 0.2 = 1.2$$\n分母是该项的平方：\n$$\\text{分母} = (1.2)^2 = 1.44$$\n因此，偏导数的值为：\n$$\\frac{\\partial H}{\\partial V_{E}(C)} = - \\frac{0.6}{1.44} = - \\frac{60}{144}$$\n通过分子分母同除以最大公约数 $12$ 来简化分数：\n$$\\frac{\\partial H}{\\partial V_{E}(C)} = - \\frac{5}{12}$$\n换算成小数，结果是 $-0.41666...$。问题要求四舍五入到四位有效数字，得到 $-0.4167$。\n负号表示，随着状况的环境方差组分增加，信号的诚实度降低，这是诚实信号理论中的一个关键结果。", "answer": "$$\\boxed{-0.4167}$$", "id": "2726691"}, {"introduction": "演化生物学的研究最终需要数据的检验。当我们观察到一个种群中的信号行为时，我们如何判断它们是在进行诚实的“分离”通讯，还是所有个体都在发出相似信号的“混合”策略？本练习将指导你应用赤池信息准则（Akaike Information Criterion, AIC）这一强大的统计工具，通过比较不同模型的似然度，让你学会如何基于观测数据来客观地推断信号系统的真实模式。[@problem_id:2726630]", "problem": "考虑一个群体，其中具有潜在遗传质量的个体发出一种代价高昂的信号。根据与代价原则（handicap principle）相关的指标机制观点，高质量的个体能承担更高的信号成本。我们观测到数据对 $(s_i, q_i)$，其中 $i \\in \\{1,\\dots,n\\}$，$s_i \\in \\mathbb{R}$ 是一个标量信号强度，$q_i \\in \\{0,1\\}$ 是观测到的质量标签（$q_i = 1$ 表示高质量，$q_i = 0$ 表示低质量）。你需要对两种信号模型进行基于似然的模型比较：\n\n- 分离模型（Separating model）：信号能够提供关于质量的信息，模型化为条件高斯分布，具有特定于质量的均值和共享方差。形式上，$s_i \\mid q_i = j \\sim \\mathcal{N}(\\mu_j, \\sigma^2)$，其中 $j \\in \\{0,1\\}$。\n- 混合模型（Pooling model）：信号不能提供关于质量的信息，模型化为与质量无关的单个高斯分布。形式上，$s_i \\sim \\mathcal{N}(\\mu, \\sigma^2)$，且独立于 $q_i$。\n\n你的任务是实现最大似然估计，并使用赤池信息准则（Akaike Information Criterion, AIC）来比较这两个模型。\n\n需要使用的基本定义：\n- 对于 $x \\in \\mathbb{R}$，高斯（正态）密度函数为 $f(x \\mid \\mu, \\sigma^2) = \\dfrac{1}{\\sqrt{2\\pi \\sigma^2}} \\exp\\!\\left(-\\dfrac{(x-\\mu)^2}{2\\sigma^2}\\right)$，其中 $\\sigma^2  0$。\n- 独立观测值的对数似然是各对数密度之和。\n- 在混合模型下，最大似然估计量（通过将对数似然的导数设为零得出）是样本均值 $\\hat{\\mu} = \\dfrac{1}{n} \\sum_{i=1}^n s_i$ 和方差 $\\hat{\\sigma}^2 = \\dfrac{1}{n} \\sum_{i=1}^n (s_i - \\hat{\\mu})^2$。在分离模型下，均值是特定于组的样本均值 $\\hat{\\mu}_j = \\dfrac{1}{n_j} \\sum_{i: q_i = j} s_i$（其中 $j \\in \\{0,1\\}$，$n_j = \\sum_{i=1}^n \\mathbb{I}[q_i = j]$），而共享方差为 $\\hat{\\sigma}^2 = \\dfrac{1}{n} \\sum_{j \\in \\{0,1\\}} \\sum_{i: q_i = j} (s_i - \\hat{\\mu}_j)^2$。\n- 对于具有未知均值和方差的高斯模型，其最大化对数似然（在最大似然估计处求值）可以表示为\n$$\n\\log L = -\\dfrac{n}{2}\\left( \\log(2\\pi) + 1 + \\log(\\hat{\\sigma}^2) \\right),\n$$\n其中 $\\hat{\\sigma}^2$ 是相应的最大似然方差（残差平方和的 $\\dfrac{1}{n}$ 倍）。\n- 赤池信息准则为 $\\mathrm{AIC} = 2k - 2 \\log L$，其中 $k$ 是自由参数的数量。对于混合模型，$k = 2$（一个均值和一个方差）。对于具有两个均值和一个共享方差的分离模型，$k = 3$。\n\n重要的实现细节：\n- 如果某个质量类别缺失（即，对于某个 $j$，$n_j = 0$），则对于该数据集，将分离模型视为与混合模型相同，其 $k = 2$，$\\hat{\\mu}$ 等于总体样本均值，因为缺失类别的均值是不可辨识的。\n- 为确保数值稳定性，如果计算出的 $\\hat{\\sigma}^2$ 等于 $0$，在计算对数似然之前，将其替换为 $\\varepsilon = 10^{-12}$。\n- 比较 AIC 值时，如果它们在绝对容差 $\\tau = 10^{-9}$ 内相等，则优先选择混合模型。\n\n测试的输入规范：\n你将直接在程序中硬编码以下三个数据集（每个数据集都是一对对齐的数组 $(\\mathbf{s}, \\mathbf{q})$）。\n\n- 数据集 #1（一个有利于分离模型的案例）：$n = 10$，对齐的观测值\n  - $\\mathbf{q} = [\\,1,\\,1,\\,1,\\,1,\\,1,\\,0,\\,0,\\,0,\\,0,\\,0\\,]$,\n  - $\\mathbf{s} = [\\,9.8,\\,10.5,\\,10.2,\\,11.0,\\,9.7,\\,4.8,\\,5.1,\\,5.5,\\,6.0,\\,4.9\\,]$.\n- 数据集 #2（一个有利于混合模型的案例）：$n = 10$，对齐的观测值\n  - $\\mathbf{q} = [\\,1,\\,1,\\,1,\\,1,\\,1,\\,0,\\,0,\\,0,\\,0,\\,0\\,]$,\n  - $\\mathbf{s} = [\\,6.8,\\,7.1,\\,7.0,\\,7.3,\\,6.9,\\,7.2,\\,6.7,\\,7.4,\\,6.8,\\,7.0\\,]$.\n- 数据集 #3（一个不平衡的边缘案例）：$n = 10$，对齐的观测值\n  - $\\mathbf{q} = [\\,1,\\,1,\\,1,\\,1,\\,1,\\,1,\\,1,\\,1,\\,1,\\,0\\,]$,\n  - $\\mathbf{s} = [\\,7.9,\\,8.1,\\,8.2,\\,8.0,\\,7.8,\\,8.3,\\,8.1,\\,8.0,\\,7.7,\\,8.05\\,]$.\n\n任务：\n- 对于每个数据集，计算两种模型下的最大似然估计，计算相应的最大化对数似然和 AIC 值，并根据 AIC 规则（AIC 值越低越好；在容差 $\\tau$ 内打平时，优先选择混合模型）来决定哪个模型更适合数据。\n- 将每个数据集的决策表示为一个整数：如果分离模型更好，则输出 $1$，否则输出 $0$。\n\n最终输出格式：\n- 你的程序应生成一行输出，其中包含三个数据集的决策，形式为用方括号括起来的逗号分隔列表，例如 $[\\text{result}_1,\\text{result}_2,\\text{result}_3]$。每个结果必须是整数（$0$ 或 $1$）。", "solution": "该问题要求基于最大似然原理和赤池信息准则（AIC），对生物种群中信号行为的两种统计模型进行定量比较。该问题是自包含的，具有坚实的统计理论基础，并且是适定的。我们将开始解答。\n\n任务的核心是评估对于每个给定的数据集，两种模型中哪一个能对观测到的数据对 $(s_i, q_i)$ 提供更简约的拟合，其中 $s_i$ 是一个连续信号，$q_i$ 是一个二元质量标签。\n\n两种相互竞争的模型是：\n1.  **混合模型（Pooling Model）**：该模型假设信号 $s_i$ 不提供关于质量 $q_i$ 的信息。信号被建模为来自单个高斯分布 $s_i \\sim \\mathcal{N}(\\mu, \\sigma^2)$ 的独立抽样。该模型有 $k_{\\text{pool}} = 2$ 个自由参数：均值 $\\mu$ 和方差 $\\sigma^2$。\n\n2.  **分离模型（Separating Model）**：该模型与代价原则一致，假设信号是信息性的。信号从两个高斯分布之一中抽取，具体取决于质量，$s_i \\mid q_i=j \\sim \\mathcal{N}(\\mu_j, \\sigma^2)$，其中 $j \\in \\{0, 1\\}$。关键是，方差 $\\sigma^2$ 被假定在两个质量组之间是共享的。该模型有 $k_{\\text{sep}} = 3$ 个自由参数：两个均值 $\\mu_0$ 和 $\\mu_1$，以及共享方差 $\\sigma^2$。\n\n对于每个模型和数据集，我们首先找到其参数的最大似然估计（MLEs）。问题中给出了这些 MLEs 的标准闭式表达式。\n\n对于**混合模型**，给定一个包含 $n$ 个信号的样本 $\\{s_1, \\dots, s_n\\}$：\n-   均值的 MLE 是总体样本均值：\n    $$ \\hat{\\mu} = \\frac{1}{n} \\sum_{i=1}^{n} s_i $$\n-   方差的 MLE 是样本方差（分母为 $n$）：\n    $$ \\hat{\\sigma}^2_{\\text{pool}} = \\frac{1}{n} \\sum_{i=1}^{n} (s_i - \\hat{\\mu})^2 $$\n\n对于**分离模型**，我们首先根据质量标签 $q_i$ 将数据划分为两个子样本。设 $n_j = \\sum_{i=1}^{n} \\mathbb{I}[q_i=j]$ 为组 $j \\in \\{0, 1\\}$ 中的个体数量。\n-   特定于组的均值的 MLEs 是子样本均值：\n    $$ \\hat{\\mu}_j = \\frac{1}{n_j} \\sum_{i: q_i=j} s_i \\quad \\text{对于 } j \\in \\{0, 1\\} $$\n-   共享方差的 MLE 是合并方差，计算方法是总残差平方和除以总样本量 $n$：\n    $$ \\hat{\\sigma}^2_{\\text{sep}} = \\frac{1}{n} \\left( \\sum_{i: q_i=0} (s_i - \\hat{\\mu}_0)^2 + \\sum_{i: q_i=1} (s_i - \\hat{\\mu}_1)^2 \\right) $$\n\n一旦计算出给定模型的方差 MLE $\\hat{\\sigma}^2$，就可以使用提供的公式计算最大化对数似然 $\\log L$，该公式适用于均值和方差均被估计的高斯模型：\n$$ \\log L = -\\frac{n}{2} \\left( \\log(2\\pi) + 1 + \\log(\\hat{\\sigma}^2) \\right) $$\n为保证数值稳定性，采取了一项预防措施：如果任何计算出的 $\\hat{\\sigma}^2$ 为零，在取对数之前，会将其替换为 $\\varepsilon = 10^{-12}$。\n\n利用每个模型的最大化对数似然 $\\log L$ 和参数数量 $k$，我们计算 AIC：\n$$ \\mathrm{AIC} = 2k - 2 \\log L $$\nAIC 值较低的模型被认为更拟合数据，因为它在拟合优度（高 $\\log L$）和模型复杂度（低 $k$）之间取得了更好的平衡。\n\n当一个数据集只包含一个质量类别的观测值时（即 $n_0=0$ 或 $n_1=0$），会出现一个关键的边缘情况。在这种情况下，缺失类别（$\\mu_j$）的参数是不可辨识的。分离模型无法与混合模型区分开来。根据问题规范，我们将分离模型视为与混合模型相同：我们为其分配相同的对数似然，并且值得注意的是，参数数量也相同，即 $k_{\\text{sep}} = 2$。\n\n最终的决策规则如下：如果分离模型的 AIC 在考虑数值容差 $\\tau = 10^{-9}$ 的情况下，严格小于混合模型的 AIC，则选择分离模型（输出 $1$）。即，如果 $\\mathrm{AIC}_{\\text{sep}}  \\mathrm{AIC}_{\\text{pool}} - \\tau$。否则，选择混合模型（输出 $0$），这包括 AIC 值几乎相等的情况。\n\n对每个数据集，算法流程如下：\n1.  计算混合模型的参数 $k_{\\text{pool}}$、$\\hat{\\sigma}^2_{\\text{pool}}$、$\\log L_{\\text{pool}}$ 和 $\\mathrm{AIC}_{\\text{pool}}$。\n2.  检查类别不平衡的边缘情况。如果一个类别缺失，则设置 $k_{\\text{sep}} = k_{\\text{pool}}$ 和 $\\mathrm{AIC}_{\\text{sep}} = \\mathrm{AIC}_{\\text{pool}}$。\n3.  如果两个类别都存在，计算分离模型的参数 $k_{\\text{sep}}$、$\\hat{\\sigma}^2_{\\text{sep}}$、$\\log L_{\\text{sep}}$ 和 $\\mathrm{AIC}_{\\text{sep}}$。\n4.  使用指定的容差和决策规则比较 $\\mathrm{AIC}_{\\text{sep}}$ 和 $\\mathrm{AIC}_{\\text{pool}}$，以确定结果（$0$ 或 $1$）。\n将此过程应用于所有三个数据集，以生成最终输出。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the model comparison problem for the three specified datasets.\n    \"\"\"\n    \n    # Define the datasets as per the problem statement.\n    test_cases = [\n        # Dataset #1: Expected to favor the separating model.\n        {\n            \"s\": np.array([9.8, 10.5, 10.2, 11.0, 9.7, 4.8, 5.1, 5.5, 6.0, 4.9]),\n            \"q\": np.array([1, 1, 1, 1, 1, 0, 0, 0, 0, 0]),\n        },\n        # Dataset #2: Expected to favor the pooling model.\n        {\n            \"s\": np.array([6.8, 7.1, 7.0, 7.3, 6.9, 7.2, 6.7, 7.4, 6.8, 7.0]),\n            \"q\": np.array([1, 1, 1, 1, 1, 0, 0, 0, 0, 0]),\n        },\n        # Dataset #3: Imbalanced edge case.\n        {\n            \"s\": np.array([7.9, 8.1, 8.2, 8.0, 7.8, 8.3, 8.1, 8.0, 7.7, 8.05]),\n            \"q\": np.array([1, 1, 1, 1, 1, 1, 1, 1, 1, 0]),\n        },\n    ]\n\n    results = []\n    for case in test_cases:\n        s_data = case[\"s\"]\n        q_data = case[\"q\"]\n        result = _compare_models(s_data, q_data)\n        results.append(result)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\ndef _calculate_aic(n, k, sigma2_hat):\n    \"\"\"\n    Calculates the Akaike Information Criterion (AIC).\n\n    Args:\n        n (int): Number of observations.\n        k (int): Number of free parameters in the model.\n        sigma2_hat (float): Maximum likelihood estimate of the variance.\n\n    Returns:\n        float: The calculated AIC value.\n    \"\"\"\n    # Numerical stability constant as specified.\n    epsilon = 1e-12\n    if sigma2_hat = 0.0:\n        sigma2_hat = epsilon\n\n    # Maximized log-likelihood for a Gaussian model.\n    # logL = -n/2 * (log(2*pi) + 1 + log(sigma^2_hat))\n    logL = -n / 2.0 * (np.log(2 * np.pi) + 1.0 + np.log(sigma2_hat))\n    \n    # AIC = 2k - 2*logL\n    aic = 2 * k - 2 * logL\n    return aic\n\ndef _compare_models(s, q):\n    \"\"\"\n    Performs AIC-based model comparison between a pooling and a separating model.\n\n    Args:\n        s (np.ndarray): Array of signal magnitudes.\n        q (np.ndarray): Array of quality labels (0 or 1).\n\n    Returns:\n        int: 1 if the separating model is better, 0 otherwise.\n    \"\"\"\n    n = len(s)\n    tau = 1e-9  # Tie-breaking tolerance\n\n    # --- Pooling Model ---\n    # Parameters: mu, sigma^2 (k=2)\n    k_pool = 2\n    # MLE for variance is the population variance (ddof=0).\n    sigma2_hat_pool = np.var(s)\n    aic_pool = _calculate_aic(n, k_pool, sigma2_hat_pool)\n\n    # --- Separating Model ---\n    # Parameters: mu_0, mu_1, sigma^2 (k=3)\n    s_group0 = s[q == 0]\n    s_group1 = s[q == 1]\n    \n    n0 = len(s_group0)\n    n1 = len(s_group1)\n\n    # Handle edge case where one class is absent.\n    if n0 == 0 or n1 == 0:\n        # Separating model is identical to pooling model.\n        k_sep = 2\n        aic_sep = _calculate_aic(n, k_sep, sigma2_hat_pool)\n    else:\n        # Standard case with both classes present.\n        k_sep = 3\n        \n        # MLEs for group means.\n        mu0_hat = np.mean(s_group0)\n        mu1_hat = np.mean(s_group1)\n        \n        # Sum of squared residuals for each group.\n        ssr0 = np.sum((s_group0 - mu0_hat)**2)\n        ssr1 = np.sum((s_group1 - mu1_hat)**2)\n        \n        # MLE for shared variance.\n        sigma2_hat_sep = (ssr0 + ssr1) / n\n        aic_sep = _calculate_aic(n, k_sep, sigma2_hat_sep)\n\n    # --- Comparison ---\n    # Choose separating model if its AIC is strictly lower, considering tolerance.\n    if aic_sep  aic_pool - tau:\n        return 1\n    else: # Favor pooling model in case of tie or if it's better.\n        return 0\n\nif __name__ == \"__main__\":\n    solve()\n```", "id": "2726630"}]}