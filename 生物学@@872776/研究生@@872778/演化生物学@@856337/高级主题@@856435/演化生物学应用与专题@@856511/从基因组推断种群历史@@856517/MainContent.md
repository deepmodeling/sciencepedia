## 引言
了解一个物种的群体动态历史——其有效群体大小的波动、扩张与瓶颈——是理解其[演化潜力](@entry_id:200131)和适应性过程的基础。现代[基因组学](@entry_id:138123)技术为我们提供了前所未有的海量数据，其中蕴藏着追溯这些历史事件的丰富线索。然而，基因组序列中的变异模式与群体历史之间的关系并非一目了然。从复杂的遗传数据中准确解读出人口历史的轨迹，需要依赖于精密的统计推断模型。本文章旨在填补理论知识与实际应用之间的鸿沟，系统性地阐述从基因组数据推断群体动态历史的核心方法论。

通过本文的学习，读者将能够掌握这一领域的关键知识。第一章“原理与机制”将深入剖析合并理论的数学基础，并解释PSMC等现代推断方法是如何建立在这些原理之上的。第二章“应用与跨学科连接”将展示这些方法在解决[演化生物学](@entry_id:145480)、人类学和保护生物学等领域的实际问题中的强大能力，并探讨如何应对自然选择等混淆因素的挑战。最后，第三章“动手实践”将通过具体问题，巩固理论知识并培养解决实际问题的技能。现在，让我们从构建整个推断框架的基石——合并理论的原理与机制开始。

## 原理与机制

本章旨在深入探讨从基因组数据推断群体动态历史背后的核心原理与机制。我们将从合并理论的基本概念出发，逐步构建起理解现代推断方法（如Skyline图和顺序马尔可夫合并模型）所需的理论框架。我们将阐明这些方法如何将基因组序列中蕴含的谱系信息转化为对有效群体大小随时间变化的估计，并探讨这些推断所固有的理论局限性和实践中的关键考量。

### 合并理论的基础

合并理论（Coalescent Theory）为我们提供了一个强大的数学框架，用以理解基因样本在[回溯时间](@entry_id:260844)中的祖先关系。与按时间前向模拟整个群体演化的[Wright-Fisher模型](@entry_id:148998)不同，合并理论只关注样本中谱系的祖先关系，从而极大地提高了[计算效率](@entry_id:270255)。这一理论是所有现代基因组人口历史推断方法的地基。

#### 有效群体大小：谱系学视角

在群体遗传学中，我们必须区分两个关键概念：**普查群体大小（census population size, $N$）**和**有效群体大小（effective population size, $N_e$）**。普查群体大小是在某一时间点对群体中个体数量的直接统计，是一个人口学参数。然而，影响基因多样[性的演化](@entry_id:163338)力量，如[遗传漂变](@entry_id:145594)，其强度并非直接由 $N$ 决定。

**有效群体大小 $N_e$** 是一个理论抽象，它被定义为一个理想化的Wright-Fisher群体的规模，该理想群体经历的遗传漂变强度与我们正在研究的实际群体相同。这个理想群体遵循一系列简化假设，包括[随机交配](@entry_id:149892)、世代不重叠、群体大小恒定以及每个个体贡献的后代数目服从泊松分布。在合并理论的语境下，$N_e$ 的定义更为直观：它是一个理想化群体的规模，其谱系合并的速率与实际群体相同。

当一个群体的普查大小随时间变化，记为 $N(t)$ 时，我们常常希望用一个单一的 $N_e$ 值来总结其在一段时间内的整体遗传效应。这个总结性的 $N_e$ 并非简单的算术平均值。[遗传漂变](@entry_id:145594)的影响在[小群](@entry_id:198763)体时期会被不成比例地放大。一个短暂的[种群瓶颈](@entry_id:154577)期对基因多样性的丧失和谱系合并的加速，其效应远超过一个长时间的种[群扩张](@entry_id:195070)期。为了正确反映这一点，有效群体大小被定义为普查群体大小的**谐波平均数（harmonic mean）**。

具体而言，在满足一系列核心假设（包括[随机交配](@entry_id:149892)、[中性演化](@entry_id:172700)、符合[Wright-Fisher模型](@entry_id:148998)的繁殖成功率[方差](@entry_id:200758)）的前提下，一个时间段内成对谱系的合并总概率，等同于一个大小恒为 $N_e$ 的理想群体在相同时间段内的合并总概率。这导出了以下关系 [@problem_id:2700359]：

$$
\frac{1}{N_e} = \frac{1}{T} \int_0^T \frac{1}{N(t)} dt
$$

这里，$T$ 是所考虑的时间区间的总长度。从这个公式可以看出，$1/N_e$ 是 $1/N(t)$ 的[时间平均](@entry_id:267915)值。由于谐波平均数由较小的数值主导，因此群体历史中的瓶颈期（$N(t)$ 较小）对长期有效群体大小的贡献最大。这一定义是理解所有基于合并理论的推断方法输出结果的关键，因为它们估计的是 $N_e(t)$，而非 $N(t)$。[种群结构](@entry_id:148599)、选择或高度倾斜的繁殖成功率等因素都会使 $N_e$ 与 $N$ 的关系变得更加复杂。

#### 合并过程：速率与等待时间

合并理论的核心是描述 $k$ 个谱系样本在回溯过程中如何合并成一个共同祖先。在一个大小为 $N_e$ 的理想[二倍体](@entry_id:268054)群体中，考虑任意两个谱系。在上一代，它们各自从 $2N_e$ 个亲本基因拷贝中[随机抽样](@entry_id:175193)。它们选择同一个亲本基因拷贝（即发生合并）的概率是 $1/(2N_e)$。

当样本中有 $k$ 个谱系时，共有 $\binom{k}{2}$ 个可能的谱系对。在群体规模 $N_e$ 很大的极限下，我们可以忽略在同一代发生两次或以上独立合并事件的极小概率。因此，在任何一代中发生一次合并事件的总概率（或称瞬时风险）是所有谱系对的合并概率之和 [@problem_id:2700389]：

$$
\lambda_k = \binom{k}{2} \frac{1}{2N_e}
$$

这里的下标 $k$ 表示当前存在的谱系数量。这个公式揭示了一个关键性质：合并速率与谱系数量的平方成正比。随着谱系不断合并、数量减少，合并过程会逐渐放慢。

在时间尺度被恰当缩放（例如，以 $2N_e$ 代为单位）且 $N_e$ 趋于无穷大的连续时间极限下，即所谓的**金曼合并过程（Kingman's coalescent）**，等待下一个合并事件发生的时间 $T_k$ 服从一个指数分布，其速[率参数](@entry_id:265473)为 $\lambda_k$。换句话说，从拥有 $k$ 个谱系到剩下 $k-1$ 个谱系的[期望等待时间](@entry_id:274249)是 $1/\lambda_k = 2N_e / \binom{k}{2}$ 代。

这种“谱系数量依赖的合并速率”和“指数分布的等待时间”是构建Skyline图等非[参数化](@entry_id:272587)推断方法的基础。这些方法正是通过分析谱系树中各个合并区间（inter-coalescent intervals）的长度，来反推在那个历史时期，与观测到的等待时间相符的有效群体大小 $N_e(t)$。

#### 漂变与合并：前向与后向过程的对偶性

合并速率与有效群体大小成反比的关系（$\lambda \propto 1/N_e$）是整个推断框架的基石。除了上述基于抽样概率的直观推导，我们还可以从一个更深刻的理论角度——前向与后向时间过程的对偶性——来理解它。

我们可以考虑一个[等位基因频率](@entry_id:146872) $X_t$ 在群体中随时间前向演化的[随机过程](@entry_id:159502)。在[中性演化](@entry_id:172700)下，其变化仅由遗传漂变驱动。在**[扩散近似](@entry_id:147930)（diffusion approximation）**下，[等位基因频率](@entry_id:146872)的演化可以用一个[随机微分方程](@entry_id:146618)来描述。对于一个中性的、[随机交配](@entry_id:149892)的二倍体群体，其 infinitesimal variance（无穷小[方差](@entry_id:200758)）与 $X_t(1-X_t)$ 成正比，与 $2N_e(t)$ 成反比。这反映了漂变的强度：群体越小，随机频率波动越大。

群体中的**[期望杂合度](@entry_id:204049)（expected heterozygosity）**，即随机抽取两个等位基因为不同类型的概率，在频率为 $X_t$ 时等于 $2X_t(1-X_t)$。利用[扩散](@entry_id:141445)理论的数学工具（[无穷小生成元](@entry_id:270424)），可以推导出[期望杂合度](@entry_id:204049)随时间衰减的速率 [@problem_id:2700411]。其变化率满足如下[微分方程](@entry_id:264184)：

$$
\frac{d}{dt}\mathbb{E}[2X_t(1-X_t)] = -\frac{1}{2N_e(t)}\mathbb{E}[2X_t(1-X_t)]
$$

这个方程的含义是，[期望杂合度](@entry_id:204049)由于遗传漂变而衰减，其瞬时衰减速率恰好是 $1/(2N_e(t))$。

现在，我们从后向时间的合并视角来看。从群体中随机抽取两个谱系，它们在时间 $t$ 之前尚未合并的概率，就等于它们在时间 $t$ 时不是“血脉同源”（identical by descent）的概率。这个概率的动态演化，与前向时间中[期望杂合度](@entry_id:204049)的衰减过程，是完全对偶的。因此，两个谱系在时间 $t$ 尚未合并的概率，也以 $1/(2N_e(t))$ 的速率衰减。这个衰减速率，根据定义，就是成对谱系的**瞬时合并风险（instantaneous coalescent hazard）**。

$$
\lambda_2(t) = \frac{1}{2N_e(t)}
$$

这种对偶性优雅地证明了，驱动等位基因频率随机波动的力量（漂变）和驱动谱系回溯合并的力量，本质上是同一枚硬币的两面，它们的强度都由 $1/N_e(t)$ 来量化。

### 推断方法的建模策略

在建立了合并谱系与有效群体大小之间的定量关系后，下一个问题是如何利用这一关系从基因数据中反推 $N_e(t)$ 的轨迹。不同的推断方法采用了不同的建模策略来表示未知的函数 $N_e(t)$。

#### [参数化](@entry_id:272587)与非参数化方法

对 $N_e(t)$ 的建模大致可分为两大流派：**参数化模型（parametric models）**和**非[参数化](@entry_id:272587)模型（nonparametric models）**。

**[参数化](@entry_id:272587)模型**假定 $N_e(t)$ 的历史轨迹遵循一个预先设定的、由少量参数（记为向量 $\theta$）描述的数学函数。例如，一个常见的模型是[指数增长模型](@entry_id:269008)，$N_e(t) = N_0 \exp(rt)$，其中参数 $\theta = (N_0, r)$ 分别代表当前有效群体大小和增长率。这类模型的优点是简洁、易于解释，且统计功效较高。然而，它们的巨大缺点是模型刚性：如果真实的群体历史（例如，一次瓶颈后紧随扩张）与预设的函数形式不符，推断结果将会产生严重的系统性偏差。

相比之下，**非[参数化](@entry_id:272587)方法**（在群体遗传学背景下，常指代高度灵活的模型，如skyline图）不假定 $N_e(t)$ 的特定函数形式，而是将其近似为一个[分段函数](@entry_id:160275)，通常是**分段[常数函数](@entry_id:152060)（piecewise-constant function）**。这种模型由许多参数（每个片段的高度）组成，允许它拟合更复杂的动态历史。例如，**贝叶斯Skyline图（Bayesian Skyline Plot, BSP）**就是此类方法的典型代表 [@problem_id:2700417]。这类方法的优势在于其灵活性，能够发现未预料到的群体历史模式。其代价是需要更多的数据来可靠地估计数量众多的参数，并且更容易出现过拟合。

#### Skyline图谱：正则化与平滑

Skyline系列方法的核心思想是，合并谱系中相邻合并事件之间的时间间隔（inter-coalescent interval）包含了关于该时期 $N_e$ 的信息：长间隔意味着大 $N_e$，短间隔意味着小 $N_e$。然而，从有限的、充满随机性的谱系数据中直接恢复一个[连续函数](@entry_id:137361) $N_e(t)$ 是一个统计学上所谓的**病态[反问题](@entry_id:143129)（ill-posed inverse problem）** [@problem_id:2700386]。

从数学上看，将 $N_e(t)$ 映射到合并时间[分布](@entry_id:182848)的算子是一个积分算子，它具有平滑效应。反向操作，即从数据反推 $N_e(t)$，则类似于[微分](@entry_id:158718)，会极大地放大数据中的噪声，导致解极其不稳定。因此，任何稳健的非参数化推断都必须引入某种形式的**正则化（regularization）**，即对解的复杂性或“粗糙度”施加约束，以牺牲一定的偏差（bias）为代价来换取[方差](@entry_id:200758)（variance）的降低。

不同的Skyline方法可以被理解为采用了不同的正则化策略 [@problem_id:2700450]：

*   **经典Skyline图（Classical Skyline Plot）**：此方法为每个合并[区间估计](@entry_id:177880)一个独立的 $N_e$ 值。这相当于不施加任何正则化，导致参数数量与样本大小成正比。结果是一条非常“嘈杂”的 $N_e(t)$ 曲线，[方差](@entry_id:200758)极大，容易过拟合。

*   **贝叶斯Skyline图（BSP）**：BSP通过将相邻的合并区间“分组”并为每组估计一个共同的 $N_e$ 值来进行正则化。这是一种**投影正则化**，它将无限维的函数空间投影到一个低维的分段常数函数空间上。通过贝叶斯框架，分组方式和每组的 $N_e$ 值都可以从数据中推断。这在降低[方差](@entry_id:200758)的同时，也引入了偏差，因为它无法分辨组内的群体大小波动 [@problem_id:2700386, @problem_id:2700417]。

*   **Skyride/Skygrid模型**：这类模型采用了一种更精细的**平滑先验（smoothing prior）**作为正则化。例如，它们可能在离散时间点上的 $\log(N_e(t))$ 值上施加一个[高斯马尔可夫随机场](@entry_id:749746)（Gaussian Markov Random Field, GMRF）先验。这种先验会惩罚相邻时间点上 $N_e$ 值的剧烈变化，从而产生一条更平滑的轨迹。这类似于经典的**[吉洪诺夫正则化](@entry_id:140094)（Tikhonov regularization）**，通过惩罚解的导数来抑制高频[振荡](@entry_id:267781) [@problem_id:2700386, @problem_id:2700450]。

### 基于重组的基因组尺度推断

Skyline图最初是为单个非重组位点（如线粒体DNA）设计的。为了将合并理论的威力应用到全基因组数据，我们必须处理遗传重组。

#### [祖先重组图](@entry_id:189125)与顺序马尔可夫合并模型

当考虑一个发生重组的[染色体](@entry_id:276543)区域时，单个谱系树已不足以描述其完整的祖先历史。取而代之的是一个更为复杂的结构，称为**[祖先重组图](@entry_id:189125)（Ancestral Recombination Graph, ARG）**。ARG是一个同时包含了合并事件（谱系分叉点向下，朝向过去）和重组事件（谱系[分叉](@entry_id:270606)点向上，朝向过去）的图。沿着[染色体](@entry_id:276543)，每个位点的谱系树都是ARG的一个局部横切面。

一个关键的理论要点是，沿着[染色体](@entry_id:276543)位置 $x$ 的局部谱系树序列 $\{G(x)\}$，在真实的ARG下，并**不是**一个[马尔可夫过程](@entry_id:160396)。这是因为，当一个重组事件发生后，分离出的谱系片段将重新合并到ARG的某个分支上，而这个分支的选择取决于ARG在那个时间点的**全局**结构，而不仅仅是当前局部谱系树 $G(x)$ 的信息。这种“[长程依赖](@entry_id:181727)”使得对完整的ARG进行[似然](@entry_id:167119)计算在计算上极其困难。

为了克服这一障碍，**顺序马尔可夫合并模型（Sequentially Markovian Coalescent, SMC）**被提出。SMC是一个强大的近似，它强制假定局部谱系树序列 $\{G(x)\}$ 是一个沿着[染色体](@entry_id:276543)位置的一阶[马尔可夫过程](@entry_id:160396)。在这个近似下，当重组发生时，谱系片段的重新合并只依赖于当前的局部谱系树 $G(x)$，而“忘记”了更远位置的谱系历史。这种简化大大降低了计算复杂度，并为构建隐马尔可夫模型（HMM）铺平了道路 [@problem_id:2700398]。

#### 成对顺序马尔可夫合并模型 (PSMC)

**PSMC**是SMC框架下最著名和最早的应用之一，它专门用于分析单个二倍体个体的基因组。它实际上是在分析该个体两条同源[染色体](@entry_id:276543)（两个单倍型，$k=2$）的祖先历史。

PSMC的核心是一个**[隐马尔可夫模型](@entry_id:141989)（Hidden Markov Model, HMM）**。在这个模型中：

*   **隐状态**：沿着基因组的每个位置，其“隐状态”是该位置两条谱系**最近公共祖先的时间（Time to Most Recent Common Ancestor, [TMRCA](@entry_id:174926)）**。为了使模型可计算，连续的[TMRCA](@entry_id:174926)被离散化成若干个时间区间。
*   **转移**：从一个位置到下一个位置，隐状态（[TMRCA](@entry_id:174926)）的改变是由重组事件驱动的。PSMC采用了一种被称为**SMC'**的近似。在此模型下，当重组以与[TMRCA](@entry_id:174926)成正比的速率发生时，谱系树上会发生一次“切割与重连”。切[割点](@entry_id:637448) $u$ 在 $[0, T)$ 的谱系分支上均匀选取。之后，被切断的谱系向前（朝向现在）重新寻找合并对象。重要的是，SMC'允许它与原先的伙伴谱系重新合并，这导致[TMRCA](@entry_id:174926)有一定概率保持不变（$T' = T$）。它也可以与另一个谱系合并，产生一个新的[TMRCA](@entry_id:174926) $T'$，这个$T'$可能比$T$小，也可能比$T$大。这导致HMM的转移矩阵不仅有非零的对角线元素（自转移），还允许在非相邻的状态间跳跃 [@problem_id:2700418]。
*   **发射**：在给定的[TMRCA](@entry_id:174926) $T$ 下，该基因组片段上预期积累的突变数量与 $2\mu T$ 成正比（$\mu$是突变率）。因此，观测到的杂合位点密度（即HMM的“发射概率”）提供了关于[TMRCA](@entry_id:174926)的直接信息 [@problem_id:2700398]。

通过拟合这个HMM，PSMC可以解码出沿着基因组最可能的[TMRCA](@entry_id:174926)序列，并最终推断出与该[TMRCA](@entry_id:174926)[分布](@entry_id:182848)相符的分段常数 $N_e(t)$ 轨迹。

#### 超越成对：MSMC 与 SMC++

PSMC ($k=2$) 对于远古时期的 $N_e$ 分辨率较高，但在近期历史的推断上能力有限，因为两个谱系在近期发生合并的事件非常稀少。为了解决这个问题，后续方法扩展到了多个单倍型（$k>2$）。

当使用 $k$ 个单倍型时，总的合并速率约为 $\binom{k}{2}/(2N_e(t))$，比成对情况快得多。这意味着在近期，发生**第一次合并**的概率大大增加，从而为推断近期的 $N_e(t)$ 提供了更多信息。

*   **MSMC (Multiple Sequentially Markovian Coalescent)** 明确地利用了这一点，它构建了一个HMM来模拟 $k$ 个单倍型中**第一次合并事件的时间**在基因组上如何变化。

*   **SMC++** 则采用了不同的策略，它通过一种巧妙的**复合似然（composite likelihood）**方法，使得能够利用大量（甚至是未定相的）基因组数据，同时在计算上保持可行。

引入多个单倍型也带来了新的挑战。在任何一个基因组位置，所有 $\binom{k}{2}$ 个谱系对的[TMRCA](@entry_id:174926)都源于同一个局部谱系树，因此它们是高度相关的，不能被当作独立观测。MSMC通过只关注第一次合并来回避对完整谱系树的建模。SMC++则通过其复合似然框架，在 tractability 和对依赖性的精确建模之间做出权衡 [@problem_id:2700388]。

### 模型的局限与实践考量

#### [偏差-方差权衡](@entry_id:138822)与[模型选择](@entry_id:155601)

在使用如BSP或PSMC等分段常数模型时，一个核心的实践问题是如何选择“片段”的数量（在BSP中是分组数 $m$，在PSMC中是时间区间数 $T$）。这个选择体现了统计学中一个经典的**偏差-方差权衡（bias-variance trade-off）** [@problem_id:2700446]。

*   **低 $m$ 或 $T$**：使用较少的片段意味着模型非常“僵硬”。它无法捕捉 $N_e(t)$ 的快速波动，从而可能产生高**偏差**（系统性地偏离真相，即[欠拟合](@entry_id:634904)）。但由于每个参数都由大量数据（合并或重组事件）支持，其估计值的**[方差](@entry_id:200758)**会较低，结果较为稳定。
*   **高 $m$ 或 $T$**：使用更多的片段使模型非常灵活，能够拟合更精细的 $N_e(t)$ 曲线，从而降低偏差。然而，每个参数现在只由少量数据支持，导致估计值对数据的随机性极为敏感，[方差](@entry_id:200758)剧增，容易出现**[过拟合](@entry_id:139093)**（模型拟合了数据中的噪声而非真实信号）。

必须认识到，推断的分辨率存在一个根本极限，这个极限由数据中信息事件（合并、重组）的密度决定。即使将模型参数设得再多，我们也无法分辨在两个连续的合并事件之间发生的群体大小变化。试图这样做只会增加[方差](@entry_id:200758)，而不能有意义地减少偏差 [@problem_id:2700446]。

在贝叶斯框架下，这个问题可以通过**[模型选择](@entry_id:155601)**或**[模型平均](@entry_id:635177)**来解决。例如，可以通过计算不同 $m$ 值的模型的**[边际似然](@entry_id:636856)（marginal likelihood）**并比较**[贝叶斯因子](@entry_id:143567)（Bayes factors）**来选择最优模型。[边际似然](@entry_id:636856)内在地惩罚了不必要的[模型复杂度](@entry_id:145563)（一种“[贝叶斯奥卡姆剃刀](@entry_id:196552)”效应）。更先进的方法，如使用**[可逆跳转马尔可夫链蒙特卡洛](@entry_id:754338)（[RJMCMC](@entry_id:754374)）**，可以对 $m$ 本身进行采样，从而在所有可能的[模型复杂度](@entry_id:145563)上进行**[贝叶斯模型平均](@entry_id:168960)**，避免了依赖于对 $m$ 的单一先验选择 [@problem_id:2700446]。