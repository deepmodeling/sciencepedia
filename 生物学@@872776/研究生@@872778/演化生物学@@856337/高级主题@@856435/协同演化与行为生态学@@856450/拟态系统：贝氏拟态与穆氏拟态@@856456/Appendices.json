{"hands_on_practices": [{"introduction": "拟态的成功与否通常取决于其在种群中的相对频率。本练习利用演化博弈论的基石——复制子方程（replicator equation），来模拟这种频率依赖性选择。通过求解该模型 [@problem_id:2734496]，你将深入理解在贝氏拟态系统中，模型（model）的防御成本与模拟者（mimic）被捕食的风险之间如何相互作用，从而决定模拟者是被淘汰、达到稳定共存，还是最终“淹没”整个警戒色信号系统。", "problem": "警戒色猎物通常会形成警戒信号复合体，其中有防御的模型有时会伴随着无防御的拟态者。考虑一个充分混合的捕食者-猎物环境，其中有两种警戒信号携带者：有防御的模型（$T$ 型）和无防御的拟态者（$M$ 型）。令 $q \\in [0,1]$ 表示信号携带者中拟态者的频率。捕食者攻击警戒信号携带者的概率为 $A(q)$，该概率取决于信号的可靠性；假设其为线性形式 $A(q) = a_0 + a_1 q$，其中 $0 \\leq a_0 \\leq 1$，且 $a_1$ 使得对于所有 $q \\in [0,1]$ 都有 $0 \\leq A(q) \\leq 1$。$a_1$ 的符号代表了生态学机制：$a_1  0$ 对应于贝氏拟态条件（更多的拟态者稀释了信号，增加了对警戒信号的攻击），而 $a_1  0$ 对应于缪勒式拟态条件（更大部分的诚实信号发送者减少了对警戒信号的攻击）。假设模型由于产生毒素而付出固定成本 $s \\in [0,1]$，这会降低它们的基础适应度，且与攻击无关；而拟态者不支付此成本，但在被攻击时会完全死亡。\n\n绝对适应度如下：拟态者为 $W_m(q) = 1 - A(q)$，模型为 $W_t = 1 - s$。设平均适应度为 $\\bar{W}(q) = q W_m(q) + (1 - q) W_t$。频率 $q$ 根据复制子动态常微分方程 (ODE) $\\dot{q} = q \\big(W_m(q) - \\bar{W}(q)\\big)$ 演化。\n\n从这些假设和复制子动态常微分方程的定义出发，推导 $q$ 的一维选择梯度，并分析所有平衡点的局部稳定性。确定参数 $a_0$、$a_1$ 和 $s$ 的条件，在这些条件下，选择会驱动拟态者达到低频率（边界灭绝）、固定，或稳定的多态频率。最后，报告内部平衡频率 $q^{\\ast}$（如果存在）作为 $a_0$、$a_1$ 和 $s$ 的函数的闭合形式解析表达式。最终答案必须是 $q^{\\ast}$ 的单个闭合形式表达式。无需四舍五入，也无需单位，因为所有量都是无量纲的概率或频率。", "solution": "所提出的问题是数理演化生物学中的一个标准练习。该问题是自洽的，其科学基础在于频率依赖性选择和复制子动态的原理，并且问题的提出足够清晰和严谨，能够得出一个唯一的、有意义的解。因此，该问题被认为是有效的。我们开始进行推导。\n\n拟态者频率 $q$ 的动态由复制子方程控制：\n$$ \\dot{q} = q \\big(W_m(q) - \\bar{W}(q)\\big) $$\n其中 $W_m(q)$ 是拟态者的适应度，$\\bar{W}(q)$ 是信号携带者种群的平均适应度。平均适应度定义为 $\\bar{W}(q) = q W_m(q) + (1 - q) W_t$，其中 $W_t$ 是有防御模型的适应度。\n\n首先，我们展开选择梯度项 $W_m(q) - \\bar{W}(q)$：\n$$ W_m(q) - \\bar{W}(q) = W_m(q) - \\big(q W_m(q) + (1 - q) W_t\\big) = (1 - q) W_m(q) - (1 - q) W_t = (1 - q) \\big(W_m(q) - W_t\\big) $$\n将其代回复制子方程，得到一个更清晰的形式：\n$$ \\dot{q} = q(1 - q) \\big(W_m(q) - W_t\\big) $$\n项 $S(q) = W_m(q) - W_t$ 代表在当前种群构成 $q$ 的情况下，拟态者相对于模型的适应度优势。这是一维选择梯度，它驱动了 $q \\in (0,1)$ 频率的变化。\n\n接下来，我们将指定的适应度函数代入 $S(q)$ 的表达式中。拟态者的适应度为 $W_m(q) = 1 - A(q)$，其中攻击概率为 $A(q) = a_0 + a_1 q$。模型的适应度为 $W_t = 1 - s$。\n$$ S(q) = W_m(q) - W_t = \\big(1 - (a_0 + a_1 q)\\big) - (1 - s) = 1 - a_0 - a_1 q - 1 + s = s - a_0 - a_1 q $$\n因此，拟态者频率的完整常微分方程为：\n$$ \\dot{q} = q(1 - q)(s - a_0 - a_1 q) $$\n该系统的平衡点，记为 $q^{\\ast}$，是使 $\\dot{q} = 0$ 的 $q$ 值。从该方程中，我们可以确定三个潜在的平衡点：\n1.  边界平衡点 $q^{\\ast} = 0$，对应拟态者的灭绝。\n2.  边界平衡点 $q^{\\ast} = 1$，对应拟态者的固定。\n3.  任何内部平衡点 $q^{\\ast} \\in (0,1)$，它是线性项 $s - a_0 - a_1 q^{\\ast} = 0$ 的根。\n\n主要任务是找到这个内部平衡点 $q^{\\ast}$ 的闭合形式表达式。我们求解方程 $s - a_0 - a_1 q^{\\ast} = 0$ 以得到 $q^{\\ast}$：\n$$ a_1 q^{\\ast} = s - a_0 $$\n假设 $a_1 \\neq 0$，我们可以分离出 $q^{\\ast}$：\n$$ q^{\\ast} = \\frac{s - a_0}{a_1} $$\n这就是内部平衡频率的解析表达式。\n\n为了完整起见，我们分析此平衡点的稳定性和存在条件。令 $f(q) = \\dot{q}$。如果 $f'(q^{\\ast})  0$，则平衡点 $q^{\\ast}$ 是局部稳定的；如果 $f'(q^{\\ast}) > 0$，则是不稳定的。\n导数为 $f'(q) = (1-2q)(s - a_0 - a_1 q) - a_1 q(1 - q)$。\n在内部平衡点 $q^{\\ast} = \\frac{s - a_0}{a_1}$ 处，根据定义，项 $(s - a_0 - a_1 q^{\\ast})$ 为零。因此，导数简化为：\n$$ f'(q^{\\ast}) = - a_1 q^{\\ast}(1 - q^{\\ast}) $$\n要使 $q^{\\ast}$ 成为一个多态平衡点，它必须位于区间 $(0,1)$ 内，这意味着 $q^{\\ast}(1 - q^{\\ast}) > 0$。因此，内部平衡点的稳定性仅取决于 $a_1$ 的符号：\n-   如果 $a_1 > 0$ (贝氏拟态)，则 $f'(q^{\\ast})  0$，内部平衡点是 **稳定的**。这对应于负频率依赖性选择，即拟态者的适应度随着其频率的增加而降低。如果拟态者在稀有时具有优势（$W_m(0) > W_t \\implies s > a_0$），但在普遍时处于劣势（$W_m(1)  W_t \\implies s  a_0 + a_1$），则可能出现稳定的多态性。这些条件，$a_0  s  a_0 + a_1$，确保了 $0  q^{\\ast}  1$。\n-   如果 $a_1  0$ (缪勒式拟态条件)，则 $f'(q^{\\ast}) > 0$，内部平衡点是 **不稳定的**。这对应于正频率依赖性选择，即拟态者的适应度随着其频率的增加而增加。这样的系统会导致双稳态，种群会根据初始频率相对于不稳定平衡点 $q^{\\ast}$ 的位置，收敛到拟态者灭绝（$q=0$）或固定（$q=1$）。该内部平衡点存在于 $(0,1)$ 内的条件是 $a_0+a_1  s  a_0$。\n\n具体问题只要求内部平衡频率 $q^{\\ast}$ 的闭合形式解析表达式。这个表达式已在上面推导出。", "answer": "$$\n\\boxed{\\frac{s - a_0}{a_1}}\n$$", "id": "2734496"}, {"introduction": "在真实的生态系统中，捕食者的学习和遗忘过程并非是线性的。本练习建立在一个更符合实际的假设之上：捕食者对警戒信号的回避行为会随着与有毒猎物的相遇而饱和。通过构建一个捕食者学习饱和模型 [@problem_id:2734461]，你将推导出警戒色策略从有利变为不利的拟态者频率临界值，这个练习揭示了一个重要的生态学原理：一个在特定条件下有利的演化策略，可能会在跨越一个“引爆点”后突然变得无效。", "problem": "一种有防御能力的猎物（“模型”）面临着频率依赖性捕食，因为可食的“贝氏”拟态者稀释了其警戒色警告信号的可靠性。假设以下最简化的、符合生物学标准的要素。\n\n- 设贝氏拟态者在具警戒色猎物中的相对频率为 $q \\ge 0$，因此警告信号的可靠性（真正有防御能力的警戒色携带者所占的比例）为 $\\rho(q) = \\frac{1}{1+q}$。\n\n- 捕食者对警告信号的回避行为会随着与有防御能力猎物相遇所产生的厌恶性刺激而饱和。通过假设捕食者攻击具警戒色猎物个体的概率为 $A(q) = \\frac{1}{1 + \\lambda \\rho(q)}$ 来对此饱和现象进行建模，其中 $\\lambda  0$ 是一个学习强度参数，它综合了相遇率、记忆以及每次攻击有防御能力猎物所带来的厌恶体验强度。\n\n- 如果模型个体带有警告信号，每次攻击会给该个体带来期望为 $c_m \\in (0,1]$ 的适应度损失。如果模型采用另一种隐蔽色图案，捕食者不会从其外表学会回避它；假设它们以一个恒定的基线概率 $a_0 \\in (0,1)$ 进行攻击，且每次此类攻击会给隐蔽色个体带来期望为 $c_c \\in (0,1]$ 的适应度损失。\n\n- 设两种策略的每代基线适应度（在没有捕食的情况下）均定标为 $1$，因此捕食通过期望攻击损失以乘法方式降低适应度。\n\n假设参数满足 $c_m  a_0 c_c$，这确保了当警告信号完全可靠时，警戒色是有利的。定义当拟态者频率为 $q$ 时，具警戒色模型个体的适应度为 $W_m(q) = 1 - c_m A(q)$，隐蔽色模型个体的适应度为 $W_c = 1 - a_0 c_c$。\n\n请从第一性原理出发，证明存在一个临界拟态频率 $q_c$，使得对于所有 $q  q_c$，具警戒色模型的适应度低于隐蔽色替代方案，并用 $\\lambda$、$c_m$、$c_c$ 和 $a_0$ 表示 $q_c$。您的最终答案必须是 $q_c$ 的单个封闭形式表达式，不带单位。请勿近似或四舍五入；请提供精确的符号表达式。", "solution": "问题陈述具有科学依据、问题设定良好、客观且自洽。所提供的参数和函数形式代表了贝氏拟态系统中频率依赖性选择的一个标准且逻辑一致的模型。这些假设足以推导出一个唯一且有意义的解。因此，我们将按要求进行推导。\n\n任务是找到一个临界拟态频率，我们记为 $q_c$，在该频率下，具警戒色模型个体的适应度 $W_m(q)$ 变得小于隐蔽色模型个体的适应度 $W_c$。该临界频率被定义为两种适应度值相等的点。对于所有大于 $q_c$ 的拟态频率 $q$，警戒策略必定不如隐蔽策略有利。\n\n适应度函数给出如下：\n$$W_m(q) = 1 - c_m A(q)$$\n$$W_c = 1 - a_0 c_c$$\n其中 $W_c$ 相对于拟态频率 $q$ 是一个常数。\n\n临界频率 $q_c$ 是满足条件 $W_m(q_c) = W_c$ 的 $q$ 值。将适应度表达式代入此等式，得到：\n$$1 - c_m A(q_c) = 1 - a_0 c_c$$\n这可简化为关于期望适应度损失的条件：\n$$c_m A(q_c) = a_0 c_c$$\n\n问题给出了捕食者攻击概率 $A(q)$ 的表达式：\n$$A(q) = \\frac{1}{1 + \\lambda \\rho(q)}$$\n其中 $\\rho(q) = \\frac{1}{1+q}$ 是警告信号的可靠性。将 $A(q_c)$ 的表达式代入我们的条件，得到：\n$$c_m \\left( \\frac{1}{1 + \\lambda \\rho(q_c)} \\right) = a_0 c_c$$\n\n现在我们必须解这个方程求出 $q_c$。首先，我们求解包含 $\\rho(q_c)$ 的项：\n$$1 + \\lambda \\rho(q_c) = \\frac{c_m}{a_0 c_c}$$\n问题中说明 $c_m  a_0 c_c$，这保证了等式右边大于 $1$。这是一致的，因为由于 $\\lambda  0$ 且 $\\rho(q_c)  0$，等式左边也必须大于 $1$。\n分离出含 $\\rho(q_c)$ 的项：\n$$\\lambda \\rho(q_c) = \\frac{c_m}{a_0 c_c} - 1 = \\frac{c_m - a_0 c_c}{a_0 c_c}$$\n$$\\rho(q_c) = \\frac{1}{\\lambda} \\left( \\frac{c_m - a_0 c_c}{a_0 c_c} \\right)$$\n\n现在，我们代入 $\\rho(q) = \\frac{1}{1+q}$ 的定义：\n$$\\frac{1}{1+q_c} = \\frac{c_m - a_0 c_c}{\\lambda a_0 c_c}$$\n\n为了解出 $q_c$，我们对两边取倒数：\n$$1 + q_c = \\frac{\\lambda a_0 c_c}{c_m - a_0 c_c}$$\n最后，分离出 $q_c$：\n$$q_c = \\frac{\\lambda a_0 c_c}{c_m - a_0 c_c} - 1$$\n为了将它们合并成一个分数，我们找到一个公分母：\n$$q_c = \\frac{\\lambda a_0 c_c - (c_m - a_0 c_c)}{c_m - a_0 c_c}$$\n$$q_c = \\frac{\\lambda a_0 c_c - c_m + a_0 c_c}{c_m - a_0 c_c}$$\n$$q_c = \\frac{a_0 c_c (1 + \\lambda) - c_m}{c_m - a_0 c_c}$$\n\n这个表达式给出了临界拟态频率 $q_c$。为了使 $q_c$ 成为一个物理上有意义的正频率（$q_c  0$），分子也必须为正，因为根据假设，分母 $c_m - a_0 c_c$ 是正的。分子为正的条件是 $a_0 c_c (1 + \\lambda) - c_m  0$，或 $c_m  a_0 c_c (1 + \\lambda)$。这是在 $q=0$ 时警戒色具有优势所必需的条件，因为 $W_m(0)  W_c$ 意味着 $c_m A(0)  a_0 c_c$，即 $c_m \\frac{1}{1+\\lambda}  a_0 c_c$。问题的设定隐含地要求此条件存在，以便有非平凡解。\n\n现在，我们必须证明对于所有 $q  q_c$，具警戒色模型的适应度低于隐蔽色替代方案，即 $W_m(q)  W_c$。这等价于证明警戒色形态的期望适应度损失大于隐蔽色形态的期望适应度损失，即 $c_m A(q)  a_0 c_c$。\n\n让我们分析函数 $A(q)$ 的行为。\n信号可靠性为 $\\rho(q) = \\frac{1}{1+q}$。对于 $q \\ge 0$，$\\rho(q)$ 是 $q$ 的严格递减函数。随着拟态者频率 $q$ 的增加，信号变得不那么可靠。\n攻击概率为 $A(q) = \\frac{1}{1 + \\lambda \\rho(q)}$。由于 $\\lambda  0$ 且 $\\rho(q)$ 是 $q$ 的递减函数，分母 $1 + \\lambda \\rho(q)$ 也是 $q$ 的严格递减函数。因此，其倒数 $A(q)$ 是 $q$ 的严格递增函数。\n这意味着随着拟态频率 $q$ 的增加，捕食者攻击具警戒色个体的概率 $A(q)$ 也会增加。\n\n我们定义 $q_c$ 为期望损失相等的点：$c_m A(q_c) = a_0 c_c$。\n由于 $c_m  0$ 且 $A(q)$ 是 $q$ 的严格递增函数，乘积 $c_m A(q)$ 也是 $q$ 的严格递增函数。\n因此，对于任何 $q  q_c$，必然有：\n$$A(q)  A(q_c)$$\n$$c_m A(q)  c_m A(q_c)$$\n代入 $q_c$ 的定义：\n$$c_m A(q)  a_0 c_c$$\n从基线适应度 $1$ 中减去这个不等式，会反转不等号：\n$$1 - c_m A(q)  1 - a_0 c_c$$\n这恰好是条件：\n$$W_m(q)  W_c$$\n这证实了对于所有大于推导出的临界频率 $q_c$ 的拟态频率 $q$，隐蔽策略比警戒策略产生更高的适应度。在警戒色最初有利但对模型的一次攻击成本高于隐蔽色的期望成本的参数空间中，这样的 $q_c  0$ 的存在是有保证的。", "answer": "$$ \\boxed{\\frac{a_0 c_c (1 + \\lambda) - c_m}{c_m - a_0 c_c}} $$", "id": "2734461"}, {"introduction": "前面的练习关注拟态者在种群中的频率演化，而本练习将视角转向拟态性状本身的演化过程。我们将使用定量遗传学中的兰德方程（Lande's equation），通过计算模拟来追踪一个连续视觉性状的演化轨迹。通过亲手实现这个模型 [@problem_id:2734462]，你将体验到遗传结构（以 $G$ 矩阵为代表）如何与自然选择相互作用，共同塑造表型的演化路径，这为你提供了一个强大的工具，以连接理论模型与可观测的表型变化。", "problem": "考虑一个代表视觉模拟图案的连续数量性状。设该性状为一个向量 $\\mathbf{z} \\in \\mathbb{R}^m$，其在离散时间内根据 Lande 方程演化，\n$$\n\\Delta \\mathbf{z} = \\mathbf{G}\\, \\nabla W(\\mathbf{z}),\n$$\n其中 $\\mathbf{G}$ 是一个恒定的对称半正定遗传方差-协方差矩阵，$W(\\mathbf{z})$ 是绝对适合度。模型点（被防御模型的性状）为 $\\mathbf{z}^\\star \\in \\mathbb{R}^m$。假设捕食者对图案相似性的泛化遵循一个高斯判别函数，定义为\n$$\nc(d) = \\exp(-\\beta d^2), \\quad d = \\|\\mathbf{z} - \\mathbf{z}^\\star\\|_2,\n$$\n其中 $\\beta  0$ 表示判别强度，$\\|\\cdot\\|_2$ 是欧几里得范数。设与警戒图案的相遇会更新捕食者的攻击厌恶程度，其更新量与图案相遇中不美味体验的比例成正比。分别用 $q$ 和 $p$ 表示模型和模拟者的种群频率，用 $u_M \\in [0,1]$ 和 $u_m \\in [0,1]$ 表示模型和模拟者的不美味程度。设 $\\rho \\in (0,1]$ 是通过学习可达到的最大攻击减少量。在这些假设下，定义频率依赖的学习因子\n$$\nR = \\rho \\cdot \\frac{u_M q + u_m p}{q + p}.\n$$\n假设绝对适合度与习得的攻击厌恶和知觉混淆的乘积成正比，因此（在任意正仿射变换下）可以表示为\n$$\nW(\\mathbf{z}) = R \\, c(\\|\\mathbf{z} - \\mathbf{z}^\\star\\|_2).\n$$\n你必须通过从初始状态 $\\mathbf{z}_0$ 开始迭代离散时间的 Lande 更新来计算演化轨迹，保持 $\\mathbf{G}$ 和生态参数不变，直到性状与模型点的欧几里得距离小于一个很小的容差，或者达到最大迭代次数。形式上，迭代\n$$\n\\mathbf{z}_{t+1} = \\mathbf{z}_t + \\mathbf{G}\\, \\nabla W(\\mathbf{z}_t),\n$$\n对于 $t = 0,1,2,\\dots$，并在满足 $\\|\\mathbf{z}_t - \\mathbf{z}^\\star\\|_2 \\le \\varepsilon$ 的最小 $t$ 值处停止，或者如果在 $N_{\\max}$ 次迭代内不存在这样的 $t$，则报告失败。\n\n你的实现应仅基于上述定义以及梯度和范数的标准属性。除这些定义和基础微积分外，不要假设任何额外的公式。对于每个测试用例，你的程序必须返回满足 $\\|\\mathbf{z}_t - \\mathbf{z}^\\star\\|_2 \\le \\varepsilon$ 所需的迭代次数（整数）；如果在 $N_{\\max}$ 次迭代内未达到阈值，则为该测试用例返回整数 $-1$。\n\n对所有测试用例使用以下常量：容差 $\\varepsilon = 10^{-6}$ 和最大迭代次数 $N_{\\max} = 10^5$。以下所有测试用例都使用二维性状（$m = 2$）和模型点 $\\mathbf{z}^\\star = (0,0)$。\n\n实现该算法并评估以下测试套件。每个用例指定了 $(\\mathbf{z}_0, \\mathbf{G}, \\beta, \\rho, p, q, u_M, u_m)$：\n\n- 测试用例 A（贝氏拟态，中度学习）：\n  - $\\mathbf{z}_0 = (1.0, 0.5)$,\n  - $\\mathbf{G} = \\mathrm{diag}(0.02, 0.01)$,\n  - $\\beta = 3.0$, $\\rho = 0.9$,\n  - $p = 0.1$, $q = 0.3$,\n  - $u_M = 1.0$, $u_m = 0.0$.\n\n- 测试用例 B（贝氏拟态，极低遗传方差）：\n  - $\\mathbf{z}_0 = (1.0, 1.0)$,\n  - $\\mathbf{G} = \\mathrm{diag}(10^{-8}, 10^{-8})$,\n  - $\\beta = 3.0$, $\\rho = 0.9$,\n  - $p = 0.7$, $q = 0.3$,\n  - $u_M = 1.0$, $u_m = 0.0$.\n\n- 测试用例 C（缪氏拟态，各向异性协方差）：\n  - $\\mathbf{z}_0 = (2.0, -1.0)$,\n  - $\\mathbf{G} = \\begin{pmatrix}0.02  0.015\\\\ 0.015  0.03\\end{pmatrix}$,\n  - $\\beta = 2.0$, $\\rho = 0.8$,\n  - $p = 0.5$, $q = 0.5$,\n  - $u_M = 1.0$, $u_m = 0.6$.\n\n- 测试用例 D（贝氏拟态，相关响应）：\n  - $\\mathbf{z}_0 = (-1.5, 1.0)$,\n  - $\\mathbf{G} = \\begin{pmatrix}0.01  0.005\\\\ 0.005  0.01\\end{pmatrix}$,\n  - $\\beta = 4.0$, $\\rho = 0.7$,\n  - $p = 0.2$, $q = 0.4$,\n  - $u_M = 1.0$, $u_m = 0.0$.\n\n- 测试用例 E（缪氏拟态，强判别能力）：\n  - $\\mathbf{z}_0 = (3.0, 3.0)$,\n  - $\\mathbf{G} = \\mathrm{diag}(0.005, 0.005)$,\n  - $\\beta = 6.0$, $\\rho = 0.9$,\n  - $p = 0.4$, $q = 0.6$,\n  - $u_M = 1.0$, $u_m = 0.9$.\n\n你的程序应该生成单行输出，其中包含用方括号括起来的逗号分隔的结果列表（例如，“[result_A,result_B,result_C,result_D,result_E]”）。结果必须是如上所述的整数，并按 A 到 E 的顺序排列。", "solution": "该问题要求模拟在频率依赖选择下多变量性状的演化，该过程由 Lande 的离散时间方程描述。其生物学背景是模拟者视觉图案 $\\mathbf{z} \\in \\mathbb{R}^m$ 向被防御模型生物图案 $\\mathbf{z}^\\star \\in \\mathbb{R}^m$ 的演化。演化轨迹通过迭代以下方程确定\n$$\n\\mathbf{z}_{t+1} = \\mathbf{z}_t + \\mathbf{G}\\, \\nabla W(\\mathbf{z}_t)\n$$\n其中 $\\mathbf{z}_t$ 是第 $t$ 代的性状向量，$\\mathbf{G}$ 是遗传方差-协方差矩阵，$\\nabla W(\\mathbf{z}_t)$ 是绝对适合度曲面 $W(\\mathbf{z})$ 上的选择梯度。\n\n适合度函数 $W(\\mathbf{z})$ 定义为两个具有生物学动机的因子的乘积：$W(\\mathbf{z}) = R \\cdot c(\\|\\mathbf{z} - \\mathbf{z}^\\star\\|_2)$。第一项 $R$ 是频率依赖的学习因子，由下式给出\n$$\nR = \\rho \\cdot \\frac{u_M q + u_m p}{q + p}.\n$$\n该项代表了习得的捕食者厌恶强度，它取决于模拟者和模型种群的频率（$p$，$q$）和不美味程度（$u_m$，$u_M$），并由最大学习效应 $\\rho$ 进行缩放。对于给定的生态参数集，$R$ 是一个常数。第二项 $c(d) = \\exp(-\\beta d^2)$（其中 $d = \\|\\mathbf{z} - \\mathbf{z}^\\star\\|_2$）是一个描述知觉混淆的高斯函数。该函数在 $d=0$（即当 $\\mathbf{z} = \\mathbf{z}^\\star$ 时）达到峰值，并随着模拟者图案与模型图案的差异增大而减小。参数 $\\beta$ 控制该峰值的陡峭程度，代表捕食者的判别能力。这个适合度景观在 $\\mathbf{z} = \\mathbf{z}^\\star$ 处有唯一的全局最大值，它充当演化吸引子。\n\n为了实现迭代更新，我们必须首先计算适合度函数 $\\nabla W(\\mathbf{z})$ 的梯度。梯度向量指向适合度最陡峭的增长方向。使用链式法则，并令 $\\mathbf{x} = \\mathbf{z} - \\mathbf{z}^\\star$，梯度的第 $i$ 个分量是：\n$$\n\\frac{\\partial W}{\\partial z_i} = \\frac{\\partial}{\\partial z_i} \\left[ R \\exp(-\\beta \\|\\mathbf{z} - \\mathbf{z}^\\star\\|_2^2) \\right] = R \\cdot \\exp(-\\beta \\|\\mathbf{z} - \\mathbf{z}^\\star\\|_2^2) \\cdot \\frac{\\partial}{\\partial z_i} (-\\beta \\sum_{j=1}^m (z_j - z_j^\\star)^2)\n$$\n$$\n\\frac{\\partial W}{\\partial z_i} = R \\cdot \\exp(-\\beta \\|\\mathbf{z} - \\mathbf{z}^\\star\\|_2^2) \\cdot (-2\\beta (z_i - z_i^\\star)) = -2\\beta R \\, c(\\|\\mathbf{z} - \\mathbf{z}^\\star\\|_2) (z_i - z_i^\\star).\n$$\n以向量形式表示，梯度为：\n$$\n\\nabla W(\\mathbf{z}) = -2\\beta R \\exp(-\\beta \\|\\mathbf{z} - \\mathbf{z}^\\star\\|_2^2) (\\mathbf{z} - \\mathbf{z}^\\star).\n$$\n梯度始终指向模型点 $\\mathbf{z}^\\star$，其大小随着模拟者性状 $\\mathbf{z}$ 接近 $\\mathbf{z}^\\star$ 而减小。\n\n将梯度代入 Lande 方程，得到模拟的显式更新规则：\n$$\n\\mathbf{z}_{t+1} = \\mathbf{z}_t - 2\\beta R \\exp(-\\beta \\|\\mathbf{z}_t - \\mathbf{z}^\\star\\|_2^2) \\mathbf{G}(\\mathbf{z}_t - \\mathbf{z}^\\star).\n$$\n该方程描述了对选择的响应。选择压力与 $-(\\mathbf{z}_t - \\mathbf{z}^\\star)$ 成正比，并由遗传方差-协方差矩阵 $\\mathbf{G}$ 左乘。如果 $\\mathbf{G}$ 是单位矩阵的标量倍，种群将直接向最优点演化。然而，如果 $\\mathbf{G}$ 具有非对角元素（遗传相关）或对角线上的方差不相等，演化轨迹将会产生偏离，可能不会遵循最陡峭的上升路径。\n\n解决该问题的算法是这个迭代过程的直接实现。对于每个测试用例：\n$1.$ 定义常量参数，包括初始性状 $\\mathbf{z}_0$、矩阵 $\\mathbf{G}$ 以及标量值 $\\beta, \\rho, p, q, u_M, u_m$。模型点固定为 $\\mathbf{z}^\\star=(0,0)$。使用常量 $\\varepsilon=10^{-6}$ 和 $N_{\\max}=10^5$。\n$2.$ 预先计算恒定的学习因子 $R$。\n$3.$ 启动一个循环，最多运行 $N_{\\max}$ 次迭代，迭代计数器 $t$ 从 0 开始。\n$4.$ 在每次迭代 $t$（对于 $t=0, 1, \\dots, N_{\\max}$）开始时，计算欧几里得距离 $\\|\\mathbf{z}_t - \\mathbf{z}^\\star\\|_2$。\n$5.$ 将此距离与容差 $\\varepsilon$ 进行比较。如果 $\\|\\mathbf{z}_t - \\mathbf{z}^\\star\\|_2 \\le \\varepsilon$，则认为性状已收敛。此用例的模拟终止，并将当前迭代次数 $t$ 记录为结果。\n$6.$ 如果尚未达到收敛，则使用推导出的更新公式计算下一个性状向量 $\\mathbf{z}_{t+1}$。这包括计算指数项，执行矩阵-向量乘积 $\\mathbf{G}(\\mathbf{z}_t - \\mathbf{z}^\\star)$，缩放结果，并将更新量加到 $\\mathbf{z}_t$上。\n$7.$ 如果循环完成了所有 $N_{\\max}+1$ 次检查而距离仍未低于 $\\varepsilon$，则认为模拟失败。此用例的记录结果为 $-1$。\n\n此计算过程精确地模拟了所指定的拟态演化模型，提供了在给定的遗传和生态约束下，模拟者表型变得与模型无法区分所需的世代数。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the evolutionary trajectory problem for a set of test cases.\n    \"\"\"\n\n    # Define global constants for all test cases.\n    epsilon = 1e-6\n    n_max = 100000\n    z_star = np.array([0.0, 0.0])\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        {   # Test case A\n            \"z0\": np.array([1.0, 0.5]),\n            \"G\": np.diag([0.02, 0.01]),\n            \"beta\": 3.0, \"rho\": 0.9,\n            \"p\": 0.1, \"q\": 0.3,\n            \"u_M\": 1.0, \"u_m\": 0.0\n        },\n        {   # Test case B\n            \"z0\": np.array([1.0, 1.0]),\n            \"G\": np.diag([1e-8, 1e-8]),\n            \"beta\": 3.0, \"rho\": 0.9,\n            \"p\": 0.7, \"q\": 0.3,\n            \"u_M\": 1.0, \"u_m\": 0.0\n        },\n        {   # Test case C\n            \"z0\": np.array([2.0, -1.0]),\n            \"G\": np.array([[0.02, 0.015], [0.015, 0.03]]),\n            \"beta\": 2.0, \"rho\": 0.8,\n            \"p\": 0.5, \"q\": 0.5,\n            \"u_M\": 1.0, \"u_m\": 0.6\n        },\n        {   # Test case D\n            \"z0\": np.array([-1.5, 1.0]),\n            \"G\": np.array([[0.01, 0.005], [0.005, 0.01]]),\n            \"beta\": 4.0, \"rho\": 0.7,\n            \"p\": 0.2, \"q\": 0.4,\n            \"u_M\": 1.0, \"u_m\": 0.0\n        },\n        {   # Test case E\n            \"z0\": np.array([3.0, 3.0]),\n            \"G\": np.diag([0.005, 0.005]),\n            \"beta\": 6.0, \"rho\": 0.9,\n            \"p\": 0.4, \"q\": 0.6,\n            \"u_M\": 1.0, \"u_m\": 0.9\n        }\n    ]\n\n    results = []\n    for case in test_cases:\n        z = case[\"z0\"].astype(np.float64)\n        G = case[\"G\"].astype(np.float64)\n        beta = case[\"beta\"]\n        rho = case[\"rho\"]\n        p = case[\"p\"]\n        q = case[\"q\"]\n        u_M = case[\"u_M\"]\n        u_m = case[\"u_m\"]\n\n        # Calculate the constant learning factor R\n        R = rho * (u_M * q + u_m * p) / (q + p)\n\n        # Pre-calculate the constant part of the update term's scalar factor\n        # The update is z_{t+1} = z_t - 2*beta*R*exp(...) * G(z_t - z_star)\n        C = -2.0 * beta * R\n\n        iterations = -1\n        # Loop from t=0 to t=n_max. Check for convergence at the beginning of each step.\n        for t in range(n_max + 1):\n            # Calculate displacement vector and distance from the model point\n            d_vec = z - z_star\n            dist = np.linalg.norm(d_vec)\n\n            # Check for stopping condition\n            if dist = epsilon:\n                iterations = t\n                break\n            \n            # If t reaches n_max here, it means z_n_max did not converge,\n            # so we break loop and keep iterations = -1. This check is implicit\n            # in the for loop range.\n\n            # Calculate the full update vector for z_t -> z_{t+1}\n            # delta_z = G * grad(W(z))\n            # grad(W(z)) = -2*beta*R*exp(-beta*dist^2)*(z-z_star)\n            # scalar_part = -2*beta*R*exp(-beta*dist^2)\n            scalar_part = C * np.exp(-beta * dist**2)\n            delta_z = scalar_part * np.dot(G, d_vec)\n            \n            # Update the trait vector\n            z = z + delta_z\n        \n        results.append(iterations)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "2734462"}]}