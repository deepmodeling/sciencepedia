{"hands_on_practices": [{"introduction": "环境科学的基石之一是准确评估随时间发生的变化。然而，我们对变化的感知很容易因我们选择的参考点而产生偏差。本练习将介绍“基线漂移综合征”，这是一个解释我们为何会对长期环境退化视而不见的批判性概念。通过一个假设情景[@problem_id:2488851]，我们将定量地分辨一个简单选择的“基线”与更严谨但通常无法观测的“反事实”之间的区别，从而揭示分析中看似微小的选择如何导致对环境影响的截然不同的结论。", "problem": "一个长期的海洋监测项目在离散的年度时间点 $t \\in \\{1,\\dots,T\\}$ 测量一个基础无脊椎动物物种的底栖覆盖度，从而产生一个时间序列 $Y_t$（例如，在标准化的带状样带中的覆盖百分比）。一个胁迫因子（例如，慢性营养盐负荷）在时间 $t=\\tau$ 开始影响系统，此后观测到的过程可能会偏离其先前的轨迹。设 $Y_t(1)$ 表示在时间 $t$ 胁迫因子下的实现结果，设 $Y_t(0)$ 表示在时间 $t$ 没有胁迫因子的情况下本应发生的未被观测到的反事实结果。一位分析师通过两种方式报告趋势和效应大小：(i) 通过在指定的时间窗口内对 $Y_t$ 关于 $t$ 进行线性回归拟合，以及 (ii) 通过将变化表示为相对于选定基线 $B$ 的百分比（例如，单个时间点的值 $Y_{t_b}$ 或基线期内的平均值）。\n\n为便于说明，假设存在以下科学上合理的数据生成过程：在胁迫因子出现之前，系统遵循线性轨迹 $Y_t(0) = \\alpha + \\gamma t$；在 $t \\ge \\tau$ 开始之后，实现的过程为 $Y_t(1) = Y_t(0) + \\delta + \\eta (t-\\tau)$，其中 $\\delta \\le 0$ 和 $\\eta \\le 0$ 分别代表由胁迫因子引起的瞬时水平损失和斜率降低。考虑具体的参数化：$\\alpha=100$, $\\gamma=2$, $\\delta=-30$, $\\eta=-3$, $\\tau=10$，基线选择为 $t_b=12$ 且 $B=Y_{t_b}(1)$，评估时间为 $T=20$。\n\n下列陈述中哪些是正确的？选择所有适用项。\n\nA. 在生态监测中，基线是任何空间对照组，它等同于反事实，因为两者都代表未受影响的参考条件。\n\nB. 在因果推断方面，反事实是 $Y_t(0)$，即在时间 $t$ 没有胁迫因子下的未观测结果；而基线是分析师选择的参考水平，如 $Y_{t_b}$ 或指定时期内的平均值，用于中心化或缩放；这两者在概念上是截然不同的。\n\nC. 因为对 $Y_t$ 关于 $t$ 的线性回归对于 $Y_t$ 的平移和缩放具有等变性，所以改变基线不会影响任何指标下的趋势推断，包括斜率和百分比变化的幅度。\n\nD. 如果无胁迫因子轨迹 $Y_t(0)$ 具有非零趋势（例如，$\\gamma \\ne 0$），那么使用影响后的基线 $B=Y_{t_b}(1)$ 来计算时间 $T$ 的百分比损失，通常会低估在 $T$ 时的真实反事实损失；这种偏误源于将基线与因果反事实混为一谈。\n\nE. 基线漂移综合征是指连续的观察者群体逐渐将基线 $B$ 重置为当代的、已经退化的状态，这会系统性地削弱对长期损失的感知；可以通过将基准锚定于干扰前的基准点来缓解这种情况，方法是进行明确的反事实重建（例如，使用古生态学指标、档案记录和机理模型）。\n\nF. 在参数化 $\\alpha=100$, $\\gamma=2$, $\\delta=-30$, $\\eta=-3$, $\\tau=10$, $t_b=12$ 和 $T=20$ 的情况下，$T$ 时的反事实损失超过了相对于基线的损失，真实损失 $L^\\ast = \\dfrac{Y_T(0)-Y_T(1)}{Y_T(0)}$ 的近似值为 $L^\\ast \\approx 0.43$，而相对于基线的损失 $\\widehat{L} = \\dfrac{B-Y_T(1)}{B}$ 的近似值为 $\\widehat{L} \\approx 0.09$。\n\n通过选择正确的选项来回答。", "solution": "首先必须验证问题陈述的科学性和逻辑完整性。\n\n第 1 步：提取已知条件\n问题提供了以下信息：\n- 底栖覆盖度的时间序列由 $Y_t$ 表示，针对离散的年度时间点 $t \\in \\{1,\\dots,T\\}$。\n- 一个胁迫因子在时间 $t=\\tau$ 开始。\n- 胁迫因子下的实现结果是 $Y_t(1)$。\n- 没有胁迫因子时的未观测反事实结果是 $Y_t(0)$。\n- 分析方法包括：(i) 对 $Y_t$ 关于 $t$ 的线性回归，以及 (ii) 相对于基线 $B$ 的百分比变化。\n- 基线 $B$ 是一个选定的参考值，例如单个值 $Y_{t_b}$ 或一个时期内的平均值。\n- 数据生成过程定义如下：\n    - 对于 $t  \\tau$，过程为 $Y_t(0) = \\alpha + \\gamma t$。观测过程 $Y_t$ 是 $Y_t(0)$。\n    - 对于 $t \\ge \\tau$，实现的过程为 $Y_t(1) = Y_t(0) + \\delta + \\eta (t-\\tau)$。观测过程 $Y_t$ 是 $Y_t(1)$。\n- 具体的参数值为：$\\alpha=100$, $\\gamma=2$, $\\delta=-30$, $\\eta=-3$, $\\tau=10$。\n- 具体的分析选择为：基线选择 $t_b=12$ 且 $B=Y_{t_b}(1)$，评估时间为 $T=20$。\n\n第 2 步：验证\n该问题在科学上植根于定量生态学和环境统计学。所呈现的概念——因果推断中的反事实、时间基线及其产生偏误的可能性——是生态影响评估中的标准和核心议题。该数学模型，一个在干预点截距和斜率发生变化的分段线性函数，是说明此类问题的常见且适当的简化。参数是指定的，使得问题适定且自洽。语言客观而精确。一个具有现有趋势的系统受到胁迫因子影响的情景在科学上是现实的。问题陈述中没有矛盾、歧义或事实错误。\n\n第 3 步：结论\n问题是有效的。可以推导出严谨的解。\n\n我们根据提供的定义和模型来分析每个陈述。问题的核心在于因果反事实（一个代表在没有干预的情况下会发生什么的理论构建）与基线（一个为比较而实际选择的参考点）之间的区别。\n\n模型方程为：\n所有 $t$ 的反事实轨迹：\n$$Y_t(0) = \\alpha + \\gamma t = 100 + 2t$$\n$t \\ge \\tau$ 时的实现轨迹：\n$$Y_t(1) = Y_t(0) + \\delta + \\eta(t-\\tau) = (100 + 2t) - 30 - 3(t-10)$$\n\n评估提供的选项：\n\nA. 在生态监测中，基线是任何空间对照组，它等同于反事实，因为两者都代表未受影响的参考条件。\n这个陈述是错误的。基线是参考点的一个通用术语，可以是时间上的（例如，影响前的平均值）或空间上的（例如，对照地点）。它不局限于空间对照组。更根本的是，基线不等同于反事实。反事实 $Y_t(0)$ 是在时间 $t$ 没有影响的情况下本应发生的具体、通常未被观测到的状态。基线，例如来自对照地点的测量值或来自影响地点的过去测量值，被用作反事实的*估计量*。在一个具有非零趋势（$\\gamma \\ne 0$）的动态系统中，一个固定的基线值（例如 $Y_{\\tau-1}$）对于 $t > \\tau-1$ 来说不可能等于不断变化的反事实 $Y_t(0)$。问题本身使用了一个影响后的值 $B=Y_{t_b}(1)$ 作为基线，这明确地不同于未受影响的反事实。\n结论：**错误**。\n\nB. 在因果推断方面，反事实是 $Y_t(0)$，即在时间 $t$ 没有胁迫因子下的未观测结果；而基线是分析师选择的参考水平，如 $Y_{t_b}$ 或指定时期内的平均值，用于中心化或缩放；这两者在概念上是截然不同的。\n这个陈述提供了正确的定义。反事实 $Y_t(0)$ 是因果推断中的一个核心概念，代表“控制”条件下的潜在结果。基线是为计算相对变化或标准化数据而实际选择的参考值。这两者在根本上是不同的概念。反事实是我们试图估计以确定因果效应的对象，而基线是一种报告工具，其正确选择对于避免误导性结论至关重要。该陈述正确地断言它们在概念上是截然不同的。\n结论：**正确**。\n\nC. 因为对 $Y_t$ 关于 $t$ 的线性回归对于 $Y_t$ 的平移和缩放具有等变性，所以改变基线不会影响任何指标下的趋势推断，包括斜率和百分比变化的幅度。\n这个陈述是错误的。首先，虽然线性回归斜率估计对于预测变量（$t$）的仿射变换是不变的，但它对于响应变量（$Y_t$）的缩放仅具有等变性；它会随着缩放因子而缩放。其次，该陈述错误地应用了这一性质。推断并不总是关于 $Y_t$ 本身的斜率。分析师可能会计算一个新的指标，例如与基线相比的百分比变化，$Z_t = (Y_t - B)/B$。这个变换是 $Z_t = (1/B)Y_t - 1$。将 $Z_t$ 对 $t$ 进行回归得到的斜率是...将 $Y_t$ 对 $t$ 进行回归所得斜率的 $(1/B)$ 倍。由于斜率现在依赖于 $B$ 的值，改变基线 $B$ 会直接影响在这个百分比变化指标中推断出的趋势。此外，百分比变化本身的幅度 $(Y_t - B)/B$，根据其定义就依赖于 $B$。因此，当以百分比形式衡量时，改变基线会深刻影响关于趋势的推断。\n结论：**错误**。\n\nD. 如果无胁迫因子轨迹 $Y_t(0)$ 具有非零趋势（例如，$\\gamma \\ne 0$），那么使用影响后的基线 $B=Y_{t_b}(1)$ 来计算时间 $T$ 的百分比损失，通常会低估在 $T$ 时的真实反事实损失；这种偏误源于将基线与因果反事实混为一谈。\n这个陈述是正确的。胁迫因子在时间 $T$ 的真实效应是反事实结果与实现结果之间的差值，$Y_T(0) - Y_T(1)$。真实的比例损失是 $L^\\ast = (Y_T(0) - Y_T(1)) / Y_T(0)$。使用影响后基线 $B=Y_{t_b}(1)$（其中 $t_b \\ge \\tau$）的分析师会计算一个相对于基线的变化，我们可以称之为 $\\widehat{L} = (B - Y_T(1))/B$（假设 $B > Y_T(1)$，否则就是相对于基线的增益）。在给定的情景中，系统具有正向的潜在趋势（$\\gamma=2 > 0$），因此反事实 $Y_T(0)$ 大于任何更早的反事实值 $Y_{t_b}(0)$（对于 $T>t_b$）。基线 $B=Y_{t_b}(1)$ 是一个*受影响*的值，所以 $Y_{t_b}(1)  Y_{t_b}(0)$。因此，基线 $B$ 远低于真实的参考点 $Y_T(0)$。使用一个受抑制且非动态的基线作为参考会导致对真实损失的低估。这个错误恰恰是由于将一个方便（但不合适）的基线与真实的（但未被观测到的）反事实混为一谈。这是基线漂移综合征的典型表现。\n结论：**正确**。\n\nE. 基线漂移综合征是指连续的观察者群体逐渐将基线 $B$ 重置为当代的、已经退化的状态，这会系统性地削弱对长期损失的感知；可以通过将基准锚定于干扰前的基准点来缓解这种情况，方法是进行明确的反事实重建（例如，使用古生态学指标、档案记录和机理模型）。\n这个陈述是正确的。它提供了对基线漂移综合征的标准而准确的定义，这是一个由渔业科学家 Daniel Pauly 首次提出的概念。它描述了每一代人如何可能将一个退化的生态系统视为正常，导致对历史上更原始状态的集体失忆。这系统性地降低了期望值，并掩盖了长期环境退化的真实程度。所提出的缓解策略也是历史生态学中的标准做法。为了建立一个更准确的“原始”基线，科学家利用早于现代监测的来源证据来重建过去的生态系统状态，例如古生态学数据（如沉积物核心）、历史档案（如旧地图、照片、捕鱼日志）和能够后向预测系统动态的过程基础模型。这些方法都是明确的反事实重建形式。\n结论：**正确**。\n\nF. 在参数化 $\\alpha=100$, $\\gamma=2$, $\\delta=-30$, $\\eta=-3$, $\\tau=10$, $t_b=12$ 和 $T=20$ 的情况下，$T$ 时的反事实损失超过了相对于基线的损失，真实损失 $L^\\ast = \\dfrac{Y_T(0)-Y_T(1)}{Y_T(0)}$ 的近似值为 $L^\\ast \\approx 0.43$，而相对于基线的损失 $\\widehat{L} = \\dfrac{B-Y_T(1)}{B}$ 的近似值为 $\\widehat{L} \\approx 0.09$。\n这个陈述需要进行数值计算。让我们计算必要的量。\n评估时间为 $T=20$。\n$T=20$ 时的反事实：\n$$Y_{20}(0) = 100 + 2(20) = 140$$\n$T=20$ 时的实现结果（注意 $20 \\ge \\tau=10$）：\n$$Y_{20}(1) = Y_{20}(0) + \\delta + \\eta(20-\\tau) = 140 - 30 - 3(20-10) = 140 - 30 - 30 = 80$$\n基线设置在 $t_b=12$。\n基线值 $B = Y_{12}(1)$（注意 $12 \\ge \\tau=10$）：\n$$Y_{12}(1) = Y_{12}(0) + \\delta + \\eta(12-\\tau) = (100 + 2(12)) - 30 - 3(12-10) = 124 - 30 - 6 = 88$$\n现在，我们计算两个损失指标。\n真实反事实损失：\n$$L^\\ast = \\frac{Y_{20}(0) - Y_{20}(1)}{Y_{20}(0)} = \\frac{140 - 80}{140} = \\frac{60}{140} = \\frac{3}{7} \\approx 0.42857$$\n相对于基线的损失：\n$$\\widehat{L} = \\frac{B - Y_{20}(1)}{B} = \\frac{88 - 80}{88} = \\frac{8}{88} = \\frac{1}{11} \\approx 0.09091$$\n计算出的值 $L^\\ast \\approx 0.43$ 和 $\\widehat{L} \\approx 0.09$ 与陈述相符。显然，反事实损失大大超过了相对于基线的损失（$0.43 > 0.09$）。该陈述在数量上是准确的。\n结论：**正确**。", "answer": "$$\\boxed{BDEF}$$", "id": "2488851"}, {"introduction": "科学结论的可靠性取决于其所依据的数据，而生态数据往往是不完美的。一个普遍的挑战是“不完美探测”——即物种即使存在也未能被观察到。本实践练习旨在挑战您超越对现场数据的初步分析，通过实施一个分层统计模型来明确处理这种观测误差[@problem_id:2488903]。通过将严谨模型的结果与一个简化的指标进行比较，本练习展示了环境科学如何在面对不确定性时得出稳健的推断，这是区分基于证据的结论与表面解释的关键一步。", "problem": "环境科学旨在通过数据推断状态变量，同时考虑观测误差，而环境保护主义通常宣传可能忽略了已知偏差的简化指标。考虑一项任务：对于一个通过重复的探测/未探测调查进行监测的物种，在存在不完美探测的情况下，估计其多季节站点占有率趋势。您需要实现一个程序，使用分层占有模型来估计占有率趋势，并将其与一个忽略了不完美探测的朴素变化指标——一种宣传式统计量——进行比较。\n\n使用的建模框架（基本原理）：\n- 潜在占有状态：对于季节 $t$ 的站点 $i$，其潜在真实占有状态 $z_{it}$ 是一个成功概率为 $\\psi_t$ 的伯努利随机变量，记作 $z_{it} \\sim \\mathrm{Bernoulli}(\\psi_t)$，其中 $i \\in \\{1,\\dots,S\\}$ 且 $t \\in \\{1,\\dots,T\\}$。\n- 探测模型：在 $z_{it} = 1$ 的条件下，每次重复调查 $j \\in \\{1,\\dots,J_{it}\\}$ 会产生一次探测 $y_{itj} \\sim \\mathrm{Bernoulli}(p)$，各次重复调查之间相互独立，且在所有季节和站点中探测概率 $p$ 恒定。如果 $z_{it} = 0$，那么 $y_{itj} = 0$ 几乎必然成立。\n- 占有率的时间趋势：占有概率遵循 logistic 趋势，\n$$\n\\mathrm{logit}(\\psi_t) = \\alpha + \\beta \\cdot (t-1),\n$$\n其中 $\\alpha \\in \\mathbb{R}$ 且 $\\beta \\in \\mathbb{R}$，并且 $\\mathrm{logit}(x) = \\log\\left(\\frac{x}{1-x}\\right)$。\n\n估计原则：\n- 使用最大似然估计 (MLE)，通过对潜在变量 $z_{it}$ 进行边缘化来估计 $(\\alpha,\\beta,p)$。从上述生成过程中推导出站点-季节观测模型，并最大化所有站点和季节的联合似然。\n\n每个测试用例的必需输出：\n1. 分层趋势变化（以小数表示）：使用 $(\\alpha,\\beta)$ 的最大似然估计值，通过 $\\psi_t = \\mathrm{logit}^{-1}(\\alpha + \\beta \\cdot (t-1))$ 计算\n$$\n\\Delta_{\\mathrm{hier}} = \\frac{\\psi_T - \\psi_1}{\\psi_1},\n$$\n2. 忽略不完美探测的朴素变化（以小数表示）：对于每个季节 $t$，计算至少有一次探测的站点比例，记为 $d_t$。然后\n$$\n\\Delta_{\\mathrm{naive}} = \\frac{d_T - d_1}{d_1}.\n$$\n3. 朴素变化与分层变化之间的差异：\n$$\n\\Delta_{\\mathrm{diff}} = \\Delta_{\\mathrm{naive}} - \\Delta_{\\mathrm{hier}}.\n$$\n\n每个测试用例的三个输出都必须表示为小数，并四舍五入到恰好 $3$ 位小数。\n\n不涉及角度单位。不需要物理单位。百分比变化必须以小数形式返回，而不是百分数。\n\n需要实现和评估的测试套件：\n每个测试用例是一个站点列表，其中每个站点是一个包含各季节数据的列表，每个季节包含一个重复探测结果（0/1）的列表。每个测试用例中都有 $3$ 个季节。重复次数 $J_{it}$ 可能因测试用例和季节而异。\n\n- 测试用例 A（中等下降信号，中等探测率；$S=12$ 个站点，$T=3$ 个季节，每个季节 $J_{it}=3$ 次重复）：\n  [\n    [[1,0,1],[1,0,0],[0,1,0]],\n    [[0,1,1],[0,0,1],[0,0,1]],\n    [[1,1,1],[1,0,1],[0,0,1]],\n    [[0,0,1],[0,0,0],[0,0,0]],\n    [[0,1,0],[0,0,0],[0,0,0]],\n    [[1,0,0],[0,0,0],[0,0,0]],\n    [[1,1,0],[0,1,0],[0,1,0]],\n    [[0,0,0],[0,0,1],[0,0,0]],\n    [[0,0,0],[1,0,0],[0,0,1]],\n    [[1,0,0],[1,0,0],[0,0,0]],\n    [[0,0,0],[0,0,0],[0,0,0]],\n    [[0,1,0],[0,0,0],[0,0,0]]\n  ]\n\n- 测试用例 B（近似稳定的占有率，低探测率；$S=10$ 个站点，$T=3$ 个季节，每个季节 $J_{it}=4$ 次重复）：\n  [\n    [[1,0,0,0],[0,1,0,0],[0,0,1,0]],\n    [[0,0,0,0],[0,0,0,0],[0,0,0,0]],\n    [[0,1,0,0],[0,0,1,0],[0,0,0,1]],\n    [[1,1,0,0],[0,0,0,0],[0,1,0,0]],\n    [[0,0,0,0],[0,0,0,0],[0,0,0,0]],\n    [[0,1,1,0],[0,0,0,0],[0,0,1,0]],\n    [[0,0,0,0],[1,0,0,0],[0,0,0,0]],\n    [[0,1,0,0],[0,1,0,0],[0,0,0,0]],\n    [[0,0,0,0],[0,0,1,0],[0,0,0,0]],\n    [[1,0,0,0],[0,0,0,0],[0,0,0,0]]\n  ]\n\n- 测试用例 C（强增长信号，高探测率；$S=8$ 个站点，$T=3$ 个季节，每个季节 $J_{it}=2$ 次重复）：\n  [\n    [[0,0],[0,1],[1,1]],\n    [[0,0],[0,1],[1,1]],\n    [[1,1],[1,1],[1,1]],\n    [[0,0],[0,0],[1,0]],\n    [[0,0],[0,1],[1,1]],\n    [[1,0],[1,1],[1,1]],\n    [[0,0],[0,0],[0,0]],\n    [[0,1],[1,1],[1,1]]\n  ]\n\n您的任务：\n- 实现一个完整的程序，对上述三个测试用例中的每一个，通过最大似然估计来拟合指定的分层占有模型，计算 $\\Delta_{\\mathrm{hier}}$、$\\Delta_{\\mathrm{naive}}$ 和 $\\Delta_{\\mathrm{diff}}$，并将每个结果四舍五入到恰好 $3$ 位小数。\n- 您的程序必须生成单行输出，其中包含一个扁平的、逗号分隔的列表，用方括号括起来，包含所有结果。要求的顺序是：\n  [\n    $\\Delta_{\\mathrm{hier}}^{(A)}$,\n    $\\Delta_{\\mathrm{naive}}^{(A)}$,\n    $\\Delta_{\\mathrm{diff}}^{(A)}$,\n    $\\Delta_{\\mathrm{hier}}^{(B)}$,\n    $\\Delta_{\\mathrm{naive}}^{(B)}$,\n    $\\Delta_{\\mathrm{diff}}^{(B)}$,\n    $\\Delta_{\\mathrm{hier}}^{(C)}$,\n    $\\Delta_{\\mathrm{naive}}^{(C)}$,\n    $\\Delta_{\\mathrm{diff}}^{(C)}$\n  ]\n例如，您的输出必须是单行，格式为“[x1,x2,x3,x4,x5,x6,x7,x8,x9]”，其中每个 $x_k$ 是一个四舍五入到恰好 $3$ 位的小数。\n\n实现约束：\n- 程序必须是自包含的，无需输入，并使用最大似然估计，其似然计算在数值上应保持稳定，并与上述模型定义一致。通过无约束参数，对 $\\psi_t$ 和 $p$ 均使用 logistic 函数。\n- 将所有最终数值结果表示为小数点后恰好有 $3$ 位数字的小数。", "solution": "问题陈述被评估为有效。它在科学上基于统计生态学的既定原则，特别是物种占有的分层建模。问题定义明确，提供了对数据、生成模型、估计原则（最大似然估计）和所需精确输出指标的完整描述。语言客观且正式。所有必要的数据和约束都已提供，使得问题自包含且可解。\n\n该任务是在不完美探测条件下估计生态趋势，并将一个严谨的基于模型的估计与一个忽略了此复杂性的朴素估计进行比较。这需要对分层占有模型的似然函数进行推导和最大化。\n\n待估计的模型参数为 $\\boldsymbol{\\theta} = (\\alpha, \\beta, p)$，其中 $\\alpha$ 和 $\\beta$ 定义了占有概率 $\\psi_t$ 的时间趋势，$p$ 是探测概率。\n季节 $t \\in \\{1, \\dots, T\\}$ 的占有概率由 logistic 模型给出：\n$$ \\psi_t = \\frac{1}{1 + \\exp(-(\\alpha + \\beta(t-1)))} $$\n站点 $i \\in \\{1, \\dots, S\\}$ 在季节 $t$ 的潜在（未观测）真实占有状态，记为 $z_{it}$，是一个伯努利随机变量：\n$$ z_{it} \\sim \\mathrm{Bernoulli}(\\psi_t) $$\n观测数据由站点 $i$ 在季节 $t$ 的 $J_{it}$ 次重复调查组成。每次调查的结果 $y_{itj}$ 是探测到（1）或未探测到（0）。在站点被占有（$z_{it}=1$）的条件下，每次调查都是一次成功概率为 $p$ 的独立伯努利试验：\n$$ y_{itj} | z_{it}=1 \\sim \\mathrm{Bernoulli}(p) $$\n如果站点未被占有（$z_{it}=0$），则不可能有探测，所以 $y_{itj}=0$。\n\n为了执行最大似然估计，我们必须首先通过对潜在状态 $z_{it}$ 进行边缘化来构建观测数据的似然函数。设站点 $i$ 在季节 $t$ 的数据由 $J_{it}$ 次调查中的探测次数 $k_{it} = \\sum_{j=1}^{J_{it}} y_{itj}$ 来总结。\n\n单个站点-季节观测值的似然贡献 $L_{it}$ 取决于是否发生了探测：\n\n情况1：至少有一次探测（$k_{it}  0$）。\n如果观测到一次或多次探测，则该站点必被占有（$z_{it}=1$）。此观测的概率是站点被占有的概率乘以在占有条件下特定探测历史的概率。\n$$ L_{it}(k_{it}0) = P(z_{it}=1) \\cdot P(\\text{data}_{it} | z_{it}=1) = \\psi_t \\cdot p^{k_{it}} (1-p)^{J_{it}-k_{it}} $$\n\n情况2：没有探测（$k_{it} = 0$）。\n这可能以两种互斥的方式发生：要么站点被占有，但在 $J_{it}$ 次调查中均未探测到物种；要么站点未被占有。\n$$ L_{it}(k_{it}=0) = P(z_{it}=1) \\cdot P(k_{it}=0 | z_{it}=1) + P(z_{it}=0) \\cdot P(k_{it}=0 | z_{it}=0) $$\n$$ L_{it}(k_{it}=0) = \\psi_t \\cdot (1-p)^{J_{it}} + (1-\\psi_t) \\cdot 1 $$\n\n假设独立性，总似然是所有站点和季节的这些单独似然的乘积：\n$$ L(\\alpha, \\beta, p) = \\prod_{i=1}^{S} \\prod_{t=1}^{T} L_{it} $$\n为了进行数值优化，我们使用负对数似然（NLL）。设 $D_1 = \\{(i, t) | k_{it}  0\\}$ 和 $D_0 = \\{(i, t) | k_{it} = 0\\}$。\n$$ \\mathrm{NLL}(\\alpha, \\beta, p) = - \\log L = - \\sum_{(i,t) \\in D_1} \\left[ \\log(\\psi_t) + k_{it}\\log(p) + (J_{it}-k_{it})\\log(1-p) \\right] - \\sum_{(i,t) \\in D_0} \\log\\left( \\psi_t (1-p)^{J_{it}} + 1-\\psi_t \\right) $$\n为确保数值稳定性并便于无约束优化，参数 $(\\alpha, \\beta, p)$ 被重新参数化。我们可以在 $(\\alpha, \\beta, \\text{logit}(p))$ 上进行优化，其中 $\\text{logit}(p) = \\log(p/(1-p))$。使用数值优化算法，例如 `scipy.optimize.minimize` 中可用的 Broyden–Fletcher–Goldfarb–Shanno (BFGS) 算法，来最小化关于这些无约束参数的 NLL。\n\n在找到最大似然估计值 $(\\hat{\\alpha}, \\hat{\\beta}, \\hat{p})$ 后，计算所需的量：\n1.  分层相对变化，$\\Delta_{\\mathrm{hier}}$：\n    $$ \\hat{\\psi}_1 = \\frac{1}{1 + \\exp(-\\hat{\\alpha})} $$\n    $$ \\hat{\\psi}_T = \\frac{1}{1 + \\exp(-(\\hat{\\alpha} + \\hat{\\beta}(T-1)))} $$\n    $$ \\Delta_{\\mathrm{hier}} = \\frac{\\hat{\\psi}_T - \\hat{\\psi}_1}{\\hat{\\psi}_1} $$\n2.  朴素相对变化，$\\Delta_{\\mathrm{naive}}$：\n    对于每个季节 $t$，至少有一次探测的站点比例为 $d_t = \\frac{1}{S} \\sum_{i=1}^{S} \\mathbb{I}(k_{it}0)$，其中 $\\mathbb{I}(\\cdot)$ 是指示函数。\n    $$ \\Delta_{\\mathrm{naive}} = \\frac{d_T - d_1}{d_1} $$\n3.  差异，$\\Delta_{\\mathrm{diff}}$：\n    $$ \\Delta_{\\mathrm{diff}} = \\Delta_{\\mathrm{naive}} - \\Delta_{\\mathrm{hier}} $$\n对提供的每个测试用例执行这些计算。", "answer": "```python\nimport numpy as np\nfrom scipy.optimize import minimize\n\ndef solve():\n    \"\"\"\n    Main function to solve the occupancy modeling problem for all test cases.\n    \"\"\"\n    test_cases = {\n        'A': [\n            [[1,0,1],[1,0,0],[0,1,0]],\n            [[0,1,1],[0,0,1],[0,0,1]],\n            [[1,1,1],[1,0,1],[0,0,1]],\n            [[0,0,1],[0,0,0],[0,0,0]],\n            [[0,1,0],[0,0,0],[0,0,0]],\n            [[1,0,0],[0,0,0],[0,0,0]],\n            [[1,1,0],[0,1,0],[0,1,0]],\n            [[0,0,0],[0,0,1],[0,0,0]],\n            [[0,0,0],[1,0,0],[0,0,1]],\n            [[1,0,0],[1,0,0],[0,0,0]],\n            [[0,0,0],[0,0,0],[0,0,0]],\n            [[0,1,0],[0,0,0],[0,0,0]]\n        ],\n        'B': [\n            [[1,0,0,0],[0,1,0,0],[0,0,1,0]],\n            [[0,0,0,0],[0,0,0,0],[0,0,0,0]],\n            [[0,1,0,0],[0,0,1,0],[0,0,0,1]],\n            [[1,1,0,0],[0,0,0,0],[0,1,0,0]],\n            [[0,0,0,0],[0,0,0,0],[0,0,0,0]],\n            [[0,1,1,0],[0,0,0,0],[0,0,1,0]],\n            [[0,0,0,0],[1,0,0,0],[0,0,0,0]],\n            [[0,1,0,0],[0,1,0,0],[0,0,0,0]],\n            [[0,0,0,0],[0,0,1,0],[0,0,0,0]],\n            [[1,0,0,0],[0,0,0,0],[0,0,0,0]]\n        ],\n        'C': [\n            [[0,0],[0,1],[1,1]],\n            [[0,0],[0,1],[1,1]],\n            [[1,1],[1,1],[1,1]],\n            [[0,0],[0,0],[1,0]],\n            [[0,0],[0,1],[1,1]],\n            [[1,0],[1,1],[1,1]],\n            [[0,0],[0,0],[0,0]],\n            [[0,1],[1,1],[1,1]]\n        ]\n    }\n\n    all_results = []\n    \n    for case_data in [test_cases['A'], test_cases['B'], test_cases['C']]:\n        # Perform calculations for one test case\n        S = len(case_data)\n        T = len(case_data[0]) if S > 0 else 0\n\n        # Pre-process data into summary statistics (k_it, J_it)\n        summary_data = []\n        for i in range(S):\n            site_summary = []\n            for t in range(T):\n                detections = case_data[i][t]\n                k_it = sum(detections)\n                J_it = len(detections)\n                site_summary.append((k_it, J_it))\n            summary_data.append(site_summary)\n\n        # Numerically stable logistic function\n        def logistic(x):\n            return 1.0 / (1.0 + np.exp(-x))\n\n        # Numerically stable log-sum-exp for log(exp(a) + exp(b))\n        def log_sum_exp(a, b):\n            if a > b:\n                return a + np.log(1.0 + np.exp(b - a))\n            else:\n                return b + np.log(1.0 + np.exp(a - b))\n\n        # Negative log-likelihood function\n        def nll(params):\n            alpha, beta, logit_p = params\n            \n            # Using stable forms for log(p) and log(1-p)\n            log_p = -np.log(1.0 + np.exp(-logit_p))\n            log_1_minus_p = -np.log(1.0 + np.exp(logit_p))\n            if np.isinf(log_p) or np.isinf(log_1_minus_p): return np.inf\n\n            total_log_likelihood = 0.0\n\n            for t_idx in range(T):\n                t = t_idx + 1\n                logit_psi = alpha + beta * (t - 1.0)\n                \n                log_psi_t = -np.log(1.0 + np.exp(-logit_psi))\n                log_1_minus_psi_t = -np.log(1.0 + np.exp(logit_psi))\n                if np.isinf(log_psi_t) or np.isinf(log_1_minus_psi_t): return np.inf\n\n                for i in range(S):\n                    k_it, J_it = summary_data[i][t_idx]\n                    \n                    if k_it > 0:\n                        term = log_psi_t + k_it * log_p + (J_it - k_it) * log_1_minus_p\n                        total_log_likelihood += term\n                    else:\n                        term1 = log_1_minus_psi_t\n                        term2 = log_psi_t + J_it * log_1_minus_p\n                        total_log_likelihood += log_sum_exp(term1, term2)\n            \n            return -total_log_likelihood\n\n        # Find Maximum Likelihood Estimates\n        initial_params = np.array([0.0, 0.0, 0.0]) # alpha, beta, logit(p)\n        result = minimize(nll, initial_params, method='BFGS')\n        alpha_mle, beta_mle, logit_p_mle = result.x\n\n        # 1. Calculate hierarchical change\n        psi_1 = logistic(alpha_mle)\n        psi_T = logistic(alpha_mle + beta_mle * (T - 1))\n        \n        delta_hier = (psi_T - psi_1) / psi_1 if psi_1 != 0 else np.inf\n\n        # 2. Calculate naive change\n        d = np.zeros(T)\n        for t_idx in range(T):\n            detected_sites_count = sum(1 for i in range(S) if summary_data[i][t_idx][0] > 0)\n            d[t_idx] = detected_sites_count / S\n        \n        d_1 = d[0]\n        d_T = d[-1]\n        \n        delta_naive = (d_T - d_1) / d_1 if d_1 != 0 else np.inf\n\n        # 3. Calculate the difference\n        delta_diff = delta_naive - delta_hier\n        \n        # Append rounded results\n        all_results.append(f\"{delta_hier:.3f}\")\n        all_results.append(f\"{delta_naive:.3f}\")\n        all_results.append(f\"{delta_diff:.3f}\")\n        \n    # Print the final formatted output\n    print(f\"[{','.join(all_results)}]\")\n\nsolve()\n```", "id": "2488903"}, {"introduction": "当我们对某个环境趋势有了可靠的估计后，最终的科学目标是理解其成因。然而，仅仅观察到两个变量一同变化并不足以建立因果联系，因为它们的关系可能被其他因素所“混淆”。本练习将向您介绍有向无环图（DAGs），这是一个强大的工具，用于描绘因果假设并识别此类“混淆”变量[@problem_id:2488829]。通过推导混淆偏误的数学表达式，您将具体理解为何相关性不等于因果关系，并学习从观测数据中分离出真实因果效应所需的形式化推理。", "problem": "一个环境流行病学团队旨在估计长期环境空气污染暴露对心血管结局的总因果效应。为使研究立足于环境科学而非环保主义，该团队将问题框定为实测变量之间经验上可识别的因果关系，而非宣传倡导。设变量为：空气污染暴露 $A$、社会经济地位 $S$、吸烟强度 $M$ 和心血管结局 $Y$。\n\n使用因果图的核心定义和标准因果推理，按以下步骤进行：\n\n1) 提出一个关于 $A$、$S$、$M$ 和 $Y$ 之间合理的有向无环图 (DAG) 结构，该结构需反映以下由领域知识证明的定性陈述，且不与已知的生物学或社会决定因素相矛盾：社会经济地位 $S$ 影响居住地点，从而影响空气污染暴露 $A$；$S$ 还通过多种路径影响吸烟强度 $M$ 和基线心血管风险 $Y$；吸烟 $M$ 影响 $Y$；空气污染 $A$ 影响 $Y$；并且从长期来看，$A$ 不直接导致 $M$ 的变化。不要引入超出这些陈述所隐含的环或对撞节点。\n\n2) 仅使用基本因果图原理，确定一个用于估计 $A$ 对 $Y$ 的总因果效应的最小充分调整集。\n\n3) 现在假设一个与您的DAG一致的线性结构因果模型 (SCM)，其干扰项是联合独立且均值为零的：\n$$\nS \\sim \\mathcal{N}(0,\\sigma_S^2), \\quad A \\,=\\, \\gamma_S S + \\varepsilon_A, \\quad M \\,=\\, \\delta_S S + \\varepsilon_M, \\quad Y \\,=\\, \\beta_A A + \\beta_M M + \\beta_S S + \\varepsilon_Y,\n$$\n其中 $\\varepsilon_A$、$\\varepsilon_M$ 和 $\\varepsilon_Y$ 彼此之间以及与 $S$ 相互独立，各自具有有限方差，并且所有期望都是有限的。\n\n设 $\\theta_{\\text{naive}}$ 是仅将 $Y$ 对 $A$ 进行回归得到的普通最小二乘法 (OLS; Ordinary Least Squares) 斜率，设 $\\theta_{\\text{adj}}$ 是将 $Y$ 对 $A$ 和 $S$ 进行回归得到的关于 $A$ 的OLS偏斜率（不要将 $M$ 包含在调整集中）。从协方差定律和OLS斜率的定义出发，推导 $\\theta_{\\text{naive}} - \\theta_{\\text{adj}}$ 的闭式解析表达式，用结构参数 $\\beta_A$、$\\beta_M$、$\\beta_S$、$\\gamma_S$、$\\delta_S$、$\\sigma_S^2$ 和 $\\varepsilon_A$ 的方差（记作 $\\sigma_A^2$）表示。\n\n最终答案仅报告 $\\theta_{\\text{naive}} - \\theta_{\\text{adj}}$ 的简化表达式。不需要数值近似，也不需要单位。", "solution": "所述问题具有科学依据、提法得当且客观。它采用因果推断和统计学中的标准、可形式化的方法——具体为有向无环图（DAG）和线性结构因果模型（SCM）——来解决环境流行病学中的一个有效问题。问题的前提是内部一致的，所需信息足以得到唯一解。因此，该问题是有效的，我们着手求解。\n\n该问题分为三个部分。我们将依次解答。\n\n第 $1$ 部分：构建有向无环图 (DAG)\n\n问题给出了变量之间的以下定性关系：空气污染暴露（$A$）、社会经济地位（$S$）、吸烟强度（$M$）和心血管结局（$Y$）。\n1. 社会经济地位 $S$ 影响空气污染暴露 $A$：$S \\to A$。\n2. 社会经济地位 $S$ 影响吸烟强度 $M$：$S \\to M$。\n3. 社会经济地位 $S$ 影响心血管结局 $Y$：$S \\to Y$。\n4. 吸烟强度 $M$ 影响心血管结局 $Y$：$M \\to Y$。\n5. 空气污染暴露 $A$ 影响心血管结局 $Y$：$A \\to Y$。\n6. 空气污染暴露 $A$ 不直接导致吸烟强度 $M$。不存在边 $A \\to M$。\n\n基于这些有向关系，变量 $S$ 是 $A$、$M$ 和 $Y$ 的共同原因。变量 $A$ 和 $M$ 是 $S$ 对 $Y$ 影响的中介变量，但它们也各自有直接指向 $Y$ 的因果路径。最终生成的DAG包含从 $S$ 指向 $A$、$M$ 和 $Y$ 的箭头；一个从 $A$ 指向 $Y$ 的箭头；以及一个从 $M$ 指向 $Y$ 的箭头。\n\n第 $2$ 部分：识别最小充分调整集\n\n目标是估计 $A$ 对 $Y$ 的总因果效应，这对应于路径 $A \\to Y$。为实现此目标，我们必须阻断所有 $A$ 和 $Y$ 之间的非因果“后门”路径。后门路径是指从 $A$ 到 $Y$ 的一条路径，其起始于一个指向 $A$ 的箭头。\n\n在构建的DAG中，我们识别出从 $A$ 到 $Y$ 的以下路径：\n- 直接因果路径：$A \\to Y$。\n- 一条通过混杂因素 $S$ 的后门路径：$A \\leftarrow S \\to Y$。\n- 另一条涉及 $S$ 和 $M$ 的后门路径：$A \\leftarrow S \\to M \\to Y$。\n\n为了估计 $A$ 对 $Y$ 的因果效应，我们必须阻断所有后门路径，同时保持所有因果路径开放。根据后门准则，一个变量集 $Z$ 是一个充分调整集，如果：\n1. $Z$ 中没有变量是 $A$ 的后代。\n2. $Z$ 阻断了 $A$ 和 $Y$ 之间的每一条后门路径。\n\n两条已识别的后门路径 $A \\leftarrow S \\to Y$ 和 $A \\leftarrow S \\to M \\to Y$ 都包含变量 $S$。以 $S$ 为条件可以阻断这两条路径。变量 $S$ 不是 $A$ 的后代。因此，集合 $\\{S\\}$ 满足后门准则，是一个充分调整集。\n\n为了确定 $\\{S\\}$ 是否为最小充分调整集，我们必须确认 $\\{S\\}$ 的任何真子集都不是充分的。唯一的真子集是空集 $\\emptyset$，它会使两条后门路径都保持开放。因此，以 $S$ 为条件是必要的。集合 $\\{S\\}$ 因此是一个最小充分调整集。\n\n第 $3$ 部分：推导差值 $\\theta_{\\text{naive}} - \\theta_{\\text{adj}}$\n\n我们给定线性结构因果模型 (SCM)：\n$$\nS \\sim \\mathcal{N}(0,\\sigma_S^2), \\quad A = \\gamma_S S + \\varepsilon_A, \\quad M = \\delta_S S + \\varepsilon_M, \\quad Y = \\beta_A A + \\beta_M M + \\beta_S S + \\varepsilon_Y\n$$\n误差项 $\\varepsilon_A$、$\\varepsilon_M$、$\\varepsilon_Y$ 和变量 $S$ 是相互独立的，均值为零且方差有限。我们记 $\\text{Var}(\\varepsilon_A) = \\sigma_A^2$。\n\n朴素估计量 $\\theta_{\\text{naive}}$ 是仅将 $Y$ 对 $A$ 进行回归得到的普通最小二乘法 (OLS) 斜率。它由下式给出：\n$$\n\\theta_{\\text{naive}} = \\frac{\\text{Cov}(Y,A)}{\\text{Var}(A)}\n$$\n调整后的估计量 $\\theta_{\\text{adj}}$ 是将 $Y$ 对 $A$ 和 $S$ 进行回归得到的关于 $A$ 的OLS偏斜率。为求此值，我们首先将 $Y$ 表示为 $A$ 和 $S$ 以及一个与 $A$ 和 $S$ 不相关的误差项的函数。我们将 $M$ 的方程代入 $Y$ 的方程中：\n$$\nY = \\beta_A A + \\beta_M (\\delta_S S + \\varepsilon_M) + \\beta_S S + \\varepsilon_Y\n$$\n$$\nY = \\beta_A A + (\\beta_M \\delta_S + \\beta_S)S + (\\beta_M \\varepsilon_M + \\varepsilon_Y)\n$$\n这是一个关于 $A$ 和 $S$ 的 $Y$ 的线性模型。新的误差项是 $u = \\beta_M \\varepsilon_M + \\varepsilon_Y$。我们必须检查回归变量 $A$ 和 $S$ 是否与 $u$ 不相关。\n$$\n\\text{Cov}(A, u) = \\text{Cov}(\\gamma_S S + \\varepsilon_A, \\beta_M \\varepsilon_M + \\varepsilon_Y) = 0\n$$\n$$\n\\text{Cov}(S, u) = \\text{Cov}(S, \\beta_M \\varepsilon_M + \\varepsilon_Y) = 0\n$$\n由于 $S$、$\\varepsilon_A$、$\\varepsilon_M$ 和 $\\varepsilon_Y$ 的相互独立性，这两个协方差都为零。因为回归变量与误差项不相关，所以 $A$ 的系数的OLS估计量将是真实参数 $\\beta_A$ 的无偏且一致的估计量。因此：\n$$\n\\theta_{\\text{adj}} = \\beta_A\n$$\n现在我们计算 $\\theta_{\\text{naive}}$。我们需要 $\\text{Var}(A)$ 和 $\\text{Cov}(Y,A)$。首先，我们从SCM中计算必要的方差和协方差。\n$$\n\\text{Var}(S) = \\sigma_S^2\n$$\n$$\n\\text{Var}(A) = \\text{Var}(\\gamma_S S + \\varepsilon_A) = \\gamma_S^2 \\text{Var}(S) + \\text{Var}(\\varepsilon_A) = \\gamma_S^2 \\sigma_S^2 + \\sigma_A^2\n$$\n混杂因素 $S$ 和暴露 $A$ 之间的协方差是：\n$$\n\\text{Cov}(S,A) = \\text{Cov}(S, \\gamma_S S + \\varepsilon_A) = \\gamma_S \\text{Var}(S) = \\gamma_S \\sigma_S^2\n$$\n吸烟 $M$ 和暴露 $A$ 之间的协方差是：\n$$\n\\text{Cov}(M,A) = \\text{Cov}(\\delta_S S + \\varepsilon_M, \\gamma_S S + \\varepsilon_A) = \\delta_S \\gamma_S \\text{Var}(S) = \\delta_S \\gamma_S \\sigma_S^2\n$$\n现在，我们计算结局 $Y$ 和暴露 $A$ 之间的协方差：\n$$\n\\text{Cov}(Y,A) = \\text{Cov}(\\beta_A A + \\beta_M M + \\beta_S S + \\varepsilon_Y, A)\n$$\n$$\n= \\beta_A \\text{Var}(A) + \\beta_M \\text{Cov}(M,A) + \\beta_S \\text{Cov}(S,A) + \\text{Cov}(\\varepsilon_Y, A)\n$$\n由于 $\\text{Cov}(\\varepsilon_Y, A) = \\text{Cov}(\\varepsilon_Y, \\gamma_S S + \\varepsilon_A)=0$，我们代入先前推导出的项：\n$$\n\\text{Cov}(Y,A) = \\beta_A (\\gamma_S^2 \\sigma_S^2 + \\sigma_A^2) + \\beta_M (\\delta_S \\gamma_S \\sigma_S^2) + \\beta_S (\\gamma_S \\sigma_S^2)\n$$\n现在我们可以计算 $\\theta_{\\text{naive}}$：\n$$\n\\theta_{\\text{naive}} = \\frac{\\text{Cov}(Y,A)}{\\text{Var}(A)} = \\frac{\\beta_A (\\gamma_S^2 \\sigma_S^2 + \\sigma_A^2) + \\beta_M \\delta_S \\gamma_S \\sigma_S^2 + \\beta_S \\gamma_S \\sigma_S^2}{\\gamma_S^2 \\sigma_S^2 + \\sigma_A^2}\n$$\n$$\n\\theta_{\\text{naive}} = \\beta_A + \\frac{\\gamma_S \\sigma_S^2 (\\beta_M \\delta_S + \\beta_S)}{\\gamma_S^2 \\sigma_S^2 + \\sigma_A^2}\n$$\n所求的差值是 $\\theta_{\\text{naive}} - \\theta_{\\text{adj}}$。由于 $\\theta_{\\text{adj}} = \\beta_A$，这个差值就是遗漏变量偏误项：\n$$\n\\theta_{\\text{naive}} - \\theta_{\\text{adj}} = \\left( \\beta_A + \\frac{\\gamma_S \\sigma_S^2 (\\beta_M \\delta_S + \\beta_S)}{\\gamma_S^2 \\sigma_S^2 + \\sigma_A^2} \\right) - \\beta_A\n$$\n$$\n\\theta_{\\text{naive}} - \\theta_{\\text{adj}} = \\frac{\\gamma_S \\sigma_S^2 (\\beta_M \\delta_S + \\beta_S)}{\\gamma_S^2 \\sigma_S^2 + \\sigma_A^2}\n$$\n这就是最终的简化表达式。它量化了因未对混杂因素 $S$ 进行调整而引入的偏误。该偏误是混杂路径对结局的影响（$\\beta_M \\delta_S + \\beta_S$ 项）与混杂因素和暴露之间的关联（与其他项相关）的乘积。", "answer": "$$\n\\boxed{\\frac{\\gamma_S \\sigma_S^2 (\\beta_M \\delta_S + \\beta_S)}{\\gamma_S^2 \\sigma_S^2 + \\sigma_A^2}}\n$$", "id": "2488829"}]}