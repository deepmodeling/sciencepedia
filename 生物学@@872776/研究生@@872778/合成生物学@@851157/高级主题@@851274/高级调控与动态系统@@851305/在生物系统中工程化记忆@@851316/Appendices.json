{"hands_on_practices": [{"introduction": "双稳态是设计生物记忆系统的基石。本练习将探讨一个利用正反馈来创建两种稳定状态的经典合成基因线路 [@problem_id:2037230]。通过计算触发状态转换所需的关键诱导剂浓度，你将亲身体验控制这些记忆系统的非线性动力学和分岔理论。", "problem": "一位合成生物学家正在一个细菌菌株中设计一种遗传“记忆”电路。该记忆的状态由一种荧光蛋白P的浓度决定。该电路的设计使得编码P的基因以一个恒定的低基础速率表达。此外，蛋白P可以作为其自身基因的转录激活因子，从而形成一个正反馈回路。这种自我激活是协同的，需要两个P分子与启动子结合，并且依赖于化学诱导剂S的存在。\n\n蛋白质浓度 $[P]$ 的动力学可以用以下微分方程来描述：\n$$\n\\frac{d[P]}{dt} = k_{basal} + V_{max}([S]) \\frac{[P]^2}{K^2 + [P]^2} - \\gamma [P]\n$$\n其中，最大活化生产速率 $V_{max}$ 依赖于诱导剂浓度 $[S]$，遵循如下的类Michaelis-Menten函数：\n$$\nV_{max}([S]) = V_{peak} \\frac{[S]}{K_S + [S]}\n$$\n该系统被设计用来展现记忆（迟滞）效应。当诱导剂浓度 $[S]$ 从零缓慢增加时，系统保持在低表达状态，直到 $[S]$ 达到一个临界值 $[S]_{up}$，此时蛋白质浓度会突然转换到高表达状态。实验已经确定，这种向上转换恰好发生在蛋白质浓度达到临界值 $[P]_{up} = 2.00 \\text{ }\\mu\\text{M}$ 时。\n\n使用下面提供的参数，计算触发此转换所需的临界诱导剂浓度 $[S]_{up}$。\n\n- 基础生产速率, $k_{basal} = 0.075 \\text{ }\\mu\\text{M} \\cdot \\text{min}^{-1}$\n- 峰值活化生产速率, $V_{peak} = 2.00 \\text{ }\\mu\\text{M} \\cdot \\text{min}^{-1}$\n- 蛋白质降解速率常数, $\\gamma = 0.100 \\text{ min}^{-1}$\n- 蛋白质P的活化常数, $K = 4.00 \\text{ }\\mu\\text{M}$\n- 诱导剂S的活化常数, $K_S = 10.0 \\text{ }\\mu\\text{M}$\n\n请以 $\\mu\\text{M}$ 为单位给出 $[S]_{up}$ 的答案，并四舍五入到三位有效数字。", "solution": "蛋白质动力学由以下公式给出：\n$$\n\\frac{d[P]}{dt} = k_{basal} + V_{max}([S]) \\frac{[P]^{2}}{K^{2} + [P]^{2}} - \\gamma [P].\n$$\n定义 $f(P;S) = k_{basal} + V_{max}([S]) \\frac{P^{2}}{K^{2} + P^{2}} - \\gamma P$。在向上转换点（一个鞍结分岔点），稳态条件和相切条件同时成立：\n$$\nf(P_{up}; S_{up}) = 0, \\quad \\frac{\\partial f}{\\partial P}(P_{up}; S_{up}) = 0.\n$$\n计算导数：\n$$\n\\frac{\\partial f}{\\partial P} = V_{max}([S]) \\cdot \\frac{2 K^{2} P}{(K^{2} + P^{2})^{2}} - \\gamma.\n$$\n因此，相切条件给出：\n$$\nV_{max}([S_{up}]) = \\gamma \\frac{(K^{2} + P_{up}^{2})^{2}}{2 K^{2} P_{up}}.\n$$\n将此代入稳态条件：\n$$\n0 = k_{basal} + \\left[\\gamma \\frac{(K^{2} + P_{up}^{2})^{2}}{2 K^{2} P_{up}}\\right] \\frac{P_{up}^{2}}{K^{2} + P_{up}^{2}} - \\gamma P_{up}\n= k_{basal} + \\gamma \\frac{(K^{2} + P_{up}^{2}) P_{up}}{2 K^{2}} - \\gamma P_{up}.\n$$\n这可以简化为一致性条件：\n$$\nk_{basal} + \\gamma P_{up} \\frac{P_{up}^{2} - K^{2}}{2 K^{2}} = 0,\n$$\n给定的 $P_{up}$ 和参数满足此条件（如下文验证）。\n\n现在将 $V_{max}$ 与诱导剂联系起来：\n$$\nV_{max}([S]) = V_{peak} \\frac{[S]}{K_{S} + [S]} \\quad \\Rightarrow \\quad [S] = \\frac{K_{S} V_{max}}{V_{peak} - V_{max}}.\n$$\n使用给定的 $P_{up}$，在转换点计算 $V_{max}$：\n$$\nV_{max}([S_{up}]) = \\gamma \\frac{(K^{2} + P_{up}^{2})^{2}}{2 K^{2} P_{up}}.\n$$\n当 $P_{up} = 2.00$，$K = 4.00$，$\\gamma = 0.100$（以所述单位计时），\n$$\nK^{2} = 16,\\quad P_{up}^{2} = 4,\\quad K^{2} + P_{up}^{2} = 20,\\quad (K^{2} + P_{up}^{2})^{2} = 400,\n$$\n$$\nV_{max}([S_{up}]) = 0.100 \\cdot \\frac{400}{2 \\cdot 16 \\cdot 2} = 0.100 \\cdot \\frac{400}{64} = 0.625.\n$$\n检验稳态一致性：\n$$\nk_{basal} + V_{max}\\frac{P_{up}^{2}}{K^{2} + P_{up}^{2}} - \\gamma P_{up} = 0.075 + 0.625 \\cdot \\frac{4}{20} - 0.100 \\cdot 2.00 = 0.075 + 0.125 - 0.200 = 0,\n$$\n确认条件得到满足。\n\n最后，使用 $V_{peak} = 2.00$ 和 $K_{S} = 10.0$ 求解 $[S]_{up}$：\n$$\n[S]_{up} = \\frac{K_{S} V_{max}([S_{up}])}{V_{peak} - V_{max}([S_{up}])} = \\frac{10.0 \\cdot 0.625}{2.00 - 0.625} = \\frac{6.25}{1.375} = \\frac{50}{11} \\approx 4.54545.\n$$\n四舍五入到三位有效数字，$[S]_{up} = 4.55$，单位符合要求。", "answer": "$$\\boxed{4.55}$$", "id": "2037230"}, {"introduction": "在单个开关的基础上，一个记忆模块在真实世界中的表现很大程度上取决于其被整合到的局部基因组环境。该实践深入探讨了位置效应的生物物理机制，特别是DNA超螺旋和转录干扰，并对它们如何影响启动子活性进行建模 [@problem_id:2734336]。通过这个计算练习，你将能够预测记忆装置在不同基因组位置的可靠性，这是稳健地工程化基因线路的一项关键技能。", "problem": "设计一个程序，该程序模拟基因组整合环境如何通过局部DNA超螺旋和转录干扰来调节转录起始，然后预测双稳态记忆在有限观察时间内的可靠性。该系统由两个启动子组成，分别表示为启动子A和启动子B，形成一个对称的双态记忆（例如，相互抑制或基于重组酶的锁存器）。该模型必须源于基本的生物学和物理学原理，并以开发者无需超出此处给出的定义的领域特定启发式方法即可实现的方式表达。\n\n使用以下基本依据：\n- 分子生物学中心法则（转录以由启动子可及性决定的速率产生RNA）。\n- 起始的统计热力学：转录起始速率随着有效自由能垒的降低而指数增加。\n- 双超螺旋域模型：转录中的RNA聚合酶在前方产生正超螺旋，在后方产生负超螺旋；在稳态下，来自多个来源的局部超螺旋贡献相加，并因松弛过程而随基因组距离衰减。\n- 启动子遮蔽的泊松过程：干扰性聚合酶的通过被视为具有平均到达通量的泊松过程；启动子在遮蔽窗口内无事件概率相等的时间比例内是自由的。\n- 作为恒定风险下生存的双态可靠性：到时间 $T$ 为止不发生翻转的概率是速率等于自发翻转速率的泊松过程的生存函数。\n\n模型规范：\n1) 启动子 $X \\in \\{\\mathrm{A}, \\mathrm{B}\\}$ 处的局部超螺旋密度为\n$$\\sigma_X = \\sigma_0 + \\sum_{j=1}^{n_X} \\left( \\xi \\, r_{j,X} \\, e^{-d_{j,X}/\\ell} \\, o_{j,X} \\right),$$\n其中 $\\sigma_0$ 是背景超螺旋密度（无量纲），$\\xi$ 是一个比例常数（单位为超螺旋密度每 $\\mathrm{s}^{-1}$），$r_{j,X}$ 是邻居 $j$ 的转录起始速率（单位为 $\\mathrm{s}^{-1}$），$d_{j,X}$ 是从邻居 $j$ 到启动子 $X$ 的基因组距离（单位为碱基对），$\\ell$ 是特征衰减长度（单位为碱基对），而 $o_{j,X} \\in \\{-1,+1\\}$ 是一个方向/符号因子，编码邻居是在启动子处沉积净负超螺旋（$-1$）还是净正超螺旋（$+1$）。\n\n2) 启动子 $X$ 处的内在起始速率（无遮蔽时）为\n$$r_{i,X} = r_{\\mathrm{base},X} \\, \\exp\\!\\left(-\\kappa \\, \\sigma_X\\right),$$\n其中 $r_{\\mathrm{base},X}$ 是零超螺旋下的基线起始速率（单位为 $\\mathrm{s}^{-1}$），$\\kappa$ 是一个无量纲的敏感度常数。负超螺旋（$\\sigma_X  0$）降低了能垒并增加了 $r_{i,X}$。\n\n3) 转录干扰被建模为由穿过启动子 $X$ 的RNA聚合酶的干扰通量 $J_X$（单位为 $\\mathrm{s}^{-1}$）引起的启动子遮蔽。有效起始速率变为\n$$r_{\\mathrm{eff},X} = r_{i,X} \\, \\exp\\!\\left(-\\tau \\, J_X\\right),$$\n其中 $\\tau$ 是每次通过的遮蔽时间（单位为 $\\mathrm{s}$）。干扰通量为\n$$J_X = r_{\\mathrm{int},X} \\, f_X \\, \\exp\\!\\left(-d_{\\mathrm{int},X}/\\lambda_{\\mathrm{occ}}\\right),$$\n其中 $r_{\\mathrm{int},X}$ 是干扰启动子的起始速率（单位为 $\\mathrm{s}^{-1}$），$f_X \\in [0,1]$ 是到达启动子 $X$ 的通读分数（无量纲），$d_{\\mathrm{int},X}$ 是从干扰启动子到 $X$ 的距离（单位为碱基对），以及 $\\lambda_{\\mathrm{occ}}$ 是遍历概率的特征衰减长度（单位为碱基对）。\n\n4) 状态 $X$ 的自发翻转速率被建模为\n$$k_{\\mathrm{flip},X} = k_0 \\, \\exp\\!\\left(-\\eta \\, r_{\\mathrm{eff},X}\\right),$$\n其中 $k_0$ 是一个基线翻转速率（单位为 $\\mathrm{s}^{-1}$），$\\eta$ 是一个敏感度常数（单位为 $\\mathrm{s}$），它捕捉了增加的稳定表达如何降低翻转风险。\n\n5) 如果记忆以相等的先验概率存储任一状态，并且风险是时间均匀的，则在时间范围 $T$（单位为 $\\mathrm{s}$）内的可靠性为\n$$R = \\tfrac{1}{2} \\left[\\exp\\!\\left(-k_{\\mathrm{flip},\\mathrm{A}} \\, T\\right) + \\exp\\!\\left(-k_{\\mathrm{flip},\\mathrm{B}} \\, T\\right)\\right],$$\n这是在两个可能的存储状态下不发生翻转的平均生存概率。\n\n单位与常数：\n- 所有速率 $r$ 和 $k$ 的单位均为 $\\mathrm{s}^{-1}$。\n- 距离 $d$ 和 $d_{\\mathrm{int}}$ 的单位均为碱基对。\n- 时间常数 $\\tau$、$\\eta$ 和时间范围 $T$ 的单位均为 $\\mathrm{s}$。\n- 超螺旋密度 $\\sigma$ 是无量纲的。\n对所有测试用例使用以下固定常数：\n- $\\sigma_0 = -0.055$,\n- $\\kappa = 25.0$,\n- $\\xi = 0.01$,\n- $\\ell = 1500.0$,\n- $\\tau = 1.5$,\n- $\\lambda_{\\mathrm{occ}} = 800.0$,\n- $k_0 = 1.0 \\times 10^{-4}$,\n- $\\eta = 10.0$。\n\n每个测试用例的输入规范：\n- 启动子 A 参数：$r_{\\mathrm{base},\\mathrm{A}}$、邻居列表 $\\{(r_{j,\\mathrm{A}}, d_{j,\\mathrm{A}}, o_{j,\\mathrm{A}})\\}_{j=1}^{n_\\mathrm{A}}$ 和干扰集 $(r_{\\mathrm{int},\\mathrm{A}}, d_{\\mathrm{int},\\mathrm{A}}, f_\\mathrm{A})$。\n- 启动子 B 参数：$r_{\\mathrm{base},\\mathrm{B}}$、邻居列表 $\\{(r_{j,\\mathrm{B}}, d_{j,\\mathrm{B}}, o_{j,\\mathrm{B}})\\}_{j=1}^{n_\\mathrm{B}}$ 和干扰集 $(r_{\\mathrm{int},\\mathrm{B}}, d_{\\mathrm{int},\\mathrm{B}}, f_\\mathrm{B})$。\n- 时间范围 $T$。\n\n您的程序必须为每个测试用例计算 $R$ 并输出结果。\n\n测试套件：\n使用以下参数提供恰好 $5$ 个测试用例。\n\n- 测试用例 1（中等负超螺旋和轻度干扰，$T = 3600.0$）：\n  - 启动子 A：$r_{\\mathrm{base},\\mathrm{A}} = 0.05$，邻居 $\\{(0.3, 600, -1)\\}$，干扰 $(0.4, 500, 0.2)$。\n  - 启动子 B：$r_{\\mathrm{base},\\mathrm{B}} = 0.05$，邻居 $\\{(0.2, 800, -1)\\}$，干扰 $(0.3, 700, 0.15)$。\n  - $T = 3600.0$。\n\n- 测试用例 2（A 存在强正超螺旋和遮蔽，B 条件有利，$T = 3600.0$）：\n  - 启动子 A：$r_{\\mathrm{base},\\mathrm{A}} = 0.05$，邻居 $\\{(0.6, 300, +1), (0.5, 500, +1)\\}$，干扰 $(1.0, 200, 0.6)$。\n  - 启动子 B：$r_{\\mathrm{base},\\mathrm{B}} = 0.05$，邻居 $\\{(0.4, 1000, -1)\\}$，干扰 $(0.2, 900, 0.1)$。\n  - $T = 3600.0$。\n\n- 测试用例 3（无邻居，无干扰，$T = 3600.0$）：\n  - 启动子 A：$r_{\\mathrm{base},\\mathrm{A}} = 0.05$，邻居 $\\{\\}$，干扰 $(0.0, 1000, 0.0)$。\n  - 启动子 B：$r_{\\mathrm{base},\\mathrm{B}} = 0.05$，邻居 $\\{\\}$，干扰 $(0.0, 1000, 0.0)$。\n  - $T = 3600.0$。\n\n- 测试用例 4（距离很长导致耦合可忽略，$T = 7200.0$）：\n  - 启动子 A：$r_{\\mathrm{base},\\mathrm{A}} = 0.05$，邻居 $\\{(0.8, 5000, +1)\\}$，干扰 $(0.5, 4000, 0.1)$。\n  - 启动子 B：$r_{\\mathrm{base},\\mathrm{B}} = 0.05$，邻居 $\\{(1.0, 6000, -1)\\}$，干扰 $(0.5, 6000, 0.05)$。\n  - $T = 7200.0$。\n\n- 测试用例 5（强有益负超螺旋，无干扰，$T = 3600.0$）：\n  - 启动子 A：$r_{\\mathrm{base},\\mathrm{A}} = 0.05$，邻居 $\\{(1.2, 200, -1), (1.0, 400, -1)\\}$，干扰 $(0.0, 500, 0.0)$。\n  - 启动子 B：$r_{\\mathrm{base},\\mathrm{B}} = 0.05$，邻居 $\\{(1.2, 300, -1)\\}$，干扰 $(0.0, 500, 0.0)$。\n  - $T = 3600.0$。\n\n最终输出格式：\n您的程序应生成单行输出，其中包含可靠性结果。结果为一个以逗号分隔的十进制数列表，并用方括号括起来，每个可靠性值四舍五入到恰好六位小数，并与测试用例的顺序相同。例如，包含三个假设结果的输出必须如下所示：\n\"[0.912345,0.876543,0.999000]\"。", "solution": "问题陈述经过验证并被确定为有效。它是自洽的，提供了一整套方程、参数和常数。该模型在计算上是适定的，对于每组输入都会得到唯一的解。其基本原理在分子生物学和生物物理学中有坚实的科学基础，特别是双超螺旋域模型、转录的统计力学以及随机分子事件的泊松过程建模。其中没有逻辑矛盾、事实错误或含糊不清之处。因此，我将着手构建解决方案。\n\n目标是计算双稳态基因记忆系统在时间范围 $T$ 内的可靠性 $R$。可靠性由其两个状态（由启动子A和B代表）的稳定性决定。每个状态的稳定性由一个自发翻转速率 $k_{\\mathrm{flip},X}$ 来量化，其中 $X \\in \\{A, B\\}$。计算遵循一个清晰的因果链，从基因组环境到最终的系统可靠性，我将详细说明如下。\n\n首先，对于每个启动子 $X$，我们必须计算局部DNA超螺旋密度 $\\sigma_X$。它是一个背景超螺旋 $\\sigma_0$ 与来自 $n_X$ 个邻近转录基因的贡献之和。公式为：\n$$\n\\sigma_X = \\sigma_0 + \\sum_{j=1}^{n_X} \\left( \\xi \\, r_{j,X} \\, e^{-d_{j,X}/\\ell} \\, o_{j,X} \\right)\n$$\n在此，$\\xi$ 是一个比例常数，$r_{j,X}$ 是邻居 $j$ 的转录速率，$d_{j,X}$ 是到它的基因组距离，$\\ell$ 是超螺旋的特征衰减长度，而 $o_{j,X}$ 是一个方向因子（$+1$ 代表正超螺旋，$-1$ 代表负超螺旋）。\n\n其次，局部超螺旋密度 $\\sigma_X$ 直接影响启动子的内在转录起始速率 $r_{i,X}$。DNA解旋是转录起始的一部分，因此负超螺旋（$\\sigma_X  0$）通常会增强这一过程。该模型通过指数依赖关系来捕捉这一点：\n$$\nr_{i,X} = r_{\\mathrm{base},X} \\, \\exp(-\\kappa \\, \\sigma_X)\n$$\n其中 $r_{\\mathrm{base},X}$ 是零超螺旋下的基线速率，$\\kappa$ 是启动子对超螺旋的敏感度。\n\n第三，我们考虑转录干扰。穿过启动子 $X$ 的RNA聚合酶通量 $J_X$ 会遮蔽它，阻止其自身的机制结合。这个干扰通量被建模为：\n$$\nJ_X = r_{\\mathrm{int},X} \\, f_X \\, \\exp(-d_{\\mathrm{int},X}/\\lambda_{\\mathrm{occ}})\n$$\n其中 $r_{\\mathrm{int},X}$ 是干扰启动子的速率，$f_X$ 是通读至启动子 $X$ 的转录本分数，$d_{\\mathrm{int},X}$ 是距离，而 $\\lambda_{\\mathrm{occ}}$ 是聚合酶到达启动子 $X$ 概率的衰减长度。\n\n第四，超螺旋和干扰的综合效应产生有效起始速率 $r_{\\mathrm{eff},X}$。遮蔽效应将内在速率 $r_{i,X}$ 乘以一个对应于启动子未被遮蔽的概率的因子。这被建模为泊松过程：\n$$\nr_{\\mathrm{eff},X} = r_{i,X} \\, \\exp(-\\tau \\, J_X)\n$$\n其中 $\\tau$ 是每次干扰聚合酶通过时启动子被遮蔽的特征时间。\n\n第五，由启动子 $X$ 维持的记忆状态的稳定性与其有效表达速率 $r_{\\mathrm{eff},X}$ 成反比。更高的表达会加强该状态，降低其翻转的概率。这被建模为一个恒定风险，即自发翻转速率 $k_{\\mathrm{flip},X}$：\n$$\nk_{\\mathrm{flip},X} = k_0 \\, \\exp(-\\eta \\, r_{\\mathrm{eff},X})\n$$\n其中 $k_0$ 是一个基线翻转速率，$\\eta$ 是一个量化表达稳定效应的敏感度常数。\n\n最后，有了两个状态的翻转速率 $k_{\\mathrm{flip},A}$ 和 $k_{\\mathrm{flip},B}$，我们就可以计算在时间范围 $T$ 内的整个系统可靠性 $R$。假设初始时每个状态的可能性相等，则可靠性是平均生存概率：\n$$\nR = \\frac{1}{2} \\left[\\exp(-k_{\\mathrm{flip},A} \\, T) + \\exp(-k_{\\mathrm{flip},B} \\, T)\\right]\n$$\n这就完成了计算序列。所提供的程序为每个给定的测试用例实现了这些步骤，使用指定的常数来生成最终的可靠性值列表。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the problem of calculating memory reliability in a biological system.\n    \"\"\"\n    \n    # Define fixed constants from the problem statement\n    SIGMA_0 = -0.055\n    KAPPA = 25.0\n    XI = 0.01\n    L_DECAY = 1500.0\n    TAU = 1.5\n    LAMBDA_OCC = 800.0\n    K0 = 1.0e-4\n    ETA = 10.0\n\n    def calculate_k_flip(r_base, neighbors, interference_params):\n        \"\"\"\n        Calculates the spontaneous flip rate for a single promoter.\n\n        Args:\n            r_base (float): Baseline initiation rate.\n            neighbors (list): List of tuples for supercoiling neighbors.\n                              Each tuple is (r_j, d_j, o_j).\n            interference_params (tuple): Parameters for transcriptional interference.\n                                         Tuple is (r_int, d_int, f).\n\n        Returns:\n            float: The calculated spontaneous flip rate k_flip.\n        \"\"\"\n        # Step 1: Calculate local supercoiling density sigma_X\n        supercoiling_sum = 0.0\n        for r_j, d_j, o_j in neighbors:\n            supercoiling_sum += XI * r_j * np.exp(-d_j / L_DECAY) * o_j\n        sigma_x = SIGMA_0 + supercoiling_sum\n\n        # Step 2: Calculate intrinsic initiation rate r_i,X\n        r_i_x = r_base * np.exp(-KAPPA * sigma_x)\n\n        # Step 3: Calculate interfering flux J_X\n        r_int_x, d_int_x, f_x = interference_params\n        j_x = r_int_x * f_x * np.exp(-d_int_x / LAMBDA_OCC)\n\n        # Step 4: Calculate effective initiation rate r_eff,X\n        r_eff_x = r_i_x * np.exp(-TAU * j_x)\n\n        # Step 5: Calculate spontaneous flip rate k_flip,X\n        k_flip_x = K0 * np.exp(-ETA * r_eff_x)\n        \n        return k_flip_x\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # Test case 1\n        {\n            \"A\": {\"r_base\": 0.05, \"neighbors\": [(0.3, 600, -1)], \"interfering\": (0.4, 500, 0.2)},\n            \"B\": {\"r_base\": 0.05, \"neighbors\": [(0.2, 800, -1)], \"interfering\": (0.3, 700, 0.15)},\n            \"T\": 3600.0\n        },\n        # Test case 2\n        {\n            \"A\": {\"r_base\": 0.05, \"neighbors\": [(0.6, 300, 1), (0.5, 500, 1)], \"interfering\": (1.0, 200, 0.6)},\n            \"B\": {\"r_base\": 0.05, \"neighbors\": [(0.4, 1000, -1)], \"interfering\": (0.2, 900, 0.1)},\n            \"T\": 3600.0\n        },\n        # Test case 3\n        {\n            \"A\": {\"r_base\": 0.05, \"neighbors\": [], \"interfering\": (0.0, 1000, 0.0)},\n            \"B\": {\"r_base\": 0.05, \"neighbors\": [], \"interfering\": (0.0, 1000, 0.0)},\n            \"T\": 3600.0\n        },\n        # Test case 4\n        {\n            \"A\": {\"r_base\": 0.05, \"neighbors\": [(0.8, 5000, 1)], \"interfering\": (0.5, 4000, 0.1)},\n            \"B\": {\"r_base\": 0.05, \"neighbors\": [(1.0, 6000, -1)], \"interfering\": (0.5, 6000, 0.05)},\n            \"T\": 7200.0\n        },\n        # Test case 5\n        {\n            \"A\": {\"r_base\": 0.05, \"neighbors\": [(1.2, 200, -1), (1.0, 400, -1)], \"interfering\": (0.0, 500, 0.0)},\n            \"B\": {\"r_base\": 0.05, \"neighbors\": [(1.2, 300, -1)], \"interfering\": (0.0, 500, 0.0)},\n            \"T\": 3600.0\n        }\n    ]\n\n    results = []\n    for case in test_cases:\n        # Calculate k_flip for Promoter A\n        params_A = case[\"A\"]\n        k_flip_A = calculate_k_flip(\n            params_A[\"r_base\"], params_A[\"neighbors\"], params_A[\"interfering\"]\n        )\n\n        # Calculate k_flip for Promoter B\n        params_B = case[\"B\"]\n        k_flip_B = calculate_k_flip(\n            params_B[\"r_base\"], params_B[\"neighbors\"], params_B[\"interfering\"]\n        )\n        \n        # Get time horizon T\n        T = case[\"T\"]\n\n        # Step 6: Calculate reliability R\n        reliability = 0.5 * (np.exp(-k_flip_A * T) + np.exp(-k_flip_B * T))\n        results.append(reliability)\n\n    # Final print statement in the exact required format.\n    formatted_results = [f\"{r:.6f}\" for r in results]\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```", "id": "2734336"}, {"introduction": "记忆系统的最终目的是准确记录并允许我们检索关于过去事件的信息。这个问题将从输入信号到充满噪声的实验读数的整个过程视为一个信息通道，并可以用隐马尔可夫模型（Hidden Markov Model, HMM）进行建模 [@problem_id:2734309]。通过实现前向-后向算法，你将学习如何进行统计推断，以解码最可能的输入历史，从而将原始观测数据转化为有意义的历史信息。", "problem": "您正在为一个基因组编辑生物记忆设备建模，其中细胞在每个离散时间步的分子输入是隐藏的，但会通过在基因组位点上累积的编辑留下记录。该系统由一个离散时间概率模型描述，该模型包含两个隐藏过程：一个二元输入过程和一个二元记忆状态过程。观测值是每次是否检测到编辑的读数。您需要从第一性原理出发，推导出计算给定观测值的输入过程的后验边缘概率所需的前向和后向递归，然后实现一个程序，将这些递归应用于指定的测试套件。最终的程序输出必须是单行，包含每个测试用例的解码后输入序列列表。\n\n模型说明。时间从 $t=1$ 到 $t=T$。隐藏输入过程为 $I_t \\in \\{0,1\\}$，其中 $I_t=1$ 表示外部输入存在，$I_t=0$ 表示其不存在。隐藏记忆状态为 $S_t \\in \\{0,1\\}$，其中 $S_t=0$ 表示未编辑的位点，$S_t=1$ 表示已编辑的位点。观测值为 $O_t \\in \\{0,1\\}$，其中 $O_t=1$ 表示在测序中检测到编辑，$O_t=0$ 表示未检测到编辑。第一个时间步之前的初始记忆状态几乎必然固定为 $S_0=0$。\n\n该模型遵循以下条件独立性和因式分解，这些都基于隐马尔可夫模型和动态贝叶斯网络的标准假设：输入过程是一个一阶马尔可夫链，其转移矩阵为 $A_I$，初始分布为 $\\pi_I$；记忆状态的转移取决于当前输入和前一个记忆状态；观测值仅取决于当前记忆状态。形式上，\n- $P(I_1=i) = \\pi_I[i]$ 且 $P(I_t=i \\mid I_{t-1}=j) = A_I[j,i]$，对于 $t \\ge 2$。\n- $P(S_t \\mid S_{t-1}, I_t)$ 由一个输入调制的、生物学上现实的不可逆编辑过程指定：一旦编辑，位点将保持编辑状态。具体来说，对于 $S_{t-1}=0$，$P(S_t=1 \\mid S_{t-1}=0, I_t=0) = p_{\\mathrm{off}}$ 且 $P(S_t=1 \\mid S_{t-1}=0, I_t=1) = p_{\\mathrm{on}}$，且对于 $i \\in \\{0,1\\}$，$P(S_t=0 \\mid S_{t-1}=0, I_t=i) = 1 - P(S_t=1 \\mid S_{t-1}=0, I_t=i)$。对于 $S_{t-1}=1$，$P(S_t=1 \\mid S_{t-1}=1, I_t=i) = 1$ 对两个 $i \\in \\{0,1\\}$ 均成立。\n- 在给定记忆状态的情况下，观测值是由跨时间独立的测序噪声生成的：$P(O_t=1 \\mid S_t=1) = q$ 且 $P(O_t=1 \\mid S_t=0) = r$，且对于 $s \\in \\{0,1\\}$，$P(O_t=0 \\mid S_t=s) = 1 - P(O_t=1 \\mid S_t=s)$。\n\n任务。\n1. 仅使用概率的乘法法则、全概率定律、贝叶斯法则以及上述规定的马尔可夫性质，推导出用于计算每个 $t \\in \\{1,\\dots,T\\}$ 和 $i \\in \\{0,1\\}$ 的平滑后验边缘概率 $P(I_t=i \\mid O_{1:T})$ 的前向和后向递归，其中 $O_{1:T}$ 表示观测序列。您的推导不得假设任何预先陈述的隐马尔可夫模型公式；它必须从这些基本原理出发。推导应以联合隐过程 $(S_t, I_t)$ 和给定的条件分布来表示。\n2. 设计一种算法，该算法能够以数值稳定性的方式实现这些递归，适用于任意 $T$，并使用缩放或对数变换来避免下溢。您的算法应生成由 $\\hat{I}_t = \\arg\\max_{i \\in \\{0,1\\}} P(I_t=i \\mid O_{1:T})$ 定义的每个时间点 $t$ 的解码输入历史。\n3. 将该算法实现为一个程序，该程序在下面提供的测试套件上运行，并以单行列表的形式输出解码后的输入历史。不涉及物理单位。所有概率必须表示为 $[0,1]$ 范围内的十进制数。\n\n测试套件。对于每个测试用例，您将获得 $T$、输入转移矩阵 $A_I$、输入先验 $\\pi_I$、记忆转移编辑概率 $p_{\\mathrm{off}}$ 和 $p_{\\mathrm{on}}$、观测参数 $q$ 和 $r$，以及观测序列 $O_{1:T}$。\n\n- 测试用例 1：\n  - $T=6$\n  - $A_I = \\begin{bmatrix} 0.95  0.05 \\\\ 0.10  0.90 \\end{bmatrix}$\n  - $\\pi_I = \\begin{bmatrix} 0.90  0.10 \\end{bmatrix}$\n  - $p_{\\mathrm{off}} = 0.01$, $p_{\\mathrm{on}} = 0.20$\n  - $q = 0.95$, $r = 0.05$\n  - $O_{1:6} = [0,0,1,1,1,1]$\n- 测试用例 2：\n  - $T=4$\n  - $A_I = \\begin{bmatrix} 0.98  0.02 \\\\ 0.02  0.98 \\end{bmatrix}$\n  - $\\pi_I = \\begin{bmatrix} 0.95  0.05 \\end{bmatrix}$\n  - $p_{\\mathrm{off}} = 0.005$, $p_{\\mathrm{on}} = 0.15$\n  - $q = 0.98$, $r = 0.02$\n  - $O_{1:4} = [0,0,0,0]$\n- 测试用例 3：\n  - $T=5$\n  - $A_I = \\begin{bmatrix} 0.90  0.10 \\\\ 0.10  0.90 \\end{bmatrix}$\n  - $\\pi_I = \\begin{bmatrix} 0.50  0.50 \\end{bmatrix}$\n  - $p_{\\mathrm{off}} = 0.001$, $p_{\\mathrm{on}} = 0.30$\n  - $q = 0.95$, $r = 0.05$\n  - $O_{1:5} = [1,1,1,1,1]$\n- 测试用例 4：\n  - $T=5$\n  - $A_I = \\begin{bmatrix} 0.90  0.10 \\\\ 0.10  0.90 \\end{bmatrix}$\n  - $\\pi_I = \\begin{bmatrix} 0.80  0.20 \\end{bmatrix}$\n  - $p_{\\mathrm{off}} = 0.05$, $p_{\\mathrm{on}} = 0.10$\n  - $q = 0.90$, $r = 0.10$\n  - $O_{1:5} = [0,1,0,1,0]$\n\n最终输出格式。您的程序应生成单行输出，其中包含四个测试用例的解码输入序列，形式为用方括号括起来的逗号分隔列表，其中每个解码序列本身是按时间顺序排列的整数 $0$ 或 $1$ 的列表。例如，对于四个用例，所需格式为 $[\\,[0,1,1],\\,[0,0],\\,[1,1,1],\\,[0,1]\\,]$。程序不得读取任何输入，也不得打印任何其他文本。每个用例的答案是解码后的整数列表，这些列表是可直接测试的。", "solution": "该问题要求推导并实现一种算法，用于从一系列带噪声的观测值 $O_{1:T}$ 中推断出隐藏的输入序列 $I_{1:T}$。该系统是一个离散时间概率模型，涉及两个耦合的隐藏过程：输入 $I_t \\in \\{0, 1\\}$ 和记忆状态 $S_t \\in \\{0, 1\\}$。这种结构是动态贝叶斯网络的一个特例，其推断任务是一个经典的平滑问题。我们将有条不紊地进行，从第一性原理的形式化推导开始。\n\n令时间 $t$ 的联合隐状态为 $X_t = (S_t, I_t)$。$X_t$ 的状态空间由 4 个状态组成：$\\{(0,0), (0,1), (1,0), (1,1)\\}$。现在的问题是，在给定观测序列 $O_{1:T}$ 的情况下，推断隐藏状态序列 $X_{1:T}$ 的 $I_t$ 分量。这可以通过使用前向-后向算法来实现，我们将从概率论的基本公理推导出该算法。\n\n**用联合状态 $X_t = (S_t, I_t)$ 表示的模型说明**\n\n1.  **初始状态概率**：$P(X_1 = (s,i))$。\n    给定固定初始条件 $S_0=0$ 以及 $I_1$ 与 $S_0$ 的独立性，我们有：\n    $$P(X_1=(s,i)) = P(S_1=s, I_1=i) = P(S_1=s \\mid I_1=i, S_0=0) P(I_1=i) = P(S_1=s \\mid S_0=0, I_1=i) \\pi_I[i]$$\n\n2.  **状态转移概率**：$P(X_t=(s,i) \\mid X_{t-1}=(s',j))$。\n    使用链式法则和指定的条件独立性：\n    $$P(X_t=(s,i) \\mid X_{t-1}=(s',j)) = P(S_t=s, I_t=i \\mid S_{t-1}=s', I_{t-1}=j)$$\n    $$= P(S_t=s \\mid I_t=i, S_{t-1}=s') P(I_t=i \\mid I_{t-1}=j)$$\n    第一项 $P(S_t=s \\mid S_{t-1}=s', I_t=i)$ 由具有概率 $p_{\\mathrm{off}}$ 和 $p_{\\mathrm{on}}$ 的不可逆编辑过程定义。第二项是输入马尔可夫链的转移 $A_I[j,i]$。\n\n3.  **观测（发射）概率**：$P(O_t=o \\mid X_t=(s,i))$。\n    观测值 $O_t$ 仅取决于记忆状态 $S_t$：\n    $$P(O_t=o \\mid X_t=(s,i)) = P(O_t=o \\mid S_t=s)$$\n    这由测序噪声参数 $q$ 和 $r$ 定义。\n\n**前向-后向算法的推导**\n\n我们的目标是计算 $P(I_t=i \\mid O_{1:T})$。我们首先找到联合平滑后验概率 $P(S_t=s, I_t=i \\mid O_{1:T})$，然后对 $S_t$ 进行边缘化。\n\n**前向递归**\n令 $\\alpha_t(s,i) \\equiv P(S_t=s, I_t=i, O_{1:t})$ 为时间 $t$ 的隐状态与截至时间 $t$ 的观测序列的联合概率。\n\n-   **初始化 ($t=1$)：**\n    根据乘法法则，并使用模型定义：\n    $$\\alpha_1(s,i) = P(O_1 \\mid S_1=s, I_1=i) P(S_1=s, I_1=i) = P(O_1 \\mid S_1=s) P(S_1=s \\mid S_0=0, I_1=i) \\pi_I[i]$$\n\n-   **递归 ($t  1$)：**\n    我们将 $\\alpha_t(s,i)$ 表示为 $\\alpha_{t-1}$ 的函数。\n    $$\\alpha_t(s,i) = P(S_t=s, I_t=i, O_{1:t}) = P(O_t \\mid S_t=s, I_t=i, O_{1:t-1}) P(S_t=s, I_t=i, O_{1:t-1})$$\n    根据条件独立性，$P(O_t \\mid S_t=s, I_t=i, O_{1:t-1}) = P(O_t \\mid S_t=s)$。对于第二项，我们对 $t-1$ 时刻的状态进行边缘化：\n    $$P(S_t=s, I_t=i, O_{1:t-1}) = \\sum_{s' \\in \\{0,1\\}} \\sum_{j \\in \\{0,1\\}} P(S_t=s, I_t=i, S_{t-1}=s', I_{t-1}=j, O_{1:t-1})$$\n    $$= \\sum_{s'} \\sum_{j} P(S_t=s, I_t=i \\mid S_{t-1}=s', I_{t-1}=j, O_{1:t-1}) P(S_{t-1}=s', I_{t-1}=j, O_{1:t-1})$$\n    状态转移与过去的观测无关，所以 $P(\\dots \\mid S_{t-1}, I_{t-1}, O_{1:t-1}) = P(S_t=s, I_t=i \\mid S_{t-1}=s', I_{t-1}=j)$。最后一项恰好是 $\\alpha_{t-1}(s',j)$。\n    将这些结合起来，得到递归式：\n    $$\\alpha_t(s,i) = P(O_t \\mid S_t=s) \\sum_{s'} \\sum_{j} P(S_t=s \\mid S_{t-1}=s', I_t=i) P(I_t=i \\mid I_{t-1}=j) \\alpha_{t-1}(s',j)$$\n\n**后向递归**\n令 $\\beta_t(s,i) \\equiv P(O_{t+1:T} \\mid S_t=s, I_t=i)$ 为给定时间 $t$ 的状态下，未来观测序列的概率。\n\n-   **初始化 ($t=T$)：**\n    未来的观测序列为空，这是一个概率为 $1$ 的事件。\n    $$\\beta_T(s,i) = 1 \\quad \\forall s,i$$\n\n-   **递归 ($t  T$)：**\n    我们通过对 $t+1$ 时刻的状态进行边缘化，将 $\\beta_t(s,i)$ 表示为 $\\beta_{t+1}$ 的函数：\n    $$\\beta_t(s,i) = \\sum_{s''} \\sum_{k} P(O_{t+1:T}, S_{t+1}=s'', I_{t+1}=k \\mid S_t=s, I_t=i)$$\n    $$= \\sum_{s''} \\sum_{k} P(O_{t+1:T} \\mid S_{t+1}=s'', I_{t+1}=k, S_t=s, I_t=i) P(S_{t+1}=s'', I_{t+1}=k \\mid S_t=s, I_t=i)$$\n    根据模型的马尔可夫性质，给定当前状态，未来的观测与过去的状态无关。\n    $$P(O_{t+1:T} \\mid \\dots) = P(O_{t+1} \\mid S_{t+1}=s'') P(O_{t+2:T} \\mid S_{t+1}=s'', I_{t+1}=k) = P(O_{t+1} \\mid S_{t+1}=s'') \\beta_{t+1}(s'',k)$$\n    第二项是状态转移概率。结合起来得到：\n    $$\\beta_t(s,i) = \\sum_{s''} \\sum_{k} \\beta_{t+1}(s'',k) P(O_{t+1} \\mid S_{t+1}=s'') P(S_{t+1}=s'' \\mid S_t=s, I_{t+1}=k) P(I_{t+1}=k \\mid I_t=i)$$\n\n**平滑后验概率计算**\n联合隐状态的平滑后验概率 $\\gamma_t(s,i) = P(S_t=s, I_t=i \\mid O_{1:T})$ 由下式给出：\n$$\\gamma_t(s,i) = \\frac{P(S_t=s, I_t=i, O_{1:T})}{P(O_{1:T})} = \\frac{P(O_{t+1:T} \\mid S_t=s, I_t=i, O_{1:t}) P(S_t=s, I_t=i, O_{1:t})}{P(O_{1:T})}$$\n使用条件独立性，$P(O_{t+1:T} \\mid \\dots) = P(O_{t+1:T} \\mid S_t=s, I_t=i) = \\beta_t(s,i)$。另一项是 $\\alpha_t(s,i)$。\n因此，$P(S_t=s, I_t=i, O_{1:T}) = \\alpha_t(s,i) \\beta_t(s,i)$。证据的似然为 $P(O_{1:T}) = \\sum_{s'} \\sum_{j'} \\alpha_T(s',j')$。\n后验概率为：\n$$\\gamma_t(s,i) = \\frac{\\alpha_t(s,i) \\beta_t(s,i)}{\\sum_{s'} \\sum_{j'} \\alpha_t(s', j') \\beta_t(s', j')}$$\n最后，我们通过对记忆状态求和来获得输入的边缘后验概率：\n$$P(I_t=i \\mid O_{1:T}) = \\sum_{s \\in \\{0,1\\}} \\gamma_t(s,i)$$\n解码后的输入则为 $\\hat{I}_t = \\arg\\max_{i \\in \\{0,1\\}} P(I_t=i \\mid O_{1:T})$。\n\n**数值稳定性**\n直接计算 $\\alpha_t$ 和 $\\beta_t$ 很容易出现数值下溢，因为概率会随着时间累乘。我们引入缩放因子。定义缩放后的前向概率 $\\hat{\\alpha}_t(s,i) = P(S_t=s, I_t=i \\mid O_{1:t})$。递归关系保持不变，但在每一步之后，值都会被归一化。令 $c_t = P(O_t \\mid O_{1:t-1})$ 为缩放因子。\n-   **前向传递**：使用带有 $\\hat{\\alpha}_{t-1}$ 的递归计算临时的未缩放 $\\alpha'_t(s,i)$，然后找到 $c_t = \\sum_{s,i} \\alpha'_t(s,i)$，最后设置 $\\hat{\\alpha}_t(s,i) = \\alpha'_t(s,i) / c_t$。\n-   **后向传递**：使用递归 $\\hat{\\beta}_t(s,i) = \\frac{1}{c_{t+1}} \\sum_{s'',k} \\dots \\hat{\\beta}_{t+1}(s'',k)$ 计算缩放后的后向变量 $\\hat{\\beta}_t(s,i)$。\n平滑后验概率随后与缩放量的乘积成正比：$\\gamma_t(s,i) \\propto \\hat{\\alpha}_t(s,i) \\hat{\\beta}_t(s,i)$。在每个时间步 $t$ 对该乘积进行归一化，即可得到正确的平滑分布。\n此过程是前向-后向算法的一种标准且数值稳健的实现。", "answer": "```python\nimport numpy as np\n\ndef run_fwd_bwd(T, A_I, pi_I, p_off, p_on, q, r, O):\n    \"\"\"\n    Implements the scaled forward-backward algorithm to decode the hidden input sequence.\n\n    Args:\n        T (int): Length of the sequence.\n        A_I (np.ndarray): Input transition matrix, shape (2, 2).\n        pi_I (np.ndarray): Initial input distribution, shape (2,).\n        p_off (float): Edit probability when input is off.\n        p_on (float): Edit probability when input is on.\n        q (float): True positive rate for observation (P(O=1|S=1)).\n        r (float): False positive rate for observation (P(O=1|S=0)).\n        O (list or np.ndarray): Observation sequence of length T.\n\n    Returns:\n        list: The decoded input sequence.\n    \"\"\"\n    # State representation: S_t in {0, 1}, I_t in {0, 1}\n    # We use 2x2 matrices for alpha, beta, where rows are S_t and cols are I_t.\n\n    # 1. Pre-compute model parameter matrices\n    # Memory transition tensor A_S[i, s_prev, s_curr] = P(S_t=s_curr | S_{t-1}=s_prev, I_t=i)\n    A_S = np.zeros((2, 2, 2))\n    A_S[0, 0, 0] = 1 - p_off  # I=0, S_prev=0 - S_curr=0\n    A_S[0, 0, 1] = p_off      # I=0, S_prev=0 - S_curr=1\n    A_S[0, 1, 0] = 0          # I=0, S_prev=1 - S_curr=0 (irreversible)\n    A_S[0, 1, 1] = 1          # I=0, S_prev=1 - S_curr=1\n    A_S[1, 0, 0] = 1 - p_on   # I=1, S_prev=0 - S_curr=0\n    A_S[1, 0, 1] = p_on       # I=1, S_prev=0 - S_curr=1\n    A_S[1, 1, 0] = 0          # I=1, S_prev=1 - S_curr=0 (irreversible)\n    A_S[1, 1, 1] = 1          # I=1, S_prev=1 - S_curr=1\n\n    # Observation matrix B[s, o] = P(O_t=o | S_t=s)\n    B = np.array([[1 - r, r], [1 - q, q]])\n\n    # 2. Forward pass (filtering)\n    alpha = np.zeros((T, 2, 2))  # alpha[t, s, i]\n    c = np.zeros(T)  # scaling factors c[t] = P(O_{t+1} | O_{1:t})\n\n    # Initialization (t=0, corresponding to time step 1)\n    # S_0 is fixed to 0\n    alpha_unscaled = np.zeros((2, 2))\n    o1 = O[0]\n    for s in range(2):\n        for i in range(2):\n            alpha_unscaled[s, i] = B[s, o1] * A_S[i, 0, s] * pi_I[i]\n    \n    c[0] = np.sum(alpha_unscaled)\n    if c[0] > 0:\n        alpha[0] = alpha_unscaled / c[0]\n\n    # Recursion (t=1 to T-1)\n    for t in range(1, T):\n        alpha_unscaled_t = np.zeros((2, 2))\n        ot = O[t]\n        for s_curr in range(2):\n            for i in range(2):\n                sum_prev = 0\n                for s_prev in range(2):\n                    for j in range(2):\n                        sum_prev += alpha[t - 1, s_prev, j] * A_I[j, i] * A_S[i, s_prev, s_curr]\n                alpha_unscaled_t[s_curr, i] = B[s_curr, ot] * sum_prev\n        \n        c[t] = np.sum(alpha_unscaled_t)\n        if c[t] > 0:\n            alpha[t] = alpha_unscaled_t / c[t]\n\n    # 3. Backward pass\n    beta = np.zeros((T, 2, 2)) # beta[t, s, i]\n    \n    # Initialization (t=T-1, corresponding to time step T)\n    beta[T - 1] = 1.0\n\n    # Recursion (t=T-2 down to 0)\n    for t in range(T - 2, -1, -1):\n        beta_unscaled_t = np.zeros((2, 2))\n        ot_plus_1 = O[t + 1]\n        for s_prev in range(2):\n            for j in range(2):\n                sum_next = 0\n                for s_curr in range(2):\n                    for i in range(2):\n                        sum_next += beta[t + 1, s_curr, i] * B[s_curr, ot_plus_1] * A_S[i, s_prev, s_curr] * A_I[j, i]\n                beta_unscaled_t[s_prev, j] = sum_next\n        \n        if c[t+1] > 0:\n            beta[t] = beta_unscaled_t / c[t+1]\n\n    # 4. Smoothing and Decoding\n    decoded_I = []\n    for t in range(T):\n        gamma_unscaled = alpha[t] * beta[t]\n        gamma_t = gamma_unscaled / np.sum(gamma_unscaled) # Normalization\n        \n        # Marginalize over S_t to get P(I_t | O_{1:T})\n        p_I_t = np.sum(gamma_t, axis=0) # Sum over s\n        \n        # Decode\n        decoded_I.append(int(np.argmax(p_I_t)))\n        \n    return decoded_I\n\n\ndef solve():\n    \"\"\"\n    Defines the test suites and runs the forward-backward algorithm for each case.\n    \"\"\"\n    test_cases = [\n        {\n            \"T\": 6,\n            \"A_I\": np.array([[0.95, 0.05], [0.10, 0.90]]),\n            \"pi_I\": np.array([0.90, 0.10]),\n            \"p_off\": 0.01, \"p_on\": 0.20,\n            \"q\": 0.95, \"r\": 0.05,\n            \"O\": [0, 0, 1, 1, 1, 1]\n        },\n        {\n            \"T\": 4,\n            \"A_I\": np.array([[0.98, 0.02], [0.02, 0.98]]),\n            \"pi_I\": np.array([0.95, 0.05]),\n            \"p_off\": 0.005, \"p_on\": 0.15,\n            \"q\": 0.98, \"r\": 0.02,\n            \"O\": [0, 0, 0, 0]\n        },\n        {\n            \"T\": 5,\n            \"A_I\": np.array([[0.90, 0.10], [0.10, 0.90]]),\n            \"pi_I\": np.array([0.50, 0.50]),\n            \"p_off\": 0.001, \"p_on\": 0.30,\n            \"q\": 0.95, \"r\": 0.05,\n            \"O\": [1, 1, 1, 1, 1]\n        },\n        {\n            \"T\": 5,\n            \"A_I\": np.array([[0.90, 0.10], [0.10, 0.90]]),\n            \"pi_I\": np.array([0.80, 0.20]),\n            \"p_off\": 0.05, \"p_on\": 0.10,\n            \"q\": 0.90, \"r\": 0.10,\n            \"O\": [0, 1, 0, 1, 0]\n        }\n    ]\n\n    results = []\n    for case in test_cases:\n        decoded_seq = run_fwd_bwd(\n            case[\"T\"], case[\"A_I\"], case[\"pi_I\"],\n            case[\"p_off\"], case[\"p_on\"],\n            case[\"q\"], case[\"r\"], case[\"O\"]\n        )\n        results.append(decoded_seq)\n\n    # Format the output as a string representation of a list of lists.\n    # The default str() for lists includes spaces, which is fine.\n    # e.g., '[[0, 1], [0, 0]]'\n    formatted_results = ','.join(map(str, results))\n    print(f\"[{formatted_results}]\")\n\nsolve()\n```", "id": "2734309"}]}