{"hands_on_practices": [{"introduction": "操作性条件反射是学习理论的基石，其核心思想是行为的后果会影响该行为在未来发生的频率。强化是一种增加行为频率的过程，但它分为两种类型：正强化（通过给予愉悦的刺激）和负强化（通过移除厌恶的刺激）。这项练习 [@problem_id:2298868] 通过一个经典的实验场景，帮助我们辨别和理解负强化，这是一个经常被误解但至关重要的概念。", "problem": "一位动物行为学家设计了一个实验来研究蒙古沙鼠的学习行为。沙鼠被放置在一个由令人不适的强光照射的实验箱中。实验箱内有一个小杠杆。最初，沙鼠在实验箱内探索，并偶尔会意外地按下杠杆，此时强光会立即熄灭30秒，然后重新亮起。几次这样的事件发生后，研究人员观察到，每当灯亮时，沙鼠开始有意识地、且越来越频繁地按压杠杆。\n\n下列哪个陈述最准确地描述了这一学习过程？\n\nA. 这是经典条件作用的一个例子，其中按压杠杆是对强光的条件反应。\n\nB. 这是操作性条件作用的一个例子，其中移除光线是一种负惩罚。\n\nC. 这是操作性条件作用的一个例子，其中移除光线是一种负强化。\n\nD. 这是印随的一个例子，其中沙鼠对杠杆形成了一种快速且不可逆的依恋。\n\nE. 这是操作性条件作用的一个例子，其中暂时的黑暗是一种正强化。\n\nF. 这是习惯化的一个例子，因为沙鼠对光刺激的反应随时间减弱。", "solution": "我们通过分析沙鼠的行为（按压杠杆）与其后果（终止一个厌恶性的强光）之间的关联来识别其学习范式。在操作性条件作用中，行为的后果会改变该行为未来的发生频率：强化会增加行为，而惩罚会减少行为。关联的符号（正与负）分别指增加刺激与移除刺激。\n\n在这里，按压杠杆导致了一个厌恶性刺激（强光）的移除。观察到的效果是，当灯亮时，按压杠杆的频率随时间增加。因此，该行为因厌恶性刺激的移除而得到加强。根据定义，这是负强化（操作性条件作用）。\n\n评估各个选项：\n- A (经典条件作用)：经典条件作用将刺激配对以引发反射性反应；按压杠杆是一个自主的操作性行为，而不是由条件刺激引发的反射，所以这是不正确的。\n- B (负惩罚)：负惩罚涉及移除一个想要的刺激以减少行为；在这里，行为增加了，并且被移除的刺激是厌恶性的，所以这是不正确的。\n- C (负强化)：在行为发生后移除一个厌恶性刺激会增加该行为的发生频率；这与情景相符，是正确的。\n- D (印随)：印随是在敏感期内发生的快速、不可逆的依恋；不适用于此。\n- E (正强化)：正强化涉及呈现一个愉悦的刺激；在这里，某物（光）被移除了，而不是增加了，所以这是不正确的。\n- F (习惯化)：习惯化是对重复刺激的反应减弱；相反，在此情景中，操作性反应因其后果而增加，所以这是不正确的。\n\n因此，最准确的描述是通过负强化进行的操作性条件作用。", "answer": "$$\\boxed{C}$$", "id": "2298868"}, {"introduction": "我们如何教动物完成它们通常不会自发进行的复杂动作，比如让狗打滚？答案在于一种被称为“塑造”或“连续渐进法”的强大技术。这个过程包括将最终的目标行为分解成一系列更小、可实现的步骤，并依次强化每一步。这项练习 [@problem_id:2298894] 提供了一个训练狗的实用例子，清晰地展示了如何将操作性条件反射的原理应用于现实世界的训练挑战中。", "problem": "一位动物行为学课程的学生决定运用其操作性条件反射的知识来训练他的狗。目标是教会狗一个它在指令下不会自然完成的复杂行为：完整的“翻滚”。该学生计划使用塑造法（也称为连续渐进法），并以食物奖励作为正强化物。这只狗已经被可靠地训练成在听到“趴下”的口头指令时会躺下。\n\n以下哪个训练计划最有效、最合逻辑地应用了塑造法原理来教狗翻滚？\n\nA. 学生说出“翻滚”的口头指令，只有当狗完成整个完整的翻滚动作时才给它零食。重复此过程，直到狗学会指令与完成动作之间的联系。\n\nB. 学生首先命令狗“趴下”。然后，用零食作为诱饵，引导狗的头朝向其肩膀，使其将重心转移到一侧臀部，并立即给予零食。一旦狗能可靠地侧躺在臀部上，学生就停止给予零食，直到狗完全侧躺。掌握此步骤后，只有当狗将重心进一步转移到背部时才给予零食，最后，只有在完成整个翻滚动作时才给予零食。只有在狗能够可靠地完成整个身体翻滚动作后，才引入“翻滚”的口头指令，使其与该动作相关联。\n\nC. 学生命令狗“趴下”。然后，他们拿着零食，反复说“翻滚”，等待狗随机偶然地完成整个翻滚动作。一旦狗完成该动作，它就会得到零食。\n\nD. 学生首先命令狗“趴下”并给它一个零食。然后，他们一边说“翻滚”，一边用手将狗推向一侧，然后再翻到另一侧，在强制移动完成后再给它一个零食。重复此过程，直到狗开始在没有被推动的情况下执行该动作。\n\nE. 学生首先奖励狗服从“趴下”的命令。然后，他们奖励狗专心看着他们手中的零食。接下来，他们奖励狗恢复到站立姿势。最后，他们试图从站立姿势教狗翻滚。", "solution": "我们应用操作性条件反射中的塑造法（连续渐进法）原理：对越来越接近目标反应的行为进行差异化强化，一旦达到新标准，就停止对先前较容易形式的行为进行强化。关键组成部分包括：从狗能够根据提示执行的现有行为（躺下）开始，在达到期望的近似行为时立即使用正强化，逐步提高标准，尽快淡化任何提示或诱饵，并在完整行为能够可靠执行后才引入语言指令，以便指令能对已建立的反应产生刺激控制。\n\n评估各个选项：\n\nA. 该选项在完整行为出现之前不给予强化，并在行为学会之前就引入了语言指令。狗仅凭语言指令就自发完成完整翻滚的概率非常低，因此这不是塑造法，而是一种低效的随机捕捉法。\n\nB. 该选项从一个已知的行为（“趴下”）开始，然后对连续的近似行为使用差异化强化：将重心转移到一侧臀部，然后侧躺，然后躺在背上，最后完成整个翻滚，一旦下一步建立起来，就停止对早期近似行为的强化。语言指令仅在完整翻滚能够可靠执行后才引入，这正确地转移了刺激控制。这是使用正强化和标准递进的塑造法的教科书式应用。\n\nC. 该选项在反复说指令的同时，等待完整的翻滚动作偶然发生。与A类似，它未能强化中间的近似行为，并且过早地引入了指令，使得学习变得不太可能且效率低下。\n\nD. 该选项使用身体提示（推动）而不是强化自愿的连续近似行为。身体操纵可以产生顺从，但狗并未学习操作性序列，因此这不是所定义的塑造法。\n\nE. 这个序列强化了偏离目标的行为（站起来），并没有构建一个朝向翻滚的渐进近似路径。相对于目标反应，这是不合逻辑的，并且没有实施塑造法。\n\n因此，唯一正确应用了塑造法，并结合了连续近似的差异化强化和正确的指令引入的选项是B。", "answer": "$$\\boxed{B}$$", "id": "2298894"}, {"introduction": "学习的背后是否有数学规律？Rescorla-Wagner 模型为我们理解经典条件反射提供了一个简洁而强大的数学框架。该模型的核心观点是，学习是由“意外”驱动的，即预期与实际发生事件之间的差异。这项练习 [@problem_id:2298875] 让你亲手计算在学习过程中联想强度的逐次变化，从而深入理解一个刺激如何通过预测奖励来获得其“价值”。", "problem": "一位行为生物学家正在使用一种称为自动塑形的程序来研究日本鹌鹑的联结学习。在这个实验中，彩色灯光的照明作为条件刺激 (CS)，预示着食物颗粒的递送，而食物颗粒是无条件刺激 (US)。灯光与食物之间的联结强度由一个“联结强度”值 $V$ 来量化。\n\n学习过程由 Rescorla-Wagner 模型描述。在单个学习试验中，刺激 $X$ 的联结强度变化 $\\Delta V_X$ 由以下公式给出：\n$$ \\Delta V_X = \\alpha_X \\beta (\\lambda - V_{total}) $$\n此处，$\\alpha_X$ 是刺激 $X$ 的显著性，$\\beta$ 是与无条件刺激相关的学习率参数，$\\lambda$ 是无条件刺激所能支持的最大可能联结强度，而 $V_{total}$ 是该试验中出现的所有刺激的联结强度之和。试验后更新的联结强度为 $V_{X, \\text{new}} = V_{X, \\text{old}} + \\Delta V_X$。\n\n在这个具体实验中，使用了两种灯光：红光 (R) 和绿光 (G)。参数定义如下：\n- 红光的显著性, $\\alpha_R = 0.5$\n- 绿光的显著性, $\\alpha_G = 0.3$\n- 食物递送的学习率参数, $\\beta = 0.4$\n- 食物所支持的最大联结强度, $\\lambda = 100$\n- 如果不递送食物，相应的 $\\lambda$ 将为 0。\n- 最初，鹌鹑对两种灯光都没有先前的联结，因此它们的初始联结强度为 $V_{R,0} = 0$ 和 $V_{G,0} = 0$。\n\n鹌鹑经历了以下四个训练试验序列：\n- **试验 1**：红光亮起，随后递送食物。\n- **试验 2**：红光亮起，随后递送食物。\n- **试验 3**：红光和绿光同时亮起，随后递送食物。\n- **试验 4**：红光和绿光同时亮起，随后递送食物。\n\n计算第四次试验结束时绿光 ($V_G$) 的联结强度。将您的最终答案四舍五入到四位有效数字。", "solution": "我们使用 Rescorla-Wagner 学习规则。对于在无条件刺激值为 $\\lambda$ 的试验中出现的任何刺激 $X$，其联结强度的变化为\n$$\n\\Delta V_{X}=\\alpha_{X}\\beta\\left(\\lambda - V_{\\text{total}}\\right),\n$$\n其中 $V_{\\text{total}}$ 是该试验中出现的所有刺激的联结强度之和，且 $V_{X,\\text{new}}=V_{X,\\text{old}}+\\Delta V_{X}$。未在试验中出现的刺激其联结强度不变。\n\n给定 $\\alpha_{R}=0.5$，$\\alpha_{G}=0.3$，$\\beta=0.4$，$\\lambda=100$，以及初始值 $V_{R,0}=0$，$V_{G,0}=0$，我们逐个试验进行计算。\n\n试验 1 (R 出现，递送食物)：$V_{\\text{total}}=V_{R,0}=0$。则\n$$\n\\Delta V_{R,1}=\\alpha_{R}\\beta(\\lambda - V_{\\text{total}})=0.5\\cdot 0.4\\cdot (100-0)=20,\n$$\n所以 $V_{R,1}=0+20=20$，且 $V_{G,1}=0$。\n\n试验 2 (R 出现，递送食物)：$V_{\\text{total}}=V_{R,1}=20$。则\n$$\n\\Delta V_{R,2}=0.5\\cdot 0.4\\cdot (100-20)=16,\n$$\n所以 $V_{R,2}=20+16=36$，且 $V_{G,2}=0$。\n\n试验 3 (R 和 G 出现，递送食物)：$V_{\\text{total}}=V_{R,2}+V_{G,2}=36+0=36$。则\n$$\n\\Delta V_{R,3}=0.5\\cdot 0.4\\cdot (100-36)=12.8,\\qquad \\Delta V_{G,3}=0.3\\cdot 0.4\\cdot (100-36)=7.68,\n$$\n所以 $V_{R,3}=36+12.8=48.8$ 且 $V_{G,3}=0+7.68=7.68$。\n\n试验 4 (R 和 G 出现，递送食物)：$V_{\\text{total}}=V_{R,3}+V_{G,3}=48.8+7.68=56.48$。则\n$$\n\\Delta V_{R,4}=0.5\\cdot 0.4\\cdot (100-56.48)=8.704,\\qquad \\Delta V_{G,4}=0.3\\cdot 0.4\\cdot (100-56.48)=5.2224,\n$$\n所以 $V_{R,4}=48.8+8.704=57.504$ 且 $V_{G,4}=7.68+5.2224=12.9024$。\n\n因此，第四次试验结束时绿光的联结强度为 $V_{G,4}=12.9024$，四舍五入到四位有效数字为 $12.90$。", "answer": "$$\\boxed{12.90}$$", "id": "2298875"}]}