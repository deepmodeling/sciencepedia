{"hands_on_practices": [{"introduction": "A successful Umbrella Sampling simulation hinges on a well-chosen set of biasing potentials, ensuring sufficient phase space overlap between neighboring windows for accurate reconstruction. This practice moves beyond heuristic rules, challenging you to derive from first principles the analytical relationship between the underlying potential, the biasing force constant, and the optimal window spacing needed to achieve a specific statistical overlap ([@problem_id:2772126]). Mastering this derivation solidifies your understanding of how thermostatistical properties govern the design of efficient enhanced sampling experiments.", "problem": "Consider a one-dimensional reaction coordinate $\\xi$ with an underlying unbiased potential of mean force (PMF) $W(\\xi)$ that is locally harmonic in the region of interest, $W(\\xi) \\approx \\frac{1}{2}\\kappa(\\xi-\\xi^{\\ast})^{2}$, where $\\kappa>0$ is a constant curvature and $\\xi^{\\ast}$ is a fixed reference position. You plan to perform umbrella sampling using a family of harmonic biasing potentials $U_{i}(\\xi)=\\frac{1}{2}k(\\xi-\\xi_{i})^{2}$, where all windows share the same force constant $k>0$ and their centers are uniformly spaced, $\\xi_{i+1}-\\xi_{i}=\\Delta$. The system is at temperature $T$, and all energies are molar (per mole). Assume canonical equilibrium within each umbrella window and that the harmonic approximation for $W(\\xi)$ holds across adjacent windows.\n\nDefine the statistical overlap between any two neighboring biased ensembles $i$ and $i+1$ by the Bhattacharyya coefficient $\\mathrm{BC}_{i,i+1}$,\n$$\n\\mathrm{BC}_{i,i+1} \\equiv \\int_{-\\infty}^{\\infty}\\sqrt{p_{i}(\\xi)\\,p_{i+1}(\\xi)}\\,d\\xi,\n$$\nwhere $p_{i}(\\xi)\\propto \\exp\\!\\big(-\\beta\\,[W(\\xi)+U_{i}(\\xi)]\\big)$ is the equilibrium probability density in window $i$ and $\\beta = (R T)^{-1}$ with $R$ the universal gas constant expressed in $\\mathrm{kJ}\\ \\mathrm{mol}^{-1}\\ \\mathrm{K}^{-1}$.\n\nStarting only from the Boltzmann distribution, the harmonic forms of $W(\\xi)$ and $U_{i}(\\xi)$, and the above definition of $\\mathrm{BC}_{i,i+1}$, derive an analytic expression for the window spacing $\\Delta$ that achieves a target overlap $\\mathrm{BC}_{i,i+1}=1/2$. Then evaluate the spacing for the following parameters:\n- $k = 10.0\\ \\mathrm{kJ}\\ \\mathrm{mol}^{-1}\\ \\mathrm{nm}^{-2}$,\n- $\\kappa = 2.00\\ \\mathrm{kJ}\\ \\mathrm{mol}^{-1}\\ \\mathrm{nm}^{-2}$,\n- $T = 300.0\\ \\mathrm{K}$,\n- $R = 8.314462618\\times 10^{-3}\\ \\mathrm{kJ}\\ \\mathrm{mol}^{-1}\\ \\mathrm{K}^{-1}$.\n\nRound your final numerical result for $\\Delta$ to four significant figures and express it in nanometers.", "solution": "The problem is subjected to validation and is found to be scientifically grounded, well-posed, and self-contained. The provided data are sufficient and consistent for deriving a unique solution. We proceed with the derivation.\n\nThe objective is to derive an expression for the window spacing, $\\Delta$, that results in a statistical overlap of $\\mathrm{BC}_{i,i+1} = 1/2$ between adjacent umbrella sampling windows, and then to compute its numerical value.\n\nFirst, we characterize the equilibrium probability density, $p_{i}(\\xi)$, for a system in the $i$-th umbrella window. The total potential energy experienced by the system in this window is the sum of the unbiased potential of mean force, $W(\\xi)$, and the biasing potential, $U_i(\\xi)$.\n$$\nV_{i}(\\xi) = W(\\xi) + U_{i}(\\xi)\n$$\nGiven the harmonic approximations for $W(\\xi)$ and $U_i(\\xi)$:\n$$\nV_{i}(\\xi) = \\frac{1}{2}\\kappa(\\xi-\\xi^{\\ast})^{2} + \\frac{1}{2}k(\\xi-\\xi_{i})^{2}\n$$\nwhere $\\kappa$ and $k$ are force constants, $\\xi^{\\ast}$ is the minimum of the unbiased PMF, and $\\xi_i$ is the center of the $i$-th biasing potential. We expand the quadratic terms:\n$$\nV_{i}(\\xi) = \\frac{1}{2}\\kappa(\\xi^2 - 2\\xi\\xi^{\\ast} + (\\xi^{\\ast})^2) + \\frac{1}{2}k(\\xi^2 - 2\\xi\\xi_i + \\xi_i^2)\n$$\n$$\nV_{i}(\\xi) = \\frac{1}{2}(\\kappa+k)\\xi^2 - (\\kappa\\xi^{\\ast} + k\\xi_i)\\xi + \\frac{1}{2}(\\kappa(\\xi^{\\ast})^2 + k\\xi_i^2)\n$$\nThis expression is a quadratic function of $\\xi$, which can be rewritten in a standard harmonic form by completing the square.\n$$\nV_{i}(\\xi) = \\frac{1}{2}(\\kappa+k)\\left(\\xi - \\frac{\\kappa\\xi^{\\ast} + k\\xi_i}{\\kappa+k}\\right)^2 + C_i\n$$\nwhere $C_i$ is a constant term that does not depend on the coordinate $\\xi$. The total potential in each window is thus harmonic with a combined force constant $k_{tot} = \\kappa+k$ and a minimum located at:\n$$\n\\mu_i = \\frac{\\kappa\\xi^{\\ast} + k\\xi_i}{\\kappa+k}\n$$\nThe equilibrium probability density $p_i(\\xi)$ follows the Boltzmann distribution, $p_i(\\xi) \\propto \\exp(-\\beta V_i(\\xi))$, where $\\beta = (RT)^{-1}$. Since $V_i(\\xi)$ is quadratic in $\\xi$, $p_i(\\xi)$ is a Gaussian (normal) distribution:\n$$\np_{i}(\\xi) = \\mathcal{N}(\\xi | \\mu_i, \\sigma_{tot}^2) = \\frac{1}{\\sqrt{2\\pi\\sigma_{tot}^2}}\\exp\\left(-\\frac{(\\xi-\\mu_i)^2}{2\\sigma_{tot}^2}\\right)\n$$\nThe variance $\\sigma_{tot}^2$ is the same for all windows and is given by:\n$$\n\\sigma_{tot}^2 = \\frac{1}{\\beta k_{tot}} = \\frac{1}{\\beta(\\kappa+k)} = \\frac{RT}{\\kappa+k}\n$$\nNext, we evaluate the Bhattacharyya coefficient, $\\mathrm{BC}_{i,i+1}$, between two adjacent windows, $i$ and $i+1$.\n$$\n\\mathrm{BC}_{i,i+1} = \\int_{-\\infty}^{\\infty}\\sqrt{p_{i}(\\xi)\\,p_{i+1}(\\xi)}\\,d\\xi\n$$\nThe integrand involves the geometric mean of two Gaussian densities with the same variance $\\sigma_{tot}^2$ but different means $\\mu_i$ and $\\mu_{i+1}$.\n$$\n\\sqrt{p_{i}(\\xi)p_{i+1}(\\xi)} = \\sqrt{\\frac{1}{2\\pi\\sigma_{tot}^2}\\exp\\left(-\\frac{(\\xi-\\mu_i)^2}{2\\sigma_{tot}^2}\\right)\\exp\\left(-\\frac{(\\xi-\\mu_{i+1})^2}{2\\sigma_{tot}^2}\\right)}\n$$\n$$\n= \\frac{1}{\\sqrt{2\\pi\\sigma_{tot}^2}}\\exp\\left(-\\frac{(\\xi-\\mu_i)^2 + (\\xi-\\mu_{i+1})^2}{4\\sigma_{tot}^2}\\right)\n$$\nThe exponent's numerator can be rearranged:\n$$\n(\\xi-\\mu_i)^2 + (\\xi-\\mu_{i+1})^2 = 2\\xi^2 - 2\\xi(\\mu_i+\\mu_{i+1}) + \\mu_i^2+\\mu_{i+1}^2 = 2\\left(\\xi-\\frac{\\mu_i+\\mu_{i+1}}{2}\\right)^2 + \\frac{1}{2}(\\mu_i-\\mu_{i+1})^2\n$$\nSubstituting this back into the expression for the geometric mean:\n$$\n\\sqrt{p_{i}(\\xi)p_{i+1}(\\xi)} = \\frac{1}{\\sqrt{2\\pi\\sigma_{tot}^2}}\\exp\\left(-\\frac{2\\left(\\xi-\\frac{\\mu_i+\\mu_{i+1}}{2}\\right)^2 + \\frac{1}{2}(\\mu_i-\\mu_{i+1})^2}{4\\sigma_{tot}^2}\\right)\n$$\n$$\n= \\exp\\left(-\\frac{(\\mu_i-\\mu_{i+1})^2}{8\\sigma_{tot}^2}\\right) \\frac{1}{\\sqrt{2\\pi\\sigma_{tot}^2}}\\exp\\left(-\\frac{\\left(\\xi-\\frac{\\mu_i+\\mu_{i+1}}{2}\\right)^2}{2\\sigma_{tot}^2}\\right)\n$$\nNow we integrate over $\\xi$ to obtain $\\mathrm{BC}_{i,i+1}$:\n$$\n\\mathrm{BC}_{i,i+1} = \\exp\\left(-\\frac{(\\mu_i-\\mu_{i+1})^2}{8\\sigma_{tot}^2}\\right) \\int_{-\\infty}^{\\infty} \\frac{1}{\\sqrt{2\\pi\\sigma_{tot}^2}}\\exp\\left(-\\frac{\\left(\\xi-\\frac{\\mu_i+\\mu_{i+1}}{2}\\right)^2}{2\\sigma_{tot}^2}\\right)d\\xi\n$$\nThe integral is of a normalized Gaussian probability density over its entire domain, which equals $1$. Therefore:\n$$\n\\mathrm{BC}_{i,i+1} = \\exp\\left(-\\frac{(\\mu_i-\\mu_{i+1})^2}{8\\sigma_{tot}^2}\\right)\n$$\nThe difference between the means of adjacent distributions is:\n$$\n\\mu_{i+1} - \\mu_i = \\frac{\\kappa\\xi^{\\ast} + k\\xi_{i+1}}{\\kappa+k} - \\frac{\\kappa\\xi^{\\ast} + k\\xi_i}{\\kappa+k} = \\frac{k(\\xi_{i+1}-\\xi_i)}{\\kappa+k} = \\frac{k\\Delta}{\\kappa+k}\n$$\nSubstituting the expressions for $(\\mu_{i+1}-\\mu_i)^2$ and $\\sigma_{tot}^2$ into the formula for $\\mathrm{BC}_{i,i+1}$:\n$$\n\\mathrm{BC}_{i,i+1} = \\exp\\left(-\\frac{1}{8} \\left(\\frac{k\\Delta}{\\kappa+k}\\right)^2 \\frac{1}{\\sigma_{tot}^2}\\right) = \\exp\\left(-\\frac{k^2\\Delta^2}{8(\\kappa+k)^2} \\beta(\\kappa+k)\\right)\n$$\n$$\n\\mathrm{BC}_{i,i+1} = \\exp\\left(-\\frac{\\beta k^2 \\Delta^2}{8(\\kappa+k)}\\right)\n$$\nWe are given the condition that the overlap must be $\\mathrm{BC}_{i,i+1} = 1/2$.\n$$\n\\frac{1}{2} = \\exp\\left(-\\frac{\\beta k^2 \\Delta^2}{8(\\kappa+k)}\\right)\n$$\nTaking the natural logarithm of both sides:\n$$\n\\ln\\left(\\frac{1}{2}\\right) = -\\ln(2) = -\\frac{\\beta k^2 \\Delta^2}{8(\\kappa+k)}\n$$\n$$\n\\ln(2) = \\frac{\\beta k^2 \\Delta^2}{8(\\kappa+k)}\n$$\nWe can now solve for $\\Delta^2$:\n$$\n\\Delta^2 = \\frac{8(\\kappa+k)\\ln(2)}{\\beta k^2}\n$$\nSubstituting $\\beta = (RT)^{-1}$, we obtain the final analytical expression for the window spacing $\\Delta$:\n$$\n\\Delta = \\sqrt{\\frac{8RT(\\kappa+k)\\ln(2)}{k^2}} = \\frac{\\sqrt{8RT(\\kappa+k)\\ln(2)}}{k}\n$$\nFinally, we substitute the given numerical values:\n$k = 10.0\\ \\mathrm{kJ}\\ \\mathrm{mol}^{-1}\\ \\mathrm{nm}^{-2}$\n$\\kappa = 2.00\\ \\mathrm{kJ}\\ \\mathrm{mol}^{-1}\\ \\mathrm{nm}^{-2}$\n$T = 300.0\\ \\mathrm{K}$\n$R = 8.314462618\\times 10^{-3}\\ \\mathrm{kJ}\\ \\mathrm{mol}^{-1}\\ \\mathrm{K}^{-1}$\n\nFirst, calculate the product $RT$:\n$RT = (8.314462618\\times 10^{-3}\\ \\mathrm{kJ}\\ \\mathrm{mol}^{-1}\\ \\mathrm{K}^{-1}) \\times (300.0\\ \\mathrm{K}) = 2.4943387854\\ \\mathrm{kJ}\\ \\mathrm{mol}^{-1}$\nNext, calculate the term $\\kappa+k$:\n$\\kappa+k = 2.00\\ \\mathrm{kJ}\\ \\mathrm{mol}^{-1}\\ \\mathrm{nm}^{-2} + 10.0\\ \\mathrm{kJ}\\ \\mathrm{mol}^{-1}\\ \\mathrm{nm}^{-2} = 12.0\\ \\mathrm{kJ}\\ \\mathrm{mol}^{-1}\\ \\mathrm{nm}^{-2}$\nNow, substitute these into the expression for $\\Delta$:\n$$\n\\Delta = \\frac{\\sqrt{8 \\times (2.4943387854\\ \\mathrm{kJ}\\ \\mathrm{mol}^{-1}) \\times (12.0\\ \\mathrm{kJ}\\ \\mathrm{mol}^{-1}\\ \\mathrm{nm}^{-2}) \\times \\ln(2)}}{10.0\\ \\mathrm{kJ}\\ \\mathrm{mol}^{-1}\\ \\mathrm{nm}^{-2}}\n$$\n$$\n\\Delta = \\frac{\\sqrt{239.456523398\\ \\mathrm{kJ}^2\\ \\mathrm{mol}^{-2}\\ \\mathrm{nm}^{-2} \\times \\ln(2)}}{10.0\\ \\mathrm{kJ}\\ \\mathrm{mol}^{-1}\\ \\mathrm{nm}^{-2}}\n$$\n$$\n\\Delta = \\frac{\\sqrt{165.9868065\\ \\mathrm{kJ}^2\\ \\mathrm{mol}^{-2}\\ \\mathrm{nm}^{-2}}}{10.0\\ \\mathrm{kJ}\\ \\mathrm{mol}^{-1}\\ \\mathrm{nm}^{-2}}\n$$\n$$\n\\Delta = \\frac{12.8835959\\ \\mathrm{kJ}\\ \\mathrm{mol}^{-1}\\ \\mathrm{nm}^{-1}}{10.0\\ \\mathrm{kJ}\\ \\mathrm{mol}^{-1}\\ \\mathrm{nm}^{-2}} = 1.28835959\\ \\mathrm{nm}\n$$\nRounding to four significant figures as requested gives:\n$$\n\\Delta \\approx 1.288\\ \\mathrm{nm}\n$$", "answer": "$$\n\\boxed{1.288}\n$$", "id": "2772126"}, {"introduction": "Effective enhanced sampling requires not just proper setup but also keen diagnostic skills to interpret simulation behavior. This problem presents a classic, non-trivial puzzle in Replica Exchange Molecular Dynamics (REMD): high exchange acceptance rates coupled with poor conformational sampling ([@problem_id:2455419]). By dissecting this apparent paradox, you will learn to look beyond surface-level metrics and diagnose subtle but critical issues, such as the decoupling of solute and solvent energy scales or the mismatch between exchange and relaxation timescales.", "problem": "A protein is simulated in explicit solvent using Replica Exchange Molecular Dynamics (REMD), where multiple replicas at different temperatures exchange temperatures to maintain detailed balance in the extended ensemble. The measured average exchange acceptance rates between all neighboring temperature pairs are uniformly high, yet over a long wall-clock time the protein in the lowest-temperature replica shows no folding transitions and remains trapped in a misfolded ensemble. Which of the following could plausibly explain this outcome without contradicting the observed high acceptance rates? Select all that apply.\n\nA. In explicit solvent, the total potential energy $U_\\text{tot}$ is dominated by solvent degrees of freedom, so neighboring replicas have strong overlap in $U_\\text{tot}$ and exchange readily; however, the protein’s conformational energy $U_\\text{prot}$ overlaps poorly across temperatures, so exchanges do not translate into effective heating of the protein conformational degrees of freedom.\n\nB. High exchange acceptance implies ergodic sampling by itself; therefore, the lack of folding must indicate a coding error in the Metropolis acceptance test.\n\nC. The exchange attempt interval $\\tau_\\text{ex}$ is much shorter than the protein’s structural relaxation time $\\tau_\\text{relax}$ at a given temperature, so after a temperature swap there is insufficient intrareplica time for conformations to equilibrate at the new temperature before the next swap, leading to temperature-space diffusion without configurational barrier crossing.\n\nD. Because the Metropolis rule in temperature REMD depends on kinetic energy, imposing holonomic constraints (for example, bond constraints) artificially inflates acceptance while suppressing barrier crossing.\n\nE. Using more replicas than necessary always decreases sampling efficiency by preventing temperature diffusion, which explains the lack of folding despite high acceptance.", "solution": "The problem statement will now be subjected to rigorous validation.\n\n### Step 1: Extract Givens\n-   A protein is simulated in explicit solvent.\n-   The simulation method is Replica Exchange Molecular Dynamics (REMD).\n-   Multiple replicas exist at different temperatures.\n-   Replicas exchange temperatures to maintain detailed balance in the extended ensemble.\n-   The measured average exchange acceptance rates between all neighboring temperature pairs are \"uniformly high\".\n-   Over a long wall-clock time, the protein in the lowest-temperature replica shows no folding transitions.\n-   The protein remains trapped in a misfolded ensemble.\n-   The question asks for a plausible explanation for this outcome that does not contradict the high acceptance rates.\n\n### Step 2: Validate Using Extracted Givens\n-   **Scientifically Grounded**: The problem describes a scenario in computational chemistry using a standard and widely-used enhanced sampling technique, Replica Exchange Molecular Dynamics (REMD). The concepts of explicit solvent, potential energy, temperature, folding transitions, and acceptance rates are all fundamental to the fields of molecular dynamics and statistical mechanics. The scenario presented—high exchange rates coupled with poor conformational sampling—is a known and frequently discussed challenge in the practical application of REMD. The problem is firmly based on established scientific principles.\n-   **Well-Posed**: The problem is well-posed. It presents a specific observation (high exchange rates, poor sampling) and asks for possible physical causes from a set of options. A definite logical analysis can be performed to evaluate the validity of each proposed cause.\n-   **Objective**: The language is precise and quantitative where needed (e.g., \"uniformly high\" acceptance rates). It does not contain subjective or opinion-based statements. It describes a physical observation and asks for a scientific explanation.\n\n### Step 3: Verdict and Action\nThe problem statement is scientifically sound, well-posed, and objective. It describes a realistic and non-trivial puzzle in the application of a major computational method. The problem is valid. We will proceed with the derivation of the solution.\n\nThe core of the problem lies in the apparent contradiction between an efficient random walk in temperature space (indicated by \"uniformly high\" exchange acceptance rates) and an inefficient random walk in the protein's conformational space (indicated by the lack of folding transitions).\n\nThe fundamental formula for the acceptance probability of a temperature exchange between two replicas, $i$ and $j$, at inverse temperatures $\\beta_i = 1/(k_B T_i)$ and $\\beta_j = 1/(k_B T_j)$ with potential energies $U_i$ and $U_j$, is given by the Metropolis criterion for the extended ensemble:\n$$ P_{\\text{acc}} = \\min\\left(1, e^{(\\beta_i - \\beta_j)(U_i - U_j)}\\right) = \\min\\left(1, e^{\\Delta\\beta \\Delta U}\\right) $$\nA \"high\" acceptance rate, for example between neighboring replicas $i$ and $i+1$ where $\\beta_i > \\beta_{i+1}$, implies that the exponent, $(\\beta_i - \\beta_{i+1})(U_i - U_{i+1})$, is frequently close to zero or negative. This facilitates the diffusion of replicas through temperature space. The goal of this diffusion is to allow a configuration at a low temperature to travel to a high temperature, overcome a potential energy barrier, and then return to the low temperature in a new conformational basin. The problem states this second part—the overcoming of conformational barriers—is not happening. We must analyze why.\n\nNow, we evaluate each option.\n\n**A. In explicit solvent, the total potential energy $U_\\text{tot}$ is dominated by solvent degrees of freedom, so neighboring replicas have strong overlap in $U_\\text{tot}$ and exchange readily; however, the protein’s conformational energy $U_\\text{prot}$ overlaps poorly across temperatures, so exchanges do not translate into effective heating of the protein conformational degrees of freedom.**\n\nThis statement describes a well-known pathology of REMD in explicit solvent. The total potential energy of the system is the sum of terms: $U_\\text{tot} = U_\\text{protein} + U_\\text{protein-solvent} + U_\\text{solvent-solvent}$. In a typical simulation box, the number of solvent molecules vastly exceeds the number of atoms in the protein. Consequently, the potential energy and its fluctuations are dominated by the solvent-solvent interactions. The acceptance probability $P_\\text{acc}$ depends on $U_\\text{tot}$. It is possible for the energy distributions $P(U_\\text{tot})$ of adjacent temperatures to have significant overlap, leading to high acceptance rates, simply due to the large fluctuations of the solvent energy. However, the energy distribution of the solute alone, $P(U_\\text{protein})$, may have very poor overlap between the same two temperatures. In such a scenario, an exchange may be accepted because of a favorable configuration of solvent molecules, not because the protein has entered a conformation that is more thermally accessible at the higher temperature. The protein's conformation effectively \"hides\" within the vast energy landscape of the solvent. The temperature random walk becomes decoupled from the desired conformational random walk. This is a correct and plausible explanation.\n\n**Verdict: Correct**\n\n**B. High exchange acceptance implies ergodic sampling by itself; therefore, the lack of folding must indicate a coding error in the Metropolis acceptance test.**\n\nThis statement is fundamentally incorrect. High exchange acceptance merely implies that replicas are efficiently traversing the ladder of temperatures. It is a necessary but not sufficient condition for achieving ergodic sampling of the conformational space. Ergodicity requires that the system is able to visit all accessible microstates over time. REMD is designed to accelerate this process, but a high exchange rate does not guarantee its success. The failure to sample conformations can arise from physical reasons, as described in option A and C, not just a bug in the code. To claim that high acceptance *implies* ergodicity is a gross oversimplification and is factually wrong.\n\n**Verdict: Incorrect**\n\n**C. The exchange attempt interval $ \\tau_\\text{ex}$ is much shorter than the protein’s structural relaxation time $ \\tau_\\text{relax}$ at a given temperature, so after a temperature swap there is insufficient intrareplica time for conformations to equilibrate at the new temperature before the next swap, leading to temperature-space diffusion without configurational barrier crossing.**\n\nThis statement describes another classic inefficiency in REMD. For REMD to be effective, a conformation that swaps to a higher temperature must have sufficient time to evolve and cross an energy barrier before it swaps back to a lower temperature. The characteristic time for such a conformational change is the relaxation time, $\\tau_\\text{relax}$. If the time between exchange attempts, $\\tau_\\text{ex}$, is much smaller than $\\tau_\\text{relax}$ (i.e., $\\tau_\\text{ex} \\ll \\tau_\\text{relax}$), the configuration does not have enough time to change significantly. The system will diffuse rapidly in temperature space, but the configurations will remain \"frozen\" or \"stuck\" to their respective temperature indices. The random walk in temperature is not productively coupled to exploration of the conformational landscape. This leads to the exact scenario described in the problem: high acceptance rates but no conformational progress.\n\n**Verdict: Correct**\n\n**D. Because the Metropolis rule in temperature REMD depends on kinetic energy, imposing holonomic constraints (for example, bond constraints) artificially inflates acceptance while suppressing barrier crossing.**\n\nThe premise of this statement is false. The standard temperature REMD acceptance probability, $P_{\\text{acc}} = \\min(1, \\exp(\\Delta\\beta \\Delta U))$, depends explicitly on the difference in *potential energy* ($\\Delta U$) and the difference in inverse temperatures ($\\Delta\\beta$). It does not depend on the kinetic energy of the replicas. The kinetic energy terms, which are assumed to be functions only of temperature and the number of degrees of freedom, cancel out during the derivation of the exchange probability from the canonical partition function. Since the premise that the rule \"depends on kinetic energy\" is incorrect, the entire argument is invalid.\n\n**Verdict: Incorrect**\n\n**E. Using more replicas than necessary always decreases sampling efficiency by preventing temperature diffusion, which explains the lack of folding despite high acceptance.**\n\nThis claim is the opposite of the truth. Temperature diffusion is the random walk of a given replica through the set of temperatures. The efficiency of this diffusion is limited by the acceptance rate between adjacent temperatures. Increasing the number of replicas for a fixed temperature range means the temperature difference $\\Delta T$ between adjacent replicas becomes smaller. A smaller $\\Delta T$ leads to a greater overlap between the potential energy distributions $P(U)$ of neighboring replicas, which in turn *increases* the exchange acceptance rate. Therefore, using more replicas generally *improoves* temperature diffusion, it does not prevent it. While using an excessive number of replicas is computationally wasteful, it does not \"prevent temperature diffusion\" and would not explain the observed problem. Poor temperature diffusion is caused by using too *few* replicas, leading to low acceptance rates.\n\n**Verdict: Incorrect**\n\nIn summary, options A and C present two distinct and well-documented physical reasons why a REMD simulation can exhibit high exchange acceptance rates while failing to enhance conformational sampling.", "answer": "$$\\boxed{AC}$$", "id": "2455419"}, {"introduction": "The ultimate goal of many enhanced sampling simulations is the quantitative reconstruction of a free energy landscape. This hands-on coding exercise guides you through implementing the Weighted Histogram Analysis Method (WHAM), the cornerstone algorithm for combining data from multiple biased simulations ([@problem_id:2455424]). By starting with deterministically generated histogram data and implementing the self-consistent WHAM equations, you will gain practical, code-level insight into how raw simulation counts are transformed into a physically meaningful potential of mean force.", "problem": "A ligand’s internal rotation around a dihedral coordinate is modeled as a one-dimensional periodic coordinate $\\theta \\in [-\\pi,\\pi)$ in radians. The ligand resides in a buried, nearly-symmetric binding pocket, which induces an unknown reduced potential of mean force $u_0(\\theta)$ in units of thermal energy $k_\\mathrm{B}T$ (dimensionless). At equilibrium without external bias, the probability density is $p_0(\\theta) \\propto \\exp\\!\\left(-u_0(\\theta)\\right)$, and the free energy profile is $F(\\theta) = -\\ln p_0(\\theta) + \\text{constant}$ in units of $k_\\mathrm{B}T$. A set of $M$ harmonic-bias experiments are carried out, each applying a bias $u_i(\\theta)$ and collecting $N_i$ independent equilibrium samples of $\\theta$ from the corresponding biased distribution $p_i(\\theta) \\propto \\exp\\!\\left(-[u_0(\\theta)+u_i(\\theta)]\\right)$. The harmonic bias is $u_i(\\theta) = \\tfrac{k}{2}\\,d(\\theta,\\theta_i)^2$ with stiffness $k$ in units of $k_\\mathrm{B}T/\\mathrm{rad}^2$, where $d(\\theta,\\theta_i)$ is the minimum-image angular distance in radians, defined by $d(\\theta,\\theta_i) = \\mathrm{wrap}(\\theta-\\theta_i)$ with $\\mathrm{wrap}(x)$ mapping $x$ into $(-\\pi,\\pi]$ by adding or subtracting multiples of $2\\pi$. For each experiment $i \\in \\{1,\\ldots,M\\}$, a histogram $h_{i,j}$ of the sampled angles is formed over $B$ uniform bins partitioning $[-\\pi,\\pi)$, indexed by $j \\in \\{0,1,\\ldots,B-1\\}$ with bin width $\\Delta\\theta = 2\\pi/B$ and bin centers $\\theta_j = -\\pi + (j+\\tfrac{1}{2})\\Delta\\theta$. The count $h_{i,j}$ is the number of samples in bin $j$ for window $i$.\n\nYour task is to estimate the unbiased free energy profile $F(\\theta_j)$ up to an additive constant from these biased histograms and then compute two scalar quantities per test case:\n- The barrier height $\\Delta F_\\mathrm{bar}$ between the two lowest minima near $\\theta \\approx 0$ and $\\theta \\approx \\pi$, defined as the maximum value of $F(\\theta)$ along the direct path from $\\theta=0$ to $\\theta=\\pi$ (i.e., $\\theta \\in [0,\\pi]$) minus the lower of the two minimum values found within the neighborhoods $\\theta \\in [-\\pi/3,\\pi/3]$ (near $\\theta \\approx 0$) and $\\theta$ satisfying $|d(\\theta,\\pi)| \\le \\pi/3$ (near $\\theta \\approx \\pi$).\n- The asymmetry $\\Delta F_\\mathrm{asym} = F_\\mathrm{min}(\\text{near } \\pi) - F_\\mathrm{min}(\\text{near } 0)$, where $F_\\mathrm{min}(\\text{near } 0)$ is the minimum of $F(\\theta)$ over $\\theta \\in [-\\pi/3,\\pi/3]$, and $F_\\mathrm{min}(\\text{near } \\pi)$ is the minimum of $F(\\theta)$ over angles that satisfy $|d(\\theta,\\pi)| \\le \\pi/3$.\n\nAngles must be handled in radians. Energies and free energies must be treated in units of $k_\\mathrm{B}T$ (dimensionless). The final reported scalar results are dimensionless floats.\n\nTo make the problem fully specified and testable, you will generate the histograms deterministically from a known reduced potential $u_0(\\theta)$ using the following construction per test case:\n- The underlying reduced potential is $u_0(\\theta) = -\\alpha \\cos(2\\theta) - \\beta \\cos(\\theta)$ with given parameters $(\\alpha,\\beta)$.\n- The number of windows is $M = 8$, with bias centers $\\theta_i = -\\pi + i \\cdot \\frac{\\pi}{4}$ for $i \\in \\{0,1,2,3,4,5,6,7\\}$.\n- The bin count is $B$ as specified per test case, with uniform bins over $[-\\pi,\\pi)$.\n- For each window $i$, the bias is $u_i(\\theta) = \\tfrac{k}{2}\\,d(\\theta,\\theta_i)^2$ with the specified stiffness $k$.\n- For each window $i$, the exact expected discrete probability for bin $j$ is\n$$\np_{i,j} = \\frac{\\exp\\!\\left(-[u_0(\\theta_j) + u_i(\\theta_j)]\\right)}{\\sum_{m=0}^{B-1} \\exp\\!\\left(-[u_0(\\theta_m) + u_i(\\theta_m)]\\right)}.\n$$\n- The histogram counts are deterministically set by rounding the expected counts $N_i p_{i,j}$ to integers such that the total in window $i$ is exactly $N_i$. Specifically, for each window $i$, first compute the real vector $\\mathbf{e}_i$ with components $e_{i,j} = N_i p_{i,j}$, take the floor of each component to get integers, and then distribute the remaining $N_i - \\sum_j \\lfloor e_{i,j}\\rfloor$ counts by adding one to the bins with the largest fractional parts $e_{i,j} - \\lfloor e_{i,j}\\rfloor$ (breaking any exact ties by lower $j$).\n\nYou must implement a program that:\n- Constructs the histograms using the above deterministic procedure.\n- Uses only the histograms $h_{i,j}$, the known biases $u_i(\\theta_j)$, the counts $N_i$, and the bin centers $\\theta_j$ to estimate the unbiased free energy $F(\\theta_j)$ up to an additive constant.\n- Computes $\\Delta F_\\mathrm{bar}$ and $\\Delta F_\\mathrm{asym}$ as defined.\n\nTest Suite. Implement your program to run the following three cases and aggregate their results:\n- Case $1$ (happy path, strongly bimodal and nearly symmetric):\n  - $\\alpha = 1.5$, $\\beta = 0.1$.\n  - $k = 20$.\n  - $B = 60$.\n  - $(N_0,\\ldots,N_7) = (2000,1500,2500,1800,2200,1600,2400,1700)$.\n- Case $2$ (boundary case, nearly flat pocket):\n  - $\\alpha = 0.15$, $\\beta = 0.0$.\n  - $k = 8$.\n  - $B = 60$.\n  - $(N_0,\\ldots,N_7) = (1200,1200,1200,1200,1200,1200,1200,1200)$.\n- Case $3$ (asymmetric case with reversed minimum ordering):\n  - $\\alpha = 1.6$, $\\beta = -0.3$.\n  - $k = 25$.\n  - $B = 60$.\n  - $(N_0,\\ldots,N_7) = (3000,1800,2200,2000,2600,1800,2400,1600)$.\n\nFinal Output Format. Your program should produce a single line of output containing the three pairs of results in a list-of-lists form:\n- The output must be a single line string representing $[\\,[\\Delta F_\\mathrm{bar}^{(1)},\\Delta F_\\mathrm{asym}^{(1)}],\\,[\\Delta F_\\mathrm{bar}^{(2)},\\Delta F_\\mathrm{asym}^{(2)}],\\,[\\Delta F_\\mathrm{bar}^{(3)},\\Delta F_\\mathrm{asym}^{(3)}]\\,]$, where superscripts indicate the case number.\n- All angles must be in radians internally, and the reported values are floats in units of $k_\\mathrm{B}T$ (dimensionless). No units should be printed.", "solution": "The problem presented is a well-defined exercise in computational statistical mechanics, specifically the reconstruction of a potential of mean force (PMF), or free energy profile, from a set of biased simulations. This is a standard task in molecular dynamics, often addressed using the Weighted Histogram Analysis Method (WHAM) or the Multistate Bennett Acceptance Ratio (MBAR) method. The problem provides all necessary data and a deterministic procedure to generate simulation-like histograms, thus making it a complete and solvable numerical problem.\nThe problem is valid as it is scientifically grounded, well-posed, and objective. It does not violate any fundamental principles of physics or mathematics. All parameters and procedures are described with sufficient precision to admit a unique solution.\n\nMy approach will be to implement the procedure as follows:\n1.  For each test case, first generate the required input data. This involves discretizing the coordinate $\\theta$, calculating the true underlying potential $u_0(\\theta)$ and the biasing potentials $u_i(\\theta)$ on this grid, and then constructing the histograms $h_{i,j}$ using the specified deterministic rounding procedure based on the exact biased probabilities.\n2.  With the histograms $h_{i,j}$, number of samples $N_i$, and bias potentials $u_i(\\theta_j)$ in hand, the next step is to compute the unbiased free energy profile $F(\\theta_j)$. I will use the WHAM equations, which provide a self-consistent set of relations to find the optimal estimate of the free energy profile. The equations are:\n    $$\n    e^{-F_j} = C \\cdot \\frac{\\sum_{i=1}^M h_{i,j}}{\\sum_{i=1}^M N_i e^{f_i - u_{i,j}}}\n    $$\n    $$\n    e^{-f_i} = \\sum_{j=0}^{B-1} e^{-F_j - u_{i,j}}\n    $$\n    Here, $F_j$ is the free energy of bin $j$, $u_{i,j} = u_i(\\theta_j)$ is the bias potential of window $i$ in bin $j$, and $f_i$ are the free energies of the individual simulations. $C$ is a normalization constant. These equations are solved iteratively until the values of $F_j$ and $f_i$ converge. To ensure numerical stability, calculations involving sums of exponentials are performed in log-space using the log-sum-exp trick.\n\n3.  After obtaining the converged free energy profile $F(\\theta_j)$, the final step is to extract the two requested scalar quantities: the barrier height $\\Delta F_\\mathrm{bar}$ and the asymmetry $\\Delta F_\\mathrm{asym}$. This requires identifying the correct index ranges that correspond to the angular regions specified in the problem: $\\theta \\in [0,\\pi]$ for the barrier top, $\\theta \\in [-\\pi/3, \\pi/3]$ for the minimum near zero, and $|d(\\theta,\\pi)| \\le \\pi/3$ for the minimum near $\\pi$. The minima and maximum of the profile $F(\\theta_j)$ are found within these specific index ranges, and the final scalars are calculated according to their definitions.\n\nA critical component is the correct handling of periodic boundary conditions for the angle $\\theta$. The minimum-image angular distance $d(\\theta, \\phi)$ must be calculated using a function that correctly wraps the difference $\\theta-\\phi$ into the interval $(-\\pi, \\pi]$, as specified. This is squared to compute the harmonic bias energies.\n\nThe entire procedure is encapsulated in a Python script that processes each of the three test cases and formats the final results as a single string, conforming to the specified output format.", "answer": "```python\nimport numpy as np\nfrom scipy.special import logsumexp\n\ndef solve():\n    \"\"\"\n    Main function to solve the problem for the given test cases.\n    It orchestrates the data generation, analysis, and final output formatting.\n    \"\"\"\n\n    def wrap_to_pi(x):\n        \"\"\"\n        Wraps angle(s) x to the interval (-pi, pi].\n\n        Parameters:\n        x (float or np.ndarray): The angle(s) in radians.\n\n        Returns:\n        float or np.ndarray: The wrapped angle(s).\n        \"\"\"\n        y = np.mod(x, 2 * np.pi)\n        # For an array y, np.where is used for conditional assignment.\n        # if y > pi, it is mapped to y - 2*pi, resulting in the range (-pi, 0).\n        # if y <= pi, it is unchanged, giving the range [0, pi].\n        # The combination of these two is (-pi, pi].\n        y = np.where(y > np.pi, y - 2 * np.pi, y)\n        return y\n\n    def process_case(alpha, beta, k, B, N_i):\n        \"\"\"\n        Processes a single test case: generates histograms, runs WHAM, and computes results.\n        \"\"\"\n        # 1. Setup grid and parameters\n        M = 8  # Number of windows\n        delta_theta = 2 * np.pi / B\n        theta_j = -np.pi + (np.arange(B) + 0.5) * delta_theta\n        theta_i_centers = -np.pi + np.arange(M) * np.pi / 4\n\n        # 2. Generate histograms deterministically\n        histograms = np.zeros((M, B), dtype=np.int64)\n        bias_potentials = np.zeros((M, B))\n        \n        # Calculate unbiased potential on the grid\n        u0_j = -alpha * np.cos(2 * theta_j) - beta * np.cos(theta_j)\n\n        for i in range(M):\n            # Calculate bias potential for window i\n            d_theta = wrap_to_pi(theta_j - theta_i_centers[i])\n            ui_j = 0.5 * k * d_theta**2\n            bias_potentials[i, :] = ui_j\n\n            # Calculate total potential and exact probabilities for bin j in window i\n            total_potential = u0_j + ui_j\n            log_probs = -total_potential\n            log_probs -= logsumexp(log_probs)  # Normalize using logsumexp\n            probs = np.exp(log_probs)\n            \n            # Calculate expected counts\n            expected_counts = N_i[i] * probs\n            \n            # Deterministic rounding procedure\n            floored_counts = np.floor(expected_counts)\n            h_ij = floored_counts.astype(np.int64)\n            # Use round() to handle potential float precision issues\n            remainder = int(round(N_i[i] - np.sum(floored_counts)))\n            \n            if remainder > 0:\n                fractional_parts = expected_counts - floored_counts\n                j_indices = np.arange(B)\n                # Sort indices by fractional part (descending) and then index (ascending) to break ties\n                sorted_indices = np.lexsort((j_indices, -fractional_parts))\n                indices_to_increment = sorted_indices[:remainder]\n                h_ij[indices_to_increment] += 1\n            \n            histograms[i, :] = h_ij\n\n        # 3. Reconstruct free energy profile using WHAM\n        F = np.zeros(B)  # Initial guess for free energies\n        N_i_arr = np.array(N_i)\n        total_counts_j = np.sum(histograms, axis=0)\n        \n        # Bins with zero counts will have infinite free energy\n        non_zero_counts = total_counts_j > 0\n        log_total_counts_j = np.full(B, -np.inf)\n        if np.any(non_zero_counts):\n            log_total_counts_j[non_zero_counts] = np.log(total_counts_j[non_zero_counts])\n\n        # WHAM iterative solution\n        max_iter = 10000\n        tolerance = 1e-9\n        for _ in range(max_iter):\n            F_old = F.copy()\n            \n            # Update f_i (dimensionless free energies of each simulation)\n            f = -logsumexp(-F[np.newaxis, :] - bias_potentials, axis=1)\n\n            # Update F_j (unbiased free energy profile)\n            log_sum_exp_term = logsumexp(np.log(N_i_arr)[:, np.newaxis] + f[:, np.newaxis] - bias_potentials, axis=0)\n            F = -log_total_counts_j + log_sum_exp_term\n\n            # Normalize F to prevent drift and handle any infinities\n            finite_F = F[np.isfinite(F)]\n            if finite_F.size > 0:\n                F -= np.min(finite_F)\n            \n            # Check for convergence\n            if np.all(np.isclose(F, F_old, atol=tolerance, rtol=0)):\n                break\n\n        # 4. Analyze the free energy profile F\n        # Define index ranges for analysis using boolean masks\n        range_0_pi_mask = theta_j >= 0\n        range_near_0_mask = (theta_j >= -np.pi/3) & (theta_j <= np.pi/3)\n        range_near_pi_mask = (theta_j <= -2*np.pi/3) | (theta_j >= 2*np.pi/3)\n\n        # Ensure ranges are not empty before taking min/max\n        if not np.any(range_near_0_mask) or not np.any(range_near_pi_mask) or not np.any(range_0_pi_mask):\n             return [np.nan, np.nan] # Should not happen with B=60\n\n        # Find minima and maxima in the specified ranges\n        F_min_near_0 = np.min(F[range_near_0_mask])\n        F_min_near_pi = np.min(F[range_near_pi_mask])\n        F_barrier_top = np.max(F[range_0_pi_mask])\n\n        # Calculate final scalar quantities\n        delta_F_bar = F_barrier_top - min(F_min_near_0, F_min_near_pi)\n        delta_F_asym = F_min_near_pi - F_min_near_0\n        \n        return [delta_F_bar, delta_F_asym]\n\n    # Define the test cases from the problem statement\n    test_cases = [\n        # Case 1: happy path, strongly bimodal and nearly symmetric\n        {\n            \"alpha\": 1.5, \"beta\": 0.1, \"k\": 20, \"B\": 60,\n            \"N_i\": [2000, 1500, 2500, 1800, 2200, 1600, 2400, 1700]\n        },\n        # Case 2: boundary case, nearly flat pocket\n        {\n            \"alpha\": 0.15, \"beta\": 0.0, \"k\": 8, \"B\": 60,\n            \"N_i\": [1200, 1200, 1200, 1200, 1200, 1200, 1200, 1200]\n        },\n        # Case 3: asymmetric case with reversed minimum ordering\n        {\n            \"alpha\": 1.6, \"beta\": -0.3, \"k\": 25, \"B\": 60,\n            \"N_i\": [3000, 1800, 2200, 2000, 2600, 1800, 2400, 1600]\n        }\n    ]\n    \n    results = []\n    for case_params in test_cases:\n        result = process_case(**case_params)\n        results.append(result)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "2455424"}]}