{"hands_on_practices": [{"introduction": "Before implementing complex thermostat algorithms, it's crucial to understand the theoretical target they aim to achieve. The canonical ensemble is not defined by a fixed kinetic energy, but rather by a specific, predictable distribution of kinetic energies. This first exercise [@problem_id:2825163] guides you through a fundamental derivation to quantify the expected magnitude of these temperature fluctuations, which serves as a key signature of correct canonical sampling.", "problem": "Consider a classical system of $N$ particles evolved under a thermostat so that momenta are sampled from the canonical ensemble at thermodynamic temperature $T$. After removal of any holonomic constraints and overall conserved quantities, suppose the system has $f$ effective kinetic degrees of freedom (DOF). The instantaneous kinetic temperature estimator commonly used in molecular dynamics (MD) thermostats is defined by\n$$\n\\hat{T} \\equiv \\frac{2 K}{f k_{B}},\n$$\nwhere $K$ is the instantaneous kinetic energy and $k_{B}$ is the Boltzmann constant. In the canonical ensemble, the joint momentum distribution factorizes and obeys the Maxwell–Boltzmann form, so that\n$$\nP(\\{p_{i}\\}\\,|\\,T) \\propto \\exp\\!\\left(-\\beta \\sum_{i=1}^{f} \\frac{p_{i}^{2}}{2 m_{i}}\\right), \\quad \\beta \\equiv \\frac{1}{k_{B} T},\n$$\nwith effective masses $m_{i} > 0$ associated to the $f$ quadratic kinetic modes.\n\nStarting from these canonical-ensemble facts and basic properties of independent Gaussian variables, derive a closed-form expression for the dimensionless relative variance\n$$\n\\frac{\\operatorname{Var}(\\hat{T})}{T^{2}}\n$$\nin terms of $f$ only. Express your final answer as a single analytic expression in $f$. This ratio is dimensionless; no units are required. No numerical rounding is required.", "solution": "The problem as stated is scientifically grounded, self-contained, and well-posed. It is a standard derivation in statistical mechanics. We shall proceed with the solution.\n\nThe objective is to derive an expression for the dimensionless relative variance of the instantaneous kinetic temperature estimator, $\\hat{T}$, defined as\n$$\n\\hat{T} \\equiv \\frac{2 K}{f k_{B}}\n$$\nwhere $K$ is the total instantaneous kinetic energy, $f$ is the number of effective kinetic degrees of freedom, and $k_{B}$ is the Boltzmann constant. The quantity to be derived is $\\frac{\\operatorname{Var}(\\hat{T})}{T^2}$.\n\nThe variance is defined as $\\operatorname{Var}(\\hat{T}) = \\langle \\hat{T}^2 \\rangle - \\langle \\hat{T} \\rangle^2$. The angle brackets $\\langle \\dots \\rangle$ denote an average over the canonical ensemble at thermodynamic temperature $T$. The required ratio is therefore\n$$\n\\frac{\\operatorname{Var}(\\hat{T})}{T^2} = \\frac{\\langle \\hat{T}^2 \\rangle - \\langle \\hat{T} \\rangle^2}{T^2}\n$$\nThe total kinetic energy $K$ is the sum of the kinetic energies of the $f$ independent modes:\n$$\nK = \\sum_{i=1}^{f} K_i = \\sum_{i=1}^{f} \\frac{p_i^2}{2 m_i}\n$$\nwhere $p_i$ and $m_i$ are the momentum and effective mass for the $i$-th degree of freedom, respectively.\n\nFirst, we calculate the expectation value $\\langle \\hat{T} \\rangle$.\n$$\n\\langle \\hat{T} \\rangle = \\left\\langle \\frac{2 K}{f k_{B}} \\right\\rangle = \\frac{2}{f k_{B}} \\langle K \\rangle = \\frac{2}{f k_{B}} \\left\\langle \\sum_{i=1}^{f} K_i \\right\\rangle = \\frac{2}{f k_{B}} \\sum_{i=1}^{f} \\langle K_i \\rangle\n$$\nEach momentum $p_i$ is distributed according to the Maxwell-Boltzmann distribution, which for a single mode is a Gaussian distribution. The expectation value of the energy for a single quadratic degree of freedom in the canonical ensemble is a direct consequence of the equipartition theorem, which states that $\\langle K_i \\rangle = \\frac{1}{2} k_{B} T$.\n\nThus, the average total kinetic energy is:\n$$\n\\langle K \\rangle = \\sum_{i=1}^{f} \\frac{1}{2} k_{B} T = \\frac{f}{2} k_{B} T\n$$\nSubstituting this into the expression for $\\langle \\hat{T} \\rangle$:\n$$\n\\langle \\hat{T} \\rangle = \\frac{2}{f k_{B}} \\left( \\frac{f}{2} k_{B} T \\right) = T\n$$\nThis shows that $\\hat{T}$ is an unbiased estimator of the thermodynamic temperature $T$.\n\nNext, we calculate the second moment, $\\langle \\hat{T}^2 \\rangle$:\n$$\n\\langle \\hat{T}^2 \\rangle = \\left\\langle \\left( \\frac{2 K}{f k_{B}} \\right)^2 \\right\\rangle = \\frac{4}{(f k_{B})^2} \\langle K^2 \\rangle\n$$\nWe need to evaluate $\\langle K^2 \\rangle$:\n$$\n\\langle K^2 \\rangle = \\left\\langle \\left( \\sum_{i=1}^{f} K_i \\right)^2 \\right\\rangle = \\left\\langle \\sum_{i=1}^{f} K_i^2 + \\sum_{i \\neq j} K_i K_j \\right\\rangle = \\sum_{i=1}^{f} \\langle K_i^2 \\rangle + \\sum_{i \\neq j} \\langle K_i K_j \\rangle\n$$\nThe joint momentum distribution factorizes, which means the momentum variables $p_i$ are statistically independent. Consequently, the kinetic energy terms $K_i = \\frac{p_i^2}{2m_i}$ are also statistically independent. For $i \\neq j$, we have:\n$$\n\\langle K_i K_j \\rangle = \\langle K_i \\rangle \\langle K_j \\rangle = \\left( \\frac{1}{2} k_{B} T \\right) \\left( \\frac{1}{2} k_{B} T \\right) = \\frac{1}{4} (k_{B} T)^2\n$$\nNow we must calculate $\\langle K_i^2 \\rangle$. This requires the fourth moment of the momentum, $\\langle p_i^4 \\rangle$. For a one-dimensional Gaussian variable $x$ with mean $0$ and variance $\\sigma^2$, the moments are $\\langle x^2 \\rangle = \\sigma^2$ and $\\langle x^4 \\rangle = 3 \\sigma^4$. From the distribution $P(p_i) \\propto \\exp(-\\frac{\\beta p_i^2}{2m_i})$, we identify the variance of $p_i$ as $\\sigma_{p_i}^2 = m_i k_{B} T$.\nThus, the moments of $p_i$ are:\n$$\n\\langle p_i^2 \\rangle = m_i k_{B} T\n$$\n$$\n\\langle p_i^4 \\rangle = 3 (m_i k_{B} T)^2\n$$\nWe can now find $\\langle K_i^2 \\rangle$:\n$$\n\\langle K_i^2 \\rangle = \\left\\langle \\left( \\frac{p_i^2}{2m_i} \\right)^2 \\right\\rangle = \\frac{1}{4m_i^2} \\langle p_i^4 \\rangle = \\frac{1}{4m_i^2} \\left[ 3 (m_i k_{B} T)^2 \\right] = \\frac{3}{4} (k_{B} T)^2\n$$\nNow we assemble the terms for $\\langle K^2 \\rangle$. The sum $\\sum_{i=1}^{f} \\langle K_i^2 \\rangle$ has $f$ identical terms, and the sum $\\sum_{i \\neq j} \\langle K_i K_j \\rangle$ has $f(f-1)$ identical terms.\n$$\n\\langle K^2 \\rangle = f \\left[ \\frac{3}{4} (k_{B} T)^2 \\right] + f(f-1) \\left[ \\frac{1}{4} (k_{B} T)^2 \\right]\n$$\n$$\n\\langle K^2 \\rangle = \\frac{(k_{B} T)^2}{4} [3f + f(f-1)] = \\frac{(k_{B} T)^2}{4} [3f + f^2 - f] = \\frac{(k_{B} T)^2}{4} (f^2 + 2f)\n$$\nSubstitute this result back into the expression for $\\langle \\hat{T}^2 \\rangle$:\n$$\n\\langle \\hat{T}^2 \\rangle = \\frac{4}{(f k_{B})^2} \\langle K^2 \\rangle = \\frac{4}{f^2 k_{B}^2} \\left[ \\frac{(k_{B} T)^2}{4} (f^2 + 2f) \\right] = \\frac{f^2 + 2f}{f^2} T^2 = \\left( 1 + \\frac{2}{f} \\right) T^2\n$$\nNow we can compute the variance of $\\hat{T}$:\n$$\n\\operatorname{Var}(\\hat{T}) = \\langle \\hat{T}^2 \\rangle - \\langle \\hat{T} \\rangle^2 = \\left( 1 + \\frac{2}{f} \\right) T^2 - T^2 = \\frac{2}{f} T^2\n$$\nFinally, the required dimensionless relative variance is:\n$$\n\\frac{\\operatorname{Var}(\\hat{T})}{T^2} = \\frac{\\frac{2}{f} T^2}{T^2} = \\frac{2}{f}\n$$\nThis result shows that the relative fluctuation of the kinetic temperature estimator is inversely proportional to the number of degrees of freedom, which is a fundamental result in the statistical mechanics of finite systems.", "answer": "$$\\boxed{\\frac{2}{f}}$$", "id": "2825163"}, {"introduction": "Moving from theory to practice, we now address how to configure an advanced algorithm, the Nosé-Hoover chain thermostat, for optimal performance. The algorithm's effectiveness hinges on a set of 'mass' parameters, $Q_i$, which must be chosen carefully to ensure the thermostat can efficiently exchange energy with the system across a wide range of physically relevant frequencies. This problem [@problem_id:2825162] introduces a robust, physically-motivated procedure for setting these parameters to achieve efficient and ergodic sampling.", "problem": "You are asked to parameterize a Nosé–Hoover chain (NHC) thermostat for Molecular Dynamics (MD) at temperature $T$. The chain has length $M$ and thermostat variables indexed by $i \\in \\{1,\\dots,M\\}$, each with thermostat mass $Q_i$. Let $k_{\\mathrm{B}}$ denote the Boltzmann constant. The first thermostat couples to the physical system with an effective number of degrees of freedom $g_1$, while deeper thermostats act on the preceding thermostat variable and may be taken to couple a single degree of freedom, $g_i = 1$ for $i>1$.\n\nStarting from the following fundamental bases only:\n- Equipartition: each independent quadratic degree of freedom in thermal equilibrium at temperature $T$ carries average energy $\\tfrac{1}{2}k_{\\mathrm{B}}T$.\n- Small-oscillation (harmonic) approximation: near equilibrium, a quadratic mode with inertia $m$ and stiffness $k$ oscillates with angular frequency $\\omega = \\sqrt{k/m}$ and characteristic time $ \\tau = 1/\\omega$.\n\nUse these to construct a procedure to choose the thermostat masses $Q_i$ so that the characteristic times $\\tau_i$ of the thermostat chain form an equal time-scale spacing on a logarithmic axis, i.e., a geometric progression with common ratio $r>1$. Then, demonstrate the implied distribution of thermostat angular frequencies $\\omega_i$ across the chain.\n\nSelect all options that correctly and self-consistently specify such a procedure and correctly describe its effect on the thermostat frequency distribution. Each option refers to the chain indexed by $i$ starting at $i=1$ with a prescribed base time scale $\\tau_1$ and common ratio $r>1$.\n\nA. Choose $\\tau_i = \\tau_1 r^{\\,i-1}$ and set $Q_i = g_i\\,k_{\\mathrm{B}}T\\,\\tau_i^2 = g_i\\,k_{\\mathrm{B}}T\\,\\tau_1^2\\,r^{\\,2(i-1)}$. Then $\\omega_i = 1/\\tau_i = \\omega_1\\,r^{-(i-1)}$ with $\\omega_1 = 1/\\tau_1$, so the frequencies are equally spaced on a logarithmic scale.\n\nB. Choose $\\tau_i = \\tau_1 r^{\\,i-1}$ but set $Q_i = g_i\\,k_{\\mathrm{B}}T\\,\\tau_1^2\\,r^{-(i-1)}$. Then $\\omega_i \\propto \\sqrt{Q_i}$, giving $\\omega_i = \\omega_1\\,r^{-\\tfrac{1}{2}(i-1)}$, which yields equal logarithmic spacing of thermostat frequencies.\n\nC. Choose a constant $Q_i = Q$ for all $i$ so that all thermostat time scales are identical. This “flat” choice yields a uniform damping across the spectrum by placing thermostats at the same frequency, which is desirable for broad-band control.\n\nD. Choose $Q_i = g_i\\,k_{\\mathrm{B}}T\\,\\tau_1^2\\,r^{\\,i-1}$ so that $\\omega_i = \\omega_1\\,r^{-\\tfrac{1}{2}(i-1)}$. This realizes equal time-scale spacing because the masses scale linearly with the ratio $r$.\n\nE. In an $M$-thermostat chain, take $g_1 = g_{\\mathrm{phys}}$ (the number of physical degrees of freedom coupled to the first thermostat) and $g_i=1$ for $i>1$, and choose $\\tau_i = \\tau_1 r^{\\,i-1}$ with $Q_i = g_i\\,k_{\\mathrm{B}}T\\,\\tau_i^2$, i.e., $Q_1 = g_{\\mathrm{phys}}\\,k_{\\mathrm{B}}T\\,\\tau_1^2$ and $Q_{i>1} = k_{\\mathrm{B}}T\\,\\tau_1^2\\,r^{\\,2(i-1)}$. This preserves a geometric frequency distribution $\\omega_i = \\omega_1 r^{-(i-1)}$ across the chain.\n\nSelect all that apply.", "solution": "We derive the mapping between thermostat mass and time scale from the stated bases.\n\nBy the small-oscillation approximation, a quadratic mode with inertia $m$ and stiffness $k$ has angular frequency $\\omega = \\sqrt{k/m}$ and characteristic time $\\tau = 1/\\omega = \\sqrt{m/k}$. In a Nosé–Hoover chain (NHC), the thermostat variable at level $i$ is a quadratic mode with inertia $Q_i$. The “stiffness” governing its fluctuations near equilibrium is set by the thermal scale of the degree(s) of freedom it regulates. By equipartition, each quadratic degree of freedom contributes an average energy of $\\tfrac{1}{2}k_{\\mathrm{B}}T$. For the first thermostat, which regulates the kinetic energy of an effective $g_1$ degrees of freedom, the relevant thermal scale is proportional to $g_1 k_{\\mathrm{B}}T$. For deeper thermostats, which regulate a single preceding thermostat variable, it is conventional and consistent to take $g_i = 1$ for $i>1$.\n\nThese considerations lead to the widely used and dimensionally consistent mapping (a standard and well-tested choice in MD practice)\n$$\n\\tau_i^2 \\;=\\; \\frac{Q_i}{g_i\\,k_{\\mathrm{B}}T}, \\qquad \\text{equivalently} \\qquad Q_i \\;=\\; g_i\\,k_{\\mathrm{B}}T\\,\\tau_i^2,\n$$\nso that the thermostat’s natural frequency is\n$$\n\\omega_i \\;=\\; \\frac{1}{\\tau_i} \\;=\\; \\sqrt{\\frac{g_i\\,k_{\\mathrm{B}}T}{Q_i}}.\n$$\n\nNow impose equal time-scale spacing on a logarithmic axis by choosing\n$$\n\\tau_i \\;=\\; \\tau_1\\, r^{\\,i-1}, \\qquad r>1.\n$$\nSubstituting into the mapping gives the thermostat masses\n$$\nQ_i \\;=\\; g_i\\,k_{\\mathrm{B}}T\\,\\tau_i^2 \\;=\\; g_i\\,k_{\\mathrm{B}}T\\,\\tau_1^2\\, r^{\\,2(i-1)}.\n$$\nThe corresponding frequencies are\n$$\n\\omega_i \\;=\\; \\frac{1}{\\tau_i} \\;=\\; \\frac{1}{\\tau_1}\\, r^{-(i-1)} \\;=\\; \\omega_1\\, r^{-(i-1)},\n$$\nso $\\{\\omega_i\\}$ are geometrically spaced with common ratio $1/r$, i.e., equally spaced on a logarithmic frequency axis.\n\nWe now evaluate each option:\n\nA. This option specifies $\\tau_i = \\tau_1 r^{\\,i-1}$ and sets $Q_i = g_i\\,k_{\\mathrm{B}}T\\,\\tau_i^2 = g_i\\,k_{\\mathrm{B}}T\\,\\tau_1^2\\, r^{\\,2(i-1)}$, and deduces $\\omega_i = \\omega_1 r^{-(i-1)}$. This matches the derivation above and correctly states the logarithmic frequency spacing. Verdict — Correct.\n\nB. This option assigns $Q_i = g_i\\,k_{\\mathrm{B}}T\\,\\tau_1^2\\, r^{-(i-1)}$, which contradicts $Q_i \\propto \\tau_i^2$ for $\\tau_i = \\tau_1 r^{\\,i-1}$; the power of $r$ is incorrect and has the wrong sign. It also asserts $\\omega_i \\propto \\sqrt{Q_i}$, whereas from $\\omega_i = 1/\\tau_i$ and $\\tau_i^2 = Q_i/(g_i k_{\\mathrm{B}}T)$ we have $\\omega_i \\propto 1/\\sqrt{Q_i}$, not $\\sqrt{Q_i}$. Verdict — Incorrect.\n\nC. Choosing a constant $Q_i = Q$ yields identical $\\tau_i = \\sqrt{Q/(g_i k_{\\mathrm{B}}T)}$ only if $g_i$ is also constant; even then, all thermostats would share the same characteristic frequency $\\omega_i$, which does not provide coverage across a band of frequencies and does not realize equal time-scale spacing. The claimed “uniform damping across the spectrum” does not follow from identical frequencies. Verdict — Incorrect.\n\nD. This option uses $Q_i \\propto r^{\\,i-1}$, which would imply $\\tau_i \\propto r^{\\tfrac{1}{2}(i-1)}$ and $\\omega_i \\propto r^{-\\tfrac{1}{2}(i-1)}$, not the target $\\tau_i \\propto r^{\\,i-1}$. Hence it does not realize equal time-scale spacing by a geometric progression in $\\tau_i$ with ratio $r$; it compresses the spacing by a square root. Verdict — Incorrect.\n\nE. This option incorporates the conventional and consistent choice $g_1 = g_{\\mathrm{phys}}$ and $g_i=1$ for $i>1$, applies $\\tau_i = \\tau_1 r^{\\,i-1}$, and sets $Q_i = g_i\\,k_{\\mathrm{B}}T\\,\\tau_i^2$, explicitly giving $Q_1 = g_{\\mathrm{phys}}\\,k_{\\mathrm{B}}T\\,\\tau_1^2$ and $Q_{i>1} = k_{\\mathrm{B}}T\\,\\tau_1^2\\, r^{\\,2(i-1)}$. The resulting $\\omega_i = \\omega_1 r^{-(i-1)}$ matches the geometric frequency distribution. This is a correct and commonly used implementation detail that remains consistent with the derived procedure. Verdict — Correct.\n\nTherefore, the correct options are A and E.", "answer": "$$\\boxed{AE}$$", "id": "2825162"}, {"introduction": "Once your simulation is running with a properly configured thermostat and barostat, the final step is to analyze the data and report results with statistical confidence. Because molecular dynamics trajectories are time-correlated, simply calculating a mean value is insufficient; we must also quantify its uncertainty. This exercise [@problem_id:2825153] bridges the gap between simulation output and reliable statistics, having you relate simulation length, observable fluctuations, and autocorrelation time to determine the runtime needed to achieve a target precision.", "problem": "In a constant Number, Pressure, Temperature (NPT) ensemble molecular dynamics simulation of liquid water at ambient conditions, you intend to report the mean pressure $\\langle P \\rangle$ with a prescribed statistical precision. Consider a stationary, ergodic pressure time series $P(t)$ generated by a simulation employing a deterministic thermostat and barostat. Define the pressure fluctuation as $\\delta P(t) = P(t) - \\langle P \\rangle$, the autocovariance function as $C_{P}(t) = \\langle \\delta P(0)\\,\\delta P(t) \\rangle$, and the normalized autocorrelation function as $\\rho_{P}(t) = C_{P}(t)/C_{P}(0)$. The integrated autocorrelation time is defined in continuous time as\n$$\n\\tau_{\\mathrm{int}} = \\int_{0}^{\\infty} \\rho_{P}(t)\\,dt,\n$$\nassumed finite and well-defined for the process. A short pilot run has supplied the following reliable estimates: the standard deviation of instantaneous pressure fluctuations $\\sigma_{P} = \\sqrt{C_{P}(0)} = 250\\ \\text{bar}$ and the integrated autocorrelation time $\\tau_{\\mathrm{int}} = 2.5\\ \\text{ps}$. You wish the standard error (root-mean-square uncertainty) of the sample mean pressure $\\overline{P}$ computed from a long production trajectory of duration $T$ to satisfy $\\operatorname{SE}[\\overline{P}] = 2.0\\ \\text{bar}$.\n\nStarting only from the fundamental definitions of time averages and two-time correlation functions, derive the asymptotic large-$T$ expression for the variance of the time-average of a correlated stationary process in terms of $C_{P}(t)$, reformulate it in terms of $\\sigma_{P}$ and $\\tau_{\\mathrm{int}}$, and then obtain an explicit expression for the minimal production length $T$ required to achieve the target standard error. Use this expression to compute the required $T$ for the given $\\sigma_{P}$ and $\\tau_{\\mathrm{int}}$. Express the final time in $\\text{ns}$, and round your answer to four significant figures.", "solution": "The problem as stated is scientifically sound, well-posed, and contains all necessary information for its resolution. It constitutes a standard exercise in the statistical analysis of time series data from molecular simulations. We proceed with the derivation and solution.\n\nThe sample mean (or time average) of the pressure, $\\overline{P}$, over a production run of duration $T$ is defined as:\n$$\n\\overline{P} = \\frac{1}{T} \\int_{0}^{T} P(t') \\, dt'\n$$\nThe variance of this sample mean, which quantifies its statistical uncertainty, is given by $\\operatorname{Var}[\\overline{P}] = \\langle (\\overline{P} - \\langle \\overline{P} \\rangle)^2 \\rangle$. For a stationary and ergodic process, the ensemble average of the time average is equal to the ensemble average of the instantaneous quantity, $\\langle \\overline{P} \\rangle = \\langle P \\rangle$. Therefore, we can write:\n$$\n\\operatorname{Var}[\\overline{P}] = \\left\\langle \\left( \\frac{1}{T} \\int_{0}^{T} P(t') \\, dt' - \\langle P \\rangle \\right)^2 \\right\\rangle\n$$\nUsing the definition of the pressure fluctuation, $\\delta P(t) = P(t) - \\langle P \\rangle$, this becomes:\n$$\n\\operatorname{Var}[\\overline{P}] = \\left\\langle \\left( \\frac{1}{T} \\int_{0}^{T} \\delta P(t') \\, dt' \\right)^2 \\right\\rangle = \\frac{1}{T^2} \\left\\langle \\left( \\int_{0}^{T} \\delta P(t') \\, dt' \\right) \\left( \\int_{0}^{T} \\delta P(t'') \\, dt'' \\right) \\right\\rangle\n$$\nWe can bring the ensemble average inside the integrals:\n$$\n\\operatorname{Var}[\\overline{P}] = \\frac{1}{T^2} \\int_{0}^{T} dt' \\int_{0}^{T} dt'' \\, \\langle \\delta P(t') \\, \\delta P(t'') \\rangle\n$$\nThe process is stationary, which means the two-time correlation function depends only on the time difference, not on the absolute times. Thus, we can write $\\langle \\delta P(t') \\, \\delta P(t'') \\rangle = C_{P}(|t' - t''|)$, where $C_{P}(t)$ is the autocovariance function. The expression for the variance becomes:\n$$\n\\operatorname{Var}[\\overline{P}] = \\frac{1}{T^2} \\int_{0}^{T} dt' \\int_{0}^{T} dt'' \\, C_{P}(|t' - t''|)\n$$\nTo evaluate this double integral, we perform a change of variables. Let $\\tau = t' - t''$ and $s = t''$. The Jacobian of this transformation is $1$. The integration domain in the $(t', t'')$ plane is a square defined by $0 \\le t' \\le T$ and $0 \\le t'' \\le T$. In the new variables $(\\tau, s)$, this corresponds to $0 \\le s \\le T$ and $-s \\le \\tau \\le T-s$. We can rewrite the integral as:\n$$\nI = \\int_{0}^{T} ds \\int_{-s}^{T-s} d\\tau \\, C_{P}(|\\tau|)\n$$\nWe can switch the order of integration. The range of $\\tau$ is from $-T$ to $T$. For a given $\\tau$, the range of $s$ is from $\\max(0, -\\tau)$ to $\\min(T, T-s)$. Wait, the upper limit for s is from $t' = \\tau+s \\le T$, so $s \\le T-\\tau$.\nThe correct limits after switching order are:\n$$\nI = \\int_{-T}^{T} d\\tau \\int_{\\max(0, -\\tau)}^{\\min(T, T-\\tau)} ds \\, C_{P}(|\\tau|)\n$$\nThe inner integral over $s$ evaluates to the length of the integration interval.\nIf $\\tau > 0$, the interval is $[0, T-\\tau]$, with length $T-\\tau$.\nIf $\\tau < 0$, the interval is $[-\\tau, T]$, with length $T-(-\\tau) = T+\\tau$.\nIn both cases, the length is $T-|\\tau|$. Therefore, the integral becomes:\n$$\nI = \\int_{-T}^{T} (T - |\\tau|) C_{P}(|\\tau|) \\, d\\tau\n$$\nSince the integrand is an even function of $\\tau$, we can write:\n$$\nI = 2 \\int_{0}^{T} (T - \\tau) C_{P}(\\tau) \\, d\\tau\n$$\nSubstituting this result back into the expression for the variance gives the exact formula:\n$$\n\\operatorname{Var}[\\overline{P}] = \\frac{2}{T^2} \\int_{0}^{T} (T - \\tau) C_{P}(\\tau) \\, d\\tau = \\frac{2}{T} \\int_{0}^{T} \\left(1 - \\frac{\\tau}{T}\\right) C_{P}(\\tau) \\, d\\tau\n$$\nThis is the first required derivation. Now we consider the asymptotic limit where the simulation time $T$ is much larger than the characteristic decay time of the correlations. In this limit, $C_P(\\tau)$ decays to approximately zero for $\\tau \\ll T$. For values of $\\tau$ where $C_P(\\tau)$ is non-negligible, the factor $(1 - \\tau/T)$ is approximately $1$. We can also extend the upper limit of the integral to infinity, as the integrand vanishes for large $\\tau$. This gives the asymptotic expression for large $T$:\n$$\n\\operatorname{Var}[\\overline{P}] \\approx \\frac{2}{T} \\int_{0}^{\\infty} C_{P}(\\tau) \\, d\\tau\n$$\nNext, we reformulate this in terms of the given quantities $\\sigma_{P}$ and $\\tau_{\\mathrm{int}}$. We are given the normalized autocorrelation function $\\rho_{P}(t) = C_{P}(t)/C_{P}(0)$ and the standard deviation $\\sigma_{P} = \\sqrt{C_{P}(0)}$. This implies $C_{P}(t) = C_{P}(0)\\rho_{P}(t) = \\sigma_{P}^{2}\\rho_{P}(t)$. Substituting this into the variance expression:\n$$\n\\operatorname{Var}[\\overline{P}] \\approx \\frac{2\\sigma_{P}^{2}}{T} \\int_{0}^{\\infty} \\rho_{P}(\\tau) \\, d\\tau\n$$\nUsing the definition of the integrated autocorrelation time, $\\tau_{\\mathrm{int}} = \\int_{0}^{\\infty} \\rho_{P}(t)\\,dt$, we obtain:\n$$\n\\operatorname{Var}[\\overline{P}] \\approx \\frac{2\\sigma_{P}^{2}\\tau_{\\mathrm{int}}}{T}\n$$\nThe standard error of the mean, $\\operatorname{SE}[\\overline{P}]$, is the square root of the variance of the mean: $\\operatorname{SE}[\\overline{P}] = \\sqrt{\\operatorname{Var}[\\overline{P}]}$. Therefore:\n$$\n\\operatorname{SE}[\\overline{P}]^2 \\approx \\frac{2\\sigma_{P}^{2}\\tau_{\\mathrm{int}}}{T}\n$$\nSolving this for the minimal production length $T$ that achieves a target standard error yields the explicit expression:\n$$\nT \\approx \\frac{2\\sigma_{P}^{2}\\tau_{\\mathrm{int}}}{\\operatorname{SE}[\\overline{P}]^2}\n$$\nNow, we substitute the provided numerical values: $\\sigma_{P} = 250\\ \\text{bar}$, $\\tau_{\\mathrm{int}} = 2.5\\ \\text{ps}$, and $\\operatorname{SE}[\\overline{P}] = 2.0\\ \\text{bar}$.\n$$\nT \\approx \\frac{2 \\times (250)^2 \\times 2.5}{(2.0)^2} \\ \\text{ps}\n$$\n$$\nT \\approx \\frac{2 \\times 62500 \\times 2.5}{4.0} \\ \\text{ps}\n$$\n$$\nT \\approx \\frac{312500}{4.0} \\ \\text{ps} = 78125 \\ \\text{ps}\n$$\nThe problem requires the answer in nanoseconds ($\\text{ns}$), where $1 \\ \\text{ns} = 1000 \\ \\text{ps}$.\n$$\nT \\approx \\frac{78125}{1000} \\ \\text{ns} = 78.125 \\ \\text{ns}\n$$\nFinally, rounding the result to four significant figures gives $78.13 \\ \\text{ns}$.", "answer": "$$\\boxed{78.13}$$", "id": "2825153"}]}