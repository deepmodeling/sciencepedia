{"hands_on_practices": [{"introduction": "The cornerstone of the Born interpretation is that the squared modulus of a wavefunction, $|\\psi|^2$, represents a probability density. For this to be physically meaningful, the total probability of finding the particle somewhere in space must be unity. This practice [@problem_id:2829832] will guide you through the essential process of normalization for a Gaussian-type orbital, a function of paramount importance in modern computational chemistry, reinforcing the direct link between the mathematical formalism and physical probability.", "problem": "An isotropic Gaussian-type orbital is proposed as a variational ansatz for an electron in a spherically symmetric field in $3$D space, given by $\\phi(\\mathbf{r}) = N \\exp(-\\alpha r^{2})$, where $\\alpha>0$ and $r = |\\mathbf{r}|$. Invoke the Born probability interpretation, which states that $|\\phi(\\mathbf{r})|^{2}$ is a probability density in configuration space, and use only first principles to determine the normalization constant $N$ such that the total probability of finding the electron anywhere in $\\mathbb{R}^{3}$ equals $1$. Work in atomic units, so that the Bohr radius $a_{0} = 1$. Express your final answer as a closed-form analytic expression for $N$ in terms of $\\alpha$. Do not include units in your final boxed answer.", "solution": "The problem is subjected to validation and is found to be scientifically grounded, well-posed, and objective. It presents a standard, solvable problem in quantum mechanics without any apparent flaws. Therefore, we proceed with a rigorous derivation of the solution.\n\nThe problem requires the determination of the normalization constant $N$ for the given isotropic Gaussian-type orbital $\\phi(\\mathbf{r}) = N \\exp(-\\alpha r^{2})$. According to the Born probability interpretation, the quantity $|\\phi(\\mathbf{r})|^{2}$ represents the probability density for the position of the electron. The condition for normalization states that the integral of this probability density over all of three-dimensional space must be equal to $1$. Mathematically, this is expressed as:\n$$ \\int_{\\mathbb{R}^3} |\\phi(\\mathbf{r})|^2 dV = 1 $$\nThe given wavefunction is a real-valued function, assuming $N$ is a real constant. Thus, $|\\phi(\\mathbf{r})|^2 = \\phi(\\mathbf{r})^2$. The normalization condition becomes:\n$$ \\int_{\\mathbb{R}^3} \\left( N \\exp(-\\alpha r^2) \\right)^2 dV = 1 $$\n$$ N^2 \\int_{\\mathbb{R}^3} \\exp(-2\\alpha r^2) dV = 1 $$\nThe integrand $\\exp(-2\\alpha r^2)$ possesses spherical symmetry, as it depends only on the radial distance $r = |\\mathbf{r}|$. It is therefore highly advantageous to perform the integration in spherical coordinates. The differential volume element $dV$ in spherical coordinates is given by $dV = r^2 \\sin\\theta \\, dr \\, d\\theta \\, d\\phi$, where the integration limits are $r \\in [0, \\infty)$, $\\theta \\in [0, \\pi]$, and $\\phi \\in [0, 2\\pi]$.\n\nSubstituting the volume element into the normalization integral, we obtain:\n$$ N^2 \\int_0^{2\\pi} \\int_0^\\pi \\int_0^\\infty \\exp(-2\\alpha r^2) r^2 \\sin\\theta \\, dr \\, d\\theta \\, d\\phi = 1 $$\nThe integrand is independent of the angles $\\theta$ and $\\phi$. This allows for the separation of the integral into a product of three one-dimensional integrals:\n$$ N^2 \\left( \\int_0^{2\\pi} d\\phi \\right) \\left( \\int_0^\\pi \\sin\\theta \\, d\\theta \\right) \\left( \\int_0^\\infty r^2 \\exp(-2\\alpha r^2) \\, dr \\right) = 1 $$\nThe angular integrals are standard and evaluate as follows:\n$$ \\int_0^{2\\pi} d\\phi = [\\phi]_0^{2\\pi} = 2\\pi $$\n$$ \\int_0^\\pi \\sin\\theta \\, d\\theta = [-\\cos\\theta]_0^\\pi = (-\\cos\\pi) - (-\\cos 0) = -(-1) - (-1) = 2 $$\nThe product of the angular integrals yields the total solid angle of a sphere, which is $4\\pi$. The normalization equation thus simplifies to:\n$$ 4\\pi N^2 \\int_0^\\infty r^2 \\exp(-2\\alpha r^2) \\, dr = 1 $$\nWe must now evaluate the remaining radial integral, which we denote as $I_r$:\n$$ I_r = \\int_0^\\infty r^2 \\exp(-2\\alpha r^2) \\, dr $$\nThis is a standard form of a Gaussian integral. We use the general formula:\n$$ \\int_0^\\infty x^n \\exp(-ax^2) \\, dx = \\frac{\\Gamma\\left(\\frac{n+1}{2}\\right)}{2a^{(n+1)/2}} $$\nIn our integral $I_r$, we have $n=2$ and the parameter $a = 2\\alpha$. Applying the formula:\n$$ I_r = \\frac{\\Gamma\\left(\\frac{2+1}{2}\\right)}{2(2\\alpha)^{(2+1)/2}} = \\frac{\\Gamma\\left(\\frac{3}{2}\\right)}{2(2\\alpha)^{3/2}} $$\nUsing the properties of the Gamma function, $\\Gamma(z+1) = z\\Gamma(z)$ and $\\Gamma(1/2) = \\sqrt{\\pi}$, we find:\n$$ \\Gamma\\left(\\frac{3}{2}\\right) = \\Gamma\\left(\\frac{1}{2} + 1\\right) = \\frac{1}{2}\\Gamma\\left(\\frac{1}{2}\\right) = \\frac{\\sqrt{\\pi}}{2} $$\nSubstituting this result back into the expression for $I_r$:\n$$ I_r = \\frac{\\frac{\\sqrt{\\pi}}{2}}{2(2\\alpha)^{3/2}} = \\frac{\\sqrt{\\pi}}{4(2\\alpha)^{3/2}} $$\nNow, we substitute the value of the integral $I_r$ back into the normalization equation:\n$$ 4\\pi N^2 \\left( \\frac{\\sqrt{\\pi}}{4(2\\alpha)^{3/2}} \\right) = 1 $$\nWe solve for $N^2$:\n$$ N^2 \\frac{\\pi \\sqrt{\\pi}}{(2\\alpha)^{3/2}} = 1 $$\n$$ N^2 \\frac{\\pi^{3/2}}{(2\\alpha)^{3/2}} = 1 \\implies N^2 \\left( \\frac{\\pi}{2\\alpha} \\right)^{3/2} = 1 $$\nSolving for $N^2$:\n$$ N^2 = \\left( \\frac{\\pi}{2\\alpha} \\right)^{-3/2} = \\left( \\frac{2\\alpha}{\\pi} \\right)^{3/2} $$\nBy convention, the normalization constant $N$ for a real wavefunction is taken to be real and positive. Taking the square root of both sides gives the final expression for $N$:\n$$ N = \\left[ \\left( \\frac{2\\alpha}{\\pi} \\right)^{3/2} \\right]^{1/2} = \\left( \\frac{2\\alpha}{\\pi} \\right)^{3/4} $$\nThis is the closed-form analytic expression for the normalization constant in terms of the parameter $\\alpha$.", "answer": "$$\\boxed{\\left(\\frac{2\\alpha}{\\pi}\\right)^{3/4}}$$", "id": "2829832"}, {"introduction": "While single wavefunctions are fundamental, quantum systems are often described by linear combinations of functions from a basis set. For calculating probabilities efficiently, it is highly advantageous for this basis to be orthonormal. This exercise [@problem_id:2829863] demonstrates the Gram-Schmidt procedure, a powerful constructive method to build an orthonormal basis from any linearly independent set, and reveals why this property is crucial for the practical application of the Born rule.", "problem": "Consider the Hilbert space $\\mathcal{H} = L^{2}([0,1])$ of square-integrable complex-valued functions on $[0,1]$ with the standard inner product $\\langle \\varphi | \\chi \\rangle = \\int_{0}^{1} \\varphi^{\\ast}(x)\\,\\chi(x)\\,dx$. Let the linearly independent set be $\\{f_{1}, f_{2}\\}$ with $f_{1}(x) = 1$ and $f_{2}(x) = x$.\n\n- Using only the definition of the inner product and normalization, construct an orthonormal set $\\{\\phi_{1}, \\phi_{2}\\}$ from $\\{f_{1}, f_{2}\\}$ via the Gram–Schmidt procedure.\n- Let $\\psi(x) = A\\,(1+x)$ with $A$ chosen so that $\\psi$ is normalized in $\\mathcal{H}$. Suppose we perform a measurement of an observable $\\hat{O}$ whose eigenfunctions form a complete orthonormal basis of $\\mathcal{H}$ that contains $\\{\\phi_{1}, \\phi_{2}\\}$ as its first two elements. Using the Born probability interpretation and starting from the definitions above, compute the probability to obtain the eigenvalue associated with $\\phi_{1}$ when the system is in state $\\psi$.\n- Briefly justify, in terms of the definitions you used, why orthonormality simplifies the computation of Born probabilities compared to using a merely linearly independent but non-orthonormal set.\n\nProvide the probability as an exact number. No rounding is required. Express your final answer as a pure number without units.", "solution": "The problem as stated is scientifically grounded, well-posed, and objective. It is a standard exercise in quantum mechanics, specifically concerning the properties of Hilbert spaces and the postulates of quantum measurement. All provided information is self-contained and consistent. Therefore, we may proceed with a formal solution.\n\nThe problem is partitioned into three tasks. We will address each in sequence.\n\nFirst, we must construct an orthonormal set $\\{\\phi_{1}, \\phi_{2}\\}$ from the linearly independent set $\\{f_{1}, f_{2}\\}$ where $f_{1}(x) = 1$ and $f_{2}(x) = x$ in the Hilbert space $\\mathcal{H} = L^{2}([0,1])$. The inner product is defined as $\\langle \\varphi | \\chi \\rangle = \\int_{0}^{1} \\varphi^{\\ast}(x)\\,\\chi(x)\\,dx$. We apply the Gram–Schmidt orthonormalization procedure.\n\nStep 1: Normalize the first function, $f_{1}(x)$. The first vector of our orthonormal set, $\\phi_{1}$, is given by the normalization of $f_{1}$.\nThe norm squared of $f_{1}$ is:\n$$ \\|f_{1}\\|^{2} = \\langle f_{1} | f_{1} \\rangle = \\int_{0}^{1} (1)^{\\ast}(1)\\,dx = \\int_{0}^{1} 1\\,dx = [x]_{0}^{1} = 1 $$\nSince the norm $\\|f_{1}\\| = \\sqrt{1} = 1$, the function $f_{1}$ is already normalized. Thus,\n$$ \\phi_{1}(x) = \\frac{f_{1}(x)}{\\|f_{1}\\|} = 1 $$\n\nStep 2: Construct the second orthonormal function, $\\phi_{2}$. We first define a vector $u_{2}$ that is orthogonal to $\\phi_{1}$ by subtracting the projection of $f_{2}$ onto $\\phi_{1}$ from $f_{2}$:\n$$ u_{2}(x) = f_{2}(x) - \\langle \\phi_{1} | f_{2} \\rangle \\phi_{1}(x) $$\nWe must compute the inner product $\\langle \\phi_{1} | f_{2} \\rangle$:\n$$ \\langle \\phi_{1} | f_{2} \\rangle = \\int_{0}^{1} \\phi_{1}^{\\ast}(x) f_{2}(x) \\,dx = \\int_{0}^{1} (1)^{\\ast}(x) \\,dx = \\int_{0}^{1} x \\,dx = \\left[\\frac{x^{2}}{2}\\right]_{0}^{1} = \\frac{1}{2} $$\nSubstituting this result, we find $u_{2}(x)$:\n$$ u_{2}(x) = x - \\left(\\frac{1}{2}\\right)(1) = x - \\frac{1}{2} $$\nNow, we normalize $u_{2}(x)$ to obtain $\\phi_{2}(x)$. We first calculate the norm squared of $u_{2}$:\n$$ \\|u_{2}\\|^{2} = \\langle u_{2} | u_{2} \\rangle = \\int_{0}^{1} \\left(x - \\frac{1}{2}\\right)^{\\ast}\\left(x - \\frac{1}{2}\\right)\\,dx = \\int_{0}^{1} \\left(x - \\frac{1}{2}\\right)^{2}\\,dx $$\n$$ \\|u_{2}\\|^{2} = \\int_{0}^{1} \\left(x^{2} - x + \\frac{1}{4}\\right)\\,dx = \\left[\\frac{x^{3}}{3} - \\frac{x^{2}}{2} + \\frac{x}{4}\\right]_{0}^{1} = \\frac{1}{3} - \\frac{1}{2} + \\frac{1}{4} = \\frac{4 - 6 + 3}{12} = \\frac{1}{12} $$\nThe norm is $\\|u_{2}\\| = \\sqrt{\\frac{1}{12}} = \\frac{1}{2\\sqrt{3}}$.\nFinally, $\\phi_{2}(x)$ is:\n$$ \\phi_{2}(x) = \\frac{u_{2}(x)}{\\|u_{2}\\|} = \\frac{x - \\frac{1}{2}}{1/(2\\sqrt{3})} = 2\\sqrt{3}\\left(x - \\frac{1}{2}\\right) = \\sqrt{3}(2x-1) $$\nThe constructed orthonormal set is $\\{\\phi_{1}(x), \\phi_{2}(x)\\} = \\{1, \\sqrt{3}(2x-1)\\}$.\n\nSecond, we are asked to compute the probability of obtaining the eigenvalue associated with $\\phi_{1}$ when the system is in the state $\\psi(x) = A\\,(1+x)$.\nFirst, the state $\\psi(x)$ must be normalized. The normalization condition is $\\langle \\psi | \\psi \\rangle = 1$. Let's assume $A$ is a real, positive constant.\n$$ \\langle \\psi | \\psi \\rangle = \\int_{0}^{1} [A(1+x)]^{\\ast}[A(1+x)]\\,dx = A^{2} \\int_{0}^{1} (1+x)^{2}\\,dx = 1 $$\n$$ \\int_{0}^{1} (1+2x+x^{2})\\,dx = \\left[x + x^{2} + \\frac{x^{3}}{3}\\right]_{0}^{1} = 1 + 1 + \\frac{1}{3} = \\frac{7}{3} $$\nTherefore, $A^{2} \\left(\\frac{7}{3}\\right) = 1$, which gives $A^{2} = \\frac{3}{7}$, and so $A = \\sqrt{\\frac{3}{7}}$.\nThe normalized state is $\\psi(x) = \\sqrt{\\frac{3}{7}}(1+x)$.\n\nAccording to the Born probability interpretation, the probability $P(\\lambda_{1})$ of measuring the eigenvalue $\\lambda_{1}$ corresponding to the eigenfunction $\\phi_{1}$ is the squared magnitude of the projection of the state vector $\\psi$ onto the eigenstate $\\phi_{1}$. This projection is given by the inner product $\\langle \\phi_{1} | \\psi \\rangle$.\n$$ P(\\lambda_{1}) = |\\langle \\phi_{1} | \\psi \\rangle|^{2} $$\nWe compute the inner product:\n$$ \\langle \\phi_{1} | \\psi \\rangle = \\int_{0}^{1} \\phi_{1}^{\\ast}(x)\\psi(x)\\,dx = \\int_{0}^{1} (1)^{\\ast} \\left(\\sqrt{\\frac{3}{7}}(1+x)\\right)\\,dx $$\n$$ \\langle \\phi_{1} | \\psi \\rangle = \\sqrt{\\frac{3}{7}} \\int_{0}^{1} (1+x)\\,dx = \\sqrt{\\frac{3}{7}} \\left[x + \\frac{x^{2}}{2}\\right]_{0}^{1} = \\sqrt{\\frac{3}{7}} \\left(1 + \\frac{1}{2}\\right) = \\sqrt{\\frac{3}{7}} \\left(\\frac{3}{2}\\right) $$\nNow, we calculate the probability:\n$$ P(\\lambda_{1}) = \\left|\\sqrt{\\frac{3}{7}} \\left(\\frac{3}{2}\\right)\\right|^{2} = \\left(\\frac{3}{7}\\right) \\left(\\frac{3}{2}\\right)^{2} = \\left(\\frac{3}{7}\\right) \\left(\\frac{9}{4}\\right) = \\frac{27}{28} $$\n\nThird, we must justify why orthonormality simplifies the computation.\nAny state $\\psi$ in the Hilbert space can be expanded in terms of a complete basis of eigenfunctions $\\{\\phi_{i}\\}$ of an observable $\\hat{O}$:\n$$ |\\psi\\rangle = \\sum_{i} c_{i} |\\phi_{i}\\rangle $$\nwhere $c_{i}$ are the expansion coefficients. The Born rule states that the probability of measuring the eigenvalue corresponding to $\\phi_{j}$ is $|c_{j}|^{2}$. The core of the problem is to find these coefficients $c_{j}$.\n\nIf the basis $\\{\\phi_{i}\\}$ is orthonormal, meaning $\\langle \\phi_{j} | \\phi_{i} \\rangle = \\delta_{ij}$ (the Kronecker delta), the coefficients can be found by a simple projection. We take the inner product of the expansion with $\\langle \\phi_{j} |$:\n$$ \\langle \\phi_{j} | \\psi \\rangle = \\left\\langle \\phi_{j} \\left| \\sum_{i} c_{i} \\right|\\phi_{i}\\right\\rangle = \\sum_{i} c_{i} \\langle \\phi_{j} | \\phi_{i} \\rangle = \\sum_{i} c_{i} \\delta_{ij} = c_{j} $$\nThus, for an orthonormal basis, each coefficient $c_{j}$ is given directly by the inner product $c_{j} = \\langle \\phi_{j} | \\psi \\rangle$. This is a single, independent calculation for each coefficient.\n\nIn contrast, if we were to use a non-orthonormal basis, such as the original set $\\{f_{i}\\}$, the expansion would be $|\\psi\\rangle = \\sum_{i} d_{i} |f_{i}\\rangle$. To find the coefficients $d_{j}$, projecting with $\\langle f_{j} |$ gives:\n$$ \\langle f_{j} | \\psi \\rangle = \\sum_{i} d_{i} \\langle f_{j} | f_{i} \\rangle $$\nThe terms $\\langle f_{j} | f_{i} \\rangle$ are the elements of the Gram matrix $G_{ji}$. This equation represents a system of coupled linear algebraic equations for the coefficients $\\{d_{i}\\}$, which must be solved by matrix inversion ($d = G^{-1} \\langle f | \\psi \\rangle$). This is computationally far more complex than the direct evaluation of integrals for the orthonormal case. Orthonormality diagonalizes the Gram matrix, decoupling the equations and thus simplifying the calculation of expansion coefficients, which are the fundamental quantities for computing Born probabilities.", "answer": "$$ \\boxed{\\frac{27}{28}} $$", "id": "2829863"}, {"introduction": "Real chemical systems, particularly those with high symmetry, often exhibit degeneracy, where multiple distinct quantum states share the same energy. In such cases, the probability of measuring a degenerate eigenvalue is not found by projecting onto a single state, but onto the entire subspace of degenerate states. This advanced problem [@problem_id:2829855] introduces the formal mechanism for handling degeneracy using projection operators, providing a more general and powerful application of the Born rule essential for describing complex molecular spectra and properties.", "problem": "A single-electron subspace of a molecular Hilbert space is modeled as a finite-dimensional complex Hilbert space $\\mathcal{H}=\\mathbb{C}^{4}$. An observable $\\hat{A}$ (for example, an effective electronic Hamiltonian restricted to a symmetry-adapted subspace) is represented by a self-adjoint operator on $\\mathcal{H}$. By the spectral theorem, there exists a projection-valued measure (PVM) $E(\\cdot)$ on the Borel subsets of $\\mathbb{R}$ such that $\\hat{A}=\\int_{\\mathbb{R}} \\lambda\\, \\mathrm{d}E(\\lambda)$. According to the Born probability rule, a normalized state $|\\psi\\rangle \\in \\mathcal{H}$ induces a probability measure $\\mu_{\\psi}$ on outcomes defined by $\\mu_{\\psi}(\\Delta)=\\langle \\psi|E(\\Delta)|\\psi\\rangle$ for any Borel set $\\Delta\\subset\\mathbb{R}$.\n\nIn this model, $\\hat{A}$ has a degenerate eigenvalue $a\\in\\mathbb{R}$ with eigenspace $\\mathcal{H}_{a}$ of dimension greater than one:\n- The eigenspace $\\mathcal{H}_{a}$ is two-dimensional, spanned by the orthonormal vectors\n$$\n|u_{1}\\rangle=\\frac{1}{\\sqrt{2}}\\begin{pmatrix}1 \\\\[4pt] 0 \\\\[4pt] 1 \\\\[4pt] 0\\end{pmatrix},\\qquad\n|u_{2}\\rangle=\\frac{1}{\\sqrt{2}}\\begin{pmatrix}0 \\\\[4pt] 1 \\\\[4pt] 0 \\\\[4pt] 1\\end{pmatrix}.\n$$\n- The remaining orthonormal eigenvectors (corresponding to nondegenerate eigenvalues $b$ and $c$) complete an orthonormal basis, for example\n$$\n|u_{3}\\rangle=\\frac{1}{\\sqrt{2}}\\begin{pmatrix}1 \\\\[4pt] 0 \\\\[4pt] -1 \\\\[4pt] 0\\end{pmatrix},\\qquad\n|u_{4}\\rangle=\\frac{1}{\\sqrt{2}}\\begin{pmatrix}0 \\\\[4pt] 1 \\\\[4pt] 0 \\\\[4pt] -1\\end{pmatrix}.\n$$\n\nA normalized state vector is prepared as\n$$\n|\\psi\\rangle=\\frac{1}{\\sqrt{6}}\\begin{pmatrix}1 \\\\[4pt] 1 \\\\[4pt] 2 \\\\[4pt] 0\\end{pmatrix}.\n$$\n\nTasks:\n1) Using only the definitions stated above, explain how the degeneracy of the eigenvalue $a$ is represented within the projection-valued measure $E(\\cdot)$, and write $E(\\{a\\})$ explicitly in operator form for this example.\n\n2) Using the Born probability rule and your expression for $E(\\{a\\})$, compute the probability $\\Pr(a)$ that a measurement of $\\hat{A}$ on the state $|\\psi\\rangle$ yields the outcome $a$. Provide the final result as an exact number. No rounding is required, and no units are involved.", "solution": "The problem as stated is subjected to validation and is found to be scientifically grounded, well-posed, and internally consistent. It provides a formal and precise framework based on the principles of quantum mechanics in a finite-dimensional Hilbert space. All provided data, including the vector components and normalizations, are correct and sufficient for a unique solution. We may therefore proceed with the solution.\n\nThe problem is divided into two parts. The first requires an explanation of the representation of degeneracy within the projection-valued measure (PVM) formalism and the explicit construction of the projector for the degenerate eigenvalue. The second part requires the calculation of a measurement probability using the Born rule.\n\n**Part 1: The Projector for the Degenerate Eigenspace**\n\nAccording to the spectral theorem for self-adjoint operators, the operator $\\hat{A}$ can be written as $\\hat{A} = \\int_{\\mathbb{R}} \\lambda\\,\\mathrm{d}E(\\lambda)$, where $E$ is a projection-valued measure. For any Borel set $\\Delta \\subset \\mathbb{R}$, $E(\\Delta)$ is a projection operator. Specifically, for a discrete eigenvalue $a$ of $\\hat{A}$, the operator $E(\\{a\\})$ is the orthogonal projection onto the eigenspace $\\mathcal{H}_a$ corresponding to that eigenvalue.\n\nIn this problem, the eigenvalue $a$ is degenerate, and its corresponding eigenspace $\\mathcal{H}_a$ is a two-dimensional subspace of $\\mathcal{H}=\\mathbb{C}^{4}$. The problem states that $\\mathcal{H}_a$ is spanned by the orthonormal vectors $|u_1\\rangle$ and $|u_2\\rangle$.\n\nThe projection operator $P_a$ onto a subspace spanned by an orthonormal set of vectors $\\{|v_i\\rangle\\}$ is given by $P_a = \\sum_i |v_i\\rangle\\langle v_i|$. Therefore, the degeneracy of eigenvalue $a$ is represented by the fact that the projector $E(\\{a\\})$ is a sum of more than one rank-one projector. For this specific case, the projector onto $\\mathcal{H}_a$ is:\n$$\nE(\\{a\\}) = P_a = |u_1\\rangle\\langle u_1| + |u_2\\rangle\\langle u_2|\n$$\nWe now construct this operator explicitly in matrix form. The given vectors are:\n$$\n|u_1\\rangle = \\frac{1}{\\sqrt{2}}\\begin{pmatrix} 1 \\\\ 0 \\\\ 1 \\\\ 0 \\end{pmatrix}, \\quad |u_2\\rangle = \\frac{1}{\\sqrt{2}}\\begin{pmatrix} 0 \\\\ 1 \\\\ 0 \\\\ 1 \\end{pmatrix}\n$$\nThe corresponding bra-vectors are:\n$$\n\\langle u_1| = \\frac{1}{\\sqrt{2}}\\begin{pmatrix} 1 & 0 & 1 & 0 \\end{pmatrix}, \\quad \\langle u_2| = \\frac{1}{\\sqrt{2}}\\begin{pmatrix} 0 & 1 & 0 & 1 \\end{pmatrix}\n$$\nThe individual rank-one projectors are calculated as outer products:\n$$\n|u_1\\rangle\\langle u_1| = \\frac{1}{2} \\begin{pmatrix} 1 \\\\ 0 \\\\ 1 \\\\ 0 \\end{pmatrix} \\begin{pmatrix} 1 & 0 & 1 & 0 \\end{pmatrix} = \\frac{1}{2} \\begin{pmatrix}\n1 & 0 & 1 & 0 \\\\\n0 & 0 & 0 & 0 \\\\\n1 & 0 & 1 & 0 \\\\\n0 & 0 & 0 & 0\n\\end{pmatrix}\n$$\n$$\n|u_2\\rangle\\langle u_2| = \\frac{1}{2} \\begin{pmatrix} 0 \\\\ 1 \\\\ 0 \\\\ 1 \\end{pmatrix} \\begin{pmatrix} 0 & 1 & 0 & 1 \\end{pmatrix} = \\frac{1}{2} \\begin{pmatrix}\n0 & 0 & 0 & 0 \\\\\n0 & 1 & 0 & 1 \\\\\n0 & 0 & 0 & 0 \\\\\n0 & 1 & 0 & 1\n\\end{pmatrix}\n$$\nSumming these two matrices gives the explicit form for $E(\\{a\\})$:\n$$\nE(\\{a\\}) = \\frac{1}{2} \\begin{pmatrix}\n1 & 0 & 1 & 0 \\\\\n0 & 1 & 0 & 1 \\\\\n1 & 0 & 1 & 0 \\\\\n0 & 1 & 0 & 1\n\\end{pmatrix}\n$$\n\n**Part 2: Calculation of the Probability**\n\nThe Born probability rule states that the probability $\\Pr(a)$ of obtaining the outcome $a$ when measuring the observable $\\hat{A}$ on a system in the normalized state $|\\psi\\rangle$ is given by the expectation value of the corresponding projection operator.\n$$\n\\Pr(a) = \\mu_{\\psi}(\\{a\\}) = \\langle\\psi|E(\\{a\\})|\\psi\\rangle\n$$\nUsing the expression for $E(\\{a\\})$ from Part $1$, we have:\n$$\n\\Pr(a) = \\langle\\psi|(|u_1\\rangle\\langle u_1| + |u_2\\rangle\\langle u_2|)|\\psi\\rangle\n$$\nBy linearity of the inner product, this separates into:\n$$\n\\Pr(a) = \\langle\\psi|u_1\\rangle\\langle u_1|\\psi\\rangle + \\langle\\psi|u_2\\rangle\\langle u_2|\\psi\\rangle\n$$\nThis is equivalent to the sum of the squared magnitudes of the projection amplitudes of $|\\psi\\rangle$ onto the basis vectors of the eigenspace $\\mathcal{H}_a$:\n$$\n\\Pr(a) = |\\langle u_1|\\psi\\rangle|^2 + |\\langle u_2|\\psi\\rangle|^2\n$$\nWe are given the state vector:\n$$\n|\\psi\\rangle = \\frac{1}{\\sqrt{6}}\\begin{pmatrix} 1 \\\\ 1 \\\\ 2 \\\\ 0 \\end{pmatrix}\n$$\nWe now compute the required inner products:\n$$\n\\langle u_1|\\psi\\rangle = \\left( \\frac{1}{\\sqrt{2}}\\begin{pmatrix} 1 & 0 & 1 & 0 \\end{pmatrix} \\right) \\left( \\frac{1}{\\sqrt{6}}\\begin{pmatrix} 1 \\\\ 1 \\\\ 2 \\\\ 0 \\end{pmatrix} \\right) = \\frac{1}{\\sqrt{12}} (1 \\cdot 1 + 0 \\cdot 1 + 1 \\cdot 2 + 0 \\cdot 0) = \\frac{3}{\\sqrt{12}} = \\frac{3}{2\\sqrt{3}} = \\frac{\\sqrt{3}}{2}\n$$\n$$\n\\langle u_2|\\psi\\rangle = \\left( \\frac{1}{\\sqrt{2}}\\begin{pmatrix} 0 & 1 & 0 & 1 \\end{pmatrix} \\right) \\left( \\frac{1}{\\sqrt{6}}\\begin{pmatrix} 1 \\\\ 1 \\\\ 2 \\\\ 0 \\end{pmatrix} \\right) = \\frac{1}{\\sqrt{12}} (0 \\cdot 1 + 1 \\cdot 1 + 0 \\cdot 2 + 1 \\cdot 0) = \\frac{1}{\\sqrt{12}} = \\frac{1}{2\\sqrt{3}}\n$$\nNow, we square the magnitudes and sum them to find the probability:\n$$\n|\\langle u_1|\\psi\\rangle|^2 = \\left(\\frac{\\sqrt{3}}{2}\\right)^2 = \\frac{3}{4}\n$$\n$$\n|\\langle u_2|\\psi\\rangle|^2 = \\left(\\frac{1}{2\\sqrt{3}}\\right)^2 = \\frac{1}{4 \\cdot 3} = \\frac{1}{12}\n$$\nThe total probability is the sum:\n$$\n\\Pr(a) = \\frac{3}{4} + \\frac{1}{12} = \\frac{9}{12} + \\frac{1}{12} = \\frac{10}{12} = \\frac{5}{6}\n$$\nThis is the final answer. The calculation is exact and no approximation is necessary.", "answer": "$$\\boxed{\\frac{5}{6}}$$", "id": "2829855"}]}