{"hands_on_practices": [{"introduction": "Before diving into complex numerical applications, it is essential to build intuition with a model that can be solved completely by hand. This exercise tasks you with finding the analytical solution to the $2 \\times 2$ generalized eigenvalue problem, the simplest non-trivial application of the linear variation method. By deriving the energies and analyzing their behavior as the basis set transforms from orthogonal ($s \\to 0$) to linearly dependent ($s \\to 1$), you will gain a concrete understanding of how the overlap matrix $S$ fundamentally shapes the energy spectrum [@problem_id:2902363].", "problem": "In the linear variational method for the time-independent electronic Schrödinger equation, one minimizes the Rayleigh quotient $E[\\mathbf{c}]=\\dfrac{\\mathbf{c}^{\\mathsf{T}}\\,\\mathbf{H}\\,\\mathbf{c}}{\\mathbf{c}^{\\mathsf{T}}\\,\\mathbf{S}\\,\\mathbf{c}}$ over nonzero coefficient vectors $\\mathbf{c}$ spanning a finite, non-orthogonal basis $\\{\\chi_{1},\\chi_{2}\\}$. Consider a $2\\times 2$ Hamiltonian matrix $\\mathbf{H}=\\begin{pmatrix} h_{11} & h_{12} \\\\ h_{12} & h_{22}\\end{pmatrix}$ and a symmetric overlap matrix $\\mathbf{S}=\\begin{pmatrix} 1 & s \\\\ s & 1 \\end{pmatrix}$ with $|s|<1$ so that $\\mathbf{S}$ is positive definite. Assume $h_{11},h_{22},h_{12}\\in\\mathbb{R}$, and that $\\mathbf{H}$ is symmetric. \n\nStarting from the Rayleigh-Ritz variational principle (no pre-orthogonalization), derive the stationarity condition and the associated secular equation that determines the generalized eigenvalues. Solve analytically for the two generalized eigenvalues as functions of $h_{11}$, $h_{22}$, $h_{12}$, and $s$. Then analyze the limits $s\\to 0$ and $s\\to 1^{-}$, explaining what happens physically and mathematically in each case, and extract the finite limit of the eigenvalue that remains finite as $s\\to 1^{-}$ (if it exists generically).\n\nProvide your final answer as a single row matrix containing, in this order: \n- the larger-root branch $E_{+}(s)$,\n- the smaller-root branch $E_{-}(s)$,\n- the limits $\\lim_{s\\to 0}E_{+}(s)$ and $\\lim_{s\\to 0}E_{-}(s)$,\n- and the finite limit $\\lim_{s\\to 1^{-}}E_{\\mathrm{finite}}(s)$.\n\nNo numerical evaluation is required; give exact closed-form expressions. No units are needed. Do not include any additional commentary in the final answer.", "solution": "The starting point is the Rayleigh-Ritz variational principle, which asserts that approximate stationary energies in a finite basis are stationary values of the Rayleigh quotient $E[\\mathbf{c}]=\\dfrac{\\mathbf{c}^{\\mathsf{T}}\\,\\mathbf{H}\\,\\mathbf{c}}{\\mathbf{c}^{\\mathsf{T}}\\,\\mathbf{S}\\,\\mathbf{c}}$ under variations of the coefficient vector $\\mathbf{c}\\neq \\mathbf{0}$. Stationarity with respect to $\\delta \\mathbf{c}$, subject to the constraint $\\mathbf{c}^{\\mathsf{T}}\\mathbf{S}\\mathbf{c}=1$ (or equivalently by introducing a Lagrange multiplier), yields the generalized eigenvalue equation\n$$\n\\mathbf{H}\\,\\mathbf{c}=E\\,\\mathbf{S}\\,\\mathbf{c}.\n$$\nNontrivial coefficients $\\mathbf{c}$ exist only if the determinant of the coefficient matrix is zero, leading to the secular equation\n$$\n\\det(\\mathbf{H}-E\\,\\mathbf{S})=0.\n$$\nFor the given $2\\times 2$ matrices\n$$\n\\mathbf{H}-E\\,\\mathbf{S}=\\begin{pmatrix}\nh_{11}-E & h_{12}-E s\\\\\nh_{12}-E s & h_{22}-E\n\\end{pmatrix}.\n$$\nThe determinant is\n$$\n\\det(\\mathbf{H}-E\\,\\mathbf{S})=(h_{11}-E)(h_{22}-E)-(h_{12}-E s)^{2}=0.\n$$\nExpanding and collecting powers of $E$ gives a quadratic equation\n$$\n(1-s^{2})\\,E^{2}+\\bigl(2 s\\,h_{12}-(h_{11}+h_{22})\\bigr)\\,E+\\bigl(h_{11}\\,h_{22}-h_{12}^{2}\\bigr)=0.\n$$\nDefine the coefficients\n$$\na=1-s^{2},\\qquad b=2 s\\,h_{12}-(h_{11}+h_{22}),\\qquad c=h_{11}\\,h_{22}-h_{12}^{2}.\n$$\nSince $|s|<1$, we have $a>0$. The generalized eigenvalues are then given by the quadratic formula\n$$\nE_{\\pm}(s)=\\frac{-b\\pm\\sqrt{b^{2}-4 a c}}{2 a}.\n$$\nSubstituting $a,b,c$ explicitly yields\n$$\nE_{\\pm}(s)=\\frac{(h_{11}+h_{22}-2 s\\,h_{12})\\pm\\sqrt{\\bigl(h_{11}+h_{22}-2 s\\,h_{12}\\bigr)^{2}-4(1-s^{2})\\bigl(h_{11}\\,h_{22}-h_{12}^{2}\\bigr)}}{2(1-s^{2})}.\n$$\nThis gives the exact analytical expressions for the two generalized eigenvalues. Because $\\mathbf{H}$ is symmetric and $\\mathbf{S}$ is symmetric positive definite for $|s|<1$, these generalized eigenvalues are real.\n\nNow analyze the limits:\n\n1) Limit $s\\to 0$. In this case $\\mathbf{S}\\to \\mathbf{I}$ and the basis becomes orthonormal. Setting $s=0$ directly in the quadratic gives\n$$\nE_{\\pm}(0)=\\frac{(h_{11}+h_{22})\\pm\\sqrt{(h_{11}-h_{22})^{2}+4 h_{12}^{2}}}{2},\n$$\nwhich are precisely the usual eigenvalues of the symmetric $2\\times 2$ matrix $\\mathbf{H}$ in an orthonormal basis.\n\n2) Limit $s\\to 1^{-}$. As $s\\to 1^{-}$, the overlap matrix $\\mathbf{S}$ develops one vanishing eigenvalue, reflecting that the two basis vectors become linearly dependent. The secular equation coefficients behave as $a=1-s^{2}\\to 0^{+}$, $b\\to 2 h_{12}-(h_{11}+h_{22})$, and $c$ remains constant. One expects one root to diverge in magnitude while the other can remain finite. This can be seen from Viète’s formulas for the quadratic:\n$$\nE_{+}(s)+E_{-}(s)=\\frac{h_{11}+h_{22}-2 s\\,h_{12}}{1-s^{2}},\\qquad E_{+}(s)\\,E_{-}(s)=\\frac{h_{11}\\,h_{22}-h_{12}^{2}}{1-s^{2}}.\n$$\nIf $E_{\\mathrm{fin}}(s)$ denotes the branch that remains finite as $s\\to 1^{-}$, then\n$$\nE_{\\mathrm{fin}}(s)=\\frac{E_{+}(s)\\,E_{-}(s)}{E_{+}(s)+E_{-}(s)}=\\frac{h_{11}\\,h_{22}-h_{12}^{2}}{h_{11}+h_{22}-2 s\\,h_{12}}.\n$$\nTaking the limit $s\\to 1^{-}$ yields the finite limit\n$$\n\\lim_{s\\to 1^{-}}E_{\\mathrm{fin}}(s)=\\frac{h_{11}\\,h_{22}-h_{12}^{2}}{h_{11}+h_{22}-2 h_{12}},\n$$\nprovided $h_{11}+h_{22}-2 h_{12}\\neq 0$ (the generic case). In the exceptional case $h_{11}+h_{22}-2 h_{12}=0$, the finite limit ceases to exist unless also $h_{11}\\,h_{22}-h_{12}^{2}=0$, in which case the problem is further degenerate. The other root diverges in magnitude as\n$$\nE_{\\mathrm{div}}(s)\\sim \\frac{h_{11}+h_{22}-2 s\\,h_{12}}{1-s^{2}},\n$$\nreflecting the collapse of the variational space to a one-dimensional subspace when the two basis vectors become linearly dependent.\n\nCollecting the requested results, we provide $E_{+}(s)$, $E_{-}(s)$, $\\lim_{s\\to 0}E_{+}(s)$, $\\lim_{s\\to 0}E_{-}(s)$, and $\\lim_{s\\to 1^{-}}E_{\\mathrm{fin}}(s)$ in closed form.", "answer": "$$\\boxed{\\begin{pmatrix}\n\\dfrac{(h_{11}+h_{22}-2 s\\,h_{12})+\\sqrt{\\bigl(h_{11}+h_{22}-2 s\\,h_{12}\\bigr)^{2}-4(1-s^{2})\\bigl(h_{11}\\,h_{22}-h_{12}^{2}\\bigr)}}{2(1-s^{2})} &\n\\dfrac{(h_{11}+h_{22}-2 s\\,h_{12})-\\sqrt{\\bigl(h_{11}+h_{22}-2 s\\,h_{12}\\bigr)^{2}-4(1-s^{2})\\bigl(h_{11}\\,h_{22}-h_{12}^{2}\\bigr)}}{2(1-s^{2})} &\n\\dfrac{(h_{11}+h_{22})+\\sqrt{(h_{11}-h_{22})^{2}+4 h_{12}^{2}}}{2} &\n\\dfrac{(h_{11}+h_{22})-\\sqrt{(h_{11}-h_{22})^{2}+4 h_{12}^{2}}}{2} &\n\\dfrac{h_{11}\\,h_{22}-h_{12}^{2}}{h_{11}+h_{22}-2 h_{12}}\n\\end{pmatrix}}$$", "id": "2902363"}, {"introduction": "The power of the linear variation method relies on a well-chosen basis, but what happens when the basis functions are not distinct enough? This practice explores the critical issue of near-linear dependence, a common pitfall in quantum chemical calculations. You will construct a simple $2 \\times 2$ system with nearly collinear basis functions and demonstrate how this condition makes the resulting energy eigenvalues acutely sensitive to small perturbations, providing a stark lesson on the importance of numerical stability in practical computations [@problem_id:2902369].", "problem": "Consider the linear variational (Rayleigh–Ritz) treatment of a single-electron Hamiltonian restricted to a subspace spanned by two trial functions that are nearly linearly dependent. Let $\\{\\,\\varphi_{1},\\varphi_{2}\\,\\}$ be an orthonormal set, $\\langle \\varphi_{i}|\\varphi_{j}\\rangle=\\delta_{ij}$. Define the nonorthogonal, normalized trial functions\n$$\n\\chi_{1}=\\varphi_{1},\\qquad \\chi_{2}=\\cos\\theta\\,\\varphi_{1}+\\sin\\theta\\,\\varphi_{2},\n$$\nwith a small angle $\\theta$ (in radians), so that the two functions are nearly collinear. Take $\\theta=0.01$.\n\n1. Using only the inner products of $\\varphi_{1}$ and $\\varphi_{2}$ and the above definitions, compute the overlap matrix $S$ with elements $S_{ij}=\\langle \\chi_{i}|\\chi_{j}\\rangle$.\n\n2. Let the unperturbed Hamiltonian in the orthonormal $\\{\\,\\varphi_{1},\\varphi_{2}\\,\\}$ basis be $H_{\\varphi}=E_{0}\\,I$, where $I$ is the $2\\times 2$ identity and $E_{0}=0$ in electronvolts (eV). Construct the Hamiltonian matrix $H$ in the nonorthogonal $\\{\\,\\chi_{1},\\chi_{2}\\,\\}$ basis from the definitions above. Now introduce a perturbation $\\Delta H$ that adds a small bias only to the first basis function in the $\\{\\,\\chi_{1},\\chi_{2}\\,\\}$ representation: $(\\Delta H)_{11}=\\delta$, $(\\Delta H)_{12}=(\\Delta H)_{21}=(\\Delta H)_{22}=0$, with $\\delta=1.0\\times 10^{-3}$ in eV.\n\n3. Starting from the Rayleigh–Ritz variational principle for a linear expansion in $\\{\\,\\chi_{1},\\chi_{2}\\,\\}$, derive the generalized secular equations and solve the resulting generalized eigenvalue problem for the perturbed Hamiltonian $H+\\Delta H$. Determine the highest-energy root $E_{\\text{high}}$ explicitly in terms of $\\theta$ and $\\delta$, specialize to the given numerical values, and evaluate it.\n\nRound your final numerical answer to four significant figures. Express the final energy in eV.", "solution": "The problem statement has been validated and is found to be scientifically grounded, well-posed, and free of contradictions. It represents a standard, albeit important, application of the linear variational method in quantum chemistry, specifically illustrating the consequences of near-linear dependence in the basis set. We shall proceed with the solution.\n\nThe problem is divided into three parts. We will address each in sequence.\n\nPart 1: Computation of the Overlap Matrix $S$.\nThe trial functions are defined as $\\chi_{1}=\\varphi_{1}$ and $\\chi_{2}=\\cos\\theta\\,\\varphi_{1}+\\sin\\theta\\,\\varphi_{2}$, where the set $\\{\\,\\varphi_{1},\\varphi_{2}\\,\\}$ is orthonormal, meaning $\\langle \\varphi_{i}|\\varphi_{j}\\rangle=\\delta_{ij}$. The elements of the overlap matrix $S$ are given by $S_{ij}=\\langle \\chi_{i}|\\chi_{j}\\rangle$.\n\nWe compute the matrix elements:\n$S_{11} = \\langle \\chi_{1}|\\chi_{1}\\rangle = \\langle \\varphi_{1}|\\varphi_{1}\\rangle = 1$.\n$S_{22} = \\langle \\chi_{2}|\\chi_{2}\\rangle = \\langle \\cos\\theta\\,\\varphi_{1}+\\sin\\theta\\,\\varphi_{2} | \\cos\\theta\\,\\varphi_{1}+\\sin\\theta\\,\\varphi_{2} \\rangle$.\nExpanding this inner product gives:\n$S_{22} = \\cos^{2}\\theta\\langle \\varphi_{1}|\\varphi_{1}\\rangle + \\sin^{2}\\theta\\langle \\varphi_{2}|\\varphi_{2}\\rangle + 2\\cos\\theta\\sin\\theta\\langle \\varphi_{1}|\\varphi_{2}\\rangle$.\nUsing the orthonormality condition, $\\langle \\varphi_{1}|\\varphi_{1}\\rangle = 1$, $\\langle \\varphi_{2}|\\varphi_{2}\\rangle = 1$, and $\\langle \\varphi_{1}|\\varphi_{2}\\rangle = 0$.\nThus, $S_{22} = \\cos^{2}\\theta \\cdot 1 + \\sin^{2}\\theta \\cdot 1 + 0 = \\cos^{2}\\theta + \\sin^{2}\\theta = 1$. This confirms that $\\chi_{2}$ is normalized.\n\nThe off-diagonal element $S_{12}$ is:\n$S_{12} = \\langle \\chi_{1}|\\chi_{2}\\rangle = \\langle \\varphi_{1} | \\cos\\theta\\,\\varphi_{1}+\\sin\\theta\\,\\varphi_{2} \\rangle = \\cos\\theta\\langle \\varphi_{1}|\\varphi_{1}\\rangle + \\sin\\theta\\langle \\varphi_{1}|\\varphi_{2}\\rangle = \\cos\\theta \\cdot 1 + \\sin\\theta \\cdot 0 = \\cos\\theta$.\nSince the basis functions are real, the overlap matrix is symmetric, so $S_{21} = S_{12} = \\cos\\theta$.\n\nThe overlap matrix $S$ is therefore:\n$$\nS = \\begin{pmatrix} 1 & \\cos\\theta \\\\ \\cos\\theta & 1 \\end{pmatrix}\n$$\n\nPart 2: Construction of the Hamiltonian Matrix.\nThe unperturbed Hamiltonian operator $\\hat{H}$ is specified by its matrix representation in the orthonormal $\\{\\,\\varphi_{1},\\varphi_{2}\\,\\}$ basis, $H_{\\varphi}=E_{0}\\,I$. This implies that $\\varphi_{1}$ and $\\varphi_{2}$ are eigenstates of $\\hat{H}$ with the same eigenvalue $E_{0}$. Given $E_{0}=0$, we have $\\hat{H}|\\varphi_{1}\\rangle = 0$ and $\\hat{H}|\\varphi_{2}\\rangle = 0$.\n\nThe matrix elements of the unperturbed Hamiltonian in the nonorthogonal $\\{\\,\\chi_{1},\\chi_{2}\\,\\}$ basis are $H_{ij} = \\langle \\chi_{i}|\\hat{H}|\\chi_{j}\\rangle$.\n$H_{11} = \\langle \\chi_{1}|\\hat{H}|\\chi_{1}\\rangle = \\langle \\varphi_{1}|\\hat{H}|\\varphi_{1}\\rangle = \\langle \\varphi_{1}|0\\rangle = 0$.\n$H_{12} = \\langle \\chi_{1}|\\hat{H}|\\chi_{2}\\rangle = \\langle \\varphi_{1}|\\hat{H}| \\cos\\theta\\,\\varphi_{1}+\\sin\\theta\\,\\varphi_{2} \\rangle = \\langle \\varphi_{1}| \\cos\\theta(\\hat{H}|\\varphi_{1}\\rangle) + \\sin\\theta(\\hat{H}|\\varphi_{2}\\rangle) \\rangle = \\langle \\varphi_{1}|0\\rangle = 0$.\nSimilarly, $H_{21} = H_{12} = 0$, and $H_{22} = \\langle \\chi_{2}|\\hat{H}|\\chi_{2}\\rangle = 0$.\nThe unperturbed Hamiltonian matrix $H$ in the $\\{\\,\\chi_{1},\\chi_{2}\\,\\}$ basis is the zero matrix:\n$$\nH = \\begin{pmatrix} 0 & 0 \\\\ 0 & 0 \\end{pmatrix}\n$$\nThe perturbation is given in the $\\{\\,\\chi_1, \\chi_2\\,\\}$ basis as $(\\Delta H)_{11}=\\delta$, with all other elements being zero. So, $\\Delta H = \\begin{pmatrix} \\delta & 0 \\\\ 0 & 0 \\end{pmatrix}$.\nThe total Hamiltonian matrix is $H_{\\text{total}} = H + \\Delta H$:\n$$\nH_{\\text{total}} = \\begin{pmatrix} \\delta & 0 \\\\ 0 & 0 \\end{pmatrix}\n$$\n\nPart 3: Solution of the Generalized Eigenvalue Problem.\nThe Rayleigh–Ritz method leads to the generalized secular equation $\\det(H_{\\text{total}} - E S) = 0$, where $E$ represents the energy eigenvalues. Substituting the matrices $H_{\\text{total}}$ and $S$ we have derived:\n$$\n\\det\\left( \\begin{pmatrix} \\delta & 0 \\\\ 0 & 0 \\end{pmatrix} - E \\begin{pmatrix} 1 & \\cos\\theta \\\\ \\cos\\theta & 1 \\end{pmatrix} \\right) = 0\n$$\n$$\n\\det \\begin{pmatrix} \\delta - E & -E\\cos\\theta \\\\ -E\\cos\\theta & -E \\end{pmatrix} = 0\n$$\nEvaluating the determinant gives the characteristic equation:\n$$\n(\\delta - E)(-E) - (-E\\cos\\theta)(-E\\cos\\theta) = 0\n$$\n$$\n-E\\delta + E^2 - E^2\\cos^2\\theta = 0\n$$\n$$\nE^2(1 - \\cos^2\\theta) - E\\delta = 0\n$$\nUsing the trigonometric identity $\\sin^2\\theta + \\cos^2\\theta = 1$, this simplifies to:\n$$\nE^2\\sin^2\\theta - E\\delta = 0\n$$\nFactoring out $E$, we get:\n$$\nE(E\\sin^2\\theta - \\delta) = 0\n$$\nThis equation yields two energy roots:\n$E_{1} = 0$\n$E_{2} = \\frac{\\delta}{\\sin^2\\theta}$\n\nThe problem asks for the highest-energy root, $E_{\\text{high}}$. Given that $\\delta = 1.0 \\times 10^{-3} > 0$ and $\\theta=0.01$ is a small, non-zero angle, $\\sin^2\\theta > 0$. Therefore, $E_{2} > E_{1}$.\nThe highest-energy root is:\n$$\nE_{\\text{high}} = \\frac{\\delta}{\\sin^2\\theta}\n$$\nThis result is notable. A small perturbation $\\delta$ to a single basis function can lead to a very large energy shift if the basis functions are nearly linearly dependent, i.e., if $|\\cos\\theta|$ is close to $1$, which means $\\sin^2\\theta$ is close to $0$.\n\nFinally, we substitute the given numerical values: $\\delta = 1.0 \\times 10^{-3}$ eV and $\\theta = 0.01$ radians.\n$$\nE_{\\text{high}} = \\frac{1.0 \\times 10^{-3}}{\\sin^2(0.01)} \\text{ eV}\n$$\nCalculation gives:\n$\\sin(0.01) \\approx 0.0099998333$\n$\\sin^2(0.01) \\approx 9.99966667 \\times 10^{-5}$\n$$\nE_{\\text{high}} \\approx \\frac{1.0 \\times 10^{-3}}{9.99966667 \\times 10^{-5}} \\text{ eV} \\approx 10.00033334 \\text{ eV}\n$$\nRounding to four significant figures as required, we obtain $10.00$ eV.", "answer": "$$\n\\boxed{10.00}\n$$", "id": "2902369"}, {"introduction": "The ultimate test of understanding is to translate theory into a working algorithm. This final practice guides you through the process of implementing the linear variation method in a program to solve for the energy levels of the classic particle-in-a-box problem [@problem_id:2816688]. By building the Hamiltonian and overlap matrices from a polynomial basis and solving the resulting generalized eigenvalue problem, you will not only solidify your grasp of the entire workflow but also directly observe the variational principle in action as your basis set systematically converges toward the exact quantum mechanical solutions.", "problem": "Consider the one-dimensional particle-in-a-box problem on the interval $[0,L]$ with an infinite potential barrier outside, so that the wavefunction satisfies Dirichlet boundary conditions $\\psi(0)=\\psi(L)=0$. Inside the box, the time-independent Schrödinger equation for a free particle is\n$$\n-\\frac{\\hbar^2}{2m}\\,\\frac{d^2\\psi}{dx^2}=E\\,\\psi \\quad \\text{for } x\\in(0,L),\n$$\nwith $\\psi(0)=\\psi(L)=0$. Work in dimensionless units where $\\hbar^2/(2m)=1$, so that energies and lengths are measured in units such that the exact energy spectrum is\n$$\nE_n^{\\mathrm{exact}}=\\left(\\frac{n\\pi}{L}\\right)^2,\\quad n\\in\\mathbb{N}.\n$$\nUse the linear variation method with a nonorthogonal polynomial basis that enforces the boundary conditions. Specifically, for a chosen basis size $N\\in\\mathbb{N}$, use basis functions\n$$\n\\phi_k(x)=x\\,(L-x)\\left(\\frac{x}{L}\\right)^k,\\quad k=0,1,\\dots,N-1,\n$$\nwhich are polynomials that vanish at $x=0$ and $x=L$ and are generally nonorthogonal under the standard $L^2$ inner product on $[0,L]$. Define the overlap matrix $S\\in\\mathbb{R}^{N\\times N}$ and the Hamiltonian (kinetic) matrix $H\\in\\mathbb{R}^{N\\times N}$ by\n$$\nS_{ij}=\\int_0^L \\phi_i(x)\\,\\phi_j(x)\\,dx,\\qquad H_{ij}=\\int_0^L \\frac{d\\phi_i}{dx}(x)\\,\\frac{d\\phi_j}{dx}(x)\\,dx,\n$$\nso that the generalized eigenvalue problem\n$$\nH\\,\\mathbf{c} = E\\,S\\,\\mathbf{c}\n$$\nyields Ritz approximations $E$ to the exact energy eigenvalues. You must compute the integrals defining $H$ and $S$ exactly by polynomial algebra (i.e., by forming the relevant product polynomials and integrating them analytically as antiderivatives), not by numerical quadrature, to ensure internal consistency and reproducibility.\n\nWrite a complete program that:\n- Constructs the basis polynomials $\\phi_k$ as above for given $L$ and $N$.\n- Builds the matrices $H$ and $S$ by exact integration of polynomials as specified.\n- Solves the generalized symmetric eigenvalue problem $H\\,\\mathbf{c}=E\\,S\\,\\mathbf{c}$ to obtain the $N$ approximate energies, sorted in ascending order.\n- For a specified comparison count $M\\in\\mathbb{N}$ with $1\\le M\\le N$, computes the root-mean-square (RMS) relative error between the lowest $M$ approximate energies and the exact energies $\\{E_n^{\\mathrm{exact}}\\}_{n=1}^M$:\n$$\n\\varepsilon_{\\mathrm{RMS}}=\\sqrt{\\frac{1}{M}\\sum_{n=1}^{M}\\left(\\frac{E_n^{\\mathrm{approx}}-E_n^{\\mathrm{exact}}}{E_n^{\\mathrm{exact}}}\\right)^2}.\n$$\nAll energies are dimensionless in the chosen units, so no unit conversion is needed. Angles do not appear. Percentages must not be used; the RMS relative error must be returned as a decimal number.\n\nTest suite:\n- Case $1$: $L=1.0$, $N=1$, $M=1$.\n- Case $2$: $L=1.0$, $N=3$, $M=3$.\n- Case $3$: $L=\\pi$, $N=5$, $M=4$.\n- Case $4$: $L=2.5$, $N=6$, $M=4$.\n\nProgram output specification:\n- For each test case, compute $\\varepsilon_{\\mathrm{RMS}}$ as defined above.\n- Round each $\\varepsilon_{\\mathrm{RMS}}$ to $8$ decimal places.\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, in the same order as the test cases (for example, $[r_1,r_2,r_3,r_4]$).", "solution": "We begin from the time-independent Schrödinger equation for a free particle in a one-dimensional infinite potential well on $[0,L]$:\n$$\n-\\frac{\\hbar^2}{2m}\\,\\frac{d^2\\psi}{dx^2}=E\\,\\psi,\\quad \\psi(0)=\\psi(L)=0.\n$$\nAdopting units where $\\hbar^2/(2m)=1$, the operator on the left-hand side simplifies to $-\\frac{d^2}{dx^2}$. The exact eigenfunctions are $\\psi_n(x)=\\sqrt{\\frac{2}{L}}\\sin\\left(\\frac{n\\pi x}{L}\\right)$ with exact energies $E_n^{\\mathrm{exact}}=\\left(\\frac{n\\pi}{L}\\right)^2$.\n\nThe linear variation method (Rayleigh–Ritz method) constructs an approximate solution space by taking linear combinations of chosen basis functions $\\{\\phi_k\\}_{k=0}^{N-1}$, so that a trial wavefunction is $\\psi(x)=\\sum_{k=0}^{N-1} c_k\\,\\phi_k(x)$. The variational principle states that the Rayleigh quotient\n$$\n\\mathcal{R}[\\psi]=\\frac{\\langle \\psi| \\hat{H}|\\psi\\rangle}{\\langle \\psi|\\psi\\rangle}\n$$\nis stationary at the exact eigenstates and provides upper bounds to the exact eigenvalues when the basis enforces boundary conditions. Here $\\hat{H}=-\\frac{d^2}{dx^2}$ in the adopted units, and the inner product on $L^2([0,L])$ is $\\langle f|g\\rangle=\\int_0^L f(x)\\,g(x)\\,dx$.\n\nProjecting the Schrödinger equation onto the subspace spanned by $\\{\\phi_k\\}$ yields the generalized matrix eigenvalue problem\n$$\n\\sum_{j=0}^{N-1} H_{ij}\\,c_j = E \\sum_{j=0}^{N-1} S_{ij}\\,c_j,\\quad i=0,\\dots,N-1,\n$$\nwhere the overlap matrix and Hamiltonian matrix elements are\n$$\nS_{ij}=\\int_0^L \\phi_i(x)\\,\\phi_j(x)\\,dx,\\qquad H_{ij}=\\int_0^L \\phi_i(x)\\left(-\\frac{d^2}{dx^2}\\right)\\phi_j(x)\\,dx.\n$$\nBecause the basis functions are constructed to satisfy $\\phi_k(0)=\\phi_k(L)=0$, integration by parts transforms the Hamiltonian matrix into a symmetric, positive-definite form without boundary terms:\n$$\nH_{ij}=\\int_0^L \\frac{d\\phi_i}{dx}(x)\\,\\frac{d\\phi_j}{dx}(x)\\,dx.\n$$\nThis follows from\n$$\n\\int_0^L \\phi_i(x)\\left(-\\frac{d^2\\phi_j}{dx^2}(x)\\right)\\,dx\n=\\left.-\\phi_i(x)\\frac{d\\phi_j}{dx}(x)\\right|_0^L + \\int_0^L \\frac{d\\phi_i}{dx}(x)\\,\\frac{d\\phi_j}{dx}(x)\\,dx,\n$$\nand the boundary term vanishes because $\\phi_i(0)=\\phi_i(L)=0$.\n\nWe choose a nonorthogonal polynomial basis that enforces the boundary conditions:\n$$\n\\phi_k(x)=x\\,(L-x)\\left(\\frac{x}{L}\\right)^k,\\quad k=0,1,\\dots,N-1.\n$$\nEach $\\phi_k$ is a polynomial in $x$ multiplied by $x(L-x)$, so it vanishes at $x=0$ and $x=L$. The set is typically nonorthogonal with respect to $\\langle \\cdot|\\cdot\\rangle$, so the overlap matrix $S$ is not the identity.\n\nAlgorithmic construction via polynomial algebra:\n- Represent $\\phi_k(x)$ as a polynomial in $x$ using explicit coefficients. Introduce the polynomial $X(x)=x$ and the boundary factor $B(x)=x(L-x)=-x^2+Lx$. Then\n$$\n\\phi_k(x)=B(x)\\left(\\frac{X(x)}{L}\\right)^k.\n$$\nThus, $\\phi_k$ can be formed by polynomial multiplication and scaling. Its derivative $\\frac{d\\phi_k}{dx}$ is obtained by polynomial differentiation.\n- To compute $S_{ij}$ and $H_{ij}$ exactly, note that the products $\\phi_i(x)\\,\\phi_j(x)$ and $\\frac{d\\phi_i}{dx}(x)\\,\\frac{d\\phi_j}{dx}(x)$ are polynomials. Their integrals over $[0,L]$ are computed analytically by taking antiderivatives (increasing powers by one and dividing by the new power) and evaluating at $x=L$ and $x=0$. This avoids numerical quadrature and yields exact rational combinations of $L$ and powers of $L$ in floating representation.\n- Assemble the symmetric matrices $S$ and $H$, then solve the generalized symmetric eigenvalue problem\n$$\nH\\,\\mathbf{c}=E\\,S\\,\\mathbf{c}\n$$\nusing a routine for Hermitian generalized problems (e.g., a function that solves $A\\mathbf{v}=\\lambda B\\mathbf{v}$ with $A$ and $B$ symmetric and $B$ positive-definite). The resulting eigenvalues $\\{E_n^{\\mathrm{approx}}\\}$ are sorted ascending.\n- For a given $M\\le N$, compute the root-mean-square relative error\n$$\n\\varepsilon_{\\mathrm{RMS}}=\\sqrt{\\frac{1}{M}\\sum_{n=1}^{M}\\left(\\frac{E_n^{\\mathrm{approx}}-E_n^{\\mathrm{exact}}}{E_n^{\\mathrm{exact}}}\\right)^2},\n$$\nwhere $E_n^{\\mathrm{exact}}=\\left(\\frac{n\\pi}{L}\\right)^2$.\n\nTest cases and expectations:\n- Case $1$ ($L=1.0$, $N=1$, $M=1$) uses a single basis function; it produces a variational upper bound to the ground state, so the relative error is positive and modest.\n- Case $2$ ($L=1.0$, $N=3$, $M=3$) examines how three nonorthogonal polynomials capture the first three states; the RMS error should decrease compared to Case $1$ due to the enlarged subspace.\n- Case $3$ ($L=\\pi$, $N=5$, $M=4$) changes the length scale; exact energies become $E_n^{\\mathrm{exact}}=n^2$ in the chosen units, testing scale invariance of the construction.\n- Case $4$ ($L=2.5$, $N=6$, $M=4$) probes a different $L$ and larger basis, further testing convergence and conditioning.\n\nImplementation details:\n- Construct polynomials using coefficient arrays for $X(x)=x$ and $B(x)=-x^2+Lx$, then form $\\phi_k$ and its derivative.\n- Compute matrix entries by analytic integration of coefficient arrays.\n- Solve the generalized eigenproblem with a Hermitian solver appropriate for $H$ and $S$.\n- For each test case, compute $\\varepsilon_{\\mathrm{RMS}}$, round to $8$ decimal places, and output the list of the four rounded values in a single bracketed line.\n\nThis approach integrates the variational principle with an explicit, exact polynomial treatment of matrix elements, ensuring that any observed convergence behavior is attributable to the basis choice rather than numerical quadrature artifacts.", "answer": "```python\nimport numpy as np\nfrom scipy.linalg import eigh\n\ndef make_phi_polynomials(L, N):\n    \"\"\"\n    Construct basis polynomials phi_k(x) = x (L - x) (x/L)^k as numpy.poly1d objects in x.\n    Returns a list of poly1d objects [phi_0, ..., phi_{N-1}].\n    \"\"\"\n    x = np.poly1d([1.0, 0.0])        # x\n    B = -x**2 + L * x                # x(L - x)\n    phis = []\n    for k in range(N):\n        scale = (1.0 / L) ** k\n        phi_k = B * (scale * x**k)\n        phis.append(phi_k)\n    return phis\n\ndef integrate_poly_over_interval(p, a, b):\n    \"\"\"\n    Analytically integrate polynomial p over [a, b] using antiderivative.\n    p is numpy.poly1d.\n    \"\"\"\n    P = p.integ()\n    return float(P(b) - P(a))\n\ndef build_matrices(L, N):\n    \"\"\"\n    Build overlap matrix S and Hamiltonian matrix H for the polynomial basis.\n    \"\"\"\n    phis = make_phi_polynomials(L, N)\n    dphis = [phi.deriv() for phi in phis]\n    S = np.zeros((N, N), dtype=float)\n    H = np.zeros((N, N), dtype=float)\n    for i in range(N):\n        for j in range(i, N):\n            # Overlap\n            sij = integrate_poly_over_interval(phis[i] * phis[j], 0.0, L)\n            # Kinetic/Hamiltonian via gradients\n            hij = integrate_poly_over_interval(dphis[i] * dphis[j], 0.0, L)\n            S[i, j] = S[j, i] = sij\n            H[i, j] = H[j, i] = hij\n    return H, S\n\ndef approximate_energies(L, N):\n    \"\"\"\n    Compute approximate energies by solving the generalized eigenvalue problem H c = E S c.\n    Returns sorted eigenvalues (ascending).\n    \"\"\"\n    H, S = build_matrices(L, N)\n    # Solve generalized symmetric eigenproblem\n    w = eigh(H, S, eigvals_only=True)\n    # Ensure real and sorted\n    w = np.real_if_close(w)\n    w.sort()\n    return w\n\ndef exact_energies(L, M):\n    \"\"\"\n    Exact energies E_n = (n*pi/L)^2 for n=1..M in units with hbar^2/(2m)=1.\n    \"\"\"\n    n = np.arange(1, M + 1, dtype=float)\n    return (np.pi * n / L) ** 2\n\ndef rms_relative_error(approx_vals, exact_vals):\n    \"\"\"\n    Compute RMS relative error between arrays approx_vals and exact_vals.\n    \"\"\"\n    rel = (approx_vals - exact_vals) / exact_vals\n    return float(np.sqrt(np.mean(rel**2)))\n\ndef solve():\n    # Define the test cases from the problem statement: (L, N, M)\n    test_cases = [\n        (1.0, 1, 1),\n        (1.0, 3, 3),\n        (np.pi, 5, 4),\n        (2.5, 6, 4),\n    ]\n\n    results = []\n    for L, N, M in test_cases:\n        approx = approximate_energies(L, N)[:M]\n        exact = exact_energies(L, M)\n        err = rms_relative_error(approx, exact)\n        results.append(f\"{err:.8f}\")\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(results)}]\")\n\nif __name__ == \"__main__\":\n    solve()\n```", "id": "2816688"}]}