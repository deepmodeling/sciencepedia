{"hands_on_practices": [{"introduction": "At the core of every molecular dynamics simulation is the integrator, the algorithm that advances atomic positions and velocities through time. The choice of the time step, $\\Delta t$, is arguably the most critical parameter, as it governs both the efficiency and the stability of the simulation. This first practice delves into the fundamental principles of numerical stability by analyzing the widely used velocity Verlet algorithm, providing the theoretical tools needed to select a robust time step and prevent your simulations from producing unphysical, divergent trajectories [@problem_id:2469790].", "problem": "In atomistic Molecular Dynamics (MD), the velocity Verlet integrator is widely used to integrate Newton’s equations of motion. Consider a one-dimensional harmonic oscillator representative of a single normal mode of a crystalline solid, with potential energy $U(x)=\\tfrac{1}{2}k x^{2}$ and mass $m$. The equation of motion is $m\\,\\ddot{x}(t)=-k\\,x(t)$, which can be written as $\\ddot{x}(t)=-\\omega^{2}x(t)$ with $\\omega=\\sqrt{k/m}$. The standard velocity Verlet update advances position and velocity over a time step $\\Delta t$ using the sequence: first a half-step velocity update using the current acceleration, then a full-step position update using the half-step velocity, then a full evaluation of the acceleration from the updated position, and finally a second half-step velocity update using the new acceleration.\n\nStarting from Newton’s second law and the velocity Verlet update definition, write the discrete-time update in the linear form $\\begin{pmatrix}x_{n+1}\\\\ v_{n+1}\\end{pmatrix}=M(\\Delta t)\\begin{pmatrix}x_{n}\\\\ v_{n}\\end{pmatrix}$ for some $2\\times 2$ matrix $M(\\Delta t)$ that depends on $\\omega$ and $\\Delta t$. Perform a linear stability analysis by requiring that all eigenvalues of $M(\\Delta t)$ have magnitude less than or equal to $1$. Determine the largest time step $\\Delta t_{\\text{max}}$ for which velocity Verlet is linearly stable for this harmonic oscillator. Express your final answer as a single closed-form analytic expression in terms of $\\omega$, and state it in seconds. No numerical evaluation or rounding is required.", "solution": "The problem statement is submitted for validation.\n\n**Step 1: Extract Givens**\n- System: One-dimensional harmonic oscillator.\n- Potential Energy: $U(x)=\\tfrac{1}{2}k x^{2}$.\n- Mass: $m$.\n- Equation of motion: $m\\,\\ddot{x}(t)=-k\\,x(t)$, or $\\ddot{x}(t)=-\\omega^{2}x(t)$ with $\\omega=\\sqrt{k/m}$.\n- Algorithm: Velocity Verlet integrator.\n- Velocity Verlet update sequence:\n    1. A half-step velocity update using the current acceleration.\n    2. A full-step position update using the half-step velocity.\n    3. A full evaluation of the acceleration from the updated position.\n    4. A second half-step velocity update using the new acceleration.\n- Task: Derive the discrete-time update matrix $M(\\Delta t)$ in the form $\\begin{pmatrix}x_{n+1}\\\\ v_{n+1}\\end{pmatrix}=M(\\Delta t)\\begin{pmatrix}x_{n}\\\\ v_{n}\\end{pmatrix}$.\n- Task: Perform a linear stability analysis by requiring that all eigenvalues of $M(\\Delta t)$ have magnitude less than or equal to $1$.\n- Task: Determine the largest time step $\\Delta t_{\\text{max}}$ for which the integration is stable, expressed in terms of $\\omega$.\n\n**Step 2: Validate Using Extracted Givens**\nThe problem is subjected to a critical review of its validity.\n- **Scientific Grounding**: The problem is scientifically sound. It addresses the stability of the velocity Verlet algorithm, a cornerstone of molecular dynamics simulations, applied to the harmonic oscillator, a fundamental model in physics. The concepts are standard in computational physics and materials chemistry.\n- **Well-Posedness**: The problem is well-posed. It provides all necessary information: the physical system, the equations of motion, the specific numerical integration scheme, and a clear, mathematically precise criterion for stability. The tasks lead to a unique, derivable result.\n- **Objectivity**: The problem is stated in objective, formal language, free of ambiguity or subjective claims.\n\nThe problem does not exhibit any of the listed flaws. It is not scientifically unsound, non-formalizable, incomplete, unrealistic, ill-posed, trivial, or unverifiable.\n\n**Step 3: Verdict and Action**\nThe problem is deemed **valid**. A solution will be constructed.\n\nThe velocity Verlet algorithm discretizes the equations of motion. Let $x_n = x(t_n)$, $v_n = v(t_n)$, and $a_n = a(t_n)$ be the position, velocity, and acceleration at time step $n$. The acceleration for the harmonic oscillator is $a(t) = -\\omega^2 x(t)$. The update steps from time $t_n$ to $t_{n+1} = t_n + \\Delta t$ are as follows.\n\nFirst, the velocity is updated by a half time step:\n$$v_{n+1/2} = v_n + a_n \\frac{\\Delta t}{2} = v_n - \\omega^2 x_n \\frac{\\Delta t}{2}$$\n\nSecond, the position is updated by a full time step using this intermediate velocity:\n$$x_{n+1} = x_n + v_{n+1/2} \\Delta t = x_n + \\left(v_n - \\omega^2 x_n \\frac{\\Delta t}{2}\\right) \\Delta t$$\n$$x_{n+1} = \\left(1 - \\frac{\\omega^2 (\\Delta t)^2}{2}\\right) x_n + (\\Delta t) v_n$$\nThis provides the first row of the update matrix $M(\\Delta t)$.\n\nThird, the new acceleration $a_{n+1}$ is calculated using the new position $x_{n+1}$:\n$$a_{n+1} = -\\omega^2 x_{n+1}$$\n\nFourth, the final velocity $v_{n+1}$ is computed with a second half-step update using the new acceleration:\n$$v_{n+1} = v_{n+1/2} + a_{n+1} \\frac{\\Delta t}{2} = \\left(v_n - \\omega^2 x_n \\frac{\\Delta t}{2}\\right) - \\omega^2 x_{n+1} \\frac{\\Delta t}{2}$$\n$$v_{n+1} = v_n - \\frac{\\omega^2 \\Delta t}{2} (x_n + x_{n+1})$$\nTo express $v_{n+1}$ purely in terms of $x_n$ and $v_n$, we substitute the expression for $x_{n+1}$:\n$$v_{n+1} = v_n - \\frac{\\omega^2 \\Delta t}{2} \\left(x_n + \\left(1 - \\frac{\\omega^2 (\\Delta t)^2}{2}\\right) x_n + (\\Delta t) v_n \\right)$$\n$$v_{n+1} = v_n - \\frac{\\omega^2 \\Delta t}{2} \\left(\\left(2 - \\frac{\\omega^2 (\\Delta t)^2}{2}\\right) x_n + (\\Delta t) v_n \\right)$$\n$$v_{n+1} = \\left(-\\omega^2 \\Delta t + \\frac{\\omega^4 (\\Delta t)^3}{4}\\right) x_n + \\left(1 - \\frac{\\omega^2 (\\Delta t)^2}{2}\\right) v_n$$\nThis can be written as:\n$$v_{n+1} = \\left(-\\omega^2 \\Delta t \\left(1 - \\frac{\\omega^2 (\\Delta t)^2}{4}\\right)\\right) x_n + \\left(1 - \\frac{\\omega^2 (\\Delta t)^2}{2}\\right) v_n$$\nThis provides the second row of the update matrix.\n\nCombining these results, the system of linear equations is:\n$$\\begin{pmatrix} x_{n+1} \\\\ v_{n+1} \\end{pmatrix} = \\begin{pmatrix} 1 - \\frac{\\omega^2 (\\Delta t)^2}{2} & \\Delta t \\\\ -\\omega^2 \\Delta t \\left(1 - \\frac{\\omega^2 (\\Delta t)^2}{4}\\right) & 1 - \\frac{\\omega^2 (\\Delta t)^2}{2} \\end{pmatrix} \\begin{pmatrix} x_n \\\\ v_n \\end{pmatrix}$$\nSo, the update matrix is:\n$$M(\\Delta t) = \\begin{pmatrix} 1 - \\frac{\\omega^2 (\\Delta t)^2}{2} & \\Delta t \\\\ -\\omega^2 \\Delta t \\left(1 - \\frac{\\omega^2 (\\Delta t)^2}{4}\\right) & 1 - \\frac{\\omega^2 (\\Delta t)^2}{2} \\end{pmatrix}$$\n\nFor the stability analysis, we must find the eigenvalues $\\lambda$ of $M(\\Delta t)$ by solving the characteristic equation $\\det(M - \\lambda I) = 0$. The trace and determinant of $M$ are required.\n$$\\text{Tr}(M) = \\left(1 - \\frac{\\omega^2 (\\Delta t)^2}{2}\\right) + \\left(1 - \\frac{\\omega^2 (\\Delta t)^2}{2}\\right) = 2 - \\omega^2 (\\Delta t)^2$$\n$$\\det(M) = \\left(1 - \\frac{\\omega^2 (\\Delta t)^2}{2}\\right)^2 - (\\Delta t)\\left(-\\omega^2 \\Delta t \\left(1 - \\frac{\\omega^2 (\\Delta t)^2}{4}\\right)\\right)$$\n$$\\det(M) = \\left(1 - \\omega^2 (\\Delta t)^2 + \\frac{\\omega^4 (\\Delta t)^4}{4}\\right) + \\left(\\omega^2 (\\Delta t)^2 - \\frac{\\omega^4 (\\Delta t)^4}{4}\\right) = 1$$\nThe fact that $\\det(M)=1$ is a signature of a symplectic integrator, which correctly preserves phase-space volume for Hamiltonian systems.\n\nThe characteristic equation is $\\lambda^2 - \\text{Tr}(M) \\lambda + \\det(M) = 0$:\n$$\\lambda^2 - \\left(2 - \\omega^2 (\\Delta t)^2\\right) \\lambda + 1 = 0$$\nThe eigenvalues are given by the quadratic formula:\n$$\\lambda = \\frac{(2 - \\omega^2 (\\Delta t)^2) \\pm \\sqrt{(2 - \\omega^2 (\\Delta t)^2)^2 - 4}}{2}$$\nThe algorithm is stable if and only if the magnitude of both eigenvalues is less than or equal to $1$, i.e., $|\\lambda| \\le 1$. Since their product $\\lambda_1 \\lambda_2 = \\det(M) = 1$, if the eigenvalues are real and not equal to $\\pm 1$, one must have magnitude greater than $1$, leading to instability. Therefore, stability requires that the eigenvalues be complex conjugates on the unit circle. This occurs when the discriminant of the characteristic polynomial is non-positive.\n$$\\text{Discriminant} = (2 - \\omega^2 (\\Delta t)^2)^2 - 4 \\le 0$$\n$$(2 - \\omega^2 (\\Delta t)^2)^2 \\le 4$$\nTaking the square root of both sides:\n$$|2 - \\omega^2 (\\Delta t)^2| \\le 2$$\nThis inequality is equivalent to the conjunction of two linear inequalities:\n$$-2 \\le 2 - \\omega^2 (\\Delta t)^2 \\quad \\text{and} \\quad 2 - \\omega^2 (\\Delta t)^2 \\le 2$$\nThe first inequality gives:\n$$-4 \\le -\\omega^2 (\\Delta t)^2$$\n$$\\omega^2 (\\Delta t)^2 \\le 4$$\nSince $\\omega > 0$ and $\\Delta t > 0$, this becomes:\n$$\\omega \\Delta t \\le 2$$\nThe second inequality gives:\n$$-\\omega^2 (\\Delta t)^2 \\le 0$$\n$$\\omega^2 (\\Delta t)^2 \\ge 0$$\nThis is always satisfied for real $\\omega$ and $\\Delta t$.\n\nThus, the condition for linear stability is $\\omega \\Delta t \\le 2$. The maximum allowed time step $\\Delta t_{\\text{max}}$ is the value that saturates this inequality.\n$$\\Delta t_{\\text{max}} = \\frac{2}{\\omega}$$\nThe angular frequency $\\omega$ has units of radians per second, or inverse seconds ($\\text{s}^{-1}$). Therefore, the expression $\\frac{2}{\\omega}$ correctly yields a result in seconds.", "answer": "$$\\boxed{\\frac{2}{\\omega}}$$", "id": "2469790"}, {"introduction": "Once we have a stable integrator, our focus shifts to the forces that drive the atomic motion. While short-range forces are computationally straightforward, the long-range nature of electrostatic interactions in periodic systems presents a formidable challenge that cannot be solved by a simple cutoff. This exercise guides you through the derivation and implementation of the Ewald summation method, the cornerstone algorithm for accurately and efficiently handling long-range electrostatics, using the classic calculation of the Madelung constant for an ionic crystal as a testbed [@problem_id:2469742].", "problem": "Consider an infinite ionic crystal with the rock-salt (sodium chloride) structure constructed by periodically repeating a conventional cubic unit cell of side length $a = 1$ (dimensionless units). The unit cell contains $8$ ions with charges $q_j \\in \\{+1,-1\\}$ placed at the following fractional coordinates (in units of $a$): anions ($q_j = -1$) at $(0,0,0)$, $(0,\\tfrac{1}{2},\\tfrac{1}{2})$, $(\\tfrac{1}{2},0,\\tfrac{1}{2})$, $(\\tfrac{1}{2},\\tfrac{1}{2},0)$; cations ($q_j = +1$) at $(\\tfrac{1}{2},0,0)$, $(0,\\tfrac{1}{2},0)$, $(0,0,\\tfrac{1}{2})$, $(\\tfrac{1}{2},\\tfrac{1}{2},\\tfrac{1}{2})$. The electrostatic interaction between two ions at positions $\\mathbf{r}$ and $\\mathbf{r}'$ is given by the Coulomb potential $1/\\lVert \\mathbf{r}-\\mathbf{r}' \\rVert$ in the chosen dimensionless system, and the crystal is treated with periodic boundary conditions (PBC).\n\nYour task is to compute the sodium chloride Madelung constant, defined for this lattice as a dimensionless number $\\mathcal{M}$ that relates to the total electrostatic energy per conventional unit cell, $E_{\\mathrm{cell}}$, via\n$$\nE_{\\mathrm{cell}} = -\\frac{8\\,\\mathcal{M}}{r_0},\n$$\nwhere $r_0$ is the nearest-neighbor distance in units of $a$. For the rock-salt structure in this conventional cubic cell with $a=1$, the nearest-neighbor distance is $r_0 = \\tfrac{1}{2}$, so that\n$$\n\\mathcal{M} = -\\frac{E_{\\mathrm{cell}}}{16}.\n$$\n\nDerive and implement an Ewald summation for the electrostatic energy per conventional unit cell starting from the Coulomb interaction and the principle of splitting the $1/r$ potential into a rapidly convergent real-space part and a rapidly convergent reciprocal-space part using a Gaussian screening of width $\\alpha^{-1}$. Adopt conducting (tin-foil) boundary conditions. Use the following standard building blocks as the starting point of your derivation:\n- Coulomb’s law $1/\\lVert \\mathbf{r} \\rVert$,\n- superposition in periodic boundary conditions,\n- the complementary error function $\\operatorname{erfc}(x)$ for the real-space screening,\n- Fourier representation of the long-range part in reciprocal space.\n\nIn your implementation, the real-space lattice vectors are $\\mathbf{R} = (n_x, n_y, n_z)$ with $n_x,n_y,n_z \\in \\mathbb{Z}$, and the reciprocal-space vectors are $\\mathbf{k} = 2\\pi(m_x,m_y,m_z)$ with $m_x,m_y,m_z \\in \\mathbb{Z}$. The energy per conventional unit cell must be evaluated as a sum over all pairs of charges in the basis and over all periodic images, with the self-interaction properly removed. Use a spherical distance cutoff $r_{\\mathrm{cut}}$ in real space and a maximum integer index $N_{\\mathrm{real}}$ for bounding the real-space lattice box via $n_\\alpha \\in \\{-N_{\\mathrm{real}},\\dots,N_{\\mathrm{real}}\\}$, and use a maximum integer index $N_{\\mathbf{k}}$ in reciprocal space via $m_\\alpha \\in \\{-N_{\\mathbf{k}},\\dots,N_{\\mathbf{k}}\\}$ excluding $\\mathbf{k}=\\mathbf{0}$.\n\nWrite a program that, for a given parameter tuple $(\\alpha, N_{\\mathrm{real}}, r_{\\mathrm{cut}}, N_{\\mathbf{k}})$, computes the Ewald energy $E_{\\mathrm{cell}}$ and returns the corresponding Madelung constant $\\mathcal{M}$. Round each reported $\\mathcal{M}$ to $8$ decimal places.\n\nTest suite:\n- Case $1$: $(\\alpha, N_{\\mathrm{real}}, r_{\\mathrm{cut}}, N_{\\mathbf{k}}) = (2.0, 4, 4.0, 4)$\n- Case $2$: $(\\alpha, N_{\\mathrm{real}}, r_{\\mathrm{cut}}, N_{\\mathbf{k}}) = (3.5, 5, 5.0, 6)$\n- Case $3$: $(\\alpha, N_{\\mathrm{real}}, r_{\\mathrm{cut}}, N_{\\mathbf{k}}) = (6.0, 3, 3.0, 8)$\n- Case $4$: $(\\alpha, N_{\\mathrm{real}}, r_{\\mathrm{cut}}, N_{\\mathbf{k}}) = (4.0, 8, 8.0, 3)$\n- Case $5$: $(\\alpha, N_{\\mathrm{real}}, r_{\\mathrm{cut}}, N_{\\mathbf{k}}) = (4.5, 10, 10.0, 10)$\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (e.g., $[\\text{result}_1,\\text{result}_2,\\dots]$), where each $\\text{result}_i$ is the computed $\\mathcal{M}$ for the corresponding test case, rounded to $8$ decimal places. No physical units are required because all quantities are dimensionless by construction. Ensure that all trigonometric arguments are interpreted in radians. The final outputs must be floating-point numbers.", "solution": "The user has provided a valid, well-posed problem statement from the field of computational materials chemistry. The task is to derive and implement the Ewald summation method to calculate the Madelung constant for an infinite rock-salt crystal structure under specific, clearly defined conditions. The problem is scientifically grounded, objective, and contains all necessary information for a unique solution. I will therefore proceed with the derivation and implementation.\n\nThe electrostatic energy per unit cell, $E_{\\mathrm{cell}}$, of an infinite, periodic crystal lattice of $N$ ions with charges $q_j$ at fractional positions $\\mathbf{u}_j$ within a unit cell of lattice vectors $\\mathbf{a}_1, \\mathbf{a}_2, \\mathbf{a}_3$ is given by\n$$\nE_{\\mathrm{cell}} = \\frac{1}{2} \\sum_{i=1}^{N} \\sum_{j=1}^{N} \\sum_{\\mathbf{R}}' \\frac{q_i q_j}{|\\mathbf{r}_{ij} + \\mathbf{R}|}\n$$\nwhere the electrostatic constant $1/(4\\pi\\epsilon_0)$ is set to $1$, $\\mathbf{r}_{ij} = \\mathbf{r}_i - \\mathbf{r}_j = (\\mathbf{u}_i - \\mathbf{u}_j)a$ are the vector separations between ions in the primary cell (with side length $a=1$ here), and $\\mathbf{R} = n_1\\mathbf{a}_1 + n_2\\mathbf{a}_2 + n_3\\mathbf{a}_3$ are the real-space lattice vectors for integers $n_1, n_2, n_3$. The prime on the summation indicates that the term for $i=j$ is excluded when $\\mathbf{R}=\\mathbf{0}$ to avoid the infinite self-energy of a point charge. This sum is conditionally convergent and converges extremely slowly.\n\nThe Ewald summation method accelerates convergence by splitting the Coulomb potential $1/r$ into a short-range and a long-range component using the identity involving the complementary error function, $\\operatorname{erfc}(x)$, and the error function, $\\operatorname{erf}(x)$:\n$$\n\\frac{1}{r} = \\frac{\\operatorname{erfc}(\\alpha r)}{r} + \\frac{\\operatorname{erf}(\\alpha r)}{r}\n$$\nThe parameter $\\alpha$ controls the width of a Gaussian charge distribution used for screening, and its value is chosen to balance the convergence of the two resulting sums. The electrostatic energy $E_{\\mathrm{cell}}$ is then expressed as the sum of three components: a real-space sum ($E_{\\mathrm{real}}$), a reciprocal-space sum ($E_{\\mathrm{recip}}$), and a self-energy correction ($E_{\\mathrm{self}}$).\n\n$E_{\\mathrm{cell}} = E_{\\mathrm{real}} + E_{\\mathrm{recip}} - E_{\\mathrm{self}}$\n\n**1. Real-Space Term ($E_{\\mathrm{real}}$)**\n\nThe short-range part, involving $\\operatorname{erfc}(\\alpha r)/r$, decays rapidly, allowing the sum to be truncated at a reasonably small cutoff distance $r_{\\mathrm{cut}}$. The real-space energy is:\n$$\nE_{\\mathrm{real}} = \\frac{1}{2} \\sum_{i=1}^{N} \\sum_{j=1}^{N} \\sum_{\\mathbf{R}}' \\frac{q_i q_j \\operatorname{erfc}(\\alpha |\\mathbf{r}_{ij} + \\mathbf{R}|)}{|\\mathbf{r}_{ij} + \\mathbf{R}|}\n$$\nFor computational purposes, this is more efficiently calculated by separating the terms for interacting distinct ions ($i \\neq j$) from the self-interaction terms with periodic images ($i=j, \\mathbf{R} \\neq \\mathbf{0}$):\n$$\nE_{\\mathrm{real}} = \\sum_{i=1}^{N-1} \\sum_{j=i+1}^{N} q_i q_j \\sum_{\\mathbf{R}} \\frac{\\operatorname{erfc}(\\alpha |\\mathbf{r}_{ij} + \\mathbf{R}|)}{|\\mathbf{r}_{ij} + \\mathbf{R}|} + \\frac{1}{2} \\sum_{i=1}^{N} q_i^2 \\sum_{\\mathbf{R} \\neq \\mathbf{0}} \\frac{\\operatorname{erfc}(\\alpha |\\mathbf{R}|)}{|\\mathbf{R}|}\n$$\nThe sums over $\\mathbf{R} = (n_x, n_y, n_z)a$ are taken for integers $n_\\alpha \\in \\{-N_{\\mathrm{real}}, \\dots, N_{\\mathrm{real}}\\}$ and for interaction distances less than $r_{\\mathrm{cut}}$.\n\n**2. Reciprocal-Space Term ($E_{\\mathrm{recip}}$)**\n\nThe long-range part, involving $\\operatorname{erf}(\\alpha r)/r$, is smoothly varying and is efficiently computed in reciprocal space using a Fourier transform. The charge distribution of the unit cell, $\\rho(\\mathbf{r}) = \\sum_{j=1}^N q_j \\delta(\\mathbf{r}-\\mathbf{r}_j)$, is expanded in a Fourier series. The reciprocal-space energy contribution is given by:\n$$\nE_{\\mathrm{recip}} = \\frac{1}{2V} \\sum_{\\mathbf{k} \\neq \\mathbf{0}} \\frac{4\\pi}{k^2} e^{-k^2 / (4\\alpha^2)} |S(\\mathbf{k})|^2\n$$\nHere, $V=a^3$ is the volume of the unit cell (in this problem, $V=1^3=1$). The vectors $\\mathbf{k} = 2\\pi(m_x/a, m_y/a, m_z/a)$ are the reciprocal lattice vectors for integers $m_\\alpha \\in \\{-N_{\\mathbf{k}}, \\dots, N_{\\mathbf{k}}\\}$ (with $a=1$). The term $\\mathbf{k}=\\mathbf{0}$ is excluded, which corresponds to conducting (tin-foil) boundary conditions, appropriate for a charge-neutral system ($\\sum q_j = 0$). The structure factor, $S(\\mathbf{k})$, is the Fourier transform of the charge distribution in the unit cell:\n$$\nS(\\mathbf{k}) = \\sum_{j=1}^{N} q_j e^{-i \\mathbf{k} \\cdot \\mathbf{r}_j}\n$$\n$|S(\\mathbf{k})|^2$ is the squared modulus of the structure factor. Substituting the constants for this problem, the expression becomes:\n$$\nE_{\\mathrm{recip}} = 2\\pi \\sum_{\\mathbf{k} \\neq \\mathbf{0}} \\frac{e^{-k^2 / (4\\alpha^2)}}{k^2} \\left| \\sum_{j=1}^{N} q_j e^{-i\\mathbf{k} \\cdot \\mathbf{r}_j} \\right|^2\n$$\n\n**3. Self-Energy Correction ($E_{\\mathrm{self}}$)**\n\nThe Ewald method effectively replaces each point charge $q_j$ with a point charge plus a screening Gaussian charge distribution of the opposite sign, $-q_j$, and then adds a compensating charge distribution of $+q_j$ that is handled in reciprocal space. The reciprocal-space sum incorrectly includes the interaction energy of each charge's compensating Gaussian with itself. This spurious self-interaction energy must be subtracted. For a single Gaussian charge distribution, this energy is $q_j^2 \\alpha / \\sqrt{\\pi}$. Summing over all ions in the unit cell gives:\n$$\nE_{\\mathrm{self}} = \\frac{\\alpha}{\\sqrt{\\pi}} \\sum_{j=1}^{N} q_j^2\n$$\nFor the given rock-salt cell, we have $8$ ions with charges $q_j \\in \\{+1, -1\\}$, so $\\sum q_j^2 = 8$. Thus, $E_{\\mathrm{self}} = 8\\alpha/\\sqrt{\\pi}$.\n\n**4. Madelung Constant Calculation**\n\nThe total electrostatic energy per conventional unit cell is $E_{\\mathrm{cell}} = E_{\\mathrm{real}} + E_{\\mathrm{recip}} - E_{\\mathrm{self}}$. The problem defines the Madelung constant $\\mathcal{M}$ via the relation:\n$$\nE_{\\mathrm{cell}} = -\\frac{8 \\mathcal{M}}{r_0}\n$$\nWith the given nearest-neighbor distance $r_0 = 1/2$, this simplifies to $E_{\\mathrm{cell}} = -16 \\mathcal{M}$.\nTherefore, the Madelung constant to be computed is:\n$$\n\\mathcal{M} = -\\frac{E_{\\mathrm{cell}}}{16} = -\\frac{1}{16} (E_{\\mathrm{real}} + E_{\\mathrm{recip}} - E_{\\mathrm{self}})\n$$\nThe following program implements these formulas to compute $\\mathcal{M}$ for the provided test cases.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.special import erfc\n\ndef calculate_madelung(params):\n    \"\"\"\n    Calculates the Madelung constant for a NaCl crystal using Ewald summation.\n    \n    The implementation follows the derived formulas for the real-space sum,\n    reciprocal-space sum, and self-energy correction.\n    \"\"\"\n    alpha, N_real, r_cut, N_k = params\n    a = 1.0  # Unit cell side length\n    V = a**3 # Unit cell volume\n\n    # Define ion charges and fractional coordinates for the conventional cell\n    charges = np.array([-1, -1, -1, -1, 1, 1, 1, 1], dtype=np.float64)\n    positions = np.array([\n        [0.0, 0.0, 0.0], [0.0, 0.5, 0.5], [0.5, 0.0, 0.5], [0.5, 0.5, 0.0], # Anions\n        [0.5, 0.0, 0.0], [0.0, 0.5, 0.0], [0.0, 0.0, 0.5], [0.5, 0.5, 0.5]  # Cations\n    ], dtype=np.float64) * a\n    \n    num_ions = len(charges)\n\n    # 1. Real-space sum (E_real)\n    # This part sums the short-range interactions.\n    # It is split into two parts for clarity and efficiency:\n    # E_real_ij for interactions between different ions (i != j) and their periodic images.\n    # E_real_ii for interactions between an ion and its own periodic images.\n    \n    # Part 1.1: Sum over distinct pairs (i > j)\n    E_real_ij = 0.0\n    for i in range(num_ions):\n        for j in range(i + 1, num_ions):\n            q_i, q_j = charges[i], charges[j]\n            r_ij = positions[i] - positions[j]\n            \n            for nx in range(-N_real, N_real + 1):\n                for ny in range(-N_real, N_real + 1):\n                    for nz in range(-N_real, N_real + 1):\n                        R = np.array([nx, ny, nz], dtype=np.float64) * a\n                        dist = np.linalg.norm(r_ij + R)\n                        if dist > 1e-9 and dist  r_cut: # Exclude self-interaction at R=0\n                            E_real_ij += q_i * q_j * erfc(alpha * dist) / dist\n                            \n    # Part 1.2: Sum over self-interactions with periodic images (i == j, R != 0)\n    E_real_ii_summand = 0.0\n    for nx in range(-N_real, N_real + 1):\n        for ny in range(-N_real, N_real + 1):\n            for nz in range(-N_real, N_real + 1):\n                if nx == 0 and ny == 0 and nz == 0:\n                    continue\n                R = np.array([nx, ny, nz], dtype=np.float64) * a\n                dist = np.linalg.norm(R)\n                if dist  r_cut:\n                    E_real_ii_summand += erfc(alpha * dist) / dist\n    \n    E_real_ii = 0.5 * np.sum(charges**2) * E_real_ii_summand\n    \n    # There's a subtle point here: The prime on the original sum means exclude i=j when R=0.\n    # The split into i!=j and i==j already handles this.\n    # The i!=j sum over all R is correct.\n    # The i==j sum must be over R!=0.\n    # My first implementation was slightly off. The sum over distinct pairs should not exclude anything.\n    # A cleaner way is to sum over all pairs and all R, then subtract the i=j, R=0 term (which is infinite anyway)\n    # Let's reconsider the standard algorithm.\n    E_real_final = 0.0\n    for i in range(num_ions):\n      for j in range(num_ions):\n        r_ij = positions[i] - positions[j]\n        for nx in range(-N_real, N_real+1):\n          for ny in range(-N_real, N_real+1):\n            for nz in range(-N_real, N_real+1):\n              if i == j and nx == 0 and ny == 0 and nz == 0:\n                continue\n              R = np.array([nx,ny,nz]) * a\n              dist = np.linalg.norm(r_ij + R)\n              if dist  r_cut:\n                E_real_final += charges[i] * charges[j] * erfc(alpha * dist) / dist\n    E_real = 0.5 * E_real_final\n\n    # 2. Reciprocal-space sum (E_recip)\n    # This part sums the long-range interactions in Fourier space.\n    E_recip = 0.0\n    for mx in range(-N_k, N_k + 1):\n        for my in range(-N_k, N_k + 1):\n            for mz in range(-N_k, N_k + 1):\n                if mx == 0 and my == 0 and mz == 0:\n                    continue\n                \n                k_vec = 2 * np.pi / a * np.array([mx, my, mz], dtype=np.float64)\n                k_sq = np.dot(k_vec, k_vec)\n\n                # Structure factor S(k)\n                k_dot_r = np.dot(positions, k_vec)\n                S_k = np.sum(charges * np.exp(-1j * k_dot_r))\n                S_k_sq_abs = np.abs(S_k)**2\n                \n                E_recip += np.exp(-k_sq / (4 * alpha**2)) / k_sq * S_k_sq_abs\n\n    E_recip *= 2 * np.pi / V\n\n    # 3. Self-energy correction (E_self)\n    # This term corrects for the spurious self-interaction of the screening\n    # Gaussian charge distributions included in the reciprocal-space sum.\n    E_self = (alpha / np.sqrt(np.pi)) * np.sum(charges**2)\n\n    # 4. Total energy and Madelung Constant (M)\n    E_cell = E_real + E_recip - E_self\n    \n    # Relation from problem statement: E_cell = -16 * M\n    M = -E_cell / 16.0\n    \n    return round(M, 8)\n\ndef solve():\n    # Define the test cases from the problem statement.\n    test_cases = [\n        (2.0, 4, 4.0, 4),\n        (3.5, 5, 5.0, 6),\n        (6.0, 3, 3.0, 8),\n        (4.0, 8, 8.0, 3),\n        (4.5, 10, 10.0, 10),\n    ]\n\n    results = []\n    for case in test_cases:\n        result = calculate_madelung(case)\n        results.append(result)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "2469742"}, {"introduction": "With the ability to run stable simulations that correctly account for physical forces, we can now turn to a primary goal of atomistic modeling: the calculation of macroscopic thermodynamic properties. The Helmholtz free energy difference, $\\Delta F$, is a particularly important quantity, yet it cannot be measured as a simple time average. This practice explores a powerful modern approach based on nonequilibrium work simulations, asking you to derive and implement the Bennett Acceptance Ratio (BAR) method, which connects the Crooks Fluctuation Theorem to the principle of maximum likelihood estimation for a statistically optimal result [@problem_id:2469784].", "problem": "You will work with nonequilibrium work data from forward and reverse molecular switching processes and use them to estimate a free-energy difference by a statistically optimal bidirectional estimator. Assume the Crooks fluctuation theorem holds: the forward and reverse work distributions satisfy the relation\n$$\n\\frac{p_F(w)}{p_R(-w)} = \\exp\\big(\\beta\\,[w - \\Delta F]\\big),\n$$\nwhere $p_F(w)$ is the forward work density, $p_R(w)$ is the reverse work density, $\\beta$ is the inverse temperature, and $\\Delta F$ is the equilibrium free energy difference between the end states. Here $\\beta$ has units $\\mathrm{(energy)^{-1}}$, and $w$ and $\\Delta F$ have units of energy. The goal is to derive and implement the maximum likelihood estimator based on labeled samples from both forward and reverse processes.\n\nTask 1 (derivation): Starting from Bayes’ rule, Crooks fluctuation theorem, and the assumption that the $n_F$ forward work samples $\\{w_i^{(F)}\\}_{i=1}^{n_F}$ are independent draws from $p_F(w)$ while the $n_R$ reverse work samples $\\{w_j^{(R)}\\}_{j=1}^{n_R}$ are independent draws from $p_R(w)$, derive the maximum likelihood stationarity conditions for the free-energy difference $\\Delta F$ and a constant $C$ that encodes the class prior odds. Show that the condition for the optimal $C$ is\n$$\nC^\\star = \\ln\\!\\left(\\frac{n_F}{n_R}\\right),\n$$\nand that, with $C$ set to $C^\\star$, the maximum likelihood condition for $\\Delta F$ can be written as a single nonlinear equation in $\\Delta F$ that is strictly monotone and has a unique solution.\n\nTask 2 (computation): Implement a numerical solver to compute $\\Delta F$ by finding the root of the stationarity equation for $\\Delta F$ at the optimal $C^\\star$. Your implementation must:\n- Use a robust one-dimensional root-finding method to solve for the unique root in $\\Delta F$.\n- Use the provided finite work samples and the provided $\\beta$ values.\n- Treat all work values in $\\mathrm{kJ\\,mol^{-1}}$ and all inverse temperatures $\\beta$ in $\\mathrm{(kJ\\,mol^{-1})^{-1}}$.\n- Report $\\Delta F$ in $\\mathrm{kJ\\,mol^{-1}}$, rounded to six decimal places.\n\nTest suite: For each of the following cases, compute $\\Delta F$ by solving the maximum likelihood condition with the optimal constant $C^\\star$.\n\n- Case 1 (balanced, moderate overlap):\n  - $\\beta = 1.000000\\ \\mathrm{(kJ\\,mol^{-1})^{-1}}$\n  - $W_F = [1.5,\\ 2.0,\\ 2.5,\\ 1.8,\\ 2.2]\\ \\mathrm{kJ\\,mol^{-1}}$\n  - $W_R = [-1.5,\\ -2.1,\\ -1.8,\\ -2.5,\\ -2.2]\\ \\mathrm{kJ\\,mol^{-1}}$\n\n- Case 2 (unbalanced sample sizes):\n  - $\\beta = 0.500000\\ \\mathrm{(kJ\\,mol^{-1})^{-1}}$\n  - $W_F = [3.6,\\ 4.2,\\ 3.9,\\ 4.1,\\ 3.8,\\ 4.5,\\ 3.7]\\ \\mathrm{kJ\\,mol^{-1}}$\n  - $W_R = [-3.8,\\ -4.3,\\ -4.0,\\ -3.9]\\ \\mathrm{kJ\\,mol^{-1}}$\n\n- Case 3 (high $\\beta$, narrow overlap):\n  - $\\beta = 2.000000\\ \\mathrm{(kJ\\,mol^{-1})^{-1}}$\n  - $W_F = [0.8,\\ 1.1,\\ 0.9,\\ 1.3]\\ \\mathrm{kJ\\,mol^{-1}}$\n  - $W_R = [-1.7,\\ -2.2,\\ -2.0,\\ -1.9,\\ -2.1]\\ \\mathrm{kJ\\,mol^{-1}}$\n\n- Case 4 (degenerate symmetric pair):\n  - $\\beta = 1.000000\\ \\mathrm{(kJ\\,mol^{-1})^{-1}}$\n  - $W_F = [0.0]\\ \\mathrm{kJ\\,mol^{-1}}$\n  - $W_R = [0.0]\\ \\mathrm{kJ\\,mol^{-1}}$\n\nFinal output format: Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (e.g., \"[result1,result2,result3,result4]\"). Each result must be the $\\Delta F$ value for the corresponding case, in $\\mathrm{kJ\\,mol^{-1}}$, rounded to six decimal places. The program must be self-contained, use no input, and have no randomness. Angle units are not applicable. Percentages are not used anywhere; all outputs are plain floats.", "solution": "We begin from two fundamental components:\n\n1. The Crooks fluctuation theorem: for work $w$ in the forward process and the negative of reverse work $-w$ in the reverse process, the distributions satisfy\n$$\n\\frac{p_F(w)}{p_R(-w)} = \\exp\\!\\big(\\beta\\,[w - \\Delta F]\\big).\n$$\n\n2. Bayes’ rule for labeled data combined with independence: given class priors $\\pi_F$ and $\\pi_R$ (proportional to $n_F$ and $n_R$), the posterior probability that an observation with value $x$ belongs to the forward class is\n$$\nP(F\\mid x) = \\frac{\\pi_F p_F(x)}{\\pi_F p_F(x) + \\pi_R p_R(x)}.\n$$\n\nTo reconcile the two distributions’ support, we define a common variable $x$ such that the forward samples enter as $x_i^{(F)} = w_i^{(F)}$ while reverse samples enter as $x_j^{(R)} = -w_j^{(R)}$. With this definition, the Crooks fluctuation theorem becomes\n$$\n\\frac{p_F(x)}{p_R(x)} = \\exp\\!\\big(\\beta\\,[x - \\Delta F]\\big).\n$$\nLet $\\pi_F = n_F/(n_F+n_R)$ and $\\pi_R = n_R/(n_F+n_R)$. Then the posterior odds read\n$$\n\\frac{P(F\\mid x)}{P(R\\mid x)} = \\frac{\\pi_F p_F(x)}{\\pi_R p_R(x)} = \\frac{\\pi_F}{\\pi_R}\\,\\exp\\!\\big(\\beta\\,[x - \\Delta F]\\big).\n$$\nTaking logarithms yields a logistic regression form,\n$$\n\\log\\!\\frac{P(F\\mid x)}{1 - P(F\\mid x)} = \\beta\\,(x - \\Delta F) + C,\n$$\nwhere\n$$\nC \\equiv \\ln\\!\\left(\\frac{\\pi_F}{\\pi_R}\\right) = \\ln\\!\\left(\\frac{n_F}{n_R}\\right)\n$$\nup to an additive constant independent of the parameters of interest. Thus\n$$\nP(F\\mid x) = \\frac{1}{1 + \\exp\\!\\big(-[\\beta\\,(x - \\Delta F) + C]\\big)}.\n$$\nDefine the logistic function $\\sigma(z) \\equiv \\frac{1}{1 + e^{-z}}$. Then\n$$\nP(F\\mid x) = \\sigma\\!\\big(\\beta\\,(x - \\Delta F) + C\\big),\\quad P(R\\mid x) = 1 - P(F\\mid x) = \\sigma\\!\\big(-\\beta\\,(x - \\Delta F) - C\\big).\n$$\n\nMaximum likelihood estimation (MLE) for $\\Delta F$ and $C$: The labeled dataset consists of $n_F$ forward samples with $x_i^{(F)} = w_i^{(F)}$ and $n_R$ reverse samples with $x_j^{(R)} = -w_j^{(R)}$. The log-likelihood is\n$$\n\\mathcal{L}(\\Delta F, C) = \\sum_{i=1}^{n_F} \\log P(F\\mid x_i^{(F)}) + \\sum_{j=1}^{n_R} \\log P(R\\mid x_j^{(R)}).\n$$\nTaking derivatives with respect to $C$ and $\\Delta F$ and setting them to zero yields the stationarity equations. Using $\\partial \\log \\sigma(z)/\\partial z = 1 - \\sigma(z)$ and $\\partial \\log (1 - \\sigma(z))/\\partial z = -\\sigma(z)$, and $\\partial z/\\partial C = 1$ and $\\partial z/\\partial \\Delta F = -\\beta$, we obtain:\n- For $C$,\n$$\n\\frac{\\partial \\mathcal{L}}{\\partial C} = \\sum_{i=1}^{n_F} \\big[1 - \\sigma(z_i^{(F)})\\big] - \\sum_{j=1}^{n_R} \\sigma(z_j^{(R)}) = 0,\n$$\nwhere $z_i^{(F)} \\equiv \\beta\\,(x_i^{(F)} - \\Delta F) + C$ and $z_j^{(R)} \\equiv \\beta\\,(x_j^{(R)} - \\Delta F) + C$.\n- For $\\Delta F$,\n$$\n\\frac{\\partial \\mathcal{L}}{\\partial \\Delta F} = -\\beta \\sum_{i=1}^{n_F} \\big[1 - \\sigma(z_i^{(F)})\\big] - \\beta \\sum_{j=1}^{n_R} \\big[-\\sigma(z_j^{(R)})\\big] = 0,\n$$\nwhich simplifies to\n$$\n\\sum_{i=1}^{n_F} \\big[1 - \\sigma(z_i^{(F)})\\big] = \\sum_{j=1}^{n_R} \\sigma(z_j^{(R)}).\n$$\n\nComparing the two stationarity conditions, we see they are the same equation. However, $C$ is determined by the class priors (and, equivalently, by maximizing the likelihood with respect to $C$ when the priors are set to the empirical class frequencies). Hence the optimal constant is\n$$\nC^\\star = \\ln\\!\\left(\\frac{n_F}{n_R}\\right).\n$$\nWith $C$ fixed at $C^\\star$, the maximum likelihood condition becomes a single nonlinear equation for $\\Delta F$:\n$$\ng(\\Delta F) \\equiv \\sum_{i=1}^{n_F} \\Big[1 - \\sigma\\!\\big(\\beta\\,(x_i^{(F)} - \\Delta F) + C^\\star\\big)\\Big] - \\sum_{j=1}^{n_R} \\sigma\\!\\big(\\beta\\,(x_j^{(R)} - \\Delta F) + C^\\star\\big) = 0.\n$$\nSubstituting $x_i^{(F)} = w_i^{(F)}$ and $x_j^{(R)} = -w_j^{(R)}$ yields the computable form\n$$\ng(\\Delta F) = \\sum_{i=1}^{n_F} \\Big[1 - \\sigma\\!\\big(\\beta\\,(w_i^{(F)} - \\Delta F) + C^\\star\\big)\\Big] - \\sum_{j=1}^{n_R} \\sigma\\!\\big(\\beta\\,(-w_j^{(R)} - \\Delta F) + C^\\star\\big).\n$$\n\nUniqueness and monotonicity: Each term in $g(\\Delta F)$ is a smooth function of $\\Delta F$. For forward terms, the map $\\Delta F \\mapsto 1 - \\sigma(\\beta(w - \\Delta F) + C^\\star)$ increases with $\\Delta F$ because $\\partial/\\partial \\Delta F \\big(1 - \\sigma\\big) = \\beta\\,\\sigma(1 - \\sigma) \\ge 0$. For reverse terms, the map $\\Delta F \\mapsto \\sigma(\\beta(-w - \\Delta F) + C^\\star)$ decreases with $\\Delta F$ because $\\partial/\\partial \\Delta F \\sigma = -\\beta\\,\\sigma(1 - \\sigma) \\le 0$. Therefore, $g(\\Delta F)$ is strictly increasing, continuous, and satisfies\n$$\n\\lim_{\\Delta F \\to -\\infty} g(\\Delta F) = -n_R  0,\\quad \\lim_{\\Delta F \\to +\\infty} g(\\Delta F) = n_F  0,\n$$\nensuring a unique root by the intermediate value theorem. This is Bennett’s acceptance ratio maximum likelihood estimator in its logistic form, with the optimal constant $C^\\star$ given above.\n\nAlgorithmic design:\n- Inputs: arrays $W_F$ and $W_R$ and scalar $\\beta$ for each case.\n- Compute $C^\\star = \\ln(n_F/n_R)$.\n- Define $x^{(F)} = W_F$ and $x^{(R)} = -W_R$.\n- Define $g(\\Delta F)$ as above using the logistic function $\\sigma(z) = 1/(1 + e^{-z})$.\n- Use a robust bracketed root-finder on $g(\\Delta F)$ over a wide interval (e.g., $\\Delta F \\in [-10^4, 10^4]$ in the same energy unit as $W_F$ and $W_R$), guaranteed to bracket the unique root because $g$ transitions from negative to positive over the real line.\n- Solve for $\\Delta F$, and round to six decimal places in $\\mathrm{kJ\\,mol^{-1}}$.\n- Repeat for each test case.\n\nImplementation details:\n- Use a stable logistic evaluation, $\\sigma(z)$, to prevent overflow at large $\\lvert z \\rvert$.\n- Use a proven root-finding method such as Brent’s method to obtain the unique root of $g(\\Delta F)$ for each case.\n- The final outputs are the four $\\Delta F$ values in $\\mathrm{kJ\\,mol^{-1}}$, each rounded to six decimal places, printed as a single bracketed comma-separated list.\n\nThis approach starts from the Crooks fluctuation theorem and Bayes’ rule, expresses the likelihood under independence, shows that the optimal constant is $C^\\star = \\ln(n_F/n_R)$, and reduces the maximum likelihood estimator for $\\Delta F$ to solving a one-dimensional strictly monotone nonlinear equation, which is computed numerically for the provided bidirectional work datasets.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.special import expit\nfrom scipy.optimize import brentq\n\ndef mle_bar_deltaF(w_forward, w_reverse, beta):\n    \"\"\"\n    Compute Delta F (kJ/mol) via Bennett's acceptance ratio MLE condition\n    using forward work samples w_forward and reverse work samples w_reverse,\n    with inverse temperature beta in (kJ/mol)^(-1).\n\n    We solve g(DeltaF) = 0, where:\n      g(DeltaF) = sum_{i in F} [1 - sigma(beta*(wF_i - DeltaF) + C*)]\n                  - sum_{j in R} sigma(beta*(-wR_j - DeltaF) + C*)\n    with C* = ln(nF/nR).\n    \"\"\"\n    wF = np.asarray(w_forward, dtype=float)\n    wR = np.asarray(w_reverse, dtype=float)\n    nF = wF.size\n    nR = wR.size\n    if nF == 0 or nR == 0:\n        raise ValueError(\"Both forward and reverse sample sets must be non-empty.\")\n    Cstar = np.log(nF / nR)\n    \n    # Define the function whose root we want to find.\n    def g(DeltaF):\n        # Arguments for the logistic function (expit)\n        zF = beta * (wF - DeltaF) + Cstar\n        zR = beta * (-wR - DeltaF) + Cstar\n        \n        # BAR/MLE equation in logistic form\n        term_F = np.sum(1.0 - expit(zF))\n        term_R = np.sum(expit(zR))\n        \n        return term_F - term_R\n\n    # Bracket the unique root. A wide interval ensures a sign change\n    # because g(DeltaF) is monotonic and goes from -nR to nF.\n    lo, hi = -1.0e4, 1.0e4\n    glo = g(lo)\n    ghi = g(hi)\n    \n    # Safety check to expand bounds if necessary (shouldn't happen with expit)\n    expand = 0\n    while glo * ghi >= 0 and expand  5:\n        lo *= 10.0\n        hi *= 10.0\n        glo = g(lo)\n        ghi = g(hi)\n        expand += 1\n        \n    # Find the root using Brent's method, which is robust for bracketed roots.\n    DeltaF_root = brentq(g, lo, hi, xtol=1e-12, rtol=1e-12, maxiter=1000)\n    return DeltaF_root\n\ndef solve():\n    # Define the test cases from the problem statement.\n    # Units: kJ/mol for work, (kJ/mol)^(-1) for beta\n    test_cases = [\n        # Case 1\n        {\n            \"beta\": 1.0,\n            \"wF\": [1.5, 2.0, 2.5, 1.8, 2.2],\n            \"wR\": [-1.5, -2.1, -1.8, -2.5, -2.2],\n        },\n        # Case 2\n        {\n            \"beta\": 0.5,\n            \"wF\": [3.6, 4.2, 3.9, 4.1, 3.8, 4.5, 3.7],\n            \"wR\": [-3.8, -4.3, -4.0, -3.9],\n        },\n        # Case 3\n        {\n            \"beta\": 2.0,\n            \"wF\": [0.8, 1.1, 0.9, 1.3],\n            \"wR\": [-1.7, -2.2, -2.0, -1.9, -2.1],\n        },\n        # Case 4\n        {\n            \"beta\": 1.0,\n            \"wF\": [0.0],\n            \"wR\": [0.0],\n        },\n    ]\n\n    results = []\n    for case in test_cases:\n        beta = case[\"beta\"]\n        wF = case[\"wF\"]\n        wR = case[\"wR\"]\n        DeltaF = mle_bar_deltaF(wF, wR, beta)\n        results.append(f\"{DeltaF:.6f}\")\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(results)}]\")\n\nsolve()\n```", "id": "2469784"}]}