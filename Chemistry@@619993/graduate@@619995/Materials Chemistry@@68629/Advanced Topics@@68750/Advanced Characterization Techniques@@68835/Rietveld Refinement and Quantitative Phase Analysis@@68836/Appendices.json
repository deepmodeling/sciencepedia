{"hands_on_practices": [{"introduction": "Before any meaningful analysis of a diffraction pattern can begin, we must ensure the data is free from instrumental artifacts. Two of the most common systematic errors in laboratory Bragg-Brentano diffractometers are a constant zero-point shift and an angle-dependent peak shift due to specimen displacement. This practice guides you through the crucial first step of deriving the correction model from first principles and implementing a calibration procedure, which is essential for accurate lattice parameter determination in any high-quality Rietveld refinement [@problem_id:2517921].", "problem": "A Bragg–Brentano parafocusing X-ray diffraction (XRD) instrument exhibits two dominant systematic errors that shift peak positions: an additive zero shift and a specimen displacement along the diffractometer axis. Consider a calibration using a crystalline standard with known expected peak positions, then apply the estimated instrument corrections to a separate sample pattern prior to Rietveld refinement. Your task is to derive from first principles a linearizable relationship between measured and expected positions that allows simultaneous estimation of the zero shift and the specimen displacement using only the known instrument radius and the calibrant peak positions, and then use those estimates to correct a sample’s measured pattern by solving the appropriate implicit equation for the corrected angles. All angles must be treated and reported in degrees, and the specimen displacement must be treated and reported in millimetres.\n\nStarting points you may assume:\n- Bragg’s law for diffraction relates interplanar spacing, wavelength, and the Bragg angle. In the Bragg–Brentano geometry, a peak occurs at a scattering angle that is twice the Bragg angle.\n- In this parafocusing geometry, a small specimen height error modifies the diffraction condition via a deterministic path-length effect that depends on the Bragg angle and the diffractometer radius.\n- The zero shift is an additive angular offset to the measured $2\\theta$ that is independent of angle.\n\nDo not use any “shortcut” formulas not derived from these principles; instead, construct the appropriate relation and estimation procedure from these bases.\n\nFor each test case below, you are given:\n- The diffractometer radius $R$ in millimetres.\n- The expected calibrant peak positions (true) in $2\\theta$ in degrees.\n- The measured calibrant peak positions in $2\\theta$ in degrees.\n- A set of sample peak positions (observed) in $2\\theta$ in degrees that must be corrected using your estimated instrument parameters.\n\nYour program must, for each test case:\n1) Estimate the zero shift $z$ in degrees and the specimen displacement $\\Delta h$ in millimetres from the calibrant peaks and $R$, using a physically justified linearizable model derived from the Bragg–Brentano geometry with a small-displacement approximation. Do not assume either parameter is known a priori.\n2) Apply the estimated $z$ and $\\Delta h$ to correct each provided sample $2\\theta$ by solving the appropriate implicit correction equation for the corrected $2\\theta$ using a numerically stable fixed-point or root-finding iteration. Use a convergence tolerance of $\\varepsilon = 10^{-10}$ degrees on the corrected $2\\theta$ and a maximum of $100$ iterations per peak. If the iteration does not converge within the limit, return the last iterate.\n3) Report all outputs as real numbers rounded to six decimal places.\n\nTest suite (three cases):\n- Case $1$:\n  - $R = 200.0$ mm\n  - Expected calibrant $2\\theta$ (degrees): $[28.44200, 47.30500, 56.11900]$\n  - Measured calibrant $2\\theta$ (degrees): $[28.40870, 47.27610, 56.09320]$\n  - Sample observed $2\\theta$ (degrees): $[30.00000, 45.00000, 60.00000, 75.00000]$\n- Case $2$:\n  - $R = 217.5$ mm\n  - Expected calibrant $2\\theta$ (degrees): $[28.44200, 47.30500, 56.11900]$\n  - Measured calibrant $2\\theta$ (degrees): $[28.32200, 47.18500, 55.99900]$\n  - Sample observed $2\\theta$ (degrees): $[25.00000, 40.00000, 55.00000, 70.00000]$\n- Case $3$:\n  - $R = 160.0$ mm\n  - Expected calibrant $2\\theta$ (degrees): $[28.44200, 47.30500, 56.11900]$\n  - Measured calibrant $2\\theta$ (degrees): $[28.58100, 47.43630, 56.24560]$\n  - Sample observed $2\\theta$ (degrees): $[35.00000, 50.00000, 65.00000, 80.00000]$\n\nAngle unit: degrees. Length unit: millimetres. No other units may be used. Express $z$ as a real number in degrees and $\\Delta h$ as a real number in millimetres. Each corrected sample peak must be expressed as a real number in degrees.\n\nFinal output format:\n- Produce a single line containing a comma-separated list enclosed in square brackets.\n- The list must concatenate, in order, for each test case: the estimated zero shift $z$ (degrees), the estimated specimen displacement $\\Delta h$ (millimetres), followed by the corrected sample $2\\theta$ values (degrees) in the exact order given for that case.\n- All numbers must be rounded to six decimal places.\n- Concretely, for three cases each with four sample peaks, the output must contain $3 \\times (2 + 4) = 18$ numbers, e.g., $[z_1, \\Delta h_1, c_{1,1}, c_{1,2}, c_{1,3}, c_{1,4}, z_2, \\Delta h_2, c_{2,1}, c_{2,2}, c_{2,3}, c_{2,4}, z_3, \\Delta h_3, c_{3,1}, c_{3,2}, c_{3,3}, c_{3,4}]$, where each $c_{i,j}$ is a corrected sample $2\\theta$ in degrees.", "solution": "The problem is validated as scientifically grounded, well-posed, and an objective task in applied physics and data analysis. It requires the derivation and application of a model for systematic errors in Bragg-Brentano X-ray diffractometry. The solution proceeds in two stages: first, the derivation of the model and estimation of instrument parameters from calibration data; second, the application of these parameters to correct measured data from a sample.\n\nThe relationship between the measured scattering angle, $2\\theta_m$, and the true crystallographic scattering angle, $2\\theta_c$, is affected by several systematic errors. The problem specifies two dominant errors: an instrument zero shift, $z$, and a specimen displacement error, $\\Delta h$. The measured angle is the sum of the true angle and the contributions from these errors.\n\nThe zero shift, $z$, is a constant angular offset added to all measurements, independent of the angle itself. Thus, its contribution to the measured angle is simply $+z$.\n\nThe specimen displacement error arises when the sample surface is not perfectly coincident with the goniometer's focusing circle axis. A displacement $\\Delta h$ of the specimen along its surface normal (perpendicular to the sample plane) introduces an angle-dependent shift in the measured peak position. A geometric analysis of the Bragg-Brentano parafocusing geometry reveals that for a small displacement $\\Delta h$ relative to the goniometer radius $R$, the induced angular shift in $2\\theta$, denoted $\\Delta(2\\theta)_{disp}$, is given in radians by:\n$$\n\\Delta(2\\theta)_{disp} \\approx -2\\frac{\\Delta h}{R}\\cos(\\theta_c)\n$$\nwhere $\\theta_c = 2\\theta_c / 2$ is the true Bragg angle. The negative sign indicates that a positive displacement (sample too high, toward the source/detector) shifts the peak to a lower $2\\theta$ value. To work in degrees, as required, we convert this expression:\n$$\n\\Delta(2\\theta)_{disp, deg} = \\left(-2\\frac{\\Delta h}{R}\\cos(\\theta_c)\\right) \\times \\frac{180}{\\pi} = -\\frac{360}{\\pi}\\frac{\\Delta h}{R}\\cos(\\theta_c)\n$$\nCombining both error terms, the relationship between the measured and true angles is:\n$$\n2\\theta_m \\approx 2\\theta_c + z + \\Delta(2\\theta)_{disp, deg} = 2\\theta_c + z - \\frac{360}{\\pi}\\frac{\\Delta h}{R}\\cos(\\theta_c)\n$$\nTo estimate the unknown parameters $z$ and $\\Delta h$, we rearrange this equation into a linear form suitable for regression. Using the provided calibrant data, for which both $2\\theta_m$ and $2\\theta_c$ are known for a set of peaks $i=1, \\dots, N$:\n$$\n2\\theta_{m,i} - 2\\theta_{c,i} = z - \\left(\\frac{360}{\\pi R}\\Delta h\\right) \\cos(\\theta_{c,i})\n$$\nThis equation is of the form $Y_i = C + M X_i$, which defines a straight line. We can identify the variables and coefficients:\n- The dependent variable is $Y_i = 2\\theta_{m,i} - 2\\theta_{c,i}$.\n- The independent variable is $X_i = \\cos(\\theta_{c,i}) = \\cos(2\\theta_{c,i}/2)$.\n- The intercept is $C = z$.\n- The slope is $M = -\\frac{360}{\\pi R}\\Delta h$.\n\nGiven a set of calibration peaks, the values for $z$ and $M$ can be determined by performing a linear least-squares fit of $Y$ versus $X$. The instrument zero shift $z$ is directly given by the intercept of the fit. The specimen displacement $\\Delta h$ can be calculated from the slope $M$:\n$$\n\\Delta h = -M \\frac{\\pi R}{360}\n$$\nOnce the parameters $z$ and $\\Delta h$ (via $M$) are estimated, they can be used to correct the measured peak positions, $2\\theta_{obs}$, for a new sample. For such a sample, the true, corrected position $2\\theta_{corr}$ is unknown. It is found by solving the following implicit equation:\n$$\n2\\theta_{obs} = 2\\theta_{corr} + z - \\frac{360}{\\pi}\\frac{\\Delta h}{R}\\cos(\\theta_{corr})\n$$\nSubstituting $M = -\\frac{360}{\\pi R}\\Delta h$, we get:\n$$\n2\\theta_{obs} = 2\\theta_{corr} + z + M \\cos(\\theta_{corr})\n$$\nRearranging to solve for $2\\theta_{corr}$ gives:\n$$\n2\\theta_{corr} = 2\\theta_{obs} - z - M \\cos(\\frac{2\\theta_{corr}}{2})\n$$\nThis equation is in the form $x = g(x)$, where $x = 2\\theta_{corr}$ and $g(x) = (2\\theta_{obs} - z) - M \\cos(x/2)$. It can be solved numerically using fixed-point iteration. We define an iterative sequence:\n$$\nx_{k+1} = (2\\theta_{obs} - z) - M \\cos\\left(\\frac{\\pi}{180} \\frac{x_k}{2}\\right)\n$$\nA suitable initial guess is $x_0 = 2\\theta_{obs} - z$, which neglects the small displacement correction. The iteration is repeated until the change between successive values, $|x_{k+1} - x_k|$, falls below a specified tolerance $\\varepsilon = 10^{-10}$. The convergence is rapid because the derivative $|g'(x)| = |(M \\pi / 360) \\sin(x/2)| = |(\\Delta h/R)\\sin(x/2)|$ is typically much less than $1$. If convergence is not achieved within $100$ iterations, the last computed value is used. All angles must be handled in degrees, with conversions to radians for trigonometric function arguments.", "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves for instrument correction parameters and applies them to sample data\n    for a series of test cases in X-ray diffraction analysis.\n    \"\"\"\n    # Test cases as provided in the problem description.\n    test_cases = [\n        {\n            \"R\": 200.0,\n            \"cal_true\": np.array([28.44200, 47.30500, 56.11900]),\n            \"cal_meas\": np.array([28.40870, 47.27610, 56.09320]),\n            \"sam_obs\": np.array([30.00000, 45.00000, 60.00000, 75.00000]),\n        },\n        {\n            \"R\": 217.5,\n            \"cal_true\": np.array([28.44200, 47.30500, 56.11900]),\n            \"cal_meas\": np.array([28.32200, 47.18500, 55.99900]),\n            \"sam_obs\": np.array([25.00000, 40.00000, 55.00000, 70.00000]),\n        },\n        {\n            \"R\": 160.0,\n            \"cal_true\": np.array([28.44200, 47.30500, 56.11900]),\n            \"cal_meas\": np.array([28.58100, 47.43630, 56.24560]),\n            \"sam_obs\": np.array([35.00000, 50.00000, 65.00000, 80.00000]),\n        }\n    ]\n\n    all_results = []\n    \n    # Define constants for the iterative correction\n    TOLERANCE = 1e-10\n    MAX_ITERATIONS = 100\n\n    for case in test_cases:\n        R = case[\"R\"]\n        cal_true_2theta = case[\"cal_true\"]\n        cal_meas_2theta = case[\"cal_meas\"]\n        sam_obs_2theta = case[\"sam_obs\"]\n\n        # Step 1: Estimate z and delta_h using linear regression.\n        # The model is: 2theta_meas = 2theta_true + z - (360/pi * delta_h/R) * cos(theta_true)\n        # We linearize this as: y = C + M*x\n        # where y = 2theta_meas - 2theta_true, x = cos(theta_true), C = z, M = -(360/pi * delta_h/R)\n        \n        y_cal = cal_meas_2theta - cal_true_2theta\n        theta_true_deg = cal_true_2theta / 2.0\n        x_cal = np.cos(np.deg2rad(theta_true_deg))\n\n        # Perform linear least-squares regression to find slope (M) and intercept (C).\n        # np.polyfit(x, y, 1) returns [slope, intercept].\n        slope, intercept = np.polyfit(x_cal, y_cal, 1)\n\n        # Estimate parameters z and delta_h from regression results.\n        z_est = intercept  # in degrees\n        # From M = -(360/pi * delta_h/R), we get delta_h = -M * (pi*R/360)\n        delta_h_est = -slope * (np.pi * R / 360.0)  # in mm\n\n        all_results.append(z_est)\n        all_results.append(delta_h_est)\n\n        # Step 2: Correct sample peak positions by solving the implicit equation.\n        # 2theta_corr = 2theta_obs - z + (360/pi * delta_h/R) * cos(theta_corr)\n        # Using the slope M: 2theta_corr = 2theta_obs - z - M * cos(theta_corr)\n        \n        corrected_peaks = []\n        for obs_peak in sam_obs_2theta:\n            # Fixed-point iteration: x_{k+1} = g(x_k)\n            # where x = 2theta_corr\n\n            # Initial guess for the corrected angle\n            x_corr = obs_peak - z_est\n            \n            constant_term = obs_peak - z_est\n            cosine_coeff = -slope\n            \n            for _ in range(MAX_ITERATIONS):\n                x_prev = x_corr\n                # The argument to cosine must be in radians. x_prev is 2*theta in degrees.\n                theta_corr_rad = np.deg2rad(x_prev / 2.0)\n                x_corr = constant_term + cosine_coeff * np.cos(theta_corr_rad)\n                \n                if np.abs(x_corr - x_prev)  TOLERANCE:\n                    break\n            \n            corrected_peaks.append(x_corr)\n        \n        all_results.extend(corrected_peaks)\n\n    # Format all numbers to six decimal places for the final output string.\n    formatted_results = [f\"{num:.6f}\" for num in all_results]\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```", "id": "2517921"}, {"introduction": "Once instrumental contributions to peak positions are accounted for, the shape and breadth of diffraction peaks hold a wealth of information about the sample's own microstructure. Peak broadening arises from two primary physical sources: the finite size of coherently scattering crystalline domains and the presence of microstrain within the crystal lattice. This exercise introduces the classic Williamson-Hall analysis, a powerful method to deconvolve and quantify these two contributions based on their distinct dependencies on the diffraction angle $\\theta$ [@problem_id:2517814]. You will not only learn to extract volume-weighted crystallite size $D$ and microstrain $\\epsilon$, but also to assess the statistical correlation between them, a frequent challenge in line profile analysis.", "problem": "You are given line profile broadening data for powder X-ray diffraction peaks of a cubic nanocrystalline material measured with a laboratory diffractometer using Copper K-alpha radiation. The objective is to extract the volume-weighted crystallite size $D$ and the root-mean-square microstrain $\\epsilon$ by partitioning the peak breadth into contributions from finite crystallite size and microstrain in a Rietveld-like manner, and to quantify the parameter correlation from a statistically sound least-squares model.\n\nFoundational starting points you must use:\n- Bragg’s Law: $2 d \\sin \\theta = \\lambda$, where $\\theta$ is the Bragg angle and $\\lambda$ is the wavelength.\n- For a polycrystalline powder in the kinematic approximation, the integral breadth (area divided by height) of a diffraction peak, after instrument deconvolution, can be modeled as the sum of size and strain broadening contributions along the diffraction vector.\n- For volume-weighted crystallite size, the Scherrer-type relation for the integral breadth is proportional to $1/\\cos \\theta$.\n- For root-mean-square microstrain (assumed isotropic), the strain broadening integral breadth scales with $\\tan \\theta$.\n\nUse the following data and constants:\n- Use Copper K-alpha wavelength $\\lambda$ in nanometers: $\\lambda = 0.15406$.\n- Use shape factor $K = 0.9$ appropriate for volume-weighted size.\n- The peak breadths supplied below are instrument-corrected integral breadths, denoted $\\beta^\\star$, expressed in radians of $2\\theta$. Angles are given as $2\\theta$ in degrees. When computing trigonometric functions, you must use $\\theta$ in radians, where $\\theta = (2\\theta)/2$ converted to radians from degrees.\n- You must report $D$ in nanometers and $\\epsilon$ as a dimensionless decimal (not a percent).\n\nTest suite:\nFor each case, a set of $2\\theta$ values (in degrees) and corresponding instrument-corrected integral breadths $\\beta^\\star$ (in radians of $2\\theta$) is provided.\n\n- Case A (broad angular coverage, moderate size and strain):\n  - $2\\theta$: $[40, 50, 70, 90, 110, 120]$\n  - $\\beta^\\star$: $[0.005028, 0.005638, 0.007124, 0.009159, 0.012226, 0.014476]$\n\n- Case B (limited angular coverage, stronger parameter correlation expected):\n  - $2\\theta$: $[40, 50, 60]$\n  - $\\beta^\\star$: $[0.003919, 0.004416, 0.004979]$\n\n- Case C (dominantly size broadening):\n  - $2\\theta$: $[40, 50, 70, 90, 110, 120]$\n  - $\\beta^\\star$: $[0.005904, 0.006122, 0.006773, 0.007845, 0.009662, 0.011092]$\n\n- Case D (dominantly strain broadening):\n  - $2\\theta$: $[40, 50, 70, 90, 110, 120]$\n  - $\\beta^\\star$: $[0.003788, 0.004814, 0.007172, 0.010197, 0.014526, 0.017598]$\n\nRequirements:\n1. Starting from the foundational relations, construct a linearizable model that partitions the integral breadth into size and strain components as a function of $\\theta$, suitable for least-squares estimation of two parameters that map to $D$ and $\\epsilon$.\n2. Use ordinary least squares on the linearized model to estimate the two regression parameters from each case’s data. From those, compute $D$ (in nanometers) and $\\epsilon$ (dimensionless).\n3. Estimate the parameter covariance matrix from the least-squares design matrix and residual sum of squares. Propagate this covariance to obtain the covariance between $D$ and $\\epsilon$, and report the correlation coefficient $r$ between $D$ and $\\epsilon$ defined as $r = \\mathrm{cov}(D,\\epsilon)/\\sqrt{\\mathrm{var}(D)\\mathrm{var}(\\epsilon)}$. If the denominator is numerically zero, set $r$ to $0$.\n4. Angles must be converted to radians for any trigonometric function evaluations. Final $D$ must be expressed in nanometers and $\\epsilon$ as a decimal. Do not use a percent sign.\n5. Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, where each case’s result is a three-element list $[D,\\epsilon,r]$ with each value formatted to six decimal places. For example: $[[D_A,\\epsilon_A,r_A],[D_B,\\epsilon_B,r_B],[D_C,\\epsilon_C,r_C],[D_D,\\epsilon_D,r_D]]$.\n\nYour task:\n- Implement a program that applies the above modeling and estimation to the provided test suite and prints the single-line aggregated result as specified.", "solution": "The problem presented is a valid and well-posed application of X-ray line profile analysis. It requires the determination of crystallite size and microstrain from powder diffraction data using a standard Williamson-Hall approach. All provided data, constants, and foundational principles are scientifically sound and internally consistent.\n\nThe objective is to determine the volume-weighted crystallite size, $D$, and the root-mean-square microstrain, $\\epsilon$, by modeling the instrument-corrected integral breadth, $\\beta^\\star$, of diffraction peaks. The total breadth is assumed to be a linear sum of the size-broadening contribution, $\\beta_D$, and the strain-broadening contribution, $\\beta_\\epsilon$:\n$$ \\beta^\\star = \\beta_D + \\beta_\\epsilon $$\n\nThe size contribution is described by the Scherrer equation, where the integral breadth is inversely proportional to the crystallite size and the cosine of the Bragg angle, $\\theta$:\n$$ \\beta_D = \\frac{K \\lambda}{D \\cos\\theta} $$\nHere, $K$ is the dimensionless Scherrer shape factor (given as $K=0.9$), $\\lambda$ is the X-ray wavelength (given as $\\lambda=0.15406$ nm), and $D$ is the volume-weighted crystallite size in nanometers. The breadth $\\beta_D$ is expressed in radians of $2\\theta$.\n\nThe strain contribution is modeled based on Wilson's theory for isotropic strain, where the breadth is proportional to the tangent of the Bragg angle:\n$$ \\beta_\\epsilon = 4 \\epsilon \\tan\\theta $$\nHere, $\\epsilon$ is the dimensionless root-mean-square microstrain, and $\\beta_\\epsilon$ is also in radians of $2\\theta$.\n\nCombining these two contributions gives the total breadth model:\n$$ \\beta^\\star = \\frac{K \\lambda}{D \\cos\\theta} + 4 \\epsilon \\tan\\theta $$\n\nTo estimate the parameters $D$ and $\\epsilon$ using linear least-squares, this equation is rearranged into the Williamson-Hall form by multiplying by $\\cos\\theta$:\n$$ \\beta^\\star \\cos\\theta = \\frac{K \\lambda}{D} + 4 \\epsilon \\sin\\theta $$\n\nThis equation is of the linear form $y_i = c + m x_i$ for each diffraction peak $i$, where:\n- The dependent variable is $y_i = \\beta^\\star_i \\cos\\theta_i$.\n- The independent variable is $x_i = \\sin\\theta_i$.\n- The intercept is $c = \\frac{K \\lambda}{D}$.\n- The slope is $m = 4 \\epsilon$.\n\nThe analysis proceeds by first converting the given diffraction angles $2\\theta$ from degrees to radians and calculating $\\theta_i = (2\\theta_i)/2$. Then, for each data point $(\\beta^\\star_i, \\theta_i)$, the corresponding pair $(x_i, y_i)$ is computed. The optimal values for the slope $\\hat{m}$ and intercept $\\hat{c}$ are found by performing an ordinary least-squares (OLS) regression. In matrix notation, for a system $\\mathbf{y} = \\mathbf{Xp}$, where $\\mathbf{p} = [c, m]^T$ is the parameter vector and $\\mathbf{X}$ is the design matrix, the OLS estimate is given by $\\hat{\\mathbf{p}} = (\\mathbf{X}^T\\mathbf{X})^{-1}\\mathbf{X}^T\\mathbf{y}$.\n\nFrom the estimated parameters $\\hat{c}$ and $\\hat{m}$, the physical quantities are derived:\n$$ D = \\frac{K \\lambda}{\\hat{c}} \\quad \\text{and} \\quad \\epsilon = \\frac{\\hat{m}}{4} $$\n\nTo quantify the statistical correlation between the determined parameters $D$ and $\\epsilon$, we first compute the covariance matrix of the regression parameters, $\\mathrm{cov}(\\hat{\\mathbf{p}})$. This is given by:\n$$ \\mathrm{cov}(\\hat{\\mathbf{p}}) = \\hat{\\sigma}^2 (\\mathbf{X}^T\\mathbf{X})^{-1} $$\nwhere $\\hat{\\sigma}^2$ is the unbiased estimate of the regression variance, calculated from the residual sum of squares (RSS):\n$$ \\hat{\\sigma}^2 = \\frac{1}{N-k} \\mathrm{RSS} = \\frac{1}{N-2} \\sum_{i=1}^{N} (y_i - (\\hat{c} + \\hat{m}x_i))^2 $$\nHere, $N$ is the number of data points and $k=2$ is the number of parameters in the linear model.\n\nThe covariance between $D$ and $\\epsilon$ is found by propagating the covariance from $\\hat{\\mathbf{p}} = [\\hat{c}, \\hat{m}]^T$ through the transformation functions. The Jacobian matrix $\\mathbf{J}$ for the transformation from $(c, m)$ to $(D, \\epsilon)$ is:\n$$ \\mathbf{J} = \\begin{pmatrix} \\frac{\\partial D}{\\partial c}  \\frac{\\partial D}{\\partial m} \\\\ \\frac{\\partial \\epsilon}{\\partial c}  \\frac{\\partial \\epsilon}{\\partial m} \\end{pmatrix} = \\begin{pmatrix} -\\frac{K\\lambda}{c^2}  0 \\\\ 0  \\frac{1}{4} \\end{pmatrix} $$\nThe covariance matrix for $(D, \\epsilon)$ is then approximated by $\\mathrm{cov}(D, \\epsilon) \\approx \\mathbf{J} \\, \\mathrm{cov}(\\hat{\\mathbf{p}}) \\, \\mathbf{J}^T$.\n\nFinally, the correlation coefficient, $r(D, \\epsilon)$, is computed:\n$$ r(D, \\epsilon) = \\frac{\\mathrm{cov}(D, \\epsilon)}{\\sqrt{\\mathrm{var}(D)\\mathrm{var}(\\epsilon)}} $$\nThis calculation reveals that the correlation between the derived physical parameters is the negative of the correlation between the regression parameters, i.e., $r(D, \\epsilon) = -r(\\hat{c}, \\hat{m})$. A strong negative correlation between the fitted slope and intercept, typical for this type of linear fit over a positive range of $x_i$, results in a strong positive correlation between $D$ and $\\epsilon$.\n\nThe following program implements this entire procedure for the provided test cases.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves for crystallite size (D), microstrain (epsilon), and their\n    correlation (r) from XRD peak broadening data using Williamson-Hall analysis.\n    \"\"\"\n\n    # Define constants from the problem statement.\n    K = 0.9  # Scherrer shape factor\n    LAMBDA = 0.15406  # Wavelength in nanometers\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # Case A: Broad angular coverage\n        (np.array([40.0, 50.0, 70.0, 90.0, 110.0, 120.0]),\n         np.array([0.005028, 0.005638, 0.007124, 0.009159, 0.012226, 0.014476])),\n        # Case B: Limited angular coverage\n        (np.array([40.0, 50.0, 60.0]),\n         np.array([0.003919, 0.004416, 0.004979])),\n        # Case C: Dominantly size broadening\n        (np.array([40.0, 50.0, 70.0, 90.0, 110.0, 120.0]),\n         np.array([0.005904, 0.006122, 0.006773, 0.007845, 0.009662, 0.011092])),\n        # Case D: Dominantly strain broadening\n        (np.array([40.0, 50.0, 70.0, 90.0, 110.0, 120.0]),\n         np.array([0.003788, 0.004814, 0.007172, 0.010197, 0.014526, 0.017598])),\n    ]\n\n    results = []\n    for case in test_cases:\n        two_theta_deg, beta_star = case\n        N = len(two_theta_deg)\n\n        # Convert 2*theta in degrees to theta in radians\n        theta_rad = np.deg2rad(two_theta_deg / 2)\n\n        # Construct variables for the Williamson-Hall plot: y = c + m*x\n        # x = sin(theta)\n        # y = beta_star * cos(theta)\n        x_wh = np.sin(theta_rad)\n        y_wh = beta_star * np.cos(theta_rad)\n\n        # Perform Ordinary Least Squares (OLS) regression\n        # Design matrix X for model y = p[0] + p[1]*x\n        X = np.vstack([np.ones(N), x_wh]).T\n        \n        # Calculate parameters p_hat = [c_hat, m_hat] using (X.T * X)^-1 * X.T * y\n        # Use np.linalg.solve for better numerical stability than direct inversion\n        try:\n            XTX = X.T @ X\n            XTy = X.T @ y_wh\n            p_hat = np.linalg.solve(XTX, XTy)\n        except np.linalg.LinAlgError:\n            # Handle singular matrix case, though unlikely with this data\n            results.append([0.0, 0.0, 0.0])\n            continue\n            \n        c_hat, m_hat = p_hat\n\n        # Calculate crystallite size (D) and microstrain (epsilon)\n        # c_hat = K * lambda / D  => D = K * lambda / c_hat\n        # m_hat = 4 * epsilon    => epsilon = m_hat / 4\n        D = 0.0\n        if c_hat > 0:\n            D = (K * LAMBDA) / c_hat\n        \n        epsilon = m_hat / 4.0\n\n        # Calculate the correlation coefficient between D and epsilon\n        r_De = 0.0\n        # Number of parameters in the model k=2\n        if N > 2:\n            # Calculate residual sum of squares (RSS)\n            residuals = y_wh - (c_hat + m_hat * x_wh)\n            RSS = np.sum(residuals**2)\n            \n            # Estimate of the regression variance sigma^2\n            sigma2_hat = RSS / (N - 2)\n\n            # Covariance matrix of the parameters [c, m]\n            try:\n                XTX_inv = np.linalg.inv(XTX)\n                cov_p = sigma2_hat * XTX_inv\n                \n                var_c = cov_p[0, 0]\n                var_m = cov_p[1, 1]\n                cov_cm = cov_p[0, 1]\n\n                # Denominator for correlation coefficient of (c, m)\n                denom_r_cm = np.sqrt(var_c * var_m)\n                \n                if denom_r_cm > 1e-15: # Avoid division by zero\n                    r_cm = cov_cm / denom_r_cm\n                    # Correlation of (D, epsilon) is -1 * correlation of (c, m)\n                    r_De = -r_cm\n                else:\n                    # Occurs if fit is perfect (RSS=0), so no statistical variance\n                    r_De = 0.0\n\n            except np.linalg.LinAlgError:\n                r_De = 0.0\n        else:\n            # Cannot estimate variance with N = k, correlation is undefined\n            r_De = 0.0\n\n        results.append([D, epsilon, r_De])\n\n    # Format output string\n    output_str = \"[\"\n    output_str += \",\".join(\n        f\"[{res[0]:.6f},{res[1]:.6f},{res[2]:.6f}]\" for res in results\n    )\n    output_str += \"]\"\n    \n    # Final print statement in the exact required format.\n    print(output_str)\n\nsolve()\n```", "id": "2517814"}, {"introduction": "A primary application of the Rietveld method is Quantitative Phase Analysis (QPA), which determines the weight fractions of different crystalline phases in a mixture. However, the accuracy of QPA is critically dependent on the physical fidelity of the underlying model. This advanced practice challenges you to think like an expert analyst, critically evaluating how common sample-related effects like microabsorption and preferred orientation (texture) can systematically bias quantitative results [@problem_id:2517872]. By re-analyzing hypothetical \"published\" data from first principles, you will gain a profound appreciation for how modeling choices directly impact the final reported phase quantities.", "problem": "You are given a set of phase-quantitative results from Rietveld refinement along with physical parameters needed to reassess two common sources of systematic bias in quantitative phase analysis: microabsorption and preferred orientation. The aim is to re-estimate the phase fractions when alternative modeling choices are used. The problem must be solved by reasoning from first principles about diffraction intensities and attenuation, without relying on any canned formula that directly maps reported phase fractions to corrected ones.\n\nYou must assume the following foundational base:\n- The Beer–Lambert law for attenuation of X-rays, namely that intensity decays as $I = I_0 \\exp(-\\mu \\ell)$ through path length $\\ell$ with linear attenuation coefficient $\\mu$.\n- In Rietveld refinement, the refined scale factor for a phase is, to leading order, proportional to the diffracted intensity that would be obtained from the amount of that phase present in the irradiated volume.\n- Preferred orientation alters the distribution of crystallite orientations, thereby weighting certain Bragg peaks by a multiplicative factor relative to a random powder. A standard phenomenological model widely used to quantify this weighting at a Bragg angle-dependent orientation is the March–Dollase function.\n\nYou will adopt the following physically motivated, simplified intensity model:\n- Consider a phase $k$ comprising approximately spherical crystallites of radius $R_k$ (in micrometers). Let the mass attenuation coefficient be $\\mu_{m,k}$ (in cm$^2$ g$^{-1}$) and the density be $\\rho_k$ (in g cm$^{-3}$). The linear attenuation coefficient is $\\mu_k = \\mu_{m,k}\\,\\rho_k$ (in cm$^{-1}$).\n- A microabsorption transmission factor $T_k$ for a sphere is defined by averaging the Beer–Lambert attenuation over rays through a sphere of radius $R_k$:\n$$\nT_k(x_k) = \\frac{1 - e^{-x_k}}{x_k}, \\quad \\text{with } x_k = 2 \\mu_k R_k^{(\\mathrm{cm})}, \\quad R_k^{(\\mathrm{cm})} = R_k^{(\\mu \\mathrm{m})} \\times 10^{-4}.\n$$\n- A preferred orientation intensity multiplier for a phase $k$ is approximated by a single effective March–Dollase factor\n$$\nP_k(r_k,\\theta_k) = \\left(r_k^2 \\cos^2 \\theta_k + r_k^{-1} \\sin^2 \\theta_k\\right)^{-3/2},\n$$\nwhere $r_k$ is the March–Dollase parameter and $\\theta_k$ is an effective angle, both taken as given for each phase; $\\theta_k$ must be treated in degrees in the input but used in radians in calculations.\n\nFor a published analysis that reported phase fractions $\\{w_{k}^{(\\mathrm{pub})}\\}_k$ under the modeling choice that neglected both microabsorption and preferred orientation, you are to re-estimate the fractions under alternative modeling choices. Treat the Rietveld scale factors as proportional to the published fractions when both microabsorption and preferred orientation were neglected. Then, by first-principles reasoning, derive how the microabsorption transmission factors $\\{T_k\\}$ and preferred orientation multipliers $\\{P_k\\}$ alter the conversion between scale factor and actual phase fraction. Implement this logic to compute corrected fractions for specified modeling choices.\n\nAngles must be interpreted in degrees in the input parameters and converted to radians for trigonometric functions. Physical units must be used as specified: $\\mu_m$ in cm$^2$ g$^{-1}$, $\\rho$ in g cm$^{-3}$, and $R$ in $\\mu$m, with internal conversion of $R$ to cm. Final phase fractions are unitless and must be expressed as decimals.\n\nTest suite and required outputs:\n- For each test case, you are given:\n  - Published phase fractions $w^{(\\mathrm{pub})}$ as a list that sums to $1$.\n  - Per-phase arrays of the same length for $\\mu_m$, $\\rho$, $R$ (in $\\mu$m), $r$, and $\\theta$ (in degrees).\n  - A modeling choice flag taking one of the values in the set $\\{\\text{\"none\"}, \\text{\"microabsorption\"}, \\text{\"texture\"}, \\text{\"both\"}\\}$ indicating which corrections to apply in recomputing the fractions.\n- Your program must compute corrected fractions for each test case and return each result as a list of floats, each rounded to $6$ decimal places, such that the list sums to $1$ within rounding tolerance. Fractions must be decimals (not percentages).\n\nThe test suite consists of the following $7$ cases, all framed for X-ray radiation at a fixed wavelength where the given $\\mu_m$ values are applicable:\n- Case $1$ (sanity, three-phase sample $S1$, no corrections):\n  - $w^{(\\mathrm{pub})} = [0.5, 0.3, 0.2]$\n  - $\\mu_m = [260, 53, 48]$ cm$^2$ g$^{-1}$\n  - $\\rho = [5.24, 3.98, 2.65]$ g cm$^{-3}$\n  - $R = [10, 5, 3]$ $\\mu$m\n  - $r = [0.9, 1.1, 1.0]$\n  - $\\theta = [30, 45, 0]$ degrees\n  - modeling choice: \"none\"\n- Case $2$ (same $S1$, microabsorption only):\n  - same parameters as Case $1$\n  - modeling choice: \"microabsorption\"\n- Case $3$ (same $S1$, preferred orientation only):\n  - same parameters as Case $1$\n  - modeling choice: \"texture\"\n- Case $4$ (same $S1$, both corrections):\n  - same parameters as Case $1$\n  - modeling choice: \"both\"\n- Case $5$ (two-phase sample $S2$, negligible microabsorption, microabsorption only):\n  - $w^{(\\mathrm{pub})} = [0.6, 0.4]$\n  - $\\mu_m = [50, 60]$ cm$^2$ g$^{-1}$\n  - $\\rho = [3.0, 3.0]$ g cm$^{-3}$\n  - $R = [1.0, 1.0]$ $\\mu$m\n  - $r = [2.0, 1.0]$\n  - $\\theta = [10, 0]$ degrees\n  - modeling choice: \"microabsorption\"\n- Case $6$ (same $S2$, strong texture only):\n  - same parameters as Case $5$\n  - modeling choice: \"texture\"\n- Case $7$ (two-phase sample $S3$, strong microabsorption contrast, microabsorption only):\n  - $w^{(\\mathrm{pub})} = [0.7, 0.3]$\n  - $\\mu_m = [300, 30]$ cm$^2$ g$^{-1}$\n  - $\\rho = [7.2, 2.5]$ g cm$^{-3}$\n  - $R = [15.0, 2.0]$ $\\mu$m\n  - $r = [1.0, 1.0]$\n  - $\\theta = [0, 0]$ degrees\n  - modeling choice: \"microabsorption\"\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, where each element is the list of corrected fractions for one test case in the order above, with each fraction rounded to $6$ decimal places. For example, a syntactically correct output would look like $[[0.1,0.9],[0.2,0.8]]$ for two hypothetical cases. No additional text or characters are permitted in the output line.", "solution": "The problem as stated is valid. It is scientifically grounded in the principles of X-ray diffraction and quantitative phase analysis, well-posed, and contains all necessary information for a unique solution. The simplified models for microabsorption and preferred orientation are standard approximations in the field. We shall proceed with a solution derived from first principles.\n\nThe objective is to re-estimate quantitative phase analysis results, $\\{w_k^{(\\mathrm{pub})}\\}_k$, by applying corrections for microabsorption and preferred orientation that were initially neglected. The foundation of this re-estimation lies in the relationship between the true weight fraction of a phase, $w_k$, and the intensity it contributes to the diffraction pattern, $I_k$.\n\nIn a powder diffraction experiment, the intensity measured for a reflection from phase $k$, $I_k^{(\\mathrm{meas})}$, is proportional to its true weight fraction $w_k$. However, this relationship is modulated by several physical effects, including microabsorption and preferred orientation (texture). We can express this as:\n$$I_k^{(\\mathrm{meas})} \\propto w_k \\cdot T_k \\cdot P_k$$\nHere, $T_k$ is the microabsorption transmission factor and $P_k$ is the preferred orientation (texture) factor for phase $k$. The proportionality constant absorbs instrumental factors and intrinsic scattering properties of the phase, which are constant for all phases in the analysis.\n\nThe problem states that the published weight fractions, $w_k^{(\\mathrm{pub})}$, were obtained from an analysis that neglected both microabsorption and preferred orientation. This is equivalent to assuming that $T_k = 1$ and $P_k = 1$ for all phases. Under such an assumption, the measured intensity is taken to be directly proportional to the weight fraction:\n$$I_k^{(\\mathrm{meas})} \\propto w_k^{(\\mathrm{pub})}$$\n\nBy equating these two proportionalities, we establish the core relationship between the true weight fractions and the published, uncorrected ones:\n$$w_k^{(\\mathrm{pub})} \\propto w_k \\cdot T_k \\cdot P_k$$\nFrom this, we can solve for the true weight fraction, $w_k$, which we will denote as $w_k^{(\\mathrm{corr})}$ to signify the corrected value. We find that $w_k^{(\\mathrm{corr})}$ is proportional to the published fraction divided by the correction factors:\n$$w_k^{(\\mathrm{corr})} \\propto \\frac{w_k^{(\\mathrm{pub})}}{T_k \\cdot P_k}$$\nLet us define an un-normalized corrected weight fraction, $w_k'$, as:\n$$w_k' = \\frac{w_k^{(\\mathrm{pub})}}{T_k \\cdot P_k}$$\nSince the sum of all weight fractions in the sample must equal unity, we must re-normalize these values:\n$$w_k^{(\\mathrm{corr})} = \\frac{w_k'}{\\sum_j w_j'} = \\frac{w_k^{(\\mathrm{pub})} / (T_k \\cdot P_k)}{\\sum_j \\left( w_j^{(\\mathrm{pub})} / (T_j \\cdot P_j) \\right)}$$\nThis is the final equation we will implement. The values of $T_k$ and $P_k$ are determined by the `modeling_choice` flag. If a correction is not applied, the corresponding factor remains $1$.\n\nThe specific models for the correction factors are provided.\n\nFor microabsorption, the transmission factor $T_k$ for a spherical crystallite is:\n$$T_k(x_k) = \\frac{1 - e^{-x_k}}{x_k}$$\nwhere the dimensionless parameter $x_k$ is given by $x_k = 2 \\mu_k R_k^{(\\mathrm{cm})}$. The linear attenuation coefficient $\\mu_k$ (in cm$^{-1}$) is calculated from the given mass attenuation coefficient $\\mu_{m,k}$ (in cm$^2$ g$^{-1}$) and density $\\rho_k$ (in g cm$^{-3}$) as $\\mu_k = \\mu_{m,k} \\rho_k$. The crystallite radius $R_k$, given in micrometers ($\\mu$m), must be converted to centimeters (cm) using $R_k^{(\\mathrm{cm})} = R_k^{(\\mu \\mathrm{m})} \\times 10^{-4}$.\n\nFor preferred orientation, the intensity multiplier $P_k$ is modeled by the March–Dollase function:\n$$P_k(r_k, \\theta_k) = \\left(r_k^2 \\cos^2 \\theta_k + r_k^{-1} \\sin^2 \\theta_k\\right)^{-3/2}$$\nHere, $r_k$ is the March–Dollase parameter and $\\theta_k$ is an effective angle. The angle $\\theta_k$ is provided in degrees and must be converted to radians for use in trigonometric functions, via $\\theta_k^{(\\mathrm{rad})} = \\theta_k^{(\\mathrm{deg})} \\frac{\\pi}{180}$. A value of $r_k = 1$ indicates no preferred orientation, which results in $P_k=1$ for any angle $\\theta_k$.\n\nThe algorithm for each test case is as follows:\n1.  For each phase $k$ in the mixture, initialize correction factors $T_k \\leftarrow 1$ and $P_k \\leftarrow 1$.\n2.  Based on the `modeling_choice`, calculate the necessary correction factors.\n    - If `modeling_choice` is `\"microabsorption\"` or `\"both\"`, calculate each $T_k$ using the formula provided. Special care is taken for the case $x_k \\to 0$, where the limit of $T_k$ is $1$.\n    - If `modeling_choice` is `\"texture\"` or `\"both\"`, calculate each $P_k$ using the March–Dollase formula.\n3.  Compute the un-normalized corrected weight fraction $w_k'$ for each phase using $w_k' = w_k^{(\\mathrm{pub})} / (T_k \\cdot P_k)$.\n4.  Sum the un-normalized fractions: $W' = \\sum_j w_j'$.\n5.  Compute the final, normalized corrected weight fractions: $w_k^{(\\mathrm{corr})} = w_k' / W'$.\n6.  The final results are rounded to the specified precision of $6$ decimal places.\nThis procedure rigorously applies the physical correction models, derived from first principles, to re-evaluate the initial quantitative analysis.", "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the Rietveld quantitative phase analysis correction problem\n    for a given suite of test cases.\n    \"\"\"\n\n    test_cases = [\n        # Case 1 (sanity, three-phase sample S1, no corrections)\n        {\n            \"w_pub\": [0.5, 0.3, 0.2],\n            \"mu_m\": [260, 53, 48],\n            \"rho\": [5.24, 3.98, 2.65],\n            \"R\": [10, 5, 3],\n            \"r\": [0.9, 1.1, 1.0],\n            \"theta\": [30, 45, 0],\n            \"choice\": \"none\",\n        },\n        # Case 2 (same S1, microabsorption only)\n        {\n            \"w_pub\": [0.5, 0.3, 0.2],\n            \"mu_m\": [260, 53, 48],\n            \"rho\": [5.24, 3.98, 2.65],\n            \"R\": [10, 5, 3],\n            \"r\": [0.9, 1.1, 1.0],\n            \"theta\": [30, 45, 0],\n            \"choice\": \"microabsorption\",\n        },\n        # Case 3 (same S1, preferred orientation only)\n        {\n            \"w_pub\": [0.5, 0.3, 0.2],\n            \"mu_m\": [260, 53, 48],\n            \"rho\": [5.24, 3.98, 2.65],\n            \"R\": [10, 5, 3],\n            \"r\": [0.9, 1.1, 1.0],\n            \"theta\": [30, 45, 0],\n            \"choice\": \"texture\",\n        },\n        # Case 4 (same S1, both corrections)\n        {\n            \"w_pub\": [0.5, 0.3, 0.2],\n            \"mu_m\": [260, 53, 48],\n            \"rho\": [5.24, 3.98, 2.65],\n            \"R\": [10, 5, 3],\n            \"r\": [0.9, 1.1, 1.0],\n            \"theta\": [30, 45, 0],\n            \"choice\": \"both\",\n        },\n        # Case 5 (two-phase sample S2, negligible microabsorption, microabsorption only)\n        {\n            \"w_pub\": [0.6, 0.4],\n            \"mu_m\": [50, 60],\n            \"rho\": [3.0, 3.0],\n            \"R\": [1.0, 1.0],\n            \"r\": [2.0, 1.0],\n            \"theta\": [10, 0],\n            \"choice\": \"microabsorption\",\n        },\n        # Case 6 (same S2, strong texture only)\n        {\n            \"w_pub\": [0.6, 0.4],\n            \"mu_m\": [50, 60],\n            \"rho\": [3.0, 3.0],\n            \"R\": [1.0, 1.0],\n            \"r\": [2.0, 1.0],\n            \"theta\": [10, 0],\n            \"choice\": \"texture\",\n        },\n        # Case 7 (two-phase sample S3, strong microabsorption contrast, microabsorption only)\n        {\n            \"w_pub\": [0.7, 0.3],\n            \"mu_m\": [300, 30],\n            \"rho\": [7.2, 2.5],\n            \"R\": [15.0, 2.0],\n            \"r\": [1.0, 1.0],\n            \"theta\": [0, 0],\n            \"choice\": \"microabsorption\",\n        },\n    ]\n\n    results = []\n    for case in test_cases:\n        w_pub = np.array(case[\"w_pub\"])\n        mu_m = np.array(case[\"mu_m\"])\n        rho = np.array(case[\"rho\"])\n        R_micron = np.array(case[\"R\"])\n        r = np.array(case[\"r\"])\n        theta_deg = np.array(case[\"theta\"])\n        choice = case[\"choice\"]\n        \n        num_phases = len(w_pub)\n        T_factors = np.ones(num_phases)\n        P_factors = np.ones(num_phases)\n\n        if choice in [\"microabsorption\", \"both\"]:\n            mu = mu_m * rho                  # Linear attenuation coefficient in cm^-1\n            R_cm = R_micron * 1e-4           # Radius in cm\n            x = 2 * mu * R_cm\n            \n            # Avoid division by zero for x_k=0, where lim T_k = 1.\n            # Using np.where to handle vectorization properly.\n            T_factors = np.where(x == 0, 1.0, (1.0 - np.exp(-x)) / x)\n\n        if choice in [\"texture\", \"both\"]:\n            theta_rad = np.deg2rad(theta_deg)\n            cos2_theta = np.cos(theta_rad)**2\n            sin2_theta = np.sin(theta_rad)**2\n            \n            # March-Dollase term\n            term = r**2 * cos2_theta + r**(-1) * sin2_theta\n            P_factors = term**(-1.5)\n\n        # Calculate un-normalized corrected weight fractions\n        w_prime = w_pub / (T_factors * P_factors)\n        \n        # Normalize to get final corrected weight fractions\n        w_corr = w_prime / np.sum(w_prime)\n        \n        # Round and format\n        rounded_w_corr = np.round(w_corr, 6).tolist()\n        results.append(rounded_w_corr)\n\n    # Print in the exact required format\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "2517872"}]}