{"hands_on_practices": [{"introduction": "Before trusting the results of a complex analytic gradient calculation, it is essential to have a method for verification. This practice explores the workhorse of numerical validation: the finite-difference method. By analyzing the interplay between truncation and round-off errors, you will derive the optimal step size for approximating forces, gaining critical insight into the inherent limitations of numerical differentiation. [@problem_id:2874113]", "problem": "In Born–Oppenheimer quantum chemistry, the molecular force component along a single internal coordinate $R$ is $F(R)=-\\frac{dE(R)}{dR}$, where $E(R)$ is the electronic energy at fixed nuclear coordinates. Suppose $E(R)$ is sufficiently smooth and you approximate the derivative $\\frac{dE(R)}{dR}$ by the central finite-difference estimator\n$$\nG_{h}(R)\\;=\\;\\frac{E(R+h)\\;-\\;E(R-h)}{2h}.\n$$\nAssume two independent sources of error:\n- Truncation error arises from the Taylor-series remainder and scales with $h$ as $\\mathcal{O}(h^2)$.\n- Numerical noise arises because each computed energy evaluation $E(R\\pm h)$ is contaminated by an additive error due to floating-point roundoff and incomplete Self-Consistent Field (SCF) convergence. Model this by assuming the computed energies are $\\tilde{E}(R\\pm h)=E(R\\pm h)+\\delta_{\\pm}$ with $|\\delta_{\\pm}|\\le \\sigma_{E}$, where $\\sigma_{E}$ is a known bound on the absolute energy error that aggregates machine roundoff and SCF residual.\n\nStarting only from the Taylor expansion for $E(R\\pm h)$ about $R$ with an integral-form remainder and the above noise model, derive the leading-order expression for the magnitude of the total error in $G_{h}(R)$ as a function of $h$, $E^{(3)}(R)$, and $\\sigma_{E}$. Then determine the step size $h$ that minimizes this leading-order error. Express your final answer as a single closed-form analytic expression for the optimal step size $h_{\\text{opt}}$ in terms of $\\sigma_{E}$ and $E^{(3)}(R)$. Do not substitute numerical values and do not include units in your final expression.", "solution": "The problem requires the derivation of an optimal step size, $h_{\\text{opt}}$, for a central finite-difference approximation of an energy derivative. The derivation must account for two competing sources of error: the truncation error inherent in the finite-difference formula and the numerical noise from the energy evaluation. The total error must first be expressed as a function of the step size $h$, and then this function must be minimized to find the optimal $h$.\n\nThe quantity to be approximated is the first derivative of the energy, $E'(R) = \\frac{dE(R)}{dR}$. The central finite-difference estimator for this quantity is given by $D_h(R) = \\frac{E(R+h) - E(R-h)}{2h}$. Note that the force is $F(R) = -E'(R)$, so we are computing an approximation to $-F(R)$. The total error in our computation of the derivative is the difference between the computed value, which includes numerical noise, and the true value of the derivative.\n\nLet us first determine the truncation error, $\\epsilon_{\\text{trunc}}$. This error is the difference between the finite-difference approximation using exact energies and the true derivative: $\\epsilon_{\\text{trunc}}(h) = D_h(R) - E'(R)$. We are instructed to use the Taylor series expansion with the integral form of the remainder. For a sufficiently smooth function $E(R)$, the expansions for $E(R+h)$ and $E(R-h)$ about $R$ up to the second-order term are:\n$$\nE(R+h) = E(R) + E'(R)h + \\frac{E''(R)}{2!}h^2 + \\frac{1}{2!} \\int_R^{R+h} (R+h-t)^2 E^{(3)}(t) dt\n$$\n$$\nE(R-h) = E(R) - E'(R)h + \\frac{E''(R)}{2!}h^2 + \\frac{1}{2!} \\int_R^{R-h} (R-h-t)^2 E^{(3)}(t) dt\n$$\nSubtracting the second equation from the first gives:\n$$\nE(R+h) - E(R-h) = 2E'(R)h + \\frac{1}{2} \\left( \\int_R^{R+h} (R+h-t)^2 E^{(3)}(t) dt - \\int_R^{R-h} (R-h-t)^2 E^{(3)}(t) dt \\right)\n$$\nDividing by $2h$ to form the finite-difference expression $D_h(R)$:\n$$\nD_h(R) = E'(R) + \\frac{1}{4h} \\left( \\int_R^{R+h} (R+h-t)^2 E^{(3)}(t) dt - \\int_R^{R-h} (R-h-t)^2 E^{(3)}(t) dt \\right)\n$$\nThe truncation error is therefore:\n$$\n\\epsilon_{\\text{trunc}}(h) = \\frac{1}{4h} \\left( \\int_R^{R+h} (R+h-t)^2 E^{(3)}(t) dt - \\int_R^{R-h} (R-h-t)^2 E^{(3)}(t) dt \\right)\n$$\nTo find the leading-order behavior, we assume $h$ is small. For $t$ in the integration intervals $[R-h, R+h]$, we can approximate the third derivative $E^{(3)}(t)$ by its value at the center of the interval, $E^{(3)}(R)$, as $E^{(3)}(t) \\approx E^{(3)}(R)$. This is justified because the function $E(R)$ is assumed to be smooth.\n$$\n\\epsilon_{\\text{trunc}}(h) \\approx \\frac{E^{(3)}(R)}{4h} \\left( \\int_R^{R+h} (R+h-t)^2 dt - \\int_R^{R-h} (R-h-t)^2 dt \\right)\n$$\nThe integrals evaluate to:\n$$\n\\int_R^{R+h} (R+h-t)^2 dt = \\left[ -\\frac{(R+h-t)^3}{3} \\right]_R^{R+h} = 0 - \\left(-\\frac{h^3}{3}\\right) = \\frac{h^3}{3}\n$$\n$$\n\\int_R^{R-h} (R-h-t)^2 dt = \\left[ -\\frac{(R-h-t)^3}{3} \\right]_R^{R-h} = 0 - \\left(-\\frac{(-h)^3}{3}\\right) = -\\frac{h^3}{3}\n$$\nSubstituting these back into the expression for $\\epsilon_{\\text{trunc}}(h)$:\n$$\n\\epsilon_{\\text{trunc}}(h) \\approx \\frac{E^{(3)}(R)}{4h} \\left( \\frac{h^3}{3} - \\left(-\\frac{h^3}{3}\\right) \\right) = \\frac{E^{(3)}(R)}{4h} \\left( \\frac{2h^3}{3} \\right) = \\frac{E^{(3)}(R)}{6}h^2\n$$\nThe magnitude of the leading-order truncation error is $|\\epsilon_{\\text{trunc}}(h)| \\approx \\frac{|E^{(3)}(R)|}{6}h^2$.\n\nNext, we analyze the error from numerical noise. The computed gradient estimator $\\tilde{G}_h(R)$ uses energies contaminated with errors $\\delta_{\\pm}$:\n$$\n\\tilde{G}_h(R) = \\frac{\\tilde{E}(R+h) - \\tilde{E}(R-h)}{2h} = \\frac{(E(R+h) + \\delta_+) - (E(R-h) + \\delta_-)}{2h}\n$$\n$$\n\\tilde{G}_h(R) = \\frac{E(R+h) - E(R-h)}{2h} + \\frac{\\delta_+ - \\delta_-}{2h} = D_h(R) + \\epsilon_{\\text{noise}}(h)\n$$\nThe error due to numerical noise is $\\epsilon_{\\text{noise}}(h) = \\frac{\\delta_+ - \\delta_-}{2h}$. We are given an upper bound on the magnitude of the individual energy errors: $|\\delta_{\\pm}| \\le \\sigma_E$. We seek a bound for the magnitude of the noise error $|\\epsilon_{\\text{noise}}(h)|$:\n$$\n|\\epsilon_{\\text{noise}}(h)| = \\left| \\frac{\\delta_+ - \\delta_-}{2h} \\right| = \\frac{|\\delta_+ - \\delta_-|}{2h}\n$$\nUsing the triangle inequality, $|\\delta_+ - \\delta_-| \\le |\\delta_+| + |-\\delta_-| = |\\delta_+| + |\\delta_-|$. The worst-case scenario occurs when the errors have opposite signs and maximum magnitude:\n$$\n|\\epsilon_{\\text{noise}}(h)| \\le \\frac{|\\delta_+| + |\\delta_-|}{2h} \\le \\frac{\\sigma_E + \\sigma_E}{2h} = \\frac{2\\sigma_E}{2h} = \\frac{\\sigma_E}{h}\n$$\nThe total error in the computed gradient is $\\epsilon_{\\text{total}} = \\tilde{G}_h(R) - E'(R) = \\epsilon_{\\text{trunc}}(h) + \\epsilon_{\\text{noise}}(h)$. The magnitude of the total error is bounded by the sum of the magnitudes of the individual error contributions (again, by the triangle inequality):\n$$\n|\\epsilon_{\\text{total}}(h)| \\le |\\epsilon_{\\text{trunc}}(h)| + |\\epsilon_{\\text{noise}}(h)|\n$$\nWe define the total error function $\\mathcal{E}(h)$ using the leading-order truncation error and the worst-case noise error:\n$$\n\\mathcal{E}(h) = \\frac{|E^{(3)}(R)|}{6}h^2 + \\frac{\\sigma_E}{h}\n$$\nTo find the step size $h$ that minimizes this total error, we differentiate $\\mathcal{E}(h)$ with respect to $h$ and set the result to zero:\n$$\n\\frac{d\\mathcal{E}(h)}{dh} = \\frac{d}{dh} \\left( \\frac{|E^{(3)}(R)|}{6}h^2 + \\sigma_E h^{-1} \\right) = 2 \\frac{|E^{(3)}(R)|}{6}h - \\sigma_E h^{-2} = \\frac{|E^{(3)}(R)|}{3}h - \\frac{\\sigma_E}{h^2}\n$$\nSetting the derivative to zero to find the optimal step size, $h_{\\text{opt}}$:\n$$\n\\frac{|E^{(3)}(R)|}{3}h_{\\text{opt}} - \\frac{\\sigma_E}{h_{\\text{opt}}^2} = 0\n$$\n$$\n\\frac{|E^{(3)}(R)|}{3}h_{\\text{opt}} = \\frac{\\sigma_E}{h_{\\text{opt}}^2}\n$$\n$$\nh_{\\text{opt}}^3 = \\frac{3\\sigma_E}{|E^{(3)}(R)|}\n$$\nSolving for $h_{\\text{opt}}$ yields:\n$$\nh_{\\text{opt}} = \\left( \\frac{3\\sigma_E}{|E^{(3)}(R)|} \\right)^{\\frac{1}{3}}\n$$\nThe second derivative, $\\frac{d^2\\mathcal{E}}{dh^2} = \\frac{|E^{(3)}(R)|}{3} + \\frac{2\\sigma_E}{h^3}$, is positive for positive $h$, $\\sigma_E$, and non-zero $E^{(3)}(R)$, confirming that this value of $h$ corresponds to a minimum of the error function. The use of the absolute value $|E^{(3)}(R)|$ is necessary to ensure the step size $h_{\\text{opt}}$ is a real and positive quantity.", "answer": "$$\n\\boxed{\\left( \\frac{3\\sigma_{E}}{|E^{(3)}(R)|} \\right)^{\\frac{1}{3}}}\n$$", "id": "2874113"}, {"introduction": "Analytic gradients offer precision and efficiency but rely on solving complex underlying equations, like the Coupled-Perturbed Hartree-Fock (CPHF) equations. This exercise takes you inside this process to understand how numerical inaccuracies propagate. You will derive a rigorous bound on the gradient error based on the residual from the CPHF solver, linking the quality of the linear algebra solution directly to the accuracy of the final molecular force. [@problem_id:2874050]", "problem": "Consider a restricted Hartree–Fock (RHF) reference for a closed-shell molecule and a single nuclear displacement parameter $q$. The energy gradient along $q$ can be formulated via a Lagrangian approach in analytic derivative theory, in which the stationary conditions enforce that the response of the molecular orbitals to the perturbation $q$ satisfies a linear system known as the Coupled-Perturbed Hartree–Fock (CPHF) equations. Let the response amplitudes be collected in a vector $x \\in \\mathbb{R}^{n}$ that solves the linear system $A x = b$, where $A \\in \\mathbb{R}^{n \\times n}$ is the RHF orbital Hessian restricted to occupied–virtual rotations and $b \\in \\mathbb{R}^{n}$ is the corresponding right-hand side determined by the derivative of the Fock operator with respect to $q$. Assume $A$ is symmetric positive definite and its spectrum is bounded below by a positive constant, i.e., $\\lambda_{\\min}(A) \\ge \\alpha$ with $\\alpha > 0$. The analytic energy gradient along $q$ can be written as a sum of a term $c \\in \\mathbb{R}$ independent of $x$ and a linear functional of $x$, namely $G = c + d^{\\mathsf{T}} x$, where $d \\in \\mathbb{R}^{n}$ depends on the unperturbed RHF solution and on $q$. Suppose the CPHF equations are solved iteratively and produce an approximate solution $\\tilde{x}$ with residual $r := b - A \\tilde{x}$. Let $\\|\\cdot\\|_{2}$ denote the Euclidean norm for vectors and the induced operator norm for matrices. You are given bounds $\\|d\\|_{2} \\le \\gamma$ with $\\gamma > 0$ and $\\lambda_{\\min}(A) \\ge \\alpha$ with $\\alpha > 0$, and you define $\\rho := \\|r\\|_{2}$. The approximate gradient is $\\tilde{G} := c + d^{\\mathsf{T}} \\tilde{x}$. Using only fundamental properties of the RHF Lagrangian stationarity, linear response, and basic norm inequalities, derive how the residual $r$ propagates into the energy gradient error $\\Delta G := G - \\tilde{G}$ and obtain the tightest upper bound expressible in terms of $\\alpha$, $\\gamma$, and $\\rho$ for the magnitude $|\\Delta G|$. Provide your final result as a single analytic expression $B(\\alpha,\\gamma,\\rho)$ such that $|\\Delta G|$ is bounded above by $B(\\alpha,\\gamma,\\rho)$. Do not include units and do not approximate numerically.", "solution": "The problem as stated is scientifically sound and mathematically well-posed. We shall proceed with its formal derivation.\n\nThe exact analytic energy gradient along the nuclear displacement coordinate $q$ is given by\n$$\nG = c + d^{\\mathsf{T}} x\n$$\nwhere $c \\in \\mathbb{R}$ is a constant term, $d \\in \\mathbb{R}^{n}$ is a vector of coefficients, and the vector $x \\in \\mathbb{R}^{n}$ contains the exact molecular orbital response amplitudes. This response vector $x$ is the solution to the Coupled-Perturbed Hartree–Fock (CPHF) linear system:\n$$\nA x = b\n$$\nHere, $A \\in \\mathbb{R}^{n \\times n}$ is the symmetric positive definite (SPD) orbital Hessian matrix, and $b \\in \\mathbb{R}^{n}$ is the right-hand side vector determined by the perturbation.\n\nAn iterative solver produces an approximate solution $\\tilde{x}$, which does not exactly satisfy the CPHF equations. The corresponding approximate gradient is:\n$$\n\\tilde{G} = c + d^{\\mathsf{T}} \\tilde{x}\n$$\nThe error in the computed gradient is the difference between the exact and approximate gradients:\n$$\n\\Delta G = G - \\tilde{G} = (c + d^{\\mathsf{T}} x) - (c + d^{\\mathsf{T}} \\tilde{x}) = d^{\\mathsf{T}}(x - \\tilde{x})\n$$\nLet us denote the error in the solution vector as $\\Delta x = x - \\tilde{x}$. Then, the gradient error is $\\Delta G = d^{\\mathsf{T}} \\Delta x$.\n\nThe residual vector $r$ associated with the approximate solution $\\tilde{x}$ is defined as:\n$$\nr = b - A \\tilde{x}\n$$\nWe can relate the solution error $\\Delta x$ to the residual $r$. Since $Ax = b$, we can substitute this into the definition of the residual:\n$$\nr = Ax - A \\tilde{x} = A(x - \\tilde{x}) = A \\Delta x\n$$\nSince the matrix $A$ is given as symmetric positive definite, it is invertible. Therefore, we can express the solution error $\\Delta x$ in terms of the residual $r$ and the inverse of the Hessian, $A^{-1}$:\n$$\n\\Delta x = A^{-1} r\n$$\nSubstituting this expression for $\\Delta x$ back into the formula for the gradient error $\\Delta G$, we obtain:\n$$\n\\Delta G = d^{\\mathsf{T}} (A^{-1} r)\n$$\nWe are tasked with finding the tightest upper bound on the magnitude of this error, $|\\Delta G|$. We begin by applying the Cauchy-Schwarz inequality to the inner product $d^{\\mathsf{T}} (A^{-1} r)$:\n$$\n|\\Delta G| = |d^{\\mathsf{T}} (A^{-1} r)| \\le \\|d\\|_{2} \\|A^{-1} r\\|_{2}\n$$\nwhere $\\|\\cdot\\|_{2}$ denotes the Euclidean vector norm.\n\nNext, we apply the property of the induced matrix norm (also known as the operator $2$-norm) to the term $\\|A^{-1} r\\|_{2}$:\n$$\n\\|A^{-1} r\\|_{2} \\le \\|A^{-1}\\|_{2} \\|r\\|_{2}\n$$\nCombining these inequalities, we have:\n$$\n|\\Delta G| \\le \\|d\\|_{2} \\|A^{-1}\\|_{2} \\|r\\|_{2}\n$$\nThe problem provides the following bounds: $\\|d\\|_{2} \\le \\gamma$ and $\\|r\\|_{2} = \\rho$. Substituting these into our inequality yields:\n$$\n|\\Delta G| \\le \\gamma \\cdot \\|A^{-1}\\|_{2} \\cdot \\rho\n$$\nThe final step is to find an upper bound for $\\|A^{-1}\\|_{2}$. For a symmetric matrix such as $A$, the induced $2$-norm is equal to its spectral radius, which is the maximum absolute value of its eigenvalues. Let the eigenvalues of $A$ be denoted by $\\lambda_i(A)$.\n$$\n\\|A\\|_{2} = \\max_{i} |\\lambda_i(A)|\n$$\nThe matrix $A^{-1}$ is also symmetric, and its eigenvalues are the reciprocals of the eigenvalues of $A$, i.e., $1/\\lambda_i(A)$. Therefore, the norm of $A^{-1}$ is:\n$$\n\\|A^{-1}\\|_{2} = \\max_{i} \\left|\\frac{1}{\\lambda_i(A)}\\right|\n$$\nSince $A$ is positive definite, all its eigenvalues $\\lambda_i(A)$ are positive. Thus, the absolute value is redundant. The maximum of the reciprocals is equal to the reciprocal of the minimum:\n$$\n\\|A^{-1}\\|_{2} = \\frac{1}{\\min_{i} \\lambda_i(A)} = \\frac{1}{\\lambda_{\\min}(A)}\n$$\nWe are given that the spectrum of $A$ is bounded below by a positive constant $\\alpha$, i.e., $\\lambda_{\\min}(A) \\ge \\alpha > 0$. This implies:\n$$\n\\frac{1}{\\lambda_{\\min}(A)} \\le \\frac{1}{\\alpha}\n$$\nTherefore, we have an upper bound for the norm of the inverse Hessian:\n$$\n\\|A^{-1}\\|_{2} \\le \\frac{1}{\\alpha}\n$$\nSubstituting this final piece into our inequality for $|\\Delta G|$, we arrive at the desired bound:\n$$\n|\\Delta G| \\le \\gamma \\left(\\frac{1}{\\alpha}\\right) \\rho = \\frac{\\gamma \\rho}{\\alpha}\n$$\nThis bound is tight. To demonstrate this, consider a worst-case scenario where all inequalities become equalities. This occurs if:\n$1$. The norms of $d$ and $r$ take their maximum allowed values, i.e., $\\|d\\|_{2} = \\gamma$ and $\\|r\\|_{2} = \\rho$.\n$2$. The smallest eigenvalue of $A$ is exactly $\\alpha$, i.e., $\\lambda_{\\min}(A) = \\alpha$.\n$3$. The vectors $d$ and $r$ are both aligned with the eigenvector $\\phi_{\\min}$ corresponding to the eigenvalue $\\lambda_{\\min}(A) = \\alpha$. Specifically, let $d = \\gamma \\phi_{\\min}$ and $r = \\rho \\phi_{\\min}$.\n$4$. The vector $A^{-1}r$ is aligned with $d$, which is met by the condition in point $3$.\n\nIn such a case, $A^{-1}r = A^{-1}(\\rho \\phi_{\\min}) = \\rho (A^{-1}\\phi_{\\min}) = \\rho (\\frac{1}{\\alpha}\\phi_{\\min})$. The gradient error is then\n$$\n\\Delta G = d^{\\mathsf{T}}(A^{-1}r) = (\\gamma \\phi_{\\min})^{\\mathsf{T}} \\left(\\frac{\\rho}{\\alpha}\\phi_{\\min}\\right) = \\frac{\\gamma \\rho}{\\alpha} (\\phi_{\\min}^{\\mathsf{T}}\\phi_{\\min}) = \\frac{\\gamma \\rho}{\\alpha}\n$$\nas $\\|\\phi_{\\min}\\|_{2}=1$. Since we have constructed a valid case where the error magnitude $|\\Delta G|$ is exactly equal to $\\frac{\\gamma \\rho}{\\alpha}$, this expression represents the tightest possible upper bound.\nThe bound $B(\\alpha, \\gamma, \\rho)$ is therefore established.", "answer": "$$\n\\boxed{\\frac{\\gamma \\rho}{\\alpha}}\n$$", "id": "2874050"}, {"introduction": "At the very foundation of analytic derivative theory lie the derivatives of electron repulsion integrals (ERIs), which in turn depend on the Boys function $F_n(T)$. This exercise delves into the heart of integral evaluation, revealing the elegant relationship between $\\frac{\\mathrm{d}F_{n}}{\\mathrm{d}T}$ and $F_{n+1}(T)$. More importantly, it challenges you to confront the critical issue of numerical stability in the recurrence relations used to compute them, a crucial consideration for building robust quantum chemistry software. [@problem_id:2874088]", "problem": "Consider primitive Gaussian-type orbitals with exponents $\\alpha$ and $\\beta$ centered at nuclei located at $\\mathbf{A}$ and $\\mathbf{B}$, respectively. By the Gaussian product theorem, the product of two Gaussians centered at $\\mathbf{A}$ and $\\mathbf{B}$ can be written as a Gaussian centered at the composite center $\\mathbf{P}$ with exponent $\\zeta = \\alpha + \\beta$, multiplied by a Gaussian prefactor depending on $\\mathbf{A}$ and $\\mathbf{B}$. In the standard derivation of analytic expressions for the electron repulsion integral (ERI) over Gaussians, one encounters one-dimensional radial integrals of the form that define the Boys function,\n$$\nF_{n}(T) \\equiv \\int_{0}^{1} t^{2n} \\exp\\!\\big(-T t^{2}\\big)\\,\\mathrm{d}t,\n$$\nwhere $n \\in \\mathbb{N}_{0}$ and $T \\ge 0$ is a scalar that depends on Gaussian exponents and intercenter distances, e.g., $T = \\rho|\\mathbf{P}-\\mathbf{Q}|^2$ with $\\rho = \\frac{\\alpha \\beta}{\\alpha + \\beta}$ and $\\mathbf{P}, \\mathbf{Q}$ composite centers arising from the Gaussian product theorem on electron $1$ and electron $2$ coordinates, respectively.\n\nIn analytic energy gradients and Hessians, derivatives of ERIs with respect to nuclear Cartesian coordinates appear. Through the chain rule, differentiation of ERIs introduces derivatives of $F_{n}(T)$ with respect to $T$, multiplied by derivatives of $T$ with respect to nuclear coordinates. Working from the fundamental definition of $F_{n}(T)$ above and standard properties of Gaussian integrals, do the following:\n\n- Explain why derivatives of the ERI with respect to nuclear coordinates necessarily contain factors of $\\frac{\\mathrm{d}F_{n}}{\\mathrm{d}T}$ multiplied by derivatives of $T$.\n- Starting strictly from the defining integral for $F_{n}(T)$, derive a closed-form expression for $\\frac{\\mathrm{d}F_{n}}{\\mathrm{d}T}$ in terms of Boys functions.\n- Analyze the numerical stability of direct differentiation identities for $\\frac{\\mathrm{d}F_{n}}{\\mathrm{d}T}$ across the regimes of small $T$ (i.e., $T \\to 0$) and large $T$ (i.e., $T \\to \\infty$), identifying any potential loss of significance.\n- Construct a stable computational scheme for $\\frac{\\mathrm{d}F_{n}}{\\mathrm{d}T}$ that avoids catastrophic cancellation at small $T$ and retains accuracy at large $T$. Your scheme should rely only on well-tested expansions and recurrences derivable from the integral definition, namely:\n  - the Maclaurin series of $F_{n}(T)$ for small $T$,\n  - the large-$T$ asymptotic form of $F_{n}(T)$,\n  - and a directionally stable three-term recurrence connecting $F_{n+1}(T)$ and $F_{n}(T)$.\nExplain which direction of the recurrence is stable and why, and how to combine initialization and recurrence to cover all $T$.\n\nProvide, as your final answer, the single closed-form analytic expression you have derived for $\\frac{\\mathrm{d}F_{n}}{\\mathrm{d}T}$ in terms of Boys functions. No numerical evaluation is required, and no units are needed because $F_{n}(T)$ is dimensionless. Express your final answer as a single analytic expression.", "solution": "The problem posed is a standard, well-defined exercise in the analytic theory of molecular integrals in quantum chemistry. It is scientifically grounded, objective, and contains sufficient information for a rigorous analysis. We shall proceed with the derivation and discussion as requested.\n\nFirst, we address why derivatives of the electron repulsion integral (ERI) with respect to nuclear coordinates must involve derivatives of the Boys function, $F_n(T)$. An ERI over four Gaussian basis functions is written as $(\\mu\\nu|\\lambda\\sigma)$. By the Gaussian product theorem, the product of two Gaussians, e.g., $\\phi_{\\mu}$ and $\\phi_{\\nu}$, can be expressed as a single Gaussian centered at a new point $\\mathbf{P}$. The ERI then reduces to a two-electron integral over two new charge distributions centered at $\\mathbf{P}$ and $\\mathbf{Q}$. This integral is ultimately expressed as a finite sum of terms, where each term is a product of some constants and a Boys function $F_n(T)$. The argument $T$ is given by $T = \\rho |\\mathbf{P}-\\mathbf{Q}|^2$, where $\\rho$ is a function of the Gaussian exponents, and the centers $\\mathbf{P}$ and $\\mathbf{Q}$ are functions of the original nuclear coordinates $\\{\\mathbf{R}_A\\}$.\nTherefore, any ERI can be schematically written as a function of the nuclear coordinates $\\mathbf{R}_A$ through its dependence on the arguments $T_k$:\n$$\n\\text{ERI}(\\{\\mathbf{R}_A\\}) = \\sum_k C_k F_{n_k}(T_k(\\{\\mathbf{R}_A\\}))\n$$\nwhere $C_k$ are coefficients that also depend on nuclear coordinates. When differentiating with respect to a Cartesian component of a nuclear position, say $R_{A,x}$, the chain rule must be applied:\n$$\n\\frac{\\partial (\\text{ERI})}{\\partial R_{A,x}} = \\sum_k \\left( \\frac{\\partial C_k}{\\partial R_{A,x}} F_{n_k}(T_k) + C_k \\frac{\\mathrm{d}F_{n_k}}{\\mathrm{d}T_k} \\frac{\\partial T_k}{\\partial R_{A,x}} \\right)\n$$\nThe centers $\\mathbf{P}$ and $\\mathbf{Q}$ are weighted averages of nuclear coordinates, so their positions, and thus their separation $|\\mathbf{P}-\\mathbf{Q}|$, depend on $\\{\\mathbf{R}_A\\}$. Consequently, the term $\\frac{\\partial T_k}{\\partial R_{A,x}}$ is, in general, non-zero. This makes the appearance of the derivative $\\frac{\\mathrm{d}F_{n_k}}{\\mathrm{d}T_k}$ an unavoidable consequence of analytic gradient theory.\n\nNext, we derive a closed-form expression for $\\frac{\\mathrm{d}F_{n}}{\\mathrm{d}T}$. We begin with the integral definition of the Boys function:\n$$\nF_{n}(T) = \\int_{0}^{1} t^{2n} \\exp(-T t^{2})\\,\\mathrm{d}t\n$$\nThe integrand and its partial derivative with respect to $T$ are continuous functions of both $t$ and $T$ over the domain of integration and for $T \\ge 0$. Therefore, we can differentiate under the integral sign (Leibniz integral rule):\n$$\n\\frac{\\mathrm{d}F_{n}}{\\mathrm{d}T} = \\frac{\\mathrm{d}}{\\mathrm{d}T} \\int_{0}^{1} t^{2n} \\exp(-T t^{2})\\,\\mathrm{d}t = \\int_{0}^{1} \\frac{\\partial}{\\partial T} \\left( t^{2n} \\exp(-T t^{2}) \\right) \\,\\mathrm{d}t\n$$\nThe partial derivative of the integrand is:\n$$\n\\frac{\\partial}{\\partial T} \\left( t^{2n} \\exp(-T t^{2}) \\right) = t^{2n} \\left( -t^2 \\exp(-T t^{2}) \\right) = -t^{2n+2} \\exp(-T t^{2})\n$$\nSubstituting this back into the integral gives:\n$$\n\\frac{\\mathrm{d}F_{n}}{\\mathrm{d}T} = \\int_{0}^{1} (-1) t^{2(n+1)} \\exp(-T t^{2}) \\,\\mathrm{d}t = - \\int_{0}^{1} t^{2(n+1)} \\exp(-T t^{2}) \\,\\mathrm{d}t\n$$\nBy inspection, the resulting integral is the definition of $F_{n+1}(T)$. Therefore, we arrive at the compact and fundamental relationship:\n$$\n\\frac{\\mathrm{d}F_{n}}{\\mathrm{d}T} = -F_{n+1}(T)\n$$\n\nWe now analyze the numerical stability of using this identity. The identity itself is exact. Any numerical instability arises from the method used to evaluate $F_{n+1}(T)$. A common but flawed approach would be to use the upward recurrence relation for the Boys function, which can be derived through integration by parts:\n$$\nF_{n+1}(T) = \\frac{(2n+1)F_n(T) - \\exp(-T)}{2T}\n$$\nIf one has an accurate value for $F_n(T)$ and uses this formula to compute $F_{n+1}(T)$, severe loss of significance can occur, particularly for large values of $T$. In this regime, $\\exp(-T)$ is exceedingly small, and $F_n(T)$ also becomes small. The numerator involves the subtraction of two numbers, $(2n+1)F_n(T)$ and $\\exp(-T)$, which can be of similar magnitude, leading to catastrophic cancellation. The subsequent division by $2T$ further propagates any error. Thus, upward recursion is numerically unstable and must be avoided for computing the sequence of Boys functions. The \"direct differentiation identity\" is unstable only if coupled with an unstable evaluation method for $F_{n+1}(T)$.\n\nFinally, we construct a stable computational scheme for $\\frac{\\mathrm{d}F_{n}}{\\mathrm{d}T}$, which amounts to a stable scheme for computing $F_{n+1}(T)$. The strategy is partitioned based on the value of $T$.\n\nFor small $T$:\nThe Maclaurin series expansion of $F_n(T)$ is obtained by expanding the exponential term in its defining integral:\n$$\nF_n(T) = \\int_{0}^{1} t^{2n} \\sum_{k=0}^{\\infty} \\frac{(-Tt^2)^k}{k!} \\,\\mathrm{d}t = \\sum_{k=0}^{\\infty} \\frac{(-T)^k}{k!} \\int_{0}^{1} t^{2n+2k} \\,\\mathrm{d}t = \\sum_{k=0}^{\\infty} \\frac{(-T)^k}{k! (2n+2k+1)}\n$$\nFor small $T$, this is an alternating series with rapidly decreasing terms, which is numerically stable and converges quickly. To compute $\\frac{\\mathrm{d}F_n}{\\mathrm{d}T} = -F_{n+1}(T)$, one simply computes $F_{n+1}(T)$ using its own Maclaurin series:\n$$\nF_{n+1}(T) = \\sum_{k=0}^{\\infty} \\frac{(-T)^k}{k! (2n+2k+3)}\n$$\nThis approach is robust for $T$ below some threshold, e.g., $T < 10$.\n\nFor large $T$:\nThe series expansion becomes unsuitable. Instead, we use the downward recurrence relation, which is the stable direction. By rearranging the recurrence previously shown, we get:\n$$\nF_{n}(T) = \\frac{2T F_{n+1}(T) + \\exp(-T)}{2n+1}\n$$\nThis relation is stable for decreasing $n$ because division by the factor $2n+1$ suppresses any propagated error. To compute a set of Boys functions $\\{ F_k(T) \\}_{k=0}^{N_{max}}$, one starts from an index $M > N_{max}$ large enough such that $F_M(T)$ can be accurately approximated. The asymptotic form for large $T$ is $F_M(T) \\sim \\frac{(2M-1)!!\\sqrt{\\pi}}{2^{M+1}} T^{-M-1/2}$. For sufficiently large $M$, one can simply set $F_M(T) = 0$ as the starting guess.\nThe stable computational procedure is:\n1. Choose a starting index $M$ well above the highest required index $n+1$. A typical choice is $M \\approx n_{max} + T$.\n2. Initialize with $F_M(T) = 0$.\n3. Recurse downwards from $k=M$ to $k=1$ using the relation $F_{k-1}(T) = \\frac{2TF_k(T) + \\exp(-T)}{2k-1}$ to generate an un-normalized sequence $\\{F'_{k}(T)\\}$.\n4. Compute the value of $F_0(T)$ accurately. For non-zero $T$, this is given by $F_0(T) = \\frac{\\sqrt{\\pi}}{2\\sqrt{T}}\\text{erf}(\\sqrt{T})$, which itself can be computed using stable methods like continued fraction expansions for large $T$.\n5. The un-normalized value $F'_0(T)$ from the downward recurrence is proportional to the true value $F_0(T)$. The normalization constant is $C = F'_0(T) / F_0(T)$.\n6. Rescale the entire sequence: $F_k(T) = F'_k(T) / C$ for all required $k$, including $k=n+1$.\n7. The required derivative is then given by $-F_{n+1}(T)$, computed via this stable procedure.\n\nThis hybrid scheme, combining the Maclaurin series for small $T$ and a normalized downward recurrence for large $T$, provides a numerically robust method for evaluating Boys functions and, by extension, their derivatives with respect to $T$ across the entire domain $T \\ge 0$.", "answer": "$$\n\\boxed{-F_{n+1}(T)}\n$$", "id": "2874088"}]}