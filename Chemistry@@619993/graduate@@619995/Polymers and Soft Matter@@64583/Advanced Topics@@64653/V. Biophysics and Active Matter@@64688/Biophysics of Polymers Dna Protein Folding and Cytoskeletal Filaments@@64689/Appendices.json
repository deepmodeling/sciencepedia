{"hands_on_practices": [{"introduction": "A cornerstone of polymer biophysics is understanding how the physical properties of molecules like DNA are governed by their environment. The stiffness of a polyelectrolyte, quantified by its persistence length $\\ell_p$, is a classic example where electrostatic interactions play a crucial role. This practice challenges you to connect a foundational theoretical model for the salt-dependence of $\\ell_p$ to experimental data, honing your skills in computational data fitting and the physical interpretation of model parameters [@problem_id:2907118].", "problem": "A semiflexible polyelectrolyte such as double-stranded deoxyribonucleic acid (DNA) can be modeled as a worm-like chain with a persistence length that has a short-range (mechanical) part and a long-range (electrostatic) part arising from screened Coulomb interactions. Starting from the following fundamental base: (i) the worm-like chain definition of persistence length as the ratio of bending modulus to thermal energy, (ii) linearized Debye–Hückel theory for electrolytes, where the Debye screening parameter scales as $\\kappa \\propto I^{1/2}$ with ionic strength $I$, and (iii) the Odijk–Skolnick–Fixman argument that the electrostatic contribution to the bending modulus is proportional to $\\kappa^{-2}$ for a uniformly charged cylinder, deduce a minimal two-parameter model for the total persistence length as a function of ionic strength that is consistent with these scalings and with the requirement that the total persistence length approaches a finite constant at high ionic strength. Implement a program that, given measurements of ionic strength and persistence length, fits this two-parameter model by ordinary least squares and returns the best-fit parameters and their interpretation.\n\nYour program must:\n- Derive and fit the unique linear-in-parameters model implied by the above constraints, using a design variable constructed from $I$ that enforces the inverse scaling of the electrostatic term with ionic strength.\n- Use ordinary least squares to estimate the two parameters from data $\\{(I_i,\\ell_{p,i})\\}$ by minimizing the sum of squared residuals. The algorithmic requirement is to solve the linear normal equations in matrix form.\n- Interpret the fitted parameters: identify which parameter is the high-ionic-strength asymptote of the persistence length (in nanometers) and which parameter quantifies the electrostatic strength factor multiplying the inverse ionic strength (in nanometer–molar).\n\nPhysical units and output specification:\n- Ionic strength $I$ must be treated in $\\mathrm{mol\\cdot L^{-1}}$.\n- Persistence length $\\ell_p$ must be treated in $\\mathrm{nm}$.\n- The two output parameters must be reported as $\\ell_p^0$ in $\\mathrm{nm}$ and $a$ in $\\mathrm{nm\\cdot M}$.\n- Round each reported parameter to exactly three decimal places.\n\nTest suite:\n- Case A (balanced low-to-high salt):\n  - $I$ in $\\mathrm{M}$: $[0.001,\\,0.003,\\,0.01,\\,0.03,\\,0.1]$.\n  - $\\ell_p$ in $\\mathrm{nm}$: $[95.3,\\,61.4666667,\\,50.1,\\,46.5666667,\\,45.5]$.\n- Case B (high salt, weak variation):\n  - $I$ in $\\mathrm{M}$: $[0.2,\\,0.3,\\,0.5,\\,1.0]$.\n  - $\\ell_p$ in $\\mathrm{nm}$: $[45.3,\\,45.1466667,\\,45.1,\\,45.06]$.\n- Case C (very low salt, strong electrostatics):\n  - $I$ in $\\mathrm{M}$: $[0.0005,\\,0.001,\\,0.002,\\,0.005]$.\n  - $\\ell_p$ in $\\mathrm{nm}$: $[144.5,\\,95.0,\\,70.1,\\,54.8]$.\n- Case D (different polymer or buffer with stronger baseline and electrostatics):\n  - $I$ in $\\mathrm{M}$: $[0.002,\\,0.005,\\,0.02,\\,0.2]$.\n  - $\\ell_p$ in $\\mathrm{nm}$: $[92.2,\\,67.9,\\,56.0,\\,52.45]$.\n\nFinal output format:\n- Your program should produce a single line of output containing a list of results, one per case, where each case is reported as a two-element list $[\\ell_p^0,\\,a]$ with each number rounded to three decimal places and expressed in the units specified above. The full output must therefore be a single list of four two-element lists, for example $[[\\ell_p^0,\\,a],[\\ell_p^0,\\,a],[\\ell_p^0,\\,a],[\\ell_p^0,\\,a]]$, printed on a single line with no extra text.", "solution": "The problem requires the derivation and application of a physical model for the persistence length of a semiflexible polyelectrolyte, such as double-stranded DNA, as a function of the surrounding electrolyte's ionic strength. The model must be derived from fundamental principles, and its parameters must be fitted to provided experimental data using the method of ordinary least squares.\n\nThe analysis proceeds in two stages: first, the deduction of the mathematical model from the provided physical arguments, and second, the formulation and solution of the linear regression problem to determine the model parameters.\n\n**1. Derivation of the Two-Parameter Model**\n\nThe problem states that the total persistence length, $\\ell_p$, is the sum of a short-range mechanical contribution, $\\ell_p^{mech}$, and a long-range electrostatic contribution, $\\ell_p^{elec}$.\n$$\n\\ell_p = \\ell_p^{mech} + \\ell_p^{elec}\n$$\nThe mechanical part, $\\ell_p^{mech}$, arises from the intrinsic stiffness of the polymer backbone and is independent of the ionic strength, $I$. The problem includes the constraint that at high ionic strength ($I \\to \\infty$), the total persistence length approaches a finite constant. In this limit, electrostatic interactions are completely screened, causing the electrostatic contribution to vanish, $\\ell_p^{elec} \\to 0$. Therefore, the high-salt limit of the persistence length is simply the mechanical contribution. We define this constant as $\\ell_p^0$.\n$$\n\\lim_{I \\to \\infty} \\ell_p(I) = \\ell_p^{mech} = \\ell_p^0\n$$\nThe model can thus be written as:\n$$\n\\ell_p(I) = \\ell_p^0 + \\ell_p^{elec}(I)\n$$\nTo determine the functional form of $\\ell_p^{elec}(I)$, we follow the prescribed physical arguments:\n\n(i) The persistence length is the ratio of the bending modulus, $K$, to the thermal energy, $k_B T$. This applies to each contribution separately.\n$$\n\\ell_p^{elec} = \\frac{K_{elec}}{k_B T}\n$$\nwhere $K_{elec}$ is the electrostatic contribution to the bending modulus.\n\n(ii) According to the Odijk–Skolnick–Fixman (OSF) argument, the electrostatic bending modulus for a uniformly charged cylinder scales with the inverse square of the Debye screening parameter, $\\kappa$.\n$$\nK_{elec} \\propto \\kappa^{-2}\n$$\nCombining these gives $\\ell_p^{elec} \\propto \\kappa^{-2}$.\n\n(iii) From linearized Debye–Hückel theory, the Debye parameter, which represents the inverse screening length, scales with the square root of the ionic strength.\n$$\n\\kappa \\propto I^{1/2}\n$$\nTherefore, $\\kappa^2 \\propto I$.\n\nSubstituting this scaling into the expression for $\\ell_p^{elec}$, we find the electrostatic persistence length is inversely proportional to the ionic strength.\n$$\n\\ell_p^{elec} \\propto (I^{1/2})^{-2} \\implies \\ell_p^{elec} \\propto I^{-1}\n$$\nWe introduce a proportionality constant, $a$, which consolidates various physical factors such as thermal energy, solvent dielectric constant, and the polymer's linear charge density. This yields the expression for the electrostatic contribution:\n$$\n\\ell_p^{elec}(I) = \\frac{a}{I}\n$$\nCombining the mechanical and electrostatic parts, we arrive at the minimal, two-parameter model for the total persistence length as a function of ionic strength:\n$$\n\\ell_p(I) = \\ell_p^0 + \\frac{a}{I}\n$$\nThis model is consistent with all the premises. The two parameters to be determined are $\\ell_p^0$, the intrinsic persistence length, and $a$, a parameter quantifying the strength of electrostatic effects.\n\n**2. Parameter Estimation via Ordinary Least Squares (OLS)**\n\nThe derived model is linear in its parameters, $\\ell_p^0$ and $a$. For a set of $n$ measurements $(I_i, \\ell_{p,i})$, we can write the model for each data point $i$ as:\n$$\n\\ell_{p,i} = \\ell_p^0 + a \\left(\\frac{1}{I_i}\\right) + \\varepsilon_i\n$$\nwhere $\\varepsilon_i$ is the residual error for the $i$-th measurement. This is a simple linear regression problem. Let the dependent variable be $y_i = \\ell_{p,i}$ and define a design variable $x_i = 1/I_i$. The model becomes:\n$$\ny_i = \\ell_p^0 \\cdot 1 + a \\cdot x_i + \\varepsilon_i\n$$\nThis system of $n$ equations can be expressed in matrix form as $\\mathbf{y} = \\mathbf{X}\\boldsymbol{\\beta} + \\boldsymbol{\\varepsilon}$, where:\n- $\\mathbf{y}$ is the $n \\times 1$ vector of observed persistence lengths: $\\mathbf{y} = [\\ell_{p,1}, \\ell_{p,2}, \\dots, \\ell_{p,n}]^T$.\n- $\\mathbf{X}$ is the $n \\times 2$ design matrix, whose first column is a vector of ones (for the intercept term) and whose second column is the vector of design variable values:\n$$\n\\mathbf{X} = \\begin{pmatrix} 1 & x_1 \\\\ 1 & x_2 \\\\ \\vdots & \\vdots \\\\ 1 & x_n \\end{pmatrix} = \\begin{pmatrix} 1 & 1/I_1 \\\\ 1 & 1/I_2 \\\\ \\vdots & \\vdots \\\\ 1 & 1/I_n \\end{pmatrix}\n$$\n- $\\boldsymbol{\\beta}$ is the $2 \\times 1$ vector of parameters to be estimated: $\\boldsymbol{\\beta} = [\\ell_p^0, a]^T$.\n- $\\boldsymbol{\\varepsilon}$ is the $n \\times 1$ vector of residuals.\n\nThe method of ordinary least squares finds the parameter vector $\\hat{\\boldsymbol{\\beta}}$ that minimizes the sum of squared residuals, $S = \\boldsymbol{\\varepsilon}^T \\boldsymbol{\\varepsilon} = (\\mathbf{y} - \\mathbf{X}\\boldsymbol{\\beta})^T (\\mathbf{y} - \\mathbf{X}\\boldsymbol{\\beta})$. The solution to this minimization problem is given by the normal equations:\n$$\n(\\mathbf{X}^T \\mathbf{X}) \\hat{\\boldsymbol{\\beta}} = \\mathbf{X}^T \\mathbf{y}\n$$\nAssuming the matrix $\\mathbf{X}^T \\mathbf{X}$ is invertible (which it will be as long as not all $I_i$ values are identical), the OLS estimator for $\\boldsymbol{\\beta}$ is:\n$$\n\\hat{\\boldsymbol{\\beta}} = (\\mathbf{X}^T \\mathbf{X})^{-1} \\mathbf{X}^T \\mathbf{y}\n$$\nThe program will implement this matrix equation to find the values of $\\hat{\\boldsymbol{\\beta}} = [\\hat{\\ell}_p^0, \\hat{a}]^T$ for each provided dataset.\n\n**3. Interpretation of Parameters**\n\n- $\\hat{\\ell}_p^0$: The first element of $\\hat{\\boldsymbol{\\beta}}$ is the intercept of the regression of $\\ell_p$ against $1/I$. It represents the persistence length at infinite ionic strength ($1/I \\to 0$), corresponding to the intrinsic mechanical stiffness of the polymer. Its units are nanometers ($\\mathrm{nm}$).\n- $\\hat{a}$: The second element of $\\hat{\\boldsymbol{\\beta}}$ is the slope of the regression. It quantifies the magnitude of the electrostatic contribution to the persistence length. Based on the model $\\ell_p(I) = \\ell_p^0 + a/I$, for $\\ell_p$ to be in units of $\\mathrm{nm}$ and $I$ in molar ($\\mathrm{M}$ or $\\mathrm{mol \\cdot L^{-1}}$), the parameter $a$ must have units of $\\mathrm{nm \\cdot M}$.\n\nThe implementation will construct the matrices $\\mathbf{X}$ and $\\mathbf{y}$ from the input data, solve for $\\hat{\\boldsymbol{\\beta}}$ using matrix algebra, and report the two parameters rounded to three decimal places.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Derives and fits a two-parameter model for polyelectrolyte persistence length\n    to experimental data using ordinary least squares.\n    \"\"\"\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # Case A (balanced low-to-high salt)\n        (\n            [0.001, 0.003, 0.01, 0.03, 0.1],\n            [95.3, 61.4666667, 50.1, 46.5666667, 45.5]\n        ),\n        # Case B (high salt, weak variation)\n        (\n            [0.2, 0.3, 0.5, 1.0],\n            [45.3, 45.1466667, 45.1, 45.06]\n        ),\n        # Case C (very low salt, strong electrostatics)\n        (\n            [0.0005, 0.001, 0.002, 0.005],\n            [144.5, 95.0, 70.1, 54.8]\n        ),\n        # Case D (different polymer or buffer)\n        (\n            [0.002, 0.005, 0.02, 0.2],\n            [92.2, 67.9, 56.0, 52.45]\n        ),\n    ]\n\n    # Store results for all cases\n    all_results = []\n\n    for i_vals, lp_vals in test_cases:\n        # Convert data to numpy arrays for vectorization\n        I = np.array(i_vals)\n        lp = np.array(lp_vals)\n\n        # The model is lp = lp_0 + a * (1/I).\n        # This is a linear model y = beta_0 + beta_1 * x,\n        # with y = lp, x = 1/I, beta_0 = lp_0, beta_1 = a.\n        \n        # Construct the design matrix X.\n        # The first column is for the intercept (lp_0), so it's all ones.\n        # The second column is the independent variable, 1/I.\n        design_variable = 1.0 / I\n        X = np.c_[np.ones(len(I)), design_variable]\n\n        # The vector of observations y is the persistence length data.\n        y = lp\n\n        # Solve the normal equations for the parameters beta = [lp_0, a]:\n        # (X^T * X) * beta = X^T * y\n        # beta = (X^T * X)^-1 * X^T * y\n        \n        try:\n            # Calculate (X^T * X)\n            XTX = X.T @ X\n            # Calculate its inverse\n            XTX_inv = np.linalg.inv(XTX)\n            # Calculate X^T * y\n            XTy = X.T @ y\n            # Solve for the parameter vector beta_hat\n            beta_hat = XTX_inv @ XTy\n        except np.linalg.LinAlgError:\n            # In case of a singular matrix, which shouldn't happen for valid input.\n            beta_hat = [np.nan, np.nan]\n\n        # The parameters are lp_0 (intercept) and a (slope).\n        lp0_fit = beta_hat[0]\n        a_fit = beta_hat[1]\n\n        # Store the results for this case.\n        all_results.append((lp0_fit, a_fit))\n\n    # Format the final output string as a list of two-element lists,\n    # with each parameter rounded to exactly three decimal places.\n    # The format specifier ':.3f' ensures trailing zeros are included.\n    # The construction avoids spaces that Python's default list-to-string\n    # conversion would add, matching the implicit formatting of the prompt.\n    output_parts = []\n    for lp0, a in all_results:\n        output_parts.append(f\"[{lp0:.3f},{a:.3f}]\")\n    \n    final_output_string = f\"[{','.join(output_parts)}]\"\n\n    # Final print statement in the exact required format.\n    print(final_output_string)\n\nsolve()\n```", "id": "2907118"}, {"introduction": "Biopolymers are not just passive structural elements; they are active components of molecular machines that perform work. This exercise delves into the mechanism of force generation by a polymerizing filament, a process vital for cell motility and shaping. By applying the principles of statistical mechanics to a \"Brownian ratchet\" model, you will derive the celebrated exponential force-velocity relationship and use it to extract a fundamental molecular dimension from hypothetical experimental data [@problem_id:2907121].", "problem": "A single actin filament grows against a rigid, planar obstacle that exerts a constant opposing force. The filament elongates by the addition of monomers of size $a$ along the filament axis. Let the gap between the filament tip and the obstacle be $z \\ge 0$. Assume that the obstacle is in quasi-static thermal equilibrium under a constant opposing force $f$ at temperature $T$, so that the gap has a Boltzmann weight set by the potential energy $U(z) = f z$. Monomer addition requires a gap exceeding the monomer size, $z > a$. Neglect monomer dissociation compared to monomer addition. The monomer addition is a Poisson process with attempt rate $k_{\\mathrm{on}} c$ when the geometrical constraint $z > a$ is met, where $k_{\\mathrm{on}}$ is the on-rate constant and $c$ is the monomer concentration.\n\n1. Starting from the Boltzmann distribution for $z$ under the potential $U(z) = f z$ and the above kinetic picture, derive the force–velocity relation $v(f)$ for the filament tip.\n\n2. The following experimental measurements of the filament growth velocity under load were made at temperature $T = 300\\,\\mathrm{K}$:\n   - At $f = 0.0\\,\\mathrm{pN}$, $v = 130\\,\\mathrm{nm\\,s^{-1}}$.\n   - At $f = 2.0\\,\\mathrm{pN}$, $v = 35.3\\,\\mathrm{nm\\,s^{-1}}$.\n   \n   Using your derived relation, treat the data as exhibiting an exponential load dependence and extract the monomer size $a$. You may take the Boltzmann constant to be $k_B = 1.380649 \\times 10^{-23}\\,\\mathrm{J\\,K^{-1}}$ and use $1\\,\\mathrm{J} = 10^{21}\\,\\mathrm{pN\\,nm}$. Round your final result to three significant figures. Express the final answer in nanometers.", "solution": "The solution is partitioned into two parts as requested: first, the derivation of the force-velocity relation, and second, the calculation of the monomer size from the provided experimental data.\n\nPart 1: Derivation of the force–velocity relation $v(f)$.\n\nThe average growth velocity, $v$, of the filament is the product of the length added per monomer addition event, $a$, and the average rate of these events, $\\langle R \\rangle$.\n$$\nv = a \\langle R \\rangle\n$$\nThe problem states that monomer addition is a Poisson process with an attempt rate $k_{\\mathrm{on}}c$ that can only succeed if the gap $z$ between the filament tip and the obstacle is greater than the monomer size $a$. Therefore, the instantaneous rate of addition for a given gap $z$ is:\n$$ R(z) = \\begin{cases} k_{\\mathrm{on}}c & \\text{if } z > a \\\\ 0 & \\text{if } z \\le a \\end{cases} $$\nThe average rate $\\langle R \\rangle$ is found by averaging $R(z)$ over the probability distribution of the gap size $z$.\n$$\n\\langle R \\rangle = \\int_0^\\infty R(z) p(z) dz\n$$\nwhere $p(z)$ is the probability density function for the gap size $z$. The problem specifies that the gap is in quasi-static thermal equilibrium under a potential $U(z) = fz$ at temperature $T$. The probability density follows the Boltzmann distribution:\n$$\np(z) = \\frac{\\exp\\left(-\\frac{U(z)}{k_B T}\\right)}{Z} = \\frac{\\exp\\left(-\\frac{fz}{k_B T}\\right)}{Z}\n$$\nwhere $k_B$ is the Boltzmann constant and $Z$ is the partition function. The partition function is the normalization constant, obtained by integrating the Boltzmann factor over all possible states, i.e., all $z \\ge 0$.\n$$\nZ = \\int_0^\\infty \\exp\\left(-\\frac{fz}{k_B T}\\right) dz\n$$\nFor $f > 0$, this integral converges:\n$$\nZ = \\left[ -\\frac{k_B T}{f} \\exp\\left(-\\frac{fz}{k_B T}\\right) \\right]_0^\\infty = 0 - \\left(-\\frac{k_B T}{f} \\exp(0)\\right) = \\frac{k_B T}{f}\n$$\nNow we can compute the average rate $\\langle R \\rangle$:\n$$\n\\langle R \\rangle = \\int_0^\\infty R(z) p(z) dz = \\int_a^\\infty (k_{\\mathrm{on}}c) \\frac{\\exp\\left(-\\frac{fz}{k_B T}\\right)}{Z} dz\n$$\nSubstituting the expression for $Z$:\n$$\n\\langle R \\rangle = (k_{\\mathrm{on}}c) \\frac{f}{k_B T} \\int_a^\\infty \\exp\\left(-\\frac{fz}{k_B T}\\right) dz\n$$\nWe evaluate the integral:\n$$\n\\int_a^\\infty \\exp\\left(-\\frac{fz}{k_B T}\\right) dz = \\left[ -\\frac{k_B T}{f} \\exp\\left(-\\frac{fz}{k_B T}\\right) \\right]_a^\\infty = 0 - \\left(-\\frac{k_B T}{f} \\exp\\left(-\\frac{fa}{k_B T}\\right)\\right) = \\frac{k_B T}{f} \\exp\\left(-\\frac{fa}{k_B T}\\right)\n$$\nSubstituting this result back into the expression for $\\langle R \\rangle$:\n$$\n\\langle R \\rangle = (k_{\\mathrm{on}}c) \\frac{f}{k_B T} \\left( \\frac{k_B T}{f} \\exp\\left(-\\frac{fa}{k_B T}\\right) \\right) = k_{\\mathrm{on}}c \\exp\\left(-\\frac{fa}{k_B T}\\right)\n$$\nFinally, the velocity $v(f)$ is:\n$$\nv(f) = a \\langle R \\rangle = a k_{\\mathrm{on}}c \\exp\\left(-\\frac{fa}{k_B T}\\right)\n$$\nThe velocity at zero force, $v_0 = v(f=0)$, is $v_0 = a k_{\\mathrm{on}}c$. Thus, the force-velocity relation can be written as:\n$$\nv(f) = v_0 \\exp\\left(-\\frac{fa}{k_B T}\\right)\n$$\nThis is the required force-velocity relation, which shows an exponential decay of velocity with increasing opposing force.\n\nPart 2: Calculation of the monomer size $a$.\n\nWe are given two data points:\n1. $f_1 = 0.0\\,\\mathrm{pN}$, $v_1 = 130\\,\\mathrm{nm\\,s^{-1}}$\n2. $f_2 = 2.0\\,\\mathrm{pN}$, $v_2 = 35.3\\,\\mathrm{nm\\,s^{-1}}$\n\nFrom the first data point, we identify the zero-force velocity: $v_0 = v(f_1) = v_1 = 130\\,\\mathrm{nm\\,s^{-1}}$.\n\nUsing the second data point, we can write:\n$$\nv_2 = v_0 \\exp\\left(-\\frac{f_2 a}{k_B T}\\right)\n$$\nTo solve for $a$, we first rearrange the equation:\n$$\n\\frac{v_2}{v_0} = \\exp\\left(-\\frac{f_2 a}{k_B T}\\right)\n$$\nTaking the natural logarithm of both sides:\n$$\n\\ln\\left(\\frac{v_2}{v_0}\\right) = -\\frac{f_2 a}{k_B T}\n$$\nIsolating $a$, we get:\n$$\na = -\\frac{k_B T}{f_2} \\ln\\left(\\frac{v_2}{v_0}\\right)\n$$\nNow, we must compute the numerical value. First, we calculate the thermal energy $k_B T$ in units compatible with the force and distance units provided, which are $\\mathrm{pN}$ and $\\mathrm{nm}$.\n$T = 300\\,\\mathrm{K}$\n$k_B = 1.380649 \\times 10^{-23}\\,\\mathrm{J\\,K^{-1}}$\nThe conversion is $1\\,\\mathrm{J} = 10^{21}\\,\\mathrm{pN\\,nm}$.\n$$\nk_B T = (1.380649 \\times 10^{-23}\\,\\mathrm{J\\,K^{-1}}) \\times (300\\,\\mathrm{K}) = 4.141947 \\times 10^{-21}\\,\\mathrm{J}\n$$\n$$\nk_B T = (4.141947 \\times 10^{-21}\\,\\mathrm{J}) \\times \\left(\\frac{10^{21}\\,\\mathrm{pN\\,nm}}{1\\,\\mathrm{J}}\\right) = 4.141947\\,\\mathrm{pN\\,nm}\n$$\nNow we substitute the values into the expression for $a$:\n$f_2 = 2.0\\,\\mathrm{pN}$\n$v_0 = 130\\,\\mathrm{nm\\,s^{-1}}$\n$v_2 = 35.3\\,\\mathrm{nm\\,s^{-1}}$\n$$\na = -\\frac{4.141947\\,\\mathrm{pN\\,nm}}{2.0\\,\\mathrm{pN}} \\ln\\left(\\frac{35.3}{130}\\right)\n$$\n$$\na = -2.0709735\\,\\mathrm{nm} \\times \\ln(0.271538...)\n$$\n$$\na = -2.0709735\\,\\mathrm{nm} \\times (-1.30351...)\n$$\n$$\na \\approx 2.7001\\,\\mathrm{nm}\n$$\nRounding the result to three significant figures as requested, we obtain:\n$$\na = 2.70\\,\\mathrm{nm}\n$$\nThis value corresponds well with the known structural parameter for the rise per monomer in an actin filament.", "answer": "$$\\boxed{2.70}$$", "id": "2907121"}, {"introduction": "Probing the thermodynamics of single molecules often involves driving them far from equilibrium, for instance, by rapidly unfolding a protein. Jarzynski's equality offers a powerful, albeit subtle, way to extract equilibrium free energy differences, $\\Delta F$, from the statistics of non-equilibrium work, $W$, measurements. This advanced practice guides you through deriving and implementing a bias-corrected estimator for $\\Delta F$, a critical tool for robustly analyzing data from real-world single-molecule pulling experiments [@problem_id:2907045].", "problem": "You are given repeated nonequilibrium work measurements from pulling and unfolding a single protein domain with an atomic force microscope. The work values are independent and identically distributed draws from an unknown nonequilibrium work distribution generated by a fixed pulling protocol. Assume that all works are expressed in units of the thermal energy, that is, in multiples of the Boltzmann constant times temperature ($k_{\\mathrm{B}}T$). In these units, the inverse thermal energy is $\\beta = 1$. Your task is to estimate the equilibrium free energy difference $\\Delta F$ between folded and unfolded states from these nonequilibrium work values using a bias-corrected estimator derived from the nonequilibrium work relation and to assess estimator convergence.\n\nUse as the fundamental base the Jarzynski equality, a well-tested result from nonequilibrium statistical mechanics:\n$$\n\\left\\langle e^{-\\beta W} \\right\\rangle = e^{-\\beta \\Delta F},\n$$\nwhere $W$ is the work random variable, $\\beta$ is the inverse temperature, and $\\langle \\cdot \\rangle$ denotes an ensemble average over repeated realizations of the same protocol.\n\nLet $\\{W_i\\}_{i=1}^N$ be a sample of work values. Define $Y_i = e^{-\\beta W_i}$, the sample mean $\\bar{Y}_N = \\frac{1}{N}\\sum_{i=1}^N Y_i$, and the unbiased sample variance $s_Y^2 = \\frac{1}{N-1}\\sum_{i=1}^N (Y_i - \\bar{Y}_N)^2$. The naive Jarzynski estimator uses $\\bar{Y}_N$ to estimate $\\Delta F$ as $-\\beta^{-1}\\ln \\bar{Y}_N$. However, due to the concavity of the logarithm, this estimator is biased at finite $N$. Starting from the Jarzynski equality and using a second-order Taylor (delta-method) expansion of the logarithm around the population mean of $Y$, derive a bias-corrected estimator that removes the leading $\\mathcal{O}(1/N)$ bias term in expectation. Then implement this estimator and a convergence assessment as follows.\n\nConvergence assessment requirement: For a given tolerance $\\varepsilon > 0$, compute the running bias-corrected estimate $\\widehat{\\Delta F}_{\\mathrm{bc}}(n)$ for prefixes of the data of length $n = 3, 4, \\dots, N$. Define the convergence index $n^\\star$ as the smallest $n \\in \\{3,\\dots,N\\}$ such that for all $m \\in \\{n+1,\\dots,N\\}$,\n$$\n\\left| \\widehat{\\Delta F}_{\\mathrm{bc}}(m) - \\widehat{\\Delta F}_{\\mathrm{bc}}(m-1) \\right| \\le \\varepsilon.\n$$\nIf no such $n$ exists, return $-1$ for the convergence index.\n\nImplementation requirements:\n- All works are in units of $k_{\\mathrm{B}}T$, so set $\\beta = 1$. Express your final free energy estimates in units of $k_{\\mathrm{B}}T$.\n- For the variance estimate in the bias correction, use the unbiased sample variance $s_Y^2$ computed with divisor $N-1$.\n- For convergence scanning, start at $n=3$ so that variance is well-defined and not trivially dominated by extremely small sample sizes.\n- Round all reported free energy estimates to $6$ decimal places.\n- The final program must produce a single line containing a comma-separated list enclosed in square brackets of the following sequence for each test case: the naive Jarzynski estimate using all data, the bias-corrected estimate using all data, and the convergence index $n^\\star$. The overall output is the concatenation of these triples across all test cases in the order listed below.\n\nTest suite:\n- Case A (moderate dissipation): $N = 30$, $\\varepsilon = 0.1$, $\\beta = 1$, with work list\n  $$\n  W = [\\, 6.2,\\, 6.8,\\, 8.1,\\, 7.5,\\, 6.9,\\, 7.2,\\, 7.8,\\, 6.4,\\, 5.9,\\, 8.3,\\, 7.0,\\, 7.1,\\, 6.6,\\, 8.0,\\, 7.4,\\, 6.5,\\, 7.6,\\, 8.2,\\, 6.7,\\, 7.3,\\, 7.9,\\, 6.3,\\, 5.8,\\, 8.4,\\, 6.1,\\, 7.7,\\, 8.5,\\, 5.7,\\, 6.0,\\, 7.0 \\,].\n  $$\n- Case B (near equilibrium): $N = 20$, $\\varepsilon = 0.05$, $\\beta = 1$, with work list\n  $$\n  W = [\\, 3.4,\\, 3.6,\\, 3.7,\\, 3.3,\\, 3.5,\\, 3.6,\\, 3.2,\\, 3.8,\\, 3.5,\\, 3.4,\\, 3.6,\\, 3.5,\\, 3.7,\\, 3.3,\\, 3.4,\\, 3.6,\\, 3.5,\\, 3.7,\\, 3.3,\\, 3.4 \\,].\n  $$\n- Case C (far from equilibrium, broad distribution): $N = 50$, $\\varepsilon = 0.1$, $\\beta = 1$, with work list\n  $$\n  W = [\\, 12.7,\\, 13.1,\\, 12.5,\\, 13.8,\\, 12.9,\\, 14.2,\\, 12.3,\\, 13.5,\\, 12.8,\\, 14.0,\\, 13.2,\\, 12.6,\\, 13.9,\\, 12.4,\\, 13.3,\\, 12.7,\\, 14.1,\\, 12.2,\\, 13.6,\\, 12.9,\\, 13.0,\\, 14.3,\\, 12.1,\\, 13.4,\\, 12.8,\\, 13.7,\\, 12.0,\\, 13.5,\\, 11.9,\\, 14.4,\\, 12.6,\\, 13.8,\\, 12.7,\\, 13.1,\\, 12.5,\\, 14.0,\\, 13.2,\\, 11.8,\\, 13.6,\\, 12.4,\\, 13.3,\\, 12.7,\\, 13.9,\\, 12.3,\\, 13.5,\\, 11.7,\\, 14.1,\\, 12.2,\\, 13.4,\\, 11.6 \\,].\n  $$\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, in the order\n$$\n[\\, \\widehat{\\Delta F}_{\\mathrm{J}}^{(A)},\\, \\widehat{\\Delta F}_{\\mathrm{bc}}^{(A)},\\, n_\\star^{(A)},\\, \\widehat{\\Delta F}_{\\mathrm{J}}^{(B)},\\, \\widehat{\\Delta F}_{\\mathrm{bc}}^{(B)},\\, n_\\star^{(B)},\\, \\widehat{\\Delta F}_{\\mathrm{J}}^{(C)},\\, \\widehat{\\Delta F}_{\\mathrm{bc}}^{(C)},\\, n_\\star^{(C)} \\,],\n$$\nwhere the superscripts $(A)$, $(B)$, and $(C)$ refer to Cases A, B, and C, respectively. Report all $\\Delta F$ values in units of $k_{\\mathrm{B}}T$ and rounded to $6$ decimal places; report each $n_\\star$ as an integer.", "solution": "The solution proceeds in two steps: first, the derivation of the bias-corrected estimator for the free energy difference $\\Delta F$, and second, the implementation of the calculations and convergence analysis.\n\n**1. Derivation of the Bias-Corrected Estimator**\n\nThe goal is to estimate the equilibrium free energy difference $\\Delta F$ using the Jarzynski equality:\n$$\n\\left\\langle e^{-\\beta W} \\right\\rangle = e^{-\\beta \\Delta F}\n$$\nwhere $W$ is the work performed in a nonequilibrium process, $\\beta = (k_{\\mathrm{B}}T)^{-1}$ is the inverse thermal energy, and $\\langle \\cdot \\rangle$ is an ensemble average. Given a set of $N$ work measurements $\\{W_i\\}_{i=1}^N$, we define the quantities $Y_i = e^{-\\beta W_i}$. The population mean of $Y$ is $\\mu_Y = E[Y_i] = \\langle e^{-\\beta W} \\rangle$. The true free energy difference is given by $\\Delta F = -\\beta^{-1}\\ln(\\mu_Y)$.\n\nA naive estimator for $\\Delta F$ is constructed by replacing the population mean $\\mu_Y$ with the sample mean $\\bar{Y}_N = \\frac{1}{N}\\sum_{i=1}^N Y_i$:\n$$\n\\widehat{\\Delta F}_{\\mathrm{J}} = -\\beta^{-1}\\ln(\\bar{Y}_N)\n$$\nThis estimator is biased for finite $N$ because the logarithm is a concave function. To find the leading-order bias, we perform a second-order Taylor expansion of the function $f(x) = \\ln(x)$ around the population mean $\\mu_Y$, evaluated at the sample mean $\\bar{Y}_N$:\n$$\n\\ln(\\bar{Y}_N) \\approx \\ln(\\mu_Y) + (\\bar{Y}_N - \\mu_Y)f'(\\mu_Y) + \\frac{1}{2}(\\bar{Y}_N - \\mu_Y)^2 f''(\\mu_Y)\n$$\nThe derivatives are $f'(x) = 1/x$ and $f''(x) = -1/x^2$. Substituting these gives:\n$$\n\\ln(\\bar{Y}_N) \\approx \\ln(\\mu_Y) + \\frac{\\bar{Y}_N - \\mu_Y}{\\mu_Y} - \\frac{(\\bar{Y}_N - \\mu_Y)^2}{2\\mu_Y^2}\n$$\nTaking the expectation of both sides:\n$$\nE[\\ln(\\bar{Y}_N)] \\approx E[\\ln(\\mu_Y)] + \\frac{E[\\bar{Y}_N - \\mu_Y]}{\\mu_Y} - \\frac{E[(\\bar{Y}_N - \\mu_Y)^2]}{2\\mu_Y^2}\n$$\nWe know that $E[\\bar{Y}_N] = \\mu_Y$, so $E[\\bar{Y}_N - \\mu_Y] = 0$. The term $E[(\\bar{Y}_N - \\mu_Y)^2]$ is the variance of the sample mean, $\\text{Var}(\\bar{Y}_N)$. For independent and identically distributed $Y_i$, $\\text{Var}(\\bar{Y}_N) = \\sigma_Y^2/N$, where $\\sigma_Y^2 = \\text{Var}(Y_i)$ is the population variance of $Y$.\nThe expected value of the logarithm is thus:\n$$\nE[\\ln(\\bar{Y}_N)] \\approx \\ln(\\mu_Y) - \\frac{\\sigma_Y^2}{2N\\mu_Y^2}\n$$\nNow, we find the expectation of the naive estimator $\\widehat{\\Delta F}_{\\mathrm{J}}$:\n$$\nE[\\widehat{\\Delta F}_{\\mathrm{J}}] = E[-\\beta^{-1}\\ln(\\bar{Y}_N)] = -\\beta^{-1}E[\\ln(\\bar{Y}_N)] \\approx -\\beta^{-1}\\left(\\ln(\\mu_Y) - \\frac{\\sigma_Y^2}{2N\\mu_Y^2}\\right)\n$$\n$$\nE[\\widehat{\\Delta F}_{\\mathrm{J}}] \\approx -\\beta^{-1}\\ln(\\mu_Y) + \\frac{\\beta^{-1}\\sigma_Y^2}{2N\\mu_Y^2} = \\Delta F + \\frac{\\beta^{-1}\\sigma_Y^2}{2N\\mu_Y^2}\n$$\nThe leading-order bias is the second term, $\\text{Bias}(\\widehat{\\Delta F}_{\\mathrm{J}}) \\approx \\frac{\\beta^{-1}\\sigma_Y^2}{2N\\mu_Y^2}$. A bias-corrected estimator, $\\widehat{\\Delta F}_{\\mathrm{bc}}$, is constructed by subtracting an estimate of this bias from the naive estimator:\n$$\n\\widehat{\\Delta F}_{\\mathrm{bc}} = \\widehat{\\Delta F}_{\\mathrm{J}} - \\widehat{\\text{Bias}}\n$$\nTo estimate the bias, we replace the population parameters $\\mu_Y$ and $\\sigma_Y^2$ with their sample estimates: $\\bar{Y}_N$ for $\\mu_Y$, and the unbiased sample variance $s_Y^2 = \\frac{1}{N-1}\\sum_{i=1}^N (Y_i - \\bar{Y}_N)^2$ for $\\sigma_Y^2$. This yields the bias-corrected estimator:\n$$\n\\widehat{\\Delta F}_{\\mathrm{bc}} = -\\beta^{-1}\\ln(\\bar{Y}_N) - \\frac{\\beta^{-1}s_Y^2}{2N\\bar{Y}_N^2}\n$$\nGiven that all calculations are performed in units of $k_{\\mathrm{B}}T$, we set $\\beta=1$:\n$$\n\\widehat{\\Delta F}_{\\mathrm{bc}} = -\\ln(\\bar{Y}_N) - \\frac{s_Y^2}{2N\\bar{Y}_N^2}\n$$\n\n**2. Algorithm for Calculation and Convergence**\n\nThe implementation proceeds as follows: First, for each test case, the full dataset $\\{W_i\\}_{i=1}^N$ is used to calculate the naive estimate $\\widehat{\\Delta F}_{\\mathrm{J}}(N)$ and the bias-corrected estimate $\\widehat{\\Delta F}_{\\mathrm{bc}}(N)$ using the derived formula.\n\nSecond, the convergence of the bias-corrected estimator is assessed. This involves computing a series of estimates $\\widehat{\\Delta F}_{\\mathrm{bc}}(n)$ for prefixes of the data of increasing size $n$, from $n=3$ to $n=N$.\n\nThe convergence index $n^\\star$ is determined based on the stability of this series of estimates. We identify the last sample size $m$ at which the change in the estimate exceeds the tolerance $\\varepsilon$: let $S = \\{m \\in \\{4, \\dots, N\\} \\mid |\\widehat{\\Delta F}_{\\mathrm{bc}}(m) - \\widehat{\\Delta F}_{\\mathrm{bc}}(m-1)| > \\varepsilon \\}$. If this set $S$ is empty, the estimate was stable for all $n \\ge 3$, and we set $n^\\star = 3$. Otherwise, the last point of significant fluctuation occurs at $m_{\\text{max}} = \\max S$. The sequence is only stable for sample sizes greater than this point. Therefore, we set $n^\\star = m_{\\text{max}}$. This procedure provides a unique and well-defined value for $n^\\star \\in \\{3, \\dots, N\\}$.", "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the problem for all test cases and prints the final formatted output.\n    \"\"\"\n    test_cases = [\n        {\n            \"name\": \"Case A\",\n            \"W\": [6.2, 6.8, 8.1, 7.5, 6.9, 7.2, 7.8, 6.4, 5.9, 8.3, 7.0, 7.1, 6.6, 8.0, 7.4, 6.5, 7.6, 8.2, 6.7, 7.3, 7.9, 6.3, 5.8, 8.4, 6.1, 7.7, 8.5, 5.7, 6.0, 7.0],\n            \"N\": 30,\n            \"epsilon\": 0.1,\n            \"beta\": 1.0\n        },\n        {\n            \"name\": \"Case B\",\n            \"W\": [3.4, 3.6, 3.7, 3.3, 3.5, 3.6, 3.2, 3.8, 3.5, 3.4, 3.6, 3.5, 3.7, 3.3, 3.4, 3.6, 3.5, 3.7, 3.3, 3.4],\n            \"N\": 20,\n            \"epsilon\": 0.05,\n            \"beta\": 1.0\n        },\n        {\n            \"name\": \"Case C\",\n            \"W\": [12.7, 13.1, 12.5, 13.8, 12.9, 14.2, 12.3, 13.5, 12.8, 14.0, 13.2, 12.6, 13.9, 12.4, 13.3, 12.7, 14.1, 12.2, 13.6, 12.9, 13.0, 14.3, 12.1, 13.4, 12.8, 13.7, 12.0, 13.5, 11.9, 14.4, 12.6, 13.8, 12.7, 13.1, 12.5, 14.0, 13.2, 11.8, 13.6, 12.4, 13.3, 12.7, 13.9, 12.3, 13.5, 11.7, 14.1, 12.2, 13.4, 11.6],\n            \"N\": 50,\n            \"epsilon\": 0.1,\n            \"beta\": 1.0\n        }\n    ]\n\n    all_results = []\n\n    for case in test_cases:\n        W_list = case[\"W\"]\n        N = case[\"N\"]\n        epsilon = case[\"epsilon\"]\n        beta = case[\"beta\"]\n\n        W = np.array(W_list)\n        \n        # 1. Calculate estimators for the full dataset.\n        Y = np.exp(-beta * W)\n        Y_bar = np.mean(Y)\n        \n        # Naive Jarzynski estimator\n        delta_F_J_full = -1/beta * np.log(Y_bar)\n        \n        # Unbiased sample variance with N-1 denominator\n        s_Y_sq = np.var(Y, ddof=1)\n        \n        # Bias correction term and final corrected estimator\n        bias_correction = (s_Y_sq / beta) / (2 * N * Y_bar**2)\n        delta_F_bc_full = delta_F_J_full - bias_correction\n\n        # 2. Convergence analysis\n        # Calculate running bias-corrected estimates for n = 3, 4, ..., N\n        running_bc_estimates = []\n        for n in range(3, N + 1):\n            W_prefix = W[:n]\n            Y_prefix = np.exp(-beta * W_prefix)\n            Y_bar_n = np.mean(Y_prefix)\n            \n            # Naive estimator for prefix\n            delta_F_J_n = -1/beta * np.log(Y_bar_n)\n            \n            # Unbiased variance for prefix\n            s_Y_sq_n = np.var(Y_prefix, ddof=1)\n            \n            # Bias correction for prefix\n            bias_corr_n = (s_Y_sq_n / beta) / (2 * n * Y_bar_n**2)\n            delta_F_bc_n = delta_F_J_n - bias_corr_n\n            running_bc_estimates.append(delta_F_bc_n)\n\n        # Determine the convergence index n_star.\n        # It is the smallest n in {3..N} such that for all m > n,\n        # the change is less than or equal to epsilon.\n        # This is equivalent to finding the last m where the change > epsilon.\n        # That m is the new convergence index n_star. If no such m exists, n_star = 3.\n        \n        m_max_instability = -1\n        # The list running_bc_estimates is indexed 0 to N-3.\n        # The estimate for sample size n is at index n-3.\n        # We are calculating differences for m from 4 to N.\n        for m in range(4, N + 1):\n            # Difference between estimate at m and m-1\n            # Index for m is m-3, for m-1 is m-4\n            diff = abs(running_bc_estimates[m-3] - running_bc_estimates[m-4])\n            if diff > epsilon:\n                m_max_instability = m\n\n        if m_max_instability == -1:\n            # No instability was found for m >= 4, so the sequence is stable from n=3.\n            n_star = 3\n        else:\n            # The last point of instability determines the convergence index.\n            n_star = m_max_instability\n            \n        # Append results for this case.\n        # Free energy values are rounded to 6 decimal places.\n        all_results.append(f\"{delta_F_J_full:.6f}\")\n        all_results.append(f\"{delta_F_bc_full:.6f}\")\n        all_results.append(str(n_star))\n\n    # Print all results in the required single-line format.\n    print(f\"[{','.join(all_results)}]\")\n\nsolve()\n```", "id": "2907045"}]}