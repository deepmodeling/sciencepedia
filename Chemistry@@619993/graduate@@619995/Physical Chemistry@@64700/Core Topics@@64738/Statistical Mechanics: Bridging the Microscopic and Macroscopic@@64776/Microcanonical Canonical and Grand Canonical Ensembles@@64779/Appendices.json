{"hands_on_practices": [{"introduction": "Our journey into the practical application of statistical ensembles begins with the most fundamental one: the microcanonical ensemble, which describes completely isolated systems with fixed energy ($E$), volume ($V$), and particle number ($N$). In this exercise, [@problem_id:109322], we will use a simple model with discrete energy levels to derive the temperature of the system from first principles. This practice is crucial as it demonstrates how temperature, a macroscopic thermodynamic property, arises directly from the statistical definition of entropy, $S = k_B \\ln \\Omega$, and its dependence on energy.", "problem": "A system consists of $N$ non-interacting, distinguishable particles. Each particle can occupy one of three energy levels: $-\\epsilon$, $0$, or $+\\epsilon$, where $\\epsilon$ is a positive energy constant. The system is isolated and is in thermal equilibrium with a fixed total energy $E$. Furthermore, the number of particles occupying the zero-energy level is constrained to be a constant, $N_0$.\n\nAssuming that $N$, $N_0$, and the populations of the other levels are large enough for Stirling's approximation to be valid, determine the temperature $T$ of the system as a function of $E, N, N_0, \\epsilon,$ and Boltzmann's constant $k_B$. The final answer should be a single closed-form analytical expression for the temperature $T$.", "solution": "1. Constraints:\n$$N_++N_- = N - N_0 \\equiv M,\\qquad E = \\epsilon(N_+ - N_-).$$\nHence\n$$N_\\pm = \\frac{M \\pm E/\\epsilon}{2}.$$\n\n2. Entropy (Stirling):\n$$S = k_B\\bigl[N\\ln N - N_-\\ln N_- - N_0\\ln N_0 - N_+\\ln N_+\\bigr].$$\n\n3. Temperature:\n$$\\frac1T = \\frac{dS}{dE}\n= \\frac{k_B}{2\\epsilon}\\ln\\frac{N_-}{N_+},$$\nso\n$$T = \\frac{2\\epsilon}{k_B\\,\\ln\\!\\displaystyle\\frac{N_-}{N_+}}\n= \\frac{2\\epsilon}{k_B\\,\\ln\\!\\displaystyle\\frac{\\,(N-N_0)\\epsilon - E\\,}{\\,(N-N_0)\\epsilon + E\\,}}.$$", "answer": "$$\\boxed{\\frac{2\\epsilon}{k_B\\,\\ln\\!\\frac{(N - N_0)\\epsilon - E}{(N - N_0)\\epsilon + E}}}$$", "id": "109322"}, {"introduction": "Next, we consider the more common physical scenario of a system in thermal contact with a large heat reservoir at a constant temperature $T$, described by the canonical ensemble. This practice, [@problem_id:2650675], moves beyond calculating simple averages and explores the deeper statistical information encoded in the canonical partition function, $Z$. You will prove a powerful relationship between $Z$ and the energy cumulants, and then apply it to calculate the mean, variance, skewness, and kurtosis of energy for a two-level system, directly linking statistical fluctuations to thermodynamic properties like heat capacity.", "problem": "Consider a system in the canonical ensemble at absolute temperature $T$, with inverse temperature $\\beta = 1/(k_B T)$, where $k_B$ is the Boltzmann constant. The system has discrete microstates labeled by $i$ with energies $E_i$. The canonical partition function is $Z(\\beta) = \\sum_i \\exp(-\\beta E_i)$, and the canonical probability of state $i$ is $p_i = \\exp(-\\beta E_i)/Z(\\beta)$. The energy $E$ is treated as a random variable with respect to this canonical distribution.\n\n(a) Starting only from these definitions and the definition of the cumulant generating function $K(t)$ for the energy as $K(t) = \\ln \\langle \\exp(t E) \\rangle$ (where the angular brackets denote the canonical average), prove that the $n$-th cumulant $\\kappa_n$ of the energy satisfies\n$$\n\\kappa_n = (-1)^n \\frac{\\partial^n}{\\partial \\beta^n} \\ln Z(\\beta).\n$$\n\n(b) Now consider a specific model: a single nondegenerate two-level system with energies $E_0 = 0$ and $E_1 = \\varepsilon$, where $\\varepsilon > 0$ is a constant. Using part (a), compute the first four energy cumulants $\\kappa_1$, $\\kappa_2$, $\\kappa_3$, and $\\kappa_4$ as closed-form analytic expressions in terms of $\\beta$ and $\\varepsilon$. Express your final answer as a single four-entry row vector in terms of $\\beta$ and $\\varepsilon$ only. Do not substitute numerical values or include units in the final expression.", "solution": "We begin with the canonical ensemble framework. The partition function is $Z(\\beta) = \\sum_i \\exp(-\\beta E_i)$, and the canonical probability of microstate $i$ is $p_i = \\exp(-\\beta E_i)/Z(\\beta)$. The energy $E$ is a random variable that takes values $E_i$ with probabilities $p_i$.\n\nPart (a): The cumulant generating function $K(t)$ of the energy is defined by\n$$\nK(t) = \\ln \\langle \\exp(t E) \\rangle,\n$$\nwhere the canonical average $\\langle \\cdot \\rangle$ is taken with respect to $p_i$. Using the definition of $p_i$,\n$$\n\\langle \\exp(t E) \\rangle = \\sum_i p_i \\exp(t E_i) = \\frac{1}{Z(\\beta)} \\sum_i \\exp(-\\beta E_i) \\exp(t E_i) = \\frac{1}{Z(\\beta)} \\sum_i \\exp\\!\\big(-( \\beta - t ) E_i\\big).\n$$\nRecognizing the sum as the partition function evaluated at a shifted inverse temperature, we obtain\n$$\n\\langle \\exp(t E) \\rangle = \\frac{Z(\\beta - t)}{Z(\\beta)}.\n$$\nTherefore,\n$$\nK(t) = \\ln \\langle \\exp(t E) \\rangle = \\ln Z(\\beta - t) - \\ln Z(\\beta).\n$$\nBy the definition of cumulants, the $n$-th cumulant $\\kappa_n$ is the $n$-th derivative of $K(t)$ at $t=0$:\n$$\n\\kappa_n = \\left. \\frac{\\partial^n K}{\\partial t^n} \\right|_{t=0}.\n$$\nApplying the chain rule to $K(t) = \\ln Z(\\beta - t) - \\ln Z(\\beta)$, note that differentiation with respect to $t$ acts as $\\frac{\\partial}{\\partial t} = - \\frac{\\partial}{\\partial \\beta}$ on the first term and annihilates the second term (which is independent of $t$). Hence,\n$$\n\\frac{\\partial^n K}{\\partial t^n} = (-1)^n \\frac{\\partial^n}{\\partial \\beta^n} \\ln Z(\\beta - t).\n$$\nEvaluating at $t=0$ yields\n$$\n\\kappa_n = (-1)^n \\left. \\frac{\\partial^n}{\\partial \\beta^n} \\ln Z(\\beta - t) \\right|_{t=0} = (-1)^n \\frac{\\partial^n}{\\partial \\beta^n} \\ln Z(\\beta),\n$$\nwhich proves the stated relation.\n\nPart (b): For a single nondegenerate two-level system with $E_0 = 0$ and $E_1 = \\varepsilon$, the partition function is\n$$\nZ(\\beta) = 1 + \\exp(-\\beta \\varepsilon).\n$$\nDefine $u = \\exp(-\\beta \\varepsilon)$ to simplify intermediate derivatives. Then $\\ln Z(\\beta) = \\ln(1+u)$ and $u' \\equiv \\frac{\\partial u}{\\partial \\beta} = - \\varepsilon u$.\n\nWe compute successive derivatives of $\\ln Z(\\beta)$:\n1. First derivative:\n$$\n\\frac{\\partial}{\\partial \\beta} \\ln Z = \\frac{u'}{1+u} = - \\varepsilon \\frac{u}{1+u}.\n$$\nBy part (a), with $n=1$, $\\kappa_1 = - \\frac{\\partial}{\\partial \\beta} \\ln Z = \\varepsilon \\frac{u}{1+u}$. Rewriting $u = \\exp(-\\beta \\varepsilon)$,\n$$\n\\kappa_1 = \\varepsilon \\frac{\\exp(-\\beta \\varepsilon)}{1+\\exp(-\\beta \\varepsilon)} = \\varepsilon \\frac{1}{1+\\exp(\\beta \\varepsilon)}.\n$$\n\n2. Second derivative:\n$$\n\\frac{\\partial^2}{\\partial \\beta^2} \\ln Z = \\frac{\\partial}{\\partial \\beta} \\left( - \\varepsilon \\frac{u}{1+u} \\right) = \\varepsilon^2 \\frac{u}{(1+u)^2}.\n$$\nThus, for $n=2$, $\\kappa_2 = \\frac{\\partial^2}{\\partial \\beta^2} \\ln Z = \\varepsilon^2 \\frac{u}{(1+u)^2}$. In terms of $\\exp(\\beta \\varepsilon)$,\n$$\n\\kappa_2 = \\varepsilon^2 \\frac{\\exp(\\beta \\varepsilon)}{(1+\\exp(\\beta \\varepsilon))^2}.\n$$\n\n3. Third derivative:\nWe first write\n$$\n\\frac{\\partial^2}{\\partial \\beta^2} \\ln Z = \\varepsilon^2 \\frac{u}{(1+u)^2}.\n$$\nDifferentiating once more,\n$$\n\\frac{\\partial^3}{\\partial \\beta^3} \\ln Z = \\varepsilon^2 \\frac{u'(1+u)^2 - u \\cdot 2(1+u)u'}{(1+u)^4} = \\varepsilon^2 u' \\frac{(1+u)^2 - 2u(1+u)}{(1+u)^4}.\n$$\nThis simplifies to\n$$\n\\frac{\\partial^3}{\\partial \\beta^3} \\ln Z = \\varepsilon^2 u' \\frac{(1+u)(1 - u)}{(1+u)^4} = - \\varepsilon^3 \\frac{u(1 - u)}{(1+u)^3}.\n$$\nHence, for $n=3$,\n$$\n\\kappa_3 = - \\frac{\\partial^3}{\\partial \\beta^3} \\ln Z = \\varepsilon^3 \\frac{u(1 - u)}{(1+u)^3} = \\varepsilon^3 \\frac{\\exp(\\beta \\varepsilon)\\left(\\exp(\\beta \\varepsilon) - 1\\right)}{(1+\\exp(\\beta \\varepsilon))^3}.\n$$\n\n4. Fourth derivative:\nStarting from\n$$\n\\frac{\\partial^3}{\\partial \\beta^3} \\ln Z = - \\varepsilon^3 \\frac{u(1 - u)}{(1+u)^3},\n$$\ndifferentiate again:\n$$\n\\frac{\\partial^4}{\\partial \\beta^4} \\ln Z = - \\varepsilon^3 \\left[ \\frac{u'(1 - u)}{(1+u)^3} + \\frac{u(-u')}{(1+u)^3} - 3 \\frac{u(1 - u)u'}{(1+u)^4} \\right].\n$$\nCombine terms using $u' = - \\varepsilon u$:\n$$\n\\frac{\\partial^4}{\\partial \\beta^4} \\ln Z = - \\varepsilon^3 u' \\left[ \\frac{1 - 2u}{(1+u)^3} - 3 \\frac{u(1 - u)}{(1+u)^4} \\right] = \\varepsilon^4 \\frac{u(1 - 4u + u^2)}{(1+u)^4}.\n$$\nTherefore, for $n=4$, $\\kappa_4 = \\frac{\\partial^4}{\\partial \\beta^4} \\ln Z$, which in terms of $\\exp(\\beta \\varepsilon)$ becomes\n$$\n\\kappa_4 = \\varepsilon^4 \\frac{\\exp(\\beta \\varepsilon)\\left(1 - 4 \\exp(\\beta \\varepsilon) + \\exp(2 \\beta \\varepsilon)\\right)}{(1+\\exp(\\beta \\varepsilon))^4}.\n$$\n\nCollecting the four cumulants in the requested row vector form yields the final expression in terms of $\\beta$ and $\\varepsilon$ only. As a cross-check, these results are consistent with viewing the energy as a Bernoulli random variable taking values $0$ and $\\varepsilon$ with excitation probability $p = 1/(1+\\exp(\\beta \\varepsilon))$, for which the known cumulants are $\\kappa_1 = \\varepsilon p$, $\\kappa_2 = \\varepsilon^2 p(1-p)$, $\\kappa_3 = \\varepsilon^3 p(1-p)(1-2p)$, and $\\kappa_4 = \\varepsilon^4 p(1-p)\\left(1 - 6 p(1-p)\\right)$.", "answer": "$$\\boxed{\\begin{pmatrix}\n\\dfrac{\\varepsilon}{1+\\exp(\\beta \\varepsilon)} & \\dfrac{\\varepsilon^{2}\\exp(\\beta \\varepsilon)}{\\left(1+\\exp(\\beta \\varepsilon)\\right)^{2}} & \\dfrac{\\varepsilon^{3}\\exp(\\beta \\varepsilon)\\left(\\exp(\\beta \\varepsilon)-1\\right)}{\\left(1+\\exp(\\beta \\varepsilon)\\right)^{3}} & \\dfrac{\\varepsilon^{4}\\exp(\\beta \\varepsilon)\\left(1-4\\exp(\\beta \\varepsilon)+\\exp(2\\beta \\varepsilon)\\right)}{\\left(1+\\exp(\\beta \\varepsilon)\\right)^{4}}\n\\end{pmatrix}}$$", "id": "2650675"}, {"introduction": "Finally, we expand our toolkit to the grand canonical ensemble, designed for 'open' systems that can exchange not only energy but also particles with a reservoir at fixed temperature $T$ and chemical potential $\\mu$. In this hands-on practice, [@problem_id:1857002], you will analyze a quantum dot model to calculate the average number of electrons it holds. This exercise provides a clear, concrete derivation of the famous Fermi-Dirac distribution, showcasing the power and utility of the grand partition function $\\Xi$.", "problem": "Consider a quantum dot which acts as a small system in contact with a large reservoir of electrons. The reservoir maintains a constant temperature $T$ and chemical potential $\\mu$. The quantum dot has two distinct single-particle energy levels available for electrons, at energies $\\epsilon_1$ and $\\epsilon_2$. Assume that due to the Pauli exclusion principle, each of these two levels can be occupied by at most one electron. The energy of the dot is the sum of the energies of the electrons it contains, and the energy of the empty dot is zero. Let $k_B$ be the Boltzmann constant. Derive an expression for the average number of electrons, $\\langle N \\rangle$, residing on the quantum dot.", "solution": "We use the grand canonical ensemble because the quantum dot (small system) is in contact with a reservoir at fixed temperature $T$ and chemical potential $\\mu$. Let $\\beta = \\frac{1}{k_{B}T}$. For noninteracting single-particle levels subject to the Pauli exclusion principle, each level $i$ has occupation number $n_{i} \\in \\{0,1\\}$ and energy contribution $\\epsilon_{i} n_{i}$. The grand partition function is\n$$\n\\Xi=\\sum_{\\{n_{1},n_{2}\\}} \\exp\\!\\left[-\\beta\\left((\\epsilon_{1}n_{1}+\\epsilon_{2}n_{2})-\\mu(n_{1}+n_{2})\\right)\\right].\n$$\nBecause the levels are independent, this factorizes as\n$$\n\\Xi=\\prod_{i=1}^{2}\\left(\\sum_{n_{i}=0}^{1}\\exp\\!\\left[-\\beta(\\epsilon_{i}-\\mu)n_{i}\\right]\\right)=\\prod_{i=1}^{2}\\left(1+\\exp\\!\\left[-\\beta(\\epsilon_{i}-\\mu)\\right]\\right).\n$$\nIn the grand canonical ensemble, the average particle number is given by\n$$\n\\langle N\\rangle=\\frac{1}{\\beta}\\frac{\\partial \\ln \\Xi}{\\partial \\mu}.\n$$\nCompute $\\ln \\Xi$ and differentiate:\n$$\n\\ln \\Xi=\\sum_{i=1}^{2}\\ln\\!\\left(1+\\exp\\!\\left[\\beta(\\mu-\\epsilon_{i})\\right]\\right),\n$$\n$$\n\\frac{\\partial \\ln \\Xi}{\\partial \\mu}=\\sum_{i=1}^{2}\\frac{\\beta\\,\\exp\\!\\left[\\beta(\\mu-\\epsilon_{i})\\right]}{1+\\exp\\!\\left[\\beta(\\mu-\\epsilon_{i})\\right]}.\n$$\nTherefore,\n$$\n\\langle N\\rangle=\\sum_{i=1}^{2}\\frac{\\exp\\!\\left[\\beta(\\mu-\\epsilon_{i})\\right]}{1+\\exp\\!\\left[\\beta(\\mu-\\epsilon_{i})\\right]}=\\sum_{i=1}^{2}\\frac{1}{1+\\exp\\!\\left[\\beta(\\epsilon_{i}-\\mu)\\right]}.\n$$\nRestoring $\\beta=\\frac{1}{k_{B}T}$ gives\n$$\n\\langle N\\rangle=\\frac{1}{1+\\exp\\!\\left(\\frac{\\epsilon_{1}-\\mu}{k_{B}T}\\right)}+\\frac{1}{1+\\exp\\!\\left(\\frac{\\epsilon_{2}-\\mu}{k_{B}T}\\right)}.\n$$\nThis is the sum of the Fermi–Dirac occupation factors for the two levels.", "answer": "$$\\boxed{\\frac{1}{1+\\exp\\!\\left(\\frac{\\epsilon_{1}-\\mu}{k_{B}T}\\right)}+\\frac{1}{1+\\exp\\!\\left(\\frac{\\epsilon_{2}-\\mu}{k_{B}T}\\right)}}$$", "id": "1857002"}]}