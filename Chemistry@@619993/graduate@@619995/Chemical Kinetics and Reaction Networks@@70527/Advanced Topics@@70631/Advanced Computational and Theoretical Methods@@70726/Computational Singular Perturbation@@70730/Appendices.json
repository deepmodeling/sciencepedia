{"hands_on_practices": [{"introduction": "The cornerstone of model reduction for systems with multiple timescales is the concept of a slow invariant manifold (SIM). While the simplest approximation, the Quasi-Steady State Approximation (QSSA), gives a zeroth-order estimate of this manifold, its accuracy can be limited. This first practice invites you to derive the first-order correction to the QSSA from first principles, providing a more accurate representation of the slow dynamics and laying the theoretical foundation for higher-order Computational Singular Perturbation (CSP) methods. [@problem_id:2634419]", "problem": "Consider a two-species linear reaction network that models a slowly decaying reactant and a fast intermediate, expressed in nondimensional form with a small separation parameter $\\,\\varepsilon \\in (0,1]\\,$. Let $\\,x(t)\\,$ denote the slow variable (reactant) and $\\,y(t)\\,$ denote the fast variable (intermediate). The dynamics are given by the linear time-invariant system\n$$\n\\frac{dx}{dt} \\;=\\; -k_{s}\\,x \\;-\\; k_{c}\\,y, \n\\qquad\n\\varepsilon\\,\\frac{dy}{dt} \\;=\\; k_{c}\\,x \\;-\\; k_{f}\\,y,\n$$\nwith positive parameters $\\,k_{s}0\\,$, $\\,k_{c}0\\,$, and $\\,k_{f}0\\,$. This system arises from mass-action kinetics with one slow consumption channel of $\\,x\\,$ of rate $\\,k_{s}\\,$ and a fast exchange between $\\,x\\,$ and $\\,y\\,$ characterized by $\\,k_{c}\\,$ and $\\,k_{f}\\,$. The Quasi-Steady State (QSS) approximation corresponds to the lowest-order slow invariant manifold $\\,y=h_{0}(x)\\,$ obtained by setting the fast right-hand side to zero.\n\nUsing singular perturbation theory consistent with Computational Singular Perturbation (CSP), construct the slow invariant manifold as a regular expansion $\\,y=h(x;\\varepsilon)=h_{0}(x)+\\varepsilon\\,h_{1}(x)+\\mathcal{O}(\\varepsilon^{2})\\,$ by enforcing invariance under the full dynamics to first order in $\\,\\varepsilon\\,$. Start from fundamental principles, namely mass-action kinetics and the chain rule for invariant manifolds, and derive the condition that determines $\\,h_{0}(x)\\,$ and $\\,h_{1}(x)\\,$ without invoking any prepackaged formula.\n\nReport only the closed-form analytic expression for the first-order correction $\\,h_{1}(x)\\,$ in terms of $\\,x\\,$, $\\,k_{s}\\,$, $\\,k_{c}\\,$, and $\\,k_{f}\\,$. No numerical evaluation is required. The final answer must be a single analytic expression. Do not include units.", "solution": "The problem presented is judged to be valid. It is a well-posed, scientifically grounded problem in the field of chemical kinetics and singular perturbation theory. All necessary data and conditions are provided, and the problem is free of contradictions, ambiguities, or factual unsoundness. We may therefore proceed with the derivation of the solution.\n\nThe system of ordinary differential equations describing the dynamics of the slow variable $x(t)$ and the fast variable $y(t)$ is given by:\n$$\n\\frac{dx}{dt} = f(x, y) = -k_{s}x - k_{c}y\n$$\n$$\n\\varepsilon \\frac{dy}{dt} = g(x, y) = k_{c}x - k_{f}y\n$$\nwhere $k_{s}$, $k_{c}$, and $k_{f}$ are positive rate constants and $\\varepsilon$ is a small, positive parameter, $\\varepsilon \\ll 1$.\n\nWe seek to find the slow invariant manifold, which is a curve $y = h(x; \\varepsilon)$ in the phase space such that any trajectory that starts on this manifold remains on it for all subsequent time. The mathematical expression of this invariance property is that the time evolution of a point $(x(t), y(t))$ on the manifold must be tangent to the manifold at that point. If $y(t) = h(x(t); \\varepsilon)$, then by the chain rule, their time derivatives must be related by:\n$$\n\\frac{dy}{dt} = \\frac{dh(x; \\varepsilon)}{dx} \\frac{dx}{dt}\n$$\nThis is the fundamental invariance condition. We can substitute the expressions for $\\frac{dx}{dt}$ and $\\frac{dy}{dt}$ from the given system dynamics into this condition. From the second equation, we have $\\frac{dy}{dt} = \\frac{1}{\\varepsilon} g(x,y)$, so the invariance condition becomes:\n$$\n\\frac{1}{\\varepsilon} g(x, y) = \\frac{dh}{dx} f(x, y)\n$$\nSubstituting $y = h(x; \\varepsilon)$ into this equation yields the defining functional-differential equation for the invariant manifold $h(x; \\varepsilon)$:\n$$\nk_{c}x - k_{f}h(x; \\varepsilon) = \\varepsilon \\frac{dh(x; \\varepsilon)}{dx} (-k_{s}x - k_{c}h(x; \\varepsilon))\n$$\nThe problem asks for the first-order approximation of this manifold, which we represent as a regular perturbation expansion in $\\varepsilon$:\n$$\nh(x; \\varepsilon) = h_{0}(x) + \\varepsilon h_{1}(x) + \\mathcal{O}(\\varepsilon^{2})\n$$\nThe derivative with respect to $x$ is accordingly:\n$$\n\\frac{dh(x; \\varepsilon)}{dx} = \\frac{dh_{0}(x)}{dx} + \\varepsilon \\frac{dh_{1}(x)}{dx} + \\mathcal{O}(\\varepsilon^{2})\n$$\nWe now substitute these expansions into the invariance equation:\n$$\nk_{c}x - k_{f}(h_{0} + \\varepsilon h_{1} + \\dots) = \\varepsilon \\left(\\frac{dh_{0}}{dx} + \\varepsilon \\frac{dh_{1}}{dx} + \\dots\\right) \\left(-k_{s}x - k_{c}(h_{0} + \\varepsilon h_{1} + \\dots)\\right)\n$$\nTo solve for $h_{0}(x)$ and $h_{1}(x)$, we expand both sides and collect terms of like powers in $\\varepsilon$.\n\nThe left-hand side (LHS) expands to:\n$$\n\\text{LHS} = (k_{c}x - k_{f}h_{0}(x)) - \\varepsilon k_{f}h_{1}(x) + \\mathcal{O}(\\varepsilon^{2})\n$$\nThe right-hand side (RHS) expands to:\n$$\n\\text{RHS} = \\varepsilon \\left(\\frac{dh_{0}}{dx}\\right) (-k_{s}x - k_{c}h_{0}(x)) + \\mathcal{O}(\\varepsilon^{2})\n$$\nEquating the expressions for the LHS and RHS, we obtain:\n$$\n(k_{c}x - k_{f}h_{0}) - \\varepsilon k_{f}h_{1} + \\mathcal{O}(\\varepsilon^{2}) = \\varepsilon \\frac{dh_{0}}{dx}(-k_{s}x - k_{c}h_{0}) + \\mathcal{O}(\\varepsilon^{2})\n$$\nNow we equate the coefficients of corresponding powers of $\\varepsilon$.\n\nAt order $\\mathcal{O}(\\varepsilon^{0})$:\nThe terms independent of $\\varepsilon$ must be equal.\n$$\nk_{c}x - k_{f}h_{0}(x) = 0\n$$\nSolving for $h_{0}(x)$ gives the zeroth-order approximation to the slow manifold, which is the Quasi-Steady State (QSS) approximation:\n$$\nh_{0}(x) = \\frac{k_{c}}{k_{f}}x\n$$\n\nAt order $\\mathcal{O}(\\varepsilon^{1})$:\nThe terms proportional to $\\varepsilon$ must be equal.\n$$\n-k_{f}h_{1}(x) = \\frac{dh_{0}}{dx}(-k_{s}x - k_{c}h_{0}(x))\n$$\nWe have already determined $h_{0}(x)$. We can now find its derivative:\n$$\n\\frac{dh_{0}}{dx} = \\frac{d}{dx}\\left(\\frac{k_{c}}{k_{f}}x\\right) = \\frac{k_{c}}{k_{f}}\n$$\nSubstituting the expressions for $h_{0}(x)$ and $\\frac{dh_{0}}{dx}$ into the $\\mathcal{O}(\\varepsilon^{1})$ equation:\n$$\n-k_{f}h_{1}(x) = \\left(\\frac{k_{c}}{k_{f}}\\right) \\left(-k_{s}x - k_{c}\\left(\\frac{k_{c}}{k_{f}}x\\right)\\right)\n$$\nWe can factor out $x$ on the right-hand side:\n$$\n-k_{f}h_{1}(x) = \\left(\\frac{k_{c}}{k_{f}}\\right) \\left(-k_{s} - \\frac{k_{c}^{2}}{k_{f}}\\right) x\n$$\n$$\n-k_{f}h_{1}(x) = -\\frac{k_{c}}{k_{f}} \\left(k_{s} + \\frac{k_{c}^{2}}{k_{f}}\\right) x\n$$\nNow, we solve for $h_{1}(x)$ by dividing by $-k_{f}$:\n$$\nh_{1}(x) = \\frac{k_{c}}{k_{f}^{2}} \\left(k_{s} + \\frac{k_{c}^{2}}{k_{f}}\\right) x\n$$\nTo present this in a more compact form, we combine the terms inside the parenthesis:\n$$\nh_{1}(x) = \\frac{k_{c}}{k_{f}^{2}} \\left(\\frac{k_{s}k_{f} + k_{c}^{2}}{k_{f}}\\right) x\n$$\n$$\nh_{1}(x) = \\frac{k_{c}(k_{s}k_{f} + k_{c}^{2})}{k_{f}^{3}} x\n$$\nThis is the closed-form analytic expression for the first-order correction, $h_{1}(x)$, to the slow invariant manifold. The full first-order manifold is $y = h_{0}(x) + \\varepsilon h_{1}(x)$. The problem asks only for the expression for $h_{1}(x)$.", "answer": "$$\n\\boxed{\\frac{k_{c}(k_{s}k_{f} + k_{c}^{2})}{k_{f}^{3}} x}\n$$", "id": "2634419"}, {"introduction": "Moving from analytical theory to computational practice, this exercise demonstrates how to implement the core CSP algorithm for correcting a state that is off the slow manifold. You will work with the fundamental objects of CSP: the fast and slow basis vectors derived from the system's Jacobian, which allow us to decompose the dynamics. By solving for a correction in the direction of the fast subspace, you will gain hands-on experience with the machinery that allows CSP to systematically refine approximate solutions. [@problem_id:2634392]", "problem": "Consider a dimensionless, linear mass-action kinetic network with two species, where a reversible, fast interconversion is coupled to a slow, irreversible sink:\n- Species $X$ and $Y$ interconvert rapidly: $X \\rightleftharpoons Y$ with forward and backward rate constants $k_1 = 1/\\varepsilon$ and $k_2 = 1/\\varepsilon$, respectively.\n- Species $Y$ decays slowly: $Y \\rightarrow \\varnothing$ with rate constant $k_3 = 1$.\n\nLet the state be $y = [x,\\, y]^\\top \\in \\mathbb{R}^2$ denoting the concentrations of $X$ and $Y$, respectively. By the law of mass action, the system of ordinary differential equations is\n$$\n\\frac{d}{dt}\\begin{bmatrix} x \\\\ y \\end{bmatrix}\n=\n\\begin{bmatrix}\n-\\frac{1}{\\varepsilon}  \\frac{1}{\\varepsilon} \\\\\n\\frac{1}{\\varepsilon}  -\\frac{1}{\\varepsilon}-1\n\\end{bmatrix}\n\\begin{bmatrix} x \\\\ y \\end{bmatrix}\n\\equiv J(\\varepsilon)\\, y,\n$$\nwhere $J(\\varepsilon)$ is the Jacobian matrix (constant for this linear system), $\\varepsilon \\in (0,\\infty)$ is a dimensionless stiffness parameter, and all variables and parameters are dimensionless. Define the reaction vector field $f(y;\\varepsilon) = J(\\varepsilon)\\, y$.\n\nComputational Singular Perturbation (CSP) constructs a bi-orthogonal fast-slow basis from instantaneous left and right modes. Let $A^f \\in \\mathbb{R}^{2\\times 1}$ be a column basis for the one-dimensional fast subspace and $B^f \\in \\mathbb{R}^{1\\times 2}$ be the corresponding left (row) basis, chosen such that $B^f A^f = 1$. For this system, one may obtain $A^f$ and $B^f$ from the right and left eigenvectors of $J(\\varepsilon)$ associated with the fast eigenvalue (the one with the more negative real part), normalized to satisfy $B^f A^f = 1$.\n\nThe first-order CSP correction to the slow manifold at a given state $y$ seeks a displacement along fast directions, $\\delta y = A^f \\eta$, that cancels the fast component of the residual to first order. The correction amplitude $\\eta \\in \\mathbb{R}$ is defined by the linear equation\n$$\nB^f f(y;\\varepsilon) + B^f J(\\varepsilon)\\, A^f \\, \\eta = 0,\n$$\nto be solved for $\\eta$, after which the corrected state is $y_{\\text{corr}} = y + \\delta y = y + A^f \\eta$.\n\nYour task is to implement a program that, for each test case below, computes the first-order CSP correction $\\delta y = A^f \\eta$ at the provided state and reports the Euclidean norm $\\|\\delta y\\|_2$. All computations are to be carried out in dimensionless form; no physical units are required.\n\nFundamental bases and definitions to use:\n- Law of mass action for linear reactions to derive $f(y;\\varepsilon) = J(\\varepsilon)\\, y$.\n- Jacobian $J(\\varepsilon)$ as given above.\n- Fast and slow CSP subspaces obtained from left and right eigenvectors of $J(\\varepsilon)$, with $B^f A^f = 1$.\n- First-order CSP correction defined by $B^f f + B^f J A^f \\eta = 0$.\n\nAlgorithmic requirements:\n- For each test case, compute $J(\\varepsilon)$, its right and left eigenpairs, select the fast eigenpair (eigenvalue with the more negative real part), construct $A^f$ and $B^f$ normalized to $B^f A^f = 1$, evaluate $f(y;\\varepsilon)$, solve for $\\eta$ from $B^f f + B^f J A^f \\eta = 0$, form $\\delta y = A^f \\eta$, and return $\\|\\delta y\\|_2$.\n- Treat any small imaginary parts from numerical eigensolvers by taking real parts when they are within numerical tolerance.\n\nTest suite:\n- Case $1$: $\\varepsilon = 10^{-3}$, initial state $y = [1.0,\\, 0.5]^\\top$.\n- Case $2$: $\\varepsilon = 10^{-2}$, initial state $y = [2.0,\\, 2.1]^\\top$.\n- Case $3$: $\\varepsilon = 10^{-4}$, initial state $y = [1.2,\\, 1.2]^\\top$.\n- Case $4$: $\\varepsilon = 10^{-6}$, initial state $y = [0.1,\\, 0.9]^\\top$.\n- Case $5$: $\\varepsilon = 10^{-1}$, initial state $y = [3.0,\\, 1.0]^\\top$.\n\nFinal output format:\nYour program should produce a single line of output containing a Python-style list of the five floating-point results, in the same order as the test suite, i.e., a single line of the form\n[res1,res2,res3,res4,res5]\nwith no additional text or whitespace constraints beyond comma separation and enclosing brackets.", "solution": "The problem as stated is valid. It presents a clear, mathematically precise, and scientifically grounded task within the domain of computational chemical kinetics and stiff dynamical systems. All necessary definitions, parameters, and conditions are provided, and there are no internal contradictions or factual inaccuracies. The problem is a standard application of Computational Singular Perturbation (CSP) theory.\n\nWe proceed to derive the solution. The governing equation for the system is the linear ordinary differential equation (ODE) $\\frac{d}{dt}y = J(\\varepsilon)y$, where $y \\in \\mathbb{R}^2$ is the state vector of concentrations and $J(\\varepsilon)$ is the constant Jacobian matrix:\n$$\nJ(\\varepsilon) =\n\\begin{bmatrix}\n-\\frac{1}{\\varepsilon}  \\frac{1}{\\varepsilon} \\\\\n\\frac{1}{\\varepsilon}  -\\frac{1}{\\varepsilon}-1\n\\end{bmatrix}\n$$\nA critical observation is that $J(\\varepsilon)$ is a real symmetric matrix, i.e., $J(\\varepsilon) = J(\\varepsilon)^\\top$. This implies that its eigenvalues are real and its eigenvectors form an orthogonal basis. The left eigenvectors are simply the transposes of the right eigenvectors.\n\nThe problem requires the computation of the first-order CSP correction $\\delta y = A^f \\eta$. The correction amplitude $\\eta$ is determined by the equation:\n$$\nB^f f(y;\\varepsilon) + B^f J(\\varepsilon)\\, A^f \\, \\eta = 0\n$$\nwhere $f(y;\\varepsilon) = J(\\varepsilon)y$. Substituting this into the equation gives:\n$$\nB^f J(\\varepsilon) y + B^f J(\\varepsilon)\\, A^f \\, \\eta = 0\n$$\nThe basis vectors $A^f$ and $B^f$ are derived from the right and left eigenvectors, respectively, associated with the fast eigenvalue $\\lambda^f$. By definition, $A^f$ is a right eigenvector, so $J(\\varepsilon)A^f = \\lambda^f A^f$. Similarly, $B^f$ is a left eigenvector, so $B^f J(\\varepsilon) = \\lambda^f B^f$.\n\nSubstituting these properties into the equation for $\\eta$:\n$$\n(\\lambda^f B^f) y + B^f (\\lambda^f A^f) \\eta = 0\n$$\nSince $\\lambda^f$ is a scalar, we can factor it out:\n$$\n\\lambda^f (B^f y) + \\lambda^f (B^f A^f) \\eta = 0\n$$\nFor a stiff system, the fast eigenvalue $\\lambda^f$ is large and negative, so it is non-zero. We can divide the entire equation by $\\lambda^f$:\n$$\nB^f y + (B^f A^f) \\eta = 0\n$$\nThe problem specifies the normalization condition $B^f A^f = 1$. Applying this, the equation simplifies dramatically to:\n$$\nB^f y + \\eta = 0 \\implies \\eta = -B^f y\n$$\nThis elegant result for $\\eta$ is general for any system where the CSP correction is defined in this manner.\n\nNow we must construct the bases $A^f$ and $B^f$. Let $v_f$ be a right eigenvector of $J(\\varepsilon)$ corresponding to the fast eigenvalue $\\lambda^f$, as computed by a standard numerical library. Typically, such libraries return eigenvectors normalized to have a Euclidean norm of $1$, i.e., $\\|v_f\\|_2 = 1$.\nSince $J(\\varepsilon)$ is symmetric, the corresponding left eigenvector is $v_f^\\top$. We can therefore choose our bases as:\n- $A^f = v_f$ (a column vector)\n- $B^f = v_f^\\top$ (a row vector)\n\nLet us verify the normalization: $B^f A^f = v_f^\\top v_f = \\|v_f\\|_2^2 = 1^2 = 1$. The condition is satisfied.\nWith these definitions, the correction amplitude is $\\eta = -B^f y = -v_f^\\top y$.\nThe correction vector itself is $\\delta y = A^f \\eta = v_f (-v_f^\\top y) = -(v_f^\\top y) v_f$.\n\nThe task is to compute the Euclidean norm of this correction, $\\|\\delta y\\|_2$:\n$$\n\\|\\delta y\\|_2 = \\| -(v_f^\\top y) v_f \\|_2 = |-(v_f^\\top y)| \\cdot \\|v_f\\|_2\n$$\nSince $\\|v_f\\|_2 = 1$, the final expression for the required quantity is:\n$$\n\\|\\delta y\\|_2 = |v_f^\\top y|\n$$\nThis means the norm of the correction is simply the absolute value of the projection of the current state vector $y$ onto the fast eigenvector $v_f$.\n\nThe algorithm to be implemented is as follows:\n1. For each test case, comprised of a parameter $\\varepsilon$ and a state vector $y$, construct the Jacobian matrix $J(\\varepsilon)$.\n2. Compute the eigenvalues and eigenvectors of the symmetric matrix $J(\\varepsilon)$.\n3. Identify the fast eigenvalue $\\lambda^f$ as the most negative eigenvalue.\n4. Select the corresponding normalized right eigenvector, $v_f$.\n5. Calculate the dot product of $v_f$ and $y$.\n6. The result is the absolute value of this dot product, $|v_f \\cdot y|$.\n\nThis procedure will be encoded in the final program.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Computes the norm of the first-order CSP correction for a given\n    linear kinetic system.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [\n        (1e-3, np.array([1.0, 0.5])),\n        (1e-2, np.array([2.0, 2.1])),\n        (1e-4, np.array([1.2, 1.2])),\n        (1e-6, np.array([0.1, 0.9])),\n        (1e-1, np.array([3.0, 1.0])),\n    ]\n\n    results = []\n    for case in test_cases:\n        eps, y_state = case\n\n        # 1. Construct the Jacobian matrix J(eps)\n        inv_eps = 1.0 / eps\n        J = np.array([\n            [-inv_eps, inv_eps],\n            [inv_eps, -inv_eps - 1.0]\n        ])\n\n        # 2. Compute eigenvalues and eigenvectors of J.\n        # For a real symmetric matrix, eigenvalues are real and eigenvectors\n        # form an orthonormal basis. numpy.linalg.eig returns normalized\n        # eigenvectors in the columns of the `eigvecs` matrix.\n        eigvals, eigvecs = np.linalg.eig(J)\n\n        # 3. Identify the fast eigenvalue and its corresponding eigenvector.\n        # The fast mode corresponds to the eigenvalue with the most negative\n        # real part. For this system, all eigenvalues are real and negative.\n        fast_idx = np.argmin(eigvals)\n        v_f = eigvecs[:, fast_idx]\n\n        # 4. Calculate the norm of the CSP correction, ||delta_y||_2.\n        # As derived in the solution, for a symmetric Jacobian and normalized\n        # eigenvectors, this simplifies to |v_f^T * y|.\n        norm_delta_y = np.abs(np.dot(v_f, y_state))\n        \n        results.append(norm_delta_y)\n\n    # Final print statement in the exact required format.\n    # The format string ensures standard float representation.\n    print(f\"[{','.join(f'{r:.15g}' for r in results)}]\")\n\nsolve()\n```", "id": "2634392"}, {"introduction": "This final practice integrates the preceding concepts into a complete model reduction workflow for a nonlinear system, demonstrating the practical payoff of CSP. You will construct both a basic zero-order (QSSA) model and an improved first-order CSP-corrected model. By numerically simulating these reduced models and comparing their trajectories against the full, unreduced system, you will quantitatively assess the improvement in accuracy offered by the first-order correction, solidifying your understanding of why and when these advanced techniques are valuable. [@problem_id:2634446]", "problem": "Implement a complete program that, for a specified two-species nonlinear reaction network with a clear slow-fast structure, constructs zero-order and first-order Computational Singular Perturbation (CSP) slow manifolds, projects the dynamics onto these manifolds to obtain reduced one-dimensional dynamics, and quantitatively compares the resulting trajectories to the full two-dimensional dynamics over one slow timescale. All concentrations and time are nondimensional. The program must use only the Python standard library, NumPy, and SciPy as specified in the execution environment.\n\nThe network is defined by two species, denoted by $x$ (slow) and $y$ (fast), with governing equations\n$$\n\\frac{dx}{dt} = \\varepsilon \\, f(x,y), \\quad \\frac{dy}{dt} = g(x,y),\n$$\nwhere $\\varepsilon$ is a small positive parameter. The functions $f$ and $g$ are derived from mass-action kinetics for the following schematic network: a slow inflow and decay of $x$ and a fast reversible interconversion between $x$ and $y$ together with a nonlinear quadratic sink of $y$ and a linear decay of $y$. Concretely, let\n$$\nf(x,y) = s - d \\, x - k_f \\, x + k_b \\, y,\n$$\n$$\ng(x,y) = k_f \\, x - k_b \\, y - 2 k_2 \\, y^2 - k_3 \\, y,\n$$\nwith parameters $s, d, k_f, k_b, k_2, k_3  0$. This yields a standard Computational Singular Perturbation (CSP) setup of the form $\\dot{x} = \\varepsilon f(x,y)$, $\\dot{y} = g(x,y)$.\n\nYour tasks are:\n- Use the foundational principles of mass-action kinetics (with rate expressions of the form $k \\, \\prod c_i^{\\nu_i}$ for concentration $c_i$ and stoichiometric coefficient $\\nu_i$) and the invariance condition for slow manifolds to construct the zero-order and first-order CSP manifolds. The zero-order manifold $y = h_0(x)$ is defined by the quasi-steady-state condition for the fast variable,\n$$\ng(x,h_0(x)) = 0.\n$$\nGiven the quadratic nonlinearity in $y$, explicitly solve for $h_0(x)$ by solving $2 k_2 \\, y^2 + (k_b+k_3) \\, y - k_f \\, x = 0$ and choosing the nonnegative root,\n$$\nh_0(x) = \\frac{- (k_b + k_3) + \\sqrt{(k_b + k_3)^2 + 8 \\, k_2 \\, k_f \\, x}}{4 \\, k_2}.\n$$\n- Derive the first-order correction $h_1(x)$ using the invariance condition. The invariance condition states that along the slow manifold $y=h(x,\\varepsilon)$, one must have $g(x,h(x,\\varepsilon)) = \\varepsilon \\, h'(x,\\varepsilon) \\, f(x,h(x,\\varepsilon))$. With the expansion $h(x,\\varepsilon) = h_0(x) + \\varepsilon h_1(x) + \\mathcal{O}(\\varepsilon^2)$ and denoting $g_y = \\partial g / \\partial y$ and $g_x = \\partial g / \\partial x$, the order $\\varepsilon^0$ condition yields $g(x,h_0(x))=0$, and differentiating implicitly gives $h_0'(x) = - g_x(x,h_0(x)) / g_y(x,h_0(x))$. The order $\\varepsilon^1$ condition yields\n$$\ng_y(x,h_0(x)) \\, h_1(x) = h_0'(x) \\, f(x,h_0(x)),\n$$\nhence\n$$\nh_1(x) = \\frac{h_0'(x) \\, f(x,h_0(x))}{g_y(x,h_0(x))}.\n$$\nFor this network, compute $g_x(x,y) = k_f$ and $g_y(x,y) = -k_b - k_3 - 4 k_2 \\, y$, so that $h_0'(x) = \\dfrac{k_f}{k_b + k_3 + 4 k_2 \\, h_0(x)}$ and then $h_1(x)$ follows from the formula above.\n\n- Define the reduced one-dimensional slow dynamics obtained by substituting the manifold approximations into the slow equation:\n  - Zero-order CSP reduced dynamics: $\\dfrac{dx}{dt} = \\varepsilon \\, f\\!\\left(x, h_0(x)\\right)$ with $y(t) = h_0(x(t))$.\n  - First-order CSP reduced dynamics: $\\dfrac{dx}{dt} = \\varepsilon \\, f\\!\\left(x, h_0(x) + \\varepsilon \\, h_1(x)\\right)$ with $y(t) = h_0(x(t)) + \\varepsilon \\, h_1(x(t))$.\n\n- For each parameter set given in the test suite below, perform the following numerical experiment:\n  1. Integrate the full two-dimensional system from the specified initial condition $(x(0),y(0))$ over the time interval $[0, T]$ with $T = 1/\\varepsilon$.\n  2. Integrate the zero-order reduced one-dimensional system over the same time interval, starting from $x(0)$ equal to the same initial $x(0)$ as the full system, and reconstruct $y(t)$ from the manifold relation $y=h_0(x(t))$.\n  3. Integrate the first-order reduced one-dimensional system over the same time interval, starting from $x(0)$ equal to the same initial $x(0)$, and reconstruct $y(t)$ from $y=h_0(x(t))+\\varepsilon h_1(x(t))$.\n  4. On a common time grid spanning $[0,T]$, compute the maximum-in-time Euclidean norm of the concentration error between each reduced trajectory and the full trajectory,\n  $$\n  e_0 = \\max_{t \\in [0,T]} \\left\\| \\begin{bmatrix} x_{\\text{red},0}(t) - x_{\\text{full}}(t) \\\\ y_{\\text{red},0}(t) - y_{\\text{full}}(t) \\end{bmatrix} \\right\\|_2, \\quad\n  e_1 = \\max_{t \\in [0,T]} \\left\\| \\begin{bmatrix} x_{\\text{red},1}(t) - x_{\\text{full}}(t) \\\\ y_{\\text{red},1}(t) - y_{\\text{full}}(t) \\end{bmatrix} \\right\\|_2.\n  $$\n  5. Report, for each test case, the triple $[e_0, e_1, \\text{improved}]$, where $\\text{improved}$ is a boolean that is true if and only if $e_1  e_0$.\n\nTest suite:\n- Case $1$: $\\varepsilon = 0.02$, $k_f = 5.0$, $k_b = 1.0$, $k_2 = 2.0$, $k_3 = 0.5$, $s = 1.0$, $d = 0.1$, initial $(x(0),y(0)) = (0.5, 0.05)$.\n- Case $2$: $\\varepsilon = 0.005$, $k_f = 6.0$, $k_b = 1.0$, $k_2 = 4.0$, $k_3 = 0.2$, $s = 0.8$, $d = 0.05$, initial $(x(0),y(0)) = (0.3, 0.9)$.\n- Case $3$: $\\varepsilon = 0.02$, $k_f = 3.0$, $k_b = 1.0$, $k_2 = 0.1$, $k_3 = 0.4$, $s = 0.5$, $d = 0.05$, initial $(x(0),y(0)) = (0.4, 0.1)$.\n- Case $4$: $\\varepsilon = 0.10$, $k_f = 4.0$, $k_b = 1.2$, $k_2 = 1.5$, $k_3 = 0.6$, $s = 1.2$, $d = 0.2$, initial $(x(0),y(0)) = (0.6, 0.2)$.\n\nNumerical requirements:\n- Use an implicit stiff solver appropriate for stiff dynamics (for example, a backward differentiation formula) for the full two-dimensional system, and any suitable accurate integrator for the reduced systems. Use a uniform time grid on $[0,T]$ for error evaluation with at least $200$ points.\n- All computations are nondimensional; no physical units are required.\n\nFinal output format:\n- Your program should produce a single line of output containing the results for all test cases as a comma-separated list enclosed in square brackets, where each test case result is itself a list of the form $[e_0, e_1, \\text{improved}]$. For example, an output with two cases would look like $[[0.1,0.05,True],[0.2,0.18,True]]$.", "solution": "We begin with a two-species system in standard slow-fast form,\n$$\n\\frac{dx}{dt} = \\varepsilon \\, f(x,y), \\quad \\frac{dy}{dt} = g(x,y),\n$$\nwhere $\\varepsilon$ is small and positive, so that $x$ evolves on a slow timescale and $y$ relaxes rapidly. The functions $f$ and $g$ arise from mass-action kinetics, a foundational principle stating that reaction rates have the form $k \\, \\prod c_i^{\\nu_i}$, where $k$ is a rate constant, $c_i$ are species concentrations, and $\\nu_i$ are stoichiometric exponents. The chosen network yields\n$$\nf(x,y) = s - d \\, x - k_f \\, x + k_b \\, y,\n$$\n$$\ng(x,y) = k_f \\, x - k_b \\, y - 2 k_2 \\, y^2 - k_3 \\, y,\n$$\nwith positive rate parameters $s, d, k_f, k_b, k_2, k_3$.\n\nComputational Singular Perturbation (CSP) approximates the slow invariant manifold on which the fast dynamics is equilibrated, using an asymptotic expansion in $\\varepsilon$. The invariance condition for a manifold $y=h(x,\\varepsilon)$ states that the vector field evaluated at points on the manifold is tangent to the manifold graph:\n$$\n\\frac{dy}{dt} = \\frac{d}{dt} h(x,\\varepsilon) = \\frac{\\partial h}{\\partial x}(x,\\varepsilon) \\, \\frac{dx}{dt},\n$$\nand since on the manifold $\\dfrac{dx}{dt} = \\varepsilon f(x,h(x,\\varepsilon))$ and $\\dfrac{dy}{dt} = g(x,h(x,\\varepsilon))$, the invariance condition becomes\n$$\ng(x,h(x,\\varepsilon)) = \\varepsilon \\, h'(x,\\varepsilon) \\, f(x,h(x,\\varepsilon)).\n$$\nWe seek an asymptotic expansion $h(x,\\varepsilon) = h_0(x) + \\varepsilon h_1(x) + \\mathcal{O}(\\varepsilon^2)$, and substitute into the invariance condition. Expanding the left-hand side to order $\\varepsilon$ gives\n$$\ng(x,h_0(x) + \\varepsilon h_1(x)) = g(x,h_0(x)) + \\varepsilon \\, g_y(x,h_0(x)) \\, h_1(x) + \\mathcal{O}(\\varepsilon^2),\n$$\nwhere $g_y = \\partial g / \\partial y$. The right-hand side to order $\\varepsilon$ is\n$$\n\\varepsilon \\, h'(x,\\varepsilon) \\, f(x,h(x,\\varepsilon)) = \\varepsilon \\, h_0'(x) \\, f(x,h_0(x)) + \\mathcal{O}(\\varepsilon^2).\n$$\nEquating orders of $\\varepsilon$ yields:\n- Order $\\varepsilon^0$: $g(x,h_0(x)) = 0$, which defines the zero-order slow manifold $h_0$ as the quasi-steady-state for the fast dynamics.\n- Order $\\varepsilon^1$: $g_y(x,h_0(x)) \\, h_1(x) = h_0'(x) \\, f(x,h_0(x))$, which determines the first-order correction $h_1(x)$ once $h_0$ is known and differentiable.\n\nFor the specific $g(x,y)$ given, $g(x,y) = k_f x - k_b y - 2 k_2 y^2 - k_3 y$, the zero-order manifold solves\n$$\n2 k_2 \\, y^2 + (k_b + k_3) \\, y - k_f \\, x = 0,\n$$\nwhich yields\n$$\nh_0(x) = \\frac{- (k_b + k_3) + \\sqrt{(k_b + k_3)^2 + 8 k_2 k_f x}}{4 k_2},\n$$\nselecting the nonnegative root. Differentiating the identity $g(x,h_0(x)) \\equiv 0$ with respect to $x$ gives\n$$\ng_x(x,h_0(x)) + g_y(x,h_0(x)) \\, h_0'(x) = 0 \\quad \\Rightarrow \\quad h_0'(x) = -\\frac{g_x(x,h_0(x))}{g_y(x,h_0(x))},\n$$\nand here $g_x(x,y) = k_f$ and $g_y(x,y) = -k_b - k_3 - 4 k_2 y$, so\n$$\nh_0'(x) = \\frac{k_f}{k_b + k_3 + 4 k_2 \\, h_0(x)}.\n$$\nThe first-order correction then follows from the order $\\varepsilon^1$ condition:\n$$\nh_1(x) = \\frac{h_0'(x) \\, f(x,h_0(x))}{g_y(x,h_0(x))}.\n$$\n\nTo assess the fidelity of these manifolds in reproducing the full dynamics over one slow timescale, define $T = 1/\\varepsilon$. We compare:\n- The full trajectory $(x_{\\text{full}}(t), y_{\\text{full}}(t))$ solving the two-dimensional system from the given initial condition $(x(0),y(0))$ over $t \\in [0,T]$.\n- The zero-order reduced trajectory $(x_{\\text{red},0}(t), y_{\\text{red},0}(t))$ solving $\\dot{x} = \\varepsilon f(x,h_0(x))$ with $x(0)$ matching the full system's initial $x(0)$ and $y_{\\text{red},0}(t) = h_0(x_{\\text{red},0}(t))$.\n- The first-order reduced trajectory $(x_{\\text{red},1}(t), y_{\\text{red},1}(t))$ solving $\\dot{x} = \\varepsilon f(x,h_0(x)+\\varepsilon h_1(x))$ with $x(0)$ matching the full system's initial $x(0)$ and $y_{\\text{red},1}(t) = h_0(x_{\\text{red},1}(t)) + \\varepsilon h_1(x_{\\text{red},1}(t))$.\n\nOn a uniform grid of times in $[0,T]$, we compute the maximum Euclidean concentration error over the interval,\n$$\ne_0 = \\max_{t \\in [0,T]} \\left\\| \\begin{bmatrix} x_{\\text{red},0}(t) - x_{\\text{full}}(t) \\\\ y_{\\text{red},0}(t) - y_{\\text{full}}(t) \\end{bmatrix} \\right\\|_2, \\quad\ne_1 = \\max_{t \\in [0,T]} \\left\\| \\begin{bmatrix} x_{\\text{red},1}(t) - x_{\\text{full}}(t) \\\\ y_{\\text{red},1}(t) - y_{\\text{full}}(t) \\end{bmatrix} \\right\\|_2.\n$$\nWe then output $[e_0, e_1, \\text{improved}]$ for each case, where $\\text{improved}$ is true if $e_1  e_0$.\n\nAlgorithmic design:\n- Construct $h_0(x)$ explicitly via the quadratic formula to satisfy $g(x,h_0(x))=0$.\n- Compute $h_0'(x)$ via implicit differentiation as $h_0'(x) = - g_x / g_y$, using the known partial derivatives.\n- Compute $h_1(x)$ via $h_1(x) = h_0'(x) f(x,h_0(x)) / g_y(x,h_0(x))$.\n- Integrate the full two-dimensional system with a stiff solver, such as a backward differentiation formula, to handle the rapidly relaxing $y$ dynamics.\n- Integrate the one-dimensional reduced dynamics for both zero-order and first-order approximations. Reconstruct $y$ along each reduced trajectory from the corresponding manifold relation.\n- Evaluate the maximum Euclidean error on a uniform time grid over $[0,T]$ for each reduced trajectory compared to the full trajectory.\n- Assemble and print the results as specified.\n\nThe provided test suite includes four parameter sets probing different aspects: a typical stiff case, a more extreme stiffness with stronger nonlinearity, a near-linear fast dynamics case with small quadratic nonlinearity, and a borderline case with larger $\\varepsilon$. The boolean indicator reveals whether the first-order CSP manifold improves the approximation over the zero-order manifold in each scenario.\n\nAll quantities are nondimensional, so no physical units are involved. The final output is a single line containing a Python-like list of lists, one per test case, each holding two floating-point errors and one boolean as described.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.integrate import solve_ivp\n\ndef make_params(eps, kf, kb, k2, k3, s, d, x0, y0):\n    return {\n        \"eps\": float(eps),\n        \"kf\": float(kf),\n        \"kb\": float(kb),\n        \"k2\": float(k2),\n        \"k3\": float(k3),\n        \"s\": float(s),\n        \"d\": float(d),\n        \"x0\": float(x0),\n        \"y0\": float(y0),\n    }\n\ndef f_slow(x, y, p):\n    return p[\"s\"] - p[\"d\"] * x - p[\"kf\"] * x + p[\"kb\"] * y\n\ndef g_fast(x, y, p):\n    return p[\"kf\"] * x - p[\"kb\"] * y - 2.0 * p[\"k2\"] * y * y - p[\"k3\"] * y\n\ndef h0(x, p):\n    # Solve 2*k2*y^2 + (kb+k3)*y - kf*x = 0 for nonnegative y\n    a = 2.0 * p[\"k2\"]\n    b = p[\"kb\"] + p[\"k3\"]\n    disc = b * b + 8.0 * p[\"k2\"] * p[\"kf\"] * x\n    # Numerical safety: ensure nonnegative discriminant\n    disc = max(disc, 0.0)\n    y = (-b + np.sqrt(disc)) / (2.0 * a)\n    return y\n\ndef g_x(p):\n    return p[\"kf\"]\n\ndef g_y_at(x, y, p):\n    return -p[\"kb\"] - p[\"k3\"] - 4.0 * p[\"k2\"] * y\n\ndef h0_prime(x, p):\n    y = h0(x, p)\n    gy = g_y_at(x, y, p)\n    # h0' = -g_x / g_y\n    return -g_x(p) / gy\n\ndef h1(x, p):\n    y0 = h0(x, p)\n    gy = g_y_at(x, y0, p)\n    h0p = h0_prime(x, p)\n    f0 = f_slow(x, y0, p)\n    return (h0p * f0) / gy\n\ndef full_system_rhs(t, z, p):\n    x, y = z\n    dxdt = p[\"eps\"] * f_slow(x, y, p)\n    dydt = g_fast(x, y, p)\n    return [dxdt, dydt]\n\ndef reduced_zero_rhs(t, x, p):\n    # dx/dt = eps * f(x, h0(x))\n    return p[\"eps\"] * f_slow(x, h0(x, p), p)\n\ndef reduced_first_rhs(t, x, p):\n    # dx/dt = eps * f(x, h0(x) + eps * h1(x))\n    y_approx = h0(x, p) + p[\"eps\"] * h1(x, p)\n    return p[\"eps\"] * f_slow(x, y_approx, p)\n\ndef integrate_full(p, T, t_eval):\n    z0 = [p[\"x0\"], p[\"y0\"]]\n    sol = solve_ivp(\n        fun=lambda t, z: full_system_rhs(t, z, p),\n        t_span=(0.0, T),\n        y0=z0,\n        method=\"BDF\",\n        t_eval=t_eval,\n        rtol=1e-10,\n        atol=1e-12,\n    )\n    if not sol.success:\n        raise RuntimeError(\"Full system integration failed: \" + sol.message)\n    return sol.t, sol.y[0, :], sol.y[1, :]\n\ndef integrate_reduced(rhs, p, T, t_eval):\n    x0 = p[\"x0\"]\n    sol = solve_ivp(\n        fun=lambda t, x: rhs(t, x, p),\n        t_span=(0.0, T),\n        y0=[x0],\n        method=\"BDF\",\n        t_eval=t_eval,\n        rtol=1e-12,\n        atol=1e-14,\n    )\n    if not sol.success:\n        raise RuntimeError(\"Reduced system integration failed: \" + sol.message)\n    return sol.t, sol.y[0, :]\n\ndef max_traj_error(xr, yr, xf, yf):\n    # Compute max over time of Euclidean norm error between reduced and full trajectories\n    dx = xr - xf\n    dy = yr - yf\n    errs = np.sqrt(dx * dx + dy * dy)\n    return float(np.max(errs))\n\ndef run_case(p):\n    # Define slow timescale horizon\n    T = 1.0 / p[\"eps\"]\n    # Time grid for error evaluation\n    n_points = 401  # dense enough while efficient\n    t_eval = np.linspace(0.0, T, n_points)\n\n    # Integrate full system\n    t_full, x_full, y_full = integrate_full(p, T, t_eval)\n\n    # Integrate zero-order reduced system and reconstruct y\n    t0, x0 = integrate_reduced(reduced_zero_rhs, p, T, t_eval)\n    y0 = np.array([h0(x, p) for x in x0])\n\n    # Integrate first-order reduced system and reconstruct y\n    t1, x1 = integrate_reduced(reduced_first_rhs, p, T, t_eval)\n    y1 = np.array([h0(x, p) + p[\"eps\"] * h1(x, p) for x in x1])\n\n    # Compute errors (ensure time grids align)\n    assert np.allclose(t_full, t0) and np.allclose(t_full, t1)\n    e0 = max_traj_error(x0, y0, x_full, y_full)\n    e1 = max_traj_error(x1, y1, x_full, y_full)\n    improved = e1  e0\n    return [e0, e1, improved]\n\ndef solve():\n    # Define the test cases from the problem statement.\n    test_cases = [\n        make_params(eps=0.02, kf=5.0, kb=1.0, k2=2.0, k3=0.5, s=1.0, d=0.1, x0=0.5, y0=0.05),\n        make_params(eps=0.005, kf=6.0, kb=1.0, k2=4.0, k3=0.2, s=0.8, d=0.05, x0=0.3, y0=0.9),\n        make_params(eps=0.02, kf=3.0, kb=1.0, k2=0.1, k3=0.4, s=0.5, d=0.05, x0=0.4, y0=0.1),\n        make_params(eps=0.10, kf=4.0, kb=1.2, k2=1.5, k3=0.6, s=1.2, d=0.2, x0=0.6, y0=0.2),\n    ]\n\n    results = []\n    for p in test_cases:\n        res = run_case(p)\n        # Convert floats to a reasonable precision for stable output\n        e0, e1, improved = res\n        e0_out = float(np.float64(e0))\n        e1_out = float(np.float64(e1))\n        results.append([e0_out, e1_out, improved])\n\n    # Final print statement in the exact required format.\n    # Ensure booleans are represented as True/False without quotes.\n    def elem_to_str(elem):\n        if isinstance(elem, bool):\n            return \"True\" if elem else \"False\"\n        if isinstance(elem, float):\n            # Format with repr to avoid scientific notation ambiguity while keeping precision\n            return repr(elem)\n        if isinstance(elem, int):\n            return str(elem)\n        if isinstance(elem, list):\n            return \"[\" + \",\".join(elem_to_str(e) for e in elem) + \"]\"\n        return str(elem)\n\n    print(\"[\" + \",\".join(elem_to_str(r) for r in results) + \"]\")\n\nif __name__ == \"__main__\":\n    solve()\n```", "id": "2634446"}]}