{"hands_on_practices": [{"introduction": "The Jarzynski equality provides a powerful bridge between equilibrium free energies and nonequilibrium work. This first practice focuses on the crucial near-equilibrium regime, where many real-world processes occur. By performing a cumulant expansion of the equality, you will derive a fundamental result that directly links the average dissipated work, $\\langle W \\rangle - \\Delta F$, to the fluctuations in the work, $\\mathrm{Var}(W)$ [@problem_id:2659538]. This derivation solidifies the connection to the fluctuation-dissipation theorem and provides deep insight into how microscopic fluctuations govern macroscopic energy loss.", "problem": "An isothermal, well-stirred chemical reaction network is driven out of equilibrium by a time-dependent protocol $\\lambda(t)$ that modulates the chemical work conjugate to a chemostatted species. The system is initially equilibrated at inverse temperature $\\beta = 1/(k_{B}T)$ with respect to the Hamiltonian at $\\lambda(0)$, and the protocol is executed over a finite duration to $\\lambda(\\tau)$. Let $W$ denote the stochastic work performed on the system during a single realization of the protocol, and let $\\Delta F$ denote the corresponding equilibrium Helmholtz free energy difference between the states at $\\lambda(0)$ and $\\lambda(\\tau)$. Assume that the nonequilibrium work relation $\\langle \\exp(-\\beta W)\\rangle=\\exp(-\\beta \\Delta F)$ holds.\n\nStarting from the nonequilibrium work relation and only using the definition of the cumulant generating function $K_{W}(t)=\\ln \\langle \\exp(t W)\\rangle$ and the identification of the first two cumulants with the mean and variance, perform a cumulant expansion of $K_{W}(-\\beta)$ to order $\\beta^{2}$. Working consistently to order $\\beta^{2}$, derive an expression that relates the dissipated work $W_{\\mathrm{diss}}=\\langle W\\rangle-\\Delta F$ to the variance of $W$. State explicitly the approximation you make regarding higher cumulants.\n\nWhat is the resulting analytic expression for $W_{\\mathrm{diss}}$ to order $\\beta^{2}$ in terms of $\\beta$ and $\\mathrm{Var}(W)$? Provide your final answer as a closed-form expression. Do not include units in your final boxed answer.", "solution": "The problem is validated as scientifically grounded, well-posed, and objective. It is a standard derivation in nonequilibrium statistical mechanics. We may proceed with the solution.\n\nThe starting point is the provided nonequilibrium work relation, the Jarzynski equality:\n$$\n\\langle \\exp(-\\beta W) \\rangle = \\exp(-\\beta \\Delta F)\n$$\nwhere $W$ is the stochastic work, $\\Delta F$ is the equilibrium free energy difference, and $\\beta = (k_B T)^{-1}$ is the inverse temperature. The angle brackets $\\langle \\cdot \\rangle$ denote an average over an ensemble of trajectories.\n\nWe are given the definition of the cumulant generating function for the work $W$ as:\n$$\nK_W(t) = \\ln \\langle \\exp(t W) \\rangle\n$$\nBy taking the natural logarithm of both sides of the Jarzynski equality, we can relate it to the cumulant generating function evaluated at $t = -\\beta$:\n$$\n\\ln \\langle \\exp(-\\beta W) \\rangle = \\ln(\\exp(-\\beta \\Delta F))\n$$\n$$\nK_W(-\\beta) = -\\beta \\Delta F\n$$\nThis relation is exact and holds without any approximation.\n\nThe cumulant generating function can be expressed as a Maclaurin series in the variable $t$, with coefficients determined by the cumulants $\\kappa_n$ of the random variable $W$:\n$$\nK_W(t) = \\sum_{n=1}^{\\infty} \\frac{\\kappa_n}{n!} t^n = \\frac{\\kappa_1}{1!}t + \\frac{\\kappa_2}{2!}t^2 + \\frac{\\kappa_3}{3!}t^3 + \\dots\n$$\nThe problem states that the first two cumulants are identified with the mean and variance:\n- First cumulant: $\\kappa_1 = \\langle W \\rangle$\n- Second cumulant: $\\kappa_2 = \\mathrm{Var}(W) = \\langle (W - \\langle W \\rangle)^2 \\rangle$\n\nWe must perform a cumulant expansion of $K_W(-\\beta)$ to order $\\beta^2$. To do this, we substitute $t = -\\beta$ into the series expansion and truncate it after the second-order term:\n$$\nK_W(-\\beta) = \\frac{\\kappa_1}{1!}(-\\beta) + \\frac{\\kappa_2}{2!}(-\\beta)^2 + \\mathcal{O}(\\beta^3)\n$$\n$$\nK_W(-\\beta) \\approx -\\beta \\kappa_1 + \\frac{\\beta^2}{2} \\kappa_2\n$$\nThe explicit approximation made here is the neglect of all terms of order $\\beta^3$ and higher. This is stated as:\n$$\n\\sum_{n=3}^{\\infty} \\frac{\\kappa_n}{n!} (-\\beta)^n \\approx 0\n$$\nThis approximation is physically justified when the system is driven near equilibrium, such that the work distribution $P(W)$ is approximately Gaussian. For a true Gaussian distribution, all cumulants $\\kappa_n$ for $n \\geq 3$ are identically zero, rendering the expansion exact.\n\nSubstituting the definitions for $\\kappa_1$ and $\\kappa_2$ into our truncated expansion gives:\n$$\nK_W(-\\beta) \\approx -\\beta \\langle W \\rangle + \\frac{\\beta^2}{2} \\mathrm{Var}(W)\n$$\nWe now equate this approximate expression with the exact relation $K_W(-\\beta) = -\\beta \\Delta F$:\n$$\n-\\beta \\Delta F \\approx -\\beta \\langle W \\rangle + \\frac{\\beta^2}{2} \\mathrm{Var}(W)\n$$\nThe problem requires an expression for the dissipated work, $W_{\\mathrm{diss}}$, which is defined as $W_{\\mathrm{diss}} = \\langle W \\rangle - \\Delta F$. To find this, we rearrange the above relation. Assuming $\\beta \\neq 0$, we can divide the entire expression by $-\\beta$:\n$$\n\\Delta F \\approx \\langle W \\rangle - \\frac{\\beta}{2} \\mathrm{Var}(W)\n$$\nFinally, we rearrange to isolate the dissipated work on one side of the equation:\n$$\n\\langle W \\rangle - \\Delta F \\approx \\frac{\\beta}{2} \\mathrm{Var}(W)\n$$\nThis yields the expression for the dissipated work to order $\\beta^2$:\n$$\nW_{\\mathrm{diss}} \\approx \\frac{\\beta}{2} \\mathrm{Var}(W)\n$$\nThis result is a form of the fluctuation-dissipation theorem, which connects the average dissipation in a nonequilibrium process to the fluctuations (variance) of the work performed.", "answer": "$$\n\\boxed{\\frac{\\beta}{2} \\mathrm{Var}(W)}\n$$", "id": "2659538"}, {"introduction": "Theoretical relations like the Jarzynski equality are best understood when tested and observed. This hands-on computational exercise asks you to build a simulation of a finite-state system driven by a time-dependent protocol [@problem_id:2659368]. You will generate stochastic trajectories, compute the work performed along each path, and numerically verify that the exponential average $\\langle \\exp(-\\beta W) \\rangle$ converges to the predicted equilibrium quantity. This practice provides a tangible feel for the abstract concepts and builds essential skills in stochastic simulation.", "problem": "Consider a finite-state, continuous-time Markov jump process representing a chemical reaction network with a time-dependent energy landscape. Let the state space be $S=\\{0,1,\\dots,N-1\\}$. At time $t$, each state $i\\in S$ has an energy $E_i(t)$, and the system evolves as a time-inhomogeneous continuous-time Markov chain with generator $\\mathcal{L}_t$ whose off-diagonal elements are transition rates $k_{ij}(t)$ for $i\\neq j$. Assume the following fundamental base:\n- Canonical initial condition: the system starts at time $t=0$ in the canonical equilibrium distribution at inverse temperature $\\beta>0$, namely $p_i(0)=\\exp(-\\beta E_i(0))/Z(0)$, where $Z(t)=\\sum_{j=0}^{N-1}\\exp(-\\beta E_j(t))$.\n- Local Detailed Balance (LDB): for all $i\\neq j$ and times $t$, the rates satisfy $k_{ij}(t)/k_{ji}(t)=\\exp\\big(-\\beta\\big[E_j(t)-E_i(t)\\big]\\big)$.\n- Construction of rates: take a symmetric attempt rate prefactor $\\kappa>0$ and define\n$$\nk_{ij}(t)=\\kappa\\,\\exp\\Big(-\\tfrac{\\beta}{2}\\big[E_j(t)-E_i(t)\\big]\\Big),\\quad i\\neq j,\\quad k_{ii}(t)=-\\sum_{j\\neq i}k_{ij}(t).\n$$\nAssume only the energy of the currently occupied state changes explicitly with time, i.e., the external protocol does not change reaction pathways but only the state energies $E_i(t)$. For a single trajectory $t\\mapsto x_t$ with a finite number of jumps on $[0,\\tau]$, define the trajectory work associated with the protocol as\n$$\nW[x_{\\cdot}]=\\int_{0}^{\\tau}\\partial_t E_{x_t}(t)\\,dt,\n$$\nnamely the time-integral of the energy change rate of the actually occupied state. In discrete time with a uniform partition $t_k=k\\Delta t$ with $\\Delta t=\\tau/n_{\\mathrm{steps}}$, a Riemann approximation of this work is\n$$\nW\\approx \\sum_{k=0}^{n_{\\mathrm{steps}}-1}\\Big(E_{x_{t_k}}(t_{k+1})-E_{x_{t_k}}(t_k)\\Big).\n$$\nDefine the exponential work average estimator over $M$ independent trajectories as\n$$\n\\widehat{\\Phi}=\\frac{1}{M}\\sum_{m=1}^{M}\\exp\\big(-\\beta W^{(m)}\\big),\n$$\nand the reference equilibrium ratio\n$$\nR=\\frac{Z(\\tau)}{Z(0)}.\n$$\nYour task is to implement a program that:\n- Samples $M$ independent trajectories using the above continuous-time Markov chain with time-dependent rates $k_{ij}(t)$, employing a small uniform time step $\\Delta t$ and, within each time step, a jump/no-jump rule with the exact no-jump probability $\\exp\\big(-r_i(t)\\Delta t\\big)$ where $r_i(t)=\\sum_{j\\neq i}k_{ij}(t)$ for the current state $i$ at time $t$. When a jump occurs within a time step, choose the next state with probability proportional to $k_{ij}(t)$ across $j\\neq i$ at the beginning of the step.\n- Uses the canonical equilibrium distribution at time $t=0$ for sampling initial states.\n- Computes $W^{(m)}$ for each trajectory using the Riemann approximation above, then computes $\\log \\widehat{\\Phi}$ in a numerically stable way via a log-mean-exp transform.\n- Computes $\\log R=\\log Z(\\tau)-\\log Z(0)$ exactly from the protocol.\n- Returns, for each test case, a boolean indicating whether the absolute log-difference $|\\log \\widehat{\\Phi}-\\log R|$ is less than a specified tolerance $\\varepsilon$.\n\nAll energies are to be treated as dimensionless and reported in units where the product of Boltzmann constant and temperature $k_{\\mathrm{B}}T$ equals one, so $\\beta$ is dimensionless. The required outputs are booleans (unitless). Angles and percentages are not involved in this task.\n\nImplement the following test suite. In each case, the energies are linear in time, $E_i(t)=\\epsilon_i+\\alpha_i t$, with given parameters:\n- Test 1 (two-state, moderate ramp):\n  - $N=2$, $\\beta=1.0$, $\\kappa=5.0$, $\\tau=1.0$, $n_{\\mathrm{steps}}=1500$, $M=6000$, $\\varepsilon=0.02$,\n  - $\\boldsymbol{\\epsilon}=[0.0,\\,1.0]$, $\\boldsymbol{\\alpha}=[1.0,\\,0.0]$.\n- Test 2 (three-state, crossing energies, colder bath):\n  - $N=3$, $\\beta=2.0$, $\\kappa=4.0$, $\\tau=1.0$, $n_{\\mathrm{steps}}=1500$, $M=7000$, $\\varepsilon=0.03$,\n  - $\\boldsymbol{\\epsilon}=[0.0,\\,0.5,\\,1.0]$, $\\boldsymbol{\\alpha}=[0.5,\\,-0.8,\\,0.3]$.\n- Test 3 (four-state, faster quench, hotter bath):\n  - $N=4$, $\\beta=0.5$, $\\kappa=6.0$, $\\tau=0.5$, $n_{\\mathrm{steps}}=1500$, $M=7000$, $\\varepsilon=0.02$,\n  - $\\boldsymbol{\\epsilon}=[0.0,\\,0.2,\\,0.4,\\,0.6]$, $\\boldsymbol{\\alpha}=[2.0,\\,-1.0,\\,0.0,\\,0.5]$.\n\nFinal output format:\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, e.g., \"[result1,result2,result3]\".\n- For the above test suite, the results are the three booleans for the respective tests, in the given order.", "solution": "The problem requires a numerical verification of the Jarzynski equality for a finite-state, continuous-time Markov jump process governed by time-dependent rates. The Jarzynski equality states that for a system driven out of equilibrium by an external protocol, the statistical average of the exponentiated work, $\\langle e^{-\\beta W} \\rangle$, is related to the equilibrium free energy difference, $\\Delta F$, between the final and initial states of the corresponding equilibrium ensembles: $\\langle e^{-\\beta W} \\rangle = e^{-\\beta \\Delta F}$.\n\nFirst, the problem statement must be validated.\n**Step 1: Extract Givens**\n- State space: $S = \\{0, 1, \\dots, N-1\\}$.\n- State energies: $E_i(t) = \\epsilon_i + \\alpha_i t$.\n- Initial condition: Canonical distribution at $t=0$, $p_i(0) = \\exp(-\\beta E_i(0))/Z(0)$, with $Z(t) = \\sum_{j=0}^{N-1} \\exp(-\\beta E_j(t))$.\n- Transition rates: $k_{ij}(t) = \\kappa \\exp\\big(-\\frac{\\beta}{2}[E_j(t)-E_i(t)]\\big)$ for $i \\neq j$. This satisfies local detailed balance: $k_{ij}(t)/k_{ji}(t) = \\exp(-\\beta[E_j(t)-E_i(t)])$.\n- Trajectory work: $W[x_{\\cdot}] = \\int_0^\\tau \\partial_t E_{x_t}(t) dt$.\n- Work approximation: $W \\approx \\sum_{k=0}^{n_{\\mathrm{steps}}-1} (E_{x_{t_k}}(t_{k+1}) - E_{x_{t_k}}(t_k))$, with $t_k = k \\Delta t$ and $\\Delta t = \\tau/n_{\\mathrm{steps}}$.\n- Estimator: $\\widehat{\\Phi} = \\frac{1}{M} \\sum_{m=1}^M \\exp(-\\beta W^{(m)})$.\n- Reference ratio: $R = Z(\\tau)/Z(0)$.\n- Simulation method: Discrete time-stepping with jump/no-jump decision based on no-jump probability $\\exp(-r_i(t)\\Delta t)$, where $r_i(t) = \\sum_{j \\neq i} k_{ij}(t)$.\n- Task: For several test cases, determine if $|\\log \\widehat{\\Phi} - \\log R| < \\varepsilon$.\n\n**Step 2: Validate Using Extracted Givens**\nThe problem is scientifically grounded, rooted in the established principles of non-equilibrium statistical mechanics. The Jarzynski equality is a fundamental result in this field. The specified model, a continuous-time Markov process with rates satisfying local detailed balance, is a standard framework for studying such phenomena. The provided rate form, $k_{ij}(t) = \\kappa \\exp(-\\frac{\\beta}{2}[E_j(t)-E_i(t)])$, is a valid choice (Metropolis-like), which correctly implies the required detailed balance condition. The definition of work is canonical. The numerical scheme for simulating the trajectory and approximating the work is a standard and valid approach (first-order Euler-type method for stochastic processes, also known as tau-leaping). All parameters are specified, and the problem is well-posed, objective, and computationally feasible. There are no scientific or logical contradictions.\n\n**Step 3: Verdict and Action**\nThe problem is valid. A reasoned solution will be provided.\n\n**Principle-Based Solution Design**\n\nThe task is to numerically evaluate both sides of the Jarzynski equality, which in the notation of the problem is $\\widehat{\\Phi} \\approx R$. The implementation is structured into three main components: analytical calculation of the reference value, stochastic simulation to estimate the work distribution, and a final statistical comparison.\n\n1.  **Analytical Reference Calculation**: The right-hand side of the Jarzynski equality involves the equilibrium partition functions $Z(t)$ at the start and end of the protocol. The free energy change is $\\Delta F = F(\\tau) - F(0)$, where the Helmholtz free energy is $F(t) = -\\frac{1}{\\beta}\\log Z(t)$. Thus, $e^{-\\beta \\Delta F} = e^{\\log Z(\\tau) - \\log Z(0)} = Z(\\tau)/Z(0) = R$. We must compute $\\log R = \\log Z(\\tau) - \\log Z(0)$. The partition function at time $t$ is $Z(t) = \\sum_{i=0}^{N-1} \\exp(-\\beta E_i(t))$. Given the linear protocol $E_i(t) = \\epsilon_i + \\alpha_i t$, the energies $E_i(0) = \\epsilon_i$ and $E_i(\\tau) = \\epsilon_i + \\alpha_i \\tau$ are readily calculated. The sums of exponentials required for $Z(t)$ are computed using a numerically stable log-sum-exp algorithm to prevent floating-point overflow or underflow, which is essential when $\\beta E_i(t)$ values are large.\n\n2.  **Stochastic Trajectory Simulation**: The left-hand side, $\\langle e^{-\\beta W} \\rangle$, is estimated by averaging over $M$ independent stochastic trajectories.\n    *   **Initialization**: For each of the $M$ trajectories, the initial state $x(0)$ is sampled from the canonical Boltzmann distribution at $t=0$, $p_i(0) = \\exp(-\\beta E_i(0)) / Z(0)$. This ensures the system starts in thermal equilibrium as required by the theorem.\n    *   **Time Evolution**: The dynamics are simulated using a discrete-time approximation of the continuous-time Markov process. The total duration $\\tau$ is divided into $n_{\\mathrm{steps}}$ small intervals of duration $\\Delta t = \\tau/n_{\\mathrm{steps}}$. For each time step from $t_k$ to $t_{k+1}$, the system's state $x_{t_k}=i$ evolves as follows:\n        a. The transition rates $k_{ij}(t_k)$ from state $i$ to all other states $j \\neq i$ are calculated based on the energies $E_j(t_k)$ at the beginning of the interval.\n        b. The total exit rate $r_i(t_k) = \\sum_{j \\neq i} k_{ij}(t_k)$ is computed.\n        c. A stochastic decision is made: the system remains in state $i$ with probability $p_{\\text{no-jump}} = \\exp(-r_i(t_k)\\Delta t)$.\n        d. If a jump occurs (with probability $1-p_{\\text{no-jump}}$), the new state $j$ is chosen from the set of possible destination states with probability $p_{i \\to j} = k_{ij}(t_k) / r_i(t_k)$.\n    This process is repeated for all $n_{\\mathrm{steps}}$, generating a state trajectory $x_{t_0}, x_{t_1}, \\dots, x_{t_{n_{\\mathrm{steps}}-1}}$.\n\n3.  **Work Computation and Averaging**:\n    *   For each trajectory $m$, the accumulated work $W^{(m)}$ is calculated using the specified Riemann sum. With the linear energy protocol, $\\partial_t E_i(t) = \\alpha_i$, the work integral simplifies to $W = \\int_0^\\tau \\alpha_{x_t} dt$. The Riemann sum approximation becomes $W^{(m)} \\approx \\sum_{k=0}^{n_{\\mathrm{steps}}-1} \\alpha_{x_{t_k}^{(m)}} \\Delta t$. This is computed by summing the work increments at each step, which depend on the state occupied during that step.\n    *   The estimator for the Jarzynski average is $\\widehat{\\Phi} = \\frac{1}{M}\\sum_{m=1}^{M} \\exp(-\\beta W^{(m)})$. Its logarithm, $\\log\\widehat{\\Phi}$, is computed using the log-mean-exp transform: $\\log\\widehat{\\Phi} = C + \\log\\left(\\frac{1}{M}\\sum_{m=1}^{M} \\exp(-\\beta W^{(m)} - C)\\right)$, where $C = \\max_m(-\\beta W^{(m)})$. This avoids numerical errors from exponentiating large numbers.\n\n4.  **Implementation and Verification**: The entire simulation is vectorized using `NumPy` for efficiency. Instead of looping through $M$ trajectories individually, we operate on an array of $M$ states. At each time step, trajectories are grouped by their current state, and the rate calculations and jump decisions are performed in a vectorized manner for each group. Finally, the computed $|\\log \\widehat{\\Phi} - \\log R|$ is compared with the tolerance $\\varepsilon$ to return the final boolean result.", "answer": "```python\nimport numpy as np\nfrom scipy.special import logsumexp\n\ndef run_simulation(N, beta, kappa, tau, n_steps, M, epsilon_tol, eps_vec, alpha_vec):\n    \"\"\"\n    Runs a single simulation test case to numerically verify the Jarzynski equality.\n\n    Args:\n        N (int): Number of states.\n        beta (float): Inverse temperature.\n        kappa (float): Symmetric rate prefactor.\n        tau (float): Protocol duration.\n        n_steps (int): Number of time steps in the simulation.\n        M (int): Number of trajectories to simulate.\n        epsilon_tol (float): Tolerance for the comparison.\n        eps_vec (list or np.ndarray): Initial energy offsets.\n        alpha_vec (list or np.ndarray): Energy ramp rates.\n\n    Returns:\n        bool: True if the absolute log-difference is within tolerance, False otherwise.\n    \"\"\"\n    eps_vec = np.array(eps_vec, dtype=np.float64)\n    alpha_vec = np.array(alpha_vec, dtype=np.float64)\n\n    # 1. Calculate time step\n    dt = tau / n_steps\n\n    # 2. Calculate the exact reference value log R = log(Z(tau)/Z(0))\n    E0 = eps_vec\n    log_Z0 = logsumexp(-beta * E0)\n    \n    E_tau = eps_vec + alpha_vec * tau\n    log_Z_tau = logsumexp(-beta * E_tau)\n    \n    log_R = log_Z_tau - log_Z0\n\n    # 3. Sample initial states for M trajectories from the canonical distribution at t=0\n    p0 = np.exp(-beta * E0 - log_Z0)\n    p0 /= np.sum(p0)  # Normalize to correct for any floating point inaccuracies\n    initial_states = np.random.choice(N, size=M, p=p0)\n\n    # 4. Simulate M trajectories and compute work for each\n    current_states = initial_states.copy()\n    total_work = np.zeros(M, dtype=np.float64)\n    work_increments_per_step = alpha_vec * dt\n    \n    # Precompute indices of other states for performance\n    other_states_indices = [np.arange(N)[np.arange(N) != i] for i in range(N)]\n\n    for k in range(n_steps):\n        t_k = k * dt\n        \n        # Add work contribution for this step: E_x(t_{k+1}) - E_x(t_k) = alpha_x * dt\n        total_work += work_increments_per_step[current_states]\n        \n        energies_tk = eps_vec + alpha_vec * t_k\n        next_states = current_states.copy()\n\n        # Group trajectories by current state for vectorized rate calculations\n        for i in range(N):\n            in_state_i_mask = (current_states == i)\n            if not np.any(in_state_i_mask):\n                continue\n            \n            count_in_state_i = np.sum(in_state_i_mask)\n            \n            if N > 1:\n                j_neq_i = other_states_indices[i]\n                energy_i = energies_tk[i]\n                energy_j = energies_tk[j_neq_i]\n                \n                rates_ij = kappa * np.exp(-0.5 * beta * (energy_j - energy_i))\n                r_i = np.sum(rates_ij)\n            else:\n                r_i = 0.0\n\n            if r_i > 0:\n                # Decide which trajectories jump based on the no-jump probability\n                no_jump_prob = np.exp(-r_i * dt)\n                random_nums = np.random.rand(count_in_state_i)\n                \n                original_indices = np.where(in_state_i_mask)[0]\n                jumping_trajectories_mask = (random_nums >= no_jump_prob)\n                \n                if np.any(jumping_trajectories_mask):\n                    jumping_indices = original_indices[jumping_trajectories_mask]\n                    num_jumps = len(jumping_indices)\n                    \n                    # Choose next state for trajectories that jump\n                    jump_probs = rates_ij / r_i\n                    chosen_next_states = np.random.choice(j_neq_i, size=num_jumps, p=jump_probs)\n                    next_states[jumping_indices] = chosen_next_states\n        \n        current_states = next_states\n\n    # 5. Compute the log of the exponential work estimator using log-mean-exp transform\n    log_phi_hat_terms = -beta * total_work\n    max_term = np.max(log_phi_hat_terms)\n    log_phi_hat = max_term + np.log(np.mean(np.exp(log_phi_hat_terms - max_term)))\n\n    # 6. Compare with tolerance and return boolean result\n    abs_log_diff = np.abs(log_phi_hat - log_R)\n    return abs_log_diff  epsilon_tol\n\ndef solve():\n    \"\"\"\n    Defines test cases from the problem statement and runs the simulations.\n    \"\"\"\n    test_cases = [\n        # Test 1 (two-state, moderate ramp)\n        {\n            \"N\": 2, \"beta\": 1.0, \"kappa\": 5.0, \"tau\": 1.0, \"n_steps\": 1500, \"M\": 6000, \n            \"epsilon_tol\": 0.02, \"eps_vec\": [0.0, 1.0], \"alpha_vec\": [1.0, 0.0]\n        },\n        # Test 2 (three-state, crossing energies, colder bath)\n        {\n            \"N\": 3, \"beta\": 2.0, \"kappa\": 4.0, \"tau\": 1.0, \"n_steps\": 1500, \"M\": 7000,\n            \"epsilon_tol\": 0.03, \"eps_vec\": [0.0, 0.5, 1.0], \"alpha_vec\": [0.5, -0.8, 0.3]\n        },\n        # Test 3 (four-state, faster quench, hotter bath)\n        {\n            \"N\": 4, \"beta\": 0.5, \"kappa\": 6.0, \"tau\": 0.5, \"n_steps\": 1500, \"M\": 7000,\n            \"epsilon_tol\": 0.02, \"eps_vec\": [0.0, 0.2, 0.4, 0.6], \"alpha_vec\": [2.0, -1.0, 0.0, 0.5]\n        }\n    ]\n\n    results = []\n    for case in test_cases:\n        result = run_simulation(**case)\n        results.append(result)\n\n    # Final print statement in the exact required format.\n    # Python's str(bool) produces 'True'/'False' with capitalization.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "2659368"}, {"introduction": "Applying the Jarzynski equality to real or simulated data presents a significant statistical challenge, as the exponential average is often dominated by rare, low-work trajectories that are hard to sample. This final practice confronts this issue directly, exploring the systematic bias that arises from work truncation or finite sampling [@problem_id:2659456]. Analyzing how an incomplete work distribution affects the free energy estimate is a critical step toward becoming a sophisticated practitioner capable of assessing the reliability of nonequilibrium measurements.", "problem": "Consider a well-mixed stochastic chemical reaction network evolving as a continuous-time Markov jump process with a time-dependent control parameter $\\lambda(t)$ that modulates rate constants via local detailed balance. The system is initially prepared in the canonical equilibrium distribution at $\\lambda(0)=\\lambda_{0}$ and is driven by a protocol $\\lambda(t)$ from $t=0$ to $t=\\tau$, ending at $\\lambda(\\tau)=\\lambda_{1}$. Let $W$ denote the stochastic work performed on the system by the protocol along a trajectory over $[0,\\tau]$, defined through the first law at the trajectory level and the conjugate generalized forces to $\\lambda(t)$ in the usual inclusive-work convention.\n\nYou execute $N$ independent realizations of the forward protocol, obtaining work values $\\{W_{i}\\}_{i=1}^{N}$. You impose a truncation that retains only those trajectories with $W_{i}\\le w_{c}$, where $w_c \\in \\mathbb{R}$ is a fixed threshold, and you form the truncated exponential-work estimator of the equilibrium free-energy difference,\n$$\n\\widehat{\\Delta F}_{\\mathrm{trunc}}(N,w_{c})\\;=\\;-\\frac{1}{\\beta}\\,\\ln\\!\\left(\\frac{1}{M}\\sum_{i=1}^{N}e^{-\\beta W_{i}}\\mathbf{1}\\{W_{i}\\le w_{c}\\}\\right),\n$$\nwhere $M=\\sum_{i=1}^{N}\\mathbf{1}\\{W_{i}\\le w_{c}\\}$ is the number of retained trajectories and $\\beta=(k_{\\mathrm{B}}T)^{-1}$ is the inverse thermal energy.\n\nAssume the dynamics obey microscopic reversibility and local detailed balance, the initial condition is equilibrium at $\\lambda_{0}$, and the exponential moment $\\mathbb{E}[e^{-\\beta W}]$ is finite. In the large-sample limit $N\\to\\infty$ with $w_{c}$ fixed and $\\mathbb{P}(W \\le w_c) \\in (0,1)$, decide which of the following statements are correct.\n\nA. For any work distribution with $\\mathbb{P}(W > w_c) > 0$, the estimator converges almost surely to a value strictly less than the true equilibrium free-energy difference $\\Delta F$, i.e., $\\lim_{N\\to\\infty}\\widehat{\\Delta F}_{\\mathrm{trunc}}(N,w_{c})  \\Delta F$.\n\nB. If, instead of averaging over $M$ retained trajectories, you multiply the truncated average by the acceptance probability $p=\\lim_{N\\to\\infty}M/N=\\mathbb{P}(W\\le w_{c})$ and use\n$$\n\\widetilde{\\Delta F}(N,w_{c})\\;=\\;-\\frac{1}{\\beta}\\,\\ln\\!\\left(\\frac{M}{N}\\cdot\\frac{1}{M}\\sum_{i=1}^{N}e^{-\\beta W_{i}}\\mathbf{1}\\{W_{i}\\le w_{c}\\}\\right),\n$$\nthen $\\widetilde{\\Delta F}(N,w_{c})$ is asymptotically unbiased for $\\Delta F$ as $N\\to\\infty$.\n\nC. Suppose the work is approximately Gaussian, $W \\sim \\mathcal{N}(\\mu, \\sigma^2)$, with finite $(\\mu, \\sigma)$ and finite moment generating function at $t=-\\beta$. In the limit $N\\to\\infty$, the truncated estimator converges almost surely to\n$$\n\\mu-\\frac{\\beta\\sigma^{2}}{2}\\;-\\;\\frac{1}{\\beta}\\,\\ln\\!\\left(\\frac{\\Phi\\!\\left(\\frac{w_{c}-\\mu+\\beta\\sigma^{2}}{\\sigma}\\right)}{\\Phi\\!\\left(\\frac{w_{c}-\\mu}{\\sigma}\\right)}\\right),\n$$\nwhere $\\Phi(\\cdot)$ is the standard normal cumulative distribution function. Consequently, the asymptotic bias is nonpositive and is strictly negative if $\\mathbb{P}(W > w_c) > 0$.\n\nD. As a function of the threshold $w_{c}$, the large-$N$ limit of the truncated estimator is monotonically nondecreasing and approaches the true $\\Delta F$ from below as $w_{c}\\to+\\infty$. Moreover, for work distributions with unbounded lower support, the asymptotic truncated estimate can be made arbitrarily negative by taking $w_{c} \\to -\\infty$.\n\nSelect all correct statements.", "solution": "We proceed from microscopic reversibility for Markov jump processes with local detailed balance, leading to the Crooks fluctuation theorem. Let $\\mathcal{P}_{F}[\\Gamma]$ denote the path probability density of a forward trajectory $\\Gamma$ under the protocol $\\lambda(t)$, and let $\\mathcal{P}_{R}[\\Gamma^{R}]$ denote the probability density of the time-reversed path under the time-reversed protocol $\\lambda^{R}(t)=\\lambda(\\tau-t)$, both started in their respective equilibrium ensembles. Under local detailed balance and microreversibility, one has\n$$\n\\frac{\\mathcal{P}_{F}[\\Gamma]}{\\mathcal{P}_{R}[\\Gamma^{R}]}\\;=\\;e^{\\beta\\,(W[\\Gamma]-\\Delta F)},\n$$\nwhere $W[\\Gamma]$ is the inclusive work along $\\Gamma$ and $\\Delta F=F(\\lambda_{1})-F(\\lambda_{0})$ is the equilibrium free-energy difference between the end states.\n\nAveraging the identity $e^{-\\beta W[\\Gamma]}=\\left(\\mathcal{P}_{R}[\\Gamma^{R}]/\\mathcal{P}_{F}[\\Gamma]\\right)e^{-\\beta\\Delta F}$ over forward paths yields the Jarzynski equality,\n$$\n\\left\\langle e^{-\\beta W}\\right\\rangle_{F}\\;=\\;e^{-\\beta \\Delta F},\n$$\nwhere $\\langle\\cdot\\rangle_{F}$ is the expectation over the forward process with initial equilibrium at $\\lambda_{0}$. This equality holds provided the exponential moment exists, which we assume.\n\nDefine the truncated estimator\n$$\n\\widehat{\\Delta F}_{\\mathrm{trunc}}(N,w_{c})\\;=\\;-\\frac{1}{\\beta}\\,\\ln\\!\\left(\\frac{1}{M}\\sum_{i=1}^{N}e^{-\\beta W_{i}}\\mathbf{1}\\{W_{i}\\le w_{c}\\}\\right),\n$$\nwith $M=\\sum_{i=1}^{N}\\mathbf{1}\\{W_{i}\\le w_{c}\\}$. By the strong law of large numbers, if $\\mathbb{P}(W\\le w_c)\\in(0,1)$, then as $N\\to\\infty$,\n$$\n\\frac{M}{N}\\to p:=\\mathbb{P}(W\\le w_c),\\qquad \\frac{1}{M}\\sum_{i=1}^{N}e^{-\\beta W_{i}}\\mathbf{1}\\{W_{i}\\le w_{c}\\}\\to \\mathbb{E}\\!\\left[e^{-\\beta W}\\,\\middle|\\,W\\le w_c\\right],\n$$\nalmost surely. Therefore,\n$$\n\\lim_{N\\to\\infty}\\widehat{\\Delta F}_{\\mathrm{trunc}}(N,w_{c})\\;=\\;-\\frac{1}{\\beta}\\ln \\mathbb{E}\\!\\left[e^{-\\beta W}\\,\\middle|\\,W\\le w_c\\right].\n$$\nUsing the Jarzynski equality $\\mathbb{E}[e^{-\\beta W}]=e^{-\\beta\\Delta F}$, we may write the asymptotic bias $\\delta(w_{c})$ as\n$$\n\\delta(w_c)\\;=\\;\\lim_{N\\to\\infty}\\widehat{\\Delta F}_{\\mathrm{trunc}}(N,w_{c})-\\Delta F\\;=\\;-\\frac{1}{\\beta}\\,\\ln\\!\\left(\\frac{\\mathbb{E}[e^{-\\beta W}\\mid W\\le w_c]}{\\mathbb{E}[e^{-\\beta W}]}\\right).\n$$\nBecause $f(w)=e^{-\\beta w}$ is strictly decreasing in $w$, conditioning on the lower set $\\{W\\le w_c\\}$ removes larger $w$ values, which contribute smaller $f(w)$. Hence the conditional mean of a decreasing function on a lower set is at least as large as the unconditional mean. Formally, by the law of total expectation,\n$$\n\\mathbb{E}[f(W)]=p\\,\\mathbb{E}[f(W)\\mid W\\le w_c]+(1-p)\\,\\mathbb{E}[f(W)\\mid W> w_c],\n$$\nand since $f$ decreases, $\\mathbb{E}[f(W)\\mid W\\le w_c]\\ge \\mathbb{E}[f(W)\\mid W> w_c]$, which implies $\\mathbb{E}[f(W)]\\le \\mathbb{E}[f(W)\\mid W\\le w_c]$, with strict inequality if both $p\\in(0,1)$ and $\\mathbb{P}(W>w_c)>0$. Therefore,\n$$\n\\frac{\\mathbb{E}[e^{-\\beta W}\\mid W\\le w_c]}{\\mathbb{E}[e^{-\\beta W}]}\\;\\ge\\;1,\n$$\nstrictly greater than $1$ if $\\mathbb{P}(W>w_c)>0$. It follows that\n$$\n\\delta(w_c)\\;\\le\\;0,\n$$\nwith strict inequality when $\\mathbb{P}(W>w_c)>0$. This establishes a negative bias: truncating to low-work trajectories yields an asymptotic underestimation of $\\Delta F$.\n\nWe now analyze each option.\n\nOption A: It states that for any work distribution with $\\mathbb{P}(W>w_c)>0$, the asymptotic truncated estimate is strictly less than $\\Delta F$. As derived, $\\delta(w_c)\\le 0$ with strict inequality under $\\mathbb{P}(W>w_c)>0$ and $\\mathbb{P}(W\\le w_c)>0$. Hence $\\lim_{N\\to\\infty}\\widehat{\\Delta F}_{\\mathrm{trunc}}(N,w_c)=\\Delta F+\\delta(w_c)\\Delta F$. Verdict: Correct.\n\nOption B: The proposed modified estimator is\n$$\n\\widetilde{\\Delta F}(N,w_{c})=-\\frac{1}{\\beta}\\ln\\!\\left(\\frac{M}{N}\\cdot\\frac{1}{M}\\sum_{i=1}^{N}e^{-\\beta W_{i}}\\mathbf{1}\\{W_{i}\\le w_{c}\\}\\right).\n$$\nAs $N\\to\\infty$, this converges almost surely to\n$$\n-\\frac{1}{\\beta}\\ln\\!\\left(\\mathbb{P}(W\\le w_{c})\\cdot \\mathbb{E}[e^{-\\beta W}\\mid W\\le w_c]\\right)\\;=\\;-\\frac{1}{\\beta}\\ln \\mathbb{E}[e^{-\\beta W}\\,\\mathbf{1}\\{W\\le w_c\\}],\n$$\nwhich is the logarithm of the truncated exponential moment, not the full one. Since $e^{-\\beta W}\\mathbf{1}\\{W\\le w_c\\}\\le e^{-\\beta W}$ pointwise with strict inequality on $\\{W>w_c\\}$, we have\n$$\n\\mathbb{E}[e^{-\\beta W}\\,\\mathbf{1}\\{W\\le w_c\\}]\\mathbb{E}[e^{-\\beta W}]=e^{-\\beta\\Delta F}\n$$\nwhenever $\\mathbb{P}(W>w_c)>0$. Hence the limit equals $-\\frac{1}{\\beta}\\ln(\\cdot)$ of a strictly smaller positive number, which is strictly greater than $\\Delta F$ (an upward bias). This is not unbiased. Verdict: Incorrect.\n\nOption C: Suppose $W\\sim \\mathcal{N}(\\mu,\\sigma^{2})$. Compute, for $t\\in\\mathbb{R}$ and $c\\in\\mathbb{R}$,\n$$\n\\mathbb{E}\\left[e^{tW}\\,\\mathbf{1}\\{W\\le c\\}\\right]=\\int_{-\\infty}^{c} e^{t w}\\,\\frac{1}{\\sqrt{2\\pi}\\sigma}\\,\\exp\\!\\left(-\\frac{(w-\\mu)^{2}}{2\\sigma^{2}}\\right)\\,dw.\n$$\nComplete the square in the exponent:\n$$\nt w-\\frac{(w-\\mu)^{2}}{2\\sigma^{2}}=-\\frac{1}{2\\sigma^{2}}\\left(w-(\\mu+t\\sigma^{2})\\right)^{2}+\\frac{t\\mu}{1}+\\frac{t^{2}\\sigma^{2}}{2}.\n$$\nThus,\n$$\n\\mathbb{E}\\left[e^{tW}\\,\\mathbf{1}\\{W\\le c\\}\\right]=e^{t\\mu+t^{2}\\sigma^{2}/2}\\int_{-\\infty}^{c}\\frac{1}{\\sqrt{2\\pi}\\sigma}\\exp\\!\\left(-\\frac{(w-(\\mu+t\\sigma^{2}))^{2}}{2\\sigma^{2}}\\right)\\,dw.\n$$\nChange variables $z=(w-(\\mu+t\\sigma^{2}))/\\sigma$ to obtain\n$$\n\\mathbb{E}\\left[e^{tW}\\,\\mathbf{1}\\{W\\le c\\}\\right]=e^{t\\mu+t^{2}\\sigma^{2}/2}\\,\\Phi\\!\\left(\\frac{c-\\mu-t\\sigma^{2}}{\\sigma}\\right),\n$$\nwhere $\\Phi$ is the standard normal cumulative distribution function. Therefore, with $t=-\\beta$ and $c=w_c$,\n$$\n\\mathbb{E}\\left[e^{-\\beta W}\\,\\mathbf{1}\\{W\\le w_c\\}\\right]=e^{-\\beta\\mu+\\beta^{2}\\sigma^{2}/2}\\,\\Phi\\!\\left(\\frac{w_c-\\mu+\\beta\\sigma^{2}}{\\sigma}\\right).\n$$\nSimilarly, $\\mathbb{P}(W\\le w_c)=\\Phi\\!\\left(\\frac{w_c-\\mu}{\\sigma}\\right)$. Hence the conditional exponential average is\n$\n\\mathbb{E}\\!\\left[e^{-\\beta W}\\mid W\\le w_c\\right]=e^{-\\beta\\mu+\\beta^{2}\\sigma^{2}/2}\\cdot \\frac{\\Phi\\!\\left(\\frac{w_c-\\mu+\\beta\\sigma^{2}}{\\sigma}\\right)}{\\Phi\\!\\left(\\frac{w_c-\\mu}{\\sigma}\\right)}.\n$\nTaking the negative logarithm divided by $\\beta$ yields the large-$N$ limit of the truncated estimator:\n$$\n-\\frac{1}{\\beta}\\ln \\mathbb{E}\\!\\left[e^{-\\beta W}\\mid W\\le w_c\\right]=\\mu-\\frac{\\beta\\sigma^{2}}{2}-\\frac{1}{\\beta}\\ln\\!\\left(\\frac{\\Phi\\!\\left(\\frac{w_c-\\mu+\\beta\\sigma^{2}}{\\sigma}\\right)}{\\Phi\\!\\left(\\frac{w_c-\\mu}{\\sigma}\\right)}\\right),\n$$\nwhich matches the statement. Moreover, since $\\beta\\sigma>0$, the map $a\\mapsto \\Phi(a+\\beta\\sigma)/\\Phi(a)$ exceeds $1$ for all $a\\in\\mathbb{R}$, implying a strictly negative bias whenever $\\mathbb{P}(W>w_c)>0$. Verdict: Correct.\n\nOption D: Consider the function\n$\ng(w_c)=\\lim_{N\\to\\infty}\\widehat{\\Delta F}_{\\mathrm{trunc}}(N,w_c)=-\\beta^{-1}\\ln \\mathbb{E}[e^{-\\beta W}\\mid W\\le w_c].\n$\nBecause $f(w)=e^{-\\beta w}$ is decreasing, the conditional expectation $h(w_c)=\\mathbb{E}[f(W)\\mid W\\le w_c]$ is monotonically nonincreasing in $w_c$ (as the conditioning set expands, higher $W$ with smaller $f(W)$ are admitted). Therefore $g(w_c)=-\\beta^{-1}\\ln h(w_c)$ is monotonically nondecreasing in $w_c$. As $w_c\\to+\\infty$, the conditioning event becomes the full space, so $h(w_c)\\to \\mathbb{E}[e^{-\\beta W}]=e^{-\\beta\\Delta F}$ and $g(w_c)\\to \\Delta F$ from below, consistent with the negative bias established earlier. For the second claim, if the support of $W$ is unbounded below, then for any $w_c$ and any $W\\le w_c$, $e^{-\\beta W}\\ge e^{-\\beta w_c}$, implying\n$\n\\mathbb{E}[e^{-\\beta W}\\mid W\\le w_c]\\ge e^{-\\beta w_c}.\n$\nConsequently,\n$\ng(w_c)\\le -\\beta^{-1}\\ln e^{-\\beta w_c}=w_c,\n$\nand thus $g(w_c)\\to -\\infty$ as $w_c\\to -\\infty$. Verdict: Correct.\n\nIn summary, Options A, C, and D are correct; Option B is incorrect.", "answer": "$$\\boxed{ACD}$$", "id": "2659456"}]}