{"hands_on_practices": [{"introduction": "This first practice exercise takes you back to first principles to explore local, dynamic sensitivity. You will derive the sensitivity equations for a classic sequential reaction network, which describe how the concentrations of chemical species change over time in response to infinitesimal perturbations in the rate constants [@problem_id:2673555]. This foundational exercise is crucial for understanding how sensitivity coefficients are generated and provides the theoretical underpinnings for more complex numerical sensitivity analyses.", "problem": "Consider a well-mixed, isothermal batch reactor with the sequential first-order reaction network $A \\to B \\to C$. Let the concentrations be $A(t)$, $B(t)$, and $C(t)$, collected in the state vector $x(t) = (A(t), B(t), C(t))^{\\top}$. The reactions follow mass-action kinetics with strictly positive, time-invariant rate constants $k_{1} > 0$ and $k_{2} > 0$, collected in the parameter vector $p = (k_{1}, k_{2})^{\\top}$. The initial condition is $(A(0), B(0), C(0)) = (A_{0}, 0, 0)$ with $A_{0} > 0$. \n\nStarting from the definition of mass-action kinetics and the chain rule of differentiation, do the following:\n\n1. Derive the autonomous state dynamics $ \\dot{x}(t) = f(x(t), p)$.\n2. Compute the state Jacobian $f_{x}(x,p) = \\frac{\\partial f}{\\partial x}$ and the parameter Jacobian $f_{p}(x,p) = \\frac{\\partial f}{\\partial p}$ explicitly for the parameterization $p = (k_{1}, k_{2})^{\\top}$.\n3. By differentiating the state dynamics with respect to $p$, derive the local sensitivity equations for the sensitivity matrix $S(t) = \\frac{\\partial x(t)}{\\partial p}$ as an explicit linear nonhomogeneous matrix differential equation in the form $\\dot{S}(t) = \\cdots$ together with its initial condition at $t = 0$.\n4. Assuming $k_{1} \\neq k_{2}$ and using only the results of steps $1$â€“$3$ and standard methods for linear differential equations, obtain a closed-form expression for the unnormalized local sensitivity $s_{C,k_{1}}(t) = \\frac{\\partial C(t)}{\\partial k_{1}}$ as a function of $t$, $A_{0}$, $k_{1}$, and $k_{2}$.\n\nProvide your final result for $s_{C,k_{1}}(t)$ as a single closed-form analytic expression. Do not include units in your final expression.", "solution": "The problem is first subjected to validation.\n\nGivens are extracted verbatim from the problem statement:\n- Reaction network: $A \\to B \\to C$, sequential and first-order.\n- Reactor conditions: Well-mixed, isothermal, batch.\n- State vector: $x(t) = (A(t), B(t), C(t))^{\\top}$.\n- Kinetics: Mass-action.\n- Parameter vector: $p = (k_{1}, k_{2})^{\\top}$, with rate constants $k_{1} > 0$ and $k_{2} > 0$ being time-invariant.\n- Initial condition: $x(0) = (A_{0}, 0, 0)^{\\top}$, with $A_{0} > 0$.\n- Constraint: $k_{1} \\neq k_{2}$.\n- Objective: Derive a closed-form expression for the unnormalized local sensitivity $s_{C,k_{1}}(t) = \\frac{\\partial C(t)}{\\partial k_{1}}$.\n\nThe problem is assessed for validity. It is scientifically grounded, describing a canonical reaction scheme with standard mass-action kinetics. It is well-posed, providing a complete set of linear ordinary differential equations with specified initial conditions and parameters, which guarantees a unique solution exists. The problem is stated with objective and unambiguous mathematical language. All necessary information is provided, and there are no internal contradictions. Therefore, the problem is deemed valid and a solution will be furnished.\n\nThe solution proceeds by executing the four tasks outlined in the problem statement.\n\nTask $1$: Derive the state dynamics $\\dot{x}(t) = f(x(t), p)$.\nThe reaction rates for the network $A \\xrightarrow{k_1} B \\xrightarrow{k_2} C$ under mass-action kinetics are $r_{1} = k_{1} A(t)$ and $r_{2} = k_{2} B(t)$. The rates of change for the concentrations $A(t)$, $B(t)$, and $C(t)$ are:\n$$\n\\frac{dA(t)}{dt} = -r_{1} = -k_{1} A(t)\n$$\n$$\n\\frac{dB(t)}{dt} = r_{1} - r_{2} = k_{1} A(t) - k_{2} B(t)\n$$\n$$\n\\frac{dC(t)}{dt} = r_{2} = k_{2} B(t)\n$$\nUsing the state vector notation $x(t) = (A(t), B(t), C(t))^{\\top} = (x_{1}(t), x_{2}(t), x_{3}(t))^{\\top}$, the system of ordinary differential equations, $\\dot{x}(t) = f(x(t), p)$, is:\n$$\nf(x(t), p) = \\begin{pmatrix} -k_{1} x_{1}(t) \\\\ k_{1} x_{1}(t) - k_{2} x_{2}(t) \\\\ k_{2} x_{2}(t) \\end{pmatrix}\n$$\n\nTask $2$: Compute the Jacobians $f_{x}(x,p)$ and $f_{p}(x,p)$.\nThe state Jacobian $f_{x}$ is the matrix of partial derivatives of $f$ with respect to the components of $x$.\n$$\nf_{x}(x,p) = \\frac{\\partial f}{\\partial x} = \\begin{pmatrix} \\frac{\\partial f_{1}}{\\partial x_{1}} & \\frac{\\partial f_{1}}{\\partial x_{2}} & \\frac{\\partial f_{1}}{\\partial x_{3}} \\\\ \\frac{\\partial f_{2}}{\\partial x_{1}} & \\frac{\\partial f_{2}}{\\partial x_{2}} & \\frac{\\partial f_{2}}{\\partial x_{3}} \\\\ \\frac{\\partial f_{3}}{\\partial x_{1}} & \\frac{\\partial f_{3}}{\\partial x_{2}} & \\frac{\\partial f_{3}}{\\partial x_{3}} \\end{pmatrix} = \\begin{pmatrix} -k_{1} & 0 & 0 \\\\ k_{1} & -k_{2} & 0 \\\\ 0 & k_{2} & 0 \\end{pmatrix}\n$$\nThe parameter Jacobian $f_{p}$ is the matrix of partial derivatives of $f$ with respect to the components of $p = (k_{1}, k_{2})^{\\top}$.\n$$\nf_{p}(x,p) = \\frac{\\partial f}{\\partial p} = \\begin{pmatrix} \\frac{\\partial f_{1}}{\\partial k_{1}} & \\frac{\\partial f_{1}}{\\partial k_{2}} \\\\ \\frac{\\partial f_{2}}{\\partial k_{1}} & \\frac{\\partial f_{2}}{\\partial k_{2}} \\\\ \\frac{\\partial f_{3}}{\\partial k_{1}} & \\frac{\\partial f_{3}}{\\partial k_{2}} \\end{pmatrix} = \\begin{pmatrix} -x_{1}(t) & 0 \\\\ x_{1}(t) & -x_{2}(t) \\\\ 0 & x_{2}(t) \\end{pmatrix}\n$$\n\nTask $3$: Derive the local sensitivity equations for the sensitivity matrix $S(t) = \\frac{\\partial x(t)}{\\partial p}$.\nThe sensitivity matrix $S(t)$ measures the response of the state vector $x(t)$ to infinitesimal perturbations in the parameter vector $p$. We differentiate the state dynamics equation $\\dot{x}(t) = f(x(t),p)$ with respect to $p$. Interchanging the order of differentiation and applying the multivariate chain rule gives:\n$$\n\\dot{S}(t) = \\frac{d}{dt}\\left(\\frac{\\partial x(t)}{\\partial p}\\right) = \\frac{\\partial}{\\partial p}\\left(\\frac{dx(t)}{dt}\\right) = \\frac{\\partial f(x(t), p)}{\\partial p} = \\frac{\\partial f}{\\partial x}\\frac{\\partial x}{\\partial p} + \\frac{\\partial f}{\\partial p}\n$$\nSubstituting the Jacobians from Task $2$, the matrix differential equation for $S(t)$ is:\n$$\n\\dot{S}(t) = f_{x}(x, p)S(t) + f_{p}(x, p)\n$$\n$$\n\\dot{S}(t) = \\begin{pmatrix} -k_{1} & 0 & 0 \\\\ k_{1} & -k_{2} & 0 \\\\ 0 & k_{2} & 0 \\end{pmatrix} S(t) + \\begin{pmatrix} -x_{1}(t) & 0 \\\\ x_{1}(t) & -x_{2}(t) \\\\ 0 & x_{2}(t) \\end{pmatrix}\n$$\nThe initial condition $x(0) = (A_{0}, 0, 0)^{\\top}$ is independent of the parameters $k_{1}$ and $k_{2}$. Therefore, the initial sensitivity is the zero matrix:\n$$\nS(0) = \\frac{\\partial x(0)}{\\partial p} = \\begin{pmatrix} 0 & 0 \\\\ 0 & 0 \\\\ 0 & 0 \\end{pmatrix}\n$$\n\nTask $4$: Obtain a closed-form expression for $s_{C,k_{1}}(t) = \\frac{\\partial C(t)}{\\partial k_{1}}$.\nThe desired sensitivity $s_{C,k_{1}}(t)$ is the element in the third row, first column of $S(t)$. Let the first column of $S(t)$ be denoted by $S_{\\cdot, 1}(t) = (s_{A,k_{1}}(t), s_{B,k_{1}}(t), s_{C,k_{1}}(t))^{\\top}$. The system of ODEs for this vector is:\n$$\n\\frac{d}{dt} \\begin{pmatrix} s_{A,k_{1}} \\\\ s_{B,k_{1}} \\\\ s_{C,k_{1}} \\end{pmatrix} = \\begin{pmatrix} -k_{1} & 0 & 0 \\\\ k_{1} & -k_{2} & 0 \\\\ 0 & k_{2} & 0 \\end{pmatrix} \\begin{pmatrix} s_{A,k_{1}} \\\\ s_{B,k_{1}} \\\\ s_{C,k_{1}} \\end{pmatrix} + \\begin{pmatrix} -A(t) \\\\ A(t) \\\\ 0 \\end{pmatrix}\n$$\nwith initial condition $(s_{A,k_{1}}(0), s_{B,k_{1}}(0), s_{C,k_{1}}(0))^{\\top} = (0,0,0)^{\\top}$. Solving this linear system requires the explicit forms of $A(t)$ and $B(t)$, which are obtained by solving the original state equations:\n$$\nA(t) = A_{0} \\exp(-k_{1}t)\n$$\n$$\nB(t) = \\frac{k_{1}A_{0}}{k_{2}-k_{1}}(\\exp(-k_{1}t) - \\exp(-k_{2}t))\n$$\nWe solve the sensitivity equations sequentially. First, for $s_{A,k_{1}}(t)$:\n$$\n\\dot{s}_{A,k_{1}} + k_{1}s_{A,k_{1}} = -A(t) = -A_{0}\\exp(-k_{1}t)\n$$\nWith $s_{A,k_{1}}(0) = 0$, the solution is $s_{A,k_{1}}(t) = -A_{0}t\\exp(-k_{1}t)$.\n\nNext, for $s_{B,k_{1}}(t)$:\n$$\n\\dot{s}_{B,k_{1}} + k_{2}s_{B,k_{1}} = k_{1}s_{A,k_{1}}(t) + A(t) = k_{1}(-A_{0}t\\exp(-k_{1}t)) + A_{0}\\exp(-k_{1}t) = A_{0}(1-k_{1}t)\\exp(-k_{1}t)\n$$\nSolving this linear first-order ODE with $s_{B,k_{1}}(0) = 0$ yields:\n$$\ns_{B,k_{1}}(t) = \\frac{A_{0} k_{2}}{(k_{2} - k_{1})^{2}}(\\exp(-k_{1}t) - \\exp(-k_{2}t)) - \\frac{A_{0} k_{1} t}{k_{2} - k_{1}}\\exp(-k_{1}t)\n$$\nFinally, we solve for $s_{C,k_{1}}(t)$ from the third sensitivity equation:\n$$\n\\dot{s}_{C,k_{1}} = k_{2}s_{B,k_{1}}(t)\n$$\nWith $s_{C,k_{1}}(0)=0$, we integrate from $0$ to $t$:\n$$\ns_{C,k_{1}}(t) = \\int_{0}^{t} k_{2} s_{B,k_{1}}(\\tau) d\\tau\n$$\nSubstituting the expression for $s_{B,k_{1}}(\\tau)$:\n$$\ns_{C,k_{1}}(t) = k_{2} \\int_{0}^{t} \\left[ \\frac{A_{0} k_{2}}{(k_{2} - k_{1})^{2}}(\\exp(-k_{1}\\tau) - \\exp(-k_{2}\\tau)) - \\frac{A_{0} k_{1} \\tau}{k_{2} - k_{1}}\\exp(-k_{1}\\tau) \\right] d\\tau\n$$\nThe evaluation of this integral is performed in two parts. The first integral is:\n$$\n\\frac{A_{0}k_{2}^{2}}{(k_{2}-k_{1})^{2}} \\int_{0}^{t} (\\exp(-k_{1}\\tau) - \\exp(-k_{2}\\tau)) d\\tau = \\frac{A_{0}k_{2}^{2}}{(k_{2}-k_{1})^{2}} \\left( \\frac{1-\\exp(-k_{1}t)}{k_{1}} - \\frac{1-\\exp(-k_{2}t)}{k_{2}} \\right)\n$$\nThe second integral, involving integration by parts, is:\n$$\n-\\frac{A_{0}k_{1}k_{2}}{k_{2}-k_{1}} \\int_{0}^{t} \\tau\\exp(-k_{1}\\tau) d\\tau = -\\frac{A_{0}k_{1}k_{2}}{k_{2}-k_{1}} \\left( \\frac{1-\\exp(-k_{1}t)-k_{1}t\\exp(-k_{1}t)}{k_{1}^{2}} \\right)\n$$\nSumming these results and performing substantial algebraic simplification leads to the final expression:\n$$\ns_{C,k_{1}}(t) = \\frac{A_{0}k_{2}}{(k_{2}-k_{1})^{2}} \\left( \\exp(-k_{2}t) - \\exp(-k_{1}t) \\right) + \\frac{A_{0}k_{2}t}{k_{2}-k_{1}} \\exp(-k_{1}t)\n$$\nRearranging to a more compact form provides the final answer.", "answer": "$$\n\\boxed{A_{0} k_{2} \\left( \\frac{t}{k_{2} - k_{1}} \\exp(-k_{1} t) + \\frac{\\exp(-k_{2} t) - \\exp(-k_{1} t)}{(k_{2} - k_{1})^{2}} \\right)}\n$$", "id": "2673555"}, {"introduction": "Moving from a local to a global perspective, this exercise introduces the core concepts of variance-based global sensitivity analysis (GSA). You will analytically derive the first-order and total-effect Sobol indices for a simple linear model with independent inputs [@problem_id:2673531]. This practice is invaluable for building intuition, clarifying how output variance is attributed to different parameters, and understanding the relationship between main effects and total effects in the absence of parameter interactions.", "problem": "Consider a stochastic linear kinetic surrogate model for the scalar model output $Y$ given by $Y=\\sum_{j=1}^{m} a_{j} P_{j}$, where the parameters $\\{P_{j}\\}_{j=1}^{m}$ are mutually independent random variables with zero means and finite variances $\\operatorname{Var}(P_{j})=\\sigma_{j}^{2}$, and the coefficients $\\{a_{j}\\}_{j=1}^{m}$ are fixed real constants. Let $\\operatorname{Var}(\\cdot)$ denote variance and $\\mathbb{E}[\\cdot]$ denote expectation. Adopt the variance-based global sensitivity analysis framework, in which the first-order Sobol index for parameter $P_{j}$ is defined by $S_{j}=\\operatorname{Var}_{P_{j}}\\!\\left(\\mathbb{E}[Y \\mid P_{j}]\\right) / \\operatorname{Var}(Y)$, and the total-effect Sobol index is defined by $S_{T_{j}}=1-\\operatorname{Var}_{P_{-j}}\\!\\left(\\mathbb{E}[Y \\mid P_{-j}]\\right) / \\operatorname{Var}(Y)$, where $P_{-j}$ denotes the collection of all inputs except $P_{j}$. Using only these definitions, the linearity of $Y$ in the inputs, and the mutual independence of the $P_{j}$, derive explicit closed-form expressions for $S_{j}$ and $S_{T_{j}}$ in terms of $\\{a_{k}\\}$ and $\\{\\sigma_{k}^{2}\\}$. Your final answer must be a single closed-form analytic expression. No numerical evaluation is required, and no units are involved.", "solution": "The problem requires the derivation of explicit closed-form expressions for the first-order Sobol index $S_{j}$ and the total-effect Sobol index $S_{T_{j}}$ for a stochastic linear model. The model output is given by $Y = \\sum_{j=1}^{m} a_{j} P_{j}$, where the coefficients $\\{a_{j}\\}_{j=1}^{m}$ are fixed real constants and the parameters $\\{P_{j}\\}_{j=1}^{m}$ are mutually independent random variables. Each parameter $P_j$ has a mean of zero, $\\mathbb{E}[P_{j}] = 0$, and a finite variance $\\operatorname{Var}(P_{j}) = \\sigma_{j}^{2}$. We will proceed by first calculating the total variance of the output, $\\operatorname{Var}(Y)$, and then using the provided definitions to derive each index.\n\nFirst, we calculate the total variance of $Y$. The expectation of $Y$ is found by the linearity of the expectation operator:\n$$ \\mathbb{E}[Y] = \\mathbb{E}\\left[\\sum_{k=1}^{m} a_{k} P_{k}\\right] = \\sum_{k=1}^{m} a_{k} \\mathbb{E}[P_{k}] $$\nGiven that $\\mathbb{E}[P_{k}] = 0$ for all $k \\in \\{1, \\dots, m\\}$, the expectation of $Y$ is:\n$$ \\mathbb{E}[Y] = \\sum_{k=1}^{m} a_{k} (0) = 0 $$\nThe variance of $Y$ is defined as $\\operatorname{Var}(Y) = \\mathbb{E}[Y^{2}] - (\\mathbb{E}[Y])^{2}$. Since $\\mathbb{E}[Y] = 0$, the variance simplifies to $\\operatorname{Var}(Y) = \\mathbb{E}[Y^{2}]$. We can compute the variance of the sum directly. Since the parameters $\\{P_{k}\\}_{k=1}^{m}$ are mutually independent, the variance of their weighted sum is the weighted sum of their variances:\n$$ \\operatorname{Var}(Y) = \\operatorname{Var}\\left(\\sum_{k=1}^{m} a_{k} P_{k}\\right) = \\sum_{k=1}^{m} \\operatorname{Var}(a_{k} P_{k}) = \\sum_{k=1}^{m} a_{k}^{2} \\operatorname{Var}(P_{k}) $$\nSubstituting the given variances $\\operatorname{Var}(P_{k})=\\sigma_{k}^{2}$, we obtain the total variance:\n$$ \\operatorname{Var}(Y) = \\sum_{k=1}^{m} a_{k}^{2} \\sigma_{k}^{2} $$\nThis expression will serve as the denominator for both Sobol indices.\n\nNext, we derive the first-order Sobol index, $S_{j}$, defined as $S_{j} = \\operatorname{Var}_{P_{j}}\\!\\left(\\mathbb{E}[Y \\mid P_{j}]\\right) / \\operatorname{Var}(Y)$. We must first compute the conditional expectation $\\mathbb{E}[Y \\mid P_{j}]$. We can split the sum for $Y$ into terms involving $P_{j}$ and terms not involving $P_{j}$:\n$$ \\mathbb{E}[Y \\mid P_{j}] = \\mathbb{E}\\left[a_{j} P_{j} + \\sum_{k \\neq j} a_{k} P_{k} \\mid P_{j}\\right] $$\nBy the linearity of conditional expectation:\n$$ \\mathbb{E}[Y \\mid P_{j}] = \\mathbb{E}[a_{j} P_{j} \\mid P_{j}] + \\mathbb{E}\\left[\\sum_{k \\neq j} a_{k} P_{k} \\mid P_{j}\\right] $$\nThe term $a_{j} P_{j}$ is known when we condition on $P_{j}$, so $\\mathbb{E}[a_{j} P_{j} \\mid P_{j}] = a_{j} P_{j}$. For the second term, due to the mutual independence of the parameters, $P_{k}$ is independent of $P_{j}$ for any $k \\neq j$. Therefore, conditioning on $P_j$ does not affect the expectation of $P_k$:\n$$ \\mathbb{E}\\left[\\sum_{k \\neq j} a_{k} P_{k} \\mid P_{j}\\right] = \\sum_{k \\neq j} a_{k} \\mathbb{E}[P_{k} \\mid P_{j}] = \\sum_{k \\neq j} a_{k} \\mathbb{E}[P_{k}] = \\sum_{k \\neq j} a_{k} (0) = 0 $$\nThus, the conditional expectation is:\n$$ \\mathbb{E}[Y \\mid P_{j}] = a_{j} P_{j} $$\nNow we compute the variance of this quantity with respect to $P_{j}$:\n$$ \\operatorname{Var}_{P_{j}}\\!\\left(\\mathbb{E}[Y \\mid P_{j}]\\right) = \\operatorname{Var}(a_{j} P_{j}) = a_{j}^{2} \\operatorname{Var}(P_{j}) = a_{j}^{2} \\sigma_{j}^{2} $$\nFinally, the first-order Sobol index $S_{j}$ is the ratio of this variance to the total variance:\n$$ S_{j} = \\frac{a_{j}^{2} \\sigma_{j}^{2}}{\\sum_{k=1}^{m} a_{k}^{2} \\sigma_{k}^{2}} $$\n\nLastly, we derive the total-effect Sobol index, $S_{T_{j}}$, defined as $S_{T_{j}} = 1 - \\operatorname{Var}_{P_{-j}}\\!\\left(\\mathbb{E}[Y \\mid P_{-j}]\\right) / \\operatorname{Var}(Y)$, where $P_{-j}$ represents the set of all parameters except $P_{j}$. We compute the conditional expectation $\\mathbb{E}[Y \\mid P_{-j}]$:\n$$ \\mathbb{E}[Y \\mid P_{-j}] = \\mathbb{E}\\left[a_{j} P_{j} + \\sum_{k \\neq j} a_{k} P_{k} \\mid P_{-j}\\right] = \\mathbb{E}[a_{j} P_{j} \\mid P_{-j}] + \\mathbb{E}\\left[\\sum_{k \\neq j} a_{k} P_{k} \\mid P_{-j}\\right] $$\nSince $P_{j}$ is independent of the set $P_{-j}$, we have $\\mathbb{E}[a_{j} P_{j} \\mid P_{-j}] = a_{j} \\mathbb{E}[P_{j}] = 0$. The term $\\sum_{k \\neq j} a_{k} P_{k}$ is fully determined by the variables in $P_{-j}$, so its expectation conditional on $P_{-j}$ is itself.\n$$ \\mathbb{E}[Y \\mid P_{-j}] = 0 + \\sum_{k \\neq j} a_{k} P_{k} = \\sum_{k \\neq j} a_{k} P_{k} $$\nNow we compute the variance of this quantity with respect to the variables in $P_{-j}$:\n$$ \\operatorname{Var}_{P_{-j}}\\!\\left(\\mathbb{E}[Y \\mid P_{-j}]\\right) = \\operatorname{Var}\\left(\\sum_{k \\neq j} a_{k} P_{k}\\right) $$\nDue to the mutual independence of the variables in $P_{-j}$, this variance is:\n$$ \\operatorname{Var}\\left(\\sum_{k \\neq j} a_{k} P_{k}\\right) = \\sum_{k \\neq j} \\operatorname{Var}(a_{k} P_{k}) = \\sum_{k \\neq j} a_{k}^{2} \\sigma_{k}^{2} $$\nSubstituting this into the definition of $S_{T_{j}}$:\n$$ S_{T_{j}} = 1 - \\frac{\\sum_{k \\neq j} a_{k}^{2} \\sigma_{k}^{2}}{\\operatorname{Var}(Y)} = 1 - \\frac{\\sum_{k \\neq j} a_{k}^{2} \\sigma_{k}^{2}}{\\sum_{k=1}^{m} a_{k}^{2} \\sigma_{k}^{2}} $$\nBringing to a common denominator:\n$$ S_{T_{j}} = \\frac{\\left(\\sum_{k=1}^{m} a_{k}^{2} \\sigma_{k}^{2}\\right) - \\left(\\sum_{k \\neq j} a_{k}^{2} \\sigma_{k}^{2}\\right)}{\\sum_{k=1}^{m} a_{k}^{2} \\sigma_{k}^{2}} $$\nThe numerator simplifies to just the term for index $j$:\n$$ \\left(\\sum_{k=1}^{m} a_{k}^{2} \\sigma_{k}^{2}\\right) - \\left(\\sum_{k \\neq j} a_{k}^{2} \\sigma_{k}^{2}\\right) = a_{j}^{2} \\sigma_{j}^{2} $$\nTherefore, the total-effect index is:\n$$ S_{T_{j}} = \\frac{a_{j}^{2} \\sigma_{j}^{2}}{\\sum_{k=1}^{m} a_{k}^{2} \\sigma_{k}^{2}} $$\nWe find that for this linear model with independent inputs, $S_{j} = S_{T_{j}}$. This is an expected result because such a model is purely additive, meaning there are no interaction effects between parameters. The total-effect index measures the main effect plus all interactions; with no interactions, it equals the main effect, which is what the first-order index measures.", "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n\\frac{a_{j}^{2} \\sigma_{j}^{2}}{\\sum_{k=1}^{m} a_{k}^{2} \\sigma_{k}^{2}} & \\frac{a_{j}^{2} \\sigma_{j}^{2}}{\\sum_{k=1}^{m} a_{k}^{2} \\sigma_{k}^{2}}\n\\end{pmatrix}\n}\n$$", "id": "2673531"}, {"introduction": "For most real-world models, sensitivity indices cannot be derived analytically. This final exercise provides hands-on computational practice by introducing a powerful surrogate modeling technique: Polynomial Chaos Expansion (PCE) [@problem_id:2673601]. You will implement a non-intrusive PCE to approximate a non-linear model output and then compute the Sobol indices directly from the resulting polynomial coefficients, bridging the gap between GSA theory and its practical application.", "problem": "Consider the irreversible, first-order reaction network with mass-action kinetics, $A \\xrightarrow{k_1} B$ and $B \\xrightarrow{k_2} C$, starting from $(A(0),B(0),C(0))=(A_0,0,0)$. Let the uncertain parameters $(k_1,k_2)$ be independent and log-normally distributed as $k_i = \\exp(\\mu_i + \\sigma_i Z_i)$ where $Z_i \\sim \\mathcal{N}(0,1)$ are independent standard normal random variables. Define the scalar quantity of interest $Y = B_{\\max}$, the maximal transient concentration of species $B$ over time $t \\ge 0$.\n\nYour task is to implement a non-intrusive, low-order Polynomial Chaos Expansion (PCE) surrogate for $Y$ using an orthonormal basis of probabilists' Hermite polynomials in the standard normal variables, and then compute first-order Sobol sensitivity indices for $k_1$ and $k_2$ directly from the PCE coefficients.\n\nFundamental base:\n- Mass-action kinetics yields the system of ordinary differential equations $dA/dt = -k_1 A$, $dB/dt = k_1 A - k_2 B$, $dC/dt = k_2 B$, with $A(0)=A_0$, $B(0)=0$, $C(0)=0$.\n- The exact solution is $A(t) = A_0 e^{-k_1 t}$ and $B(t) = \\dfrac{k_1 A_0}{k_2 - k_1}\\left(e^{-k_1 t} - e^{-k_2 t}\\right)$ for $k_1 \\ne k_2$; for $k_1 = k_2$ the limit can be derived by l'HÃ´pital's rule.\n- The maximum of $B(t)$ over $t \\ge 0$ occurs at the unique critical time $t^\\star = \\dfrac{\\ln(k_2/k_1)}{k_2 - k_1}$ for $k_1 \\ne k_2$, giving a closed-form expression for $B_{\\max} = B(t^\\star)$. In the limit $k_1 \\to k_2$, $B_{\\max} = A_0/e$.\n\nPCE specification:\n- Use a total-order $p$ PCE with $p=2$ in the standard normal inputs $(Z_1,Z_2)$.\n- Use the orthonormal basis built from probabilists' Hermite polynomials $\\{\\psi_n(z)\\}_{n=0}^2$ with respect to the standard normal probability density function (PDF), where $\\psi_0(z)=1$, $\\psi_1(z)=z$, and $\\psi_2(z)=(z^2-1)/\\sqrt{2}$; the 2-variate basis functions are tensor products $\\Psi_{i,j}(Z_1,Z_2)=\\psi_i(Z_1)\\psi_j(Z_2)$.\n- Estimate the PCE coefficients by spectral projection with tensor-product Gaussâ€“Hermite quadrature adapted to the standard normal PDF via the change of variables $Z=\\sqrt{2}\\,x$, where $x$ is the Gaussâ€“Hermite node associated with the weight $e^{-x^2}$. Use $q=9$ nodes per input dimension.\n- With an orthonormal PCE, the variance is the sum of squared non-constant coefficients, and the first-order Sobol index for $k_1$ ($S_{k_1}$) is the fraction of variance contributed by coefficients whose basis depends only on $Z_1$, i.e., indices $(i,0)$ with $i \\ge 1$. Similarly, $S_{k_2}$ uses indices $(0,j)$ with $j \\ge 1$.\n\nNumerical and output requirements:\n- No physical units are required in the output; the Sobol indices are dimensionless and must be reported as decimals (not percentages).\n- Use total PCE order $p=2$ and Gaussâ€“Hermite quadrature with $q=9$ points per input dimension for all cases.\n- For $k_1$ near $k_2$, use a numerically stable evaluation of $B_{\\max}$ based on the limiting case $B_{\\max} = A_0/e$.\n- Implement the full computation as a self-contained program.\n- For each test case, output the pair $(S_{k_1}, S_{k_2})$ rounded to $6$ decimal places.\n\nTest suite:\nCompute $(S_{k_1}, S_{k_2})$ for the following four cases, each specified as $(A_0,\\mu_1,\\sigma_1,\\mu_2,\\sigma_2)$:\n- Case $1$: $(A_0,\\mu_1,\\sigma_1,\\mu_2,\\sigma_2) = (1.0,-0.7,0.25,0.3,0.2)$.\n- Case $2$: $(A_0,\\mu_1,\\sigma_1,\\mu_2,\\sigma_2) = (1.0,0.0,0.05,0.0,0.05)$.\n- Case $3$: $(A_0,\\mu_1,\\sigma_1,\\mu_2,\\sigma_2) = (2.5,-1.0,0.6,0.2,0.6)$.\n- Case $4$: $(A_0,\\mu_1,\\sigma_1,\\mu_2,\\sigma_2) = (0.8,-2.0,0.3,1.0,0.3)$.\n\nFinal output format:\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, with the flattened order\n$[S_{k_1}^{(1)}, S_{k_2}^{(1)}, S_{k_1}^{(2)}, S_{k_2}^{(2)}, S_{k_1}^{(3)}, S_{k_2}^{(3)}, S_{k_1}^{(4)}, S_{k_2}^{(4)}]$\nwhere the superscript indicates the test case index from $1$ to $4$. Each value must be rounded to $6$ decimal places.", "solution": "The problem statement presented is scientifically grounded, well-posed, and objective. It provides a complete and consistent set of definitions, parameters, and objectives for a standard problem in chemical kinetics and uncertainty quantification. All necessary components are specified: the kinetic model, the analytical solution for the quantity of interest, the statistical distributions of uncertain parameters, the precise form of the polynomial chaos expansion including basis functions, and the numerical method for coefficient estimation. The problem is therefore valid, and proceeding with a solution is justified.\n\nThe analysis is structured as follows. First, we define the physical model and the quantity of interest. Second, we formalize the Polynomial Chaos Expansion (PCE) for this quantity. Third, we detail the numerical procedure for computing the PCE coefficients via spectral projection using Gauss-Hermite quadrature. Finally, we derive the first-order Sobol sensitivity indices directly from these coefficients.\n\n**1. Model and Quantity of Interest**\n\nThe problem concerns an irreversible, first-order, two-step reaction network $A \\xrightarrow{k_1} B \\xrightarrow{k_2} C$. The governing system of ordinary differential equations under mass-action kinetics is:\n$$\n\\frac{d[A]}{dt} = -k_1 [A]\n$$\n$$\n\\frac{d[B]}{dt} = k_1 [A] - k_2 [B]\n$$\n$$\n\\frac{d[C]}{dt} = k_2 [B]\n$$\nWith initial conditions $[A](0) = A_0$, $[B](0) = 0$, and $[C](0) = 0$. The analytical solution for the concentration of species $B$ is:\n$$\n[B](t) = \\frac{k_1 A_0}{k_2 - k_1} \\left( e^{-k_1 t} - e^{-k_2 t} \\right) \\quad \\text{for } k_1 \\neq k_2\n$$\nThe quantity of interest, $Y$, is the maximum concentration of $B$, denoted $B_{\\max}$. To find this, we set $\\frac{d[B]}{dt} = 0$, which yields $k_1 [A](t^\\star) = k_2 [B](t^\\star)$. Solving for the time $t^\\star$ at which the maximum occurs gives:\n$$\nt^\\star = \\frac{\\ln(k_2/k_1)}{k_2 - k_1} \\quad \\text{for } k_1 \\neq k_2\n$$\nSubstituting $t^\\star$ back into the expression for $[B](t)$ gives the analytical formula for $Y$:\n$$\nY(k_1, k_2) = B_{\\max} = A_0 \\left( \\frac{k_1}{k_2} \\right)^{\\frac{k_2}{k_2 - k_1}}\n$$\nThis expression is numerically unstable as $k_1 \\to k_2$. In the limiting case $k_1 = k_2 = k$, the solution for $[B](t)$ becomes $[B](t) = k A_0 t e^{-kt}$, with a maximum $B_{\\max} = A_0 / e$ at $t^\\star = 1/k$. For implementation, a threshold is required. If $|k_1 - k_2|$ is small relative to their magnitudes, the limiting value $A_0/e$ must be used to ensure numerical stability.\n\n**2. Polynomial Chaos Expansion**\n\nThe rate parameters $k_1$ and $k_2$ are modeled as independent log-normal random variables. They are functions of independent standard normal random variables $Z_1, Z_2 \\sim \\mathcal{N}(0,1)$:\n$$\nk_1(Z_1) = \\exp(\\mu_1 + \\sigma_1 Z_1)\n$$\n$$\nk_2(Z_2) = \\exp(\\mu_2 + \\sigma_2 Z_2)\n$$\nThe quantity of interest $Y$ is therefore a function of these two random variables, $Y(Z_1, Z_2)$. We approximate $Y(Z_1, Z_2)$ using a PCE of total order $p=2$:\n$$\nY(Z_1, Z_2) \\approx \\hat{Y}(Z_1, Z_2) = \\sum_{|\\alpha| \\le 2} c_{\\alpha} \\Psi_{\\alpha}(Z_1, Z_2)\n$$\nwhere $\\alpha = (\\alpha_1, \\alpha_2)$ is a multi-index of non-negative integers, $|\\alpha| = \\alpha_1 + \\alpha_2$ is its total order, $c_{\\alpha}$ are the PCE coefficients, and $\\Psi_{\\alpha}(Z_1, Z_2)$ are the multivariate basis functions. The basis is constructed from tensor products of one-dimensional orthonormal probabilists' Hermite polynomials, $\\Psi_{\\alpha}(Z_1, Z_2) = \\psi_{\\alpha_1}(Z_1) \\psi_{\\alpha_2}(Z_2)$. The required polynomials are:\n$$\n\\psi_0(z) = 1\n$$\n$$\n\\psi_1(z) = z\n$$\n$$\n\\psi_2(z) = \\frac{z^2 - 1}{\\sqrt{2}}\n$$\nThe expansion up to total order $p=2$ involves $P = \\frac{(n+p)!}{n!p!} = \\frac{(2+2)!}{2!2!} = 6$ basis functions:\n$$\n\\hat{Y} = c_{00}\\Psi_{00} + c_{10}\\Psi_{10} + c_{01}\\Psi_{01} + c_{20}\\Psi_{20} + c_{02}\\Psi_{02} + c_{11}\\Psi_{11}\n$$\n\n**3. Coefficient Estimation via Spectral Projection**\n\nThe coefficients $c_{\\alpha}$ are computed by projecting the model output $Y$ onto the basis functions. Due to the orthonormality of the basis $\\{\\Psi_\\alpha\\}$ with respect to the joint probability density function $\\phi(Z_1,Z_2) = \\phi(Z_1)\\phi(Z_2)$ of the standard normal variables, the coefficients are given by the inner product:\n$$\nc_{\\alpha} = \\langle Y, \\Psi_{\\alpha} \\rangle = \\mathbb{E}[Y \\cdot \\Psi_{\\alpha}] = \\iint_{\\mathbb{R}^2} Y(Z_1, Z_2) \\Psi_{\\alpha}(Z_1, Z_2) \\phi(Z_1)\\phi(Z_2) \\,dZ_1 \\,dZ_2\n$$\nThis integral is approximated numerically using a tensor-product Gauss-Hermite quadrature rule with $q=9$ points per dimension. The standard Gauss-Hermite quadrature approximates integrals of the form $\\int_{-\\infty}^{\\infty} f(x) e^{-x^2} \\,dx$. To handle the standard normal weighting function $\\phi(z) = \\frac{1}{\\sqrt{2\\pi}} e^{-z^2/2}$, we perform a change of variables $z = \\sqrt{2}x$. This leads to the quadrature formula:\n$$\n\\int_{-\\infty}^{\\infty} g(z) \\phi(z) \\,dz = \\frac{1}{\\sqrt{\\pi}} \\int_{-\\infty}^{\\infty} g(\\sqrt{2}x) e^{-x^2} \\,dx \\approx \\sum_{i=1}^{q} g(\\sqrt{2}x_i) \\frac{W_i}{\\sqrt{\\pi}}\n$$\nwhere $(x_i, W_i)$ are the standard physicist's Gauss-Hermite nodes and weights. Let $z_i = \\sqrt{2}x_i$ and $w_i = W_i/\\sqrt{\\pi}$ be the nodes and weights for the probabilist's Hermite polynomials. The coefficients are then estimated as:\n$$\nc_{\\alpha} \\approx \\sum_{i=1}^{q} \\sum_{j=1}^{q} Y(z_i, z_j) \\Psi_{\\alpha}(z_i, z_j) w_i w_j\n$$\nThe algorithm involves evaluating the full model $Y(k_1(z_i), k_2(z_j))$ at each point $(z_i, z_j)$ on the $q \\times q$ quadrature grid.\n\n**4. Sobol' Sensitivity Indices from PCE Coefficients**\n\nA key advantage of using an orthonormal PCE is that the Sobol' indices can be computed directly from the coefficients without additional model evaluations. The total variance $D$ of the PCE surrogate is the sum of the squares of all non-constant coefficients:\n$$\nD = \\text{Var}[\\hat{Y}] = \\sum_{|\\alpha| > 0} c_{\\alpha}^2 \\langle \\Psi_{\\alpha}^2 \\rangle = \\sum_{0 < |\\alpha| \\le p} c_{\\alpha}^2\n$$\nFor our $p=2$ expansion, this is:\n$$\nD \\approx c_{10}^2 + c_{01}^2 + c_{20}^2 + c_{02}^2 + c_{11}^2\n$$\nThe first-order Sobol' index for an input variable measures the fraction of the total variance that is due to that variable alone. For input $Z_1$ (which controls $k_1$), this corresponds to the variance contributed by all basis functions that depend only on $Z_1$. The partial variance $D_1$ is:\n$$\nD_1 \\approx \\sum_{\\alpha_1=1}^{p} c_{(\\alpha_1, 0, \\dots, 0)}^2 = c_{10}^2 + c_{20}^2\n$$\nSimilarly, the partial variance $D_2$ associated with $Z_2$ (which controls $k_2$) is:\n$$\nD_2 \\approx \\sum_{\\alpha_2=1}^{p} c_{(0, \\alpha_2, \\dots, 0)}^2 = c_{01}^2 + c_{02}^2\n$$\nThe first-order Sobol' indices for the parameters $k_1$ and $k_2$ are then given by:\n$$\nS_{k_1} = \\frac{D_1}{D} = \\frac{c_{10}^2 + c_{20}^2}{c_{10}^2 + c_{01}^2 + c_{20}^2 + c_{02}^2 + c_{11}^2}\n$$\n$$\nS_{k_2} = \\frac{D_2}{D} = \\frac{c_{01}^2 + c_{02}^2}{c_{10}^2 + c_{01}^2 + c_{20}^2 + c_{02}^2 + c_{11}^2}\n$$\nThis procedure will be applied to each of the four test cases provided.", "answer": "[0.187383,0.810565,0.499147,0.499147,0.428389,0.366579,0.063259,0.933390]", "id": "2673601"}]}