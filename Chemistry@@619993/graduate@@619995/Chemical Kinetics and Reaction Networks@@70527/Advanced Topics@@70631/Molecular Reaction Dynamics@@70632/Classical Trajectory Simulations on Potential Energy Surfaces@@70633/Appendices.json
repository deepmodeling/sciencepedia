{"hands_on_practices": [{"introduction": "The stability and accuracy of any classical trajectory simulation hinge on the choice of the integration time step, $\\Delta t$. If $\\Delta t$ is too large, the integration will not be able to resolve the fastest motions in the system, leading to numerical instability and unphysical dynamics. This foundational exercise guides you through calculating an appropriate time step by analyzing the system's highest frequency vibration, a critical first step in setting up any reliable molecular dynamics simulation [@problem_id:2632264].", "problem": "In a classical trajectory simulation of molecular dynamics (MD) on a Born–Oppenheimer potential energy surface (PES) for an elementary reaction, the fastest vibrational degree of freedom belongs to an X–H bond stretching mode with wavenumber $\\tilde{\\nu} = 3500\\,\\mathrm{cm}^{-1}$. The trajectories are to be integrated with the velocity–Verlet algorithm. To ensure numerical stability and adequate resolution of the fastest oscillation, impose the requirement that the phase advance per integration step for the fastest harmonic mode be at most $\\pi/10$ radians. Using the relation between wavenumber and frequency based on the speed of light $c = 2.99792458 \\times 10^{10}\\,\\mathrm{cm}\\,\\mathrm{s}^{-1}$, determine a suitable time step $\\Delta t$ in femtoseconds that satisfies this requirement. Round your final numerical answer to $3$ significant figures and express it in femtoseconds. Then, briefly discuss how this choice of $\\Delta t$ affects the computational cost of computing reaction rate constants via ensembles of MD trajectories on the PES, assuming fixed total simulated physical time per trajectory.", "solution": "The problem as stated is scientifically grounded, well-posed, and objective. It presents a standard calculation required in the setup of molecular dynamics simulations, providing all necessary physical constants and constraints. The problem is valid.\n\nThe central task is to determine the maximum integration time step, $\\Delta t$, that satisfies a stability criterion for the fastest vibrational mode in a system. The stability of numerical integration schemes like the velocity–Verlet algorithm is critically dependent on the time step being significantly smaller than the period of the fastest motion in the system.\n\nFirst, we must relate the given wavenumber, $\\tilde{\\nu}$, to the angular frequency, $\\omega$, of the harmonic oscillator that models the X–H bond stretch. The wavenumber $\\tilde{\\nu}$ is the number of waves per unit length, typically in $\\mathrm{cm}^{-1}$. The frequency $\\nu$ (in $\\mathrm{s}^{-1}$ or Hz) is related to the wavenumber by the speed of light, $c$:\n$$\n\\nu = c \\tilde{\\nu}\n$$\nThe angular frequency $\\omega$ (in radians per second) is related to the frequency $\\nu$ by:\n$$\n\\omega = 2\\pi\\nu\n$$\nCombining these two relations, we express $\\omega$ directly in terms of $\\tilde{\\nu}$ and $c$:\n$$\n\\omega = 2\\pi c \\tilde{\\nu}\n$$\nThe problem imposes a constraint on the phase advance per integration step, $\\Delta\\phi$. For a harmonic oscillator, the phase advances by $\\omega \\Delta t$ over a time interval $\\Delta t$. The requirement is that this phase advance be no more than $\\pi/10$ radians:\n$$\n\\Delta\\phi = \\omega \\Delta t \\le \\frac{\\pi}{10}\n$$\nTo find the largest permissible time step, we solve for $\\Delta t$ using the equality:\n$$\n\\Delta t = \\frac{\\pi}{10\\omega}\n$$\nNow, substitute the expression for $\\omega$ in terms of the given parameters:\n$$\n\\Delta t = \\frac{\\pi}{10(2\\pi c \\tilde{\\nu})} = \\frac{1}{20 c \\tilde{\\nu}}\n$$\nThis equation provides the maximum suitable time step. We are given the values:\n$\\tilde{\\nu} = 3500\\,\\mathrm{cm}^{-1}$\n$c = 2.99792458 \\times 10^{10}\\,\\mathrm{cm}\\,\\mathrm{s}^{-1}$\n\nPlugging these values into the expression for $\\Delta t$:\n$$\n\\Delta t = \\frac{1}{20 \\times (2.99792458 \\times 10^{10}\\,\\mathrm{cm}\\,\\mathrm{s}^{-1}) \\times (3500\\,\\mathrm{cm}^{-1})}\n$$\nThe units $\\mathrm{cm}^{-1}$ and $\\mathrm{cm}$ cancel, leaving the result in seconds ($\\mathrm{s}$).\n$$\n\\Delta t = \\frac{1}{20 \\times 3500 \\times 2.99792458 \\times 10^{10}}\\,\\mathrm{s}\n$$\n$$\n\\Delta t = \\frac{1}{70000 \\times 2.99792458 \\times 10^{10}}\\,\\mathrm{s}\n$$\n$$\n\\Delta t = \\frac{1}{2.098547206 \\times 10^{15}}\\,\\mathrm{s} \\approx 4.76520 \\times 10^{-16}\\,\\mathrm{s}\n$$\nThe problem requires the answer in femtoseconds ($\\mathrm{fs}$), where $1\\,\\mathrm{fs} = 10^{-15}\\,\\mathrm{s}$. We convert the result:\n$$\n\\Delta t \\approx (4.76520 \\times 10^{-16}\\,\\mathrm{s}) \\times \\left(\\frac{1\\,\\mathrm{fs}}{10^{-15}\\,\\mathrm{s}}\\right) = 0.476520\\,\\mathrm{fs}\n$$\nRounding to $3$ significant figures, we obtain $\\Delta t = 0.477\\,\\mathrm{fs}$.\n\nRegarding the second part of the problem, the choice of this small $\\Delta t$ has a direct and significant impact on the computational cost. The total number of integration steps, $N_{\\text{steps}}$, required to simulate a physical time duration $T_{\\text{total}}$ is given by the relation:\n$$\nN_{\\text{steps}} = \\frac{T_{\\text{total}}}{\\Delta t}\n$$\nTo calculate a statistically meaningful reaction rate constant, one must simulate a large ensemble of trajectories, each for a sufficiently long physical time $T_{\\text{total}}$ to observe the reactive event. The total computational cost is proportional to the total number of force evaluations, which is proportional to $N_{\\text{steps}}$. As shown by the equation, $N_{\\text{steps}}$ is inversely proportional to $\\Delta t$.\n\nTherefore, a small $\\Delta t$, such as the value of approximately $0.5\\,\\mathrm{fs}$ dictated by the fast X–H bond vibration, forces the simulation to take a very large number of small steps to cover a given physical time. This dramatically increases the computational cost. If the time step were, for example, $10$ times larger, the simulation would be approximately $10$ times faster. However, such a large time step would fail to resolve the X–H stretch, leading to numerical instability and unphysical dynamics. This trade-off between accuracy/stability and computational cost is a fundamental challenge in molecular dynamics simulations, particularly for systems containing light atoms like hydrogen.", "answer": "$$\n\\boxed{0.477}\n$$", "id": "2632264"}, {"introduction": "The potential energy surface (PES) is the landscape that dictates the course of a chemical reaction, and its most significant features are its stationary points: minima corresponding to reactants and products, and saddle points corresponding to transition states. Before simulating reaction dynamics, it is essential to locate and characterize these points. This practice introduces the powerful Newton-Raphson method for automatically finding stationary points on a multi-dimensional PES and classifying them by analyzing the local curvature via the Hessian matrix [@problem_id:2632278].", "problem": "Consider a two-degree-of-freedom Potential Energy Surface (PES) defined by a twice continuously differentiable scalar potential function $V(q_1,q_2)$, where $q_1$ and $q_2$ are dimensionless generalized coordinates. In classical trajectory simulations on potential energy surfaces, the local structure of $V$ near stationary points (solutions of $\\nabla V = \\mathbf{0}$) governs reactive bottlenecks via the transition state, which is an index-$1$ saddle point. Your task is to implement a Newton–Raphson stationary-point search that uses the analytic gradient and Hessian of $V$, and then verify the stationary-point index by counting the number of negative eigenvalues of the Hessian at the converged point. Work entirely in mathematical terms with no external input.\n\nFundamental base to be used: Start from the Taylor expansion of the gradient and the condition for stationarity $\\nabla V(\\mathbf{q}^\\star) = \\mathbf{0}$. Do not assume any particular pre-derived update formula; implement the Newton–Raphson step by deriving it from first principles using the linearization of $\\nabla V$ about the current iterate. Because stationary points need not be minima, use step control that is consistent with convergence to stationary points (for example, by decreasing the norm of the gradient).\n\nImplement the following requirements:\n\n- Variables and operators:\n  - Let $\\mathbf{q} = (q_1,q_2)^\\top$.\n  - Let $\\mathbf{g}(\\mathbf{q}) = \\nabla V(\\mathbf{q}) \\in \\mathbb{R}^2$ be the gradient.\n  - Let $\\mathbf{H}(\\mathbf{q}) = \\nabla^2 V(\\mathbf{q}) \\in \\mathbb{R}^{2 \\times 2}$ be the Hessian.\n  - Use a convergence tolerance $\\varepsilon_{\\text{grad}} = 10^{-10}$ on the Euclidean norm $\\|\\mathbf{g}(\\mathbf{q})\\|_2$, a maximum of $N_{\\max} = 50$ iterations, and a line-search backtracking factor of $\\beta = \\tfrac{1}{2}$ if a full step fails to reduce $\\|\\mathbf{g}(\\mathbf{q})\\|_2$. If the Hessian is ill-conditioned or singular, regularize it by adding $\\mu \\mathbf{I}$ with $\\mu > 0$ chosen adaptively until a step can be computed.\n  - Determine the stationary-point index as the integer count of negative eigenvalues of $\\mathbf{H}(\\mathbf{q}^\\star)$ using an eigenvalue threshold $\\varepsilon_{\\lambda} = 10^{-8}$; that is, count eigenvalues $\\lambda$ with $\\lambda  -\\varepsilon_{\\lambda}$ as negative.\n- Units:\n  - The coordinates $q_1,q_2$ and energy $V$ are dimensionless. Report energies in the same arbitrary energy units as defined by $V$.\n- Output specification:\n  - For each test case, return a list $[q_1^\\star, q_2^\\star, \\text{index}, V^\\star]$ where $q_1^\\star$ and $q_2^\\star$ are the converged coordinates, $\\text{index}$ is an integer, and $V^\\star = V(q_1^\\star,q_2^\\star)$. Round $q_1^\\star$, $q_2^\\star$, and $V^\\star$ to $6$ decimal places.\n  - Your program should produce a single line of output containing the results for all test cases as a comma-separated list enclosed in square brackets; for example, $[r_1,r_2,r_3,\\ldots]$, where each $r_k$ is the list for test case $k$ as specified above.\n\nTest suite:\n\nImplement the Newton–Raphson search for the four analytic potentials below. For each potential, use the provided gradient $\\mathbf{g}$, Hessian $\\mathbf{H}$, and initial guess $\\mathbf{q}^{(0)}$, and produce a result $[q_1^\\star, q_2^\\star, \\text{index}, V^\\star]$.\n\n- Test case $1$ (indefinite quadratic with coupling, index-$1$ saddle):\n  - $V_1(q_1,q_2) = \\tfrac{1}{2}\\left(2 q_1^2 - 1\\cdot q_2^2\\right) + 0.3\\, q_1 q_2$.\n  - $$\\mathbf{g}_1(q_1,q_2) = \\begin{bmatrix} 2 q_1 + 0.3 q_2 \\\\ - q_2 + 0.3 q_1 \\end{bmatrix}.$$\n  - $$\\mathbf{H}_1(q_1,q_2) = \\begin{bmatrix} 2  0.3 \\\\ 0.3  -1 \\end{bmatrix}.$$\n  - Initial guess $\\mathbf{q}^{(0)} = (1.0, 1.0)^\\top$.\n- Test case $2$ (quartic-confined maximum, index-$2$):\n  - $V_2(q_1,q_2) = -\\left(q_1^2 + 2 q_2^2\\right) + \\tfrac{1}{4}\\left(q_1^4 + q_2^4\\right)$.\n  - $$\\mathbf{g}_2(q_1,q_2) = \\begin{bmatrix} -2 q_1 + q_1^3 \\\\ -4 q_2 + q_2^3 \\end{bmatrix}.$$\n  - $$\\mathbf{H}_2(q_1,q_2) = \\begin{bmatrix} -2 + 3 q_1^2  0 \\\\ 0  -4 + 3 q_2^2 \\end{bmatrix}.$$\n  - Initial guess $\\mathbf{q}^{(0)} = (0.2, -0.1)^\\top$.\n- Test case $3$ (double-well along $q_1$ crossed with harmonic $q_2$, index-$1$ saddle at the origin):\n  - $V_3(q_1,q_2) = \\left(q_1^2 - 1\\right)^2 + \\tfrac{1}{2} q_2^2$.\n  - $$\\mathbf{g}_3(q_1,q_2) = \\begin{bmatrix} 4 q_1 \\left(q_1^2 - 1\\right) \\\\ q_2 \\end{bmatrix}.$$\n  - $$\\mathbf{H}_3(q_1,q_2) = \\begin{bmatrix} 12 q_1^2 - 4  0 \\\\ 0  1 \\end{bmatrix}.$$\n  - Initial guess $\\mathbf{q}^{(0)} = (0.3, 0.4)^\\top$.\n- Test case $4$ (positive-definite quadratic with coupling, index-$0$ minimum):\n  - $V_4(q_1,q_2) = \\tfrac{1}{2}\\left(q_1^2 + q_2^2\\right) + 0.1\\, q_1 q_2$.\n  - $$\\mathbf{g}_4(q_1,q_2) = \\begin{bmatrix} q_1 + 0.1 q_2 \\\\ q_2 + 0.1 q_1 \\end{bmatrix}.$$\n  - $$\\mathbf{H}_4(q_1,q_2) = \\begin{bmatrix} 1  0.1 \\\\ 0.1  1 \\end{bmatrix}.$$\n  - Initial guess $\\mathbf{q}^{(0)} = (2.0, -1.0)^\\top$.\n\nAlgorithmic requirements:\n\n- Implement a Newton–Raphson iteration derived from linearizing $\\mathbf{g}(\\mathbf{q})$ about the current iterate to compute a trial step. If the Hessian is not solvable or is ill-conditioned, regularize it by adding $\\mu \\mathbf{I}$ with $\\mu$ increased as needed until a step can be obtained.\n- Use backtracking on the step length $\\alpha \\in (0,1]$ to ensure a decrease in $\\|\\mathbf{g}(\\mathbf{q})\\|_2$; for example, if $\\|\\mathbf{g}(\\mathbf{q} + \\alpha \\mathbf{s})\\|_2 \\ge \\|\\mathbf{g}(\\mathbf{q})\\|_2$, reduce $\\alpha \\leftarrow \\beta \\alpha$ with $\\beta = \\tfrac{1}{2}$, up to a reasonable minimum step length.\n- Stop when either $\\|\\mathbf{g}(\\mathbf{q})\\|_2 \\le \\varepsilon_{\\text{grad}}$, or the number of iterations reaches $N_{\\max}$, or the step length becomes too small to make progress.\n\nFinal output format:\n\n- Your program should produce a single line of output containing a Python-style list of four lists, one per test case, each inner list in the order $[q_1^\\star, q_2^\\star, \\text{index}, V^\\star]$ with $q_1^\\star$, $q_2^\\star$, and $V^\\star$ rounded to $6$ decimals, and $\\text{index}$ an integer. For example: $[[\\cdot,\\cdot,\\cdot,\\cdot],[\\cdot,\\cdot,\\cdot,\\cdot],[\\cdot,\\cdot,\\cdot,\\cdot],[\\cdot,\\cdot,\\cdot,\\cdot]]$.", "solution": "The problem requires the implementation of a Newton–Raphson algorithm to locate stationary points on a two-dimensional potential energy surface, $V(q_1, q_2)$, and to characterize these points by their index. The foundation of this task lies in numerical optimization and linear algebra.\n\nA stationary point, denoted $\\mathbf{q}^\\star$, of a potential energy function $V(\\mathbf{q})$ is a point where the gradient of the function vanishes. For our two-dimensional system with coordinates $\\mathbf{q} = (q_1, q_2)^\\top$, this condition is expressed as:\n$$\n\\mathbf{g}(\\mathbf{q}^\\star) = \\nabla V(\\mathbf{q}^\\star) = \\begin{bmatrix} \\frac{\\partial V}{\\partial q_1} \\\\ \\frac{\\partial V}{\\partial q_2} \\end{bmatrix}_{\\mathbf{q}=\\mathbf{q}^\\star} = \\mathbf{0}\n$$\nThe Newton–Raphson method is an iterative procedure for finding roots of a system of nonlinear equations. Here, we apply it to find the roots of the gradient vector, $\\mathbf{g}(\\mathbf{q}) = \\mathbf{0}$.\n\nThe derivation begins with a first-order Taylor expansion of the gradient vector $\\mathbf{g}(\\mathbf{q})$ around the current iterate, $\\mathbf{q}^{(k)}$. Let $\\Delta\\mathbf{q} = \\mathbf{q}^{(k+1)} - \\mathbf{q}^{(k)}$ be the step to the next iterate. The gradient at the new point $\\mathbf{q}^{(k+1)}$ is approximated as:\n$$\n\\mathbf{g}(\\mathbf{q}^{(k+1)}) = \\mathbf{g}(\\mathbf{q}^{(k)} + \\Delta\\mathbf{q}) \\approx \\mathbf{g}(\\mathbf{q}^{(k)}) + \\mathbf{H}(\\mathbf{q}^{(k)}) \\Delta\\mathbf{q}\n$$\nwhere $\\mathbf{H}(\\mathbf{q}^{(k)})$ is the Hessian matrix of second partial derivatives of $V$ evaluated at $\\mathbf{q}^{(k)}$:\n$$\n\\mathbf{H}(\\mathbf{q}) = \\nabla^2 V(\\mathbf{q}) = \\begin{bmatrix} \\frac{\\partial^2 V}{\\partial q_1^2}  \\frac{\\partial^2 V}{\\partial q_1 \\partial q_2} \\\\ \\frac{\\partial^2 V}{\\partial q_2 \\partial q_1}  \\frac{\\partial^2 V}{\\partial q_2^2} \\end{bmatrix}\n$$\nTo find the stationary point, we set the gradient at the next iterate to zero, $\\mathbf{g}(\\mathbf{q}^{(k+1)}) = \\mathbf{0}$. This leads to the following linear system for the unknown step $\\Delta\\mathbf{q}$:\n$$\n\\mathbf{g}(\\mathbf{q}^{(k)}) + \\mathbf{H}(\\mathbf{q}^{(k)}) \\Delta\\mathbf{q} = \\mathbf{0}\n$$\nRearranging for $\\Delta\\mathbf{q}$, which we will call the Newton step $\\mathbf{s}^{(k)}$, gives:\n$$\n\\mathbf{H}(\\mathbf{q}^{(k)}) \\mathbf{s}^{(k)} = -\\mathbf{g}(\\mathbf{q}^{(k)})\n$$\nThe step $\\mathbf{s}^{(k)}$ is thus found by solving this system of linear equations. The next iterate is then proposed as $\\mathbf{q}^{(k+1)} = \\mathbf{q}^{(k)} + \\mathbf{s}^{(k)}$.\n\nThe complete algorithm is as follows:\n\n1.  **Initialization**: Start with an initial guess $\\mathbf{q}^{(0)}$, a convergence tolerance $\\varepsilon_{\\text{grad}} = 10^{-10}$, a maximum number of iterations $N_{\\max} = 50$, and a backtracking factor $\\beta = \\frac{1}{2}$.\n\n2.  **Iteration**: For $k = 0, 1, 2, \\dots$ until convergence or $k = N_{\\max}$:\n    a.  **Evaluate**: Compute the gradient vector $\\mathbf{g}_k = \\mathbf{g}(\\mathbf{q}^{(k)})$ and the Hessian matrix $\\mathbf{H}_k = \\mathbf{H}(\\mathbf{q}^{(k)})$.\n    b.  **Check for Convergence**: Calculate the Euclidean norm of the gradient, $\\|\\mathbf{g}_k\\|_2$. If $\\|\\mathbf{g}_k\\|_2 \\le \\varepsilon_{\\text{grad}}$, the algorithm has converged. The stationary point is $\\mathbf{q}^\\star = \\mathbf{q}^{(k)}$. Terminate the iteration.\n    c.  **Compute Search Direction**: Solve the Newton system $\\mathbf{H}_k \\mathbf{s}_k = -\\mathbf{g}_k$ for the search direction $\\mathbf{s}_k$.\n        -   **Regularization**: If $\\mathbf{H}_k$ is singular or ill-conditioned, the system cannot be solved reliably. In such cases, the Hessian is regularized by adding a small multiple of the identity matrix, $\\mu\\mathbf{I}$, where $\\mu > 0$. We solve the modified system $(\\mathbf{H}_k + \\mu\\mathbf{I}) \\mathbf{s}_k = -\\mathbf{g}_k$. The value of $\\mu$ is chosen adaptively, starting at $\\mu=0$ and increasing it (e.g., by factors of $10$) until the matrix becomes invertible.\n    d.  **Line Search with Backtracking**: A full Newton step ($\\alpha=1$) may not lead to a reduction in the gradient norm, which is our measure of progress toward a stationary point. We introduce a step length $\\alpha_k \\in (0, 1]$ and update the position as $\\mathbf{q}^{(k+1)} = \\mathbf{q}^{(k)} + \\alpha_k \\mathbf{s}_k$. We start with $\\alpha_k=1$ and check if the condition $\\|\\mathbf{g}(\\mathbf{q}^{(k)} + \\alpha_k \\mathbf{s}_k)\\|_2  \\|\\mathbf{g}_k\\|_2$ is satisfied. If not, we reduce the step length by the backtracking factor, $\\alpha_k \\leftarrow \\beta \\alpha_k$, and repeat the check until the condition is met or $\\alpha_k$ becomes smaller than a minimum threshold, indicating a stall.\n    e.  **Update**: Set the next iterate $\\mathbf{q}^{(k+1)} = \\mathbf{q}^{(k)} + \\alpha_k \\mathbf{s}_k$.\n\n3.  **Stationary Point Analysis**: After the algorithm converges to $\\mathbf{q}^\\star$, we analyze its nature. The index of a stationary point is defined as the number of negative eigenvalues of the Hessian matrix evaluated at that point, $\\mathbf{H}^\\star = \\mathbf{H}(\\mathbf{q}^\\star)$.\n    -   We compute the eigenvalues $\\lambda_i$ of the symmetric matrix $\\mathbf{H}^\\star$.\n    -   The index is the count of eigenvalues that are strictly negative, accounting for numerical precision. We count an eigenvalue $\\lambda_i$ as negative if $\\lambda_i  -\\varepsilon_{\\lambda}$, where $\\varepsilon_{\\lambda} = 10^{-8}$.\n    -   An index of $0$ corresponds to a minimum, an index of $2$ (for a $2$D system) to a maximum, and an index of $1$ to an index-$1$ saddle point, commonly known as a transition state.\n\n4.  **Final Output**: For each test case, we report the converged coordinates $[q_1^\\star, q_2^\\star]$, the integer index of the stationary point, and the potential energy $V^\\star = V(\\mathbf{q}^\\star)$ at that point.", "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main solver function that orchestrates the stationary point search\n    for all test cases and prints the final results.\n    \"\"\"\n\n    # --- Problem Parameters ---\n    EPS_GRAD = 1e-10\n    MAX_ITER = 50\n    BETA = 0.5\n    EPS_LAMBDA = 1e-8\n    MIN_ALPHA = 1e-12\n    MU_INIT = 1e-8\n    MU_FACTOR = 10.0\n    \n    # --- Test Case Definitions ---\n    test_cases = [\n        {\n            \"V\": lambda q: 0.5 * (2 * q[0]**2 - q[1]**2) + 0.3 * q[0] * q[1],\n            \"g\": lambda q: np.array([2 * q[0] + 0.3 * q[1], -q[1] + 0.3 * q[0]]),\n            \"H\": lambda q: np.array([[2.0, 0.3], [0.3, -1.0]]),\n            \"q0\": np.array([1.0, 1.0]),\n        },\n        {\n            \"V\": lambda q: -(q[0]**2 + 2 * q[1]**2) + 0.25 * (q[0]**4 + q[1]**4),\n            \"g\": lambda q: np.array([-2 * q[0] + q[0]**3, -4 * q[1] + q[1]**3]),\n            \"H\": lambda q: np.array([[-2 + 3 * q[0]**2, 0.0], [0.0, -4 + 3 * q[1]**2]]),\n            \"q0\": np.array([0.2, -0.1]),\n        },\n        {\n            \"V\": lambda q: (q[0]**2 - 1)**2 + 0.5 * q[1]**2,\n            \"g\": lambda q: np.array([4 * q[0] * (q[0]**2 - 1), q[1]]),\n            \"H\": lambda q: np.array([[12 * q[0]**2 - 4, 0.0], [0.0, 1.0]]),\n            \"q0\": np.array([0.3, 0.4]),\n        },\n        {\n            \"V\": lambda q: 0.5 * (q[0]**2 + q[1]**2) + 0.1 * q[0] * q[1],\n            \"g\": lambda q: np.array([q[0] + 0.1 * q[1], q[1] + 0.1 * q[0]]),\n            \"H\": lambda q: np.array([[1.0, 0.1], [0.1, 1.0]]),\n            \"q0\": np.array([2.0, -1.0]),\n        },\n    ]\n\n    def find_stationary_point(V, g, H, q0):\n        \"\"\"\n        Implements the Newton-Raphson algorithm with regularization and backtracking.\n        \"\"\"\n        q = np.copy(q0)\n        \n        for _ in range(MAX_ITER):\n            grad_k = g(q)\n            norm_grad_k = np.linalg.norm(grad_k)\n\n            if norm_grad_k  EPS_GRAD:\n                break\n            \n            H_k = H(q)\n            \n            # --- Solve for Newton step with regularization ---\n            mu = 0.0\n            step = None\n            while step is None:\n                try:\n                    H_reg = H_k + mu * np.identity(2)\n                    step = np.linalg.solve(H_reg, -grad_k)\n                except np.linalg.LinAlgError:\n                    if mu == 0.0:\n                        mu = MU_INIT\n                    else:\n                        mu *= MU_FACTOR\n                    if mu  1e6:  # Failsafe\n                        return None # Could not find a suitable step\n            \n            # --- Backtracking line search ---\n            alpha = 1.0\n            while alpha  MIN_ALPHA:\n                q_trial = q + alpha * step\n                grad_trial = g(q_trial)\n                if np.linalg.norm(grad_trial)  norm_grad_k:\n                    break\n                alpha *= BETA\n            else: # If alpha became too small, stall\n                break\n            \n            q = q + alpha * step\n\n        # --- Post-convergence analysis ---\n        q_star = q\n        H_star = H(q_star)\n        \n        # Eigenvalues of the real symmetric Hessian\n        eigenvalues = np.linalg.eigvalsh(H_star)\n        \n        # Count negative eigenvalues to find the index\n        index = np.sum(eigenvalues  -EPS_LAMBDA)\n        \n        V_star = V(q_star)\n        \n        return [\n            round(q_star[0], 6), \n            round(q_star[1], 6), \n            int(index), \n            round(V_star, 6)\n        ]\n\n    results = []\n    for case in test_cases:\n        result = find_stationary_point(case[\"V\"], case[\"g\"], case[\"H\"], case[\"q0\"])\n        results.append(result)\n\n    # Format output according to specification\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n\n```", "id": "2632278"}, {"introduction": "Transition State Theory (TST) provides a framework for calculating reaction rates based on the crucial \"no-recrossing\" assumption: a trajectory that crosses the dividing surface from reactants to products never returns. This hands-on simulation puts that assumption to the test, allowing you to quantify the prevalence of dynamical recrossing. By comparing the behavior of trajectories at a dynamically optimal dividing surface versus a naive geometric one, you will gain a tangible understanding of the dynamical corrections that are essential for accurate rate calculations [@problem_id:2632247].", "problem": "You will implement and compare two configuration-space dividing surfaces (DS) for a two-degree-of-freedom Hamiltonian model of a barrier-crossing reaction and evaluate dynamical recrossing by counting trajectory crossings in a test ensemble of classical trajectories integrated on a quadratic potential energy surface (PES). The two DS are: (i) a surface orthogonal to the unstable mode at the saddle and (ii) a geometric surface at constant reaction coordinate along a chosen axis. You must derive the algorithm starting from Newton’s laws and Hamilton’s equations of motion.\n\nModel definition:\n- Consider a two-dimensional configuration vector $\\mathbf{q} = (x,y)^{\\mathsf{T}}$ and conjugate momentum $\\mathbf{p} = (p_x,p_y)^{\\mathsf{T}}$, with unit masses so that kinetic energy is $T(\\mathbf{p}) = \\tfrac{1}{2}(p_x^2 + p_y^2)$.\n- The potential energy surface is quadratic with one unstable and one stable mode, constructed by rotating the eigenbasis by an angle $\\theta$ (in radians). Let the rotation matrix be\n$$\n\\mathbf{R}(\\theta) = \\begin{pmatrix}\n\\cos\\theta  -\\sin\\theta \\\\\n\\sin\\theta  \\phantom{-}\\cos\\theta\n\\end{pmatrix}.\n$$\n- Let the Hessian in the eigenbasis be $\\mathrm{diag}(-a, b)$ with $a>0$, $b>0$; the Hessian in the laboratory $(x,y)$ frame is then\n$$\n\\mathbf{H} = \\mathbf{R}(\\theta)\\,\\mathrm{diag}(-a, b)\\,\\mathbf{R}(\\theta)^{\\mathsf{T}}.\n$$\n- The potential is $V(\\mathbf{q}) = \\tfrac{1}{2}\\mathbf{q}^{\\mathsf{T}}\\mathbf{H}\\mathbf{q}$, which has a saddle at $\\mathbf{q}=\\mathbf{0}$ with barrier energy $0$ by construction.\n\nEquations of motion and integrator:\n- Hamilton’s equations read $\\dot{\\mathbf{q}} = \\mathbf{p}$ and $\\dot{\\mathbf{p}} = -\\nabla V(\\mathbf{q}) = -\\mathbf{H}\\mathbf{q}$.\n- Integrate trajectories with the velocity-Verlet algorithm with fixed time step $\\Delta t$:\n  1. $\\mathbf{p}_{n+\\tfrac{1}{2}} = \\mathbf{p}_n - \\tfrac{1}{2}\\Delta t\\,\\mathbf{H}\\mathbf{q}_n$,\n  2. $\\mathbf{q}_{n+1} = \\mathbf{q}_n + \\Delta t\\,\\mathbf{p}_{n+\\tfrac{1}{2}}$,\n  3. $\\mathbf{p}_{n+1} = \\mathbf{p}_{n+\\tfrac{1}{2}} - \\tfrac{1}{2}\\Delta t\\,\\mathbf{H}\\mathbf{q}_{n+1}$.\n\nDividing surfaces to compare:\n- Define the rotation that maps lab-frame coordinates to eigenbasis coordinates by $\\mathbf{c} = (u,v)^{\\mathsf{T}} = \\mathbf{R}(\\theta)^{\\mathsf{T}}\\mathbf{q}$ and similarly for momenta $\\mathbf{\\pi} = (p_u,p_v)^{\\mathsf{T}} = \\mathbf{R}(\\theta)^{\\mathsf{T}}\\mathbf{p}$.\n- DS 1 (unstable-mode orthogonal DS): the level set $u=0$; count only forward crossings with $p_u>0$.\n- DS 2 (geometric DS at constant reaction coordinate): the level set $x=0$; count only forward crossings with $p_x>0$.\n- For a perfect no-recrossing DS, each reactive trajectory should have exactly one forward crossing. Define the recrossing count for a single trajectory as $\\max(0, N_+ - 1)$, where $N_+$ is the number of forward crossings. The total recrossing for an ensemble is the sum of these per-trajectory recrossing counts.\n\nInitial ensemble and energy:\n- Work in the eigenbasis to set initial conditions. Fix the initial unstable coordinate at $u(0) = s_0  0$ (reactant side) and draw the initial stable coordinate $v(0)$ from a normal distribution with mean $0$ and standard deviation $\\sigma$. Set the initial stable momentum $p_v(0)=0$.\n- Enforce a microcanonical total energy $E>0$ by solving for $p_u(0)>0$ from\n$$\nE = \\tfrac{1}{2}\\left(p_u(0)^2 + p_v(0)^2\\right) + \\tfrac{1}{2}\\left(-a\\,u(0)^2 + b\\,v(0)^2\\right).\n$$\nIf the right-hand side would make $p_u(0)$ imaginary for a sampled $v(0)$, reject that $v(0)$ and resample until feasible.\n- Transform initial conditions back to the lab frame via $\\mathbf{q}(0) = \\mathbf{R}(\\theta)\\,(u(0),v(0))^{\\mathsf{T}}$ and $\\mathbf{p}(0) = \\mathbf{R}(\\theta)\\,(p_u(0),0)^{\\mathsf{T}}$.\n\nTrajectory integration and crossing detection:\n- For each trajectory, integrate up to a maximum time $T_{\\max}$ or until the absolute unstable coordinate magnitude exceeds a cutoff $U_{\\mathrm{cut}}$ (to avoid numerical overflow), whichever occurs first.\n- Detect forward crossings for DS 1 by sign changes of $u$ from $\\le 0$ to $0$ with $p_u>0$ at the detection time; similarly for DS 2 with $x$ and $p_x$.\n- The total recrossing count for a DS is the sum over the ensemble of $\\max(0,N_+ - 1)$ as defined above.\n\nNumerical units:\n- Use reduced dimensionless units with unit mass. Angles, including $\\theta$, must be in radians. Recrossing counts are unitless integers.\n\nTest suite, parameter coverage, and output format:\n- Implement exactly the following three test cases to probe different geometric alignments:\n  1. Case A (aligned, boundary): $a=2.0$, $b=1.0$, $\\theta=0.0$, $E=0.1$, $N=200$, $\\sigma=0.02$, $s_0=-0.05$, $\\Delta t=0.001$, $T_{\\max}=5.0$, $U_{\\mathrm{cut}}=20.0$.\n  2. Case B (moderate rotation): $a=2.0$, $b=1.0$, $\\theta=\\pi/6$, $E=0.1$, $N=200$, $\\sigma=0.02$, $s_0=-0.05$, $\\Delta t=0.001$, $T_{\\max}=5.0$, $U_{\\mathrm{cut}}=20.0$.\n  3. Case C (strong rotation): $a=2.0$, $b=1.0$, $\\theta=\\pi/3$, $E=0.1$, $N=200$, $\\sigma=0.02$, $s_0=-0.05$, $\\Delta t=0.001$, $T_{\\max}=5.0$, $U_{\\mathrm{cut}}=20.0$.\n- Your program must:\n  - Use a fixed random seed to make results deterministic.\n  - Produce, for each case, a list of two integers $[R_{\\mathrm{unstable}}, R_{\\mathrm{geo}}]$ equal to the total recrossing counts summed over the ensemble for DS 1 and DS 2, respectively.\n  - Print a single line containing a list of these per-case lists, in order, with no extra text. The exact format must be: \n    - $[[R_{\\mathrm{unstable}}^{(A)}, R_{\\mathrm{geo}}^{(A)}],[R_{\\mathrm{unstable}}^{(B)}, R_{\\mathrm{geo}}^{(B)}],[R_{\\mathrm{unstable}}^{(C)}, R_{\\mathrm{geo}}^{(C)}]]$.", "solution": "The problem presented is a well-defined exercise in computational chemical dynamics. It is scientifically sound, self-contained, and algorithmically specified. It addresses the fundamental concept of the dividing surface in reaction rate theory, a cornerstone of chemical kinetics. The comparison between the dynamically correct dividing surface and a naive geometric one is a classic and instructive demonstration. I shall proceed with the derivation and algorithmic design.\n\nThe system is described by a two-dimensional Hamiltonian for a particle of unit mass, $m=1$, moving in a quadratic potential energy surface (PES). The state of the system is given by the phase space vector $(\\mathbf{q}, \\mathbf{p})$, where $\\mathbf{q} = (x,y)^{\\mathsf{T}}$ are the configuration-space coordinates and $\\mathbf{p} = (p_x,p_y)^{\\mathsf{T}}$ are the conjugate momenta. The Hamiltonian $H(\\mathbf{q}, \\mathbf{p})$ is the sum of kinetic and potential energies, $H = T(\\mathbf{p}) + V(\\mathbf{q})$.\n\nThe kinetic energy is $T(\\mathbf{p}) = \\frac{1}{2m}\\mathbf{p}^{\\mathsf{T}}\\mathbf{p} = \\frac{1}{2}(p_x^2 + p_y^2)$, since $m=1$.\nThe potential energy is a quadratic form $V(\\mathbf{q}) = \\frac{1}{2}\\mathbf{q}^{\\mathsf{T}}\\mathbf{H}\\mathbf{q}$, where $\\mathbf{H}$ is the Hessian matrix of second derivatives of the potential evaluated at the origin $\\mathbf{q}=\\mathbf{0}$. This PES has a saddle point at the origin.\n\nThe Hessian matrix $\\mathbf{H}$ is constructed from its diagonal form in the eigenbasis. Let the eigenvectors of the Hessian define a coordinate system $(u,v)$. The corresponding eigenvalues are $-a$ and $b$, with $a>0$ and $b>0$. The coordinate $u$ corresponds to the unstable mode (the reaction coordinate at the saddle point), and $v$ corresponds to the stable, transverse mode. In this eigenbasis, the Hessian is $\\mathbf{D} = \\mathrm{diag}(-a, b)$.\n\nThe laboratory frame $(x,y)$ is rotated with respect to the eigenbasis $(u,v)$ by an angle $\\theta$. The transformation is given by the rotation matrix $\\mathbf{R}(\\theta)$:\n$$\n\\mathbf{R}(\\theta) = \\begin{pmatrix} \\cos\\theta  -\\sin\\theta \\\\ \\sin\\theta  \\cos\\theta \\end{pmatrix}\n$$\nA vector expressed in the eigenbasis, $\\mathbf{c} = (u,v)^{\\mathsf{T}}$, is transformed to the lab frame by $\\mathbf{q} = \\mathbf{R}(\\theta)\\mathbf{c}$. The Hessian in the lab frame is therefore obtained by a similarity transformation:\n$$\n\\mathbf{H} = \\mathbf{R}(\\theta)\\,\\mathbf{D}\\,\\mathbf{R}(\\theta)^{\\mathsf{T}}\n$$\nPerforming the matrix multiplication gives:\n$$\n\\mathbf{H} = \\begin{pmatrix} b\\sin^2\\theta - a\\cos^2\\theta  -(a+b)\\sin\\theta\\cos\\theta \\\\ -(a+b)\\sin\\theta\\cos\\theta  b\\cos^2\\theta - a\\sin^2\\theta \\end{pmatrix}\n$$\nThe dynamics of the system are governed by Hamilton's equations of motion:\n$$\n\\dot{\\mathbf{q}} = \\frac{\\partial H}{\\partial \\mathbf{p}} = \\mathbf{p} \\quad (\\text{since } m=1)\n$$\n$$\n\\dot{\\mathbf{p}} = -\\frac{\\partial H}{\\partial \\mathbf{q}} = -\\nabla V(\\mathbf{q}) = -\\mathbf{H}\\mathbf{q}\n$$\nThese coupled first-order ordinary differential equations will be integrated numerically using the specified velocity-Verlet algorithm, which is a second-order, time-reversible, and symplectic method suitable for Hamiltonian systems. For a time step $\\Delta t$, the state $(\\mathbf{q}_{n+1}, \\mathbf{p}_{n+1})$ at time $t_{n+1}$ is computed from the state $(\\mathbf{q}_n, \\mathbf{p}_n)$ at time $t_n$ as follows:\n$$\n\\mathbf{p}_{n+\\frac{1}{2}} = \\mathbf{p}_n - \\frac{1}{2}\\Delta t\\,\\mathbf{H}\\mathbf{q}_n\n$$\n$$\n\\mathbf{q}_{n+1} = \\mathbf{q}_n + \\Delta t\\,\\mathbf{p}_{n+\\frac{1}{2}}\n$$\n$$\n\\mathbf{p}_{n+1} = \\mathbf{p}_{n+\\frac{1}{2}} - \\frac{1}{2}\\Delta t\\,\\mathbf{H}\\mathbf{q}_{n+1}\n$$\nThe simulation requires an ensemble of initial conditions generated from a microcanonical distribution at a fixed total energy $E > 0$. We prepare initial states in the eigenbasis for physical clarity. The trajectory starts on the reactant side of the barrier, $u(0) = s_0  0$. The initial displacement in the stable mode, $v(0)$, is sampled from a Gaussian distribution $\\mathcal{N}(0, \\sigma^2)$, simulating thermal fluctuations in the bath modes. The initial momentum of the stable mode is set to zero, $p_v(0) = 0$. The initial momentum along the unstable mode, $p_u(0)$, is determined by the total energy conservation equation:\n$$\nE = T + V = \\frac{1}{2}(p_u(0)^2 + p_v(0)^2) + \\frac{1}{2}(-a u(0)^2 + b v(0)^2)\n$$\nSolving for $p_u(0)^2$ yields:\n$$\np_u(0)^2 = 2E - p_v(0)^2 + a u(0)^2 - b v(0)^2 = 2E + a s_0^2 - b v(0)^2\n$$\nFor a physically meaningful initial momentum, $p_u(0)^2$ must be non-negative. If a sampled $v(0)$ violates this, it is discarded, and a new value is drawn. We choose the positive root $p_u(0) = \\sqrt{p_u(0)^2}$ to launch the trajectory towards the barrier.\n\nThe initial phase space vector in the eigenbasis, $(\\mathbf{c}(0), \\mathbf{\\pi}(0))$, where $\\mathbf{c}(0) = (s_0, v(0))^{\\mathsf{T}}$ and $\\mathbf{\\pi}(0) = (p_u(0), 0)^{\\mathsf{T}}$, is then transformed back to the laboratory frame for integration:\n$$\n\\mathbf{q}(0) = \\mathbf{R}(\\theta)\\mathbf{c}(0) \\quad \\text{and} \\quad \\mathbf{p}(0) = \\mathbf{R}(\\theta)\\mathbf{\\pi}(0)\n$$\nEach trajectory is integrated for a maximum time $T_{\\max}$ or until the coordinate $u$ exceeds a cutoff magnitude, $|u| > U_{\\mathrm{cut}}$, indicating the particle is far from the interaction region. To check this condition, the lab-frame coordinates must be transformed back to the eigenbasis at each step:\n$$\n\\mathbf{c}(t) = \\mathbf{R}(\\theta)^{\\mathsf{T}}\\mathbf{q}(t) \\quad \\text{and} \\quad \\mathbf{\\pi}(t) = \\mathbf{R}(\\theta)^{\\mathsf{T}}\\mathbf{p}(t)\n$$\nThis gives $u(t) = q_x(t)\\cos\\theta + q_y(t)\\sin\\theta$ and $p_u(t) = p_x(t)\\cos\\theta + p_y(t)\\sin\\theta$.\n\nWe monitor crossings of two dividing surfaces (DS).\n1.  **DS 1 (Unstable-mode orthogonal DS):** Defined by the plane $u=0$. This is the ideal dividing surface for a quadratic barrier, representing the true transition state. A forward crossing is counted if $u$ transitions from $u_n \\le 0$ to $u_{n+1} > 0$ and the corresponding momentum is positive, $p_u(t_{n+1}) > 0$.\n2.  **DS 2 (Geometric DS):** Defined by the plane $x=0$. This is a naive choice based on one of the lab-frame axes. A forward crossing is counted if $x$ transitions from $x_n \\le 0$ to $x_{n+1} > 0$ and the corresponding momentum is positive, $p_x(t_{n+1}) > 0$.\n\nFor each trajectory in an ensemble of size $N$, we count the number of forward crossings, $N_+$, for each DS. A perfect DS would be crossed exactly once by every reactive trajectory. The number of recrossings for a single trajectory is therefore $\\max(0, N_+ - 1)$. The total recrossing count for a DS is the sum of these values over the entire ensemble.\n\nThe algorithmic procedure is as follows:\nFor each test case with parameters $(a, b, \\theta, E, N, \\sigma, s_0, \\Delta t, T_{\\max}, U_{\\mathrm{cut}})$:\n1.  Initialize total recrossing counters $R_{\\mathrm{unstable}} \\to 0$ and $R_{\\mathrm{geo}} \\to 0$. Construct the Hessian $\\mathbf{H}$ and rotation matrix $\\mathbf{R}(\\theta)$.\n2.  For each of $N$ trajectories:\n    a. Generate valid initial conditions $(\\mathbf{q}(0), \\mathbf{p}(0))$ in the lab frame.\n    b. Initialize per-trajectory forward crossing counters $N_{+,u} \\to 0$ and $N_{+,x} \\to 0$.\n    c. Set initial state $(\\mathbf{q}_0, \\mathbf{p}_0) = (\\mathbf{q}(0), \\mathbf{p}(0))$ and determine initial check variables $u_{-1}, x_{-1}$.\n    d. Integrate the equations of motion using velocity-Verlet for up to $T_{\\max}/\\Delta t$ steps. In each step $n$:\n        i. Compute $(\\mathbf{q}_n, \\mathbf{p}_n)$.\n        ii. Transform to eigenbasis to get $u_n$ and $p_{u,n}$.\n        iii. Check for forward crossing of DS 1: if $u_{n-1} \\le 0$ and $u_n > 0$ and $p_{u,n} > 0$, increment $N_{+,u}$.\n        iv. Check for forward crossing of DS 2: if $x_{n-1} \\le 0$ and $x_n > 0$ and $p_{x,n} > 0$, increment $N_{+,x}$.\n        v. Check termination condition $|u_n| > U_{\\mathrm{cut}}$. If true, break the integration loop.\n        vi. Update $u_{n-1} \\to u_n$, $x_{n-1} \\to x_n$.\n    e. Calculate recrossings for this trajectory: $\\Delta R_{\\mathrm{unstable}} = \\max(0, N_{+,u}-1)$ and $\\Delta R_{\\mathrm{geo}} = \\max(0, N_{+,x}-1)$.\n    f. Add to totals: $R_{\\mathrm{unstable}} \\leftarrow R_{\\mathrm{unstable}} + \\Delta R_{\\mathrm{unstable}}$, $R_{\\mathrm{geo}} \\leftarrow R_{\\mathrm{geo}} + \\Delta R_{\\mathrm{geo}}$.\n3.  Store the pair $[R_{\\mathrm{unstable}}, R_{\\mathrm{geo}}]$ for the current test case.\nAfter all cases are processed, format the collected results as specified. A fixed random seed must be used for reproducibility.\n\nWhen $\\theta=0$, the lab and eigen-frames coincide ($x=u, y=v$), so DS 1 and DS 2 are identical. We expect minimal recrossing and identical counts for both. As $\\theta$ increases, the geometric DS ($x=0$) becomes increasingly misaligned with the true transition state ($u=0$), and we anticipate a significant increase in $R_{\\mathrm{geo}}$ while $R_{\\mathrm{unstable}}$ should remain near zero, as it is dynamically correct for this potential.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Implements and compares two dividing surfaces for a 2-DOF Hamiltonian model\n    of a barrier-crossing reaction by simulating ensembles of classical trajectories.\n    \"\"\"\n\n    test_cases = [\n        # Case A (aligned, boundary): a=2.0, b=1.0, theta=0.0, E=0.1, N=200, sigma=0.02, s_0=-0.05, dt=0.001, Tmax=5.0, Ucut=20.0.\n        (2.0, 1.0, 0.0, 0.1, 200, 0.02, -0.05, 0.001, 5.0, 20.0),\n        # Case B (moderate rotation): a=2.0, b=1.0, theta=pi/6, E=0.1, N=200, sigma=0.02, s_0=-0.05, dt=0.001, Tmax=5.0, Ucut=20.0.\n        (2.0, 1.0, np.pi/6, 0.1, 200, 0.02, -0.05, 0.001, 5.0, 20.0),\n        # Case C (strong rotation): a=2.0, b=1.0, theta=pi/3, E=0.1, N=200, sigma=0.02, s_0=-0.05, dt=0.001, Tmax=5.0, Ucut=20.0.\n        (2.0, 1.0, np.pi/3, 0.1, 200, 0.02, -0.05, 0.001, 5.0, 20.0),\n    ]\n\n    all_results = []\n    \n    # Use a fixed random seed for reproducibility.\n    # The problem does not specify a seed, so one is chosen here.\n    rng = np.random.default_rng(seed=42)\n\n    for case in test_cases:\n        a, b, theta, E, N, sigma, s0, dt, Tmax, Ucut = case\n\n        # Construct Hessian and Rotation matrices\n        c, s = np.cos(theta), np.sin(theta)\n        H = np.array([\n            [b * s**2 - a * c**2, -(a + b) * s * c],\n            [-(a + b) * s * c, b * c**2 - a * s**2]\n        ])\n        R = np.array([[c, -s], [s, c]])\n        RT = R.T\n\n        total_recross_unstable = 0\n        total_recross_geo = 0\n\n        for _ in range(N):\n            # Generate initial conditions for one trajectory\n            q0, p0 = generate_initial_conditions(rng, a, b, E, s0, sigma, R)\n\n            # Run the trajectory and count forward crossings\n            n_cross_unstable, n_cross_geo = run_trajectory(q0, p0, H, RT, dt, Tmax, Ucut)\n            \n            # Sum the recrossing counts\n            total_recross_unstable += max(0, n_cross_unstable - 1)\n            total_recross_geo += max(0, n_cross_geo - 1)\n\n        all_results.append([total_recross_unstable, total_recross_geo])\n\n    # Final print statement in the exact required format.\n    # repr() creates a string representation, and .replace removes spaces.\n    print(repr(all_results).replace(\" \", \"\"))\n\ndef generate_initial_conditions(rng, a, b, E, s0, sigma, R):\n    \"\"\"\n    Generates initial phase space coordinates (q0, p0) for a single trajectory.\n    \"\"\"\n    while True:\n        v0 = rng.normal(loc=0.0, scale=sigma)\n        # pv(0) is 0 as per problem spec\n        # E = 1/2(pu^2 + pv^2) + 1/2(-a*u^2 + b*v^2)\n        pu0_sq = 2 * E + a * s0**2 - b * v0**2\n        if pu0_sq = 0:\n            pu0 = np.sqrt(pu0_sq)\n            break\n    \n    # Initial conditions in eigenbasis\n    c0 = np.array([s0, v0])      # (u(0), v(0))\n    pi0 = np.array([pu0, 0.0])   # (pu(0), pv(0))\n\n    # Transform to laboratory frame\n    q0 = R @ c0\n    p0 = R @ pi0\n    \n    return q0, p0\n\ndef run_trajectory(q, p, H, RT, dt, Tmax, Ucut):\n    \"\"\"\n    Integrates a single trajectory and counts forward crossings for both DS.\n    \"\"\"\n    num_steps = int(Tmax / dt)\n    \n    n_cross_unstable = 0\n    n_cross_geo = 0\n    \n    # Get initial values for crossing check.\n    # Lab frame variables\n    x_prev = q[0]\n    # Eigenbasis variables\n    c_prev = RT @ q\n    u_prev = c_prev[0]\n    \n    for _ in range(num_steps):\n        # Velocity-Verlet Integration Step\n        p_half = p - 0.5 * dt * (H @ q)\n        q_next = q + dt * p_half\n        p_next = p_half - 0.5 * dt * (H @ q_next)\n        \n        # Update state\n        q, p = q_next, p_next\n        \n        # Current state variables for checks\n        x_curr = q[0]\n        px_curr = p[0]\n        \n        c_curr = RT @ q\n        pi_curr = RT @ p\n        u_curr = c_curr[0]\n        pu_curr = pi_curr[0]\n        \n        # DS 1 (unstable-mode orthogonal): u=0\n        if u_prev = 0 and u_curr  0 and pu_curr  0:\n            n_cross_unstable += 1\n            \n        # DS 2 (geometric): x=0\n        if x_prev = 0 and x_curr  0 and px_curr  0:\n            n_cross_geo += 1\n            \n        # Update previous state values for next iteration's checks\n        u_prev = u_curr\n        x_prev = x_curr\n        \n        # Check termination condition based on unstable coordinate magnitude\n        if abs(u_curr)  Ucut:\n            break\n            \n    return n_cross_unstable, n_cross_geo\n\nif __name__ == \"__main__\":\n    solve()\n```", "id": "2632247"}]}