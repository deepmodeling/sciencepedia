{"hands_on_practices": [{"introduction": "This first practice provides a foundational exercise in moving from a set of chemical reactions to a continuous stochastic model. You will derive the Chemical Langevin Equation (CLE) for a nonlinear reaction network and then apply the powerful Linear Noise Approximation (LNA) to analyze fluctuations around the system's stable point. This process is a cornerstone of mesoscopic analysis, offering a direct way to quantify the magnitude of intrinsic noise in chemical systems [@problem_id:2684182].", "problem": "Consider a well-stirred, isothermal reaction system in a fixed volume $V$ with a single chemical species $X$ undergoing the following reactions with mass-action kinetics:\n- Immigration: $\\varnothing \\to X$ with rate constant $k_{0}$ (so that the propensity is $a_{1}(X)=k_{0}V$).\n- Linear degradation: $X \\to \\varnothing$ with rate constant $k_{1}$ (so that the propensity is $a_{2}(X)=k_{1}X$).\n- Pairwise annihilation: $2X \\to \\varnothing$ with rate constant $k_{2}$ (so that the propensity is $a_{3}(X)=k_{2}\\,\\frac{X(X-1)}{V}$).\n\nThe system is modeled at mesoscopic scale by the Chemical Master Equation, with propensities defined above and stoichiometric changes $\\nu_{1}=+1$, $\\nu_{2}=-1$, and $\\nu_{3}=-2$. Define the concentration $x=X/V$.\n\nStarting from the master equation description and the definitions of propensities and stoichiometry for a well-stirred system, derive the Chemical Langevin equation (CLE) for the concentration $x$ as an Itō stochastic differential equation of the form $dx=f(x)\\,dt+\\frac{1}{\\sqrt{V}}\\,g(x)\\,dW(t)$, where $W(t)$ is a standard Wiener process. Then, determine the stable deterministic fixed point $x^{\\ast}>0$ of the drift $f(x)$ and linearize the CLE about $x^{\\ast}$ to obtain an Ornstein–Uhlenbeck approximation whose stationary variance can be computed in closed form.\n\nExpress the stationary variance $\\operatorname{Var}[x]$ of the concentration $x$ at stationarity under this linear noise approximation as a single analytic expression in terms of $k_{0}$, $k_{1}$, $k_{2}$, and $V$. Do not introduce any additional symbols beyond these parameters and standard algebraic operations. Express your final answer without units and do not round.", "solution": "The starting point is the Chemical Master Equation for a well-stirred reaction system. For reactions indexed by $r$ with stoichiometric change $\\nu_{r}$ and propensity $a_{r}(X)$, the Chemical Master Equation can be approximated by a Fokker–Planck equation via a Kramers–Moyal expansion under the mesoscopic scaling where fluctuations are of order $\\sqrt{V}$. This yields the Chemical Langevin equation (CLE), an Itō stochastic differential equation for the copy number $X(t)$,\n$$\ndX(t)=\\sum_{r}\\nu_{r}\\,a_{r}\\!\\left(X(t)\\right)\\,dt+\\sum_{r}\\nu_{r}\\,\\sqrt{a_{r}\\!\\left(X(t)\\right)}\\,dW_{r}(t),\n$$\nwhere $W_{r}(t)$ are independent standard Wiener processes. Introducing the concentration $x(t)=X(t)/V$ and writing $a_{r}(X)=V\\,\\alpha_{r}(x)$ to leading order in $V$ (the macroscopic propensities), one obtains\n$$\ndx(t)=\\sum_{r}\\nu_{r}\\,\\alpha_{r}\\!\\left(x(t)\\right)\\,dt+\\frac{1}{\\sqrt{V}}\\sum_{r}\\nu_{r}\\,\\sqrt{\\alpha_{r}\\!\\left(x(t)\\right)}\\,dW_{r}(t).\n$$\nFor the present reactions, the stoichiometric changes are $\\nu_{1}=+1$, $\\nu_{2}=-1$, $\\nu_{3}=-2$. The exact discrete propensities are $a_{1}(X)=k_{0}V$, $a_{2}(X)=k_{1}X$, $a_{3}(X)=k_{2}\\,\\frac{X(X-1)}{V}$. In the mesoscopic limit, the corresponding macroscopic propensities are\n$$\n\\alpha_{1}(x)=k_{0},\\quad \\alpha_{2}(x)=k_{1}x,\\quad \\alpha_{3}(x)=k_{2}x^{2}.\n$$\nTherefore, the CLE for the concentration $x$ is\n$$\ndx=\\underbrace{\\big(k_{0}-k_{1}x-2k_{2}x^{2}\\big)}_{f(x)}\\,dt+\\frac{1}{\\sqrt{V}}\\left[\\,\\nu_{1}\\sqrt{\\alpha_{1}(x)}\\,dW_{1}+\\nu_{2}\\sqrt{\\alpha_{2}(x)}\\,dW_{2}+\\nu_{3}\\sqrt{\\alpha_{3}(x)}\\,dW_{3}\\,\\right].\n$$\nSince $W_{1}$, $W_{2}$, and $W_{3}$ are independent, the one-dimensional noise can be combined into a single effective Wiener process $W(t)$ with a state-dependent amplitude $g(x)$ that matches the total instantaneous variance:\n$$\n\\left(\\frac{1}{\\sqrt{V}}\\,g(x)\\right)^{2}dt=\\frac{1}{V}\\left(\\nu_{1}^{2}\\alpha_{1}(x)+\\nu_{2}^{2}\\alpha_{2}(x)+\\nu_{3}^{2}\\alpha_{3}(x)\\right)dt.\n$$\nThus,\n$$\ng(x)=\\sqrt{\\nu_{1}^{2}\\alpha_{1}(x)+\\nu_{2}^{2}\\alpha_{2}(x)+\\nu_{3}^{2}\\alpha_{3}(x)}=\\sqrt{k_{0}+k_{1}x+4k_{2}x^{2}}.\n$$\nThe CLE in the compact form is therefore\n$$\ndx=\\big(k_{0}-k_{1}x-2k_{2}x^{2}\\big)\\,dt+\\frac{1}{\\sqrt{V}}\\,\\sqrt{k_{0}+k_{1}x+4k_{2}x^{2}}\\,dW(t).\n$$\n\nNext, the deterministic fixed point $x^{\\ast}>0$ solves $f(x^{\\ast})=0$, i.e.,\n$$\nk_{0}-k_{1}x^{\\ast}-2k_{2}(x^{\\ast})^{2}=0,\n$$\nwhich is a quadratic equation $2k_{2}(x^{\\ast})^{2}+k_{1}x^{\\ast}-k_{0}=0$ with roots\n$$\nx=\\frac{-k_{1}\\pm\\sqrt{k_{1}^{2}+8k_{2}k_{0}}}{4k_{2}}.\n$$\nThe positive root is\n$$\nx^{\\ast}=\\frac{-k_{1}+\\sqrt{k_{1}^{2}+8k_{2}k_{0}}}{4k_{2}}.\n$$\nThe linear stability is given by $f'(x)=-k_{1}-4k_{2}x$, so $f'(x^{\\ast})=-k_{1}-4k_{2}x^{\\ast}<0$, and the fixed point is linearly stable.\n\nFor the Linear Noise Approximation (LNA), linearize the CLE about $x^{\\ast}$. Let $y=x-x^{\\ast}$, then\n$$\ndy=f'(x^{\\ast})\\,y\\,dt+\\frac{1}{\\sqrt{V}}\\,g(x^{\\ast})\\,dW(t)+\\text{higher-order terms in }y,\n$$\nand the higher-order terms are neglected. This is an Ornstein–Uhlenbeck process $dy=a\\,y\\,dt+\\sigma\\,dW$ with $a=f'(x^{\\ast})$ and $\\sigma=\\frac{1}{\\sqrt{V}}\\,g(x^{\\ast})$. Its stationary variance is\n$$\n\\operatorname{Var}[y]=\\frac{\\sigma^{2}}{-2a}=\\frac{\\frac{1}{V}\\,g(x^{\\ast})^{2}}{-2f'(x^{\\ast})}.\n$$\nSince $y=x-x^{\\ast}$, $\\operatorname{Var}[x]=\\operatorname{Var}[y]$. We compute $g(x^{\\ast})^{2}$ and $f'(x^{\\ast})$ explicitly. First,\n$$\ng(x^{\\ast})^{2}=k_{0}+k_{1}x^{\\ast}+4k_{2}(x^{\\ast})^{2}.\n$$\nUsing the steady-state relation $k_{0}=k_{1}x^{\\ast}+2k_{2}(x^{\\ast})^{2}$, we can write\n$$\ng(x^{\\ast})^{2}=\\big(k_{1}x^{\\ast}+2k_{2}(x^{\\ast})^{2}\\big)+k_{1}x^{\\ast}+4k_{2}(x^{\\ast})^{2}=2k_{1}x^{\\ast}+6k_{2}(x^{\\ast})^{2}.\n$$\nAlso,\n$$\n-2f'(x^{\\ast})=2\\big(k_{1}+4k_{2}x^{\\ast}\\big).\n$$\nTherefore,\n$$\n\\operatorname{Var}[x]=\\frac{1}{V}\\cdot\\frac{2k_1x^{\\ast} + 6k_2(x^{\\ast})^2}{2\\big(k_{1}+4k_{2}x^{\\ast}\\big)}=\\frac{1}{V}\\cdot\\frac{x^{\\ast}\\big(k_{1}+3k_{2}x^{\\ast}\\big)}{k_{1}+4k_{2}x^{\\ast}}.\n$$\nSubstituting $x^{\\ast}=\\frac{-k_{1}+\\sqrt{k_{1}^{2}+8k_{2}k_{0}}}{4k_{2}}$ yields a closed-form expression purely in terms of $k_{0}$, $k_{1}$, $k_{2}$, and $V$. Let $\\Delta=\\sqrt{k_{1}^{2}+8k_{2}k_{0}}$ for brevity during the algebra. Then\n$$\nk_{1}+4k_{2}x^{\\ast}=k_{1}+4k_{2}\\cdot\\frac{-k_{1}+\\Delta}{4k_{2}}=\\Delta,\n$$\nand\n$$\nk_{1}+3k_{2}x^{\\ast}=k_{1}+3k_{2}\\cdot\\frac{-k_{1}+\\Delta}{4k_{2}}=\\frac{k_{1}+3\\Delta}{4},\n$$\nso\n$$\n\\operatorname{Var}[x]=\\frac{1}{V}\\cdot\\frac{\\left(\\frac{-k_{1}+\\Delta}{4k_{2}}\\right)\\left(\\frac{k_{1}+3\\Delta}{4}\\right)}{\\Delta}=\\frac{\\left(-k_{1}+\\sqrt{k_{1}^{2}+8k_{2}k_{0}}\\right)\\left(k_{1}+3\\sqrt{k_{1}^{2}+8k_{2}k_{0}}\\right)}{16\\,k_{2}\\,\\sqrt{k_{1}^{2}+8k_{2}k_{0}}\\,V}.\n$$\nThis is the required stationary variance of the concentration under the linear noise approximation, expressed solely in terms of $k_{0}$, $k_{1}$, $k_{2}$, and $V$.", "answer": "$$\\boxed{\\frac{\\left(-k_{1}+\\sqrt{k_{1}^{2}+8k_{2}k_{0}}\\right)\\left(k_{1}+3\\sqrt{k_{1}^{2}+8k_{2}k_{0}}\\right)}{16\\,k_{2}\\,\\sqrt{k_{1}^{2}+8k_{2}k_{0}}\\,V}}$$", "id": "2684182"}, {"introduction": "Building on the basics, this problem introduces an essential layer of complexity: external control. We will analyze a system where a reaction rate is not constant but is driven by a periodic external signal, a common feature in biological systems governed by circadian clocks or cellular cycles. This practice will guide you through calculating the system's time-dependent mean and variance, revealing how a stochastic system responds to external forcing [@problem_id:2684171].", "problem": "Consider a single-species, well-mixed isothermal reactor of volume $V>0$ containing species $X$. The reaction network consists of two channels driven by an externally modulated inflow:\n1. Zeroth-order inflow: $\\varnothing \\to X$, with time-dependent macroscopic intensity per unit volume $k_{0}\\,[1+\\epsilon \\cos(\\omega t)]$ where $k_{0}>0$, $\\epsilon \\in (0,1)$, and $\\omega>0$ are constants imposed by an external driver.\n2. First-order degradation: $X \\to \\varnothing$, with rate constant $k_{d}>0$.\n\nLet $N(t)$ denote the (integer-valued) molecule number of $X$ at time $t$. The corresponding propensity functions for the chemical master equation are $a_{1}(t)=V\\,k_{0}\\,[1+\\epsilon \\cos(\\omega t)]$ for the inflow and $a_{2}(N)=k_{d}\\,N$ for degradation.\n\nStarting from the definitions of propensity functions in the chemical master equation and invoking the mesoscopic limit leading to the chemical Langevin equation (CLE) and the linear noise approximation (LNA) around the mean trajectory, do the following:\n\n- Derive the linear ordinary differential equation satisfied by the mean $m(t)=\\mathbb{E}[N(t)]$ and determine its unique long-time periodic solution $m_{\\infty}(t)$ induced by the periodic external drive.\n- Using the LNA about $m_{\\infty}(t)$, derive the closed linear ordinary differential equation governing the variance $v(t)=\\operatorname{Var}[N(t)]$, and determine its unique long-time periodic solution $v_{\\infty}(t)$.\n\nReport, as your final answer, the exact closed-form expression for the asymptotic variance evaluated at phase zero, $v_{\\infty}(0)$, in terms of $V$, $k_{0}$, $\\epsilon$, $\\omega$, and $k_{d}$. The final answer must be a single analytic expression. No numerical values are required, and no rounding is needed. Express the answer in units of molecules squared (do not include units in the boxed final answer).", "solution": "The dynamics of the mean number of molecules $m(t) = \\mathbb{E}[N(t)]$ can be derived directly from the chemical master equation or by taking the expectation of the chemical Langevin equation. The resulting equation is exact for any system with at most linear propensities. The rate of change of the mean is given by the expectation of the sum of stoichiometric changes weighted by their respective propensities.\nThe stoichiometric vectors for the reactions are $S_1 = +1$ and $S_2 = -1$.\n$$\n\\frac{dm(t)}{dt} = \\mathbb{E}[S_1 a_1(t) + S_2 a_2(N)] = \\mathbb{E}[V k_0(1+\\epsilon \\cos(\\omega t)) - k_d N(t)]\n$$\nSince expectation is a linear operator, this yields a closed ordinary differential equation for the mean $m(t)$:\n$$\n\\frac{dm(t)}{dt} = V k_0(1+\\epsilon \\cos(\\omega t)) - k_d m(t)\n$$\nThis is a linear first-order ODE. We seek the unique long-time periodic solution $m_{\\infty}(t)$ that is induced by the external drive. We propose a solution of the form $m_{\\infty}(t) = A + B \\cos(\\omega t) + C \\sin(\\omega t)$. Substituting this into the ODE gives:\n$$\n-B\\omega \\sin(\\omega t) + C\\omega \\cos(\\omega t) = V k_0(1+\\epsilon \\cos(\\omega t)) - k_d(A + B \\cos(\\omega t) + C \\sin(\\omega t))\n$$\nMatching the coefficients of the constant, $\\cos(\\omega t)$, and $\\sin(\\omega t)$ terms yields a system of linear equations for $A$, $B$, and $C$:\n1. Constant: $0 = V k_0 - k_d A \\implies A = \\frac{V k_0}{k_d}$\n2. $\\cos(\\omega t)$: $C\\omega = V k_0 \\epsilon - k_d B \\implies k_d B + \\omega C = V k_0 \\epsilon$\n3. $\\sin(\\omega t)$: $-B\\omega = -k_d C \\implies C = \\frac{\\omega}{k_d} B$\n\nSubstituting $C$ from (3) into (2):\n$$\nk_d B + \\omega \\left(\\frac{\\omega}{k_d} B\\right) = V k_0 \\epsilon \\implies B\\left(\\frac{k_d^2+\\omega^2}{k_d}\\right) = V k_0 \\epsilon \\implies B = \\frac{V k_0 \\epsilon k_d}{k_d^2+\\omega^2}\n$$\nAnd consequently:\n$$\nC = \\frac{\\omega}{k_d} \\left(\\frac{V k_0 \\epsilon k_d}{k_d^2+\\omega^2}\\right) = \\frac{V k_0 \\epsilon \\omega}{k_d^2+\\omega^2}\n$$\nThus, the long-time periodic mean is:\n$$\nm_{\\infty}(t) = \\frac{V k_0}{k_d} + \\frac{V k_0 \\epsilon}{k_d^2+\\omega^2} \\left( k_d \\cos(\\omega t) + \\omega \\sin(\\omega t) \\right)\n$$\nNext, we derive the equation for the variance $v(t) = \\operatorname{Var}[N(t)]$. The equation for variance is exact for this system because all propensities are at most linear functions of $N$. The general form is:\n$$\n\\frac{dv(t)}{dt} = 2 \\mathbb{E}[(N-m)(S_1 a_1 + S_2 a_2)] + \\mathbb{E}[S_1^2 a_1 + S_2^2 a_2]\n$$\n$$\n\\frac{dv(t)}{dt} = 2 \\mathbb{E}[(N-m)(-k_d N)] + \\mathbb{E}[a_1(t) + a_2(N)] = -2k_d \\mathbb{E}[N(N-m)] + a_1(t) + k_d m(t)\n$$\nSince $\\mathbb{E}[N(N-m)] = \\mathbb{E}[(m+\\xi)\\xi] = \\mathbb{E}[\\xi^2] = v$, this simplifies to:\n$$\n\\frac{dv(t)}{dt} = -2k_d v(t) + a_1(t) + k_d m(t)\n$$\nWe now seek its unique long-time periodic solution $v_{\\infty}(t)$. Let us examine the structure of the forcing term: $a_1(t) + k_d m_{\\infty}(t)$. From the ODE for the mean, we have $a_1(t) = \\frac{dm_{\\infty}(t)}{dt} + k_d m_{\\infty}(t)$. Substituting this into the variance ODE gives:\n$$\n\\frac{dv_{\\infty}(t)}{dt} + 2k_d v_{\\infty}(t) = \\left(\\frac{dm_{\\infty}(t)}{dt} + k_d m_{\\infty}(t)\\right) + k_d m_{\\infty}(t)\n$$\n$$\n\\frac{dv_{\\infty}(t)}{dt} + 2k_d v_{\\infty}(t) = \\frac{dm_{\\infty}(t)}{dt} + 2k_d m_{\\infty}(t)\n$$\nLet us define the difference function $\\delta(t) = v_{\\infty}(t) - m_{\\infty}(t)$. The equation can be rewritten as:\n$$\n\\frac{d}{dt}(v_{\\infty}(t) - m_{\\infty}(t)) + 2k_d (v_{\\infty}(t) - m_{\\infty}(t)) = 0\n$$\n$$\n\\frac{d\\delta(t)}{dt} + 2k_d \\delta(t) = 0\n$$\nThe general solution is $\\delta(t) = C \\exp(-2k_d t)$ for some constant $C$. However, both $m_{\\infty}(t)$ and $v_{\\infty}(t)$ are defined as the unique long-time *periodic* solutions. Their difference, $\\delta(t)$, must therefore also be periodic. For $k_d > 0$, the function $C \\exp(-2k_d t)$ is periodic only if $C=0$. Thus, we must have $\\delta(t) = 0$ for all $t$.\nThis establishes the remarkable result that for this system, the long-time periodic variance is equal to the long-time periodic mean:\n$$\nv_{\\infty}(t) = m_{\\infty}(t)\n$$\nThe problem asks for the value of the asymptotic variance at phase zero, $v_{\\infty}(0)$. We can find this by evaluating $m_{\\infty}(t)$ at $t=0$:\n$$\nv_{\\infty}(0) = m_{\\infty}(0) = \\frac{V k_0}{k_d} + \\frac{V k_0 \\epsilon}{k_d^2+\\omega^2} \\left( k_d \\cos(0) + \\omega \\sin(0) \\right)\n$$\n$$\nv_{\\infty}(0) = \\frac{V k_0}{k_d} + \\frac{V k_0 \\epsilon k_d}{k_d^2+\\omega^2}\n$$\nTo present this as a single expression, we find a common denominator:\n$$\nv_{\\infty}(0) = \\frac{V k_0(k_d^2+\\omega^2) + V k_0 \\epsilon k_d^2}{k_d(k_d^2+\\omega^2)}\n$$\n$$\nv_{\\infty}(0) = \\frac{V k_0 [k_d^2 + \\omega^2 + \\epsilon k_d^2]}{k_d(k_d^2+\\omega^2)}\n$$\n$$\nv_{\\infty}(0) = \\frac{V k_0 [k_d^2(1+\\epsilon) + \\omega^2]}{k_d(k_d^2+\\omega^2)}\n$$\nThis is the final analytical expression for the asymptotic variance at $t=0$.", "answer": "$$\n\\boxed{\\frac{V k_{0} \\left(k_{d}^{2}(1+\\epsilon) + \\omega^{2}\\right)}{k_{d}\\left(k_{d}^{2}+\\omega^{2}\\right)}}\n$$", "id": "2684171"}, {"introduction": "Our final practice bridges the gap between theoretical modeling and experimental science. Here, you will use the CLE not just for analysis, but as a statistical tool for parameter inference. By constructing a likelihood function based on the CLE's transition probabilities, you will learn how to determine the most probable kinetic parameters from observed time-series data, a critical skill for any quantitative modeler in biology or chemistry [@problem_id:2684181].", "problem": "Consider an isothermal, well-mixed single-species birth–death reaction network for a molecular species $X(t)$ evolving in mesoscopic copy number space under the stochastic reaction framework. The network consists of two reactions with stoichiometry vectors $\\nu_1 = +1$ and $\\nu_2 = -1$ and propensity functions (mass-action kinetics in copy-number units) $a_1(x) = k_0$ (zero-order birth) and $a_2(x) = k_1 x$ (first-order death), where $k_0 \\ge 0$ and $k_1 \\ge 0$ are unknown kinetic parameters to be inferred from data. Assume complete and noiseless state observation of $X(t)$ at discrete times $t_i = i \\Delta t$ with constant time increment $\\Delta t > 0$. Use the diffusion approximation that leads to the Chemical Langevin Equation (CLE) and a single-step Euler–Maruyama discretization to construct an approximate state–space model with Gaussian transition densities for $X(t)$ over each time step. Build a likelihood function for a full observed trajectory by multiplying these transition densities across time steps. From first principles, derive the resulting log-likelihood that depends on $(k_0,k_1)$, the observed trajectory, and $\\Delta t$, under the assumptions stated.\n\nYour task is to implement a program that, for each provided test case, evaluates the approximate log-likelihood for a finite set of candidate parameter pairs $(k_0,k_1)$ and returns the parameter pair with the largest log-likelihood. Treat all observations as real-valued, and ensure that all Gaussian variances used in the likelihood are strictly positive whenever evaluating a candidate; if a candidate $(k_0,k_1)$ would imply a nonpositive variance for any transition, the candidate must be discarded for that test case. Use only the statistical model implied by the CLE diffusion approximation, and do not introduce any additional observation noise models.\n\nYour derivation must be based on the following fundamentals:\n- The definition of propensities $a_r(x)$ and stoichiometry vectors $\\nu_r$ in stochastic chemical kinetics.\n- The diffusion approximation leading to the Chemical Langevin Equation (CLE) for mesoscopic dynamics of reaction networks.\n- The Euler–Maruyama discretization for stochastic differential equations to obtain approximate Gaussian transition densities.\n\nTest suite:\n- Test case A (general case):\n  - Time increment $\\Delta t = 0.2$.\n  - Observations (ordered list of states at times $t_0,t_1,\\dots,t_{10}$): $[\\,10.0,\\,10.4,\\,10.1,\\,11.2,\\,11.2,\\,12.0,\\,11.8,\\,12.5,\\,12.6,\\,13.1,\\,12.5\\,]$.\n  - Candidate parameter pairs $\\{(k_0,k_1)\\}$: $[\\, [\\,2.0,\\,0.1\\,],\\,[\\,1.0,\\,0.05\\,],\\,[\\,3.5,\\,0.25\\,],\\,[\\,2.0,\\,0.2\\,]\\,]$.\n- Test case B (boundary case with zero first-order death):\n  - Time increment $\\Delta t = 0.5$.\n  - Observations (ordered list of states at times $t_0,t_1,\\dots,t_{7}$): $[\\,3.0,\\,3.4,\\,4.7,\\,4.9,\\,4.8,\\,5.7,\\,6.0,\\,6.5\\,]$.\n  - Candidate parameter pairs $\\{(k_0,k_1)\\}$: $[\\, [\\,1.2,\\,0.0\\,],\\,[\\,1.2,\\,0.05\\,],\\,[\\,0.8,\\,0.0\\,],\\,[\\,2.0,\\,0.2\\,]\\,]$.\n- Test case C (higher rates and stronger state-dependence):\n  - Time increment $\\Delta t = 0.1$.\n  - Observations (ordered list of states at times $t_0,t_1,\\dots,t_{11}$): $[\\,20.0,\\,19.5,\\,20.3,\\,19.1,\\,19.0,\\,18.7,\\,19.3,\\,18.4,\\,18.2,\\,17.7,\\,17.6,\\,18.0\\,]$.\n  - Candidate parameter pairs $\\{(k_0,k_1)\\}$: $[\\, [\\,8.0,\\,0.5\\,],\\,[\\,10.0,\\,0.3\\,],\\,[\\,5.0,\\,0.6\\,],\\,[\\,7.0,\\,0.8\\,]\\,]$.\n\nFor each test case, your program must:\n- Construct the approximate Gaussian transition model implied by the CLE and Euler–Maruyama discretization for the specified network, using the given $\\Delta t$ and observed trajectory.\n- Compute the total log-likelihood for each candidate $(k_0,k_1)$ by summing across all consecutive transitions in the trajectory.\n- Select the candidate with the highest log-likelihood (breaking ties by choosing the first occurring candidate in the provided list).\n- Return the selected $(k_0,k_1)$ for each test case as a pair of decimal numbers rounded to three decimal places, preserving the order $(k_0,k_1)$.\n\nFinal output format:\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, where each element corresponds to a test case and is itself a list $[k_0,k_1]$. For example, the printed line should look like $[[k_{0,A},k_{1,A}],[k_{0,B},k_{1,B}],[k_{0,C},k_{1,C}]]$ with each entry rounded to three decimal places.\n- There are no physical units to report; all quantities are dimensionless copy numbers and rates in consistent internal units. Angles and percentages do not appear in this problem.", "solution": "The problem requires us to determine the most likely kinetic parameters $(k_0, k_1)$ for a birth-death process from a discrete set of candidates, given a time-series observation of the species count. The model for the system dynamics is specified as the diffusion approximation, which leads to the Chemical Langevin Equation (CLE).\n\nFirst, we define the stochastic reaction network. We have one species, $X$, and two reactions:\n$1$. Birth: $\\emptyset \\xrightarrow{k_0} X$, with propensity $a_1(x) = k_0$ and stoichiometry vector $\\nu_1 = +1$.\n$2$. Death: $X \\xrightarrow{k_1} \\emptyset$, with propensity $a_2(x) = k_1 x$ and stoichiometry vector $\\nu_2 = -1$.\nHere, $x$ is the copy number of species $X$, and $k_0 \\ge 0$ and $k_1 \\ge 0$ are the reaction rate constants.\n\nThe Chemical Langevin Equation provides a continuous stochastic differential equation (SDE) that approximates the discrete stochastic dynamics of the chemical master equation. For a general reaction network with $M$ reactions, the state vector $\\mathbf{X}(t)$ evolves according to:\n$$ \\frac{d\\mathbf{X}(t)}{dt} = \\sum_{r=1}^{M} \\boldsymbol{\\nu}_r a_r(\\mathbf{X}(t)) + \\sum_{r=1}^{M} \\boldsymbol{\\nu}_r \\sqrt{a_r(\\mathbf{X}(t))} \\Gamma_r(t) $$\nwhere $\\boldsymbol{\\nu}_r$ is the stoichiometry vector for reaction $r$, $a_r(\\mathbf{X}(t))$ is its propensity, and $\\Gamma_r(t)$ are independent Gaussian white noise processes.\n\nFor our single-species system, this SDE can be written in the Ito form as:\n$$ dX(t) = \\mu(X(t)) dt + \\sigma(X(t)) dW(t) $$\nThe drift term, $\\mu(x)$, is the deterministic rate of change:\n$$ \\mu(x) = \\sum_{r=1}^{2} \\nu_r a_r(x) = (+1)a_1(x) + (-1)a_2(x) = k_0 - k_1 x $$\nThe square of the diffusion term, $\\sigma^2(x)$, represents the magnitude of the stochastic fluctuations:\n$$ \\sigma^2(x) = \\sum_{r=1}^{2} \\nu_r^2 a_r(x) = (+1)^2 a_1(x) + (-1)^2 a_2(x) = k_0 + k_1 x $$\nThus, the governing CLE for the species count $X(t)$ is:\n$$ dX(t) = (k_0 - k_1 X(t)) dt + \\sqrt{k_0 + k_1 X(t)} dW(t) $$\n\nTo construct a likelihood function from discrete time-series data, we must discretize this SDE. The problem specifies using the Euler-Maruyama method. For a small time step $\\Delta t$, the state at time $t_{i+1} = t_i + \\Delta t$ is approximated from the state at $t_i$, denoted $x_i$, as:\n$$ x_{i+1} \\approx x_i + \\mu(x_i) \\Delta t + \\sigma(x_i) \\sqrt{\\Delta t} Z_i $$\nwhere $Z_i$ is a random variable drawn from a standard normal distribution, $Z_i \\sim \\mathcal{N}(0, 1)$.\n\nThis approximation implies that the conditional probability distribution of $x_{i+1}$ given $x_i$ is a Gaussian distribution:\n$$ P(x_{i+1} | x_i; k_0, k_1) \\sim \\mathcal{N}(\\mu_{i+1|i}, \\sigma^2_{i+1|i}) $$\nThe conditional mean $\\mu_{i+1|i}$ is given by the deterministic part of the update:\n$$ \\mu_{i+1|i} = E[x_{i+1} | x_i] = x_i + \\mu(x_i) \\Delta t = x_i + (k_0 - k_1 x_i) \\Delta t $$\nThe conditional variance $\\sigma^2_{i+1|i}$ is given by the squared stochastic part:\n$$ \\sigma^2_{i+1|i} = \\text{Var}[x_{i+1} | x_i] = (\\sigma(x_i) \\sqrt{\\Delta t})^2 = \\sigma^2(x_i) \\Delta t = (k_0 + k_1 x_i) \\Delta t $$\n\nGiven an observed trajectory of states $\\{x_0, x_1, \\dots, x_N\\}$ at times $\\{t_0, t_1, \\dots, t_N\\}$, the total likelihood of the parameters $(k_0, k_1)$ is the product of the probabilities of each observed transition, by the Markov property of the model:\n$$ P(x_1, \\dots, x_N | x_0; k_0, k_1) = \\prod_{i=0}^{N-1} P(x_{i+1} | x_i; k_0, k_1) $$\nFor computational stability and convenience, we work with the log-likelihood, $\\mathcal{L}(k_0, k_1)$:\n$$ \\mathcal{L}(k_0, k_1) = \\ln \\left( \\prod_{i=0}^{N-1} P(x_{i+1} | x_i; k_0, k_1) \\right) = \\sum_{i=0}^{N-1} \\ln P(x_{i+1} | x_i; k_0, k_1) $$\nThe probability density function for a single Gaussian transition is:\n$$ P(x_{i+1} | x_i; k_0, k_1) = \\frac{1}{\\sqrt{2\\pi\\sigma^2_{i+1|i}}} \\exp\\left(-\\frac{(x_{i+1} - \\mu_{i+1|i})^2}{2\\sigma^2_{i+1|i}}\\right) $$\nThe log-probability for one transition is therefore:\n$$ \\ln P(x_{i+1} | x_i; k_0, k_1) = -\\frac{1}{2}\\ln(2\\pi) - \\frac{1}{2}\\ln(\\sigma^2_{i+1|i}) - \\frac{(x_{i+1} - \\mu_{i+1|i})^2}{2\\sigma^2_{i+1|i}} $$\nSubstituting the expressions for the mean and variance, the total log-likelihood is:\n$$ \\mathcal{L}(k_0, k_1) = \\sum_{i=0}^{N-1} \\left[ -\\frac{1}{2}\\ln(2\\pi((k_0 + k_1 x_i)\\Delta t)) - \\frac{(x_{i+1} - (x_i + (k_0 - k_1 x_i)\\Delta t))^2}{2 (k_0 + k_1 x_i)\\Delta t} \\right] $$\nThe problem requires that the variance $\\sigma^2_{i+1|i}$ must be strictly positive for all transitions. Since $\\Delta t > 0$, this is equivalent to the condition $k_0 + k_1 x_i > 0$ for all $i \\in \\{0, \\dots, N-1\\}$. Any candidate parameter pair $(k_0, k_1)$ that violates this condition for any observation $x_i$ in a given trajectory must be discarded for that trajectory.\n\nThe computational procedure is to evaluate $\\mathcal{L}(k_0, k_1)$ for each candidate pair and for each test case trajectory. The pair that yields the highest log-likelihood value is the solution for that test case. Ties are resolved by selecting the first candidate in the supplied list.", "answer": "```python\nimport numpy as np\n\ndef calculate_log_likelihood(params, trajectory, dt):\n    \"\"\"\n    Calculates the log-likelihood of a parameter set given a trajectory.\n    \"\"\"\n    k0, k1 = params\n    log_likelihood = 0.0\n\n    for i in range(len(trajectory) - 1):\n        x_i = trajectory[i]\n        x_i_plus_1 = trajectory[i+1]\n        \n        # Calculate the diffusion term for variance check\n        diffusion_term = k0 + k1 * x_i\n        \n        # Per problem specification, variance must be strictly positive.\n        # Since dt > 0, this means diffusion_term must be > 0.\n        if diffusion_term = 0:\n            return -np.inf  # Invalid candidate, log-likelihood is -infinity\n\n        # Conditional variance of the transition\n        variance = diffusion_term * dt\n        \n        # Conditional mean of the transition\n        mean = x_i + (k0 - k1 * x_i) * dt\n\n        # Log probability of the transition x_i -> x_i+1 under the Gaussian approximation\n        log_prob_transition = -0.5 * np.log(2 * np.pi * variance) - 0.5 * ((x_i_plus_1 - mean)**2) / variance\n        log_likelihood += log_prob_transition\n        \n    return log_likelihood\n\ndef solve():\n    \"\"\"\n    Main function to solve the problem for all test cases.\n    \"\"\"\n    test_cases = [\n        # Test case A\n        {\n            \"dt\": 0.2,\n            \"observations\": [10.0, 10.4, 10.1, 11.2, 11.2, 12.0, 11.8, 12.5, 12.6, 13.1, 12.5],\n            \"candidates\": [[2.0, 0.1], [1.0, 0.05], [3.5, 0.25], [2.0, 0.2]],\n        },\n        # Test case B\n        {\n            \"dt\": 0.5,\n            \"observations\": [3.0, 3.4, 4.7, 4.9, 4.8, 5.7, 6.0, 6.5],\n            \"candidates\": [[1.2, 0.0], [1.2, 0.05], [0.8, 0.0], [2.0, 0.2]],\n        },\n        # Test case C\n        {\n            \"dt\": 0.1,\n            \"observations\": [20.0, 19.5, 20.3, 19.1, 19.0, 18.7, 19.3, 18.4, 18.2, 17.7, 17.6, 18.0],\n            \"candidates\": [[8.0, 0.5], [10.0, 0.3], [5.0, 0.6], [7.0, 0.8]],\n        },\n    ]\n\n    best_params_all_cases = []\n\n    for case in test_cases:\n        dt = case[\"dt\"]\n        trajectory = case[\"observations\"]\n        candidates = case[\"candidates\"]\n        \n        max_log_likelihood = -np.inf\n        best_params = None\n\n        for params in candidates:\n            current_log_likelihood = calculate_log_likelihood(params, trajectory, dt)\n            \n            # Update best parameters if a new maximum is found.\n            # Tie-breaking rule: first one in the list wins, hence '>' not '>='.\n            if current_log_likelihood > max_log_likelihood:\n                max_log_likelihood = current_log_likelihood\n                best_params = params\n        \n        best_params_all_cases.append(best_params)\n\n    # Format the final output string as specified\n    formatted_results = [f'[{r[0]:.3f},{r[1]:.3f}]' for r in best_params_all_cases]\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```", "id": "2684181"}]}