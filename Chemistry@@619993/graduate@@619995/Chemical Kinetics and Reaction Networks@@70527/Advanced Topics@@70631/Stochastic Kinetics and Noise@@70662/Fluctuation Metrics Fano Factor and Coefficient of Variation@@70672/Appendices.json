{"hands_on_practices": [{"introduction": "We begin with the cornerstone of stochastic chemical kinetics: the linear birth-death process. By solving the chemical master equation for a simple system of molecular immigration and degradation, you will derive the Poisson distribution from first principles. This foundational exercise anchors our understanding of intrinsic noise, establishing the Fano factor of $F=1$ as the benchmark for a process governed by simple, uncorrelated random events. [@problem_id:2643669]", "problem": "Consider a well-mixed, isothermal system with a single chemical species $X$ undergoing two reactions under stochastic mass-action kinetics: immigration $\\varnothing \\to X$ with constant rate $\\alpha$ and linear death $X \\to \\varnothing$ with propensity $\\mu X$, where $\\alpha > 0$ and $\\mu > 0$. Let $P_{n}(t)$ denote the probability that the copy number of $X$ is $n \\in \\{0,1,2,\\dots\\}$ at time $t$. Assume the system admits a stationary distribution.\n\nStarting from the chemical master equation and standard principles of continuous-time Markov chains for reaction networks, do the following:\n\n- Derive the steady-state probability mass function $p_{n} := \\lim_{t \\to \\infty} P_{n}(t)$ in closed form, expressed in terms of $n$, $\\alpha$, and $\\mu$.\n- Compute the stationary mean $\\mathbb{E}[X]$ and stationary variance $\\mathrm{Var}[X]$.\n- Using the definitions of the Fano factor $F := \\mathrm{Var}[X]/\\mathbb{E}[X]$ and the squared coefficient of variation $\\mathrm{CV}^{2} := \\mathrm{Var}[X]/\\big(\\mathbb{E}[X]\\big)^{2}$, express $F$ and $\\mathrm{CV}^{2}$ in terms of $\\alpha$ and $\\mu$.\n\nProvide your final answer as a single row matrix with $4$ entries in the following order:\n$$(\\mathbb{E}[X],\\; p_{n},\\; F,\\; \\mathrm{CV}^{2}).$$\nNo units are required. If you introduce any auxiliary symbols, define them unambiguously. Do not use any approximations.", "solution": "The problem posed is a standard, well-posed problem in the theory of stochastic chemical kinetics and is therefore valid. We shall proceed with its solution.\n\nLet $n$ denote the copy number of the chemical species $X$, which is a non-negative integer, $n \\in \\{0, 1, 2, \\dots\\}$. The system is governed by two elementary reactions:\n1.  Immigration: $\\varnothing \\xrightarrow{\\alpha} X$. This is a zeroth-order reaction that creates a molecule of $X$. Its rate is a constant, $\\alpha$, which represents the propensity of this reaction. This process transitions the system from state $n$ to state $n+1$.\n2.  Linear Death: $X \\xrightarrow{\\mu} \\varnothing$. This is a first-order reaction that consumes a molecule of $X$. Its propensity is $\\mu n$, where $\\mu$ is the rate constant. This process transitions the system from state $n$ to state $n-1$.\n\nThe chemical master equation describes the time evolution of $P_n(t)$, the probability of the system being in state $n$ at time $t$. For $n \\ge 1$, the change in $P_n(t)$ is due to four processes:\n-   Gain from state $n-1$ via immigration (rate $\\alpha$).\n-   Gain from state $n+1$ via death (rate $\\mu(n+1)$).\n-   Loss from state $n$ via immigration (rate $\\alpha$).\n-   Loss from state $n$ via death (rate $\\mu n$).\n\nThis leads to the following system of ordinary differential equations:\n$$ \\frac{dP_n(t)}{dt} = \\alpha P_{n-1}(t) + \\mu(n+1)P_{n+1}(t) - (\\alpha + \\mu n)P_n(t), \\quad \\text{for } n \\ge 1 $$\nFor the state $n=0$, molecules can only be created by immigration. Molecules cannot be consumed as there are none. The master equation for $n=0$ is:\n$$ \\frac{dP_0(t)}{dt} = \\mu P_1(t) - \\alpha P_0(t) $$\n\nAt steady state, the probabilities are constant in time, i.e., $\\lim_{t \\to \\infty} P_n(t) = p_n$, and thus $\\frac{dp_n}{dt} = 0$ for all $n$. The steady-state master equations are:\n$$ 0 = \\alpha p_{n-1} + \\mu(n+1)p_{n+1} - (\\alpha + \\mu n)p_n, \\quad \\text{for } n \\ge 1 \\quad (1)$$\n$$ 0 = \\mu p_1 - \\alpha p_0, \\quad \\text{for } n=0 \\quad (2)$$\n\nFor a one-dimensional birth-death process such as this, the steady state is characterized by detailed balance, where the net probability flux between any two adjacent states is zero. The flux from state $n$ to $n+1$ via immigration is $\\alpha p_n$. The flux from state $n+1$ to $n$ via death is $\\mu(n+1)p_{n+1}$. Equating these gives:\n$$ \\alpha p_n = \\mu(n+1)p_{n+1} $$\nThis yields the recurrence relation:\n$$ p_{n+1} = \\frac{\\alpha}{\\mu(n+1)} p_n, \\quad \\text{for } n \\ge 0 $$\nOne can verify this relation satisfies the full master equations $(1)$ and $(2)$. For $n=0$, it gives $\\mu p_1 = \\alpha p_0$, which is exactly equation $(2)$. For $n \\ge 1$, substituting $p_{n+1}$ and $p_{n-1}$ (from the recurrence) into equation $(1)$ confirms it holds.\n\nWe solve this recurrence relation for $p_n$ in terms of $p_0$:\n$$ p_1 = \\frac{\\alpha}{\\mu(1)} p_0 $$\n$$ p_2 = \\frac{\\alpha}{\\mu(2)} p_1 = \\frac{\\alpha}{\\mu(2)} \\frac{\\alpha}{\\mu(1)} p_0 = \\frac{1}{2!} \\left(\\frac{\\alpha}{\\mu}\\right)^2 p_0 $$\nBy induction, the general solution is:\n$$ p_n = \\frac{1}{n!} \\left(\\frac{\\alpha}{\\mu}\\right)^n p_0 $$\n\nTo determine $p_0$, we use the normalization condition $\\sum_{n=0}^{\\infty} p_n = 1$:\n$$ \\sum_{n=0}^{\\infty} \\frac{1}{n!} \\left(\\frac{\\alpha}{\\mu}\\right)^n p_0 = p_0 \\sum_{n=0}^{\\infty} \\frac{1}{n!} \\left(\\frac{\\alpha}{\\mu}\\right)^n = 1 $$\nThe summation is the Taylor series for the exponential function, $\\sum_{k=0}^{\\infty} \\frac{x^k}{k!} = \\exp(x)$.\n$$ p_0 \\exp\\left(\\frac{\\alpha}{\\mu}\\right) = 1 \\implies p_0 = \\exp\\left(-\\frac{\\alpha}{\\mu}\\right) $$\nSubstituting this back, we obtain the steady-state probability mass function:\n$$ p_n = \\frac{(\\alpha/\\mu)^n \\exp(-\\alpha/\\mu)}{n!} $$\nThis is the probability mass function of a Poisson distribution with parameter $\\lambda = \\alpha/\\mu$.\n\nThe mean $\\mathbb{E}[X]$ and variance $\\mathrm{Var}[X]$ of a Poisson distribution with parameter $\\lambda$ are both equal to $\\lambda$. Therefore:\n$$ \\mathbb{E}[X] = \\frac{\\alpha}{\\mu} $$\n$$ \\mathrm{Var}[X] = \\frac{\\alpha}{\\mu} $$\nAlternatively, we can compute these moments directly. The mean is:\n$$ \\mathbb{E}[X] = \\sum_{n=0}^{\\infty} n p_n = \\sum_{n=1}^{\\infty} n \\frac{(\\alpha/\\mu)^n \\exp(-\\alpha/\\mu)}{n!} = \\frac{\\alpha}{\\mu} \\exp\\left(-\\frac{\\alpha}{\\mu}\\right) \\sum_{n=1}^{\\infty} \\frac{(\\alpha/\\mu)^{n-1}}{(n-1)!} $$\nLetting $k=n-1$, the sum is $\\sum_{k=0}^{\\infty} \\frac{(\\alpha/\\mu)^k}{k!} = \\exp(\\alpha/\\mu)$. Thus, $\\mathbb{E}[X] = \\frac{\\alpha}{\\mu}$.\nFor the variance, we compute the second factorial moment:\n$$ \\mathbb{E}[X(X-1)] = \\sum_{n=0}^{\\infty} n(n-1) p_n = \\sum_{n=2}^{\\infty} n(n-1) \\frac{(\\alpha/\\mu)^n \\exp(-\\alpha/\\mu)}{n!} = \\left(\\frac{\\alpha}{\\mu}\\right)^2 \\exp\\left(-\\frac{\\alpha}{\\mu}\\right) \\sum_{n=2}^{\\infty} \\frac{(\\alpha/\\mu)^{n-2}}{(n-2)!} $$\nThe sum again evaluates to $\\exp(\\alpha/\\mu)$, yielding $\\mathbb{E}[X(X-1)] = (\\alpha/\\mu)^2$.\nThe variance is $\\mathrm{Var}[X] = \\mathbb{E}[X^2] - (\\mathbb{E}[X])^2 = \\mathbb{E}[X(X-1)] + \\mathbb{E}[X] - (\\mathbb{E}[X])^2$.\n$$ \\mathrm{Var}[X] = \\left(\\frac{\\alpha}{\\mu}\\right)^2 + \\frac{\\alpha}{\\mu} - \\left(\\frac{\\alpha}{\\mu}\\right)^2 = \\frac{\\alpha}{\\mu} $$\n\nNow, we compute the required fluctuation metrics. The Fano factor $F$ is defined as:\n$$ F = \\frac{\\mathrm{Var}[X]}{\\mathbb{E}[X]} = \\frac{\\alpha/\\mu}{\\alpha/\\mu} = 1 $$\nThe squared coefficient of variation $\\mathrm{CV}^2$ is defined as:\n$$ \\mathrm{CV}^2 = \\frac{\\mathrm{Var}[X]}{(\\mathbb{E}[X])^2} = \\frac{\\alpha/\\mu}{(\\alpha/\\mu)^2} = \\frac{\\mu}{\\alpha} $$\n\nThe requested quantities are thus determined. We assemble them in the specified order $(\\mathbb{E}[X], p_n, F, \\mathrm{CV}^2)$.", "answer": "$$\n\\boxed{\\begin{pmatrix} \\frac{\\alpha}{\\mu} & \\frac{\\left(\\frac{\\alpha}{\\mu}\\right)^{n} \\exp\\left(-\\frac{\\alpha}{\\mu}\\right)}{n!} & 1 & \\frac{\\mu}{\\alpha} \\end{pmatrix}}\n$$", "id": "2643669"}, {"introduction": "Theoretical models are powerful, but their predictions must be reconciled with experimental realities. This problem bridges that gap by asking you to consider the effect of imperfect detection, a ubiquitous challenge in single-molecule studies. Using the laws of total expectation and variance, you will analyze how binomial subsampling of a Poisson-distributed population affects the observed fluctuation metrics, revealing important insights into the robustness of the Fano factor and the behavior of the coefficient of variation in real-world measurements. [@problem_id:2643680]", "problem": "A single molecular species is produced and degraded in a well-mixed volume at stationarity, so that the intrinsic molecule count $X$ at the time of measurement is Poisson-distributed with mean $\\mu$, i.e., $\\mathbb{E}[X]=\\mu$ and $\\mathrm{Var}(X)=\\mu$. An imaging detector registers each molecule independently with probability $p \\in (0,1)$, producing an observed count $Y$ obtained by independent Bernoulli trials on the $X$ molecules. Thus, conditional on $X=x$, the reported count is $Y \\mid X=x \\sim \\mathrm{Binomial}(x,p)$.\n\nUsing only the definitions of expectation, variance, the law of total expectation and the law of total variance, and the definitions of the Fano factor (F) and the coefficient of variation (CV), derive the observed Fano factor $F_{\\mathrm{obs}}$ and the observed coefficient of variation $\\mathrm{CV}_{\\mathrm{obs}}$ of $Y$ in terms of $p$ and the true mean $\\mu$. Provide your final answer as a row matrix $\\left(F_{\\mathrm{obs}}, \\mathrm{CV}_{\\mathrm{obs}}\\right)$, with no units. No numerical rounding is required.", "solution": "The problem statement is scientifically grounded, well-posed, and self-contained. It describes a standard model of binomial subsampling of a Poisson-distributed population, a process often referred to as \"thinning\". All required information for a unique solution is provided. The task is to derive fluctuation metrics using fundamental laws of probability, which is a valid and non-trivial exercise. I will therefore proceed with the derivation.\n\nThe objective is to compute the observed Fano factor, $F_{\\mathrm{obs}}$, and the observed coefficient of variation, $\\mathrm{CV}_{\\mathrm{obs}}$, for the random variable $Y$. These are defined as:\n$$\nF_{\\mathrm{obs}} = \\frac{\\mathrm{Var}(Y)}{\\mathbb{E}[Y]}\n$$\n$$\n\\mathrm{CV}_{\\mathrm{obs}} = \\frac{\\sqrt{\\mathrm{Var}(Y)}}{\\mathbb{E}[Y]}\n$$\nTo compute these quantities, we must first determine the expectation, $\\mathbb{E}[Y]$, and the variance, $\\mathrm{Var}(Y)$, of the observed count $Y$. The problem specifies that this must be done using the law of total expectation and the law of total variance.\n\nWe are given the following:\n1.  The true molecule count $X$ follows a Poisson distribution with mean $\\mu$. Thus, $\\mathbb{E}[X] = \\mu$ and $\\mathrm{Var}(X) = \\mu$.\n2.  Conditional on the true count being $X=x$, the observed count $Y$ follows a Binomial distribution, $Y \\mid X=x \\sim \\mathrm{Binomial}(x,p)$, where $p$ is the detection probability.\n\nFirst, we compute the expectation of $Y$.\nAccording to the law of total expectation, $\\mathbb{E}[Y] = \\mathbb{E}[\\mathbb{E}[Y \\mid X]]$.\nThe conditional expectation of $Y$ given $X=x$ is the expectation of a $\\mathrm{Binomial}(x,p)$ distribution, which is $xp$.\nTherefore, the random variable $\\mathbb{E}[Y \\mid X]$ is given by the expression $Xp$.\nNow, we take the expectation of this random variable with respect to the distribution of $X$:\n$$\n\\mathbb{E}[Y] = \\mathbb{E}[Xp] = p \\mathbb{E}[X]\n$$\nSubstituting the given mean of $X$, $\\mathbb{E}[X] = \\mu$, we obtain the mean of $Y$:\n$$\n\\mathbb{E}[Y] = p\\mu\n$$\n\nNext, we compute the variance of $Y$.\nAccording to the law of total variance, $\\mathrm{Var}(Y) = \\mathbb{E}[\\mathrm{Var}(Y \\mid X)] + \\mathrm{Var}(\\mathbb{E}[Y \\mid X])$. We evaluate each term separately.\n\nThe first term is the expectation of the conditional variance, $\\mathbb{E}[\\mathrm{Var}(Y \\mid X)]$.\nThe conditional variance of $Y$ given $X=x$ is the variance of a $\\mathrm{Binomial}(x,p)$ distribution, which is $xp(1-p)$.\nSo, the random variable $\\mathrm{Var}(Y \\mid X)$ is given by $Xp(1-p)$.\nTaking the expectation with respect to $X$:\n$$\n\\mathbb{E}[\\mathrm{Var}(Y \\mid X)] = \\mathbb{E}[Xp(1-p)] = p(1-p)\\mathbb{E}[X]\n$$\nUsing $\\mathbb{E}[X] = \\mu$, this term becomes:\n$$\n\\mathbb{E}[\\mathrm{Var}(Y \\mid X)] = \\mu p(1-p)\n$$\n\nThe second term is the variance of the conditional expectation, $\\mathrm{Var}(\\mathbb{E}[Y \\mid X])$.\nAs determined earlier, the random variable $\\mathbb{E}[Y \\mid X]$ is $Xp$.\nIts variance is calculated as:\n$$\n\\mathrm{Var}(\\mathbb{E}[Y \\mid X]) = \\mathrm{Var}(Xp)\n$$\nUsing the variance property $\\mathrm{Var}(aZ) = a^2\\mathrm{Var}(Z)$, where $a$ is a constant, we get:\n$$\n\\mathrm{Var}(Xp) = p^2\\mathrm{Var}(X)\n$$\nSubstituting the given variance of $X$, $\\mathrm{Var}(X) = \\mu$:\n$$\n\\mathrm{Var}(\\mathbb{E}[Y \\mid X]) = p^2\\mu\n$$\n\nNow, we sum the two terms to find the total variance of $Y$:\n$$\n\\mathrm{Var}(Y) = \\mathbb{E}[\\mathrm{Var}(Y \\mid X)] + \\mathrm{Var}(\\mathbb{E}[Y \\mid X]) = \\mu p(1-p) + p^2\\mu\n$$\nFactoring out $\\mu p$:\n$$\n\\mathrm{Var}(Y) = \\mu p ( (1-p) + p ) = \\mu p (1)\n$$\n$$\n\\mathrm{Var}(Y) = p\\mu\n$$\nWe find that $\\mathrm{Var}(Y)=\\mathbb{E}[Y]=p\\mu$. This implies that the observed count $Y$ also follows a Poisson distribution, specifically $Y \\sim \\mathrm{Poisson}(p\\mu)$.\n\nWith the mean and variance of $Y$ established, we can now calculate the required fluctuation metrics.\n\nThe observed Fano factor, $F_{\\mathrm{obs}}$, is:\n$$\nF_{\\mathrm{obs}} = \\frac{\\mathrm{Var}(Y)}{\\mathbb{E}[Y]} = \\frac{p\\mu}{p\\mu} = 1\n$$\nThe Fano factor is unity, which is characteristic of a Poisson process. The original process was Poissonian with $F_X = \\frac{\\mu}{\\mu} = 1$, and the binomial observation process preserves this property.\n\nThe observed coefficient of variation, $\\mathrm{CV}_{\\mathrm{obs}}$, is:\n$$\n\\mathrm{CV}_{\\mathrm{obs}} = \\frac{\\sqrt{\\mathrm{Var}(Y)}}{\\mathbb{E}[Y]} = \\frac{\\sqrt{p\\mu}}{p\\mu}\n$$\nSimplifying this expression:\n$$\n\\mathrm{CV}_{\\mathrm{obs}} = \\frac{(p\\mu)^{1/2}}{(p\\mu)^1} = (p\\mu)^{-1/2} = \\frac{1}{\\sqrt{p\\mu}}\n$$\nThis result is contingent on $\\mu > 0$ and $p > 0$, as the coefficient of variation is undefined if the mean is zero. The problem specifies $p \\in (0,1)$, and a non-trivial case implies $\\mu > 0$.\n\nThe final results are $F_{\\mathrm{obs}} = 1$ and $\\mathrm{CV}_{\\mathrm{obs}} = \\frac{1}{\\sqrt{p\\mu}}$.", "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n1 & \\frac{1}{\\sqrt{\\mu p}}\n\\end{pmatrix}\n}\n$$", "id": "2643680"}, {"introduction": "Moving from a single species to a network, this exercise explores noise propagation in a simple linear pathway, a common motif in metabolic and gene-regulatory systems. You will employ the Linear Noise Approximation (LNA), a powerful and broadly applicable technique for analyzing fluctuations in complex networks, to derive the full stationary covariance matrix. This practice is key to understanding how fluctuations in an upstream species influence those downstream and to mastering the Lyapunov equation as a central tool in stochastic systems analysis. [@problem_id:2643667]", "problem": "Consider the well-mixed stochastic reaction network with mass-action kinetics\n$$\\varnothing \\xrightarrow{s} A \\xrightarrow{k_1} B \\xrightarrow{k_2} \\varnothing,$$\nwhere $s$, $k_1$, and $k_2$ are positive constants with units of rate, and $A$ and $B$ denote molecule counts. Starting from first principles of stochastic chemical kinetics, do the following at stationarity under the assumption that the network admits a unique steady state:\n- Derive the stationary means $\\mu_A$ and $\\mu_B$ using the macroscopic rate equations implied by the Chemical Master Equation (CME).\n- Using the Linear Noise Approximation (LNA) for this linear network, formulate and solve the steady-state continuous-time Lyapunov equation for the covariance matrix of fluctuations to obtain the stationary variances and covariance.\n- Using these results, compute the Fano factor $F_X$ and the coefficient of variation $\\mathrm{CV}_X$ for $X \\in \\{A,B\\}$.\n\nExpress your final answer as a row matrix in the order $\\left(\\mu_A, \\mu_B, F_A, F_B, \\mathrm{CV}_A, \\mathrm{CV}_B\\right)$. No numerical values are required; provide exact symbolic expressions in terms of $s$, $k_1$, and $k_2$. Do not include units in the final answer.", "solution": "The problem statement has been validated against the required criteria. All givens are provided, the problem is self-contained, scientifically grounded in the theory of stochastic chemical kinetics, and well-posed. We may proceed with the solution.\n\nThe reaction network is given by\n$$ \\varnothing \\xrightarrow{s} A \\xrightarrow{k_1} B \\xrightarrow{k_2} \\varnothing $$\nThis network describes the production of species $A$ at a constant rate $s$, the conversion of $A$ into $B$ with a first-order rate constant $k_1$, and the degradation of $B$ with a first-order rate constant $k_2$. The species $A$ and $B$ represent molecule counts.\n\nFirst, we derive the stationary means, $\\mu_A$ and $\\mu_B$. The macroscopic rate equations for the mean concentrations, which we also denote as $A$ and $B$, are obtained by treating the system deterministically.\nThe rate of change for $A$ is its production rate minus its consumption rate:\n$$ \\frac{dA}{dt} = s - k_1 A $$\nThe rate of change for $B$ is its production from $A$ minus its degradation:\n$$ \\frac{dB}{dt} = k_1 A - k_2 B $$\nAt steady state, the time derivatives are zero. Let $\\mu_A$ and $\\mu_B$ be the steady-state mean values.\nFrom the equation for $A$:\n$$ 0 = s - k_1 \\mu_A \\implies \\mu_A = \\frac{s}{k_1} $$\nFrom the equation for $B$:\n$$ 0 = k_1 \\mu_A - k_2 \\mu_B \\implies k_2 \\mu_B = k_1 \\mu_A $$\nSubstituting the expression for $\\mu_A$:\n$$ k_2 \\mu_B = k_1 \\left( \\frac{s}{k_1} \\right) = s \\implies \\mu_B = \\frac{s}{k_2} $$\n\nNext, we use the Linear Noise Approximation (LNA) to find the stationary covariance matrix of fluctuations, $C$. The LNA describes the dynamics of the fluctuations $\\boldsymbol{\\eta}(t) = (A(t) - \\mu_A, B(t) - \\mu_B)^T$ around the macroscopic steady state $\\boldsymbol{\\mu} = (\\mu_A, \\mu_B)^T$. The stationary covariance matrix $C = \\langle \\boldsymbol{\\eta} \\boldsymbol{\\eta}^T \\rangle$ is the solution to the continuous-time Lyapunov equation:\n$$ J C + C J^T + D = 0 $$\nwhere $J$ is the Jacobian matrix of the macroscopic rate equations and $D$ is the diffusion matrix, both evaluated at the steady state $\\boldsymbol{\\mu}$.\n\nThe vector of macroscopic rates is $\\mathbf{f}(A,B) = (s - k_1 A, k_1 A - k_2 B)^T$. The Jacobian matrix $J$ is:\n$$ J = \\begin{pmatrix} \\frac{\\partial f_1}{\\partial A} & \\frac{\\partial f_1}{\\partial B} \\\\ \\frac{\\partial f_2}{\\partial A} & \\frac{\\partial f_2}{\\partial B} \\end{pmatrix}_{\\boldsymbol{\\mu}} = \\begin{pmatrix} -k_1 & 0 \\\\ k_1 & -k_2 \\end{pmatrix} $$\nThe Jacobian is constant and does not depend on the state.\n\nThe diffusion matrix $D$ is given by $D = S \\cdot \\text{diag}(\\mathbf{a}(\\boldsymbol{\\mu})) \\cdot S^T$, where $S$ is the stoichiometry matrix and $\\mathbf{a}(\\boldsymbol{\\mu})$ is the vector of reaction propensities evaluated at the steady state.\nThe reactions and their propensities are:\n$R_1: \\varnothing \\xrightarrow{s} A$, propensity $a_1 = s$\n$R_2: A \\xrightarrow{k_1} B$, propensity $a_2 = k_1 A$\n$R_3: B \\xrightarrow{k_2} \\varnothing$, propensity $a_3 = k_2 B$\n\nAt steady state $\\boldsymbol{\\mu} = (s/k_1, s/k_2)^T$, the propensities are:\n$a_1(\\boldsymbol{\\mu}) = s$\n$a_2(\\boldsymbol{\\mu}) = k_1 \\mu_A = k_1 (s/k_1) = s$\n$a_3(\\boldsymbol{\\mu}) = k_2 \\mu_B = k_2 (s/k_2) = s$\nThe stoichiometry matrix $S$ for the state vector $(A, B)^T$ is:\n$$ S = \\begin{pmatrix} 1 & -1 & 0 \\\\ 0 & 1 & -1 \\end{pmatrix} $$\nThe diffusion matrix $D$ is therefore:\n$$ D = \\begin{pmatrix} 1 & -1 & 0 \\\\ 0 & 1 & -1 \\end{pmatrix} \\begin{pmatrix} s & 0 & 0 \\\\ 0 & s & 0 \\\\ 0 & 0 & s \\end{pmatrix} \\begin{pmatrix} 1 & 0 \\\\ -1 & 1 \\\\ 0 & -1 \\end{pmatrix} = s \\begin{pmatrix} 1 & -1 & 0 \\\\ 0 & 1 & -1 \\end{pmatrix} \\begin{pmatrix} 1 & 0 \\\\ -1 & 1 \\\\ 0 & -1 \\end{pmatrix} = s \\begin{pmatrix} 2 & -1 \\\\ -1 & 2 \\end{pmatrix} = \\begin{pmatrix} 2s & -s \\\\ -s & 2s \\end{pmatrix} $$\n\nNow, we solve the Lyapunov equation for the symmetric covariance matrix $C = \\begin{pmatrix} C_{AA} & C_{AB} \\\\ C_{AB} & C_{BB} \\end{pmatrix}$.\n$$ \\begin{pmatrix} -k_1 & 0 \\\\ k_1 & -k_2 \\end{pmatrix} \\begin{pmatrix} C_{AA} & C_{AB} \\\\ C_{AB} & C_{BB} \\end{pmatrix} + \\begin{pmatrix} C_{AA} & C_{AB} \\\\ C_{AB} & C_{BB} \\end{pmatrix} \\begin{pmatrix} -k_1 & k_1 \\\\ 0 & -k_2 \\end{pmatrix} + \\begin{pmatrix} 2s & -s \\\\ -s & 2s \\end{pmatrix} = \\begin{pmatrix} 0 & 0 \\\\ 0 & 0 \\end{pmatrix} $$\nPerforming the matrix multiplications yields:\n$$ \\begin{pmatrix} -k_1 C_{AA} & -k_1 C_{AB} \\\\ k_1 C_{AA} - k_2 C_{AB} & k_1 C_{AB} - k_2 C_{BB} \\end{pmatrix} + \\begin{pmatrix} -k_1 C_{AA} & k_1 C_{AA} - k_2 C_{AB} \\\\ -k_1 C_{AB} & k_1 C_{AB} - k_2 C_{BB} \\end{pmatrix} + \\begin{pmatrix} 2s & -s \\\\ -s & 2s \\end{pmatrix} = \\begin{pmatrix} 0 & 0 \\\\ 0 & 0 \\end{pmatrix} $$\nSumming the matrices gives a system of algebraic equations from the entries of the resulting matrix:\n1. $(1,1)$: $-2 k_1 C_{AA} + 2s = 0$\n2. $(1,2)$: $k_1 C_{AA} - (k_1 + k_2) C_{AB} - s = 0$\n3. $(2,2)$: $2 k_1 C_{AB} - 2 k_2 C_{BB} + 2s = 0$\n\nFrom equation (1), we find the variance of $A$, $\\sigma_A^2 = C_{AA}$:\n$$ C_{AA} = \\frac{2s}{2k_1} = \\frac{s}{k_1} $$\nSubstitute this result into equation (2) to find the covariance $C_{AB}$:\n$$ k_1 \\left(\\frac{s}{k_1}\\right) - (k_1 + k_2) C_{AB} - s = 0 $$\n$$ s - (k_1 + k_2) C_{AB} - s = 0 \\implies -(k_1 + k_2) C_{AB} = 0 $$\nSince $k_1 > 0$ and $k_2 > 0$, it follows that $k_1 + k_2 > 0$, which forces the covariance to be zero:\n$$ C_{AB} = 0 $$\nFinally, substitute $C_{AB} = 0$ into equation (3) to find the variance of $B$, $\\sigma_B^2 = C_{BB}$:\n$$ 2 k_1 (0) - 2 k_2 C_{BB} + 2s = 0 \\implies -2 k_2 C_{BB} = -2s $$\n$$ C_{BB} = \\frac{s}{k_2} $$\nThe stationary variances are $\\sigma_A^2 = s/k_1$ and $\\sigma_B^2 = s/k_2$.\n\nWith the means and variances, we compute the Fano factor $F_X = \\sigma_X^2 / \\mu_X$ and the coefficient of variation $\\mathrm{CV}_X = \\sigma_X / \\mu_X$ for $X \\in \\{A, B\\}$.\nFor species $A$:\n$$ F_A = \\frac{\\sigma_A^2}{\\mu_A} = \\frac{s/k_1}{s/k_1} = 1 $$\n$$ \\mathrm{CV}_A = \\frac{\\sigma_A}{\\mu_A} = \\frac{\\sqrt{s/k_1}}{s/k_1} = \\frac{\\sqrt{s}\\sqrt{k_1}}{s} = \\sqrt{\\frac{k_1}{s}} $$\nFor species $B$:\n$$ F_B = \\frac{\\sigma_B^2}{\\mu_B} = \\frac{s/k_2}{s/k_2} = 1 $$\n$$ \\mathrm{CV}_B = \\frac{\\sigma_B}{\\mu_B} = \\frac{\\sqrt{s/k_2}}{s/k_2} = \\frac{\\sqrt{s}\\sqrt{k_2}}{s} = \\sqrt{\\frac{k_2}{s}} $$\n\nThe required quantities are collected and presented in the specified order.\n$\\mu_A = \\frac{s}{k_1}$\n$\\mu_B = \\frac{s}{k_2}$\n$F_A = 1$\n$F_B = 1$\n$\\mathrm{CV}_A = \\sqrt{\\frac{k_1}{s}}$\n$\\mathrm{CV}_B = \\sqrt{\\frac{k_2}{s}}$", "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n\\frac{s}{k_1} & \\frac{s}{k_2} & 1 & 1 & \\sqrt{\\frac{k_1}{s}} & \\sqrt{\\frac{k_2}{s}}\n\\end{pmatrix}\n}\n$$", "id": "2643667"}]}