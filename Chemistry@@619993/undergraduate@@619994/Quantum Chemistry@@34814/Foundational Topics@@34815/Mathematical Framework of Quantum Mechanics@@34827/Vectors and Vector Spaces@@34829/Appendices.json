{"hands_on_practices": [{"introduction": "A cornerstone of quantum mechanics is the representation of physical states as vectors in a complex vector space. A key property in this space is orthogonality, which mathematically corresponds to the idea of perfectly distinguishable states. This exercise provides fundamental practice in applying the Hermitian inner product, the tool used to determine the relationship between state vectors. By setting the inner product to zero, you will solve for the condition that makes one quantum state orthogonal to another, a technique essential for constructing basis sets and analyzing state transitions. [@problem_id:1420565]", "problem": "In the mathematical formalism of quantum mechanics, physical states are represented by vectors in a complex vector space. Consider two such state vectors, $|\\phi_1\\rangle$ and $|\\phi_2\\rangle$, for a two-level system, given in a particular basis by the column vectors:\n$$\n|\\phi_1\\rangle = \\begin{pmatrix} 1 \\\\ 2i \\end{pmatrix}, \\quad |\\phi_2\\rangle = \\begin{pmatrix} 3i \\\\ 1 \\end{pmatrix}\n$$\nThe inner product of two vectors $|\\psi\\rangle = \\begin{pmatrix} a_1 \\\\ a_2 \\end{pmatrix}$ and $|\\phi\\rangle = \\begin{pmatrix} b_1 \\\\ b_2 \\end{pmatrix}$ is defined using the bra-ket notation as $\\langle\\psi|\\phi\\rangle = \\psi^\\dagger \\phi = a_1^* b_1 + a_2^* b_2$, where the dagger $\\dagger$ indicates the conjugate transpose operation and $z^*$ denotes the complex conjugate of a complex number $z$.\n\nA new state vector $|\\Psi\\rangle$ is formed by the linear combination $|\\Psi\\rangle = |\\phi_1\\rangle + c|\\phi_2\\rangle$, where $c$ is a complex coefficient. Find the specific value of $c$ that makes the vector $|\\Psi\\rangle$ orthogonal to the vector $|\\phi_1\\rangle$.", "solution": "Orthogonality requires $\\langle \\phi_{1}|\\Psi\\rangle=0$. With $|\\Psi\\rangle=|\\phi_{1}\\rangle+c|\\phi_{2}\\rangle$, this becomes\n$$\n\\langle \\phi_{1}|\\Psi\\rangle=\\langle \\phi_{1}|\\phi_{1}\\rangle+c\\,\\langle \\phi_{1}|\\phi_{2}\\rangle=0.\n$$\nSolve for $c$ as\n$$\nc=-\\frac{\\langle \\phi_{1}|\\phi_{1}\\rangle}{\\langle \\phi_{1}|\\phi_{2}\\rangle}.\n$$\nCompute $\\langle \\phi_{1}|\\phi_{1}\\rangle$ using $|\\phi_{1}\\rangle=\\begin{pmatrix}1\\\\2i\\end{pmatrix}$:\n$$\n\\langle \\phi_{1}|\\phi_{1}\\rangle=1^{*}\\cdot 1+(2i)^{*}\\cdot(2i)=1+(-2i)(2i)=1-4 i^{2}=1-4(-1)=5.\n$$\nCompute $\\langle \\phi_{1}|\\phi_{2}\\rangle$ using $|\\phi_{2}\\rangle=\\begin{pmatrix}3i\\\\1\\end{pmatrix}$:\n$$\n\\langle \\phi_{1}|\\phi_{2}\\rangle=1^{*}\\cdot(3i)+(2i)^{*}\\cdot 1=3i+(-2i)\\cdot 1=i.\n$$\nTherefore,\n$$\nc=-\\frac{5}{i}.\n$$\nUsing $1/i=-i$, this simplifies to\n$$\nc=5i.\n$$", "answer": "$$\\boxed{5i}$$", "id": "1420565"}, {"introduction": "Building on the concept of vector relationships, we now turn to linear independence. This property is crucial for defining a basis, which is a minimal set of vectors needed to describe any possible state in a given quantum system. A set of vectors is linearly dependent if one vector can be expressed as a combination of the others, indicating redundancy. This thought experiment, set in the context of a simple two-site molecule, challenges you to identify why a given set of state vectors is linearly dependent, reinforcing the connection between the dimension of a space and the maximum number of independent vectors it can contain. [@problem_id:1420610]", "problem": "In a simplified quantum mechanical model of a two-site system, such as a diatomic molecule, the state of an electron can be described by a state vector in a two-dimensional complex vector space. A standard choice for a basis is the \"site basis,\" consisting of two orthonormal vectors, $|\\phi_1\\rangle$ and $|\\phi_2\\rangle$, which represent the electron being localized on site 1 and site 2, respectively. In a particular matrix representation, these basis vectors correspond to the column vectors $\\mathbf{v}_1$ and $\\mathbf{v}_2$:\n$$\n|\\phi_1\\rangle \\rightarrow \\mathbf{v}_1 = \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix}\n$$\n$$\n|\\phi_2\\rangle \\rightarrow \\mathbf{v}_2 = \\begin{pmatrix} 0 \\\\ 1 \\end{pmatrix}\n$$\nA student, exploring alternative representations for a variational calculation, considers a new set of three state vectors. This set includes the two original basis vectors along with a third vector, $|\\phi_3\\rangle$, which represents an equal superposition of the two site states. The set of corresponding column vectors is $S = \\{ \\mathbf{v}_1, \\mathbf{v}_2, \\mathbf{v}_3 \\}$, where:\n$$\n\\mathbf{v}_1 = \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix}, \\quad \\mathbf{v}_2 = \\begin{pmatrix} 0 \\\\ 1 \\end{pmatrix}, \\quad \\mathbf{v}_3 = \\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix}\n$$\nA set of vectors is defined as **linearly dependent** if there exist scalar coefficients (not all zero) such that a linear combination of the vectors equals the zero vector. This is equivalent to stating that at least one vector in the set can be written as a linear combination of the others. If the only linear combination that equals the zero vector is the one where all coefficients are zero, the set is **linearly independent**.\n\nWhich of the following statements correctly describe the set of vectors $S$? Select all statements that apply.\n\nA. The set $S$ is linearly independent because no vector is a scalar multiple of another.\n\nB. The set $S$ is linearly independent because the set spans the entire two-dimensional vector space.\n\nC. The set $S$ is linearly dependent because $\\mathbf{v}_3 = \\mathbf{v}_1 + \\mathbf{v}_2$.\n\nD. The set $S$ is linearly dependent because the number of vectors (three) is greater than the dimension of the vector space (two).\n\nE. The set $S$ is linearly independent because the determinant of the matrix formed by any pair of vectors from the set is non-zero.", "solution": "We are given three vectors in a two-dimensional complex vector space: $\\mathbf{v}_{1} = \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix}$, $\\mathbf{v}_{2} = \\begin{pmatrix} 0 \\\\ 1 \\end{pmatrix}$, and $\\mathbf{v}_{3} = \\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix}$. By definition, a set is linearly dependent if there exist scalars, not all zero, such that a linear combination of the vectors equals the zero vector.\n\nFirst, we test for linear dependence by explicit construction. Consider the linear combination with coefficients $1$, $1$, and $-1$:\n$$\n\\mathbf{v}_{1} + \\mathbf{v}_{2} - \\mathbf{v}_{3} = \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix} + \\begin{pmatrix} 0 \\\\ 1 \\end{pmatrix} - \\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix} = \\begin{pmatrix} 1+0-1 \\\\ 0+1-1 \\end{pmatrix} = \\begin{pmatrix} 0 \\\\ 0 \\end{pmatrix}.\n$$\nSince the coefficients are not all zero, this proves that the set $S$ is linearly dependent. Equivalently, we observe that\n$$\n\\mathbf{v}_{3} = \\mathbf{v}_{1} + \\mathbf{v}_{2},\n$$\nwhich shows directly that one vector is a linear combination of the others, hence dependence.\n\nSecond, by a general theorem in linear algebra: in a vector space of dimension $n$, any set of more than $n$ vectors is linearly dependent. Here the space is two-dimensional and the set has three vectors, so the set must be linearly dependent.\n\nNow evaluate each statement:\n\n- Statement A claims independence because no vector is a scalar multiple of another. This is false: absence of scalar multiples does not guarantee independence, as shown by $\\mathbf{v}_{3} = \\mathbf{v}_{1} + \\mathbf{v}_{2}$.\n- Statement B claims independence because the set spans the space. This is false: spanning does not imply independence. A spanning set can be redundant.\n- Statement C claims dependence because $\\mathbf{v}_{3} = \\mathbf{v}_{1} + \\mathbf{v}_{2}$. This is true by the explicit relation above.\n- Statement D claims dependence because there are three vectors in a two-dimensional space. This is true by the dimension theorem.\n- Statement E claims independence because determinants for any pair are non-zero. Although any pair among $\\{\\mathbf{v}_{1}, \\mathbf{v}_{2}, \\mathbf{v}_{3}\\}$ is indeed linearly independent (non-zero determinant), pairwise independence does not imply that the full set is independent. Hence the reasoning and conclusion are false.\n\nTherefore, the correct statements are C and D.", "answer": "$$\\boxed{CD}$$", "id": "1420610"}, {"introduction": "The principles of vector spaces extend beyond simple column vectors to the realm of functions, where quantum mechanical wavefunctions reside. This practice introduces the Gram-Schmidt process, a powerful and systematic algorithm for constructing a set of orthogonal functions from a more basic, non-orthogonal set. Mastering this procedure is key to understanding how the solutions to the Schr√∂dinger equation for many model systems, like the quantum harmonic oscillator, are formed. Here, you will apply the process to simple monomials to generate orthogonal polynomials, directly mirroring the construction of basis sets used throughout quantum chemistry. [@problem_id:1420575]", "problem": "In the quantum mechanical treatment of the harmonic oscillator, the wavefunctions are often constructed from a basis of orthogonal polynomials. A powerful method for generating such a basis from a simpler set of functions is the Gram-Schmidt process.\n\nConsider a vector space of real-valued polynomials defined on the interval $(-\\infty, \\infty)$. The inner product for any two functions, $f(x)$ and $g(x)$, in this space is defined by the following weighted integral:\n$$\n\\langle f | g \\rangle = \\int_{-\\infty}^{\\infty} f(x)g(x)e^{-x^2} dx\n$$\nYou are given a basis set of simple monomials, {$u_0(x), u_1(x), u_2(x)$}, where $u_0(x)=1$, $u_1(x)=x$, and $u_2(x)=x^2$.\n\nYour task is to apply the Gram-Schmidt orthogonalization procedure to this set $\\{u_0, u_1, u_2\\}$ in the given order to construct a new set of *orthonormal* functions, $\\{\\phi_0(x), \\phi_1(x), \\phi_2(x)\\}$.\n\nDetermine the explicit expression for the second function in the resulting orthonormal set, $\\phi_1(x)$.\n\nYou may use the following definite integral identities without proof:\n- $\\int_{-\\infty}^{\\infty} e^{-x^2} dx = \\sqrt{\\pi}$\n- $\\int_{-\\infty}^{\\infty} x^2 e^{-x^2} dx = \\frac{\\sqrt{\\pi}}{2}$\n- For any odd positive integer $n$, $\\int_{-\\infty}^{\\infty} x^n e^{-x^2} dx = 0$", "solution": "We apply Gram-Schmidt with respect to the weighted inner product $\\langle f|g\\rangle=\\int_{-\\infty}^{\\infty} f(x)g(x)\\exp(-x^{2})\\,dx$ to the ordered set $\\{u_{0},u_{1},u_{2}\\}$, where $u_{0}(x)=1$, $u_{1}(x)=x$, and $u_{2}(x)=x^{2}$.\n\nFirst, set $v_{0}=u_{0}=1$. Its norm is\n$$\n\\|v_{0}\\|=\\sqrt{\\langle v_{0}|v_{0}\\rangle}=\\sqrt{\\int_{-\\infty}^{\\infty} 1\\cdot 1\\cdot \\exp(-x^{2})\\,dx}=\\sqrt{\\sqrt{\\pi}}=\\pi^{1/4}.\n$$\nThus the first orthonormal function is\n$$\n\\phi_{0}(x)=\\frac{v_{0}(x)}{\\|v_{0}\\|}=\\frac{1}{\\pi^{1/4}}.\n$$\n\nNext, construct $v_{1}$ by removing the component of $u_{1}$ along $\\phi_{0}$:\n$$\nv_{1}=u_{1}-\\langle u_{1}|\\phi_{0}\\rangle\\,\\phi_{0}.\n$$\nCompute the projection coefficient:\n$$\n\\langle u_{1}|\\phi_{0}\\rangle=\\int_{-\\infty}^{\\infty} x\\cdot \\frac{1}{\\pi^{1/4}}\\cdot \\exp(-x^{2})\\,dx=\\frac{1}{\\pi^{1/4}}\\int_{-\\infty}^{\\infty} x\\,\\exp(-x^{2})\\,dx=0,\n$$\nusing the fact that the integrand is an odd function over a symmetric interval. Hence $v_{1}=u_{1}=x$.\n\nNormalize $v_{1}$:\n$$\n\\|v_{1}\\|=\\sqrt{\\langle v_{1}|v_{1}\\rangle}=\\sqrt{\\int_{-\\infty}^{\\infty} x^{2}\\exp(-x^{2})\\,dx}=\\sqrt{\\frac{\\sqrt{\\pi}}{2}}=\\frac{\\pi^{1/4}}{\\sqrt{2}}.\n$$\nTherefore,\n$$\n\\phi_{1}(x)=\\frac{v_{1}(x)}{\\|v_{1}\\|}=\\frac{x}{\\pi^{1/4}/\\sqrt{2}}=\\frac{\\sqrt{2}\\,x}{\\pi^{1/4}}.\n$$", "answer": "$$\\boxed{\\frac{\\sqrt{2}\\,x}{\\pi^{1/4}}}$$", "id": "1420575"}]}