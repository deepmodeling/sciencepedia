{"hands_on_practices": [{"introduction": "在学习回归分析时，一个常见的问题是：为什么误差方差的无偏估计量 $S^2$ 的分母是 $n-2$，而不是我们在初等统计学中学到的样本方差分母 $n-1$？这个问题直击自由度概念的核心。通过直接计算一个分母为 $n-1$ 的替代估计量的期望值，我们可以从数学上证明它为什么是有偏的，从而理解在简单线性回归中进行 $n-2$ 修正的必要性。[@problem_id:1915695]", "problem": "一位初级数据科学家正在使用一个简单线性回归（SLR）模型来分析实验数据。该模型由 $Y_i = \\beta_0 + \\beta_1 x_i + \\varepsilon_i$ 给出，其中 $i=1, \\dots, n$，$x_i$ 是固定的非随机预测变量，且不全相等，随机误差 $\\varepsilon_i$ 是独立的，满足 $E[\\varepsilon_i] = 0$ 和 $V(\\varepsilon_i) = \\sigma^2$。\n\n参数 $\\beta_0$ 和 $\\beta_1$ 使用普通最小二乘法进行估计，得到估计量 $\\hat{\\beta}_0$ 和 $\\hat{\\beta}_1$。拟合值为 $\\hat{y}_i = \\hat{\\beta}_0 + \\hat{\\beta}_1 x_i$，残差为 $e_i = y_i - \\hat{y}_i$。\n\n已知误差方差 $\\sigma^2$ 的标准无偏估计量为 $S^2 = \\frac{1}{n-2}\\sum_{i=1}^n e_i^2$。然而，分析师回想起统计学入门课程中的样本方差公式，考虑使用一个不同的分母，并为误差方差提出了一个替代估计量：\n$$ \\hat{\\sigma}^2_{alt} = \\frac{1}{n-1}\\sum_{i=1}^n (y_i - \\hat{y}_i)^2 $$\n\n为了评估这个替代估计量，你的任务是确定其期望值。将 $E[\\hat{\\sigma}^2_{alt}]$ 表示为关于样本量 $n$ 和真实误差方差 $\\sigma^2$ 的表达式。\n\n在你的推导中，你可以不加证明地使用以下来自简单线性回归理论的标准结果：\n1. 最小二乘估计量 $\\hat{\\beta}_1$ 是 $\\beta_1$ 的无偏估计量。\n2. 斜率估计量的方差为 $V(\\hat{\\beta}_1) = \\frac{\\sigma^2}{\\sum_{i=1}^n(x_i - \\bar{x})^2}$。\n3. 残差平方和（也称为误差平方和或 SSE）可以分解为 $\\sum_{i=1}^n(y_i - \\hat{y}_i)^2 = \\sum_{i=1}^n(y_i - \\bar{y})^2 - \\hat{\\beta}_1^2 \\sum_{i=1}^n(x_i - \\bar{x})^2$。", "solution": "我们需要计算替代估计量的期望\n$$\n\\hat{\\sigma}^{2}_{alt}=\\frac{1}{n-1}\\sum_{i=1}^{n}(y_{i}-\\hat{y}_{i})^{2}=\\frac{1}{n-1}\\,\\mathrm{SSE},\n$$\n所以\n$$\nE[\\hat{\\sigma}^{2}_{alt}]=\\frac{1}{n-1}\\,E[\\mathrm{SSE}].\n$$\n使用给定的分解，\n$$\n\\mathrm{SSE}=\\sum_{i=1}^{n}(y_{i}-\\bar{y})^{2}-\\hat{\\beta}_{1}^{2}\\sum_{i=1}^{n}(x_{i}-\\bar{x})^{2},\n$$\n令 $S_{xx}=\\sum_{i=1}^{n}(x_{i}-\\bar{x})^{2}$。则\n$$\nE[\\mathrm{SSE}]=E\\!\\left[\\sum_{i=1}^{n}(y_{i}-\\bar{y})^{2}\\right]-E[\\hat{\\beta}_{1}^{2}]\\,S_{xx}.\n$$\n\n计算 $E\\!\\left[\\sum_{i=1}^{n}(y_{i}-\\bar{y})^{2}\\right]$。在 $y_{i}=\\beta_{0}+\\beta_{1}x_{i}+\\varepsilon_{i}$，$\\bar{y}=\\beta_{0}+\\beta_{1}\\bar{x}+\\bar{\\varepsilon}$ 且 $\\bar{\\varepsilon}=\\frac{1}{n}\\sum_{i=1}^{n}\\varepsilon_{i}$ 的条件下，我们有\n$$\ny_{i}-\\bar{y}=\\beta_{1}(x_{i}-\\bar{x})+(\\varepsilon_{i}-\\bar{\\varepsilon}).\n$$\n因此，\n$$\n\\sum_{i=1}^{n}(y_{i}-\\bar{y})^{2}=\\beta_{1}^{2}S_{xx}+2\\beta_{1}\\sum_{i=1}^{n}(x_{i}-\\bar{x})(\\varepsilon_{i}-\\bar{\\varepsilon})+\\sum_{i=1}^{n}(\\varepsilon_{i}-\\bar{\\varepsilon})^{2}.\n$$\n取期望，并利用 $E[\\varepsilon_{i}]=0$、误差的独立性以及 $x_{i}$ 是固定的，可得\n$$\nE\\!\\left[\\sum_{i=1}^{n}(y_{i}-\\bar{y})^{2}\\right]=\\beta_{1}^{2}S_{xx}+E\\!\\left[\\sum_{i=1}^{n}(\\varepsilon_{i}-\\bar{\\varepsilon})^{2}\\right].\n$$\n现在\n$$\n\\sum_{i=1}^{n}(\\varepsilon_{i}-\\bar{\\varepsilon})^{2}=\\sum_{i=1}^{n}\\varepsilon_{i}^{2}-n\\bar{\\varepsilon}^{2},\n$$\n所以\n$$\nE\\!\\left[\\sum_{i=1}^{n}(\\varepsilon_{i}-\\bar{\\varepsilon})^{2}\\right]=n\\sigma^{2}-n\\,\\mathrm{Var}(\\bar{\\varepsilon})=n\\sigma^{2}-n\\frac{\\sigma^{2}}{n}=(n-1)\\sigma^{2}.\n$$\n因此\n$$\nE\\!\\left[\\sum_{i=1}^{n}(y_{i}-\\bar{y})^{2}\\right]=\\beta_{1}^{2}S_{xx}+(n-1)\\sigma^{2}.\n$$\n\n接下来，根据给定的结果，\n$$\nE[\\hat{\\beta}_{1}]=\\beta_{1},\\qquad \\mathrm{Var}(\\hat{\\beta}_{1})=\\frac{\\sigma^{2}}{S_{xx}},\n$$\n所以\n$$\nE[\\hat{\\beta}_{1}^{2}]=\\mathrm{Var}(\\hat{\\beta}_{1})+(E[\\hat{\\beta}_{1}])^{2}=\\frac{\\sigma^{2}}{S_{xx}}+\\beta_{1}^{2},\n$$\n因而\n$$\nE[\\hat{\\beta}_{1}^{2}]\\,S_{xx}=\\sigma^{2}+\\beta_{1}^{2}S_{xx}.\n$$\n\n将各部分组合起来：\n$$\nE[\\mathrm{SSE}]=\\bigl(\\beta_{1}^{2}S_{xx}+(n-1)\\sigma^{2}\\bigr)-\\bigl(\\sigma^{2}+\\beta_{1}^{2}S_{xx}\\bigr)=(n-2)\\sigma^{2}.\n$$\n因此，\n$$\nE[\\hat{\\sigma}^{2}_{alt}]=\\frac{1}{n-1}E[\\mathrm{SSE}]=\\frac{n-2}{n-1}\\,\\sigma^{2}.\n$$", "answer": "$$\\boxed{\\frac{n-2}{n-1}\\sigma^{2}}$$", "id": "1915695"}, {"introduction": "上一个练习从数学上证明了为什么需要 $n-2$ 的分母。为了建立更深刻的直觉，让我们来做一个思想实验：当我们试图用一条直线（由斜率和截距两个参数定义）去拟合仅有的两个数据点时，会发生什么？这个极限情况生动地揭示了我们为何会“失去”两个自由度，并且没有任何剩余信息来估计随机误差的大小，从而为自由度的概念提供了强有力的直观解释。[@problem_id:1915683]", "problem": "一位分析师正在研究两个变量 $X$ 和 $Y$ 之间的关系。他们收集了一个仅包含两个数据点的小数据集：$(x_1, y_1) = (10, 25)$ 和 $(x_2, y_2) = (30, 35)$。\n\n分析师对该数据集拟合了一个形式为 $Y = \\beta_0 + \\beta_1 X + \\epsilon$ 的简单线性回归模型，其中 $\\epsilon$ 代表随机误差项。该过程涉及为模型参数找到估计值 $\\hat{\\beta}_0$ 和 $\\hat{\\beta}_1$。\n\n令 $SSE$ 表示拟合模型的误差平方和（也称为残差平方和），其计算公式为 $SSE = \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2$，其中 $\\hat{y}_i$ 是回归线上的预测值，$n$ 是数据点的数量。\n\n令 $s^2$ 为误差方差 $\\sigma^2$ 的标准无偏估计量。该估计量通常计算为 $s^2 = \\frac{SSE}{n-k}$，其中 $k$ 是回归模型中估计的参数数量。\n\n根据对给定的两个数据点拟合简单线性回归模型，确定得到的 $SSE$ 和 $s^2$ 的值。\n\nA. $SSE = 50$ 且 $s^2 = 50$\n\nB. $SSE  0$ 且 $s^2  0$，但根据给定信息无法确定其确切值。\n\nC. $SSE = 0$ 且 $s^2 = 0$\n\nD. $SSE = 0$ 且 $s^2$ 未定义\n\nE. $SSE = 100$ 且 $s^2$ 未定义", "solution": "我们将简单线性回归模型 $Y=\\beta_{0}+\\beta_{1}X+\\epsilon$ 拟合到两个点 $(x_{1},y_{1})=(10,25)$ 和 $(x_{2},y_{2})=(30,35)$。简单线性回归中的普通最小二乘估计值为\n$$\n\\hat{\\beta}_{1}=\\frac{S_{xy}}{S_{xx}}, \\quad \\hat{\\beta}_{0}=\\bar{y}-\\hat{\\beta}_{1}\\bar{x},\n$$\n其中\n$$\n\\bar{x}=\\frac{x_{1}+x_{2}}{2}, \\quad \\bar{y}=\\frac{y_{1}+y_{2}}{2}, \\quad S_{xx}=\\sum_{i=1}^{2}(x_{i}-\\bar{x})^{2}, \\quad S_{xy}=\\sum_{i=1}^{2}(x_{i}-\\bar{x})(y_{i}-\\bar{y}).\n$$\n计算样本均值：\n$$\n\\bar{x}=\\frac{10+30}{2}=20, \\quad \\bar{y}=\\frac{25+35}{2}=30.\n$$\n计算 $S_{xx}$ 和 $S_{xy}$：\n$$\nS_{xx}=(10-20)^{2}+(30-20)^{2}=100+100=200,\n$$\n$$\nS_{xy}=(10-20)(25-30)+(30-20)(35-30)=(-10)(-5)+(10)(5)=50+50=100.\n$$\n因此，\n$$\n\\hat{\\beta}_{1}=\\frac{100}{200}=\\frac{1}{2}, \\quad \\hat{\\beta}_{0}=30-\\frac{1}{2}\\cdot 20=20.\n$$\n拟合的直线是 $\\hat{y}=20+\\frac{1}{2}x$。在观测到的 $x$ 处的预测值为\n$$\n\\hat{y}_{1}=20+\\tfrac{1}{2}\\cdot 10=25=y_{1}, \\quad \\hat{y}_{2}=20+\\tfrac{1}{2}\\cdot 30=35=y_{2}.\n$$\n因此，两个残差都为零，所以误差平方和为\n$$\nSSE=\\sum_{i=1}^{2}(y_{i}-\\hat{y}_{i})^{2}=0.\n$$\n无偏误差方差估计量定义为\n$$\ns^{2}=\\frac{SSE}{n-k},\n$$\n其中有 $n=2$ 个数据点和 $k=2$ 个估计参数（截距和斜率），得出 $n-k=0$。因此，\n$$\ns^{2}=\\frac{0}{0},\n$$\n由于自由度为零，该值是未定义的。因此，正确的选项是 $SSE=0$ 且 $s^{2}$ 未定义。", "answer": "$$\\boxed{D}$$", "id": "1915683"}, {"introduction": "我们已经确立了自由度等于“数据点数量减去估计参数数量”的原则。现在，让我们在一个新的模型中检验这一理解。这个问题考虑了一个在物理科学中很常见的场景：过原点回归，其中我们只估计一个参数（斜率）。这个练习将挑战你应用自由度的一般原则，而不是仅仅记住标准简单回归模型的公式，从而加深对误差方差估计的普遍理解。[@problem_id:1915696]", "problem": "一位物理系学生正在研究胡克定律（Hooke's Law），该定律指出，将弹簧从其平衡位置拉伸或压缩一段距离 $x$ 所需的力 $F$ 与该距离成正比。这种关系的理论模型是 $F = \\beta_1 x$，其中 $\\beta_1$ 是弹簧常数。\n\n为了估计弹簧常数，该学生收集了 $n$ 对测量数据 $(x_i, y_i)$，其中 $x_i$ 是位移，$y_i$ 是测得的力。该学生提出了一个过原点的回归模型来描述这些数据：\n$$Y_i = \\beta_1 x_i + \\epsilon_i \\quad \\text{for } i = 1, 2, \\dots, n$$\n在此模型中，解释变量 $x_i$ 被视为固定的、非随机的常数，并且 $x_i$ 不全为零。误差项 $\\epsilon_i$ 被假定为独立同分布的随机变量，其均值为 $E[\\epsilon_i] = 0$，方差为常数 $Var(\\epsilon_i) = \\sigma^2$。参数 $\\sigma^2$ 表示力的测量误差的方差。\n\n弹簧常数 $\\beta_1$ 的最小二乘估计量由下式给出：\n$$\\hat{\\beta}_1 = \\frac{\\sum_{i=1}^n x_i Y_i}{\\sum_{i=1}^n x_i^2}$$\n\n为了估计误差方差 $\\sigma^2$，该学生考虑了一个形式如下的估计量：\n$$S^2 = k \\sum_{i=1}^n (Y_i - \\hat{\\beta}_1 x_i)^2$$\n其中 $k$ 是一个可能取决于样本量 $n$ 的常数。\n\n求出使 $S^2$ 成为 $\\sigma^2$ 的无偏估计量的 $k$ 值。将答案表示为 $n$ 的函数。", "solution": "我们将模型写成矩阵形式。令 $Y=(Y_{1},\\dots,Y_{n})'$，$X=(x_{1},\\dots,x_{n})'$ (一个 $n\\times 1$ 的矩阵)，$\\beta=\\beta_{1}$，以及 $\\epsilon=(\\epsilon_{1},\\dots,\\epsilon_{n})'$。则\n$$\nY=X\\beta+\\epsilon,\\quad E[\\epsilon]=0,\\quad \\operatorname{Var}(\\epsilon)=\\sigma^{2}I_{n},\n$$\n其中 $X$ 非零，因此 $X'X0$。最小二乘估计量为\n$$\n\\hat{\\beta}=(X'X)^{-1}X'Y,\n$$\n残差向量为\n$$\ne=Y-X\\hat{\\beta}=(I_{n}-H)Y,\\quad H=X(X'X)^{-1}X'.\n$$\n使用 $Y=X\\beta+\\epsilon$ 和 $(I_{n}-H)X=0$，我们得到\n$$\ne=(I_{n}-H)\\epsilon.\n$$\n残差平方和为\n$$\n\\operatorname{RSS}=e'e=\\epsilon'(I_{n}-H)\\epsilon.\n$$\n对于任意常数对称矩阵 $A$，恒等式\n$$\nE[\\epsilon'A\\epsilon]=\\operatorname{tr}\\!\\big(A\\,\\operatorname{Var}(\\epsilon)\\big)+E[\\epsilon]'A\\,E[\\epsilon]\n$$\n成立。取 $A=I_{n}-H$，$E[\\epsilon]=0$ 和 $\\operatorname{Var}(\\epsilon)=\\sigma^{2}I_{n}$，我们得到\n$$\nE[\\operatorname{RSS}]=\\sigma^{2}\\operatorname{tr}(I_{n}-H)=\\sigma^{2}\\big(n-\\operatorname{tr}(H)\\big).\n$$\n帽子矩阵 $H$ 是一个秩为 $p=1$ 的幂等投影，因为 $X$ 的秩为 1（$x_{i}$ 不全为零）。因此 $\\operatorname{tr}(H)=1$，所以\n$$\nE[\\operatorname{RSS}]=(n-1)\\sigma^{2}.\n$$\n所提出的估计量为 $S^{2}=k\\,\\operatorname{RSS}$。其期望为\n$$\nE[S^{2}]=k\\,(n-1)\\sigma^{2}.\n$$\n无偏性，即 $E[S^{2}]=\\sigma^{2}$，因此要求\n$$\nk=\\frac{1}{n-1}.\n$$", "answer": "$$\\boxed{\\frac{1}{n-1}}$$", "id": "1915696"}]}