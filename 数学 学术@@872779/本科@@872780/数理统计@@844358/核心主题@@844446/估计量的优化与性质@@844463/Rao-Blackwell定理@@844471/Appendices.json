{"hands_on_practices": [{"introduction": "这个首个练习将展示拉奥-布莱克维尔定理的一个基础应用。我们将从一个几何分布均值的简单无偏估计量出发，通过对完备充分统计量（样本总和）取条件期望来改进它。这个练习[@problem_id:1950082]将揭示该定理如何导出一个更直观、更有效的估计量——在这里即为样本均值。", "problem": "一位软件工程师正在测试一种新的随机算法。该算法首次成功所需的尝试次数是一个随机变量 $X$，它服从几何分布，其概率质量函数为 $P(X=k) = (1-p)^{k-1}p$，其中 $k=1, 2, 3, \\ldots$，$p$ 是每次尝试成功的未知概率。该工程师独立地进行了 $n$ 次实验，获得了一个随机样本 $X_1, X_2, \\ldots, X_n$。\n\n我们感兴趣的参数是成功一次的期望尝试次数，$\\theta = 1/p$。$\\theta$ 的一个初始、简单的无偏估计量是 $T_0 = X_1$。你的任务是求出 $\\theta$ 的一致最小方差无偏估计量 (UMVUE)。\n\n用样本和 $S = \\sum_{i=1}^n X_i$ 和样本量 $n$ 来表示你的答案。", "solution": "设 $X_{1},\\ldots,X_{n}$ 是服从 $\\operatorname{Geom}(p)$ 分布的独立随机变量，其概率质量函数为 $P(X=k)=(1-p)^{k-1}p$，$k=1,2,\\ldots$，并设 $S=\\sum_{i=1}^{n}X_{i}$。联合概率质量函数可以分解为\n$$\nP(X_{1}=x_{1},\\ldots,X_{n}=x_{n})\n=\\prod_{i=1}^{n}\\left[(1-p)^{x_{i}-1}p\\right]\n=p^{n}(1-p)^{\\sum_{i=1}^{n}(x_{i}-1)}\n=p^{n}(1-p)^{S-n},\n$$\n该式仅通过 $S$ 依赖于 $p$，因此根据因子分解定理，$S$ 是 $p$ 的充分统计量。\n\n$S$ 的分布是负二项分布，其概率质量函数为\n$$\nP(S=s)=\\binom{s-1}{n-1}p^{n}(1-p)^{s-n},\\quad s=n,n+1,\\ldots\n$$\n为了证明完备性，假设函数 $g$ 满足 $\\mathbb{E}_{p}[g(S)]=0$ 对所有 $p\\in(0,1)$ 成立。则\n$$\n\\sum_{s=n}^{\\infty}g(s)\\binom{s-1}{n-1}p^{n}(1-p)^{s-n}=0\\quad\\text{对所有 }p\\in(0,1).\n$$\n两边同除以 $p^{n}$ 并令 $q=1-p$ 可得\n$$\n\\sum_{k=0}^{\\infty}g(n+k)\\binom{n+k-1}{n-1}q^{k}=0\\quad\\text{对所有 }q\\in(0,1).\n$$\n这是一个关于 $q$ 的幂级数，它在一个区间上为零，因此所有系数都为零，这意味着对所有 $k$ 有 $g(n+k)\\binom{n+k-1}{n-1}=0$，因此对所有 $s$ 有 $g(s)=0$。所以，$S$ 是完备充分统计量。\n\n我们感兴趣的参数是 $\\theta=1/p$。因为\n$$\n\\mathbb{E}[X_{1}]=p\\sum_{k=1}^{\\infty}k(1-p)^{k-1}\n=p\\cdot\\frac{1}{\\left(1-(1-p)\\right)^{2}}\n=\\frac{1}{p}=\\theta,\n$$\n所以估计量 $T_{0}=X_{1}$ 是 $\\theta$ 的无偏估计量。根据 Rao–Blackwell 定理，估计量\n$$\nT^{*}=\\mathbb{E}[T_{0}\\mid S]=\\mathbb{E}[X_{1}\\mid S]\n$$\n的方差不大于 $T_{0}$ 的方差，并且是充分统计量 $S$ 的函数。在给定 $S=s$ 的条件下，根据可交换性，所有的 $\\mathbb{E}[X_{i}\\mid S=s]$ 都相等，并且\n$$\n\\sum_{i=1}^{n}\\mathbb{E}[X_{i}\\mid S=s]=\\mathbb{E}\\left[\\sum_{i=1}^{n}X_{i}\\mid S=s\\right]=s,\n$$\n所以 $\\mathbb{E}[X_{1}\\mid S=s]=s/n$。因此，\n$$\nT^{*}=\\frac{S}{n}.\n$$\n由于 $S$ 是完备充分统计量，根据 Lehmann–Scheffé 定理，$T^{*}=S/n$ 是 $\\theta$ 的一致最小方差无偏估计量 (UMVUE)。\n\n最后，注意到 $\\mathbb{E}[S/n]=\\mathbb{E}[X_{1}]=1/p=\\theta$，这证实了其无偏性。", "answer": "$$\\boxed{\\frac{S}{n}}$$", "id": "1950082"}, {"introduction": "从离散分布转向连续分布，本题探讨一个均匀分布的场景。这里的充分统计量不再是样本总和，而是样本最大值，这突显了该定理的灵活性。通过改进样本极差这个初始估计量，你将练习对单个次序统计量取条件期望，这是处理定义分布边界的参数时的一项关键技能[@problem_id:1950098]。请注意，问题中提到的宇宙学模型仅为帮助理解概念而设的假想情景。", "problem": "在一个简化的宇宙学模型中，一个新形成的微晕的质量 $M$ 被假定为在区间 $(0, \\Theta)$ 上服从均匀分布的随机变量，其中 $\\Theta > 0$ 是一个未知的宇宙学参数，代表在给定空间区域内此类晕可能具有的最大质量。一组天体物理学家收集了 $n$ 个此类微晕质量的随机样本，记为 $M_1, M_2, \\ldots, M_n$。\n\n一位初级研究员建议使用样本极差 $R = M_{(n)} - M_{(1)}$ 作为与参数 $\\Theta$ 相关的一个简单统计量。这里，$M_{(1)}$ 和 $M_{(n)}$ 分别是样本中观测到的最小和最大质量。虽然 $R$ 是一个有效的统计量，但它不是最优的，因为它没有利用 $\\Theta$ 的完备充分统计量所包含的全部信息。\n\n根据 Rao-Blackwell 定理，可以通过将初始估计量以一个充分统计量为条件来构造一个改进的估计量。您的任务是应用此原理来改进样本极差 $R$。通过计算给定 $\\Theta$ 的完备充分统计量下 $R$ 的条件期望，来推导改进后的估计量。请用 $M_{(n)}$ 和样本量 $n$ 的解析表达式来表示您的最终答案。", "solution": "设 $M_{1},\\ldots,M_{n}$ 是独立同分布于 $\\mathrm{Unif}(0,\\Theta)$ 的随机变量。最大顺序统计量 $M_{(n)}$ 是 $\\Theta$ 的一个完备充分统计量。根据 Rao-Blackwell 定理，将初始估计量 $R=M_{(n)}-M_{(1)}$ 以 $M_{(n)}$ 为条件，可以得到一个改进的估计量：\n$$\n\\delta^{*}(M_{(n)})=\\mathbb{E}[R \\mid M_{(n)}]=\\mathbb{E}[M_{(n)}-M_{(1)} \\mid M_{(n)}].\n$$\n记 $t$ 为 $M_{(n)}$ 的一个实现值。给定 $M_{(n)}=t$，其余的 $n-1$ 个观测值独立同分布于 $\\mathrm{Unif}(0,t)$。设 $V_{(1)}$ 表示这 $n-1$ 个独立同分布于 $\\mathrm{Unif}(0,t)$ 的变量中的最小值。样本最小值 $M_{(1)}$ 与 $V_{(1)}$ 相同，因为另一个值是最大值 $t$。那么，\n$$\n\\mathbb{E}[R \\mid M_{(n)}=t]=t-\\mathbb{E}[V_{(1)}].\n$$\n为了计算 $\\mathbb{E}[V_{(1)}]$，我们利用标准均匀分布。设 $U_{(1)}$ 是 $m=n-1$ 个独立同分布于 $\\mathrm{Unif}(0,1)$ 的变量的最小值，其期望为 $\\mathbb{E}[U_{(1)}]=1/(m+1)=1/n$。由于 $V_{(1)}$ 是从 $\\mathrm{Unif}(0,t)$ 分布中抽取的最小值，其分布与 $t \\cdot U_{(1)}$ 相同，因此其期望为 $\\mathbb{E}[V_{(1)}] = t \\cdot \\mathbb{E}[U_{(1)}] = t/n$。代入条件期望公式，我们得到：\n$$\n\\mathbb{E}[R \\mid M_{(n)}=t] = t - \\mathbb{E}[V_{(1)}] = t - \\frac{t}{n} = \\frac{n-1}{n}t.\n$$\n最终，改进后的估计量是将实现值 $t$ 替换回统计量 $M_{(n)}$，即 $\\frac{n-1}{n}M_{(n)}$。", "answer": "$$\\boxed{\\frac{n-1}{n}\\,M_{(n)}}$$", "id": "1950098"}, {"introduction": "最后一个练习提升了问题的复杂度，考虑了一个充分统计量为二维向量的分布。你将处理一个区间依赖于参数 $\\theta$ 的均匀分布，这要求同时对样本最小值和最大值取条件期望。这个练习[@problem_id:1950044]展示了拉奥-布莱克维尔定理在处理多维充分统计量时的威力，并强化了利用对称性和可交换性来求解条件期望的技巧。", "problem": "设 $X_1, X_2, \\ldots, X_n$ 是从区间 $[\\theta, 2\\theta]$ 上的均匀分布中抽取的样本容量为 $n \\ge 2$ 的随机样本，其中参数 $\\theta > 0$ 未知。给定 $\\theta$ 的一个初始无偏估计量为 $T = \\frac{2}{3}X_1$。根据这些信息，求出对 $T$ 应用 Rao-Blackwell 定理所得到的 $\\theta$ 的改进估计量。", "solution": "设 $X_{1},\\ldots,X_{n}$ 独立同分布，其概率密度为 $f(x\\mid\\theta)=\\theta^{-1}\\,\\mathbf{1}\\{\\theta\\le x\\le 2\\theta\\}$。联合密度为\n$$\nf(x_{1},\\ldots,x_{n}\\mid\\theta)=\\theta^{-n}\\,\\mathbf{1}\\{\\theta\\le X_{(1)},\\;X_{(n)}\\le 2\\theta\\}\n=\\theta^{-n}\\,\\mathbf{1}\\{X_{(n)}/2\\le \\theta\\le X_{(1)}\\}.\n$$\n根据 Neyman–Fisher 分解定理，统计量 $S=(X_{(1)},X_{(n)})$ 是 $\\theta$ 的充分统计量。\n\nRao–Blackwell 定理指出，基于初始无偏估计量 $T=\\frac{2}{3}X_{1}$ 的改进估计量为\n$$\n\\tilde{T}=E\\!\\left[T\\mid S\\right]=E\\!\\left[\\frac{2}{3}X_{1}\\mid X_{(1)},X_{(n)}\\right]=\\frac{2}{3}\\,E\\!\\left[X_{1}\\mid X_{(1)},X_{(n)}\\right].\n$$\n设 $a=X_{(1)}$ 和 $b=X_{(n)}$。根据样本的可交换性，在给定全套顺序统计量的条件下，每个带标签的观测值等于每个顺序统计量的概率为 $1/n$。因此\n$$\nE\\!\\left[X_{1}\\mid X_{(1)}=a,X_{(2)},\\ldots,X_{(n-1)},X_{(n)}=b\\right]=\\frac{1}{n}\\sum_{k=1}^{n}X_{(k)}.\n$$\n在给定 $a$ 和 $b$ 的条件下，对 $X_{(2)},\\ldots,X_{(n-1)}$ 求条件期望，并利用在给定 $(a,b)$ 的情况下，中间的顺序统计量是 $n-2$ 个独立同分布于 $\\mathrm{Uniform}(a,b)$ 的变量的顺序统计量这一事实，我们得到\n$$\nE\\!\\left[X_{1}\\mid X_{(1)}=a,X_{(n)}=b\\right]\n=\\frac{1}{n}\\left(a+b+\\sum_{k=2}^{n-1}E\\!\\left[X_{(k)}\\mid a,b\\right]\\right)\n=\\frac{1}{n}\\left(a+b+(n-2)\\frac{a+b}{2}\\right)\n=\\frac{a+b}{2}.\n$$\n因此，\n$$\n\\tilde{T}\n=\\frac{2}{3}\\cdot\\frac{X_{(1)}+X_{(n)}}{2}\n=\\frac{X_{(1)}+X_{(n)}}{3}.\n$$\n由于 $E[\\tilde{T}]=E[E[T\\mid S]]=E[T]=\\theta$，估计量 $\\tilde{T}$ 是无偏的，且其方差不大于 $T$ 的方差，这由 Rao–Blackwell 定理保证。", "answer": "$$\\boxed{\\frac{X_{(1)}+X_{(n)}}{3}}$$", "id": "1950044"}]}