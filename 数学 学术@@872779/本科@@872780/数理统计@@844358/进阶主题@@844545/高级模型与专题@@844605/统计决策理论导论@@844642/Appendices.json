{"hands_on_practices": [{"introduction": "统计决策理论的基石是评估一个估计量或决策规则的“好坏”程度。我们使用“风险函数” $R(\\theta, \\delta)$ 来量化其平均损失，从而为比较不同的统计程序提供了坚实的基础。这个练习将带你从基本原理出发，为一个特定场景计算风险，这是掌握决策论所需的核心技能。[@problem_id:1924831]", "problem": "一个专用传感器被设计用于测量一个未知但恒定的物理量，该物理量用参数 $\\theta$ 表示。由于其内部机制，任何单次测量 $X$ 都会受到随机误差的影响，使得测量值是一个在区间 $[\\theta, \\theta+1]$ 上均匀分布的随机变量。\n\n一位工程师使用该传感器进行了两次独立测量，$X_1$ 和 $X_2$。他们提出了一个估计量 $\\delta(X_1, X_2)$，用于估计 $\\theta$ 的真值。该估计量定义为测量值的样本均值减去一个常数修正因子：\n$$\n\\delta(X_1, X_2) = \\frac{X_1 + X_2}{2} - \\frac{1}{2}\n$$\n该估计量的质量使用平方误差损失函数 $L(\\theta, a) = (a - \\theta)^2$ 来评估。估计量的总体性能由其风险来量化，风险定义为损失函数的期望值，$R(\\theta, \\delta) = E[L(\\theta, \\delta)]$。\n\n计算与估计量 $\\delta(X_1, X_2)$ 相关联的风险。将答案表示为一个精确的分数。", "solution": "给定独立测量值 $X_{1}$ 和 $X_{2}$，其中 $X_{i} \\sim \\mathrm{Unif}[\\theta,\\theta+1]$，以及估计量\n$$\n\\delta(X_{1},X_{2})=\\frac{X_{1}+X_{2}}{2}-\\frac{1}{2}.\n$$\n在平方误差损失下，风险即为均方误差：\n$$\nR(\\theta,\\delta)=\\mathbb{E}\\left[(\\delta-\\theta)^{2}\\right]=\\operatorname{Var}(\\delta)+\\left(\\mathbb{E}[\\delta]-\\theta\\right)^{2}.\n$$\n对于 $X_{i} \\sim \\mathrm{Unif}[\\theta,\\theta+1]$，其均值和方差分别为\n$$\n\\mathbb{E}[X_{i}]=\\theta+\\frac{1}{2}, \\qquad \\operatorname{Var}(X_{i})=\\frac{1}{12}.\n$$\n计算 $\\delta$ 的期望：\n$$\n\\mathbb{E}[\\delta]=\\frac{\\mathbb{E}[X_{1}]+\\mathbb{E}[X_{2}]}{2}-\\frac{1}{2}=\\frac{2\\left(\\theta+\\frac{1}{2}\\right)}{2}-\\frac{1}{2}=\\theta,\n$$\n因此该估计量是无偏的，且偏差项为零。因此，\n$$\nR(\\theta,\\delta)=\\operatorname{Var}(\\delta).\n$$\n由于减去一个常数不改变方差，\n$$\n\\operatorname{Var}(\\delta)=\\operatorname{Var}\\!\\left(\\frac{X_{1}+X_{2}}{2}\\right)=\\frac{1}{4}\\operatorname{Var}(X_{1}+X_{2}).\n$$\n利用独立性，\n$$\n\\operatorname{Var}(X_{1}+X_{2})=\\operatorname{Var}(X_{1})+\\operatorname{Var}(X_{2})=\\frac{1}{12}+\\frac{1}{12}=\\frac{1}{6}.\n$$\n因此，\n$$\n\\operatorname{Var}(\\delta)=\\frac{1}{4}\\cdot\\frac{1}{6}=\\frac{1}{24}.\n$$\n因此风险不依赖于 $\\theta$，其值恒为 $\\frac{1}{24}$。", "answer": "$$\\boxed{\\frac{1}{24}}$$", "id": "1924831"}, {"introduction": "在学会如何计算风险之后，下一步自然就是利用风险来比较不同的估计量。这个问题提供了一个具体的场景，让你比较一个标准的无偏估计量和一个非传统的有偏估计量。它清晰地揭示了著名的“偏差-方差权衡”，并说明了一个带有偏差的估计量其整体表现不一定更差，因为其风险函数在参数空间的某些区域可能更优。[@problem_id:1924850]", "problem": "一位物理学家正在研究一种罕见的粒子衰变过程。在固定的时间间隔内检测到的衰变次数 $X$ 服从泊松分布，其未知平均率 $\\lambda > 0$。为了估计 $\\lambda$，实验重复了 $n$ 次，得到一个独立同分布 (i.i.d.) 的随机样本 $X_1, X_2, \\ldots, X_n$。\n\n现有两种 $\\lambda$ 的估计量可供考虑。第一种是标准样本均值，定义为 $\\delta_1(\\mathbf{X}) = \\bar{X}$，其中 $\\bar{X} = \\frac{1}{n} \\sum_{i=1}^{n} X_i$。第二种是提出的非标准估计量 $\\delta_2(\\mathbf{X}) = \\bar{X} + 1$。\n\n为了评估和比较这些估计量，该物理学家使用平方误差损失函数 $L(\\lambda, a) = (\\lambda - a)^2$。估计量 $\\delta$ 的性能由其风险函数 $R(\\lambda, \\delta)$ 来量化，风险函数是损失函数的期望值。\n\n确定第二个估计量的风险与第一个估计量的风险之比，即 $\\frac{R(\\lambda, \\delta_2)}{R(\\lambda, \\delta_1)}$。你的最终答案应该是一个关于样本大小 $n$ 和真实平均率 $\\lambda$ 的闭式解析表达式。", "solution": "我们将 $X_{1},\\ldots,X_{n}$ 建模为独立同分布的 $\\text{Poisson}(\\lambda)$，其中 $\\lambda0$。对于任何估计量 $\\delta$，在平方误差损失 $L(\\lambda,a)=(\\lambda-a)^{2}$ 下，风险即为均方误差：\n$$\nR(\\lambda,\\delta)=\\mathbb{E}_{\\lambda}\\big[(\\lambda-\\delta)^{2}\\big]=\\operatorname{Var}_{\\lambda}(\\delta)+\\big(\\mathbb{E}_{\\lambda}[\\delta]-\\lambda\\big)^{2}.\n$$\n\n当 $X_{i}\\sim\\text{Poisson}(\\lambda)$ 时，样本均值 $\\bar{X}=\\frac{1}{n}\\sum_{i=1}^{n}X_{i}$ 的性质如下：\n- $\\mathbb{E}_{\\lambda}[X_{i}]=\\lambda$ 且 $\\operatorname{Var}_{\\lambda}(X_{i})=\\lambda$。\n- 根据线性和独立性，\n$$\n\\mathbb{E}_{\\lambda}[\\bar{X}]=\\frac{1}{n}\\sum_{i=1}^{n}\\mathbb{E}_{\\lambda}[X_{i}]=\\lambda,\\quad\n\\operatorname{Var}_{\\lambda}(\\bar{X})=\\frac{1}{n^{2}}\\sum_{i=1}^{n}\\operatorname{Var}_{\\lambda}(X_{i})=\\frac{\\lambda}{n}.\n$$\n\n$\\delta_{1}(\\mathbf{X})=\\bar{X}$ 的风险：\n- 偏差为 $\\mathbb{E}_{\\lambda}[\\bar{X}]-\\lambda=0$。\n- 因此\n$$\nR(\\lambda,\\delta_{1})=\\operatorname{Var}_{\\lambda}(\\bar{X})+0^{2}=\\frac{\\lambda}{n}.\n$$\n\n$\\delta_{2}(\\mathbf{X})=\\bar{X}+1$ 的风险：\n- 期望为 $\\mathbb{E}_{\\lambda}[\\delta_{2}]=\\mathbb{E}_{\\lambda}[\\bar{X}]+1=\\lambda+1$，所以偏差为 $1$。\n- 方差为 $\\operatorname{Var}_{\\lambda}(\\delta_{2})=\\operatorname{Var}_{\\lambda}(\\bar{X})=\\frac{\\lambda}{n}$。\n- 因此\n$$\nR(\\lambda,\\delta_{2})=\\operatorname{Var}_{\\lambda}(\\delta_{2})+\\big(\\mathbb{E}_{\\lambda}[\\delta_{2}]-\\lambda\\big)^{2}=\\frac{\\lambda}{n}+1.\n$$\n\n风险之比：\n$$\n\\frac{R(\\lambda,\\delta_{2})}{R(\\lambda,\\delta_{1})}=\\frac{\\frac{\\lambda}{n}+1}{\\frac{\\lambda}{n}}=\\frac{\\lambda+n}{\\lambda}=1+\\frac{n}{\\lambda}.\n$$", "answer": "$$\\boxed{1+\\frac{n}{\\lambda}}$$", "id": "1924850"}, {"introduction": "前一个练习表明，通常不存在一个在所有情况下都一致最优的估计量，这就引出了一个关键问题：我们该如何做出选择？这个最终的练习介绍了“极小化极大原则”（minimax principle），一个核心的决策策略。该原则旨在选择那个能使最坏情况（最大）风险最小化的决策规则，为在不确定性下做出决策提供了一种稳健的方法。[@problem_id:1924864]", "problem": "在一个统计决策问题中，分析师必须在两个决策规则 $\\delta_1$ 和 $\\delta_2$ 之间做出选择，以对未知参数 $\\theta$ 进行推断。已知参数 $\\theta$ 位于区间 $[0, 1]$ 内。任何决策规则 $\\delta$ 的性能都通过一个预定义的损失函数来评估，这导出了一个风险函数 $R(\\theta, \\delta)$，表示在给定 $\\theta$ 值下的期望损失。\n\n这两个规则的风险函数如下：\n1. $R(\\theta, \\delta_1) = A \\theta (1 - \\theta)$\n2. $R(\\theta, \\delta_2) = c$\n\n其中，$A$ 和 $c$ 是已知的正常数。\n\n分析师采用极小化极大原则来选择决策规则。该原则要求选择在参数 $\\theta$ 的所有可能值上使最大可能风险最小化的规则。\n\n在极小化极大原则下，为了使规则 $\\delta_2$ 严格优于规则 $\\delta_1$，常数 $c$ 必须小于某个依赖于 $A$ 的阈值。确定这个阈值。", "solution": "根据极小化极大原则，对于一个决策规则 $\\delta$，其准则是最小化最大风险 $\\sup_{\\theta \\in [0,1]} R(\\theta,\\delta)$。对于 $\\delta_{2}$，风险是恒定的，所以\n$$\n\\sup_{\\theta \\in [0,1]} R(\\theta,\\delta_{2}) = \\sup_{\\theta \\in [0,1]} c = c.\n$$\n对于 $\\delta_{1}$，计算 $A\\theta(1-\\theta)$ 在 $[0,1]$ 上的上确界。使用配方法，\n$$\n\\theta(1-\\theta) = -\\theta^{2} + \\theta = -\\left(\\theta - \\frac{1}{2}\\right)^{2} + \\frac{1}{4},\n$$\n当 $\\theta = \\frac{1}{2}$ 时，该式达到其最大值 $\\frac{1}{4}$。因此，\n$$\n\\sup_{\\theta \\in [0,1]} R(\\theta,\\delta_{1}) = A \\cdot \\frac{1}{4} = \\frac{A}{4}.\n$$\n根据极小化极大原则，如果 $\\delta_{2}$ 的最大风险严格小于 $\\delta_{1}$ 的最大风险，则 $\\delta_{2}$ 严格优于 $\\delta_{1}$：\n$$\nc  \\frac{A}{4}.\n$$\n因此，$c$ 的阈值是 $\\frac{A}{4}$。", "answer": "$$\\boxed{\\frac{A}{4}}$$", "id": "1924864"}]}