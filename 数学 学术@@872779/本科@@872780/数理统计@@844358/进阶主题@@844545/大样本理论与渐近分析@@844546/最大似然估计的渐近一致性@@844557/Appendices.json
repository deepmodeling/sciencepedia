{"hands_on_practices": [{"introduction": "我们从一个典型案例开始，探索最大似然估计（MLE）的一致性。在许多“正则”统计模型中，证明 MLE 一致性的经典方法是利用大数定律。这个练习将带你推导拉普拉斯分布尺度参数的 MLE，并展示如何通过论证其收敛于一个期望值来证明其一致性，这是理解 MLE 渐近性质的基石。[@problem_id:1895934]", "problem": "考虑一个大小为 $n$ 的随机样本，记为 $X_1, X_2, \\ldots, X_n$，它来自一个已知位置参数为0的拉普拉斯分布。该分布中任意观测值 $X_i$ 的概率密度函数 (PDF) 由下式给出：\n$$f(x; b) = \\frac{1}{2b} \\exp\\left(-\\frac{|x|}{b}\\right)$$\n其中 $x \\in (-\\infty, \\infty)$ 且 $b > 0$ 是未知的尺度参数。\n\n您的任务是进行两项与 $b$ 的估计相关的计算。\n首先，确定尺度参数 $b$ 的最大似然估计量 (MLE)，我们将其记为 $\\hat{b}_n$。\n其次，论证估计量一致性的一个关键步骤是使用大数定律。作为此论证的一部分，请计算遵循给定拉普拉斯分布的单个随机变量 $X$ 的期望值 $E[|X|]$。\n\n请以双分量结果的形式提供您的答案，其中第一个分量是 MLE $\\hat{b}_n$ 关于样本观测值的符号表达式，第二个分量是期望值 $E[|X|]$ 的符号表达式。", "solution": "我们给定来自拉普拉斯分布的独立观测值 $X_{1},\\ldots,X_{n}$，其位置参数为 $0$，尺度参数为 $b>0$，密度函数为 $f(x;b)=\\frac{1}{2b}\\exp\\!\\left(-\\frac{|x|}{b}\\right)$。\n\n为了求 $b$ 的最大似然估计量，我们写出观测样本 $x_{1},\\ldots,x_{n}$ 的似然函数：\n$$\nL(b)=\\prod_{i=1}^{n}\\frac{1}{2b}\\exp\\!\\left(-\\frac{|x_{i}|}{b}\\right)=\\left(\\frac{1}{2b}\\right)^{n}\\exp\\!\\left(-\\frac{1}{b}\\sum_{i=1}^{n}|x_{i}|\\right),\n$$\n其对数似然函数为\n$$\n\\ell(b)=\\ln L(b)=-n\\ln(2b)-\\frac{1}{b}\\sum_{i=1}^{n}|x_{i}|.\n$$\n对 $b$ 求导：\n$$\n\\ell'(b)=-\\frac{n}{b}+\\frac{1}{b^{2}}\\sum_{i=1}^{n}|x_{i}|,\n$$\n并令 $\\ell'(b)=0$ 可得\n$$\n-\\frac{n}{b}+\\frac{1}{b^{2}}\\sum_{i=1}^{n}|x_{i}|=0 \\;\\;\\Longrightarrow\\;\\; -n b+\\sum_{i=1}^{n}|x_{i}|=0 \\;\\;\\Longrightarrow\\;\\; \\hat{b}_{n}=\\frac{1}{n}\\sum_{i=1}^{n}|x_{i}|.\n$$\n为了验证这是一个最大值，计算二阶导数\n$$\n\\ell''(b)=\\frac{n}{b^{2}}-\\frac{2}{b^{3}}\\sum_{i=1}^{n}|x_{i}|,\n$$\n并在 $b=\\hat{b}_{n}$ 处求值：\n$$\n\\ell''(\\hat{b}_{n})=\\frac{n}{\\hat{b}_{n}^{2}}-\\frac{2}{\\hat{b}_{n}^{3}}\\sum_{i=1}^{n}|x_{i}|=\\frac{n}{\\hat{b}_{n}^{2}}-\\frac{2n}{\\hat{b}_{n}^{2}}=-\\frac{n}{\\hat{b}_{n}^{2}}  0,\n$$\n因此 $\\hat{b}_{n}$ 最大化了对数似然函数（对于退化情况 $\\sum|x_{i}|=0$，似然函数在 $b\\to 0^{+}$ 时达到最大值；在模型下此事件的概率为零）。\n\n接下来，我们计算单个 $X\\sim\\text{Laplace}(0,b)$ 的 $E[|X|]$：\n$$\nE[|X|]=\\int_{-\\infty}^{\\infty}|x|\\frac{1}{2b}\\exp\\!\\left(-\\frac{|x|}{b}\\right)\\,dx.\n$$\n根据对称性，\n$$\nE[|X|]=\\frac{1}{b}\\int_{0}^{\\infty}x\\exp\\!\\left(-\\frac{x}{b}\\right)\\,dx.\n$$\n使用换元法 $u=\\frac{x}{b}$，因此 $x=bu$ 且 $dx=b\\,du$，得到\n$$\nE[|X|]=\\frac{1}{b}\\int_{0}^{\\infty}b u\\,\\exp(-u)\\,b\\,du=b\\int_{0}^{\\infty}u\\exp(-u)\\,du=b\\,\\Gamma(2)=b.\n$$\n因此，所要求的双分量结果是 MLE $\\hat{b}_{n}=\\frac{1}{n}\\sum_{i=1}^{n}|x_{i}|$ 和期望 $E[|X|]=b$。", "answer": "$$\\boxed{\\begin{pmatrix}\\frac{1}{n}\\sum_{i=1}^{n}|x_{i}|  b\\end{pmatrix}}$$", "id": "1895934"}, {"introduction": "在实际应用中，我们建立的统计模型总是基于某些假设，而这些假设可能与现实不完全相符。那么，当模型设定不正确时，我们得到的估计量会发生什么？这个问题通过一个思想实验让你探索模型误设（model misspecification）的后果。你将看到，即使我们错误地假设了方差，在某些情况下，得到的均值估计量仍然是一致的。[@problem_id:1895917] 这个练习有助于你理解 MLE 的稳健性，并让你思考估计量在非理想条件下的行为。", "problem": "一位统计学家正在分析一个数据集，该数据集包含观测值 $X_1, X_2, \\dots, X_n$，这些观测值构成了一个来自正态分布的随机样本。\n\n真实的分布具有未知的均值 $\\mu$ 和已知的方差 $\\sigma_0^2$。\n\n由于一个误解，这位统计学家错误地设定了模型。他们假设数据是从一个均值为 $\\theta$（待估计）且方差恰好为 1 的正态分布中抽取的。基于这个不正确的假设，该统计学家为参数 $\\theta$ 构建了似然函数，并找到了其最大似然估计量（MLE），我们将其记为 $\\hat{\\theta}_n$。\n\n请确定当样本量 $n$ 趋于无穷大时，该估计量 $\\hat{\\theta}_n$ 依概率收敛到的值。用分布的真实参数将你的答案表示为一个符号表达式。", "solution": "设真实的数据生成过程为 $X_{1},\\dots,X_{n}$ i.i.d. $\\sim \\mathcal{N}(\\mu,\\sigma_{0}^{2})$，其中 $\\mu$ 未知，$\\sigma_{0}^{2}$ 已知。该统计学家错误地假设模型为 $X_{i} \\sim \\mathcal{N}(\\theta,1)$ 并构造了关于 $\\theta$ 的似然函数：\n$$\nL_{n}(\\theta)=\\prod_{i=1}^{n}\\left[(2\\pi)^{-\\frac{1}{2}}\\exp\\!\\left(-\\frac{1}{2}(x_{i}-\\theta)^{2}\\right)\\right].\n$$\n对数似然函数为\n$$\n\\ell_{n}(\\theta)=\\ln L_{n}(\\theta)=-\\frac{n}{2}\\ln(2\\pi)-\\frac{1}{2}\\sum_{i=1}^{n}(x_{i}-\\theta)^{2}.\n$$\n对 $\\theta$ 求导并令其为零以求得 MLE：\n$$\n\\frac{\\partial}{\\partial\\theta}\\ell_{n}(\\theta)=-\\frac{1}{2}\\sum_{i=1}^{n}2(\\theta-x_{i})=-\\sum_{i=1}^{n}(\\theta-x_{i})=-n\\theta+\\sum_{i=1}^{n}x_{i}=0,\n$$\n这得到\n$$\n\\hat{\\theta}_{n}=\\frac{1}{n}\\sum_{i=1}^{n}X_{i}=\\bar{X}_{n}.\n$$\n在真实模型下，根据弱大数定律，\n$$\n\\bar{X}_{n}\\xrightarrow{p}\\mathbb{E}[X_{1}]=\\mu \\quad \\text{as } n\\to\\infty.\n$$\n因此，在错误设定的方差下计算出的 MLE 依概率收敛到真实均值 $\\mu$。等价地，从错误设定的 M 估计的角度来看，伪真实参数（pseudo-true parameter）最大化了期望对数似然\n$$\n\\mathbb{E}\\left[\\ell_{1}(\\theta)\\right]=-\\frac{1}{2}\\mathbb{E}\\left[(X_{1}-\\theta)^{2}\\right]+\\text{constant}=-\\frac{1}{2}\\left(\\sigma_{0}^{2}+(\\mu-\\theta)^{2}\\right)+\\text{constant},\n$$\n该式在 $\\theta=\\mu$ 处唯一地达到最大值，从而证实了相同的极限。", "answer": "$$\\boxed{\\mu}$$", "id": "1895917"}, {"introduction": "保证最大似然估计量一致性的一般性定理，通常依赖于一系列被称为“正则性条件”的假设。然而，当这些条件不被满足时，我们该如何分析估计量的性质呢？本练习将探讨一个非正则的例子：移位指数分布。该分布的支撑集依赖于待估参数 $\\theta$，这违反了标准正则性条件之一。[@problem_id:1895868] 通过这个练习，你将学习如何在这种情况下推导 MLE，并直接分析其概率分布来证明一致性，从而深化对一致性概念的理解，超越标准定理的范畴。", "problem": "在可靠性工程中，某些电子元件的寿命使用移位指数分布进行建模。该分布考虑了一个初始的“老化”期或保证寿命 $\\theta$，在此期间不可能发生故障。设 $n$ 个此类元件的寿命由随机变量 $X_1, X_2, \\dots, X_n$ 表示，它们是独立同分布的。它们的概率密度函数 (PDF) 由下式给出：\n$$f(x; \\theta) = \\exp(-(x - \\theta)) \\quad \\text{for } x \\ge \\theta$$\n且当 $x  \\theta$ 时，$f(x; \\theta) = 0$。参数 $\\theta > 0$ 是一个未知的常数，代表保证寿命。\n\n一位分析师获取了 $n$ 个元件寿命的样本，并希望估计 $\\theta$。首先，确定 $\\theta$ 的最大似然估计量 (MLE)，我们将其记为 $\\hat{\\theta}_n$。如果一个估计量随着样本量 $n$ 的增加在概率上收敛于真实的参数值，则称该估计量是一致的。对于一个一致的估计量，当 $n \\to \\infty$ 时，估计值与真实参数的距离大于任意小的固定距离 $\\epsilon  0$ 的概率应趋近于零。\n\n您的任务是为移位指数模型量化这种收敛性。找出概率 $P(|\\hat{\\theta}_n - \\theta|  \\epsilon)$ 关于样本量 $n$ 和正常数 $\\epsilon$ 的封闭形式解析表达式。", "solution": "对于一个观测样本 $x_{1},\\dots,x_{n}$，其联合似然函数为\n$$\nL(\\theta;x_{1},\\dots,x_{n})=\\prod_{i=1}^{n}f(x_{i};\\theta)\n=\\prod_{i=1}^{n}\\exp\\!\\big(-(x_{i}-\\theta)\\big)\\cdot \\mathbf{1}\\{x_{i}\\ge \\theta\\}\n=\\exp\\!\\Big(-\\sum_{i=1}^{n}x_{i}+n\\theta\\Big)\\cdot \\mathbf{1}\\{\\theta\\le x_{(1)}\\},\n$$\n其中 $x_{(1)}=\\min_{1\\le i\\le n}x_{i}$。对数似然函数为\n$$\n\\ell(\\theta)=-\\sum_{i=1}^{n}x_{i}+n\\theta \\quad \\text{subject to} \\quad \\theta\\le x_{(1)}.\n$$\n由于 $\\ell(\\theta)$ 在 $\\theta$ 上是严格递增的，因此在可行集上的最大值在边界处取得，从而得到最大似然估计量\n$$\n\\hat{\\theta}_{n}=X_{(1)}=\\min_{1\\le i\\le n}X_{i}.\n$$\n\n记 $X_{i}=\\theta+Y_{i}$，其中 $Y_{i}\\stackrel{\\text{i.i.d.}}{\\sim}\\text{Exp}(1)$，因此 $\\hat{\\theta}_{n}-\\theta=\\min_{1\\le i\\le n}Y_{i}=Y_{(1)}$。对于 $y\\ge 0$，\n$$\n\\Pr(Y_{(1)}y)=\\Pr(Y_{1}y,\\dots,Y_{n}y)=\\prod_{i=1}^{n}\\Pr(Y_{i}y)=\\big(\\exp(-y)\\big)^{n}=\\exp(-ny),\n$$\n因此 $Y_{(1)}\\sim \\text{Exp}(n)$。因为 $\\hat{\\theta}_{n}\\ge \\theta$，对于任意 $\\epsilon0$，\n$$\n\\Pr(|\\hat{\\theta}_{n}-\\theta|\\epsilon)=\\Pr(\\hat{\\theta}_{n}-\\theta\\epsilon)=\\Pr\\big(Y_{(1)}\\epsilon\\big)=\\exp(-n\\epsilon).\n$$\n这给出了所求的封闭形式表达式，并表明该估计量是一致的，因为对于任何固定的 $\\epsilon0$，当 $n\\to\\infty$ 时，$\\exp(-n\\epsilon)\\to 0$。", "answer": "$$\\boxed{\\exp(-n\\epsilon)}$$", "id": "1895868"}]}