{"hands_on_practices": [{"introduction": "理论需要通过实践来巩固。要正确实施 K 折交叉验证，第一步便是精确地划分数据集。本练习将通过一个具体的数值示例，帮助你理解当数据集大小无法被折数 $K$ 整除时，如何构建训练集和验证集；掌握这项基本技能是后续所有模型评估工作的基础。[@problem_id:1912440]", "problem": "一位数据科学家正在处理一个包含 $n=97$ 个独立观测值的数据集。为了评估机器学习模型的泛化性能，他们决定采用 $k=10$ 的 $k$-折交叉验证程序。\n\n在这种方法中，整个数据集首先被划分为 $k$ 个不重叠的子集，称为“折”。由于观测总数 $n$ 不能被折数 $k$ 整除，因此创建的各折大小会尽可能相等。具体来说，一些折将包含 $\\lfloor n/k \\rfloor$ 个观测值，而其余的折将包含 $\\lceil n/k \\rceil$ 个观测值。\n\n然后，交叉验证过程包括 $k$ 次迭代。在每次迭代中，会留出不同的折作为验证集，其余的 $k-1$ 个折组合成训练集。因此，训练集的大小在不同迭代之间可能会略有不同。\n\n请确定在此程序的 10 次迭代中，可能遇到的训练集的最小可能大小。", "solution": "我们已知总观测值为 $n=97$，折数为 $k=10$。在 $k$-折交叉验证中，数据集被划分为 $k$ 个大小尽可能相等的折，这意味着一些折的大小为 $\\lfloor n/k \\rfloor$，其余的折大小为 $\\lceil n/k \\rceil$。\n\n计算基础折的大小：\n$$\n\\left\\lfloor \\frac{n}{k} \\right\\rfloor = \\left\\lfloor \\frac{97}{10} \\right\\rfloor = 9, \\quad \\left\\lceil \\frac{n}{k} \\right\\rceil = \\left\\lceil \\frac{97}{10} \\right\\rceil = 10.\n$$\n根据除法算法，\n$$\nn = k \\left\\lfloor \\frac{n}{k} \\right\\rfloor + r \\quad \\text{with} \\quad r = n - k \\left\\lfloor \\frac{n}{k} \\right\\rfloor.\n$$\n在这里，\n$$\nr = 97 - 10 \\cdot 9 = 7.\n$$\n因此，有 $r=7$ 个大小为 $10$ 的折，以及 $k-r=3$ 个大小为 $9$ 的折。\n\n在每次迭代中，训练集的大小等于总观测值数减去留出的折的大小。因此，如果留出一个大小为 $s$ 的折，训练集的大小为\n$$\nT = n - s.\n$$\n当 $s$ 尽可能大时，训练集的大小最小，即留出一个大小为 $\\lceil n/k \\rceil = 10$ 的折，得出\n$$\nT_{\\min} = n - \\left\\lceil \\frac{n}{k} \\right\\rceil = 97 - 10 = 87.\n$$\n为完整起见，如果留出一个大小为 $9$ 的折，训练集的大小将是 $97 - 9 = 88$，这个值更大。因此，在 10 次迭代中，训练集的最小可能大小是 $87$。", "answer": "$$\\boxed{87}$$", "id": "1912440"}, {"introduction": "理解了如何设置交叉验证后，我们来探讨它的核心用途之一：模型选择。这个实践将向你展示如何利用交叉验证的结果，从多个候选模型中选出最优模型。你将学习并应用“一倍标准误”规则，这是一个在模型性能和简洁性之间取得平衡，以防止过拟合的关键策略。[@problem_id:1912455]", "problem": "一个生物统计学家团队正在使用基因组数据构建疾病风险的预测模型。他们正在使用一种称为“最小绝对收缩和选择算子”（LASSO）回归的方法。LASSO模型的复杂性由一个调整参数 $\\lambda$ 控制。$\\lambda$ 的值越高，模型越简单，预测变量越少。\n\n为了选择 $\\lambda$ 的最佳值，该团队进行了K折交叉验证（CV）。他们测试了五个不同的 $\\lambda$ 值，并为每个值计算了平均交叉验证预测误差及其标准误。结果总结如下：\n\n*   **模型 A**：$\\lambda = 0.01$，预测变量数 = 12，平均交叉验证误差 = 0.35，标准误 = 0.05\n\n*   **模型 B**：$\\lambda = 0.05$，预测变量数 = 9，平均交叉验证误差 = 0.31，标准误 = 0.04\n\n*   **模型 C**：$\\lambda = 0.10$，预测变量数 = 6，平均交叉验证误差 = 0.28，标准误 = 0.03\n\n*   **模型 D**：$\\lambda = 0.20$，预测变量数 = 4，平均交叉验证误差 = 0.30，标准误 = 0.04\n\n*   **模型 E**：$\\lambda = 0.50$，预测变量数 = 2，平均交叉验证误差 = 0.34，标准误 = 0.06\n\n该团队决定使用“一倍标准误规则”来选择最终模型。该规则倾向于选择更简单的模型以避免过拟合。根据一倍标准误规则，应选择哪个模型进行最终分析？\n\nA. 模型 A\nB. 模型 B\nC. 模型 C\nD. 模型 D\nE. 模型 E", "solution": "我们应用与交叉验证一起使用的“一倍标准误”（1-SE）规则。令 $\\hat{E}(\\lambda)$ 表示平均交叉验证误差，$\\operatorname{SE}(\\lambda)$ 表示其标准误。首先，找出具有最小平均交叉验证误差的模型：\n- 最小的平均交叉验证误差为 $\\hat{E}(\\lambda^{\\ast})=0.28$，出现在模型 C，其标准误为 $\\operatorname{SE}(\\lambda^{\\ast})=0.03$。\n\n计算 1-SE 阈值：\n$$\nT=\\hat{E}(\\lambda^{\\ast})+\\operatorname{SE}(\\lambda^{\\ast})=0.28+0.03=0.31.\n$$\n\n根据 1-SE 规则，选择平均交叉验证误差最多为 $T$ 的最简单模型（最大的 $\\lambda$，最少的预测变量）。将每个模型的平均交叉验证误差与 $T=0.31$ 进行比较：\n- 模型 A: $0.35>T$ (排除)。\n- 模型 B: $0.31\\leq T$ (符合条件)。\n- 模型 C: $0.28\\leq T$ (符合条件)。\n- 模型 D: $0.30\\leq T$ (符合条件)。\n- 模型 E: $0.34>T$ (排除)。\n\n在符合条件的模型 $\\{B,C,D\\}$ 中，选择最简单的模型（最大的 $\\lambda$ 或最少的预测变量）。它们的复杂性分别为：B 有 $9$ 个预测变量，C 有 $6$ 个，D 有 $4$ 个。其中最简单的是模型 D。因此，根据 1-SE 规则，应选择模型 D。", "answer": "$$\\boxed{D}$$", "id": "1912455"}, {"introduction": "在真实的机器学习项目中，我们经常会遇到数据预处理的挑战，例如处理缺失值。本练习将探讨一个在交叉验证中至关重要的微妙问题：“信息泄露”。通过分析一个包含数据插补的场景，你将学会如何设计严谨的验证流程，以确保模型性能评估的公正性和可靠性。[@problem_id:1912459]", "problem": "一家生物医学研究公司的数据科学家负责开发一个预测模型，以评估特定代谢综合征的风险。可用数据集表示为 $D$，包含 $N$ 名患者的记录，每条记录包含 $P$ 个特征（生物标志物、临床测量值）和一个二元结果（高风险或低风险）。生物标志物测量值中有很大一部分是缺失的。\n\n所选择的预测模型是支持向量机 (SVM)。为了处理缺失数据，团队决定使用 k-近邻 (k-NN) 插补法。在这种方法中，通过在数据集中基于非缺失特征找到 $k$ 个最相似的患者（“邻居”），然后聚合这些邻居的相应特征值（例如，通过取均值或中位数），来估计给定患者记录中某个特征的缺失值。\n\n为了获得 SVM 在未见数据上性能的可靠估计，数据科学家必须使用 K-折交叉验证。关键挑战在于如何将 k-NN 插补步骤正确地整合到交叉验证程序中，以避免“信息泄露”，因为信息泄露会导致过于乐观的性能估计。\n\n请您在以下选项中确定唯一一个方法论上合理的程序。一个“程序”如果能确保来自验证折的信息在任何方面都不会影响模型的训练或任何先前的数据准备步骤（如插补），则被认为是合理的。\n\n设带有缺失值的原始数据集为 $D$。\n\nA. **程序 A**\n1.  对整个数据集 $D$ 应用 k-NN 插补，创建一个完整的数据集 $D_{imputed}$。\n2.  将 $D_{imputed}$ 划分为 $K$ 折。\n3.  对于每一折 $i=1, \\dots, K$：\n    a. 使用第 $i$ 折作为测试集，其余 $K-1$ 折作为训练集。\n    b. 在训练集上训练 SVM 模型。\n    c. 在测试集上评估 SVM 模型。\n4.  计算所有 $K$ 次评估的平均性能指标。\n\nB. **程序 B**\n1.  将原始数据集 $D$（带有缺失值）划分为 $K$ 折。\n2.  对于每一折 $i=1, \\dots, K$：\n    a. 将第 $i$ 折指定为测试集 ($D_{test}$)，其余 $K-1$ 折为训练集 ($D_{train}$)。请注意，这两个集合仍然包含缺失值。\n    b. 仅从训练集 $D_{train}$ 学习 k-NN 结构（即识别邻居），以构建插补模型。\n    c. 使用步骤 (2b) 的插补模型填充 $D_{train}$ 和 $D_{test}$ 中的缺失值。对于 $D_{test}$ 中任何有缺失值的样本，其邻居完全在 $D_{train}$ 中寻找。这样就创建了 $D'_{train}$ 和 $D'_{test}$。\n    d. 在插补后的训练集 $D'_{train}$ 上训练 SVM 模型。\n    e. 在插补后的测试集 $D'_{test}$ 上评估 SVM 模型。\n3.  计算所有 $K$ 次评估的平均性能指标。\n\nC. **程序 C**\n1.  将原始数据集 $D$（带有缺失值）划分为 $K$ 折。\n2.  对于每一折 $i=1, \\dots, K$：\n    a. 将第 $i$ 折指定为测试集 ($D_{test}$)，其余 $K-1$ 折为训练集 ($D_{train}$)。\n    b. 对 $D_{train}$ 应用 k-NN 插补（仅使用 $D_{train}$ 内部的邻居）以创建 $D'_{train}$。\n    c. 对 $D_{test}$ 应用 k-NN 插补（仅使用 $D_{test}$ 内部的邻居）以创建 $D'_{test}$。\n    d. 在 $D'_{train}$ 上训练 SVM 模型。\n    e. 在 $D'_{test}$ 上评估 SVM 模型。\n3.  计算所有 $K$ 次评估的平均性能指标。\n\nD. **程序 D**\n1.  将原始数据集 $D$ 划分为单个训练集（80% 的数据）和单个测试集（20% 的数据）。\n2.  对训练集应用 k-NN 插补，创建插补后的训练集。\n3.  对测试集应用 k-NN 插补，创建插补后的测试集。\n4.  在插补后的训练集上训练 SVM 模型。\n5.  在插补后的测试集上评估模型并报告性能。\n\n在上述程序中，哪一个正确地实现了带插补的交叉验证，以提供对模型性能的无偏估计？", "solution": "设 $D=\\{(x_{n},y_{n})\\}_{n=1}^{N}$ 表示数据集，其中 $x_{n}\\in \\mathbb{R}^{P}$ 中有缺失条目，且 $y_{n}\\in\\{0,1\\}$ 是二元标签。一个有效的交叉验证流程必须确保，在任何一折中，使用验证数据拟合的任何函数都不会影响该折的训练或预处理的任何步骤。\n\n定义一个由 $\\eta$ 参数化的插补算子 $\\mathcal{I}_{\\eta}$，对于 k-NN 插补，$\\eta$ 包含用于计算邻居关系的训练特征集（以及任何在训练集上拟合的预处理，如缩放）。正确的逐折程序必须：\n- 仅在 $D_{train}$ 上拟合 $\\eta$，即 $\\hat{\\eta}=g(D_{train})$，\n- 生成插补后的集合 $\\tilde{D}_{train}=\\mathcal{I}_{\\hat{\\eta}}(D_{train})$ 和 $\\tilde{D}_{test}=\\mathcal{I}_{\\hat{\\eta}}(D_{test})$，\n- 在 $\\tilde{D}_{train}$ 上训练模型 $h$ 并在 $\\tilde{D}_{test}$ 上进行评估。\n\n对于 k-NN，将 $\\mathcal{I}_{\\hat{\\eta}}$ 应用于任何具有缺失坐标 $j$ 的 $x$ 时，必须仅从 $D_{train}$ 中寻找邻居，并聚合它们在坐标 $j$ 上的值来插补 $x_{j}$。\n\n根据此要求评估每个选项：\n\n- 程序 A 在拆分前对整个数据集 $D$ 进行插补。这会设定 $\\hat{\\eta}=g(D)$，它依赖于所有数据折，包括验证数据，从而违反了 $\\eta$ 必须仅从 $D_{train}$ 学习的约束。这是信息泄露。\n\n- 程序 B 首先划分 $D$，然后对于每一折 $i$，仅从 $D_{train}$ 学习 k-NN 结构，即 $\\hat{\\eta}_{i}=g(D_{train}^{(i)})$，使用 $D_{train}^{(i)}$ 内部的邻居来插补 $D_{train}^{(i)}$，并通过仅在 $D_{train}^{(i)}$ 中寻找邻居来插补 $D_{test}^{(i)}$。因此，$\\tilde{D}_{train}^{(i)}=\\mathcal{I}_{\\hat{\\eta}_{i}}(D_{train}^{(i)})$ 且 $\\tilde{D}_{test}^{(i)}=\\mathcal{I}_{\\hat{\\eta}_{i}}(D_{test}^{(i)})$。来自 $D_{test}^{(i)}$ 的信息没有为 $\\hat{\\eta}_{i}$ 提供任何信息，因此没有信息泄露。这与部署场景相匹配，在该场景中，新样本是使用训练数据存储库进行插补的。\n\n- 程序 C 仅使用 $D_{train}$ 对 $D_{train}$ 进行插补，但仅使用 $D_{test}$ 对 $D_{test}$ 进行插补。这为测试变换定义了一个不同的参数 $\\hat{\\eta}_{test}^{(i)}=g(D_{test}^{(i)})$，该参数使用了来自验证数据的统计量/结构，这些信息在部署时是不可用的，并会导致乐观的评估结果。它违反了所有预处理都必须在 $D_{train}$ 上拟合的要求。\n\n- 程序 D 不是 K-折交叉验证，并且它对训练集和测试集分别进行插补，即使用 $\\hat{\\eta}_{train}=g(D_{train})$ 和 $\\hat{\\eta}_{test}=g(D_{test})$，这不当地使用了测试信息进行预处理，并且不提供 K-折估计。\n\n因此，唯一方法论上合理的带插补的交叉验证是程序 B。", "answer": "$$\\boxed{B}$$", "id": "1912459"}]}