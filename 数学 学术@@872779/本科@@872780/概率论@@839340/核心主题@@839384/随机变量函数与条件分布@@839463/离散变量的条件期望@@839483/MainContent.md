## 引言
在不确定性的世界里，我们无时无刻不在根据新出现的信息调整自己的判断和预期。例如，[气象学](@entry_id:264031)家会根据最新的卫星云图更新对未来降雨概率的预测；金融分析师会依据公司新发布的财报调整对股票价值的估算。这种基于新知识更新预测的过程，在数学上被一个强大而优美的概念所量化——[条件期望](@entry_id:159140)。它精确地回答了这样一个问题：“在已知某些事件发生或某些变量取特定值的情况下，我们对另一个未知量的最佳猜测是什么？”

尽管这个想法非常直观，但如何严格地定义它，并发展出一套系统性的计算方法，是概率论的核心任务之一。本文旨在为读者全面解析[离散随机变量](@entry_id:163471)的条件期望，弥合直觉理解与严谨应用之间的鸿沟。通过学习本文，你将不仅掌握其数学原理，更能洞察其在解决实际问题中的巨大威力。

文章将分为三个核心部分。在“**原理与机制**”一章中，我们将从基本定义出发，深入探讨[条件期望](@entry_id:159140)的各项基本性质，如线性性、对称性，并重点介绍[全期望定律](@entry_id:265946)这一连接条件期望与无条件期望的关键桥梁。随后，在“**应用与跨学科联系**”一章中，我们将展示[条件期望](@entry_id:159140)如何作为一种通用分析工具，在[贝叶斯推断](@entry_id:146958)、[随机过程](@entry_id:159502)、网络分析和组合学等多个领域中发挥作用，揭示其作为理论与实践桥梁的重要性。最后，通过“**动手实践**”部分，你将有机会通过解决具体问题来巩固所学知识，将理论真正内化为解决问题的能力。

## 原理与机制

在概率论的研究中，当我们获得关于一个[随机系统](@entry_id:187663)某个方面的部分信息时，我们往往希望更新对该系统其他方面的预测。条件期望正是实现这一目标的核心数学工具。它量化了“在已知某些事件发生或某些[随机变量](@entry_id:195330)取特定值的前提下，另一个[随机变量的期望](@entry_id:262086)值是多少”这一问题。本章将深入探讨[离散随机变量](@entry_id:163471)的[条件期望](@entry_id:159140)的原理与机制，从基本定义出发，逐步揭示其深刻的性质和广泛的应用。

### 条件期望的基本定义

从直觉上看，[条件期望](@entry_id:159140)是在一个新的、缩小的[样本空间](@entry_id:275301)中计算期望。当我们得知[随机变量](@entry_id:195330) $X$ 的取值为 $x$ 时，所有与事件 $\{X \neq x\}$ 相关联的样本点都变得不再可能。我们的注意力转移到由事件 $\{X=x\}$ 定义的[子集](@entry_id:261956)上。

对于两个[离散随机变量](@entry_id:163471) $X$ 和 $Y$，给定事件 $\{X=x\}$，$Y$ 的**条件期望** (conditional expectation) 定义为：

$$
\mathbb{E}[Y \mid X=x] = \sum_{y} y \cdot \mathbb{P}(Y=y \mid X=x)
$$

这里的 $y$ 取遍 $Y$ 所有可能的值。此定义的核心在于**[条件概率质量函数](@entry_id:268888)** (conditional probability mass function, PMF) $\mathbb{P}(Y=y \mid X=x)$，它由下式给出：

$$
\mathbb{P}(Y=y \mid X=x) = \frac{\mathbb{P}(X=x, Y=y)}{\mathbb{P}(X=x)}
$$

其中 $\mathbb{P}(X=x, Y=y)$ 是 $X$ 和 $Y$ 的[联合概率质量函数](@entry_id:184238)，且我们要求 $\mathbb{P}(X=x) > 0$。对于一个固定的 $x$，$\mathbb{E}[Y \mid X=x]$ 是一个数值。然而，我们也可以将其视为一个关于 $x$ 的函数。更进一步，我们可以定义一个新的[随机变量](@entry_id:195330)，记作 $\mathbb{E}[Y \mid X]$，它的值是当[随机变量](@entry_id:195330) $X$ 取值为 $x$ 时，等于数值 $\mathbb{E}[Y \mid X=x]$。理解 $\mathbb{E}[Y \mid X]$ 本身是一个[随机变量](@entry_id:195330)，是掌握高级概率论的关键一步。

一个典型的例子可以阐明这个定义。假设一个[分布式计算](@entry_id:264044)系统每天需要分配工作单元。设 $N$ 是一个固定的正整数，代表总可用工作单元数。一次有效的分配是一个整数对 $(x,y)$，其中 $x$ 是分配给A集群的工作单元数，$y$ 是分配给B集群的，且满足 $x \ge 0, y \ge 0, x+y \le N$。假设所有可能的有效分配 $(x,y)$ 都是等概率的。我们感兴趣的是，在已知分配给A集群的工作单元数 $X=k$ 的情况下，分配给B集群的工作单元数 $Y$ 的[期望值](@entry_id:153208)是多少？

要计算 $\mathbb{E}[Y \mid X=k]$，我们首先需要确定在 $X=k$ 的条件下 $Y$ 的可能取值以及对应的条件概率。当 $X=k$ 时，约束条件变为 $k+y \le N$，即 $y \le N-k$。由于 $y \ge 0$，所以给定 $X=k$，$Y$ 的可能取值集合为 $\{0, 1, \dots, N-k\}$。因为初始设定是所有满足条件的 $(x,y)$ 对都是等概率的，所以当我们固定 $X=k$ 时，所有满足 $0 \le y \le N-k$ 的 $(k,y)$ 对也是等概率的。这意味着在给定 $X=k$ 的条件下，$Y$ 在集合 $\{0, 1, \dots, N-k\}$ 上服从一个[离散均匀分布](@entry_id:199268)。

因此，对于任意 $y \in \{0, 1, \dots, N-k\}$，条件概率为：
$$
\mathbb{P}(Y=y \mid X=k) = \frac{1}{N-k+1}
$$
现在，我们可以计算条件期望，它就是这个[均匀分布](@entry_id:194597)的均值：
$$
\mathbb{E}[Y \mid X=k] = \sum_{y=0}^{N-k} y \cdot \mathbb{P}(Y=y \mid X=k) = \sum_{y=0}^{N-k} y \cdot \frac{1}{N-k+1} = \frac{1}{N-k+1} \frac{(N-k)(N-k+1)}{2} = \frac{N-k}{2}
$$
这个结果非常直观：当 $X=k$ 时，$X$ 和 $Y$ 的和最大为 $N$，最小为 $k$。$Y$ 的取值范围是对称的，其期望自然落在中点。[@problem_id:1350737]

### 对事件的[条件期望](@entry_id:159140)

条件作用的概念可以从 conditioning on a random variable taking a specific value（以[随机变量](@entry_id:195330)取特定值为条件）推广到 conditioning on any event（以任意事件为条件）。设 $X$ 是一个[离散随机变量](@entry_id:163471)，A是一个概率不为零的事件。$X$ 关于 $A$ 的条件期望定义为：
$$
\mathbb{E}[X \mid A] = \sum_{x} x \cdot \mathbb{P}(X=x \mid A)
$$
这本质上是在由事件 $A$ 定义的新的、缩小的[概率空间](@entry_id:201477)中计算 $X$ 的[期望值](@entry_id:153208)。

例如，假设我们从集合 $\{1, 2, \dots, 35\}$ 中等概率地随机抽取一个整数 $X$。我们想计算在“$X$ 恰好有两个不同的正因子”这一事件 $A$ 发生的条件下 $X$ 的[期望值](@entry_id:153208)。一个整数恰好有两个不同的正因子，是素数（Prime Number）的定义。因此，事件 $A$ 就是“$X$ 是一个素数”。

原始样本空间是 $\{1, 2, \dots, 35\}$，其上的[分布](@entry_id:182848)是均匀的。条件事件 $A$ 将[样本空间](@entry_id:275301)缩小为该范围内的素数集合，即 $\mathcal{P} = \{2, 3, 5, 7, 11, 13, 17, 19, 23, 29, 31\}$。由于原始[分布](@entry_id:182848)是均匀的， conditioned on $A$，$X$ 的新[分布](@entry_id:182848)在集合 $\mathcal{P}$ 上也是均匀的。集合 $\mathcal{P}$ 中有 $11$ 个元素，所以对于任意 $p \in \mathcal{P}$，$\mathbb{P}(X=p \mid A) = 1/11$。

因此，条件期望就是这些素数的[算术平均值](@entry_id:165355)：
$$
\mathbb{E}[X \mid A] = \frac{2+3+5+7+11+13+17+19+23+29+31}{11} = \frac{160}{11} \approx 14.5
$$
这个例子清晰地展示了条件作用如何通过改变底层的[样本空间](@entry_id:275301)和[概率分布](@entry_id:146404)来影响[期望值](@entry_id:153208)。[@problem_id:1350717]

### 基本性质与计算技巧

直接使用定义计算条件期望有时会非常繁琐。幸运的是，我们可以利用一些强大的性质和技巧来简化计算，包括线性性、对称性和[全期望定律](@entry_id:265946)。

#### 条件[期望的线性](@entry_id:273513)性

与普通期望一样，条件期望也满足**线性性** (linearity)。对于[随机变量](@entry_id:195330) $Y, Z$ 和常数 $a, b$，有：
$$
\mathbb{E}[aY + bZ \mid X=x] = a\mathbb{E}[Y \mid X=x] + b\mathbb{E}[Z \mid X=x]
$$
这个性质使我们能够将复杂[随机变量的期望](@entry_id:262086)分解为更简单部分[期望的线性](@entry_id:273513)组合。

考虑一个[分布式计算](@entry_id:264044)系统，有 $N$ 个独立的计算任务和 $M$ 个服务器。每个任务被随机且均匀地分配给 $M$ 个服务器之一。服务器的运营成本由加权和 $C = \sum_{i=1}^{M} i X_i$ 给出，其中 $X_i$ 是分配给服务器 $i$ 的任务数。如果我们已知服务器1上有 $k$ 个任务（即 $X_1=k$），那么总成本的期望是多少？

我们要求解 $\mathbb{E}[C \mid X_1=k]$。利用线性性，我们可以写出：
$$
\mathbb{E}[C \mid X_1=k] = \mathbb{E}\left[\sum_{i=1}^{M} i X_i \Big| X_1=k\right] = \sum_{i=1}^{M} i \mathbb{E}[X_i \mid X_1=k]
$$
这项和可以分解为两部分：$i=1$ 的项和 $i \ge 2$ 的项。
对于 $i=1$，$X_1$ 的值已经确定为 $k$，所以 $\mathbb{E}[X_1 \mid X_1=k] = k$。
对于 $i \ge 2$，我们需要确定在 $X_1=k$ 的条件下 $X_i$ 的期望。当 $k$ 个任务已经确定分配给服务器1后，剩下的 $N-k$ 个任务中的每一个仍然被独立且均匀地分配给其余的 $M-1$ 个服务器。因此，对于 $i \in \{2, \dots, M\}$，分配给服务器 $i$ 的任务数的[期望值](@entry_id:153208)为：
$$
\mathbb{E}[X_i \mid X_1=k] = \frac{N-k}{M-1}
$$
将这些结果代回，得到总成本的[条件期望](@entry_id:159140)：
$$
\mathbb{E}[C \mid X_1=k] = 1 \cdot k + \sum_{i=2}^{M} i \cdot \frac{N-k}{M-1} = k + \frac{N-k}{M-1} \sum_{i=2}^{M} i
$$
计算算术级数和 $\sum_{i=2}^{M} i = \frac{M(M+1)}{2} - 1 = \frac{(M-1)(M+2)}{2}$，我们最终得到：
$$
\mathbb{E}[C \mid X_1=k] = k + \frac{N-k}{M-1} \frac{(M-1)(M+2)}{2} = k + \frac{(N-k)(M+2)}{2}
$$
这个例子展示了线性性如何将一个复杂的[问题分解](@entry_id:272624)为几个易于处理的子问题。[@problem_id:1350742]

#### 对称性的妙用

在许多概率模型中，**对称性** (symmetry) 或**可交换性** (exchangeability) 是一个极其强大的工具。如果一组[随机变量](@entry_id:195330)在概率意义上是无法区分的，那么它们的某些性质（包括期望）也必定是相同的。

回到上面服务器分配任务的例子。假设我们只关心前两个服务器，并且我们知道这两个服务器总共分得了 $k$ 个任务，即 $X_1+X_2=k$。那么服务器1上的任务数的期望是多少？

我们可以直接计算[条件概率分布](@entry_id:163069)，但这很复杂。一个更优雅的方法是利用对称性。由于每个任务被分配到任何服务器的概率都是相同的（$1/M$），服务器1和服务器2的角色是完全对称的。因此，在只知道它们总和的条件下，我们对其中任何一个的期望应该是相同的：
$$
\mathbb{E}[X_1 \mid X_1+X_2=k] = \mathbb{E}[X_2 \mid X_1+X_2=k]
$$
现在，利用条件[期望的线性](@entry_id:273513)性，我们可以对条件本身取期望：
$$
\mathbb{E}[X_1+X_2 \mid X_1+X_2=k] = \mathbb{E}[k \mid X_1+X_2=k] = k
$$
另一方面：
$$
\mathbb{E}[X_1+X_2 \mid X_1+X_2=k] = \mathbb{E}[X_1 \mid X_1+X_2=k] + \mathbb{E}[X_2 \mid X_1+X_2=k]
$$
结合这两个方程，我们得到 $2\mathbb{E}[X_1 \mid X_1+X_2=k] = k$，所以：
$$
\mathbb{E}[X_1 \mid X_1+X_2=k] = \frac{k}{2}
$$
这个简洁的答案，不依赖于总任务数 $N$ 或总服务器数 $M$（只要 $M \ge 2$），完全是通过对称性论证得出的。这突显了在进行复杂计算之前寻找问题内在结构的重要性。[@problem_id:1350733]

#### [全期望定律](@entry_id:265946) (Law of Total Expectation)

**[全期望定律](@entry_id:265946)**（也称为**[塔性质](@entry_id:273153)**，Tower Property）是连接条件期望和无条件期望的桥梁，其表达式为：
$$
\mathbb{E}[Y] = \mathbb{E}[\mathbb{E}[Y \mid X]]
$$
这里的右边是双重期望：内层 $\mathbb{E}[Y \mid X]$ 是一个依赖于 $X$ 的[随机变量](@entry_id:195330)，外层 $\mathbb{E}[\cdot]$ 是对这个[随机变量](@entry_id:195330)求期望。其离散形式为 $\mathbb{E}[Y] = \sum_x \mathbb{E}[Y \mid X=x] \mathbb{P}(X=x)$。直观上，这表示 $Y$ 的总平均值是其在不同条件下的平均值的加权平均。

该定律不仅用于计算无[条件期望](@entry_id:159140)，还可以反过来求解条件期望。例如，从5名一年级学生和10名二年级学生中随机选出4人组成委员会。给定委员会中至少有一名一年级学生（事件 $A$），求委员会中二年级学生人数 $S$ 的[期望值](@entry_id:153208) $\mathbb{E}[S \mid A]$。

直接计算 $\mathbb{E}[S \mid A]$ 需要枚举所有满足条件的委员会构成，非常繁琐。我们可以使用[全期望定律](@entry_id:265946)。设 $A^c$ 是 $A$ 的补事件，即“委员会中没有一年级学生”（也就是全部4人都是二年级学生）。
[全期望定律](@entry_id:265946)告诉我们：
$$
\mathbb{E}[S] = \mathbb{E}[S \mid A]\mathbb{P}(A) + \mathbb{E}[S \mid A^c]\mathbb{P}(A^c)
$$
我们可以计算出这个方程中的其他项：
1.  **无条件期望 $\mathbb{E}[S]$**：$S$ 服从[超几何分布](@entry_id:193745)。其期望为样本大小乘以总体中“成功”的比例，即 $\mathbb{E}[S] = 4 \times \frac{10}{15} = \frac{8}{3}$。
2.  **事件 $A^c$ 的概率 $\mathbb{P}(A^c)$**：从10名二年级生中选4人，总选择是从15人中选4人。$\mathbb{P}(A^c) = \frac{\binom{10}{4}}{\binom{15}{4}} = \frac{210}{1365} = \frac{2}{13}$。因此 $\mathbb{P}(A) = 1 - \frac{2}{13} = \frac{11}{13}$。
3.  **在 $A^c$ 条件下的期望 $\mathbb{E}[S \mid A^c]$**：如果事件 $A^c$ 发生，则委员会全部由二年级学生组成，所以 $S$ 必然等于4。因此 $\mathbb{E}[S \mid A^c] = 4$。

现在，我们将这些值代入[全期望公式](@entry_id:267929)并求解 $\mathbb{E}[S \mid A]$：
$$
\frac{8}{3} = \mathbb{E}[S \mid A] \cdot \frac{11}{13} + 4 \cdot \frac{2}{13}
$$
$$
\mathbb{E}[S \mid A] = \left(\frac{8}{3} - \frac{8}{13}\right) \frac{13}{11} = \frac{80}{3 \cdot 13} \cdot \frac{13}{11} = \frac{80}{33} \approx 2.42
$$
这种方法巧妙地避开了直接计算的复杂性。[@problem_id:1350711]

### [条件期望](@entry_id:159140)在常见[概率模型](@entry_id:265150)中的模式

将上述原理应用于标准的概率模型，我们可以发现一些反复出现的有用模式。

#### 独立性与泊松分裂

如果两个[随机变量](@entry_id:195330) $X$ 和 $Y$ 是独立的，那么关于 $X$ 的信息不会改变我们对 $Y$ 的期望，即 $\mathbb{E}[Y \mid X=x] = \mathbb{E}[Y]$。这个简单的原则在处理复合模型时非常有用。

一个经典的例子是**泊松 thinning (或 splitting)**。假设一个天文台在某时段内探测到的粒子总数 $N$ 服从均值为 $\lambda$ 的泊松分布。每个粒子被独立地分类为A类（概率为 $p$）或B类（概率为 $1-p$）。一个著名的结果是，A类粒子的数量 $N_A$ 和B类粒子的数量 $N_B$ 都是泊松[随机变量](@entry_id:195330)，分别服从 $\text{Poisson}(\lambda p)$ 和 $\text{Poisson}(\lambda(1-p))$ [分布](@entry_id:182848)，并且 **$N_A$ 和 $N_B$ 是相互独立的**。

现在，假设我们观测到A类事件正好有 $k$ 个，我们想求观测到的粒子总数 $N$ 的[条件期望](@entry_id:159140) $\mathbb{E}[N \mid N_A=k]$。
由于 $N = N_A + N_B$，利用线性和独立性：
$$
\mathbb{E}[N \mid N_A=k] = \mathbb{E}[N_A + N_B \mid N_A=k] = \mathbb{E}[N_A \mid N_A=k] + \mathbb{E}[N_B \mid N_A=k]
$$
第一项是 $k$。对于第二项，由于 $N_B$ 和 $N_A$ 相互独立，关于 $N_A$ 的条件信息对 $N_B$ 的期望没有影响：
$$
\mathbb{E}[N_B \mid N_A=k] = \mathbb{E}[N_B] = \lambda(1-p)
$$
因此，我们得到一个简洁而有力的结果：
$$
\mathbb{E}[N \mid N_A=k] = k + \lambda(1-p)
$$
这个结果可以直观地理解为：观测到的总数等于已经看到的A类粒子数 $k$，加上在条件作用下我们期望看到的B类粒子数。[@problem_id:1350730]

#### 条件作用下的均匀性

一个有趣的现象是，有时一个看似复杂的条件事件会导致一个非常简单的[均匀分布](@entry_id:194597)。

考虑一个[数字通信](@entry_id:271926)系统，一个包含 $n$ 个比特的数据包被传输。每个比特独立地以概率 $p$ 发生翻转。如果接收端的[错误检测](@entry_id:275069)系统报告说整个数据包中**恰好**有一个比特被翻转，那么这个被翻转比特的位置的[期望值](@entry_id:153208)是多少？

令 $E_i$ 为事件“第 $i$ 个比特翻转，而其他所有比特都未翻转”。由于独立性，$\mathbb{P}(E_i) = p(1-p)^{n-1}$。事件“恰好一个比特翻转”，记为 $A$，是这些[互斥事件](@entry_id:265118) $E_i$ 的并集，即 $A = \bigcup_{i=1}^n E_i$。因此 $\mathbb{P}(A) = \sum_{i=1}^n \mathbb{P}(E_i) = n p(1-p)^{n-1}$。

我们关心的是，在给定 $A$ 发生的条件下，翻转比特的位置是 $i$ 的概率。根据条件概率的定义：
$$
\mathbb{P}(E_i \mid A) = \frac{\mathbb{P}(E_i \cap A)}{\mathbb{P}(A)} = \frac{\mathbb{P}(E_i)}{\mathbb{P}(A)} = \frac{p(1-p)^{n-1}}{n p(1-p)^{n-1}} = \frac{1}{n}
$$
这个结果表明，一旦我们知道只有一个比特翻转，那么这个翻转发生在任何一个特定位置的概率都是相同的，即 $1/n$。原始的翻转概率 $p$ 从条件分布中消失了！因此，翻转比特的位置 $I$ 在给定 $A$ 的条件下，服从 $\{1, 2, \dots, n\}$ 上的[离散均匀分布](@entry_id:199268)。其[期望值](@entry_id:153208)就是：
$$
\mathbb{E}[I \mid A] = \sum_{i=1}^n i \cdot \mathbb{P}(I=i \mid A) = \sum_{i=1}^n i \cdot \frac{1}{n} = \frac{1}{n} \frac{n(n+1)}{2} = \frac{n+1}{2}
$$
这说明，在只有一个错误的情况下，我们期望错误出现在数据包的正中间。[@problem_id:1350715]

#### [按比例分配](@entry_id:634725)

在某些模型中，当我们将一个总量在几个分量上进行分解时，[条件期望](@entry_id:159140)往往呈现出[按比例分配](@entry_id:634725)的特性。

考虑两个独立的质量控制站，它们都从生产线上检测次品。任何一个产品是次品的概率为 $p$。A站持续工作直到发现 $r_1$ 个次品，B站持续工作直到发现 $r_2$ 个次品。设 $X_1$ 和 $X_2$ 分别是A、B两站在停止前检查到的正品数量。$X_1$ 和 $X_2$ 都服从[负二项分布](@entry_id:262151)，参数分别为 $(r_1, p)$ 和 $(r_2, p)$。如果已知这两个站总共检查了 $n$ 个正品，即 $X_1+X_2=n$，那么A站检查的正品数的期望是多少？

我们寻求 $\mathbb{E}[X_1 \mid X_1+X_2=n]$。虽然可以通过计算繁琐的[条件概率质量函数](@entry_id:268888)（一个负超几何或beta-binomial[分布](@entry_id:182848)）来求解，但结果具有非常直观的形式：
$$
\mathbb{E}[X_1 \mid X_1+X_2=n] = n \frac{r_1}{r_1+r_2}
$$
这个结果说明，总共 $n$ 个“失败”（正品）是在两个过程中[按比例分配](@entry_id:634725)的，分配的比例由各自过程需要达成的“成功”（次品）数 $r_1$ 和 $r_2$ 决定。需要发现更多次品的那个过程，被期望分配了更多的正品。这个“[按比例分配](@entry_id:634725)”的原则在许多涉及泊松、伽马、二项和[负二项分布](@entry_id:262151)族的模型中都有体现。[@problem_id:1350725]

### 在[随机过程](@entry_id:159502)中的应用

[条件期望](@entry_id:159140)的概念在分析[随机过程](@entry_id:159502)（如[随机游走](@entry_id:142620)和分支过程）时至关重要。

#### [随机游走](@entry_id:142620)[路径分析](@entry_id:753256)

考虑一个从原点 $S_0=0$ 开始的简单[对称随机游走](@entry_id:273558)，每一步以等概率向上（+1）或向下（-1）移动。假设我们观察到 $n$ 步后的终点是 $S_n=n-2$。在这一条件下，游走路径达到的最大高度 $M_n = \max_{0 \le t \le n} S_t$ 的[期望值](@entry_id:153208)是多少？

首先，我们需要解码条件 $S_n=n-2$。设 $U$ 和 $D$ 分别是向上和向下的步数。我们有 $U+D=n$ (总步数) 和 $U-D=S_n=n-2$ (最终位置)。解这个[方程组](@entry_id:193238)得到 $U=n-1, D=1$。这意味着在 $n$ 步中，恰好有一步是-1，其余 $n-1$ 步都是+1。

由于每种步序的概率都是 $(1/2)^n$，在给定恰好有一次-1步的条件下，这次-1步发生在第 $t$ 步（$t \in \{1, \dots, n\}$）的概率是均匀的，即 $1/n$。

现在，我们可以描述给定-1步发生在时刻 $t$ 的路径形态。
- 对于 $k  t$，所有步都是+1，所以 $S_k=k$。
- 在 $k=t$ 时，$S_t = S_{t-1} - 1 = (t-1)-1 = t-2$。
- 对于 $k > t$，所有后续步都是+1，所以 $S_k = S_t + (k-t) = (t-2) + (k-t) = k-2$。

路径的最大值 $M_n$ 就是 $\max(\max_{0 \le k  t} S_k, \max_{t \le k \le n} S_k)$。这等于 $\max(t-1, n-2)$。
为了得到[条件期望](@entry_id:159140)，我们将这个最大值对所有可能的 $t$ 求平均：
$$
\mathbb{E}[M_n \mid S_n=n-2] = \frac{1}{n} \sum_{t=1}^{n} \max(t-1, n-2)
$$
当 $1 \le t \le n-1$ 时，$\max(t-1, n-2)=n-2$。当 $t=n$ 时，$\max(n-1, n-2)=n-1$。
所以，和式中有 $n-1$ 项等于 $n-2$，一项等于 $n-1$。
$$
\sum_{t=1}^{n} \max(t-1, n-2) = (n-1)(n-2) + (n-1) = (n-1)(n-2+1) = (n-1)^2
$$
因此，期望的最大高度为 $\frac{(n-1)^2}{n}$。[@problem_id:1350721]

#### Percolation 模型和Tail-Sum公式

条件期望在图论和物理学的[逾渗模型](@entry_id:190508)中也很有用。考虑一个由 $n$ 个顶点 $\{1, \dots, n\}$ 组成的[路径图](@entry_id:274599) $P_n$。每个顶点以概率 $p$ 独立地被激活。给定顶点1是激活的，它所属的连通分量大小的期望是多少？

设 $K$ 是顶点1所在[连通分量](@entry_id:141881)的大小。因为是在[路径图](@entry_id:274599)上，这个[连通分量](@entry_id:141881)就是从顶点1开始的一连串连续的激活顶点。$K=k$（对于 $k  n$）意味着顶点 $1, \dots, k$ 都被激活，而顶点 $k+1$ 未被激活。给定顶点1被激活，此事件的概率为 $p^{k-1}(1-p)$。$K=n$ 则意味着顶点 $1, \dots, n$ 全部激活，概率为 $p^{n-1}$。

直接用定义求和 $\sum k \mathbb{P}(K=k)$ 会有些繁琐。这里可以使用一个计算离散非负[随机变量](@entry_id:195330)期望的便捷技巧：**Tail-Sum 公式**。
$$
\mathbb{E}[K] = \sum_{k=1}^{\infty} \mathbb{P}(K \ge k)
$$
对于我们的问题，我们需要计算 $\mathbb{E}[K \mid \text{顶点1激活}]$。事件 $\{K \ge k\}$ (其中 $k \in \{1, \dots, n\}$) 发生，当且仅当顶点 $1, 2, \dots, k$ 都被激活。给定顶点1激活，这要求顶点 $2, \dots, k$ 也被激活。由于顶点激活是独立的，此[条件概率](@entry_id:151013)为 $p^{k-1}$。
$$
\mathbb{P}(K \ge k \mid \text{顶点1激活}) = p^{k-1} \quad \text{for } k=1, 2, \dots, n
$$
应用Tail-Sum公式：
$$
\mathbb{E}[K \mid \text{顶点1激活}] = \sum_{k=1}^{n} \mathbb{P}(K \ge k \mid \text{顶点1激活}) = \sum_{k=1}^{n} p^{k-1}
$$
这是一个几何级数求和，令 $j=k-1$：
$$
\sum_{j=0}^{n-1} p^j = \frac{1-p^n}{1-p}
$$
这个结果优雅地给出了在[渗流模型](@entry_id:190508)中一个初始簇的期望大小。[@problem_id:1350707]

通过本章的学习，我们看到条件期望不仅是一个抽象的数学定义，更是一套强大的分析工具，它使我们能够在不确定性中根据获得的新信息进行推理和预测，其原理和技巧在科学和工程的众多领域中都发挥着至关重要的作用。