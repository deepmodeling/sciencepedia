## 引言
在探索不确定性的[世界时](@entry_id:275204)，我们不仅关心一个[随机变量](@entry_id:195330)（如一次测量的结果）的平均值，更常常需要理解经过某个[函数变换](@entry_id:141095)后新变量的特性。例如，一项投资的最终收益是初始资本和[随机增长率](@entry_id:191650)的函数；一个物理系统的能量是其[粒子速度](@entry_id:196946)的平方的函数；一个算法的运行效率则可能与随机输入规模的多项式相关。因此，计算一个[随机变量函数的期望](@entry_id:194426)，成为了连接概率理论与现实应用的关键一步。

然而，直接求解这个问题面临一个挑战：为了计算新变量 $Y=g(X)$ 的期望，我们是否必须先费力推导出 $Y$ 复杂的[概率分布](@entry_id:146404)？幸运的是，概率论为我们提供了一套强大的工具，使我们能够绕过这一繁琐步骤，直接从[原始变量](@entry_id:753733) $X$ 的[分布](@entry_id:182848)出发进行计算。

本文将系统地引导你掌握这一核心技能。在第一章**“原理与机制”**中，我们将学习奠基性的“[无意识统计师法则](@entry_id:270744)”（LOTUS），并探索[期望的线性](@entry_id:273513)性质、[示性函数](@entry_id:261577)等核心计算技巧。随后，在第二章**“应用与跨学科联系”**中，我们将看到这些理论如何在物理、金融、工程等领域大放异彩。最后，在第三章**“动手实践”**中，你将通过解决具体问题来巩固所学知识。现在，让我们从计算[随机变量](@entry_id:195330)函数期望的基本原理开始。

## 原理与机制

在概率论的探索中，[随机变量的期望](@entry_id:262086)是我们理解其中心趋势的核心工具。然而，在实际应用中，我们常常更关心由一个或多个[随机变量](@entry_id:195330)经过某种[函数变换](@entry_id:141095)后得到的新变量的期望。例如，一个物理系统的能量可能是其[粒子速度](@entry_id:196946)的平方的函数，一项投资的[未来价值](@entry_id:141018)是初始资本和[随机增长率](@entry_id:191650)的函数，一个算法的运行时间是随机输入规模的多项式函数。本章旨在系统地阐述计算[随机变量函数的期望](@entry_id:194426)所涉及的核心原理和关键机制。我们将从一个基本定理出发，逐步探索各种强大的计算技术和重要的理论变换。

### 基本原理：[无意识统计师法则](@entry_id:270744) (LOTUS)

处理[随机变量](@entry_id:195330)函数 $Y = g(X)$ 的期望时，一个自然的想法是：首先推导出 $Y$ 的[概率分布](@entry_id:146404)（即其[概率质量函数](@entry_id:265484)PMF或[概率密度函数](@entry_id:140610)PDF），然后再根据期望的定义来计算 $E[Y]$。这个过程虽然逻辑上可行，但往往非常繁琐。幸运的是，一个被称为**[无意识统计师法则](@entry_id:270744) (Law of the Unconscious Statistician, LOTUS)** 的基本定理为我们提供了一条捷径。这个法则之所以有这样一个略带幽默的名字，是因为它允许我们“无意识地”或“机械地”计算 $E[g(X)]$，而无需首先费力去推导 $Y = g(X)$ 的[分布](@entry_id:182848)。

该法则精确地表述如下：

1.  如果 $X$ 是一个**[离散随机变量](@entry_id:163471)**，其可能取值为 $x_1, x_2, \ldots$，对应的[概率质量函数](@entry_id:265484)为 $P(X=x_i)$，那么对于任意实值函数 $g$，其期望为：
    $$
    E[g(X)] = \sum_{i} g(x_i) P(X=x_i)
    $$

2.  如果 $X$ 是一个**[连续随机变量](@entry_id:166541)**，其概率密度函数为 $f_X(x)$，那么对于任意实值函数 $g$，其期望为：
    $$
    E[g(X)] = \int_{-\infty}^{\infty} g(x) f_X(x) dx
    $$

LOTUS的本质是，我们可以直接使用原始[随机变量](@entry_id:195330) $X$ 的[概率分布](@entry_id:146404)，对函数值 $g(x)$ 进行加权平均（离散情况）或积分（连续情况），权重就是 $X$ 取相应值的概率或概率密度。这一定理极大地简化了计算，构成了本章后续所有讨论的基石。

### 应用基本原理：直接计算法

掌握了LOTUS之后，我们便可以直接应用其公式来解决问题。这种直接计算法是处理[随机变量](@entry_id:195330)函数期望最基本、最通用的方法。

我们来看一个在数字信号处理领域的例子。在设计一种新型[数字信号处理](@entry_id:263660)器时，[量化误差](@entry_id:196306)是一个关键的性能指标。假设该误差 $X$ 服从一个在区间 $[-b, b]$ 上的对称梯形[分布](@entry_id:182848)。其中心区域 $[-a, a]$ (其中 $0  a  b$) 是均匀的，而在区间的边缘则线性递减至零。其概率密度函数 (PDF) 可以写成：
$$
f(x) =
\begin{cases}
C  \text{for } |x| \le a \\
C \left( \frac{b-|x|}{b-a} \right)  \text{for } a  |x| \le b \\
0  \text{otherwise}
\end{cases}
$$
其中 $C$ 是一个[归一化常数](@entry_id:752675)。处理器的平均误差大小，即 $E[|X|]$，是一个重要的性能特征。

要计算 $E[|X|]$，我们首先需要确定常数 $C$。根据[概率密度函数](@entry_id:140610)的定义，其在整个支撑域上的积分必须为1。利用对称性，我们有：
$$
\int_{-b}^{b} f(x) dx = 2 \int_{0}^{b} f(x) dx = 1
$$
将 $f(x)$ 的分段形式代入，我们得到 $C = \frac{1}{a+b}$。

接下来，我们应用LOTUS来计算 $g(X)=|X|$ 的期望：
$$
E[|X|] = \int_{-b}^{b} |x| f(x) dx
$$
再次利用对称性，积分可以简化为：
$$
E[|X|] = 2 \int_{0}^{b} x f(x) dx = 2 \left[ \int_{0}^{a} x C dx + \int_{a}^{b} x C \left( \frac{b-x}{b-a} \right) dx \right]
$$
代入 $C = \frac{1}{a+b}$ 并完成积分计算，我们最终可以得到一个关于参数 $a$ 和 $b$ 的闭式解 [@problem_id:1915952]：
$$
E[|X|] = \frac{a^2 + ab + b^2}{3(a+b)}
$$
这个例子完整地展示了如何通过直接应用LOTUS公式，处理一个具有分段复杂PDF的连续[随机变量函数的期望](@entry_id:194426)问题。

### 关键机制一：[期望的线性](@entry_id:273513)性质

期望最强大和有用的性质之一是其**线性性质**。对于任意[随机变量](@entry_id:195330) $X$、函数 $g(X)$ 和 $h(X)$ 以及常数 $a, b, c$，我们有：
$$
E[a g(X) + b h(X) + c] = a E[g(X)] + b E[h(X)] + c
$$
这个性质意味着我们可以将一个复杂函数的期望分解为多个[简单函数](@entry_id:137521)[期望的线性](@entry_id:273513)组合。这种“分而治之”的策略往往能让计算过程更加清晰和简单。

考虑一个计算任务，其所需的计算操作数量 $C$ 是一个随机参数 $N$ 的函数，关系为 $C(N) = N^3 + 2N$。假设 $N$ 在集合 $\{1, 2, 3, 4, 5\}$ 中等可能地取值。要计算预期的操作数量 $E[C(N)]$，我们可以直接应用LOTUS公式。但利用线性性质会更优雅：
$$
E[C(N)] = E[N^3 + 2N] = E[N^3] + 2E[N]
$$
现在，问题被分解为两个独立的、更简单的子问题：计算 $E[N^3]$ 和 $E[N]$。由于 $N$ 是一个[离散均匀分布](@entry_id:199268)，我们有：
$$
E[N] = \sum_{n=1}^{5} n \cdot P(N=n) = \frac{1}{5} \sum_{n=1}^{5} n = \frac{1}{5} \frac{5(5+1)}{2} = 3
$$
以及
$$
E[N^3] = \sum_{n=1}^{5} n^3 \cdot P(N=n) = \frac{1}{5} \sum_{n=1}^{5} n^3 = \frac{1}{5} \left( \frac{5(5+1)}{2} \right)^2 = \frac{225}{5} = 45
$$
将这两个结果结合起来，我们得到预期的操作数量 [@problem_id:1915930]：
$$
E[C(N)] = 45 + 2(3) = 51
$$
通过利用线性性质，我们将一个关于三次多项式的期望问题，简化为了计算一阶矩和三阶矩的问题，展示了该性质在简化计算中的威力。

### 关键机制二：[示性函数](@entry_id:261577)的威力

**[示性函数](@entry_id:261577) (Indicator Function)** 是一个将概率和期望联系起来的简单而深刻的工具。对于任何事件 $A$，其[示性函数](@entry_id:261577) $I_A$ (有时也记为 $\mathbf{1}_A$) 定义为：
$$
I_A =
\begin{cases}
1  \text{若事件 } A \text{ 发生} \\
0  \text{若事件 } A \text{ 未发生}
\end{cases}
$$
[示性函数](@entry_id:261577)最重要的性质是它的期望等于对应事件的概率：
$$
E[I_A] = 1 \cdot P(A) + 0 \cdot P(A^c) = P(A)
$$
这个性质非常有用，因为它允许我们将关于概率的计算问题转化为关于期望的计算问题，从而可以利用[期望的线性](@entry_id:273513)性质等工具。

例如，在一个[半导体](@entry_id:141536)芯片制造过程中，每块芯片有独立的概率 $p$ 成为次品。一个质检方案是随机抽取 $n$ 块芯片。如果样本中没有次品，质检团队获得奖励，这个奖励可以用一个[随机变量](@entry_id:195330) $Y$ 来表示，$Y=1$；否则 $Y=0$。求 $Y$ 的[期望值](@entry_id:153208) $E[Y]$。
这里，$Y$ 正是“样本中没有次品”这一事件的[示性函数](@entry_id:261577)。令 $X$ 为样本中的次品数，则 $Y = I_{\{X=0\}}$。因此，计算 $E[Y]$ 就等同于计算 $P(X=0)$。由于 $X$ 服从二项分布 $B(n,p)$，我们有 [@problem_id:1915937]：
$$
E[Y] = P(X=0) = \binom{n}{0} p^0 (1-p)^{n-0} = (1-p)^n
$$

[示性函数](@entry_id:261577)的威力在处理[分段函数](@entry_id:160275)时表现得更为淋漓尽致。考虑一个电子元件，其寿命 $T$（单位：年）服从参数为1的指数分布，即其PDF为 $f(t) = \exp(-t)$（对于 $t > 0$）。一个质量控制系统根据其寿命给出一个性能分数 $S$：如果寿命 $T  \ln(2)$，则 $S=0$；如果 $T \ge \ln(2)$，则 $S=10$。
我们可以将这个计分规则表示为 $S = 10 \cdot I_{\{T \ge \ln(2)\}}$。利用[期望的线性](@entry_id:273513)性质和[示性函数](@entry_id:261577)的性质，计算 $E[S]$ 变得异常简单：
$$
E[S] = E[10 \cdot I_{\{T \ge \ln(2)\}}] = 10 \cdot E[I_{\{T \ge \ln(2)\}}] = 10 \cdot P(T \ge \ln(2))
$$
我们只需计算元件寿命超过 $\ln(2)$ 年的概率即可：
$$
P(T \ge \ln(2)) = \int_{\ln(2)}^{\infty} \exp(-t) dt = [-\exp(-t)]_{\ln(2)}^{\infty} = \exp(-\ln(2)) = \frac{1}{2}
$$
因此，预期的性能分数为 [@problem_id:1915941]：
$$
E[S] = 10 \cdot \frac{1}{2} = 5
$$
这个例子清晰地表明，通过将[分段函数](@entry_id:160275)重写为[示性函数](@entry_id:261577)的[线性组合](@entry_id:154743)，可以极大地简化期望的计算。

### 重要的变换及其期望

在概率论和统计学的各个分支中，某些特定的[函数变换](@entry_id:141095)反复出现，它们在理论和实践中都扮演着至关重要的角色。理解这些关键变换的期望是深入学习的必经之路。

#### 矩与[方差](@entry_id:200758)

[随机变量](@entry_id:195330) $X$ 的 $k$ 阶**[原点矩](@entry_id:165197)**定义为 $E[X^k]$，而 $k$ 阶**[中心矩](@entry_id:270177)**定义为 $E[(X - E[X])^k]$。其中，一阶[原点矩](@entry_id:165197) $E[X]$ 就是我们熟知的期望（均值），而[二阶中心矩](@entry_id:200758) $E[(X-E[X])^2]$ 就是[方差](@entry_id:200758) $\text{Var}(X)$。

一个深刻的统计思想是，均值是最小化[均方误差](@entry_id:175403)的预测值。考虑一个环境研究室，其内部温度 $T$ 是一个[随机变量](@entry_id:195330)。一个恒温器的能耗率与实际温度 $T$ 和设定温度 $c$ 之间差值的平方成正比，即 $P = k(T-c)^2$。为了实现长期运行效率最高，我们需要选择一个设定值 $c$ 来最小化平均能耗率 $E[P] = E[k(T-c)^2]$。

由于 $k$ 是正常数，这等价于最小化 $J(c) = E[(T-c)^2]$。我们可以通过对 $c$ 求导并令其为零来找到最优的 $c$：
$$
\frac{dJ}{dc} = \frac{d}{dc} E[(T-c)^2] = E\left[\frac{d}{dc}(T-c)^2\right] = E[-2(T-c)] = -2(E[T] - c)
$$
令 $\frac{dJ}{dc} = 0$，我们得到 $c = E[T]$。[二阶导数](@entry_id:144508) $\frac{d^2J}{dc^2} = 2 > 0$ 保证了这是一个[最小值点](@entry_id:634980)。
这个结果表明，要最小化与一个[随机变量](@entry_id:195330)的平方偏差的期望，最佳的参考点就是该[随机变量](@entry_id:195330)自身的期望（均值）。换言之，[方差](@entry_id:200758) $\text{Var}(T) = E[(T-E[T])^2]$ 是所有可能的[均方误差](@entry_id:175403)中的最小值 [@problem_id:1915963]。例如，如果温度 $T$ 在 $[0, L]$ 上服从PDF $f(t) = \frac{2t}{L^2}$，我们可以计算出其期望 $E[T] = \frac{2L}{3}$。因此，最优的恒温器[设定点](@entry_id:154422)就是 $\frac{2L}{3}$。

#### [矩生成函数 (MGF)](@entry_id:199360)

**矩生成函数 (Moment-Generating Function, MGF)** 是一个极为有用的工具，其定义为 $M_X(t) = E[\exp(tX)]$。它之所以得名，是因为通过在 $t=0$ 处对 $M_X(t)$ 求导，可以“生成” $X$ 的各阶矩。例如，$M_X'(0) = E[X]$，$M_X''(0) = E[X^2]$。

MGF 在金融和工程领域的贴现值计算中也自然出现。考虑一个深空探测器，其动力源的寿命 $T$ 服从形状参数为 $\alpha$、速[率参数](@entry_id:265473)为 $\beta$ 的伽马[分布](@entry_id:182848)。在动力源失效时（时刻 $T$），探测器发回的最终数据被认为具有1个单位的名义价值。然而，这个未来的价值需要以一个连续[贴现率](@entry_id:145874) $r$ 折算成现值，即 $V = \exp(-rT)$。

要计算该任务的预期现值 $E[V]$，我们实际上是在计算 $E[\exp(-rT)]$。这正是寿命 $T$ 的[矩生成函数](@entry_id:154347) $M_T(t)$ 在 $t = -r$ 处的值。根据定义：
$$
E[\exp(-rT)] = \int_{0}^{\infty} \exp(-rt) \frac{\beta^{\alpha}}{\Gamma(\alpha)} t^{\alpha-1} \exp(-\beta t) dt = \frac{\beta^{\alpha}}{\Gamma(\alpha)} \int_{0}^{\infty} t^{\alpha-1} \exp(-(\beta+r)t) dt
$$
我们注意到，积分部分的形式非常类似于一个形状参数为 $\alpha$、速率参数为 $(\beta+r)$ 的伽马[分布](@entry_id:182848)的PDF（只是缺少了[归一化常数](@entry_id:752675)）。利用伽马积分的性质 $\int_{0}^{\infty} x^{a-1} \exp(-bx) dx = \frac{\Gamma(a)}{b^a}$，我们得到：
$$
E[\exp(-rT)] = \frac{\beta^{\alpha}}{\Gamma(\alpha)} \frac{\Gamma(\alpha)}{(\beta+r)^{\alpha}} = \left(\frac{\beta}{\beta+r}\right)^{\alpha}
$$
这个结果不仅给出了预期的[现值](@entry_id:141163)，也揭示了MGF作为一种强大工具，在处理指数型函数期望时的核心作用 [@problem_id:1915935]。

#### [特征函数](@entry_id:186820) (CF)

与MGF密切相关的是**[特征函数](@entry_id:186820) (Characteristic Function, CF)**，定义为 $\phi_X(k) = E[\exp(ikX)]$，其中 $i = \sqrt{-1}$ 是虚数单位，$k$ 是一个实数。[特征函数](@entry_id:186820)可以看作是MGF在虚数轴上的版本，即 $\phi_X(k) = M_X(ik)$。其主要优点是对于任何[随机变量](@entry_id:195330)（无论其矩是否存在），特征函数总是存在的。在量子力学和信号处理中，它与[傅里叶变换](@entry_id:142120)紧密相连。

在一个简化的量[子模](@entry_id:148922)型中，一个被限制在一维区域的粒子的位置不确定性 $X$ 可以用 $[-L, L]$ 上的[均匀分布](@entry_id:194597)来描述。其动量性质的分析需要计算 $E[\exp(ikX)]$，其中 $k$ 是波数。这正是 $X$ 的[特征函数](@entry_id:186820)。
根据定义，对于[均匀分布](@entry_id:194597) $f_X(x) = \frac{1}{2L}$ for $x \in [-L, L]$：
$$
\phi_X(k) = E[\exp(ikX)] = \int_{-L}^{L} \exp(ikx) \frac{1}{2L} dx
$$
当 $k \neq 0$ 时，积分结果为：
$$
\frac{1}{2L} \left[ \frac{\exp(ikx)}{ik} \right]_{-L}^{L} = \frac{1}{2Lik} (\exp(ikL) - \exp(-ikL))
$$
利用欧拉公式 $\exp(i\theta) - \exp(-i\theta) = 2i\sin(\theta)$，上式可以化简为：
$$
\phi_X(k) = \frac{2i\sin(kL)}{2Lik} = \frac{\sin(kL)}{kL}
$$
这个函数通常被称为 $\text{sinc}$ 函数。对于 $k=0$ 的情况，我们可以通过取极限 $\lim_{k \to 0} \frac{\sin(kL)}{kL} = 1$ 得到，这与直接计算 $E[\exp(i \cdot 0 \cdot X)] = E[1] = 1$ 的结果一致。因此，该特征函数是一个在所有实数 $k$ 上都连续的函数 [@problem_id:1915938]。

### 高级技巧与变换

除了上述基本方法和重要变换，还有一些更专门或更抽象的技巧，它们在处理特定类型的[分布](@entry_id:182848)或理论问题时非常有效。

#### [泊松分布](@entry_id:147769)的计算技巧

[泊松分布](@entry_id:147769)在处理计数问题时非常常见。在计算其函数的期望时，有时会遇到形如 $E[g(N)]$ 的求和，其中 $g(N)$ 的形式可以与泊松PMF中的[阶乘](@entry_id:266637)项进行巧妙的结合。

例如，在[数字通信](@entry_id:271926)中，一个数据包中的比特错误数 $N$ 服从均值为 $\lambda$ 的泊松分布。一个“[质量分数](@entry_id:161575)”被定义为 $Q = \frac{1}{N+1}$。我们来计算其期望 $E[Q]$。
$$
E[Q] = E\left[\frac{1}{N+1}\right] = \sum_{n=0}^{\infty} \frac{1}{n+1} P(N=n) = \sum_{n=0}^{\infty} \frac{1}{n+1} \frac{\exp(-\lambda)\lambda^n}{n!}
$$
这里的关键技巧是注意到 $\frac{1}{n+1} \cdot \frac{1}{n!} = \frac{1}{(n+1)!}$。于是，
$$
E[Q] = \exp(-\lambda) \sum_{n=0}^{\infty} \frac{\lambda^n}{(n+1)!}
$$
为了使求和项变回标准指数级数的形式，我们做一个代换。令 $m=n+1$，则求和变为：
$$
\sum_{m=1}^{\infty} \frac{\lambda^{m-1}}{m!} = \frac{1}{\lambda} \sum_{m=1}^{\infty} \frac{\lambda^m}{m!}
$$
我们知道[指数函数](@entry_id:161417)的泰勒展开是 $\exp(\lambda) = \sum_{m=0}^{\infty} \frac{\lambda^m}{m!} = 1 + \sum_{m=1}^{\infty} \frac{\lambda^m}{m!}$。因此，$\sum_{m=1}^{\infty} \frac{\lambda^m}{m!} = \exp(\lambda) - 1$。
将此结果代回，我们得到预期的[质量分数](@entry_id:161575) [@problem_id:1915923]：
$$
E[Q] = \frac{\exp(-\lambda)}{\lambda} (\exp(\lambda) - 1) = \frac{1 - \exp(-\lambda)}{\lambda}
$$
这种利用级数展开和代数技巧的方法是处理[泊松分布](@entry_id:147769)期望问题时一个经典且强大的策略。

#### [变量替换](@entry_id:141386)与[概率积分变换](@entry_id:262799) (PIT)

**[概率积分变换](@entry_id:262799) (Probability Integral Transform, PIT)** 是概率论中一个令人惊奇的普适性结果。它指出，如果一个[连续随机变量](@entry_id:166541) $X$ 的[累积分布函数 (CDF)](@entry_id:264700) $F_X(x)$ 是连续且严格递增的，那么由它变换得到的新[随机变量](@entry_id:195330) $U = F_X(X)$ 将服从 $(0, 1)$ 上的[均匀分布](@entry_id:194597)。

这个变换的威力在于，无论原始[随机变量](@entry_id:195330) $X$ 的[分布](@entry_id:182848)多么复杂，我们总能将其转化为一个标准的[均匀分布](@entry_id:194597)[随机变量](@entry_id:195330)。这为计算某些看似棘手的期望问题提供了全新的视角。

考虑一个由任意满足条件的[连续随机变量](@entry_id:166541) $X$ 生成的新变量 $Y = -\ln(1 - F_X(X))$。我们来求它的期望 $E[Y]$。
根据PIT，我们知道 $U = F_X(X)$ 服从 $U(0,1)$ [分布](@entry_id:182848)。因此，原问题等价于计算 $E[-\ln(1-U)]$，其中 $U \sim U(0,1)$。
我们可以通过LOTUS直接计算这个期望：
$$
E[Y] = \int_0^1 -\ln(1-u) \cdot 1 \, du
$$
但一个更有启发性的方法是找出 $Y$ 的[分布](@entry_id:182848)。令 $y \ge 0$，我们计算 $Y$ 的CDF：
$$
F_Y(y) = P(Y \le y) = P(-\ln(1-U) \le y) = P(\ln(1-U) \ge -y)
$$
由于[指数函数](@entry_id:161417)是单调递增的，我们有：
$$
P(1-U \ge \exp(-y)) = P(U \le 1 - \exp(-y))
$$
因为 $U$ 是一个标准的[均匀随机变量](@entry_id:202778)，其CDF为 $F_U(u) = u$ for $u \in [0,1]$。所以，
$$
F_Y(y) = 1 - \exp(-y)
$$
这个CDF正是速[率参数](@entry_id:265473) $\lambda = 1$ 的指数分布的CDF。我们知道，这样一个指数分布的期望是 $\frac{1}{\lambda} = 1$。
因此，我们得出了一个非常漂亮的结论：无论原始[随机变量](@entry_id:195330) $X$ 的具体[分布](@entry_id:182848)是什么（只要其CDF连续且严格递增），$E[-\ln(1-F_X(X))]$ 的值恒为1 [@problem_id:1361046]。这完美地展示了PIT在理论分析中的强大力量。

#### [多变量函数](@entry_id:145643)

LOTUS同样可以推广到多个[随机变量的函数](@entry_id:271583)。例如，对于两个[随机变量](@entry_id:195330) $T_1$ 和 $T_2$，其联合PMF为 $P(T_1=t_1, T_2=t_2)$，函数 $g(T_1, T_2)$ 的期望为：
$$
E[g(T_1, T_2)] = \sum_{t_1} \sum_{t_2} g(t_1, t_2) P(T_1=t_1, T_2=t_2)
$$
连续情况下的公式是类似的双重积分。

考虑一个双核处理器，两个核心完成任务的时间 $T_1$ 和 $T_2$ 是[相互独立](@entry_id:273670)且均在 $\{1, 2, 3, 4\}$ 上[均匀分布](@entry_id:194597)的[随机变量](@entry_id:195330)。系统的总完成时间 $T_{sys}$ 是两个核心中较慢的那个，即 $T_{sys} = \max(T_1, T_2)$。
要计算 $E[T_{sys}]$，一种方法是首先推导出 $T_{sys}$ 的PMF。我们可以通过其CDF来做到这一点：
$$
P(T_{sys} \le k) = P(\max(T_1, T_2) \le k) = P(T_1 \le k, T_2 \le k)
$$
由于独立性，这等于 $P(T_1 \le k) P(T_2 \le k) = (\frac{k}{4})^2$。然后通过 $P(T_{sys}=k) = P(T_{sys} \le k) - P(T_{sys} \le k-1)$ 得到PMF，最后计算期望。这种方法得到的结果是 $\frac{25}{8}$ [@problem_id:1915932]。

或者，我们也可以直接应用为[多变量函数](@entry_id:145643)定制的LOTUS：
$$
E[\max(T_1, T_2)] = \sum_{i=1}^4 \sum_{j=1}^4 \max(i, j) P(T_1=i, T_2=j)
$$
由于[独立同分布](@entry_id:169067)， $P(T_1=i, T_2=j) = \frac{1}{4} \cdot \frac{1}{4} = \frac{1}{16}$。我们只需计算 $16$ 种组合的 $\max(i,j)$ 值的加权平均即可。虽然计算量可能稍大，但这种方法在概念上更直接地体现了LOTUS的精神。

本章通过一系列原理和机制的阐述，从基本的LOTUS法则到各种高级技巧，系统地展示了如何计算[随机变量函数的期望](@entry_id:194426)。掌握这些方法不仅是解决概率问题的关键，也是理解更高级[统计推断](@entry_id:172747)、[随机过程](@entry_id:159502)和[机器学习理论](@entry_id:263803)的基础。