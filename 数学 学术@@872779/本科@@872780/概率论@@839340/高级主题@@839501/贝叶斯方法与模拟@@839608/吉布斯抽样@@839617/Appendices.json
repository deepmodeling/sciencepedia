{"hands_on_practices": [{"introduction": "掌握吉布斯抽样的第一步是理解其核心迭代机制。这个练习将引导你手动执行一轮完整的吉布斯抽样，通过从给定的满条件分布中抽取样本，具体展示算法如何从一个状态转移到下一个状态。通过这个基础实践[@problem_id:1920320]，你将对抽样器的工作流程建立起直观的认识。", "problem": "考虑一个二维随机向量 $(X, Y)$，其联合概率分布由以下完全条件分布定义：\n- $X$ 在给定 $Y=y$ 时的条件分布是率参数为 $y$ 的指数分布。其概率密度函数为 $p(x|y) = y \\exp(-yx)$，其中 $x > 0$。\n- $Y$ 在给定 $X=x$ 时的条件分布是均值参数为 $x$ 的泊松分布。其概率质量函数为 $p(y=k|x) = \\frac{x^k \\exp(-x)}{k!}$，其中 $k \\in \\{0, 1, 2, \\dots\\}$。\n\n您的任务是执行一次完整的吉布斯采样器迭代。从初始状态 $(x^{(0)}, y^{(0)}) = (2, 3)$ 开始，您将生成一个新状态 $(x^{(1)}, y^{(1)})$。迭代的步骤如下：首先，从分布 $p(x|y^{(0)})$ 中抽取样本 $x^{(1)}$，然后，使用这个新值 $x^{(1)}$，从分布 $p(y|x^{(1)})$ 中抽取样本 $y^{(1)}$。\n\n为了生成所需的随机变量，您必须使用逆变换采样法。请使用以下从均匀(0,1)分布中抽取的随机数：\n- 生成 $x^{(1)}$ 时，使用均匀随机数 $u_x = 0.600$。\n- 生成 $y^{(1)}$ 时，使用均匀随机数 $u_y = 0.750$。\n\n新状态 $(x^{(1)}, y^{(1)})$ 的数值是多少？$x^{(1)}$ 的值必须四舍五入到四位有效数字。", "solution": "我们使用逆变换采样法执行一次吉布斯更新。\n\n1) 从 $p(x \\mid y^{(0)}=3)$ 中采样 $x^{(1)}$。\n对于一个率为 $y$ 的指数分布，其条件累积分布函数 (CDF) 为\n$$\nF(x \\mid y)=1-\\exp(-yx), \\quad x>0.\n$$\n逆变换采样法使用 $u_{x}=F(x \\mid y)$，因此\n$$\nx^{(1)}=F^{-1}(u_{x})=-\\frac{1}{y^{(0)}}\\ln\\!\\bigl(1-u_{x}\\bigr).\n$$\n当 $y^{(0)}=3$ 且 $u_{x}=0.600$ 时，\n$$\nx^{(1)}=-\\frac{1}{3}\\ln(1-0.600)=-\\frac{1}{3}\\ln(0.4)=\\frac{1}{3}\\ln(2.5)\\approx 0.3054302439.\n$$\n四舍五入到四位有效数字：$x^{(1)}=0.3054$。\n\n2) 使用 $u_{y}=0.750$ 从 $p(y \\mid x^{(1)})$ 中采样 $y^{(1)}$。\n对于一个均值为 $x$ 的泊松分布，其概率质量函数 (pmf) 为\n$$\np(y=k \\mid x)=\\frac{x^{k}\\exp(-x)}{k!}, \\quad k\\in\\{0,1,2,\\dots\\}.\n$$\n对于离散分布，逆变换采样法选择满足 $F(k \\mid x)=\\sum_{j=0}^{k}p(j \\mid x)\\ge u_{y}$ 的最小整数 $k$。\n\n当 $x=x^{(1)}=\\frac{1}{3}\\ln(2.5)$ 时，计算\n$$\np(0 \\mid x)=\\exp(-x)=\\exp\\!\\Bigl(-\\tfrac{1}{3}\\ln(2.5)\\Bigr)=2.5^{-1/3}\\approx 0.7368.\n$$\n由于 $p(0 \\mid x) = 0.7368  0.750$，我们继续计算 $k=1$ 的情况：\n$$\np(1 \\mid x)=x\\exp(-x)=x\\,2.5^{-1/3}\\approx 0.30543\\times 0.7368\\approx 0.2250.\n$$\n然后\n$$\nF(1 \\mid x)=p(0 \\mid x)+p(1 \\mid x)\\approx 0.7368+0.2250=0.96180.750,\n$$\n所以，满足 $F(k \\mid x)\\ge 0.750$ 的最小 $k$ 是 $k=1$。因此 $y^{(1)}=1$。\n\n因此，新状态为 $(x^{(1)},y^{(1)})=(0.3054,1)$，其中 $x^{(1)}$ 已四舍五入到四位有效数字。", "answer": "$$\\boxed{\\begin{pmatrix}0.3054  1\\end{pmatrix}}$$", "id": "1920320"}, {"introduction": "吉布斯抽样器的效率并非总是很高，尤其是在变量高度相关时。这个练习通过一个经典的二元正态分布案例[@problem_id:1363745]，揭示了强相关性如何导致抽样器“混合缓慢”（slow mixing），使其在探索目标分布时步履维艰。理解这种现象对于在实际应用中诊断和解决抽样性能问题至关重要。", "problem": "在一个用于光学元件的高精度制造过程中，透镜的两个几何参数 $x_1$ 和 $x_2$ 对其性能至关重要。这些参数表示与理想设计规格的归一化偏差。由于制造过程的物理原理，这些参数不是独立的。对生产数据的分析表明，它们的联合概率分布可以用一个未归一化的密度函数 $f(x_1, x_2)$ 来建模，其形式如下：\n$$f(x_1, x_2) \\propto \\exp \\left( -\\frac{1}{2(1-\\rho^2)} (x_1^2 - 2\\rho x_1 x_2 + x_2^2) \\right)$$\n对于这个特定的过程，发现相关系数为 $\\rho = 0.99$。该分布的众数位于 $(0, 0)$，这对应于一个完美的元件。\n\n为了模拟过程中的变异，要求您使用吉布斯采样器 (Gibbs sampler)。您从初始状态 $(x_1^{(0)}, x_2^{(0)}) = (-4.0, -4.1)$ 开始，该状态代表一个处于可接受质量范围边缘的元件。\n\n您的任务是确定采样器在两次完整迭代后的状态 $(x_1^{(2)}, x_2^{(2)})$。一次完整的迭代包括先更新 $x_1$，然后更新 $x_2$。为了使计算具有确定性，您必须假设在每个采样步骤中，为变量抽取的新值等于其条件分布的均值。\n\n计算状态 $(x_1^{(2)}, x_2^{(2)})$ 的坐标。在您的最终答案中报告这两个坐标，四舍五入到四位有效数字。", "solution": "我们识别出给定的未归一化联合密度\n$$\nf(x_{1},x_{2}) \\propto \\exp\\left(-\\frac{1}{2(1-\\rho^{2})}\\left(x_{1}^{2}-2\\rho x_{1}x_{2}+x_{2}^{2}\\right)\\right)\n$$\n是一个均值向量为 $(0,0)$、单位方差、相关系数为 $\\rho$ 的二元正态分布的核。为了推导完整的条件分布，对 $x_{1}$ 进行配方：\n$$\nx_{1}^{2}-2\\rho x_{1}x_{2}+x_{2}^{2}=(x_{1}-\\rho x_{2})^{2}+(1-\\rho^{2})x_{2}^{2}.\n$$\n因此，在以 $x_{2}$ 为条件时，\n$$\nf(x_{1}\\mid x_{2}) \\propto \\exp\\left(-\\frac{1}{2(1-\\rho^{2})}(x_{1}-\\rho x_{2})^{2}\\right),\n$$\n这是一个正态分布的核，其分布为\n$$\nx_{1}\\mid x_{2} \\sim \\mathcal{N}\\!\\left(\\rho x_{2},\\,1-\\rho^{2}\\right).\n$$\n根据对称性，我们也有\n$$\nx_{2}\\mid x_{1} \\sim \\mathcal{N}\\!\\left(\\rho x_{1},\\,1-\\rho^{2}\\right).\n$$\n\n吉布斯采样器首先使用 $x_{2}$ 更新 $x_{1}$，然后使用新的 $x_{1}$ 更新 $x_{2}$。在每次抽样等于条件均值的确定性规则下，更新公式为\n$$\nx_{1}^{(t+1)}=\\rho\\,x_{2}^{(t)},\\qquad x_{2}^{(t+1)}=\\rho\\,x_{1}^{(t+1)}.\n$$\n结合这些，\n$$\nx_{2}^{(t+1)}=\\rho^{2}\\,x_{2}^{(t)},\\qquad x_{1}^{(t+1)}=\\rho\\,x_{2}^{(t)}.\n$$\n从 $(x_{1}^{(0)},x_{2}^{(0)})=(-4.0,-4.1)$ 开始，并使用 $\\rho=0.99$，第一次完整迭代产生\n$$\nx_{1}^{(1)}=\\rho\\,x_{2}^{(0)}=0.99\\times(-4.1)=-4.059,\\qquad\nx_{2}^{(1)}=\\rho\\,x_{1}^{(1)}=0.99\\times(-4.059)=-4.01841.\n$$\n然后，第二次完整迭代给出\n$$\nx_{1}^{(2)}=\\rho\\,x_{2}^{(1)}=0.99\\times(-4.01841)=-3.9782259,\\qquad\nx_{2}^{(2)}=\\rho\\,x_{1}^{(2)}=0.99\\times(-3.9782259)=-3.938443641.\n$$\n将每个坐标四舍五入到四位有效数字：\n$$\nx_{1}^{(2)}\\approx -3.978,\\qquad x_{2}^{(2)}\\approx -3.938.\n$$", "answer": "$$\\boxed{\\begin{pmatrix}-3.978  -3.938\\end{pmatrix}}$$", "id": "1363745"}, {"introduction": "在掌握了基本原理和潜在挑战后，让我们来看一个吉布斯抽样在真实世界中的复杂应用。这个练习将指导你为一个经济学中的马尔可夫转换模型构建一个吉布斯抽样器，以推断经济增长中的扩张和衰退期。通过这个综合性实践[@problem_id:2398229]，你将体会到吉布斯抽样在解决前沿研究问题中的强大能力。", "problem": "给定一个用于季度实际国内生产总值（GDP）增长率的双状态马尔可夫转换模型，该模型旨在捕捉扩张和衰退两种机制。在时间 $t$ 的隐藏状态，记为 $s_t \\in \\{0,1\\}$，遵循一个时齐一阶马尔可夫链。以该状态为条件，观测到的增长率 $y_t$ 服从高斯分布，其均值依赖于所处机制，方差为公共已知值。完整的模型设定如下：\n- 状态动态：$s_{t} \\mid s_{t-1} \\sim \\text{Categorical}\\left(P_{s_{t-1},\\cdot}\\right)$，转移矩阵为 $P = \\begin{pmatrix} p_{00}  1-p_{00} \\\\ 1-p_{11}  p_{11} \\end{pmatrix}$，其中 $p_{00} = \\mathbb{P}(s_t = 0 \\mid s_{t-1} = 0)$，$p_{11} = \\mathbb{P}(s_t = 1 \\mid s_{t-1} = 1)$。\n- 观测模型：$y_t \\mid s_t = k \\sim \\mathcal{N}(\\mu_k, \\sigma^2)$，对于 $k \\in \\{0,1\\}$ 和已知方差 $\\sigma^2$。\n- 先验：$\\mu_0 \\sim \\mathcal{N}(m_0, V_0)$，$\\mu_1 \\sim \\mathcal{N}(m_1, V_1)$，$p_{00} \\sim \\text{Beta}(a_{00}, b_{00})$，$p_{11} \\sim \\text{Beta}(a_{11}, b_{11})$。初始状态 $s_1$ 具有固定的先验概率 $\\mathbb{P}(s_1=0) = \\mathbb{P}(s_1=1) = 0.5$。\n\n您的任务是实现一个吉布斯采样器，它交替地进行以下采样：使用前向滤波-后向采样方法对隐藏状态序列 $\\{s_t\\}_{t=1}^T$ 进行采样，使用其共轭高斯后验分布对机制均值 $\\mu_0$ 和 $\\mu_1$ 进行采样，以及使用其共轭贝塔后验分布对转移概率 $p_{00}$ 和 $p_{11}$ 进行采样。请使用以下经过充分检验的事实和定义作为基本依据：\n- 用于条件概率的贝叶斯法则以及高斯分布和贝塔分布的标准性质。\n- 一阶马尔可夫链的定义以及具有高斯观测的隐马尔可夫模型（HMM）结构。\n- 用于在HMM中采样隐藏状态的前向滤波-后向采样恒等式。\n\n对于下方的每个测试用例，使用固定的随机种子、固定的迭代次数和指定的老化期（burn-in）运行吉布斯采样器。在老化期过后，通过老化期后抽样的蒙特卡洛频率，估计每个时间点的衰退边缘后验概率 $\\hat{\\pi}_t = \\mathbb{P}(s_t = 1 \\mid y_{1:T})$。如果 $\\hat{\\pi}_t \\geq 0.5$，则将时间点 $t$ 分类为衰退。对于每个测试用例，输出被分类为衰退的时间索引的整数总数。\n\n所有GDP增长值 $y_t$ 均以每季度的十进制小数形式给出（例如，$0.008$ 表示十进制的 $0.8$，而不是百分比）。最终答案中无需报告物理单位，因为要求的输出是计数。此问题不涉及角度。\n\n测试套件参数集：\n\n- 用例 A（机制分离清晰，中等持续性）：\n  - 观测值 $y_{1:20} = \\left(0.010, 0.008, 0.009, 0.007, 0.006, 0.007, -0.004, -0.006, -0.005, -0.007, -0.006, -0.004, 0.005, 0.006, 0.008, 0.009, 0.007, 0.006, 0.005, 0.007\\right)$。\n  - 已知方差 $\\sigma^2 = 0.000025$。\n  - 先验：$(m_0, V_0) = (0.007, 0.0001)$，$(m_1, V_1) = (-0.006, 0.0001)$，$(a_{00}, b_{00}) = (8, 2)$，$(a_{11}, b_{11}) = (8, 2)$。\n  - 吉布斯采样器设置：迭代次数 $N = 6000$，老化期 $B = 3000$，种子 $= 12345$。\n\n- 用例 B（单观测值边界情况，对称先验）：\n  - 观测值 $y_{1:1} = \\left(0.000\\right)$。\n  - 已知方差 $\\sigma^2 = 0.000025$。\n  - 先验：$(m_0, V_0) = (0.004, 0.0001)$，$(m_1, V_1) = (-0.004, 0.0001)$，$(a_{00}, b_{00}) = (5, 5)$，$(a_{11}, b_{11}) = (5, 5)$。\n  - 吉布斯采样器设置：迭代次数 $N = 6000$，老化期 $B = 3000$，种子 $= 12345$。\n\n- 用例 C（机制模糊，较低持续性先验）：\n  - 观测值 $y_{1:12} = \\left(0.003, 0.004, 0.002, -0.001, 0.000, -0.002, -0.003, 0.001, 0.002, 0.003, -0.002, -0.001\\right)$。\n  - 已知方差 $\\sigma^2 = 0.000025$。\n  - 先验：$(m_0, V_0) = (0.002, 0.0002)$，$(m_1, V_1) = (-0.002, 0.0002)$，$(a_{00}, b_{00}) = (2, 2)$，$(a_{11}, b_{11}) = (2, 2)$。\n  - 吉布斯采样器设置：迭代次数 $N = 6000$，老化期 $B = 3000$，种子 $= 12345$。\n\n实现您的程序以：\n- 对每个用例，使用指定的参数运行上述吉布斯采样器。\n- 老化期后，计算 $\\hat{\\pi}_t$ 作为样本中 $s_t = 1$ 的蒙特卡洛频率。\n- 统计满足 $\\hat{\\pi}_t \\geq 0.5$ 的索引 $t$ 的数量。\n- 将三个用例对应的三个整数计数汇总到一个列表中。\n\n最终输出格式：\n您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表，例如 $[x_A,x_B,x_C]$，其中 $x_A$、$x_B$ 和 $x_C$ 分别是用例A、用例B和用例C的整数计数。", "solution": "该问题要求为实际GDP增长率的双状态马尔可夫转换模型实现一个吉布斯采样器。模型参数，包括特定机制的均值和状态转移概率，将在贝叶斯框架内从观测数据中进行估计。最终目标是根据后验概率将每个时间点分类为处于“衰退”状态（$s_t = 1$），并对三个不同的测试用例统计此类时期的总数。\n\n该问题在科学上是适定的，提供了模型、先验、数据和所需算法的完整规范。它代表了马尔可夫链蒙特卡洛（MCMC）方法，特别是吉布斯采样，在隐马尔可夫模型（HMM）上的标准应用，这是计算计量经济学中的一个常见任务。所有参数都已指定，任务明确。因此，该问题被认为是有效的，并将构建一个解决方案。\n\n解决方案的核心在于从未知的变量（隐藏状态序列 $\\{s_t\\}_{t=1}^T$、机制均值 $\\mu_0$ 和 $\\mu_1$ 以及转移概率 $p_{00}$ 和 $p_{11}$）的完整条件后验分布中迭代采样。此过程构成一个吉布斯采样器。\n\n设所有参数的集合为 $\\theta = \\{\\mu_0, \\mu_1, p_{00}, p_{11}\\}$，状态序列为 $S = \\{s_t\\}_{t=1}^T$。吉布斯采样器通过初始化参数，然后迭代以下步骤来进行：\n1. 采样 $S^{(i+1)} \\sim p(S \\mid y_{1:T}, \\theta^{(i)})$。\n2. 采样 $\\mu_0^{(i+1)}, \\mu_1^{(i+1)} \\sim p(\\mu_0, \\mu_1 \\mid y_{1:T}, S^{(i+1)}, \\sigma^2)$。\n3. 采样 $p_{00}^{(i+1)}, p_{11}^{(i+1)} \\sim p(p_{00}, p_{11} \\mid S^{(i+1)})$。\n\n每个步骤详述如下。\n\n**1. 采样状态序列 $S = \\{s_t\\}_{t=1}^T$**\n\n使用前向滤波-后向采样（FFBS）算法从其条件后验分布 $p(S \\mid y_{1:T}, \\theta)$ 中对状态序列进行采样。\n\n_前向滤波_：\n我们首先计算滤波概率 $\\alpha_t(k) = p(s_t = k, y_{1:t} \\mid \\theta)$，其中 $k \\in \\{0, 1\\}$ 且 $t=1, \\dots, T$。\n- **初始化 ($t=1$)**: 初始状态先验给定为 $\\mathbb{P}(s_1=k) = 0.5$。滤波步骤从以下开始：\n  $$\n  \\alpha_1(k) = \\mathbb{P}(s_1=k) \\cdot p(y_1 \\mid s_1=k, \\theta) = 0.5 \\cdot \\mathcal{N}(y_1; \\mu_k, \\sigma^2)\n  $$\n  其中 $\\mathcal{N}(y; \\mu, \\sigma^2)$ 是正态分布的概率密度函数。\n- **递归 ($t=2, \\dots, T$)**: 对于后续的时间步，使用马尔可夫性质更新滤波概率：\n  $$\n  \\alpha_t(k) = p(y_t \\mid s_t=k, \\theta) \\sum_{j=0}^{1} p(s_t=k \\mid s_{t-1}=j, \\theta) \\cdot \\alpha_{t-1}(j)\n  $$\n  $$\n  \\alpha_t(k) = \\mathcal{N}(y_t; \\mu_k, \\sigma^2) \\sum_{j=0}^{1} P_{jk} \\cdot \\alpha_{t-1}(j)\n  $$\n  其中 $P_{jk}$ 是从状态 $j$ 到状态 $k$ 的转移概率。为防止数值下溢，向量 $\\alpha_t = (\\alpha_t(0), \\alpha_t(1))$ 通常在每一步都进行归一化。令 $\\hat{\\alpha}_t(k) = p(s_t=k \\mid y_{1:t}, \\theta) \\propto \\alpha_t(k)$。这种归一化不影响后向采样步骤。\n\n_后向采样_：\n在计算出直到 $T$ 的滤波概率后，我们按逆时间顺序对状态进行采样。\n- **初始化 ($t=T$)**: 从最终的滤波分布中采样 $s_T$：\n  $$\n  p(s_T=k \\mid y_{1:T}, \\theta) \\propto \\alpha_T(k)\n  $$\n- **递归 ($t=T-1, \\dots, 1$)**: 对于每个之前的时间步，以后续已采样的状态 $s_{t+1}$ 和滤波概率为条件对 $s_t$ 进行采样：\n  $$\n  p(s_t=j \\mid s_{t+1}=k, y_{1:T}, \\theta) \\propto p(s_{t+1}=k \\mid s_t=j) \\cdot p(s_t=j, y_{1:t}) \\propto P_{jk} \\cdot \\alpha_t(j)\n  $$\n  这给出了一个分类分布，从中抽取 $s_t$。\n\n**2. 采样机制均值 $\\mu_k$**\n\n均值 $\\mu_0$ 和 $\\mu_1$ 在以状态序列 $S$ 为条件下进行独立采样。在共轭先验设置（正态先验，正态似然）下，每个 $\\mu_k$ 的后验分布也是正态的。\n设 $S$ 是采样的状态序列。设 $Y_k = \\{y_t \\mid s_t = k\\}$ 是在状态 $k$ 中发生的观测子集，并设 $T_k = |Y_k|$ 为此类观测的数量。$\\mu_k$ 的先验为 $\\mathcal{N}(m_k, V_k)$。\n$\\mu_k$ 的后验分布为 $p(\\mu_k \\mid S, y_{1:T}) \\sim \\mathcal{N}(\\mu_{k, post}, V_{k, post})$，其中后验方差 $V_{k, \\text{post}}$ 和均值 $\\mu_{k, \\text{post}}$ 由以下公式给出：\n$$\nV_{k, \\text{post}} = \\left( \\frac{1}{V_k} + \\frac{T_k}{\\sigma^2} \\right)^{-1}\n$$\n$$\n\\mu_{k, \\text{post}} = V_{k, \\text{post}} \\left( \\frac{m_k}{V_k} + \\frac{1}{\\sigma^2} \\sum_{y_t \\in Y_k} y_t \\right)\n$$\n如果在某次迭代中没有访问到状态 $k$（即 $T_k = 0$），则 $\\mu_k$ 的后验分布等于其先验分布 $\\mathcal{N}(m_k, V_k)$。我们从此后验分布中为 $\\mu_k$ 抽取一个新样本。\n\n**3. 采样转移概率 $p_{kk}$**\n\n转移概率 $p_{00}$ 和 $p_{11}$ 在以状态序列 $S$ 为条件下进行独立采样。先验是贝塔分布，它与状态转移的二项（或伯努利）似然共轭。\n设 $N_{jk} = \\sum_{t=2}^T \\mathbb{I}(s_{t-1}=j, s_t=k)$ 为在采样的序列 $S$ 中观测到的从状态 $j$ 到状态 $k$ 的转移次数。\n- $p_{00}$ 的先验是 $\\text{Beta}(a_{00}, b_{00})$。数据提供了 $N_{00}$ 次从状态 0 到 0 的转移和 $N_{01}$ 次从状态 0 到 1 的转移。$p_{00}$ 的后验分布为：\n  $$\n  p(p_{00} \\mid S) \\sim \\text{Beta}(a_{00} + N_{00}, b_{00} + N_{01})\n  $$\n- 类似地，$p_{11}$ 的后验分布为：\n  $$\n  p(p_{11} \\mid S) \\sim \\text{Beta}(a_{11} + N_{11}, b_{11} + N_{10})\n  $$\n我们从这些后验贝塔分布中为 $p_{00}$ 和 $p_{11}$ 抽取新样本。如果 $T=1$，则没有转移，后验分布与先验分布相同。\n\n**4. 估计和分类**\n\n在运行吉布斯采样器 $N$ 次迭代并丢弃前 $B$ 次作为老化期后，我们得到 $N-B$ 个来自联合后验分布的样本。在时间 $t$ 处于衰退状态（$s_t = 1$）的边缘后验概率，是通过对老化期后的状态序列样本 $\\{S^{(i)}\\}_{i=B+1}^N$ 进行蒙特卡洛平均来估计的：\n$$\n\\hat{\\pi}_t = \\mathbb{P}(s_t = 1 \\mid y_{1:T}) \\approx \\frac{1}{N-B} \\sum_{i=B+1}^{N} \\mathbb{I}(s_t^{(i)}=1)\n$$\n如果这个估计概率大于或等于 $0.5$，则时间点 $t$ 被分类为衰退。每个测试用例的最终结果是被分类为衰退的时间索引的总数。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.stats import norm\n\n# No other libraries outside the Python standard library are permitted.\n\ndef run_gibbs_sampler(y, sigma_sq, priors, settings):\n    \"\"\"\n    Runs a Gibbs sampler for the specified Markov-switching model.\n    \"\"\"\n    T = len(y)\n    m0, V0 = priors['mu0']\n    m1, V1 = priors['mu1']\n    a00, b00 = priors['p00']\n    a11, b11 = priors['p11']\n    \n    num_iter = settings['N']\n    burn_in = settings['B']\n    seed = settings['seed']\n    \n    rng = np.random.default_rng(seed)\n\n    # 1. Initialize parameters by drawing from priors\n    mu0 = rng.normal(m0, np.sqrt(V0))\n    mu1 = rng.normal(m1, np.sqrt(V1))\n    p00 = rng.beta(a00, b00)\n    p11 = rng.beta(a11, b11)\n    \n    # Storage for post-burn-in state samples\n    num_samples_to_store = num_iter - burn_in\n    if num_samples_to_store = 0:\n        raise ValueError(\"Number of iterations must be greater than burn-in.\")\n    state_samples = np.zeros((num_samples_to_store, T), dtype=np.int8)\n    \n    # 2. Gibbs sampling iterations\n    for i in range(num_iter):\n        mus = np.array([mu0, mu1])\n        P = np.array([[p00, 1.0 - p00], [1.0 - p11, p11]])\n\n        # a. Sample states S = {s_t} using Forward-Filtering Backward-Sampling (FFBS)\n        \n        # Forward filtering\n        alpha_hat = np.zeros((T, 2))\n        \n        # t=1\n        likelihood_1 = norm.pdf(y[0], loc=mus, scale=np.sqrt(sigma_sq))\n        # Initial state prob = 0.5 for both states\n        alpha_hat[0, :] = 0.5 * likelihood_1\n        sum_alpha = np.sum(alpha_hat[0, :])\n        if sum_alpha > 0:\n            alpha_hat[0, :] /= sum_alpha\n\n        # t > 1\n        for t in range(1, T):\n            likelihood_t = norm.pdf(y[t], loc=mus, scale=np.sqrt(sigma_sq))\n            alpha_hat[t, :] = likelihood_t * (alpha_hat[t-1, :] @ P)\n            sum_alpha = np.sum(alpha_hat[t, :])\n            if sum_alpha > 0:\n                alpha_hat[t, :] /= sum_alpha\n        \n        # Backward sampling\n        states = np.zeros(T, dtype=np.int8)\n        \n        # t=T\n        p_sT = alpha_hat[T-1, :]\n        states[T-1] = rng.choice([0, 1], p=p_sT)\n\n        # t  T\n        for t in range(T-2, -1, -1):\n            s_next = states[t+1]\n            p_st = alpha_hat[t, :] * P[:, s_next]\n            sum_p = np.sum(p_st)\n            if sum_p > 0:\n                 p_st /= sum_p\n            else: # Fallback if probabilities are zero\n                p_st = np.array([0.5, 0.5])\n            states[t] = rng.choice([0, 1], p=p_st)\n\n        # b. Sample means mu_k\n        y_s0 = y[states == 0]\n        T0 = len(y_s0)\n        if T0 > 0:\n            V0_inv = 1.0 / V0\n            sigma_sq_inv = 1.0 / sigma_sq\n            V0_post_inv = V0_inv + T0 * sigma_sq_inv\n            V0_post = 1.0 / V0_post_inv\n            mu0_post = V0_post * (V0_inv * m0 + sigma_sq_inv * np.sum(y_s0))\n            mu0 = rng.normal(mu0_post, np.sqrt(V0_post))\n        else: # Sample from prior if state is not visited\n            mu0 = rng.normal(m0, np.sqrt(V0))\n\n        y_s1 = y[states == 1]\n        T1 = len(y_s1)\n        if T1 > 0:\n            V1_inv = 1.0 / V1\n            sigma_sq_inv = 1.0 / sigma_sq\n            V1_post_inv = V1_inv + T1 * sigma_sq_inv\n            V1_post = 1.0 / V1_post_inv\n            mu1_post = V1_post * (V1_inv * m1 + sigma_sq_inv * np.sum(y_s1))\n            mu1 = rng.normal(mu1_post, np.sqrt(V1_post))\n        else:\n            mu1 = rng.normal(m1, np.sqrt(V1))\n\n        # c. Sample transition probabilities p_kk\n        if T > 1:\n            N00 = np.sum((states[:-1] == 0)  (states[1:] == 0))\n            N01 = np.sum((states[:-1] == 0)  (states[1:] == 1))\n            N11 = np.sum((states[:-1] == 1)  (states[1:] == 1))\n            N10 = np.sum((states[:-1] == 1)  (states[1:] == 0))\n            \n            p00 = rng.beta(a00 + N00, b00 + N01)\n            p11 = rng.beta(a11 + N11, b11 + N10)\n        else: # T=1, no transitions, sample from priors\n            p00 = rng.beta(a00, b00)\n            p11 = rng.beta(a11, b11)\n\n        # Store sample if past burn-in\n        if i >= burn_in:\n            state_samples[i - burn_in, :] = states\n\n    # 3. Post-processing\n    # Estimate marginal posterior probability of recession (state 1)\n    # This is the mean of the indicator variable (0 or 1) across samples\n    pi_hat = np.mean(state_samples, axis=0)\n    \n    # Classify as recession if prob >= 0.5 and count\n    recession_count = np.sum(pi_hat >= 0.5)\n    \n    return int(recession_count)\n\ndef solve():\n    # Define the test cases from the problem statement.\n    test_cases = [\n        { # Case A\n            'y': np.array([0.010, 0.008, 0.009, 0.007, 0.006, 0.007, -0.004, -0.006, -0.005, -0.007, -0.006, -0.004, 0.005, 0.006, 0.008, 0.009, 0.007, 0.006, 0.005, 0.007]),\n            'sigma_sq': 0.000025,\n            'priors': {'mu0': (0.007, 0.0001), 'mu1': (-0.006, 0.0001), 'p00': (8, 2), 'p11': (8, 2)},\n            'settings': {'N': 6000, 'B': 3000, 'seed': 12345}\n        },\n        { # Case B\n            'y': np.array([0.000]),\n            'sigma_sq': 0.000025,\n            'priors': {'mu0': (0.004, 0.0001), 'mu1': (-0.004, 0.0001), 'p00': (5, 5), 'p11': (5, 5)},\n            'settings': {'N': 6000, 'B': 3000, 'seed': 12345}\n        },\n        { # Case C\n            'y': np.array([0.003, 0.004, 0.002, -0.001, 0.000, -0.002, -0.003, 0.001, 0.002, 0.003, -0.002, -0.001]),\n            'sigma_sq': 0.000025,\n            'priors': {'mu0': (0.002, 0.0002), 'mu1': (-0.002, 0.0002), 'p00': (2, 2), 'p11': (2, 2)},\n            'settings': {'N': 6000, 'B': 3000, 'seed': 12345}\n        }\n    ]\n\n    results = []\n    for case in test_cases:\n        result = run_gibbs_sampler(case['y'], case['sigma_sq'], case['priors'], case['settings'])\n        results.append(result)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n\n```", "id": "2398229"}]}