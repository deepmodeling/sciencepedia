{"hands_on_practices": [{"introduction": "This exercise explores the fundamental homeostatic mechanism that ensures centromere identity is faithfully inherited through cell divisions. By translating the biological processes of histone dilution and replenishment into a mathematical model, you will derive the necessary deposition rate to maintain a stable Centromere Protein A (CENP-A) population. This practice builds foundational skills in quantitative cell biology, demonstrating how simple conservation principles govern the stability of epigenetic information. [@problem_id:2795366]", "problem": "A centromere in a eukaryotic cell contains a fixed number of Centromere Protein A (CENP-A) nucleosomes at the end of Gap 1 (G1) phase, immediately before entry into Synthesis (S) phase. Let this number be denoted by $N_0$. Assume that during S phase, parental CENP-A nucleosomes are redistributed between the two sister chromatids without any loss, and that there is no CENP-A turnover during S phase, Gap 2 (G2) phase, or mitosis. Newly synthesized CENP-A is deposited only during the subsequent G1 phase.\n\nDuring G1, suppose that cells attempt to deposit CENP-A at a constant attempt rate $\\lambda$ (attempts per centromere per hour) over a G1 duration of $T$ hours. Each attempt independently succeeds with probability $p$ and inserts exactly one CENP-A nucleosome at the centromere. Assume no upper bound is reached during the G1 window aside from the requirement to restore the pre-replication level.\n\nStarting from conservation of parental CENP-A through replication and the definition of expectation for independent trials:\n- Derive the expected number of CENP-A nucleosomes per chromatid immediately after S phase.\n- Then determine the analytic expression for the attempt rate $\\lambda$ required to restore the centromeric CENP-A number to $N_0$ by the end of G1, in terms of $N_0$, $T$, and $p$.\n\nExpress the final answer as a closed-form expression for $\\lambda$ in nucleosomes per hour. No numerical approximation is required.", "solution": "The problem statement is subjected to validation before a solution is attempted.\n\nStep 1: Extract Givens\n- Initial number of Centromere Protein A (CENP-A) nucleosomes at the end of Gap 1 (G1) phase is $N_0$.\n- During Synthesis (S) phase, parental CENP-A nucleosomes are redistributed between the two sister chromatids without loss.\n- There is no CENP-A turnover during S phase, Gap 2 (G2) phase, or mitosis.\n- New CENP-A is deposited only during the subsequent G1 phase.\n- Deposition occurs at a constant attempt rate $\\lambda$ (attempts per centromere per hour).\n- The duration of the G1 phase is $T$ hours.\n- Each deposition attempt succeeds with probability $p$.\n- A successful attempt inserts exactly one CENP-A nucleosome.\n- The system must restore the CENP-A number to $N_0$ by the end of G1.\n\nStep 2: Validate Using Extracted Givens\nThe problem presents a simplified mathematical model of CENP-A nucleosome dynamics during the cell cycle.\n- **Scientifically Grounded:** The model is based on established biological concepts: DNA replication in S phase, dilution of parental histones onto daughter strands, and reloading of new histones to maintain epigenetic marks. The assumption of distributive segregation of CENP-A is a known hypothesis. The timing of new CENP-A deposition in G1 is also consistent with experimental observations in human cells. The model is an abstraction, but it is not scientifically unsound.\n- **Well-Posed:** The problem defines all variables ($N_0$, $\\lambda$, $T$, $p$) and provides a clear objective: derive an expression for $\\lambda$. The structure allows for a unique, meaningful solution.\n- **Objective:** The problem is stated in precise, quantitative, and unbiased language.\n\nThe problem is deemed valid as it is a formalizable, self-contained, and scientifically relevant modeling problem. It does not violate any of the criteria for invalidity.\n\nStep 3: Derivation of the Solution\nThe solution proceeds in two parts as requested.\n\nFirst, we determine the expected number of CENP-A nucleosomes per chromatid immediately after the S phase.\nLet $N_0$ be the number of CENP-A nucleosomes at the centromere of a single chromosome at the end of the G1 phase. During the S phase, the DNA is replicated, resulting in a chromosome composed of two identical sister chromatids. The problem states that the original $N_0$ parental CENP-A nucleosomes are redistributed between the centromeres of these two sister chromatids without any loss.\n\nLet $N_1$ and $N_2$ be the number of CENP-A nucleosomes on the first and second sister chromatid, respectively. The conservation of nucleosomes implies:\n$$N_1 + N_2 = N_0$$\nThe problem does not specify the mechanism of distribution, but to find the expected number on a single chromatid, we assume the distribution process is symmetric on average. There is no information to suggest a bias toward one chromatid. Therefore, the expected number of CENP-A nucleosomes on any given chromatid, $\\mathbb{E}[N_{chromatid}]$, is half of the total.\n$$\\mathbb{E}[N_{chromatid}] = \\frac{N_0}{2}$$\nAfter mitosis, each daughter cell receives one of the sister chromatids, which then becomes a chromosome in the new cell. Thus, a daughter cell begins the next G1 phase with an expected number of $N_{G1,start} = \\frac{N_0}{2}$ CENP-A nucleosomes at its centromere.\n\nSecond, we determine the analytic expression for the attempt rate $\\lambda$.\nThe goal is to restore the number of CENP-A nucleosomes to the original level, $N_0$, by the end of the G1 phase. The number of new nucleosomes that must be deposited, $\\Delta N$, is the difference between the target number and the starting number.\n$$\\mathbb{E}[\\Delta N] = N_0 - \\mathbb{E}[N_{G1,start}] = N_0 - \\frac{N_0}{2} = \\frac{N_0}{2}$$\nNew CENP-A deposition occurs during the G1 phase, which has a duration of $T$ hours. The process is modeled as a series of independent attempts. The rate of these attempts is given as $\\lambda$ attempts per hour.\nThe total number of attempts, $N_{attempts}$, over the entire G1 period is:\n$$N_{attempts} = \\lambda T$$\nEach attempt is an independent Bernoulli trial with a probability of success $p$. A successful attempt adds one nucleosome. The expected number of successfully deposited nucleosomes, $\\mathbb{E}[N_{deposited}]$, is the total number of attempts multiplied by the probability of success.\n$$\\mathbb{E}[N_{deposited}] = N_{attempts} \\times p = (\\lambda T) p$$\nTo maintain the steady-state number of CENP-A nucleosomes across cell generations, the expected number of deposited nucleosomes must equal the number lost due to dilution during replication.\n$$\\mathbb{E}[N_{deposited}] = \\mathbb{E}[\\Delta N]$$\nSubstituting the expressions derived above, we obtain the governing equation:\n$$(\\lambda T) p = \\frac{N_0}{2}$$\nWe now solve this equation for the attempt rate, $\\lambda$.\n$$\\lambda = \\frac{N_0}{2 T p}$$\nThis expression gives the required attempt rate in units of attempts per hour to ensure the epigenetic mark conveyed by the CENP-A nucleosomes is stably maintained through cell division, under the assumptions of this model.", "answer": "$$\n\\boxed{\\frac{N_0}{2 T p}}\n$$", "id": "2795366"}, {"introduction": "While maintaining an existing centromere is crucial, understanding what makes a genomic location suitable for establishing a *new* centromere is a key question in epigenetics. This problem presents a thought experiment based on synthetic biology approaches to probe the requirements for neocentromere formation. You will apply your knowledge of chromatin states to predict the outcome, weighing the competing influences of local transcription and the surrounding chromatin architecture in defining a stable epigenetic identity. [@problem_id:2795267]", "problem": "A human cell line is engineered with an inducible recruitment system that transiently targets the Holliday Junction Recognition Protein (HJURP) to a chosen genomic locus for one G1 interval, after which the tether is removed. You are evaluating two candidate loci, $X$ and $Y$, that are matched for sequence composition and replication timing, and differ only in the following chromatin features measured immediately before HJURP recruitment: $X$ sits within a domain of very high RNA Polymerase II (RNAPII) transcription and is distant from heterochromatin domains; $Y$ exhibits low to moderate RNAPII transcription and is immediately adjacent to a broad block of pericentric heterochromatin enriched for Histone H3 lysine 9 trimethylation (H3K9me3) and Heterochromatin Protein 1 (HP1). After a single induction round, you assay whether a stable centromere has been established and maintained for several cell cycles without further HJURP targeting, as indicated by sustained incorporation of Centromere Protein A (CENP-A) and kinetochore assembly.\n\nBased only on well-established principles of centromere epigenetics, nucleosome dynamics, and chromatin domain organization, which locus is more likely to acquire and maintain centromere identity, and what is the most mechanistically sound justification?\n\nA. Locus $Y$, because low to moderate transcription provides sufficient nucleosome remodeling for HJURP-mediated CENP-A replacement without excessive eviction, while proximity to pericentric H3K9me3/HP1 enriches cohesin and creates a domain boundary that stabilizes a centromere core flanked by heterochromatin.\n\nB. Locus $X$, because high transcription maximally increases nucleosome turnover and histone chaperone activity, thereby favoring CENP-A incorporation, and distance from heterochromatin prevents inhibitory H3K9me3 spreading into the nascent centromere.\n\nC. Both loci are equally likely, because centromere identity is dictated by underlying DNA sequence features rather than by transcription rate or heterochromatin context.\n\nD. Locus $Y$ is less likely than $X$, because heterochromatin directly recruits HJURP into H3K9me3 chromatin to deposit CENP-A, so adjacency to heterochromatin would divert HJURP away from the euchromatic candidate site and favor a highly transcribed region like $X$ instead.", "solution": "The problem statement must first be validated for scientific and logical integrity.\n\n**Step 1: Extracted Givens**\n*   **System:** A human cell line with an inducible recruitment system.\n*   **Protein of Interest:** Holliday Junction Recognition Protein (HJURP).\n*   **Experimental Condition:** HJURP is transiently targeted to a specific genomic locus for one G1 phase interval.\n*   **Candidate Loci:** Locus $X$ and Locus $Y$.\n*   **Shared Properties of Loci:** Matched for sequence composition and replication timing.\n*   **Properties of Locus $X$:** Located within a domain of very high RNA Polymerase II (RNAPII) transcription; distant from heterochromatin domains.\n*   **Properties of Locus $Y$:** Exhibits low to moderate RNAPII transcription; immediately adjacent to a broad block of pericentric heterochromatin enriched for Histone H3 lysine 9 trimethylation (H3K9me3) and Heterochromatin Protein 1 (HP1).\n*   **Assay:** Measurement of stable centromere establishment and maintenance, defined by sustained incorporation of Centromere Protein A (CENP-A) and subsequent kinetochore assembly for several cell cycles after the initial recruitment event.\n*   **Question:** Determine which locus ($X$ or $Y$) is more likely to develop and maintain a stable centromere, and provide the mechanistic justification based on established principles.\n\n**Step 2: Validation of Problem Statement**\nThe problem is scientifically grounded. The experimental setup described is a classic synthetic biology approach to probe the requirements for epigenetic memory, specifically for centromere identity. The components are all correct: HJURP is the bona fide chaperone for CENP-A, the histone H3 variant that epigenetically marks centromeres. Its loading is restricted to the G1 phase of the cell cycle. The description of Locus $X$ as a highly transcribed, euchromatic region and Locus $Y$ as a region with low transcription adjacent to canonical pericentric heterochromatin (H3K9me3/HP1) correctly frames the central question about the necessary chromatin environment for neocentromere formation. The problem is well-posed, objective, and internally consistent.\n\n**Step 3: Verdict**\nThe problem statement is valid. I will proceed with a solution.\n\n**Derivation of Solution**\nThe formation of a stable, heritable centromere requires not only the initial deposition of CENP-A but also a local environment that supports its retention and self-perpetuating deposition in subsequent cell cycles. The artificial targeting of HJURP ensures the initial event occurs at both loci, so the deciding factor is the long-term stability dictated by the chromatin context.\n\n$1$. **The Role of Transcription:** The process of transcription is coupled to nucleosome dynamics.\n*   At Locus $X$, the \"very high\" level of RNAPII transcription implies a state of high flux and nucleosome turnover. While some turnover is necessary for histone exchange, excessive transcription is disruptive. It antagonizes the establishment of any stable, specialized chromatin domain. A high rate of transcription would likely lead to the rapid eviction of any newly deposited CENP-A nucleosomes, favoring the incorporation of transcription-associated histone variants like H3.3. Such an environment is inherently unstable and unsuitable for maintaining the unique identity of a centromere.\n*   At Locus $Y$, the \"low to moderate\" level of transcription is considered optimal for centromere function. This level of activity provides sufficient chromatin plasticity to allow access for chaperones and remodeling complexes, facilitating the replacement of canonical H3 with CENP-A. Crucially, it is not so high as to prevent the stable assembly and retention of the CENP-A domain. This model is strongly supported by empirical observations that endogenous centromeres are not transcriptionally inert but exhibit low levels of transcription.\n\n$2$. **The Role of Flanking Heterochromatin:** In higher eukaryotes, the CENP-A core of a centromere is not an isolated island; it is functionally and structurally coupled with adjacent pericentric heterochromatin.\n*   Locus $X$ is distant from heterochromatin, meaning a nascent centromere there would lack this critical architectural context. It would be a solitary epigenetic mark in a sea of active euchromatin, lacking the structural reinforcement and domain definition provided by a heterochromatic flank.\n*   Locus $Y$ is immediately adjacent to a block of H3K9me3/HP1 heterochromatin. This organization is highly advantageous and characteristic of natural centromeres. The flanking heterochromatin serves multiple critical functions: (i) It provides mechanical rigidity to the centromere region, which is essential to withstand microtubule-generated forces during mitosis. (ii) It serves as a major platform for the recruitment of the cohesin complex, which is indispensable for holding sister chromatids together. (iii) It forms a boundary that helps to insulate the CENP-A domain, reinforcing its identity and preventing encroachment from surrounding transcriptional activities.\n\n**Conclusion:** Locus $Y$ provides a far more suitable foundation for establishing and maintaining a functional centromere. Its combination of low-to-moderate transcription and proximity to pericentric heterochromatin closely mimics the known architecture of stable, endogenous centromeres.\n\n**Evaluation of Options**\n\n**A. Locus $Y$, because low to moderate transcription provides sufficient nucleosome remodeling for HJURP-mediated CENP-A replacement without excessive eviction, while proximity to pericentric H3K9me3/HP1 enriches cohesin and creates a domain boundary that stabilizes a centromere core flanked by heterochromatin.**\nThis option provides a mechanistically precise and accurate summary of the principles derived above. It correctly identifies the ideal transcriptional level and the key supportive roles of flanking heterochromatin, including cohesin enrichment and domain stabilization. The reasoning is sound and aligns with current understanding of centromere biology.\n**Verdict: Correct.**\n\n**B. Locus $X$, because high transcription maximally increases nucleosome turnover and histone chaperone activity, thereby favoring CENP-A incorporation, and distance from heterochromatin prevents inhibitory H3K9me3 spreading into the nascent centromere.**\nThis option is incorrect. \"Maximal\" turnover is disruptive and leads to eviction, not stable incorporation. The view of flanking heterochromatin as merely \"inhibitory\" is a gross oversimplification that ignores its essential structural and functional roles in centromere organization.\n**Verdict: Incorrect.**\n\n**C. Both loci are equally likely, because centromere identity is dictated by underlying DNA sequence features rather than by transcription rate or heterochromatin context.**\nThis statement is fundamentally incorrect for humans and most higher eukaryotes, where centromeres are defined epigenetically by the presence of CENP-A. The problem itself neutralizes this argument by stating the loci are matched for sequence. Chromatin context is of paramount importance for the inheritance of epigenetic states.\n**Verdict: Incorrect.**\n\n**D. Locus $Y$ is less likely than $X$, because heterochromatin directly recruits HJURP into H3K9me3 chromatin to deposit CENP-A, so adjacency to heterochromatin would divert HJURP away from the euchromatic candidate site and favor a highly transcribed region like $X$ instead.**\nThis option is based on a false premise. The molecular pathway for HJURP recruitment does not involve direct binding to H3K9me3. HJURP is part of a complex that targets the centromere core. The idea that it would be \"diverted\" into the adjacent heterochromatin is not supported by established mechanisms. Consequently, the conclusion is invalid.\n**Verdict: Incorrect.**", "answer": "$$\\boxed{A}$$", "id": "2795267"}, {"introduction": "The theoretical principles of centromere biology are ultimately tested and refined using experimental data, primarily from Chromatin Immunoprecipitation sequencing (ChIP-seq). This final practice bridges theory and application by guiding you through the construction of a modern bioinformatics pipeline to analyze ChIP-seq data for Centromere Protein A (CENP-A). By implementing a generalized linear model to correct for common technical biases, you will learn the rigorous statistical methods required to confidently identify epigenetically marked regions from raw sequencing counts. [@problem_id:2795347]", "problem": "You are studying centromere epigenetics of Centromere Protein A (CENP-A) using Chromatin Immunoprecipitation sequencing (ChIP-seq) with a matched input control. CENP-A nucleosomes are enriched at functional centromeres, but sequencing read counts are confounded by technical biases such as genomic mappability and guanine-cytosine (GC) content. You must formalize enrichment estimation using a generalized linear model and detect significantly enriched genomic windows. Assume the following foundational starting points: (i) read counts per genomic window are stochastic counts that can be modeled by a Poisson generalized linear model (GLM) with canonical log link when overdispersion is not dominant, (ii) an input control library provides an exposure-like baseline proportional to accessible chromatin and non-specific background, and (iii) GC content and mappability are covariates that systematically bias observed read counts. Your program must implement the following, expressed in purely mathematical and algorithmic terms.\n\n1. Model specification and estimation:\n   - Treat the observed ChIP-seq count in window $i$ as a realization $y_i$ from a distribution with mean $\\mu_i$ suitable for a generalized linear model with canonical log link.\n   - Use the input control count $n_i$ as an exposure-like quantity by including an offset defined on the link scale. To ensure numerical stability where $n_i = 0$, add a fixed pseudo-count $c$ on the count scale before taking the logarithm. Use $c = 0.5$.\n   - Include two covariates per window: GC fraction $g_i$ and mappability $m_i$. Standardize each covariate across windows within each test case to have zero mean and unit standard deviation.\n   - Estimate the regression coefficients by maximum likelihood using iteratively reweighted least squares (IRLS) for the Poisson GLM, with the described offset, until a small change tolerance is achieved. You may include an $\\ell_2$-ridge stabilization term with a very small weight for numerical stability if needed.\n\n2. Residual-based inference:\n   - For each window, compute a standardized one-sided test statistic for enrichment using the Pearson residual under the fitted model, where the variance function is that of the Poisson family. Use a one-sided tail appropriate for testing $H_0$: \"no positive enrichment beyond bias-corrected expectation\" versus $H_1$: \"positive enrichment.\"\n   - Convert the test statistics into one-sided $p$-values using the Normal approximation associated with the GLM theory for large samples.\n\n3. Multiple testing:\n   - Apply the Benjaminiâ€“Hochberg procedure to control the false discovery rate (FDR) at level $q = 0.1$ across the windows within each test case. Return the set of indices of windows declared significantly enriched, using zero-based indexing.\n\n4. Test suite:\n   - Implement your program to process the following three test cases. In each case, arrays are aligned by index, and all counts are non-negative integers. GC fractions and mappability are real numbers between $0$ and $1$:\n     - Case A (happy path): \n       - ChIP counts $y$: $[15,18,120,14,17,13,110,20]$\n       - Input counts $n$: $[10,12,25,11,12,9,24,13]$\n       - GC fractions $g$: $[0.35,0.40,0.36,0.41,0.38,0.39,0.37,0.42]$\n       - Mappability $m$: $[0.95,0.96,0.70,0.97,0.95,0.96,0.68,0.97]$\n     - Case B (boundary with zeros in input and ChIP):\n       - ChIP counts $y$: $[0,1,2,0,12,0,1,0]$\n       - Input counts $n$: $[0,1,2,0,3,0,1,0]$\n       - GC fractions $g$: $[0.50,0.48,0.49,0.52,0.50,0.51,0.49,0.50]$\n       - Mappability $m$: $[0.80,0.82,0.79,0.80,0.81,0.79,0.80,0.82]$\n     - Case C (no enrichment):\n       - ChIP counts $y$: $[5,6,4,5,6,5]$\n       - Input counts $n$: $[5,6,4,5,6,5]$\n       - GC fractions $g$: $[0.40,0.41,0.39,0.40,0.41,0.40]$\n       - Mappability $m$: $[0.95,0.96,0.94,0.95,0.96,0.95]$\n   - Angles are not present in this problem, and no physical units are involved.\n\n5. Output specification:\n   - For each of the three cases, produce the list of zero-based indices of enriched windows after FDR control at level $q = 0.1$, with indices reported in strictly increasing order.\n   - Your program should produce a single line of output containing the results as a comma-separated list of the three lists, enclosed in square brackets. For example, an output could look like $[[i_1,i_2],[j_1],[]]$ where each $i_k$ and $j_k$ is an integer index.\n\nConstraints and reminders:\n- Use only the data provided above for each test case.\n- The pseudo-count is $c = 0.5$ on the count scale and applies only to the input control when computing the offset.\n- Standardize $g_i$ and $m_i$ within each test case before fitting the model.\n- All computations must be self-contained and deterministic given the above inputs.", "solution": "The comprehensive problem of identifying genomic regions with significant signal enrichment from ChIP-seq data, while correcting for known biases, is a standard task in computational biology. The provided problem statement is scientifically sound and computationally well-posed. We shall proceed by formalizing the required statistical model and the algorithmic steps for estimation and inference.\n\nThe objective is to implement a procedure based on a Generalized Linear Model (GLM) to detect genomic windows with statistically significant enrichment of Centromere Protein A (CENP-A) reads, accounting for biases from GC content, mappability, and sequencing depth as measured by an input control.\n\n**1. Model Specification**\n\nWe model the ChIP-seq read count $y_i$ in each genomic window $i$ as an independent random variable following a Poisson distribution:\n$$ y_i \\sim \\text{Poisson}(\\mu_i) $$\nwhere $\\mu_i$ is the expected count in window $i$. The Poisson distribution is appropriate for count data.\n\nThe GLM framework connects the mean $\\mu_i$ to a linear combination of predictors through a link function. For the Poisson family, the canonical link function is the natural logarithm, which ensures that the mean $\\mu_i$ is always positive. The linear predictor, $\\eta_i$, is given by:\n$$ \\eta_i = \\log(\\mu_i) $$\n\nThe linear predictor $\\eta_i$ incorporates the effects of covariates and a baseline exposure term. The model is specified as:\n$$ \\eta_i = \\beta_0 + \\beta_g g'_i + \\beta_m m'_i + \\log(n_i + c) $$\nwhere:\n-   $\\beta_0$ is the intercept term, representing the baseline log-enrichment ratio.\n-   $g_i$ and $m_i$ are the raw GC fraction and mappability for window $i$. Before being used in the model, they are standardized to $g'_i$ and $m'_i$ respectively, such that they have a mean of $0$ and a standard deviation of $1$ across all windows in a given dataset. This standardization places the covariates on a common scale and improves the numerical stability of the fitting procedure. If a covariate has zero standard deviation, its standardized value is $0$.\n-   $\\beta_g$ and $\\beta_m$ are the regression coefficients that quantify the systematic effect of GC content and mappability on the log-count, respectively.\n-   $n_i$ is the read count from the matched input control library for window $i$. The term $\\log(n_i + c)$ is an *offset* on the link scale. An offset is a predictor with a coefficient fixed to $1$. It accounts for variations in baseline read density due to chromatin accessibility and other technical factors captured by the input experiment.\n-   $c = 0.5$ is a pseudo-count added to $n_i$ to prevent taking the logarithm of zero and to stabilize the offset for windows with very low input counts.\n\nLet $\\mathbf{x}_i = [1, g'_i, m'_i]^T$ be the design vector for window $i$ and $\\boldsymbol{\\beta} = [\\beta_0, \\beta_g, \\beta_m]^T$ be the vector of coefficients. The model can be written compactly as:\n$$ \\log(\\mu_i) = \\mathbf{x}_i^T \\boldsymbol{\\beta} + \\text{offset}_i \\quad \\text{where} \\quad \\text{offset}_i = \\log(n_i + c) $$\nThis implies that the expected count $\\mu_i$ is modeled as:\n$$ \\mu_i = (n_i + c) \\exp(\\mathbf{x}_i^T \\boldsymbol{\\beta}) $$\nHere, $\\exp(\\mathbf{x}_i^T \\boldsymbol{\\beta})$ models the enrichment ratio over the baseline, adjusted for biases.\n\n**2. Parameter Estimation by Iteratively Reweighted Least Squares (IRLS)**\n\nThe coefficients $\\boldsymbol{\\beta}$ are estimated by maximizing the log-likelihood of the Poisson model. For GLMs, this is typically achieved using the IRLS algorithm. IRLS is an iterative procedure where, at each step, a weighted least squares regression is performed.\n\nStarting with an initial guess for the coefficients, $\\boldsymbol{\\beta}^{(0)}$ (e.g., a zero vector), the algorithm iterates as follows for $t=0, 1, 2, \\dots$:\n\n1.  **Calculate the linear predictor and fitted means**:\n    $$ \\boldsymbol{\\eta}^{(t)} = \\mathbf{X} \\boldsymbol{\\beta}^{(t)} + \\text{offset} $$\n    $$ \\boldsymbol{\\mu}^{(t)} = \\exp(\\boldsymbol{\\eta}^{(t)}) $$\n    where $\\mathbf{X}$ is the design matrix with rows $\\mathbf{x}_i^T$.\n\n2.  **Calculate the working response vector $\\mathbf{z}^{(t)}$**:\n    $$ z_i^{(t)} = \\eta_i^{(t)} + \\frac{y_i - \\mu_i^{(t)}}{\\mu_i^{(t)}} $$\n    This is derived from a Newton-Raphson or Fisher scoring update step.\n\n3.  **Calculate the weights matrix $\\mathbf{W}^{(t)}$**:\n    The weights are the inverse of the variance of the working response. For the Poisson GLM, the variance function is $V(\\mu) = \\mu$, and the derivative of the log link is $g'(\\mu) = 1/\\mu$. The weights are given by:\n    $$ w_i^{(t)} = \\left( (g'(\\mu_i^{(t)}))^2 V(\\mu_i^{(t)}) \\right)^{-1} = \\left( (1/\\mu_i^{(t)})^2 \\mu_i^{(t)} \\right)^{-1} = \\mu_i^{(t)} $$\n    $\\mathbf{W}^{(t)}$ is a diagonal matrix with these weights, $W_{ii}^{(t)} = \\mu_i^{(t)}$.\n\n4.  **Update the coefficients**:\n    The new coefficient vector $\\boldsymbol{\\beta}^{(t+1)}$ is found by solving the weighted least squares problem, which has the following solution. To enhance numerical stability against collinearity, a small $\\ell_2$ (ridge) regularization term with weight $\\lambda$ is added.\n    $$ \\boldsymbol{\\beta}^{(t+1)} = (\\mathbf{X}^T \\mathbf{W}^{(t)} \\mathbf{X} + \\lambda\\mathbf{I})^{-1} \\mathbf{X}^T \\mathbf{W}^{(t)} (\\mathbf{z}^{(t)} - \\text{offset}) $$\n    We will use a small stabilization parameter, e.g., $\\lambda = 10^{-6}$.\n\nThe iteration continues until the change in the coefficient vector, an appropriate norm such as $\\|\\boldsymbol{\\beta}^{(t+1)} - \\boldsymbol{\\beta}^{(t)}\\|_2$, is smaller than a predefined tolerance.\n\n**3. Residual-based Inference**\n\nOnce the IRLS algorithm has converged to the final Maximum Likelihood Estimate (MLE) $\\hat{\\boldsymbol{\\beta}}$, we compute the final fitted means $\\hat{\\boldsymbol{\\mu}} = \\exp(\\mathbf{X}\\hat{\\boldsymbol{\\beta}} + \\text{offset})$.\n\nTo test for positive enrichment in each window, we formulate a one-sided hypothesis test:\n-   $H_0$: The observed count $y_i$ is consistent with the bias-corrected expectation $\\hat{\\mu}_i$.\n-   $H_1$: The observed count $y_i$ is significantly greater than $\\hat{\\mu}_i$.\n\nThe test statistic is the standardized Pearson residual, $r_{P,i}$. For a Poisson model where $\\text{Var}(y_i) = \\mu_i$, this is:\n$$ r_{P,i} = \\frac{y_i - \\hat{\\mu}_i}{\\sqrt{\\hat{\\mu}_i}} $$\nUnder $H_0$, for large samples (or large $\\hat{\\mu}_i$), $r_{P,i}$ is approximately distributed as a standard normal variable, $Z \\sim N(0, 1)$.\n\nA large positive value of $r_{P,i}$ indicates that the observed count is much larger than expected, providing evidence for enrichment. The one-sided $p$-value for window $i$ is calculated as the upper tail probability of the standard normal distribution:\n$$ p_i = P(Z \\ge r_{P,i}) = 1 - \\Phi(r_{P,i}) $$\nwhere $\\Phi(\\cdot)$ is the cumulative distribution function (CDF) of the standard normal distribution.\n\n**4. Multiple Testing Correction**\n\nSince we are performing a hypothesis test for every window in the genome, we must correct for multiple testing to control the number of false positives. We use the Benjamini-Hochberg (BH) procedure to control the False Discovery Rate (FDR) at a level $q = 0.1$.\n\nThe BH procedure is as follows:\n1.  Collect all $N$ p-values, $\\{p_1, p_2, \\ldots, p_N\\}$.\n2.  Sort the p-values in ascending order: $p_{(1)} \\le p_{(2)} \\le \\ldots \\le p_{(N)}$.\n3.  Find the largest index $k$ such that the corresponding sorted p-value satisfies the condition:\n    $$ p_{(k)} \\le \\frac{k}{N} q $$\n4.  If such a $k$ exists, reject the null hypothesis for all tests corresponding to the p-values $p_{(1)}, \\ldots, p_{(k)}$. Otherwise, do not reject any null hypotheses.\n\nThe final output for each test case will be the set of zero-based indices of the windows for which $H_0$ was rejected, sorted in ascending order.", "answer": "```python\nimport numpy as np\nfrom scipy.stats import norm\n\ndef solve():\n    \"\"\"\n    Main function to solve the centromere epigenetics problem for all test cases.\n    \"\"\"\n    test_cases = [\n        {\n            \"y\": np.array([15, 18, 120, 14, 17, 13, 110, 20]),\n            \"n\": np.array([10, 12, 25, 11, 12, 9, 24, 13]),\n            \"g\": np.array([0.35, 0.40, 0.36, 0.41, 0.38, 0.39, 0.37, 0.42]),\n            \"m\": np.array([0.95, 0.96, 0.70, 0.97, 0.95, 0.96, 0.68, 0.97]),\n        },\n        {\n            \"y\": np.array([0, 1, 2, 0, 12, 0, 1, 0]),\n            \"n\": np.array([0, 1, 2, 0, 3, 0, 1, 0]),\n            \"g\": np.array([0.50, 0.48, 0.49, 0.52, 0.50, 0.51, 0.49, 0.50]),\n            \"m\": np.array([0.80, 0.82, 0.79, 0.80, 0.81, 0.79, 0.80, 0.82]),\n        },\n        {\n            \"y\": np.array([5, 6, 4, 5, 6, 5]),\n            \"n\": np.array([5, 6, 4, 5, 6, 5]),\n            \"g\": np.array([0.40, 0.41, 0.39, 0.40, 0.41, 0.40]),\n            \"m\": np.array([0.95, 0.96, 0.94, 0.95, 0.96, 0.95]),\n        },\n    ]\n\n    C_PSEUDO_COUNT = 0.5\n    Q_FDR_LEVEL = 0.1\n    IRLS_TOLERANCE = 1e-8\n    IRLS_MAX_ITER = 50\n    RIDGE_LAMBDA = 1e-6\n\n    final_results = []\n    \n    for case in test_cases:\n        y_counts = case[\"y\"]\n        n_counts = case[\"n\"]\n        g_frac = case[\"g\"]\n        m_map = case[\"m\"]\n        num_windows = len(y_counts)\n\n        # 1. Standardize covariates\n        g_mean, g_std = g_frac.mean(), g_frac.std(ddof=0)\n        m_mean, m_std = m_map.mean(), m_map.std(ddof=0)\n        \n        g_std = 1.0 if g_std == 0 else g_std\n        m_std = 1.0 if m_std == 0 else m_std\n\n        g_stdzd = (g_frac - g_mean) / g_std\n        m_stdzd = (m_map - m_mean) / m_std\n\n        # 2. Prepare GLM inputs\n        # Design matrix X (intercept, g', m')\n        X = np.vstack([np.ones(num_windows), g_stdzd, m_stdzd]).T\n        \n        # Offset term\n        offset = np.log(n_counts + C_PSEUDO_COUNT)\n        \n        # 3. Fit Poisson GLM using IRLS\n        beta = np.zeros(X.shape[1])\n        for _ in range(IRLS_MAX_ITER):\n            # Linear predictor and mean\n            eta = X @ beta + offset\n            mu = np.exp(eta)\n            \n            # Check for numerical instability with mu\n            mu[mu < 1e-8] = 1e-8\n            \n            # Working response and weights\n            z = eta + (y_counts - mu) / mu\n            W = np.diag(mu)\n            \n            # WLS update for beta with ridge penalty\n            X_T_W = X.T @ W\n            X_T_W_X = X_T_W @ X\n            \n            # Add ridge term for stability\n            regularizer = RIDGE_LAMBDA * np.identity(X.shape[1])\n            inv_term = np.linalg.inv(X_T_W_X + regularizer)\n            \n            beta_new = inv_term @ X_T_W @ (z - offset)\n            \n            # Check for convergence\n            if np.linalg.norm(beta_new - beta) < IRLS_TOLERANCE:\n                beta = beta_new\n                break\n            beta = beta_new\n        \n        # 4. Residual-based inference\n        # Final fitted means\n        mu_hat = np.exp(X @ beta + offset)\n        \n        # Pearson residuals as test statistics\n        # Add small epsilon to denominator to avoid division by zero if mu_hat is exactly 0\n        pearson_residuals = (y_counts - mu_hat) / np.sqrt(mu_hat + 1e-10)\n        \n        # One-sided p-values from standard normal approximation\n        p_values = norm.sf(pearson_residuals) # Survival function (1 - CDF)\n        \n        # 5. Multiple testing correction (Benjamini-Hochberg)\n        sorted_indices = np.argsort(p_values)\n        sorted_p_values = p_values[sorted_indices]\n        \n        i_range = np.arange(1, num_windows + 1)\n        bh_thresholds = (i_range / num_windows) * Q_FDR_LEVEL\n        \n        significant_mask = sorted_p_values <= bh_thresholds\n        \n        enriched_indices = []\n        if np.any(significant_mask):\n            # Find the largest k such that p_(k) <= (k/N) * q\n            k = np.where(significant_mask)[0].max()\n            significant_original_indices = sorted_indices[:k+1]\n            enriched_indices = sorted(significant_original_indices.tolist())\n\n        final_results.append(enriched_indices)\n\n    # Format output as specified\n    output_parts = [f\"[{','.join(map(str, r))}]\" for r in final_results]\n    print(f\"[{','.join(output_parts)}]\")\n\nsolve()\n```", "id": "2795347"}]}