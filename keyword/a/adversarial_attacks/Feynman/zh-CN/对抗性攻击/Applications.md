## 应用与跨学科联系

在我们探索了对抗性攻击的原理——那些能够完全愚弄我们最先进的[机器学习模型](@entry_id:262335)的奇怪、无形的推动——之后，你可能会留下一个挥之不去的问题：这仅仅是一个巧妙的派对戏法吗？一个供计算机科学家在实验室里琢磨的好奇心事物？答案，正如我们将看到的，是一个响亮的“不”。[对抗性样本](@entry_id:636615)的镜中世界并非一个遥远、理论的国度；它的边界以最密切和关键的方式触及我们自己的世界。从病床到我们行驶的高速公路，甚至到我们对人类心智的理解，这一现象都迫使我们成为更好的工程师、更谨慎的科学家和更深刻的思想家。

### 数字医生的脆弱性

没有哪个领域的[风险比](@entry_id:173429)医学更高。我们正站在一个新时代的黎明，人工智能能够以超人的准确度阅读医学扫描图像，有望更早地发现疾病，并减轻过度劳累的临床医生的负担。然而，这种新能力也伴随着新的脆弱性。

想象一个旨在通过智能手机拍摄的[皮肤病](@entry_id:900411)变照片来发现[黑色素瘤](@entry_id:904048)迹象的人工智能。这些系统从成千上万的样本中学习，捕捉人类可能错过的颜色和纹理的微妙模式。但正是这种敏感性可能被用来对付它们。一个对手原则上可以制造一个扰动——不是通过添加奇怪、嘈杂的图案，而是通过对图像的色彩平衡进行微小、均匀的调整，这种变化小到低于人类感知的阈值。对于皮肤科医生来说，图像看起来一模一样。而对于人工智能来说，一个良性的痣可能突然看起来像癌症，或者更糟的是，一个致命的[黑色素瘤](@entry_id:904048)可能被误判为无害[@problem_-id:4496259]。攻击向量甚至不必是对最终图像的数字操纵；它可能是在拍照过程中对相机应用的白平衡设置进行的微妙、恶意的调整，从而产生一种能够经受压缩和传输的鲁棒且无形的失真。

这种脆弱性并不仅限于在图像上运行的复杂深度学习模型。考虑一个病理学中更基本的任务：在染色的组织样本中分割细胞核。判断一个像素是否属于细胞核，可以基于一个物理原理——[比尔-朗伯定律](@entry_id:192870)（Beer–Lambert law），该定律将穿过染料的[光强度](@entry_id:177094)与其浓度联系起来。例如，人工智能可能会使用蓝色通道的强度来估计与细胞核结合的苏木精染料的浓度。一个[光密度](@entry_id:189768)代理值为 $1.386$ 的像素可能刚好低于 $1.ॉ40$ 的“细胞核”阈值。对该像素蓝色强度的微小、有针对性的降低——一个刚刚超过百分之一、完全不可见的变化——就可能将[光密度](@entry_id:189768)推过阈值，导致分割错误。这里的攻击不是针对一个模糊的“黑箱”，而是针对一个基于物理学的系统。它利用了数字决策的毫厘之差。

当我们将此放大到每天处理数千次扫描的医院网络时，潜在的危害变得惊人地清晰。对胸部X光片分类器的一次成功攻击，将一个“存在疾病”的病例翻转为“不存在疾病”，会产生一个假阴性。对于一个决策带有真实成本的系统——其中[假阴性](@entry_id:894446) ($c_{\mathrm{FN}}$) 比假阳性 ($c_{\mathrm{FP}}$) 灾难性得多——新增的有害误诊数量是可以量化的。它取决于攻击者可以接触到的病例比例、疾病的流行率，以及位于人工智能[决策边界](@entry_id:146073)附近的病例密度——一个由模型自身敏感性定义的“脆弱裕度”。

这个问题超出了图像的范畴。现代医学是一个数据的世界。想象一个人工智能筛选病人的电子健康记录（EHR）——一个包含实验室值、生命体征和人口统计信息的表格——来预测败血症的风险。想要操纵这个系统的对手不能只是添加随机噪声。病人的年龄不能改变，钾的实验室值不能跳到一个生理上不可能的数字，而像诊断代码这样的分类特征必须保持有效。在这里，制作一个可信的对抗性攻击是一门精巧的艺术，需要扰动尊重临床现实中错综复杂的规则和约束。

那么，我们是否应该放弃这些强大的工具呢？完全不必。这种脆弱性本身就指向了一个解决方案：拥抱人类专业知识不可替代的角色。如果我们知道一个模型对于靠近其决策阈值 $\tau$ 的输入最为脆弱，我们就可以建立一个安全网。我们可以设计一个“[人在回路](@entry_id:893842)”的系统，自动标记出任何模型置信度分数位于“延迟区”——比如说，在阈值的一个裕度 $\gamma$ 范围内——的病例。通过根据模型的已知敏感性和对手的潜在能力仔细选择 $\gamma$，我们可以确保那些最容易被攻击翻转的病例被发送给人类临床医生进行最终审查。这种简单的、有原则的延迟机制，将对手的武器——模型的敏感性——转变成了其自身防御的触发器。而在[大型语言模型](@entry_id:751149)充当心理健康聊天机器人的时代，攻击针对的是语言和逻辑本身——劫持模型指令的“提示注入”或诱使其提供有害建议的“越狱”——这种鲁棒安全策略和人类介入的原则仍然至关重要。

### 将智能根植于物理世界

当人工智能系统离开屏幕，开始与物理世界互动时，[对抗性样本](@entry_id:636615)的挑战呈现出一个新的维度。在这些信息物理系统（cyber-physical systems）中——从[自动驾驶](@entry_id:270800)汽车到工业机器人——一个错误的感知可能导致即时且不可逆转的物理后果。

让我们考虑一下电动汽车中的电池管理系统（BMS），它必须持续估算电池的荷电状态（SOC）。一个现代的BMS可能会并行运行两个估算器：一个机器学习模型，它已经学会了从传感器历史到SOC的复杂映射；以及一个传统的基于物理的模型，如扩展卡尔曼滤波器（EKF），它依赖于电池的[等效电路模型](@entry_id:1124621)。现在，假设一个对手可以向电流和电压传感器读数中注入微小、有界的扰动。机器学习模型，作为一个复杂的高维函数，正如我们所预期的那样是脆弱的；攻击者可以找到一条与[梯度对齐](@entry_id:172328)的路径，将SOC估算值推离真实值。

但EKF的行为则不同。它拥有纯数据驱动模型所缺乏的东西：一个“世界模型”。它期望电流和电压之间的关系遵循其电路模型中编码的物理定律。当一个与该模型不一致的传感器读数到达时——产生一个大的“残差”——EKF可以做一件了不起的事：它可以变得怀疑。它可以拒绝可疑的测量值，转而相信其基于物理的预测。这种内部一致性检查提供了一种天然的鲁棒性。此外，EKF建立在电荷守恒原理之上，这意味着它的SOC估算值只能通过对电流进行时间积分来改变；它不能被任意地跳变。这是一个深刻的教训：将我们的人工智能根植于它所观察的系统的物理定律中，为抵御欺骗提供了强大的防御。

这种物理上可信的扰动的想法至关重要。在研究一个根据可穿戴IMU和EMG传感器预测[人类运动](@entry_id:903325)的生物力学模型时，谈论通用的、像素般的噪声几乎没有意义。现实世界中的“对手”是物理现象：[陀螺仪](@entry_id:172950)偏置的缓慢漂移、传感器轴的轻微未对准，或当来自一块肌肉的电信号泄露到另一块肌肉的传感器时EMG通道之间的串扰。一个鲁棒的模型是对这些特定的、结构化的变换不敏感的模型，而不仅仅是对随机撒播的噪声不敏感[@problem_-id:4186292]。

这让我们进入了功能安全工程的严谨世界。对于那些失效可能造成灾难性后果的系统，工程师必须证明其每小时危险失效概率（PFH）低于一个极低的阈值，正如汽车行业的[ISO 26262](@entry_id:1126786)等标准所要求的那样。对抗性攻击的存在从根本上改变了这种计算。一个系统的失效概率不再仅仅是其平均情况下的误分类率；它是在攻击下的最坏情况率，$p_{\text{mis}}^{\text{adv}}$，这个值可能高出几个数量级。因此，对抗性攻击不仅仅是一个“网络安全”问题；它是一个直接的、可量化的[功能安全](@entry_id:1125387)威胁。一个完整的人工智能驱动车辆的安全案例现在必须包括一个明确的安全保障案例，包含来自[威胁建模](@entry_id:924842)、形式化[鲁棒性验证](@entry_id:1131076)以及在[数字孪生](@entry_id:171650)中进行的详尽测试的证据，以论证即使在攻击下，系统的风险仍然保持在可接受的低水平。

### 心灵之镜

也许最引人入胜的联系并非与我们的机器，而是与我们自己。多年来，[计算神经科学](@entry_id:274500)家一直认为，某些类型的深度神经网络，特别是卷积神经网络（CNN），不仅是强大的分类器，也是我们对人脑[腹侧视觉通路](@entry_id:1133769)——负责[物体识别](@entry_id:1129025)的通路——的最佳科学模型。他们表明，CNN不同层级的激活模式与[视觉皮层](@entry_id:1133852)不同区域的神经放电模式有着惊人的相似之处。

但[对抗性样本](@entry_id:636615)的发现给这个美丽的故事带来了麻烦。人类[视觉系统](@entry_id:151281)异常鲁棒。我们不会因为一些对我们来说不可见的、经过巧妙排列的像素就突然无法识别一辆校车。如果我们的模型如此脆弱，而大脑却如此鲁棒，那么这些模型真的能被认为是-对大脑的准确描述吗？

然而，这个看似的问题可以转化为一个强大的科学工具。它为我们提供了一套新的、可[证伪](@entry_id:260896)的预测来检验我们的理论。对抗性脆弱性不再是一个麻烦，而变成了一把哲学上的手术刀。我们现在可以为构成一个“好”的大脑模型制定出清晰、可检验的标准：

-   **心理物理不变性（Psychophysical Invariance）：** 一个模型只有在对人类观察者无法感知的任何扰动都保持稳定时，才可能是神经上可信的。如果一个变化低于我们的[最小可觉差](@entry_id:166166)（Just-Noticeable Difference）阈值，它就不应该改变模型的输出。

-   **感知度量对齐（Perceptual-Metric Alignment）：** 一个好的模型的内部“表示空间”应该反映我们自己的感知空间。如果两张图片在我们看来几乎完全相同，它们在模型内部的表示也应该彼此接近。[对抗性样本](@entry_id:636615)正是这种对齐被打破的情况。

-   **[神经稳定性](@entry_id:899220)（Neural Stability）：** 最终的检验。通过使用探针测量[视觉皮层](@entry_id:1133852)的神经活动，我们可以找到“神经静默”的扰动——即对图像进行那些不会改变大脑反应的改动。一个真正的大脑模型也必须不受这些特定的、神经静默的扰动的影响。

这改变了问题的性质。一个[对抗性样本](@entry_id:636615)不再仅仅是对一台机器的攻击；它是一项实验。它是我们可以用来探索人工智能与生物智能之间差异的探针，帮助我们完善我们的大脑模型，并推动我们走向对“看”的真正含义的更深层次理解。从一个计算机程序中的一个漏洞，我们抵达了科学中最深奥的问题之一：我们自己的心智是如何构建出这样一个稳定而有弹性的世界图景的？