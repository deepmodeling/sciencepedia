## 引言
在当今的大数据时代，我们被来自科学各个角落的复杂高维数据集所淹没——从成千上万个细胞的基因表达谱，到运动中蛋白质的原子坐标。尽管这些数据信息丰富，但它们常常掩盖了支配系统的简单底层过程。依赖于标准欧几里得距离的传统方法可能会产生误导，无法捕捉数据点之间真实的内在关系。我们如何才能在这些庞大的数据云中找到隐藏的路径和结构呢？

本文介绍**扩散图**，这是一种强大的[降维技术](@entry_id:169164)，为理解复杂数据提供了一个几何框架。通过将距离重新定义为基于[随机游走过程](@entry_id:171699)的连通性度量，扩散图揭示了数据所在的底层流形。接下来的章节将引导您了解这种优雅的方法。首先，在**“原理与机制”**一章中，我们将剖析该算法，从构建数据点图到利用其谱特性创建一个新的、有意义的坐标系。随后，**“应用与跨学科联系”**一章将展示扩散图非凡的多功能性，演示它们如何被用于绘制细胞发育图谱、揭示化学反应的编排，乃至描绘神经活动的景观。

## 原理与机制

想象一下，你是一位古代的地图绘制师，任务是绘制一个新发现的群岛。你没有卫星，没有飞机，甚至没有船只来直接测量距离。你唯一的信息来自于观察商人们在岛屿间跳跃穿梭的旅程。你注意到，在某些岛屿之间往来很容易，而另一些岛屿之间的通行则很罕见。你如何仅凭这些信息绘制出一幅地图？这正是**扩散图**旨在解决的挑战，只不过对象不是陆地岛屿，而是广阔高维空间中的数据“岛屿”。

### 从点云到路径网络

大多数有趣的数据集，无论它们代表神经元的放电模式、细胞中基因的表达，还是蛋白质的构象形状，都不仅仅是随机的点云。它们拥有潜在的结构。**[流形假设](@entry_id:275135)**认为，这些高维数据点实际上位于一个维度低得多、平滑的曲面或**流形**上或其附近 。我们的首要任务是揭示这些点之间的连接。

我们从构建一个图开始，这是一个由节点和边组成的网络。每个数据点都成为一个节点。然后我们通过搭建“桥梁”来连接这些节点。规则很简单：我们只在彼此“接近”的点之间建立桥梁。我们使用**核函数**来量化这种接近程度，最常用的是[高斯核](@entry_id:1125533)，$k_\epsilon(x,y) = \exp(-\|x-y\|^2/\epsilon)$。这个函数就像一个总桥梁建造师：它为非常近的点分配一个大的权重（一座坚固的桥），而为相距较远的点分配一个迅速衰减、接近于零的权重。参数$\epsilon$设定了我们的尺度；它定义了我们认为的“局部”范围。

但是我们应该使用什么“距离”$\|x-y\|$呢？这不是一个简单的问题。度量的选择对整个事业的成功至关重要。想象一下，我们的数据点是分子模拟中蛋白质的快照。使用所有原子的原始笛卡尔坐标将是一个错误。整个蛋白质的简单旋转或平移——这种完全不改变其内部形状的运动——会导致一个很大的[笛卡尔](@entry_id:925811)距离。我们的图所能发现的主要模式将是这些无关紧要的刚体运动，而不是我们关心的那些微妙、缓慢的构象变化。相反，我们必须使用更智能的距离，比如在最佳对齐结构后的**[均方根偏差 (RMSD)](@entry_id:170106)**，或者基于**[二面角](@entry_id:185221)**等内部坐标的距离，这些坐标对全局运动是不变的 。即便如此，我们仍需小心。[二面角](@entry_id:185221)是周期性的，存在于一个圆上。将它们视为直线上的数字会在$\pi$和$-\pi$处产生一个人为的“切口”。一个巧妙的技巧是将每个角度$\theta$不表示为单个数字，而是表示为圆上的一对坐标$(\cos\theta, \sin\theta)$，从而确保几何形状被正确捕捉 。距离的初始选择定义了我们即将探索的整个景观。

### 随机游走者的旅程

在我们的桥梁网络就位后，我们现在可以定义一个[扩散过程](@entry_id:268015)。想象一个随机游走者从一个数据点开始。在每一步，游走者决定跳到哪个相邻点。它更有可能穿过一座坚固的桥（高核权重）而不是一座脆弱的桥。我们通过创建一个**马尔可夫转移矩阵**来将其形式化，记为$P$。每个条目$P_{ij}$是从点$i$一步转移到点$j$的概率。我们通过取从$i$到$j$的桥梁权重$K_{ij}$，然后除以离开点$i$的所有桥梁的权重之和来计算它。这确保了从任何点$i$出发，跳到所有可能邻居的概率之和为一  。

矩阵$P$包含了我们数据上运动的基本规则。应用一次它模拟了随机游走的一步。通过计算矩阵的$t$次幂$P^t$，应用它$t$次，可以告诉我们从任意点$i$在恰好$t$步内到达任意其他点$j$的概率。这个过程，即概率从一个起始点在图上“扩散”开来，正是扩散图的核心——扩散。

### 一种新的距离：扩散度量

这里蕴含着该方法的核心、美妙的洞见。欧几里得距离可能会产生误导。考虑一个[细胞分化](@entry_id:273644)的数据集，其中一个祖细胞类型分化为两个不同的谱系。两个细胞，每个分支上各一个，可能在基因空间中与祖细胞很近，因此在欧几里得距离上也彼此接近。然而，它们属于根本不同的命运。

扩散图提出了一种更深刻的测量距离的方式。我们不再问“两个点相距多远？”，而是问“从它们开始的随机旅程有多相似？”。如果两个点$i$和$j$位于我们[数据流形](@entry_id:636422)的同一分支上，那么从任一点开始的随机游走在$t$步后倾向于探索一组相似的邻近点。它们在可能目的地上的概率分布，由矩阵$P^t$的行$P^t(i,\cdot)$和$P^t(j,\cdot)$给出，将会非常相似。相反，如果它们位于仅由一个遥远的瓶颈连接的独立分支上，它们的随机游走将探索图的非常不同的部分。它们的目的地分布将大相径庭 。

这种相似性被形式化为**扩散距离**，$D_t(i,j)$。它本质上是这两个概率分布之间的距离 ：
$$
D_t(i,j)^2 = \sum_{k=1}^n \frac{\left(P^t_{ik} - P^t_{jk}\right)^2}{\pi_k}
$$
其中$\pi_k$是稳态分布，一个用于校正点密度的项。这个新的度量忽略了直接的[欧几里得距离](@entry_id:143990)，而是通过图来衡量连通性。它“展开”了流形，使得在同一[连续路径](@entry_id:187361)上的点彼此接近，而在不同分支上的点则相距遥远，从而揭示了数据真实的内在几何 。

### 数据的隐藏[谐波](@entry_id:181533)

计算所有这些成对的扩散距离可能很麻烦。奇妙的是，有一种更直接的方法可以得到这个图，那就是利用线性代数的魔力。[转移矩阵](@entry_id:145510)$P$有一组特殊的向量，称为**右[特征向量](@entry_id:151813)** $\psi_\ell$，以及对应的数值，称为**特征值** $\lambda_\ell$。当我们将$P$应用于一个[特征向量](@entry_id:151813)时，这等同于仅仅将该[特征向量](@entry_id:151813)乘以其特征值：$P\psi_\ell = \lambda_\ell \psi_\ell$。这些[特征向量](@entry_id:151813)代表了我们数据图的基本“模式”或“谐波”。

对于一个随机游走矩阵，特征值都在$1$和$-1$之间。最大的特征值总是$\lambda_0 = 1$。其对应的[特征向量](@entry_id:151813)$\psi_0$是一个全为1的常数向量。这是“平凡”[特征向量](@entry_id:151813)。它代表了系统的[稳态](@entry_id:139253)：在无限长的时间之后，随机游走者在任何地方的概率都相等，所有关于起始点的信息都丢失了。这个向量不包含任何几何信息，必须从我们的图中排除。包含它然后执行标准的[数据缩放](@entry_id:636242)（如z-scoring）可能会导致数值灾难，因为你将用其接近零的方差来做除法，从而将微小的数值误差放大成一个占主导地位的、无意义的坐标 。

真正的魔力在于*非平凡*的[特征向量](@entry_id:151813)，$\psi_1, \psi_2, \ldots$。它们的特征值小于1，因此它们代表了随时间衰减的模式。**扩散图**是一种嵌入，它使用这些[特征向量](@entry_id:151813)作为我们数据的新坐标。点$x_i$沿第$\ell$轴的坐标就是第$\ell$个[特征向量](@entry_id:151813)在该点的值$\psi_\ell(i)$，再乘以其特征值对扩散时间的幂$\lambda_\ell^t$。
$$
\Psi_t(x_i) = \big( \lambda_1^t \psi_1(i), \lambda_2^t \psi_2(i), \ldots, \lambda_m^t \psi_m(i) \big)
$$
前几个[特征向量](@entry_id:151813)，对应于最接近1的特征值，是“最慢”的模式。它们代表了数据中最持久、最大尺度的结构。在这个新的低维扩散图空间中，点之间的欧几里得距离出色地逼近了图上的真实[扩散距离](@entry_id:915259) 。我们找到了一个尊[重数](@entry_id:136466)据内在连通性的坐标系。整个框架与**图拉普拉斯算子**紧密相连，后者是衡量图上“平滑度”的算子，其谱特性与$P$的谱特性密切相关 。

### 时间的显微镜

**[扩散时间](@entry_id:274894)$t$**不仅仅是一个参数；它是一个控制我们地图分辨率的旋钮，就像显微镜的焦距一样 。
*   当$t$很小时，我们只允许随机游走几步。地图对精细尺度的局部关系很敏感。我们能看到数据景观中的细小角落和缝隙。
*   当$t$很大时，我们让扩散运行很长时间。来自快速衰减模式（那些具有小$\lambda_\ell$的模式）的贡献会因$\lambda_\ell^t$变得微小而缩减为零。只有那些具有$\lambda_\ell \approx 1$的缓慢、持久的模式得以幸存。这个过程就像一个低通滤波器，平滑掉噪声并揭示数据的粗略、全局结构——大陆和主要山脉。

这种多尺度特性是一种深远的优势。我们如何选择合适的$t$？一种方法是检查**谱隙**：排序后的特征值列表通常在最初几个之后会出现一个急剧的下降。这个间隙将“信号”（捕捉真实结构的慢速模式）与“噪声”（快速模式）分离开来。我们可以选择一个足够大的$t$来放大这个间隙，从而有效地将精华与糟粕分开，而不会[过度平滑](@entry_id:634349)掉有趣的特征 。

### 一个微妙的陷阱：密度的偏见

最后还有一个微妙的问题。如果我们的数据点不是从底层流形上均匀采样的，会怎么样？想象一下绘制一个国家地图，我们有很多来自人口稠密城市的数据点，但很少有来自农村地区的。标准的随机游走会倾向于“困在”高密度的城市里。由此产生的[扩散过程](@entry_id:268015)及其生成的图将是国家内在地理和其人口分布的混合体。

扩散图的标准构建方法（对应于参数选择$\alpha=0$）正是这样做的。[扩散过程](@entry_id:268015)具有向高密度区[域漂移](@entry_id:637840)的趋势 。有时这正是我们想要的！我们可能对这个密度加权景观上的动力学感兴趣。

但通常，我们的目标是揭示流形的纯粹内在几何，而不受我们恰好如何采样它的影响。令人惊讶的是，我们可以实现这一点。通过轻微修改核的归一化——一个称为**$\alpha$-重整化**的过程——我们可以精确地控制这种密度偏差。通过将参数$\alpha$设置为1，我们可以构建一个完全抵消采样密度影响的[扩散过程](@entry_id:268015)。在大量数据的极限下，该过程的生成元收敛于流形真实的、几何的**[Laplace-Beltrami算子](@entry_id:267002)**  。这使我们能够恢复一幅纯粹的地理图，不受人口分布的污染。$\alpha$的选择赋予了我们非凡的力量来调整我们想看到的东西：是采样数据上的原始动力学，还是数据来源的隐藏世界的原始几何。

