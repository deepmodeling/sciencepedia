## 引言
在生存分析领域，Cox [比例风险模型](@entry_id:171806)是理解协变量与事件发生时间之间关系的一项至关重要的工具。其强大之处在于一个关键但有时也颇具限制性的假设：协变量的效应会随时间按比例缩放单一的基线风险率。但是，当我们的数据来自本质上不同的群体时——例如来自不同医院的患者或来自不同[人口统计学](@entry_id:143605)特征的受试者——这个假设不成立了，该怎么办？这会带来重大的分析挑战，可能导致有偏倚的结果和错误的结论。

本文深入探讨了一种巧妙的解决方案：分层[偏似然](@entry_id:165240)。它提供了一个强大的框架来处理这种异质性，而无需对群体之间的差异性质做出强有力的假设。我们将首先在 **“原理与机制”** 一章中剖析其核心统计引擎，探索分层和[偏似然](@entry_id:165240)如何协同作用，从而将我们感兴趣的效应与混杂的基线风险分离开来。随后，**“应用与跨学科联系”** 一章将展示该方法卓越的通用性，从其在流行病学研究设计中的基础性作用，到其在[隐私保护机器学习](@entry_id:636064)中的前沿应用，说明这一统计概念如何解决不同科学领域的实际问题。

## 原理与机制

要真正领会分层分析的精妙之处，我们必须首先回归其本源。让我们想象一场盛大的、跨越多座城市的马拉松比赛。我们的目标是了解一种新的训练方案（一个协变量，我们称之为 $X$）如何影响跑者的表现。这里的“事件”不是第一个完成比赛，而可能是因精疲力竭而退赛。我们测量的是“到事件发生的时间”。

在一个简单的世界里，我们可以想象所有跑者在比赛过程中都遵循一个单一、普适的“疲惫率”。这就是我们所说的 **基线风险**，$h_0(t)$。它可能在开始时较低，在中间赛程上升，在接近终点时急剧攀升。我们的训练方案 $X$ 的效应就是调整这个基线率。一个好的方案会降低它，而一个差的方案会抬高它。作为生存分析基石的 Cox [比例风险模型](@entry_id:171806)，优美地将这一思想形式化：任何跑者的个人风险为 $h(t|X) = h_0(t) \exp(\beta X)$。参数 $\beta$ 是对数风险比——它告诉我们训练方案使基线风险乘以了多少倍，而“比例风险”假设就是指这个乘数在任何时间点都是相同的。

### 不同赛道的问题

现在，如果我们的马拉松不是在单一赛道上进行，而是在几个城市——比如 Denver 和 New Orleans——同时举行，情况会怎样？基线条件截然不同。Denver 的高海拔带来的压力与 New Orleans 的湿热带来的压力类型不同。在 Denver，一个普通跑者的“疲惫”基线风险 $h_{0,\text{Denver}}(t)$ 的形状随时间的变化可能与在 New Orleans 的 $h_{0,\text{NOLA}}(t)$ 完全不同。

这打破了“城市”这个变量的[比例风险假设](@entry_id:163597)。身处 Denver 相对于 New Orleans 的风险比不是恒定的；它在整个比赛过程中都在变化。试图用一个标准的 Cox 模型来分析这种情况，仅仅将“城市”作为另一个协变量包含进去，就好比试图用一张平均化的赛道图来描述两场比赛。它会歪曲两个城市的现实，更重要的是，可能会扭曲我们对训练方案真实效应 $\beta$ 的估计。例如，如果碰巧更多接受我们特殊训练的跑者在更容易的城市比赛，我们可能会错误地将他们的成功归因于训练，而实际上是地点的原因。这是一个典型的 **混杂** 案例。

### [分而治之](@entry_id:139554)的精妙之处：分层

那么，我们如何解决这个问题呢？巧妙的思路是：不要试图将不同的现实强行塞进一个模型。相反，我们应该 *[分而治之](@entry_id:139554)*。我们将在每个城市 *内部* 分别分析比赛。这就是 **分层** 的精髓。

我们提出了一个模型，其中每个城市，或称 **层** (stratum)，都有其自己独特的、未指明的基线[风险函数](@entry_id:166593)。对于在层 $s$（例如，$s$ = Denver）中接受训练 $X$ 的跑者，其风险为：

$$
h_s(t | X) = h_{0s}(t) \exp(\beta^\top X)
$$

请注意这里的美妙之处。我们允许每个城市的基线风险 $h_{0s}(t)$ 完全不同且任意。我们实际上已将“城市”变量的非比例风险问题转移到了这些灵活的、特定于层的基线函数中。我们所维持的关键假设是，我们的训练方案的效应 $\beta$ 在所有城市都是相同的。我们相信训练的生理益处是普适的，即使赛道不同。

### [偏似然](@entry_id:165240)的奥妙

此时，一个怀疑论者可能会提出一个合理的观点：“你刚刚引入了一整套未知的函数 $h_{0s}(t)$，每个城市一个！在所有这些未知的‘冗余’信息到处都是的情况下，你怎么可能估计出 $\beta$ 呢？”

这就是 David Cox 爵士的 **[偏似然](@entry_id:165240)** (partial likelihood) 理论的精妙之处。它是现代统计学中最优美的思想之一。我们不试图对整个比赛的时间线进行建模，而是只关注事件发生的瞬间——即当有跑者退赛时。

想象在时间 $t_i$，位于 Denver 的跑者 $i$ 退赛了。让我们看看在这一刻之前仍在 Denver 比赛的跑者群体；这就是 **风险集** (risk set)，$R_{\text{Denver}}(t_i)$。我们可以问一个简单而有力的问题：鉴于在这一确切时刻，该群体中 *有某人* 退赛了，那么退赛的恰好是跑者 $i$ 的概率是多少？

这个概率就是跑者 $i$ 的个人风险与他所在风险集中所有风险之和的比值：

$$
\Pr(\text{runner } i \text{ drops out}) = \frac{h_{\text{Denver}}(t_i | X_i)}{\sum_{j \in R_{\text{Denver}}(t_i)} h_{\text{Denver}}(t_i | X_j)}
$$

现在，当我们代入模型的定义时，见证奇迹的发生：

$$
= \frac{h_{0,\text{Denver}}(t_i) \exp(\beta^\top X_i)}{\sum_{j \in R_{\text{Denver}}(t_i)} h_{0,\text{Denver}}(t_i) \exp(\beta^\top X_j)}
$$

由于在时间 $t_i$ 时，Denver 风险集中的每个跑者都共享同一个神秘的基线风险 $h_{0,\text{Denver}}(t_i)$，它在分子和分母中都作为一个公因子出现。因此，它被完全消掉了！

$$
= \frac{\exp(\beta^\top X_i)}{\sum_{j \in R_{\text{Denver}}(t_i)} \exp(\beta^\top X_j)}
$$

这是一个意义深远的结果。我们构建了一个 *只* 依赖于我们关心的参数 $\beta$ 和观测数据 $X$ 的概率。未知的基线风险已从方程中消失。我们只是在任何给定的事件时间，*在* 同一个层内比较跑者。

总的 **分层[偏似然](@entry_id:165240)** 就是在所有层中发生的所有事件上，将这些概率相乘。由于不同层中的事件是独立的，我们可以将总似然写成每个层似然的乘积：$L(\beta) = \prod_{s=1}^S L_s(\beta)$。

为了实际看到这一点，考虑一个按性别分层的癌症研究中的微型数据集。假设一名男性患者在第 3 个月出现疾病进展事件，他携带一个高风险基因（$z=1$）。在那一刻，男性风险集包括三名患者：两名携带高风险基因（$z=1$），一名没有（$z=0$）。这个单一事件对[偏似然](@entry_id:165240)的贡献是 $\frac{\exp(\beta \cdot 1)}{\exp(\beta \cdot 1) + \exp(\beta \cdot 1) + \exp(\beta \cdot 0)} = \frac{\exp(\beta)}{2\exp(\beta) + 1}$。请注意，计算只涉及来自“男性”层的患者。女性患者在另一个独立的“比赛”中，不参与这次比较。

### 模型在“学习”什么

通过观察所谓的 **得分函数** (score function)，我们可以对估计过程获得更深刻、更直观的理解。这是对数[偏似然](@entry_id:165240)的导数，我们通过将其设为零来找到 $\beta$ 的最佳估计。对于分层 Cox 模型，[得分函数](@entry_id:164520)具有一个极其简单的结构：

$$
U(\beta) = \sum_{\text{all events } i} \left[ X_i - \bar{X}_{w,s}(t_i, \beta) \right]
$$

这里，$X_i$ 是发生事件的个体的协变量向量。项 $\bar{X}_{w,s}(t_i, \beta)$ 是在那个时间点、那个层中风险集里所有人的协变量的加权平均值，权重是他们的风险得分 $\exp(\beta^\top X_j)$。

这个方程告诉我们，模型找到的 $\beta$ 值使得发生事件的人在协变量方面“看起来像”那一刻处于风险中的普通人。这是一种平衡行为。对于每一个事件，模型都会调整 $\beta$ 以最小化该事件发生在那个特定个体身上的“意外程度”。

### 实践后果：代价与回报

分层的决定不仅仅是一个技术选择；它涉及到偏倚和精度之间的一个根本性权衡。

-   **回报：消除偏倚。** 当基线风险在不同层之间确实存在差异时（如我们的 Denver vs. New Orleans 的例子），一个未分层的模型是设定错误的。它会对我们训练方案的效应 $\beta$ 产生有偏倚的估计。通过分层，我们创建了一个更稳健的模型，正确地解释了城市的混杂效应，从而为我们提供了一个更可信、无偏的 $\beta$ 估计。

-   **代价：信息损失。** 但如果基线风险自始至终实际上是相同的，只是我们不知道呢？在这种情况下，由于我们拒绝将在 Denver 的跑者与在 New Orleans 的跑者进行比较，我们主动丢弃了信息。这种跨层比较的损失导致 $\beta$ 的估计精度降低，意味着我们的[置信区间](@entry_id:138194)会更宽，[统计功效](@entry_id:197129)会更低。这在拥有许多小规模层的研究中尤其值得关注。如果一个层只有少数几个受试者，或者更糟的是，没有事件发生，它对 $\beta$ 的估计贡献就很少或没有贡献。这可能导致我们估计值的“[方差膨胀](@entry_id:756433)”。

### 知识的边界

分层也帮助我们理解能从数据中学到什么的极限。
- **可识别性：** 想象一下，在 Denver 的每个跑者都穿着一种特殊类型的鞋，而在 New Orleans 的每个跑者都穿着另一种类型。因为鞋的类型在每个城市 *内部* 是恒定的，它的效应与该城市的基线风险完美地混合在一起。[偏似然](@entry_id:165240)在设计上会将其效应连同基线风险一起抵消掉。因此，我们永远无法从这个分层模型中估计出那种鞋的效应。它的效应是不可识别的。

- **[推断与预测](@entry_id:634759)：** 尽管存在这些微妙之处，这个框架却异常完整。一旦我们得到了 $\beta$ 的估计值，我们就可以执行标准的统计检验（如 Wald 检验、[得分检验](@entry_id:171353)或似然比检验）来确定该效应是否具有[统计显著性](@entry_id:147554)。那么我们巧妙忽略掉的那些基线风险呢？我们实际上可以回过头去估计它们！利用我们的新估计 $\hat{\beta}$，我们可以使用一种称为 **Breslow 估计量** 的方法，为每个层分别构建累积基线风险的估计 $\hat{H}_{0s}(t)$。这使我们能够完善模型并为新个体生成生存预测，从而使我们的探索之旅圆满结束。

