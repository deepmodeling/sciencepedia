## 引言
科学发现的核心在于我们能根据新证据更新自身信念，这一过程被贝叶斯推断所形式化描述。该框架依赖于一个关键组成部分：[似然函数](@entry_id:921601)，它量化了在特定假设下观测到我们当前数据的概率。但是，当我们用以描述世界的模型——例如[星系形成](@entry_id:160121)、病毒爆发或[粒子碰撞](@entry_id:160531)的模拟——变得如此复杂，以至于[似然函数](@entry_id:921601)无法写出时，会发生什么呢？这正是现代科学诸多领域的核心挑战：我们能够模拟一个世界，却无法计算其存在的概率。

本文旨在通过探索[无似然推断](@entry_id:190526)（LFI）这一强大的领域来弥补这一关键空白。LFI是一套仅使用模拟器即可进行原则性统计推断的方法。我们将揭示，即使在传统[贝叶斯分析](@entry_id:271788)的数学基石缺失的情况下，科学家们如何对模型参数进行推理。您将了解到这些技术如何在最具雄心的理论与我们收集的真实世界数据之间搭建起一座坚固的桥梁。

首先，在“原理与机制”一节中，我们将剖析LFI的核心概念，从[近似贝叶斯计算](@entry_id:746494)（ABC）的直观思想到选择信息丰富的总结统计量的艺术。然后，我们将走向前沿，探索机器学习革命如何催生了基于神经网络的高效方法。随后，“应用与跨学科联系”一节将展示LFI的实际应用，揭示它如何在一个惊人多样化的领域中开启洞见，从解码我们DNA中的生命蓝图到测量宇宙的基本参数。

## 原理与机制

### 问题的核心：当[似然函数](@entry_id:921601)缺失时

现代科学推断的核心在于一个由Reverend Thomas Bayes在两个多世纪前首次阐明的、异常优美的简单关系。它告诉我们如何面对新证据时更新我们的信念。用现代形式，我们这样写：

$p(\boldsymbol{\theta} | x) \propto p(x | \boldsymbol{\theta}) \, p(\boldsymbol{\theta})$

让我们花点时间来理解这句话的含义。在右边，我们有$p(\boldsymbol{\theta})$，这是我们关于支配我们世界的参数$\boldsymbol{\theta}$的**先验**信念。这些参数可以是任何东西，从基本粒子的质量到病毒的传播率。紧挨着它的是$p(x | \boldsymbol{\theta})$，即**似然**项。这是全场的明星。它回答了这样一个问题：“如果宇宙的真实参数是$\boldsymbol{\theta}$，那么观测到我们刚刚收集到的特定数据$x$的概率是多少？”通过将我们的先验信念与证据的似然相乘，我们得到了左边的$p(\boldsymbol{\theta} | x)$，即**后验**分布——我们在看到数据*之后*对参数的更新、更精确的信念。

几个世纪以来，这个公式一直是统计学的基石。但是，当我们的世界模型变得如此复杂、如此错综，以至于我们再也无法写出[似然函数](@entry_id:921601)$p(x | \boldsymbol{\theta})$时，会发生什么呢？

这并非一个罕见或纯学术的问题。它可以说是21世纪科学诸多领域的核心挑战。以[大型强子对撞机](@entry_id:160821)为例。一位物理学家可能有一个包含特定参数$\boldsymbol{\theta}$（比如一种新作用力的强度）的理论。为了将这个理论与数据联系起来，他们必须模拟两个质子碰撞时发生的情况：夸克和胶子级联，形成[粒子簇射](@entry_id:753216)，然后与一个极其复杂的探测器相互作用。最终的结果是一个数据模式$x$。这个过程涉及太多层次的随机性和难以处理的物理学，以至于为$p(x | \boldsymbol{\theta})$写出一个明确的公式根本不可能。我们所拥有的只是一个模拟器——一个计算机程序，在给定$\boldsymbol{\theta}$的情况下，可以*生成*一个合成的数据模式$x$。我们能够创造世界，却无法计算任何一个单一世界存在的概率。

情况可能更加深远。有时，[似然](@entry_id:167119)*密度*这一概念本身就失效了。想象一个[宇宙学模拟](@entry_id:747928)器，对于给定的参数集$\boldsymbol{\theta}$，它在三维空间中生成点$x$。但假设模型的物理特性决定了输出必须始终位于该空间内一条纤细、弯曲的一维曲线上。模拟器产生一个恰好是曲线上某个特定点$x$的输出的概率为零，而产生曲线上任意位置之外的输出的概率也为零。我们能够写出并评估的那种平滑的[概率密度函数](@entry_id:140610)根本不存在。我们只剩下一个可以正向运行但其似然我们无法掌握的模拟器。

这就是前沿。我们拥有强大的、机械化的现实模型——[传染病](@entry_id:906300)的[基于主体的模型](@entry_id:199978)、核反应堆的模拟、[星系形成](@entry_id:160121)的模型——但我们无法以传统方式使用[贝叶斯法则](@entry_id:275170)。我们如同在没有[似然函数](@entry_id:921601)的情况下漂泊。那么，我们能做什么呢？

### “越来越热”的儿童游戏：[近似贝叶斯计算](@entry_id:746494)

当一个强大的公式失效时，最绝妙的解决方案往往惊人地简单。第一种也是最直观的[无似然推断](@entry_id:190526)方法叫做**[近似贝叶斯计算](@entry_id:746494)**，或称**ABC**。最好将其理解为一个“冷热”游戏。

想象一下，你想找到描述我们宇宙的参数$\boldsymbol{\theta}$。你有一个可以创造合成宇宙的模拟器。游戏规则如下：

1.  从你的先验信念分布$p(\boldsymbol{\theta})$中随机抽取一组参数$\boldsymbol{\theta}^*$。
2.  使用这些参数运行你的模拟器，生成一个合成数据集，$x_{sim}$。
3.  将你的合成数据$x_{sim}$与你的真实观测数据$x_{obs}$进行比较。
4.  如果它们看起来“足够接近”，你就宣布“热了”并保留参数$\boldsymbol{\theta}^*$。如果不够接近，你就宣布“冷了”并丢弃这些参数。

如果你将这个游戏重复数百万次，你所保留的“热”参数集合将构成对真实[后验分布](@entry_id:145605)$p(\boldsymbol{\theta} | x_{obs})$的近似。为什么？因为你系统地筛选出了那些能够产生一个看起来像我们世界的参数。

当然，我们必须对“足够接近”做出更精确的定义。我们需要定义两样东西：一个**距离函数**，$\rho(x_1, x_2)$，用来衡量两个数据集的差异程度；以及一个**容忍度**，$\epsilon$，它定义了我们的接受范围。正式的规则变成：如果$\rho(x_{sim}, x_{obs}) \le \epsilon$，则接受$\boldsymbol{\theta}^*$。被接受的参数集就是从一个近似后验$p_{\epsilon}(\boldsymbol{\theta} | x_{obs})$中抽取的样本。

这个简单的拒绝算法是ABC历史上的核心。但它立刻遇到了一个新问题。对于像[粒子探测器](@entry_id:273214)输出或星系快照这样的[高维数据](@entry_id:138874)集，一个模拟数据集在每一个维度上都与观测数据集“接近”的概率小到可以忽略不计。这就是臭名昭著的“[维度灾难](@entry_id:143920)”。如果我们试[图匹配](@entry_id:1125740)整个数据集，我们的接受率将如此接近于零，以至于我们需要模拟比[宇宙年龄](@entry_id:159794)还长的时间才能得到一个像样的样本。

解决方案是另一种科学上的简化行为：我们不比较整个数据集，而是比较少数几个经过巧妙选择的**总结统计量**。

### 抽象的艺术：选择关键信息

我们不再问整个[模拟宇宙](@entry_id:754872)$x_{sim}$是否看起来像我们观测到的宇宙$x_{obs}$，而是问一个小的总结统计量向量$s(x_{sim})$是否看起来像我们观测宇宙的总结$s(x_{obs})$。我们的接受规则变为$\rho(s(x_{sim}), s(x_{obs})) \le \epsilon$。整个游戏现在取决于我们选择好的总结统计量的能力。什么使一个总结“好”呢？

在理想世界中，我们会找到一个**充分统计量**。这是一个神奇的总结，它捕获了原始高维数据中包含的关于参数$\boldsymbol{\theta}$的*所有*信息。如果我们使用充分统计量，我们在压缩过程中不会损失任何东西。在容忍度$\epsilon$趋于零的极限情况下，我们的ABC过程将收敛到精确的、真实的后验分布。

然而，在复杂模型的现实世界中，充分统计量几乎从未存在。我们必须运用我们的科学直觉来手动设计那些对于我们关心的参数具有高度*信息量*的总结。这就是领域知识变得不可或缺的地方。考虑一个细菌感染的基于主体的模型，我们希望推断三个参数：[细菌复制](@entry_id:154865)率$\lambda$、[中性粒细胞](@entry_id:173698)杀伤率$\mu$和[中性粒细胞](@entry_id:173698)的趋化敏感性$\chi$。一个绝妙的总结统计量选择会是：
*   为了了解$\lambda$，我们可以测量感染初期细菌种群对数的斜率，此时增长近似呈指数形式。
*   为了了解$\mu$，我们可以关注[中性粒细胞](@entry_id:173698)与细菌接触的时刻，并测量每次接触的有效杀伤风险。
*   为了了解$\chi$，我们可以测量[中性粒细胞](@entry_id:173698)速度矢量与化学[梯度对齐](@entry_id:172328)的程度（一个“趋化指数”），或者它们在细菌菌落周围聚集的紧密程度（一个“[对相关函数](@entry_id:145140)”）。

每个总结都与一个特定参数有机械上的联系。它们的设计旨在“[解耦](@entry_id:160890)”不同参数的影响，从而保持每个参数的可识别性。

但即使有了巧妙的总结，还有另一个微妙之处：我们如何定义距离$\rho$？如果我们有三个总结，其中一个天然地比其他总结噪声更大（方差更大），那么一个简单的[欧几里得距离](@entry_id:143990)将被这个噪声分量所主导。我们最终可能接受那些匹配了噪声但未能匹配更有信息量信号的模拟。

解决方案是使用一个更智能的度量。我们可以通过除以它们的标准差来标准化总结统计量。更好的是，我们可以使用**马氏距离**。这种距离不仅考虑了总结统计量之间不同的尺度（方差），还考虑了它们之间的相关性。这就像找到了一个完美的坐标系来测量距离，它降低了噪声和冗余方向的权重，以专注于那些对于区分不同参数值真正重要的信息。

### 超越暴力破解：神经革命

ABC直观且强大，但其暴力拒绝模拟的方式是浪费的。运行一百万次模拟只接受几百次的情况并不少见。在过去十年里，科学家们一直在问：我们能做得更好吗？我们能否从*所有*的模拟中学习，而不仅仅是那些恰好落入我们微小接受区域的模拟？

在机器学习革命的推动下，答案是响亮的“是”。这催生了新一代的LFI方法，其效率提高了几个数量级。

其中最强大的方法之一是**[神经后验估计](@entry_id:752449)（NPE）**。NPE不是仅仅试图从后验中收集样本，而是使用[深度神经网络](@entry_id:636170)来学习整个后验分布$p(\boldsymbol{\theta} | s(x))$作为一个函数。其训练过程在概念上很简单：
1.  从先验中抽取参数$\boldsymbol{\theta}_i$，生成大量模拟数据总结$s_i$。这样就得到了一个由$(\boldsymbol{\theta}_i, s_i)$对组成的训练集。
2.  训练一个灵活的条件[密度估计](@entry_id:634063)器（如[归一化流](@entry_id:272573)）来学习这种映射。你实际上是在教网络：“当你看到一个看起来像$s_i$的输入总结时，输出一个在$\boldsymbol{\theta}_i$周围有尖锐峰值的概率分布。”

一旦训练完成，这个神经网络就变成了一个可重复使用的推断机器。你将你唯一的、真实的观测总结统计量$s(x_{obs})$输入给它，它会立即返回一个完整的、解析的[后验分布近似](@entry_id:753632)。这个特性被称为**摊销**：模拟的巨大计算成本在训练期间一次性预先支付。之后，对任何新观测的推断都非常快。与为每个新数据集从头开始进行完整的ABC分析相比，这是一个效率上的巨大飞跃。

其他神经方法学习贝叶斯方程的不同部分。神经[似然](@entry_id:167119)估计（NLE）学习[似然函数](@entry_id:921601)$p(s(x) | \boldsymbol{\theta})$，而神经比率估计（NRE）学习不同参数的似然比——这个量通常是推断所需的全部。这些方法共同代表了一种范式转变，将困难的推断问题转化为了一个机器学习任务。

### 我们真的对吗？校准与[模型检验](@entry_id:150498)

我们已经开发了这些异常复杂的工具。但能力越大，责任越大。我们如何知道我们花哨的神经网络，或者甚至是简单的[ABC算法](@entry_id:746190)，给出了一个正确的答案？即使算法是正确的，我们又如何知道我们底层的模拟器是现实的一个好模型？这是两个不同但同等重要的问题。

要回答第一个问题——*我的推断机器工作正常吗？*——我们使用一个称为**基于模拟的校准（SBC）**的程序 。SBC是一种内部一致性检验。我们和自己玩一个游戏。我们从先验中生成一个“基准真相”参数$\boldsymbol{\theta}_{true}$，运行我们的模拟器得到一个伪观测$\tilde{y}$，然后将这个伪观测通过我们整个推断流程得到一个后验。然后我们检查$\boldsymbol{\theta}_{true}$在我们计算出的后验中的位置。如果我们的推断机器校准良好，那么在多次重复这个游戏后，“真实”参数应该有10%的时间落在我们后验的底部10%分位数内，10%的时间落在第10和第20百分位数之间，依此类推。这些“秩”的分布应该是完全均匀的。如果不是，我们的机器就有偏差。SBC是调试我们推断算法的黄金标准。

但是SBC只告诉我们，*在假设我们的模拟器是世界的真实模型的情况下*，我们的工具工作正常。这是一个内部检验。要回答第二个问题——*我的模型是对现实的一个好描述吗？*——我们需要一个对照真实数据的外部检验。这是**[后验预测检验](@entry_id:1129985)（PPC）**的工作。过程是：
1.  对*真实*数据$x_{obs}$运行你的推断，以获得参数的后验分布。
2.  从这个后验中抽取许多参数集。
3.  对于每个参数集，运行你的模拟器来创造一个由复制宇宙$x_{rep}$组成的整体。
4.  现在，将你唯一的真实宇宙$x_{obs}$与这个整体进行比较。它看起来像一个典型成员吗？还是它是一个你的模型，即使使用了最佳拟合参数，也无法复制的奇异离群值？

如果真实数据与后验预测相比显得奇怪，这是一个警示信号，表明你的模型从根本上是错误的。它可能遗漏了某些关键的物理、生物或经济学原理。SBC和PPC共同使我们能够成为负责任的科学家：SBC验证我们的工具，PPC验证我们的理论。

### 犯错之美：[模型设定错误](@entry_id:170325)下的推断

那么，当我们的PPC失败，我们被迫承认我们的模型是错误的时候，会发生什么呢？正如统计学家George Box有句名言：“所有模型都是错的，但有些是有用的。”如果我们的模拟器不是现实的完美复制品，推断是否就毫无意义了？

美妙的答案是否定的。[无似然推断](@entry_id:190526)比人们想象的更稳健、更优雅。当我们试图拟合一个设定错误模型时，推断过程并不会简单地崩溃。相反，它会在我们假定的模型族中找到一个参数值，这个参数值在一种精确的信息论意义上（最小化Kullback-Leibler散度）与真实的数据生成过程*最接近*。

想象一下，生成我们数据的真实过程是对数正态的，但我们的模拟器只能产生高斯分布。如果我们运行我们的LFI流程，我们不会得到无意义的结果。后验将收敛到某个特定高斯分布的参数上：这个高斯分布与真实的对数正态分布具有*完全相同的均值和方差*。

这是一个深远的结论。即使使用一个“错误”的模型，我们仍然可以学到关于世界的正确且有用的东西——在这个例子中，是其真实的均值和方差。推断过程并不要求我们的模型完美。它只是在我们提供的模型的语言范围内，找到对现实的最佳可能近似。正是这种稳健性使得科学得以一步步地进步，建立和完善不完美的模型，而这些模型，尽管不完美，却让我们越来越接近真理。

