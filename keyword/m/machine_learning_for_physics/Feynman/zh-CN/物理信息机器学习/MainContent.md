## 引言
机器学习的预测能力与物理学的解释深度相结合，代表了[科学计算](@entry_id:143987)领域的一场范式转变。纯数据驱动的“黑箱”模型虽然擅长在海量数据中发现模式，但通常缺乏物理真实性，并且可能出现不可预测的失效。相反，传统的基于物理的模拟虽然稳健，但计算成本可能过高或本身并不完备。本文旨在弥合这一差距，探讨如何创建既快速又在物理上合理的、有原则的[混合模型](@entry_id:266571)。在接下来的章节中，我们将首先深入探讨“原理与机制”，研究将物理定律融入机器学习的架构和基本规则。随后，我们将探索“应用与跨学科联系”，展示这些强大的新工具如何加速科学发现，并为科学和工程领域创建一种通用的设计语言。

## 原理与机制

我们已经瞥见了将机器学习的预测能力与物理学的解释深度相结合所带来的激动人心的前景。但具体来说，这种结合是如何实现的呢？这是一场敌意收购，让算法取代几个世纪以来的物理定律吗？或者，这是一种合作伙伴关系？你可能不会惊讶地发现，答案是后者。真正的成功不在于盲目地将数据扔进一个计算巨口，而在于一种谨慎、有原则的融合。本章将带领我们进入锻造这些[混合模型](@entry_id:266571)的工作坊。我们将发现，关键不在于取代物理学，而在于倾听它、尊重它的基本规则，并将我们的算法建立在它不可动摇的基础之上。

### 三种架构的故事

想象一下，你想教一台机器预测天气。你拥有海量的历史大气数据——无数个过去日子的温度、压力、风速。你该如何着手？事实证明，有三种主要的哲学，一种宏大的三分法，涵盖了从纯数据驱动学习到深度物理集成的整个范围 。

首先是**黑箱**，即纯粹的**模拟器**。在这种方法中，我们假定物理定律是未知的。我们只向[机器学习模型](@entry_id:262335)展示某一时刻的大气状态 $\mathbf{x}_t$，并训练它生成下一时刻的状态 $\mathbf{x}_{t+\Delta t}$。这就像通过观看数千个视频来学习预测球的轨迹，却从未被告知牛顿定律。模型学习了一个能替代整个复杂演化算子的代理模型，即 $\hat{\mathcal{M}} : \mathbf{x}_t \mapsto \mathbf{x}_{t+\Delta t}$。如果你拥有涵盖所有可能情况的海量数据，这种方法可能非常强大。但这是一条充满危险的道路。该模型对底层物理学（如质量或能量守恒）没有内在的理解。它可能会预测出一个大气层慢慢消失或升温到不可能的温度的世界，仅仅因为它在训练数据中从未见过禁止这种情况的例子。它功能强大，但很脆弱，而且极不符合物理原理。

在光谱的另一端是**灰箱**，即**[残差学习](@entry_id:634200)**的哲学。在这里，我们承认我们现有的物理模型（源自像[纳维-斯托克斯方程](@entry_id:142275)这样的定律）虽然非常出色，但并非完美。它们可能难以处理复杂的多尺度现象，如云的形成或[湍流](@entry_id:151300)。因此，我们不要求机器从头学习一切，而是要求它只学习我们当前模型的*误差*。我们将未来预测为 $\mathbf{x}_{t+\Delta t} \approx \mathcal{M}_{\text{phys}}(\mathbf{x}_t) + \hat{R}_{\boldsymbol{\phi}}(\mathbf{x}_t)$，其中 $\mathcal{M}_{\text{phys}}$ 是我们信赖的基于物理的模型，而 $\hat{R}_{\boldsymbol{\phi}}$ 是一个学习到的校正项——即残差 。这就像使用[牛顿定律](@entry_id:163541)来获得球的基本轨迹，但训练一个小型[机器学习模型](@entry_id:262335)来预测由空气阻力引起的细微偏差。这种方法非常高效。它将预测锚定在已有的物理学基础上，继承其结构和稳定性，同时利用数据来修补其已知的弱点。

一个很好的例子是为像无人机（UAV）这样的复杂机器创建一个“数字孪生”。其核心飞行动力学由[牛顿定律](@entry_id:163541)支配，我们可以高保真地对其进行建模。但是，未建模的空气动力学效应或传感器偏差可能会引入误差。我们不必抛弃[牛顿定律](@entry_id:163541)，而是可以训练一个神经网络来预测残余力或传感器误差。关键的精妙之处在于我们*如何*注入这种校正。校正必须是**因果的**——它只能依赖于*当前*可用的信息，而不是未来的信息。我们不能用未来的测量值来校正当前的预测。例如，一种符合物理学思维的方法是学习一个残余力 $\Delta F_k$，并将其直接添加到[牛顿第二定律](@entry_id:274217)中，$m\mathbf{a} = \mathbf{F}_{\text{phys}} + \Delta F_k$。这尊重了物理学的[因果结构](@entry_id:159914)，并直接针对模型不完善的根源 。

最后，我们有**玻璃箱**，这是一种通常被称为**[物理信息神经网络](@entry_id:145229)（PINNs）**的范式。这种方法与物理学的结合最为紧密。在这里，物理定律本身（通常以[偏微分](@entry_id:194612)方程（PDE）的形式）成为训练过程的一部分。一个神经网络被提议作为 PDE 的解，例如，预测温度场 $T(\mathbf{x}, t)$。然后我们训练网络同时做两件事：拟合任何可用的测量数据，以及*最小化其对物理定律的违反程度*。我们可以自动计算网络输出的导数，并将它们代入 PDE。方程未被满足的量，$\partial_t T - \mathcal{F}(T, \nabla T, ...) \neq 0$，成为一个损失项，训练过程试图在任何地方都将其驱动到零。这就像一个学生不仅从实验室实验（数据）中学习，还通过不断检查自己的作业是否满足教科书中的方程（PDE 残差）来学习。这使得模型即使在数据稀疏的情况下也能进行训练，因为 PDE 在整个域上提供了强大的约束 。这个原理可以从局部的[微分](@entry_id:158422)定律扩展到全局的积分定律。例如，在[聚变等离子体](@entry_id:1125407)中，产生的总功率必须等于耗散的总功率。我们可以添加一个损失项来强制执行这种全局平衡，$\int_V \mathbf{J}\cdot\mathbf{E}\,dV = \int_V S\,dV$，确保模型不仅局部准确，而且全局一致，这对于工程应用通常至关重要 。

### 第一诫：汝应尊重物理定律

无论我们选择哪种架构，一个中心主题都会浮现：最稳健、最可靠的模型是那些深度尊重物理学基本原理的模型。这些原理不是可有可无的指导方针；它们是宇宙的语法。一个能流利使用这种语法的模型才是我们可以信赖的模型。

#### 守恒定律：不可违背的法则

物理学中最神圣的法则是其守恒定律：[质量、动量和能量守恒](@entry_id:1122905)。一个不能守恒这些量的模拟不仅不准确，而且根本上不稳定。它将不可避免地漂移到一个荒谬的状态，无中生有地创造物质，或累积能量直到爆炸。当我们引入机器学习组件时，我们就有可能破坏这些守恒定律。

我们如何防止这种情况发生？我们可以通过两种方式强制执行守恒：使用**软约束**或**硬约束** 。软约束就像罚款。我们在模型的损失函数中添加一个惩罚项，该项会随着模型违反守恒定律的程度而增大。模型被*劝阻*不要违反定律。而硬约束则是将定律构建到模型的架构中，使其*不可能*违反。这就像设计一辆在物理上无法超过速限的汽车。例如，为了确保一个学习到的源项 $S_{\theta}$ 不会创造或毁灭质量，我们可以设计其输出层，使其在整个域上的总和始终为零。

对于像气候模型这样漫长而混沌的模拟，硬约束通常是必不可少的。软约束可能允许每一步都有微小、几乎察觉不到的质量或能量泄漏。经过数百万步，这种泄漏会累积起来，就像慢滴水充满水桶一样，直到整个模拟变得不符合物理学地被水淹没 。这也适用于复杂的[热力学](@entry_id:172368)量。在大气中，**[湿静力能](@entry_id:1128097)** ($h = c_p T + gz + L_v q_v$) 是在对流等关键过程中守恒的量。一个用于对流的数据驱动模型必须被构建或约束以尊重这个守恒定律，否则它将系统性地向模拟气候中注入或移除能量，导致[长期漂移](@entry_id:172399) 。这也延伸到模型的[平衡态](@entry_id:270364)。一个好的混合模型不应扰乱物理系统的基本不动点；如果原始模型能正确模拟静止状态，那么经机器学习校正的模型也应如此。如果学习到的校正项在这些平衡点自然消失，就可以实现这一点 。

#### 对称性：物理定律的形态

与守恒定律同样根本的是对称性。物理定律在这里和在月球上是一样的（[平移不变性](@entry_id:195885)），它们也不取决于你面向哪个方向（旋转不变性）。一个预测[分子能量](@entry_id:190933)的机器学习模型，如果我们将该分子在空间中旋转，它应该给出相同的答案。它的预测必须在旋转下是**不变的**。

我们如何教模型这种对称性？“软”方法是通过[数据增强](@entry_id:266029)：我们在成千上万个分子的副本上训练模型，每个副本都处于随机方向，希望它能学会方向无关紧要。但这并不能保证；它可能仍有盲点。“硬”的、有原则的方法是利用群论的语言将对称性构建到网络的架构中。我们可以设计**等变的**层，这意味着它们的内部表示会与输入一致地变换。如果我们旋转输入分子，网络内部的一个矢量特征（比如说，代表一个局部偶极矩）会以完全相同的方式旋转。最终的能量是一个标量，然后以一种保证不变的方式从这些等变特征中计算出来 。这种方法是[几何深度学习](@entry_id:636472)的基石，它不仅鼓励模型学习物理学，而且迫使模型像物理学家一样*思考*，从根本上尊重空间的基本对称性。

#### 现实的构造：结构与域

物理过程并不总是在一个整齐的棋盘上发生。有时，问题域的结构本身就是不规则的，并带有物理意义。考虑[核素图](@entry_id:161758)，即所有已知原子核的地图。它不是一个矩形；它是质子和中子平面上的一个锯齿状半岛，由原子核变得不稳定的“滴线”所界定。如果我们想学习一个跨越这张图的核质量模型，将其视为矩形图像并使用标准的[卷积神经网络](@entry_id:178973)（CNN）是一个错误。CNN会要求我们用人造数据“填充”缺失的区域，迫使我们的模型从现实边缘那些不符合物理原理、不存在的原子核中学习。自然的表示是一个**图**，其中每个原子核是一个节点，边连接着通过增加或移除一个质子或中子可以到达的邻居。然后，[图神经网络](@entry_id:136853)可以通过仅在物理上存在的邻居之间传递信息来学习，完美地尊重了问题的不规则但真实的几何形状 。

### 混合模型的生命周期：从稳定性到未知

打造一个[混合模型](@entry_id:266571)是一回事；确保它能长期、稳定、有效地运行是另一回事。将数据驱动的组件与传统的物理模拟器耦合会引入新的、深刻的挑战。

#### 驯服野兽：确保稳定性

物理模拟器是一个精密的钟表机制，通过仔细的数值积分来推进时间。插入一个神经网络就像增加一个强大的、但有些不可预测的新齿轮。整个机器可能会变得不稳定。神经网络的“野性”——其输出随输入微小变化的剧烈程度——可以通过一个称为其**李普希茨常数** $L$ 的属性来量化。事实证明，[机器学习模型](@entry_id:262335)的这个属性直接控制着整个混合系统的稳定性。一个具有大 $L$（一个“陡峭的”、快速变化的函数）的模型可能需要一个不切实际的小时间步长 $\Delta t$ 来防止模拟崩溃。稳定性的一个充分条件通常可以用一个界限来表示，如 $\Delta t  2/(\rho(A) + L)$，其中 $\rho(A)$ 与物理部分有关，而 $L$ 来自机器学习部分 。这不仅仅是一个技术细节；这是一个深刻的洞见。为了构建稳定的[混合模型](@entry_id:266571)，我们必须“驯服”我们的机器学习组件，使用[正则化技术](@entry_id:261393)来保持它们平滑和良好行为。

#### 注意差距：尺度感知

物理现象跨越了巨大的尺度范围，从分子的微观舞蹈到星系的宏观旋转。一个模拟只能解析这些尺度的一部分。所有小于网格分辨率 $\Delta$ 的东西都是“[子网](@entry_id:156282)格”的，必须被近似，或**[参数化](@entry_id:265163)**。这通常是我们请求机器学习帮助的地方。但是，当我们有了更强大的计算机并细化我们的网格，比如说从 $\Delta=10$ 公里到 $\Delta=1$ 公里时，会发生什么？以前是[子网](@entry_id:156282)格的现象现在被模拟明确地解析了。机器学习的[参数化](@entry_id:265163)必须足够“聪明”，能够认识到这一点。它必须是**尺度感知的**。如果不是，它将继续尝试近似那些主模型现在正在直接计算的效应。这是一个称为**重复计算**的问题，它会注入伪能量并破坏模拟。一个设计合理的尺度感知[闭包](@entry_id:148169) $\mathcal{C}_{\Delta}$ 必须依赖于网格尺度 $\Delta$，使得其效果在[网格细化](@entry_id:168565)时消失，即 $\lim_{\Delta \to 0} \mathcal{C}_{\Delta} = 0$ 。

#### 进入广阔的未知：泛化的挑战

也许最大的挑战是**分布外（OOD）泛化**。我们在现有或过去世界的数据上训练我们的模型。但我们想用它们来预测一个从未见过的世界，比如 2100 年的地球气候。这是最终的 OOD 问题。未来的统计数据与过去的统计数据不同。

机器学习提供了一种精确的语言来描述这一挑战 。如果未来的气候出现更频繁的热浪，但在热浪中雷暴的底层物理学保持不变，这是一种**[协变量偏移](@entry_id:636196)**。输入的分布 $P(\mathbf{x})$ 发生了变化。然而，如果气候变化改变了云的微物理学，使得相同的大气状态产生不同类型的风暴，这是一种**[概念漂移](@entry_id:1122835)**。我们试图学习的关系本身，$P(y|\mathbf{x})$，已经改变了。

这正是有原则的、基于物理学的方法显示其真正实力的地方。一个在过去气候上训练的纯[黑箱模型](@entry_id:1121697)很可能在概念漂移下灾难性地失败。除了它所见过的数据，它在现实中没有任何锚点。然而，一个[灰箱模型](@entry_id:1125766)有更好的机会。其核心 $\mathcal{M}_{\text{phys}}$ 基于永恒的物理定律。如果这些定律仍然成立，那么只需要调整[残差校正](@entry_id:754267)项 $\hat{R}_{\boldsymbol{\phi}}$。通过将大部分工作委托给物理学，我们构建的模型不仅在今天更准确，而且在面对不确定的未来时更具鲁棒性。

这段旅程向我们表明，为物理学构建机器学习是一门精妙而深刻的艺术。它需要的不仅仅是大数据和快速的计算机；它需要对支配我们世界运行的原则怀有深刻而持久的尊重。最成功的模型不是那些忽视物理学的模型，而是那些由物理学的本质——其守恒定律、对称性、[因果结构](@entry_id:159914)和交织的尺度——编织而成的模型。这种宏大的融合不仅使我们的模拟变得更好，它正在创造一种新的、统一的科学发现语言。

