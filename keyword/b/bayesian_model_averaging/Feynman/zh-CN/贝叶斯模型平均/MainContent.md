## 引言
所有学科的科学家都依赖模型来理解复杂现象。然而，正如统计学家 George Box 的著名论断：“所有模型都是错误的。” 这带来了一个根本性的挑战：当面对几个相互竞争的模型时，我们应该信任哪一个？通常的做法是选择一个“最佳”模型并舍弃其余模型，但这是一种危险的策略，它忽略了有价值的信息，并导致我们对结论过度自信。贝叶斯[模型平均](@entry_id:635177)（BMA）为模型不确定性这一问题提供了一个强大且逻辑上连贯的解决方案。BMA并非挑选单一的胜利者，而是系统地结合来自一整套貌似合理的模型的见解，并根据每个模型的循证可信度对其进行加权。

本文将探讨BMA的框架。首先，在“原理与机制”一节中，我们将剖析BMA的工作原理，从其[概率论基础](@entry_id:158925)到“[贝叶斯奥卡姆剃刀](@entry_id:196552)”的概念。我们将探讨它如何更诚实地描述我们的总体不确定性。之后，“应用与跨学科联系”一节将展示BMA在实践中的多功能性，展示其在从医学诊断、因果推断到计算物理学和[可信人工智能](@entry_id:894485)开发等各个方面的影响。

## 原理与机制

### 科学家的困境：所有模型都是错误的

在我们探索世界的过程中，我们建立模型。生态学家可能为森林的生长建模，药理学家可能为药物在体内的作用建模 ，气候学家可能为地球大气建模 。这些模型是我们的科学故事，是我们对现实的数学描摹。但我们必须永远记住统计学家 George Box 的著名格言：“所有模型都是错误的，但有些是有用的。”

这就带来了一个两难的境地。如果我们有几个不同且相互竞争的模型——比如，一个气候模型强调[云反馈](@entry_id:1122515)，另一个则关注洋流——我们应该相信哪一个？一种常见的方法是**模型选择**：我们根据数据检验每个模型，并按照某个标准（如交叉验证  或AIC、BIC等惩罚分数 ）挑选出表现“最佳”的模型。然后，我们抛弃其他模型，并假设我们选择的模型是绝对真理。

但请稍加思索。这真的是一个明智的策略吗？这就像组建一个专家委员会就一项关键决策提供建议，听取了所有专家的意见后，却决定只听从一位专家——那个听起来*最*自信的专家——的建议，而完全忽略其他人的意见。如果那位专家只是在几件事情上碰巧说对了呢？如果另一位几乎同样优秀的专家，在问题的其他方面有关键的见解呢？通过挑选唯一的赢家，我们正在丢弃信息，并假装比我们应有的程度更加确定。这是一个危险的游戏，因为当我们面对一个全新的、未知的未来时，它常常导致过度自信和糟糕的决策  。一定有更好的方法。

### 群体的智慧：贝叶斯方式的平均

与其挑选一个赢家，不如让我们让所有貌似合理的模型都发表意见？这就是**贝叶斯[模型平均](@entry_id:635177)（BMA）**背后的核心思想。这不仅仅是一个聪明的技巧；它是将概率论的基本规则应用于[模型不确定性](@entry_id:265539)问题的直接、逻辑性的结果。

让我们想象一下，在给定观测数据 $D$ 的情况下，我们想要预测某个未来的量，称之为 $y$。[全概率定律](@entry_id:268479)是逻辑学的基石，它告诉我们 $y$ 的总概率是 $y$ 与每个可能模型同时发生的概率之和。写出来，我们就得到了BMA的优雅主方程：

$$
p(y \mid D) = \sum_{i=1}^{K} p(y \mid D, \mathcal{M}_i) \, p(\mathcal{M}_i \mid D)
$$

这个方程乍一看可能很复杂，但它讲述了一个非常简单的故事。它表明，我们的总体预测 $p(y \mid D)$ 是一个加权平均值。它是我们 $K$ 个不同模型预测的“混合”。让我们把它分解成两个关键组成部分。

#### 预测：$p(y \mid D, \mathcal{M}_i)$

这第一项是结果 $y$ 的[预测分布](@entry_id:165741)，*前提是假设模型 $\mathcal{M}_i$ 是正确的*。重要的是，这不仅仅是一个单一的数字；它是一个完整的概率分布。它已经考虑了该单一模型内部*参数*的不确定性。例如，在一个气候模型中，我们可能不知道控制海洋热量吸收的参数的确切值。一个恰当的[贝叶斯分析](@entry_id:271788)不仅仅是选择最佳拟合参数；它会对其所有貌似合理的参数值上的预测进行平均，并以其后验概率加权。因此，BMA实际上是一个两级平均过程：首先，我们对每个模型内的参数不确定性进行平均，然后我们对所有模型间的[模型不确定性](@entry_id:265539)进行平均 。

#### 权重：$p(\mathcal{M}_i \mid D)$

这第二项是赋予模型 $\mathcal{M}_i$ 预测的权重。这个权重是什么呢？它是模型的**[后验概率](@entry_id:153467)**——即在我们看到数据 $D$ *之后*，我们对模型 $\mathcal{M}_i$ 的信任程度。这就是贝叶斯定理的魔力所在。这些权重不是凭空捏造或设置为相等的。它们是由数据本身决定的。

一个模型的[后验概率](@entry_id:153467)与两件事成正比：我们对模型的先验信念 $p(\mathcal{M}_i)$，以及该模型对我们实际观测到的数据的解释程度，这个量被称为**边际似然**或**模型证据** $p(D \mid \mathcal{M}_i)$。

$$
\underbrace{p(\mathcal{M}_i \mid D)}_{\text{后验信念}} \propto \underbrace{p(D \mid \mathcal{M}_i)}_{\text{模型证据}} \times \underbrace{p(\mathcal{M}_i)}_{\text{先验信念}}
$$

从先验信念到后验信念的更新是由证据决定的。通常，这通过**贝叶斯因子**来量化，即两个[竞争模型](@entry_id:1122715)的证据之比，例如 $B_{10} = p(D \mid \mathcal{M}_1) / p(D \mid \mathcal{M}_0)$。举个例子，贝叶斯因子为12意味着数据在模型 $\mathcal{M}_1$ 下的可能性是在模型 $\mathcal{M}_0$ 下的12倍。这一证据可以极大地改变我们的信念。如果我们的[先验优势比](@entry_id:176132)是3比7，支持 $\mathcal{M}_0$，那么一个12的[贝叶斯因子](@entry_id:143567)将会使[后验优势比](@entry_id:164821)转变为36比7，支持 $\mathcal{M}_1$ 。正是这种数据驱动的权重使得BMA如此强大。能很好解释数据的模型在最终的平均预测中获得更大的投票权。

### “[贝叶斯奥卡姆剃刀](@entry_id:196552)”

但一个模型“很好地解释数据”意味着什么呢？[边际似然](@entry_id:636856) $p(D \mid \mathcal{M}_i)$ 并不仅仅是最佳拟合参数下的[似然](@entry_id:167119)。它是似然在*整个*[参数空间](@entry_id:178581)上，由先验加权的平均值。这带来了一个深远的结果，通常被称为**[贝叶斯奥卡姆剃刀](@entry_id:196552)** 。

想象一下有两个模型试图解释一个简单的数据集。模型A很简单，只有一个参数，且先验规定其必须在一个狭窄的范围内。模型B则复杂得多，有十个参数，其先验允许它们几乎可以是任何值。模型A将其预测能力集中在一小部分可能的结果上。模型B由于其灵活性，将其预测能力稀疏地分布在一个巨大的可能性宇宙中。如果数据恰好落在模型A预测的区域内，模型A就会得到很高的评价——其边际似然会很高。模型B，即使它可以通过某些特定的参数设置被扭曲以完美拟合数据，也会因其铺张浪费而受到惩罚。它必须承认，根据其先验，数据*本可以*出现在几乎任何地方。这种对不必要复杂性的自动惩罚是数学的自然结果；它不像AIC或BIC那样是基于计算参数数量的临时惩罚 。这就是为什么BMA通常偏爱更简单、更优雅的解释，除非一个复杂模型通过对数据真正惊人的拟合证明了其价值。

### 回报：诚实与更优的预测

那么，我们从这种有原则的平均中获得了什么？主要是两样东西：更诚实的不确定性和通常更优的预测。

我们来谈谈不确定性。当我们做出预测时，我们的无知有两个来源。第一种是**[偶然不确定性](@entry_id:634772)**（aleatoric uncertainty）：系统中固有的随机性或噪声，就像抛硬币一样。即使有无限的数据，这种不确定性也不会消失。第二种是**认知不确定性**（epistemic uncertainty）：我们对底层过程缺乏了解，例如哪个模型是正确的或其参数是什么。这是一种原则上可以通过收集更多数据来减少的不确定性 。

模型选择忽略了关于模型结构的认知不确定性。BMA则拥抱它。BMA预测的总方差可以使用[全方差定律](@entry_id:184705)进行分解：

$$
\text{总方差} = \underbrace{\text{模型内方差的平均}}_{\text{参数不确定性}} + \underbrace{\text{模型间均值的方差}}_{\text{模型不确定性}}
$$

这第二项，即不同模型预测之间的方差，是我们结构不确定性的直接度量  。通过包含它，BMA提供的[预测区间](@entry_id:635786)通常更宽，但更诚实。它们反映了我们知识的全部范围——以及我们的无知。

这种诚实也带来了更好的性能。通过在多个貌似合理的模型之间分散风险，BMA比单一、过度自信的模型在新数据上表现得更稳健，并做出校准得更好的预测。从决策理论的角度来看，如果我们想在常见的评分规则下最小化我们的预期预测误差，BMA是最佳策略 。

### 实践中的BMA：从MCMC到[深度学习](@entry_id:142022)

计算精确的BMA权重和预测可能在计算上非常困难，特别是对于当今科学中使用的复杂模型。但其原理如此强大，以至于科学家们已经开发出巧妙的方法来近似它。在许多领域，研究人员使用像[马尔可夫链蒙特卡洛](@entry_id:138779)（MCMC）这样的方法在可能的[模型空间](@entry_id:635763)中游走，以与其后验概率成正比的频率访问每个模型。通过计算MCMC链访问每个模型的次数，我们可以直接估计BMA权重 。在其他情况下，使用一种称为[变分贝叶斯](@entry_id:756437)（Variational Bayes）的近似方法，BMA权重结果与每个模型的[证据下界](@entry_id:634110)（ELBO）有着优美的关系，而ELBO是在模型训练过程中常规优化的一个量 。

也许最令人惊讶的是，这个百年历史的思想在现代人工智能的核心地带找到了新的生命。用于训练[深度神经网络](@entry_id:636170)的流行技术“dropout”，即在训练过程中暂时忽略随机神经元，可以被重新解释。通过在预测时保持dropout激活状态，并使用不同的随机dropout掩码进行多次预测，我们实际上是在执行贝叶斯[模型平均](@entry_id:635177)的近似。这种被称为MC Dropout的技术，使我们能够从即便是最大的神经网络中获得[不确定性估计](@entry_id:191096)，揭示了网络方差（其认知不确定性的度量）如何随dropout率变化 。

从其基于简单概率规则的基础，到其在尖端人工智能中的现代应用，贝叶斯[模型平均](@entry_id:635177)为科学最根本的挑战之一——如何在不确定性面前进行推理和预测——提供了一个深刻而连贯的答案。它教导我们，真正的智慧不在于找到那个唯一的、“真实”的模型，而在于优雅地结合我们能讲述的关于世界的所有貌似合理的故事中的见解。

