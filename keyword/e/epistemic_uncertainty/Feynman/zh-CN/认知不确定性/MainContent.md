## 引言
不确定性是科学与工程中一个无法逃避且根本性的方面。它并非一个需要被消除的缺陷，而是我们理解的前沿。然而，为了取得有意义的进展、建立可靠的模型并做出合理的决策，我们必须认识到并非所有的不确定性都是相同的。一个关键的知识鸿沟常常在于未能区分可减少的无知和系统固有的随机性。本文将直面这一挑战。首先，文章将深入探讨“原理与机制”，定义并对比认知不确定性（我们知识的缺乏）和[偶然不确定性](@entry_id:634772)（世界内在的变异性）。随后，“应用与跨学科联系”部分将展示这一关键区别如何成为一个强大的工具，用于构建更安全的系统、进行更精锐的科学研究，以及做出更符合伦理的选择。我们首先从探索这两种无知的面貌之间的根本区别开始。

## 原理与机制

在我们理解世界的探索中，我们不断面临不确定性。这是科学的一个基本组成部分，不是一个令人尴尬的缺陷，而是一个有待探索的前沿。然而，并非所有的不确定性都是一样的。为了取得进展、建立可靠的模型并做出合理的决策，我们必须首先学会区分我们的不确定性。我们能做的最深刻的区分，是在两种[基本类](@entry_id:158335)型的无知之间：一种是宇宙固有的特性，另一种是我们自身有限心智的特性。

### 两种不确定性的故事

想象一下，你被要求预测一次硬币抛掷的结果。你知道这枚硬币是完全公平的。结果是正面还是反面，是不确定的。但这种不确定性是由于事件本身的内在随机性。即使拥有完美的物理学知识，硬币的初始条件也如此敏感，以至于从所有实际角度来看，其结果是不可预测的。这就是**[偶然不确定性](@entry_id:634772)**（aleatoric uncertainty），源自拉丁语 *alea*，意为“骰子”。它是一个系统不可减少的、内在的变异性——一种基本的随机性嗡鸣，我们可以用概率来描述它，但对于单个事件，我们永远无法使其静音。

现在，想象一个不同的游戏。有人递给你一枚奇怪的、不平衡的硬币，再次要求你预测抛掷结果。这里的不确定性感觉不同。它不仅仅关乎抛掷的随机性，还关乎你对这枚硬币本身的深切无知。它有偏向吗？偏向多少？这就是**认知不确定性**（epistemic uncertainty），源自希腊语 *episteme*，意为“知识”。这是由于*知识缺乏*而产生的不确定性。这是一片我们希望能够驱散的无知之雾。原则上，我们可以通过收集更多信息来减少这种不确定性——抛掷硬币数百次来估计其偏向，或者对其[质心](@entry_id:138352)进行精确的物理测量。

这一区别是解开整个[不确定性量化](@entry_id:138597)领域的钥匙。[偶然不确定性](@entry_id:634772)是我们观察的系统的属性；认知不确定性是我们关于该系统知识的属性。

### 无知的剖析

在任何现实世界的科学模型中，这两种形式的不确定性都源于多种来源。学会识别它们是任何科学家或工程师的一项关键技能。

**偶然性来源：世界固有的随机性**

这些是变异性的来源，即使我们的模型和知识是完美的，它们也依然会存在。

*   **过程噪声**：许多物理系统本质上是随机的。[湍流](@entry_id:151300)阵风在桥梁上产生的力的逐次变化是[偶然不确定性](@entry_id:634772)的一个典型例子 。在[多孔材料](@entry_id:152752)中，由于热扰动，分子的随机碰撞为化学物质的输运贡献了“[过程噪声](@entry_id:270644)” 。在气候科学中，这表现为大气的“内部变率”——独立于我们的气候模型而存在的混乱、不可预测的天气模式 。

*   **[测量噪声](@entry_id:275238)**：我们进行的每一次测量都是不完美的。我们的仪器精度有限，并会受到随机波动的影响。传感器读数从来都不是纯粹的真相，而是真相加上一点随机噪声 $\varepsilon_k$。这种噪声通常被建模为从像高斯分布这样的分布中随机抽取，它是一种模糊我们对现实看法的[偶然不确定性](@entry_id:634772)  。

*   **内在模糊性**：有时，我们试图测量的事物本身就是模糊的。当放射科医生在医学图像中分割肿瘤时，由于组织对比度重叠或[图像分辨率](@entry_id:165161)有限，边界可能是内在模糊的。即使是不同的人类专家也可能在略有不同的地方画线。这种标注者之间的分歧是“基准真相”本身的一种偶然变异性 。

**认知性来源：我们知识的局限**

这些是不确定性的来源，原则上，我们可以通过收集更多数据、改进我们的模型或完善我们的理论来减少它们。

*   **参数不确定性**：我们的模型充满了参数——诸如弹簧的刚度 $k$、材料的扩散系数 $D$ 或生物[反应速率](@entry_id:185114) $\theta$ 等常数。我们通常不知道它们的精确值。我们可能会使用手册中的值作为弹簧刚度，但那是一个平均值；它可能不是*我们特定弹簧*的精确值 。当我们为一个单一、固定的样本建立模型时，我们对其固定但未知参数的不确定性是认知性的。我们可以通过对该样本进行更多校准实验来减少它 。这引出了一个极其微妙的观点：如果你正在研究一个样本*群体*，那么参数在该群体中的自然变异是偶然性的。但如果你正在研究*一个特定*的样本，你对其独特、固定参数值的不确定性是认知性的 。

*   **结构不确定性**：这也许是认知不确定性最深刻的来源。它是一种谦卑的承认：“所有模型都是错的，但有些是有用的。”我们的方程总是现实的简化。我们可能对一个根本上[非线性](@entry_id:637147)的过程使用[线性模型](@entry_id:178302)，或者我们粗粒度的模型可能忽略了在更小尺度上发生的复杂效应。我们模型的形式与现实的真[实形式](@entry_id:193866)之间的这种内在不匹配被称为**结构不确定性**或**模型差异**。这是我们知识结构本身的错误，它纯粹是认知性的。我们只能通过发明更好的理论或更全面的模型来减少它  。

*   **[数值不确定性](@entry_id:752838)**：当我们让计算机求解我们模型的方程时，我们引入了另一层近似。我们用有限的点网格来表示一个连续的对象，或者用离散的时间步长来表示一个连续的过程。计算机的答案与我们模型的真实数学解之间的差异是**[数值不确定性](@entry_id:752838)**。这是对我们（已经近似的）方程的精确解缺乏了解。这是一种认知不确定性，可以通过使用更多的计算能力——更精细的网格和更小的时间步长——来系统地减少 。

### 概率的语言：为不确定性[发声](@entry_id:908770)

为了严谨地处理这些不确定性，我们转向概率论的语言。然而，我们使用这种语言的方式，对于这两种不确定性类型是根本不同的。

我们通过在我们的世界模型中直接构建一个概率分布来表示**[偶然不确定性](@entry_id:634772)**。对于一个确定性OD[E模](@entry_id:160271)型 $x'(t) = f(x(t), \theta)$，其状态是通过带噪声的测量得到的，ODE本身是确定性的。随机性来自测量过程，$y_k = h(x(t_k)) + \epsilon_k$。[偶然不确定性](@entry_id:634772)完全由噪声项 $\epsilon_k$ 的概率分布来捕捉。这个分布定义了**[似然函数](@entry_id:921601)** $p(\text{data} | \text{model})$，它告诉我们，在给定模型的特定版本下，我们观测到的数据有多大概率出现 。

另一方面，我们通过对模型中我们不知道的部分放置概率分布来表示**认知不确定性**。如果我们对参数 $\theta$ 不确定，我们不把它当作一个单一的数字，而是当作一个[随机变量](@entry_id:195330)。我们在看到任何数据*之前*分配给它的分布称为**[先验分布](@entry_id:141376)** $p(\theta)$。它代表了我们最初的信念或无知状态。在我们收集数据后，我们使用**[贝叶斯法则](@entry_id:275170)**的魔力来更新我们的信念。先验与似然相结合，产生**[后验分布](@entry_id:145605)** $p(\theta | \text{data})$。这个[后验分布](@entry_id:145605)代表了我们新的、更精确的知识状态，并且通常比先验更“尖锐”，反映了我们认知不确定性的减少。

这个框架最终形成了一幅美丽而强大的图景，用于进行预测。为了预测一个新的结果，我们必须对*所有*不确定性的来源进行平均。这是通过[全概率定律](@entry_id:268479)完成的，其形式为一个嵌套积分。例如，在一个预测罕见事件的数字孪生中，总的[失效率](@entry_id:266388)是通过首先对*固定*模型参数 $\theta$ 的偶然噪声进行平均，然后将结果在所有可能的 $\theta$ 值上进行平均，并用我们对它们的后验信念加权得到的 ：
$$
P(\text{failure} | \text{data}) = \int \underbrace{\left[ \int \mathbb{I}(\text{failure} | \theta, \epsilon) p(\epsilon) d\epsilon \right]}_{\text{对偶然噪声求平均}} \underbrace{p(\theta | \text{data}) d\theta}_{\text{对认知不确定性求平均}}
$$
这个优雅的公式展示了无知的两副面孔如何统一起来，产生一个单一、诚实的预测，该预测考虑了我们所不知道的一切。更高级的模型甚至可以在积分内部包含一个结构不确定性项 $\delta(x)$，对我们模型形式本身的不确定性进行平均 。

### 科学模型中怀疑的印记

认知不确定性在我们的工作中实际上是如何体现的？它留下了独特的印记，如果正确解读，可以指导我们的科学探究。

最引人注目的例子之一来自[现代机器学习](@entry_id:637169)。一个像[高斯过程](@entry_id:182192)这样的高级模型，在数据上训练后，不仅可以提供预测，还可以提供其自身置信度的度量。在输入空间中它见过大量数据的区域，其预测不确定性会很低。但如果你要求它在远离任何训练数据的区域进行预测，它会有效地告诉你：“我不知道”，并且其预测方差会膨胀。这种巨大的方差是认知不确定性的直接可视化，是模型本身插上的一面警示旗，表明知识的缺乏 。

一个更深刻的印记出现在[贝叶斯模型选择](@entry_id:147207)中。想象你有两个相互竞争的科学理论，模型1和模型2，用来解释一个数据集。在进行[贝叶斯分析](@entry_id:271788)后，你发现[后验概率](@entry_id:153467)在它们之间平分——两个模型看起来几乎同样可信。[后验分布](@entry_id:145605)是双峰的，每个模型都有一个峰值。这并不意味着宇宙在两种物理定律之间[随机切换](@entry_id:197998)！这是一个深刻的认知模糊性的印记：你当前的数据不足以区分这两种相互竞争的理论 。这不是失败；这是一个发现。这种不确定性的结构为下一步该做什么提供了路[线图](@entry_id:264599)。减少这种认知不确定性的最有效方法是设计一个新的实验，在这个实验中，两个模型做出截然不同的预测。在该区域的观察很可能会消除其中一个后验峰值，解决我们的模糊性，并推动科学进步 。

这直接与统计学中熟悉的**泛化**和**偏差-方差权衡**概念相联系。预测模型的总误差可以被分解。我们无论拥有多少数据都无法摆脱的部分是[偶然不确定性](@entry_id:634772)（$\operatorname{Var}(Y|X)$）。其余的误差是认知性的。它包括模型的“方差”（如果用不同的随机数据子集训练，模型的预测会改变多少，这是由于数据有限造成的）和它的“偏差”（由于模型对于现实世界的复杂性来说过于简单而导致的系统性误差，这是[模型结构不确定性](@entry_id:1128051)）。增加数据量或改进模型类别可以减少这些认知误差分量，但偶然噪声的基底仍然存在 。

### 为什么这种区分很重要

区分[偶然不确定性](@entry_id:634772)和认知不确定性不仅仅是一个学术练习。它是科学家或工程师可以做的最实际、哲学上最重要的事情之一。它告诉我们应该把精力集中在哪里。

如果我们的预测主要由认知不确定性主导，我们知道我们可以做得更好。我们可以收集更多数据来确定我们的参数。我们可以设计更巧妙的实验来区分相互竞争的模型。我们可以回到绘图板，发展一个更复杂的理论来减少结构误差。

但如果我们的预测主要由[偶然不确定性](@entry_id:634772)主导，我们学到的东西同样重要：我们已经达到了一个基本的极限。再多关于一枚公平硬币参数的数据，也不会改善我们对下一次单次抛掷的预测。在这一点上，任务从减少不确定性转变为管理它——构建在面对不可减少的随机性时具有鲁棒性和弹性的系统。

通过学会区分世界中的随机性与我们头脑中的缺失，我们不仅了解了我们知识的局限，也找到了扩展知识的最清晰的路径。

