{"hands_on_practices": [{"introduction": "The strong Markov property allows for powerful and elegant arguments that are often not immediately obvious. This first practice exercise guides you through the derivation of the famous reflection principle for Brownian motion. By applying the strong Markov property at the first time the process hits a certain level, we can establish a surprising symmetry that allows us to compute the distribution of the maximum of a Brownian path over a finite time interval [@problem_id:2986626].", "problem": "Let $B=\\{B_{s}: s\\ge 0\\}$ be a one-dimensional standard Brownian motion (also called a Wiener process) started at $B_{0}=0$ on a filtered probability space $(\\Omega,\\mathcal{F},\\{\\mathcal{F}_{s}\\}_{s\\ge 0},\\mathbb{P})$ satisfying the usual conditions. Fix $a0$ and $t0$, and define the first hitting time of the level $a$ by\n$$\n\\tau_{a} := \\inf\\{s\\ge 0: B_{s}=a\\}.\n$$\nThe strong Markov property asserts that for any stopping time $\\tau$ with respect to the natural filtration of $B$, the shifted process $\\{B_{\\tau+s}-B_{\\tau}: s\\ge 0\\}$ is a Brownian motion independent of $\\mathcal{F}_{\\tau}$. Using only the fundamental properties of Brownian motion (independent and stationary Gaussian increments, continuity of paths, symmetry of the Gaussian distribution) and the strong Markov property at $\\tau_{a}$, derive a rigorous reflection argument that relates the law of $B_{t}$ on the event $\\{\\tau_{a}\\le t\\}$ to its reflection across the level $a$. Then use this reflection argument to compute the probability\n$$\n\\mathbb{P}\\Big(\\sup_{0\\le s\\le t} B_{s} \\ge a\\Big).\n$$\nYour final answer must be given in closed form as a single analytic expression. If you choose to express your answer in terms of the standard normal cumulative distribution function (CDF), define it precisely in your derivation.", "solution": "The problem asks for the probability $\\mathbb{P}(\\sup_{0\\le s\\le t} B_{s} \\ge a)$ for a standard one-dimensional Brownian motion $B_s$ starting at $B_0=0$, where $a0$ and $t0$ are fixed constants.\n\nFirst, we establish the equivalence between the event of the supremum reaching $a$ and the event of the first hitting time of $a$ occurring by time $t$. Let $\\tau_a = \\inf\\{s \\ge 0 : B_s = a\\}$. The paths of a Brownian motion are continuous almost surely. By the definition of the supremum, if $\\sup_{0\\le s\\le t} B_s \\ge a$, then for any $\\epsilon  0$, there exists an $s_0 \\in [0, t]$ such that $B_{s_0}  a-\\epsilon$. By continuity of paths, and since $B_0 = 0  a$, the Intermediate Value Theorem implies that the process must take the value $a$ at some time $s^* \\le s_0 \\le t$. Therefore, $\\tau_a = \\inf\\{s \\ge 0: B_s = a\\} \\le t$. Conversely, if $\\tau_a \\le t$, then there is a time $s \\in [0,t]$ such that $B_s=a$, which implies that $\\sup_{0\\le u\\le t} B_u \\ge a$. Thus, the two events are the same, and we have\n$$\n\\mathbb{P}\\Big(\\sup_{0\\le s\\le t} B_{s} \\ge a\\Big) = \\mathbb{P}(\\tau_a \\le t).\n$$\nTo compute $\\mathbb{P}(\\tau_a \\le t)$, we employ the reflection principle, which we derive using the strong Markov property of Brownian motion. We partition the event $\\{\\tau_a \\le t\\}$ into two disjoint events based on the value of $B_t$:\n$$\nE_1 = \\{\\tau_a \\le t \\text{ and } B_t \\ge a\\}\n$$\n$$\nE_2 = \\{\\tau_a \\le t \\text{ and } B_t  a\\}\n$$\nSince the distribution of $B_t$ is continuous, $\\mathbb{P}(B_t=a)=0$, so we do not need to consider this case separately in the partition. We have\n$$\n\\mathbb{P}(\\tau_a \\le t) = \\mathbb{P}(E_1) + \\mathbb{P}(E_2).\n$$\nThe reflection argument rests on proving that $\\mathbb{P}(E_1) = \\mathbb{P}(E_2)$. To establish this, we use the strong Markov property at the stopping time $\\tau_a$. This property states that the process $W_s = B_{\\tau_a+s} - B_{\\tau_a}$ for $s \\ge 0$ is a standard Brownian motion and is independent of the pre-$\\tau_a$ sigma-algebra $\\mathcal{F}_{\\tau_a}$.\n\nOn the event $\\{\\tau_a \\le t\\}$, we have $B_{\\tau_a} = a$ almost surely due to the continuity of paths. We can express $B_t$ for $t \\ge \\tau_a$ as:\n$$\nB_t = B_{\\tau_a + (t-\\tau_a)} = B_{\\tau_a} + (B_{\\tau_a+(t-\\tau_a)} - B_{\\tau_a}) = a + W_{t-\\tau_a}.\n$$\nNow we analyze the probability of $E_2$:\n$$\n\\mathbb{P}(E_2) = \\mathbb{P}(\\tau_a \\le t \\text{ and } B_t  a) = \\mathbb{P}(\\tau_a \\le t \\text{ and } a + W_{t-\\tau_a}  a) = \\mathbb{P}(\\tau_a \\le t \\text{ and } W_{t-\\tau_a}  0).\n$$\nUsing the law of total expectation by conditioning on the sigma-algebra $\\mathcal{F}_{\\tau_a}$:\n$$\n\\mathbb{P}(E_2) = \\mathbb{E}\\big[\\mathbb{P}(E_2 | \\mathcal{F}_{\\tau_a})\\big] = \\mathbb{E}\\big[\\mathbf{1}_{\\{\\tau_a \\le t\\}} \\mathbb{P}(W_{t-\\tau_a}  0 | \\mathcal{F}_{\\tau_a})\\big].\n$$\nSince $\\tau_a$ is $\\mathcal{F}_{\\tau_a}$-measurable, we can treat its value as fixed inside the conditional probability. The process $W$ is independent of $\\mathcal{F}_{\\tau_a}$. Let $u=t-\\tau_a$. On the event $\\{\\tau_a \\le t\\}$, $u \\ge 0$. If $\\tau_a  t$, then $u  0$, and $W_u \\sim N(0, u)$. By the symmetry of the Gaussian distribution about its mean of $0$, $\\mathbb{P}(W_u  0) = 1/2$. If $\\tau_a = t$, the condition becomes $W_0  0$, which is $00$, an impossible event. However, $\\mathbb{P}(\\tau_a=t)=0$ (a non-trivial result related to the law of the iterated logarithm, but can be accepted here). Thus, we can proceed:\n$$\n\\mathbb{P}(W_{t-\\tau_a}  0 | \\mathcal{F}_{\\tau_a}) = \\frac{1}{2} \\quad \\text{a.s. on } \\{\\tau_a  t\\}.\n$$\nSo, $\\mathbb{P}(E_2) = \\mathbb{E}\\left[\\mathbf{1}_{\\{\\tau_a \\le t\\}} \\cdot \\frac{1}{2}\\right] = \\frac{1}{2} \\mathbb{P}(\\tau_a \\le t)$.\n\nA similar calculation for $E_1$ gives:\n$$\n\\mathbb{P}(E_1) = \\mathbb{P}(\\tau_a \\le t \\text{ and } B_t \\ge a) = \\mathbb{P}(\\tau_a \\le t \\text{ and } W_{t-\\tau_a} \\ge 0).\n$$\n$$\n\\mathbb{P}(E_1) = \\mathbb{E}\\big[\\mathbf{1}_{\\{\\tau_a \\le t\\}} \\mathbb{P}(W_{t-\\tau_a} \\ge 0 | \\mathcal{F}_{\\tau_a})\\big].\n$$\nBy symmetry, $\\mathbb{P}(W_{t-\\tau_a} \\ge 0 | \\mathcal{F}_{\\tau_a}) = 1/2$ (since the probability of being exactly $0$ is $0$). Thus, $\\mathbb{P}(E_1) = \\frac{1}{2} \\mathbb{P}(\\tau_a \\le t)$.\nThis derivation rigorously shows that $\\mathbb{P}(E_1) = \\mathbb{P}(E_2)$. This equality is the essence of the reflection principle. It shows that conditioned on having hit level $a$ by time $t$, the process $B_t$ is equally likely to be above or below $a$. This relates the law of $B_t$ on $\\{\\tau_a \\le t\\}$ to its reflection, as requested.\n\nNow we use this result to compute the desired probability. From $\\mathbb{P}(\\tau_a \\le t) = \\mathbb{P}(E_1) + \\mathbb{P}(E_2)$ and $\\mathbb{P}(E_1)=\\mathbb{P}(E_2)$, we get\n$$\n\\mathbb{P}(\\tau_a \\le t) = 2 \\mathbb{P}(E_1) = 2 \\mathbb{P}(\\tau_a \\le t, B_t \\ge a).\n$$\nNext, we simplify the event $\\{\\tau_a \\le t, B_t \\ge a\\}$. Consider the event $\\{B_t \\ge a\\}$. Since $B_0=0$ and $a0$, for any path where $B_t \\ge a$, the path must have crossed the level $a$ at some time $s \\in [0,t]$ by the Intermediate Value Theorem for continuous functions. The first such time is $\\tau_a$, so we must have $\\tau_a \\le t$. Therefore, the event $\\{B_t \\ge a\\}$ is a subset of $\\{\\tau_a \\le t\\}$. This implies:\n$$\n\\{\\tau_a \\le t\\} \\cap \\{B_t \\ge a\\} = \\{B_t \\ge a\\}.\n$$\nSo, we have the equality of events $E_1 = \\{B_t \\ge a\\}$. This leads to\n$$\n\\mathbb{P}(\\tau_a \\le t) = 2 \\mathbb{P}(B_t \\ge a).\n$$\nThe final step is to calculate $\\mathbb{P}(B_t \\ge a)$. A standard one-dimensional Brownian motion $B_t$ started at $0$ has a Gaussian distribution with mean $0$ and variance $t$, i.e., $B_t \\sim N(0,t)$. Let $Z = B_t/\\sqrt{t}$ be a standard normal random variable, $Z \\sim N(0,1)$.\n$$\n\\mathbb{P}(B_t \\ge a) = \\mathbb{P}\\left(\\frac{B_t}{\\sqrt{t}} \\ge \\frac{a}{\\sqrt{t}}\\right) = \\mathbb{P}\\left(Z \\ge \\frac{a}{\\sqrt{t}}\\right).\n$$\nLet us define the cumulative distribution function (CDF) of the standard normal distribution as\n$$\n\\Phi(x) = \\mathbb{P}(Z \\le x) = \\int_{-\\infty}^{x} \\frac{1}{\\sqrt{2\\pi}} \\exp\\left(-\\frac{z^2}{2}\\right) dz.\n$$\nThen, $\\mathbb{P}(Z \\ge y) = 1 - \\mathbb{P}(Z  y) = 1 - \\Phi(y)$. So,\n$$\n\\mathbb{P}(B_t \\ge a) = 1 - \\Phi\\left(\\frac{a}{\\sqrt{t}}\\right).\n$$\nSubstituting this back into our main result, we obtain the final answer:\n$$\n\\mathbb{P}\\Big(\\sup_{0\\le s\\le t} B_{s} \\ge a\\Big) = 2 \\mathbb{P}(B_t \\ge a) = 2 \\left(1 - \\Phi\\left(\\frac{a}{\\sqrt{t}}\\right)\\right).\n$$", "answer": "$$\\boxed{2\\left(1 - \\Phi\\left(\\frac{a}{\\sqrt{t}}\\right)\\right)}$$", "id": "2986626"}, {"introduction": "Building on the use of stopping times, this exercise tackles a classic question: what is the probability that a Brownian motion exits an interval through a specified boundary? This is the continuous-time analogue of the famous \"gambler's ruin\" problem. By skillfully applying the Optional Stopping Theorem to the Brownian motion martingale itself, you will derive a simple and linear relationship for this probability, showcasing the practical power of martingale methods in solving exit problems [@problem_id:2986583].", "problem": "Let $\\{W_{t}\\}_{t \\geq 0}$ be a one-dimensional standard Brownian motion starting at $W_{0} = x$ with $x \\in (a,b)$, where $a  b$ are fixed real numbers. Define the first hitting times $\\tau_{a} := \\inf\\{t \\geq 0 : W_{t} = a\\}$ and $\\tau_{b} := \\inf\\{t \\geq 0 : W_{t} = b\\}$, and let $\\tau := \\tau_{a} \\wedge \\tau_{b}$. Denote by $\\mathbb{P}_{x}$ the law of the process when $W_{0} = x$. Using only the defining properties of Brownian motion, the strong Markov property, and fundamental martingale facts for Brownian motion, derive the analytic expression for the probability $\\mathbb{P}_{x}(\\tau_{a}  \\tau_{b})$. In your derivation, justify any use of stopping times and limiting arguments that involve stopping times by appealing to standard conditions under which the Optional Stopping Theorem holds. Conclude by showing that this probability is a linear function of $x$. Express your final answer as a single simplified closed-form expression in terms of $a$, $b$, and $x$. No rounding is required.", "solution": "Let $\\{W_{t}\\}_{t \\geq 0}$ be a one-dimensional standard Brownian motion starting at $W_{0} = x$, with $x \\in (a,b)$ for fixed real numbers $a  b$. The filtration generated by the process is denoted by $\\{\\mathcal{F}_{t}\\}_{t \\geq 0}$, where $\\mathcal{F}_{t} = \\sigma(W_{s} : s \\leq t)$. The governing probability measure is $\\mathbb{P}_{x}$. We wish to find the probability $p(x) := \\mathbb{P}_{x}(\\tau_{a}  \\tau_{b})$, where $\\tau_{a} := \\inf\\{t \\geq 0 : W_{t} = a\\}$ and $\\tau_{b} := \\inf\\{t \\geq 0 : W_{t} = b\\}$ are the first hitting times of $a$ and $b$ respectively.\n\nThe derivation will proceed by applying the Optional Stopping Theorem to the martingale $M_{t} = W_{t}$ and the stopping time $\\tau = \\tau_{a} \\wedge \\tau_{b}$.\n\nFirst, we establish that $\\{W_t\\}_{t \\ge 0}$ is a martingale with respect to the filtration $\\{\\mathcal{F}_t\\}_{t \\ge 0}$ under the measure $\\mathbb{P}_x$. For any $s  t$, we must show that $\\mathbb{E}_{x}[W_{t} | \\mathcal{F}_{s}] = W_{s}$.\nBy the properties of conditional expectation and the definition of Brownian motion, we have:\n$$\n\\mathbb{E}_{x}[W_{t} | \\mathcal{F}_{s}] = \\mathbb{E}_{x}[W_{s} + (W_{t} - W_{s}) | \\mathcal{F}_{s}] = W_{s} + \\mathbb{E}_{x}[W_{t} - W_{s} | \\mathcal{F}_{s}]\n$$\nThe increment $W_{t} - W_{s}$ is independent of the past information contained in $\\mathcal{F}_{s}$. Therefore, the conditional expectation is equal to the unconditional expectation:\n$$\n\\mathbb{E}_{x}[W_{t} - W_{s} | \\mathcal{F}_{s}] = \\mathbb{E}_{x}[W_{t} - W_{s}]\n$$\nA standard Brownian motion has increments with mean zero, so $\\mathbb{E}_{x}[W_{t} - W_{s}] = 0$. Thus, we have:\n$$\n\\mathbb{E}_{x}[W_{t} | \\mathcal{F}_{s}] = W_{s} + 0 = W_{s}\n$$\nThis confirms that $\\{W_{t}\\}_{t \\geq 0}$ is a martingale under $\\mathbb{P}_{x}$.\n\nNext, we define the stopping time $\\tau = \\tau_{a} \\wedge \\tau_{b}$. This is the first time the process $W_{t}$ exits the open interval $(a,b)$. To verify that $\\tau$ is a stopping time, we must show that the event $\\{\\tau \\leq t\\}$ is in $\\mathcal{F}_{t}$ for all $t \\geq 0$. The event $\\{\\tau \\leq t\\}$ can be written as:\n$$\n\\{\\tau \\leq t\\} = \\{ \\inf_{0 \\leq s \\leq t} W_{s} \\leq a \\} \\cup \\{ \\sup_{0 \\leq s \\leq t} W_{s} \\geq b \\}\n$$\nSince the paths of a Brownian motion are continuous functions, the infimum and supremum over a closed interval $[0,t]$ are $\\mathcal{F}_{t}$-measurable random variables. The union of two $\\mathcal{F}_{t}$-measurable sets is also $\\mathcal{F}_{t}$-measurable. Hence, $\\tau$ is a stopping time with respect to $\\{\\mathcal{F}_{t}\\}$.\n\nWe now apply the Optional Stopping Theorem. The theorem states that for a martingale $M_{t}$ and a stopping time $T$, under certain conditions, $\\mathbb{E}[M_{T}] = \\mathbb{E}[M_{0}]$. We must justify that these conditions hold for $M_{t} = W_{t}$ and $T = \\tau$.\nA sufficient set of conditions is that $\\mathbb{P}_{x}(\\tau  \\infty) = 1$ and that the stopped process $W_{t \\wedge \\tau}$ is uniformly integrable.\n\nThe probability that a one-dimensional Brownian motion remains within a finite interval for all time is zero. That is, $\\mathbb{P}_{x}(\\tau = \\infty) = 0$, which implies $\\mathbb{P}_{x}(\\tau  \\infty) = 1$.\n\nNow, we examine the stopped process $\\{W_{t \\wedge \\tau}\\}_{t \\geq 0}$. For any time $s  \\tau$, by the definition of $\\tau$, the process value $W_{s}$ is strictly between $a$ and $b$. Due to the continuity of Brownian paths, at the very instant of stopping, $W_{\\tau}$ must be equal to either $a$ or $b$. Consequently, for any $t \\geq 0$, the value of the stopped process $W_{t \\wedge \\tau}$ is always contained in the closed interval $[a,b]$. This means the random variables $W_{t \\wedge \\tau}$ are uniformly bounded:\n$$\na \\leq W_{t \\wedge \\tau} \\leq b \\quad \\forall t \\geq 0\n$$\nwhich implies $|W_{t \\wedge \\tau}| \\leq \\max(|a|,|b|)$. A family of random variables that is uniformly bounded is also uniformly integrable. Doob's Optional Stopping Theorem in one of its common forms states that for a uniformly integrable martingale, the expectation is preserved at a stopping time.\nAlternatively, and more directly, we can use a limiting argument. For any fixed time $T_{0}  0$, the stopped process $W_{t \\wedge T_{0}}$ is a bounded martingale, so $\\mathbb{E}_{x}[W_{T_{0} \\wedge \\tau}] = \\mathbb{E}_{x}[W_{0}] = x$. We wish to let $T_{0} \\to \\infty$. We have established that $\\tau  \\infty$ almost surely, so as $T_{0} \\to \\infty$, $T_{0} \\wedge \\tau \\to \\tau$ almost surely. By the path continuity of Brownian motion, $W_{T_{0} \\wedge \\tau} \\to W_{\\tau}$ almost surely.\nSince the random variables $\\{W_{T_{0} \\wedge \\tau}\\}_{T_{0} \\geq 0}$ are uniformly bounded by $\\max(|a|,|b|)$, we can apply the Bounded Convergence Theorem to exchange the limit and expectation:\n$$\n\\mathbb{E}_{x}[W_{\\tau}] = \\mathbb{E}_{x}[\\lim_{T_{0} \\to \\infty} W_{T_{0} \\wedge \\tau}] = \\lim_{T_{0} \\to \\infty} \\mathbb{E}_{x}[W_{T_{0} \\wedge \\tau}]\n$$\nSince $\\mathbb{E}_{x}[W_{T_{0} \\wedge \\tau}] = x$ for all $T_{0}$, the limit is also $x$. Therefore, we have established:\n$$\n\\mathbb{E}_{x}[W_{\\tau}] = x\n$$\nNow, we compute this expectation in another way. The random variable $W_{\\tau}$ can only take values $a$ or $b$ (the event $\\tau_{a} = \\tau_{b}$ has probability $0$). Its distribution is given by:\n$\\mathbb{P}_{x}(W_{\\tau} = a) = \\mathbb{P}_{x}(\\tau_{a}  \\tau_{b}) = p(x)$\n$\\mathbb{P}_{x}(W_{\\tau} = b) = \\mathbb{P}_{x}(\\tau_{b} \\leq \\tau_{a}) = 1 - p(x)$\nThe expectation of $W_{\\tau}$ is therefore:\n$$\n\\mathbb{E}_{x}[W_{\\tau}] = a \\cdot \\mathbb{P}_{x}(W_{\\tau} = a) + b \\cdot \\mathbb{P}_{x}(W_{\\tau} = b) = a \\cdot p(x) + b \\cdot (1 - p(x))\n$$\nEquating the two expressions for $\\mathbb{E}_{x}[W_{\\tau}]$:\n$$\nx = a \\cdot p(x) + b - b \\cdot p(x)\n$$\nWe now solve for $p(x)$:\n$$\nx - b = p(x) (a - b)\n$$\n$$\np(x) = \\frac{x-b}{a-b}\n$$\nThis expression can be simplified by multiplying the numerator and denominator by $-1$:\n$$\np(x) = \\frac{-(b-x)}{-(b-a)} = \\frac{b-x}{b-a}\n$$\nThis is the analytic expression for the probability $\\mathbb{P}_{x}(\\tau_{a}  \\tau_{b})$. We can rewrite this expression as:\n$$\np(x) = \\left(\\frac{-1}{b-a}\\right)x + \\frac{b}{b-a}\n$$\nThis shows that $p(x)$ is a linear function of the starting position $x$. The slope is $\\frac{-1}{b-a}$ and the intercept is $\\frac{b}{b-a}$. The derivation adheres to the use of martingale properties and the Optional Stopping Theorem as required.", "answer": "$$\\boxed{\\frac{b-x}{b-a}}$$", "id": "2986583"}, {"introduction": "Our final practice problem explores a different but equally fundamental consequence of the Markov property: its connection to differential equations. Instead of computing a probability, we will calculate the expected time it takes for a Brownian motion to exit a given interval. You will use the infinitesimal generator of the process and Dynkin’s formula to set up and solve a simple boundary value problem, providing a first glimpse into the powerful synergy between stochastic analysis and PDEs [@problem_id:2986589].", "problem": "Let $\\{B_{t}\\}_{t \\geq 0}$ be a standard one-dimensional Brownian motion started at $x \\in (a,b)$, where $a  b$ are fixed real numbers. Define the first exit time from the open interval $(a,b)$ by\n$$\n\\tau_{(a,b)} \\;=\\; \\inf\\{\\, t \\geq 0 \\,:\\, B_{t} \\notin (a,b) \\,\\}.\n$$\nDenote by $\\mathcal{L}$ the infinitesimal generator of Brownian motion, which acts on twice continuously differentiable functions $f \\in C^{2}(\\mathbb{R})$ by\n$$\n\\mathcal{L} f(y) \\;=\\; \\frac{1}{2}\\, f''(y).\n$$\nUsing the strong Markov property of Brownian motion and Dynkin’s formula for stopping times, derive the boundary value problem satisfied by the function\n$$\nu(y) \\;=\\; \\mathbb{E}_{y}\\!\\left[\\, \\tau_{(a,b)} \\,\\right], \\quad y \\in (a,b),\n$$\nand solve this boundary value problem to obtain an explicit expression for $u(x)$ in terms of $a$, $b$, and $x$. Your final answer must be a single closed-form analytic expression. No rounding is required.", "solution": "The problem asks for the expected first exit time of a standard one-dimensional Brownian motion from an open interval $(a,b)$, starting from a point $x \\in (a,b)$. Let $\\{B_t\\}_{t \\geq 0}$ be the Brownian motion, with $B_0 = y$. The function of interest is $u(y) = \\mathbb{E}_y[\\tau_{(a,b)}]$, where $\\tau_{(a,b)} = \\inf\\{ t \\geq 0 : B_t \\notin (a,b) \\}$. We are asked to derive the boundary value problem (BVP) that $u(y)$ satisfies, solve it, and provide the specific value $u(x)$.\n\nFirst, we derive the boundary value problem for $u(y)$. This consists of a differential equation on the interval $(a,b)$ and conditions at the boundaries $a$ and $b$.\n\nThe boundary conditions are determined by the definition of the stopping time $\\tau_{(a,b)}$. If the process starts at a boundary point, for instance $y=a$, it is already outside the open interval $(a,b)$. Thus, the first time $t \\geq 0$ for which $B_t \\notin (a,b)$ is $t=0$. Therefore, $\\tau_{(a,b)} = 0$ if the starting point is $a$ or $b$. By continuity of Brownian paths and the expected value operator, we can infer the boundary conditions for $u(y)$:\n$$ \\lim_{y \\to a^+} u(y) = \\mathbb{E}_a[\\tau_{(a,b)}] = 0 $$\n$$ \\lim_{y \\to b^-} u(y) = \\mathbb{E}_b[\\tau_{(a,b)}] = 0 $$\nSo, the boundary conditions are $u(a)=0$ and $u(b)=0$.\n\nA rigorous derivation of the differential equation relies on Dynkin's formula. Let $u(y)$ be the expected exit time. Assuming $u \\in C^2(a,b)$, Dynkin's formula for a stopping time $\\tau$ states:\n$$ \\mathbb{E}_y[u(B_\\tau)] = u(y) + \\mathbb{E}_y\\left[\\int_0^\\tau (\\mathcal{L}u)(B_s) ds\\right] $$\nLet $\\tau = \\tau_{(a,b)}$. On exit, $B_\\tau$ is either $a$ or $b$. At these points, the expected exit time is 0, so $u(B_\\tau) = 0$. Thus, $\\mathbb{E}_y[u(B_\\tau)] = 0$.\nThe formula becomes:\n$$ 0 = u(y) + \\mathbb{E}_y\\left[\\int_0^\\tau (\\mathcal{L}u)(B_s) ds\\right] $$\nThis equation relates the unknown function $u$ to its own generator. To solve this, we can postulate a relationship between the generator and a constant. Specifically, let's use the relationship that connects the generator to time itself, which arises from Itô's formula. A more intuitive approach (as used in many textbooks) is to apply Dynkin's formula to the function $f(y,t) = t$. The generator of the space-time process $(B_t, t)$ is $\\mathcal{G} = \\mathcal{L} + \\frac{\\partial}{\\partial t}$. Applying Dynkin's formula with $f(B_t, t) = t$ yields:\n$$ \\mathbb{E}_y[f(B_\\tau, \\tau)] = f(y,0) + \\mathbb{E}_y\\left[\\int_0^\\tau (\\mathcal{G}f)(B_s, s) ds\\right] $$\nHere, $f(B_\\tau, \\tau) = \\tau$ and $f(y,0)=0$. Also, $\\mathcal{G}f = (\\frac{1}{2}\\frac{\\partial^2}{\\partial y^2} + \\frac{\\partial}{\\partial t})t = 1$.\nThe equation becomes:\n$$ \\mathbb{E}_y[\\tau] = 0 + \\mathbb{E}_y\\left[\\int_0^\\tau 1 ds\\right] = \\mathbb{E}_y[\\tau] $$\nThis is a tautology and doesn't help find the equation for $u(y)$. The correct application of Dynkin's formula is to assume the form of the PDE for the expected time. The correct PDE for the mean exit time $u(y)$ is $\\mathcal{L}u(y) = -1$.\nLet's verify this. If we assume $\\mathcal{L}u(y) = -1$, then Dynkin's formula gives:\n$$ \\mathbb{E}_y[u(B_\\tau)] = u(y) + \\mathbb{E}_y\\left[\\int_0^\\tau (-1) ds\\right] = u(y) - \\mathbb{E}_y[\\tau] $$\nSince $u(B_\\tau) = 0$, we have $0 = u(y) - \\mathbb{E}_y[\\tau]$, which implies $u(y) = \\mathbb{E}_y[\\tau]$. This confirms that if a function $u(y)$ solves the BVP $\\mathcal{L}u = -1$ with $u(a)=u(b)=0$, it must be the mean exit time.\n\nThe complete boundary value problem is:\n$$ \\begin{cases} \\frac{1}{2} u''(y) = -1 \\implies u''(y) = -2,  y \\in (a,b) \\\\ u(a) = 0 \\\\ u(b) = 0 \\end{cases} $$\nWe now solve this BVP. Integrating the differential equation $u''(y) = -2$ with respect to $y$ gives:\n$$ u'(y) = -2y + C_1 $$\nIntegrating again:\n$$ u(y) = -y^2 + C_1 y + C_2 $$\nwhere $C_1$ and $C_2$ are constants of integration. We determine them using the boundary conditions:\n$$ u(a) = -a^2 + C_1 a + C_2 = 0 $$\n$$ u(b) = -b^2 + C_1 b + C_2 = 0 $$\nSubtracting the first equation from the second gives:\n$$ (-b^2 + a^2) + C_1(b-a) = 0 $$\n$$ -(b-a)(b+a) + C_1(b-a) = 0 $$\nSince $a  b$, $b-a \\neq 0$, so we can divide by $(b-a)$:\n$$ -(b+a) + C_1 = 0 \\implies C_1 = a+b $$\nSubstituting $C_1$ into the first boundary condition equation:\n$$ -a^2 + (a+b)a + C_2 = 0 \\implies -a^2 + a^2 + ab + C_2 = 0 \\implies C_2 = -ab $$\nThe solution to the BVP is:\n$$ u(y) = -y^2 + (a+b)y - ab $$\nThis can be factored as:\n$$ u(y) = -(y^2 - (a+b)y + ab) = -(y-a)(y-b) = (y-a)(b-y) $$\nThe problem specifies the starting point as $x \\in (a,b)$. So we substitute $y=x$ into our derived expression for $u(y)$:\n$$ u(x) = (x-a)(b-x) $$\nThis is the explicit expression for the expected first exit time.", "answer": "$$\n\\boxed{(x-a)(b-x)}\n$$", "id": "2986589"}]}