{"hands_on_practices": [{"introduction": "Before we can analyze the fine properties of a sample path, we must first establish its existence as a continuous function of time. This exercise [@problem_id:2994569] grounds our study by having you apply the powerful Kolmogorov's continuity theorem. By deriving bounds on the moments of a process's increments, you will see precisely why solutions to stochastic differential equations with well-behaved coefficients are guaranteed to have continuous versions, providing a solid foundation for all further path analysis.", "problem": "Consider a $d$-dimensional Itô diffusion $\\{X_{t}\\}_{t \\in [0,T]}$ defined on a complete filtered probability space $(\\Omega,\\mathcal{F},\\{\\mathcal{F}_{t}\\}_{t \\geq 0},\\mathbb{P})$ by the stochastic differential equation\n$$\ndX_{t} = b(X_{t})\\,dt + \\sigma(X_{t})\\,dW_{t}, \\quad X_{0} \\in \\mathbb{R}^{d},\n$$\nwhere $W_{t}$ is a standard $m$-dimensional Brownian motion and $b:\\mathbb{R}^{d} \\to \\mathbb{R}^{d}$ and $\\sigma:\\mathbb{R}^{d} \\to \\mathbb{R}^{d \\times m}$ satisfy the global Lipschitz and linear growth conditions:\n$$\n|b(x)-b(y)| + \\|\\sigma(x)-\\sigma(y)\\| \\leq L |x-y| \\quad \\text{for all } x,y \\in \\mathbb{R}^{d},\n$$\n$$\n|b(x)| + \\|\\sigma(x)\\| \\leq K (1+|x|) \\quad \\text{for all } x \\in \\mathbb{R}^{d},\n$$\nwith constants $L,K > 0$. Starting from Kolmogorov's continuity theorem and using only fundamental properties of Itô integrals, Brownian motion, and the stated Lipschitz and growth conditions, derive the minimal moment exponent in the sense of the infimum $p_{\\star}$ over all $p0$ such that one can guarantee the existence of a continuous version of $\\{X_{t}\\}_{t \\in [0,T]}$ on $[0,T]$ via moment increment bounds and Kolmogorov's criterion. Your final answer must be a single real number equal to that infimum $p_{\\star}$. No rounding is required.", "solution": "The problem requires the determination of the infimum $p_{\\star}$ of all positive exponents $p$ for which the existence of a continuous version of the Itô process $\\{X_t\\}_{t \\in [0,T]}$ can be proven using Kolmogorov's continuity theorem.\n\nKolmogorov's continuity theorem asserts that a stochastic process $\\{X_t\\}_{t \\in [0,T]}$ defined on a probability space $(\\Omega,\\mathcal{F},\\mathbb{P})$ possesses a continuous modification if there exist constants $C > 0$, $p > 0$, and $\\alpha > 0$ such that for all $s,t \\in [0,T]$, the following moment condition is satisfied:\n$$\n\\mathbb{E}[|X_t - X_s|^p] \\leq C |t-s|^{1+\\alpha}\n$$\nThe core of the task is to establish a bound on the $p$-th moment of the increment $|X_t - X_s|$ and to identify for which values of $p$ the resulting exponent of $|t-s|$ is strictly greater than $1$.\n\nThe Itô process $\\{X_t\\}$ is defined by the stochastic differential equation:\n$$\ndX_{t} = b(X_{t})\\,dt + \\sigma(X_{t})\\,dW_{t}\n$$\nFor any $s, t \\in [0,T]$ with $s  t$, the increment $X_t - X_s$ can be written in integral form as:\n$$\nX_t - X_s = \\int_s^t b(X_u)\\,du + \\int_s^t \\sigma(X_u)\\,dW_u\n$$\nWe need to estimate the $p$-th moment $\\mathbb{E}[|X_t - X_s|^p]$ for $p>0$. Using the inequality $|a+b|^p \\leq c_p(|a|^p + |b|^p)$, where $c_p = 2^{p-1}$ for $p \\geq 1$ and $c_p = 1$ for $0  p \\leq 1$, we can separate the contributions from the drift and diffusion terms:\n$$\n\\mathbb{E}[|X_t - X_s|^p] \\leq c_p \\left( \\mathbb{E}\\left[\\left|\\int_s^t b(X_u)\\,du\\right|^p\\right] + \\mathbb{E}\\left[\\left|\\int_s^t \\sigma(X_u)\\,dW_u\\right|^p\\right] \\right)\n$$\n\nFirst, we bound the drift term, $\\mathbb{E}\\left[\\left|\\int_s^t b(X_u)\\,du\\right|^p\\right]$. Using Hölder's inequality (or Jensen's inequality for integrals when $p \\geq 1$), we have:\n$$\n\\left|\\int_s^t b(X_u)\\,du\\right|^p \\leq \\left(\\int_s^t |b(X_u)|\\,du\\right)^p \\leq (t-s)^{p-1} \\int_s^t |b(X_u)|^p\\,du\n$$\nTaking the expectation and applying Fubini's theorem:\n$$\n\\mathbb{E}\\left[\\left|\\int_s^t b(X_u)\\,du\\right|^p\\right] \\leq (t-s)^{p-1} \\int_s^t \\mathbb{E}[|b(X_u)|^p]\\,du\n$$\nA standard result for SDEs with coefficients satisfying the global Lipschitz and linear growth conditions is that for any $q \\ge 1$ and $T>0$, the moments of $X_t$ are uniformly bounded on $[0,T]$, i.e., $\\sup_{t \\in [0,T]} \\mathbb{E}[|X_t|^q]  \\infty$. Given the linear growth condition $|b(x)| \\leq K(1+|x|)$, we have $|b(x)|^p \\leq K^p(1+|x|)^p \\leq c_p' K^p (1+|x|^p)$ for some constant $c_p'$. Consequently, $\\mathbb{E}[|b(X_u)|^p]$ is uniformly bounded on $[0,T]$ by some constant $C_{b,p,T}$.\n$$\n\\mathbb{E}\\left[\\left|\\int_s^t b(X_u)\\,du\\right|^p\\right] \\leq (t-s)^{p-1} \\int_s^t C_{b,p,T}\\,du = C_{b,p,T} (t-s)^p\n$$\nThis bound holds for $p \\geq 1$. A similar argument using Jensen's inequality for expectations demonstrates this bound also holds for $0  p  1$.\n\nSecond, we bound the diffusion term, $\\mathbb{E}\\left[\\left|\\int_s^t \\sigma(X_u)\\,dW_u\\right|^p\\right]$. We apply the Burkholder-Davis-Gundy (BDG) inequality, which states that for any $p > 0$, there exists a constant $C_p > 0$ such that:\n$$\n\\mathbb{E}\\left[\\left|\\int_s^t \\sigma(X_u)\\,dW_u\\right|^p\\right] \\leq C_p \\mathbb{E}\\left[ \\left( \\int_s^t \\|\\sigma(X_u)\\|^2\\,du \\right)^{p/2} \\right]\n$$\nwhere $\\|\\cdot\\|$ denotes the Frobenius norm on $\\mathbb{R}^{d \\times m}$. We now need to bound the right-hand side.\nIf $p \\geq 2$, then the exponent $p/2 \\geq 1$. By Hölder's inequality:\n$$\n\\left( \\int_s^t \\|\\sigma(X_u)\\|^2\\,du \\right)^{p/2} \\leq (t-s)^{p/2 - 1} \\int_s^t (\\|\\sigma(X_u)\\|^2)^{p/2}\\,du = (t-s)^{p/2-1} \\int_s^t \\|\\sigma(X_u)\\|^p\\,du\n$$\nTaking the expectation and using the uniform boundedness of moments of $\\sigma(X_u)$ (which follows from the linear growth condition on $\\sigma$ and moment bounds on $X_u$), we find a constant $C_{\\sigma,p,T}$:\n$$\n\\mathbb{E}\\left[ \\left( \\int_s^t \\|\\sigma(X_u)\\|^2\\,du \\right)^{p/2} \\right] \\leq (t-s)^{p/2-1} \\int_s^t \\mathbb{E}[\\|\\sigma(X_u)\\|^p]\\,du \\leq C_{\\sigma,p,T} (t-s)^{p/2}\n$$\nIf $0  p  2$, then the exponent $p/2 \\in (0,1)$. We can use Jensen's inequality for the concave function $z \\mapsto z^{p/2}$ on the expectation:\n$$\n\\mathbb{E}\\left[ \\left( \\int_s^t \\|\\sigma(X_u)\\|^2\\,du \\right)^{p/2} \\right] \\leq \\left( \\mathbb{E}\\left[ \\int_s^t \\|\\sigma(X_u)\\|^2\\,du \\right] \\right)^{p/2} = \\left( \\int_s^t \\mathbb{E}[\\|\\sigma(X_u)\\|^2]\\,du \\right)^{p/2}\n$$\nSince $\\mathbb{E}[\\|\\sigma(X_u)\\|^2]$ is uniformly bounded on $[0,T]$ by some constant $C'_{\\sigma,p,T}$, we get:\n$$\n\\left( \\int_s^t C'_{\\sigma,p,T}\\,du \\right)^{p/2} = (C'_{\\sigma,p,T}(t-s))^{p/2} = (C'_{\\sigma,p,T})^{p/2} (t-s)^{p/2}\n$$\nThus, for any $p > 0$, the diffusion term is bounded by a multiple of $(t-s)^{p/2}$:\n$$\n\\mathbb{E}\\left[\\left|\\int_s^t \\sigma(X_u)\\,dW_u\\right|^p\\right] \\leq K_p (t-s)^{p/2}\n$$\nfor some constant $K_p$.\n\nCombining the bounds for the drift and diffusion terms, we have for any $p>0$:\n$$\n\\mathbb{E}[|X_t - X_s|^p] \\leq c_p \\left( C_{b,p,T} (t-s)^p + K_p (t-s)^{p/2} \\right)\n$$\nFor small $|t-s| > 0$, the overall rate of convergence to zero is determined by the term with the smaller exponent. Since $p > p/2$ for all $p > 0$, the dominant term is $(t-s)^{p/2}$. Therefore, there exists a constant $C'_{p,T}$ such that for all $s,t \\in [0,T]$:\n$$\n\\mathbb{E}[|X_t - X_s|^p] \\leq C'_{p,T} |t-s|^{p/2}\n$$\nTo satisfy the condition of Kolmogorov's continuity theorem, the exponent of $|t-s|$ must be strictly greater than $1$. That is, we require:\n$$\n\\frac{p}{2} > 1 \\implies p > 2\n$$\nThis derivation shows that for any chosen moment exponent $p > 2$, we can establish the necessary bound $\\mathbb{E}[|X_t - X_s|^p] \\le C |t-s|^{1+\\alpha}$ with $1+\\alpha = p/2 > 1$, thus guaranteeing the existence of a continuous modification of $\\{X_t\\}$. The set of exponents $p$ for which this argument holds is $(2, \\infty)$. The problem asks for the infimum of this set.\nThe infimum of the set $(2, \\infty)$ is $2$.\nTherefore, the minimal moment exponent required by this method is $p_{\\star} = 2$.", "answer": "$$\\boxed{2}$$", "id": "2994569"}, {"introduction": "Knowing that a solution path is continuous is only the beginning; the next question is about its regularity. This practice [@problem_id:2994547] delves into the concept of $p$-variation, a tool for quantifying the \"roughness\" of a function. You will demonstrate that a solution to a typical SDE inherits the characteristic roughness of its driving Brownian motion, having finite variation only for exponents $p \\gt 2$, a property that marks a sharp departure from the smooth paths of deterministic calculus.", "problem": "Consider a one-dimensional stochastic differential equation (SDE) on a fixed finite horizon $[0,T]$ given by\n$$\ndX_{t} \\;=\\; b(X_{t})\\,dt \\;+\\; \\sigma(X_{t})\\,dW_{t}, \\qquad X_{0}\\in\\mathbb{R},\n$$\nwhere $W$ is a standard Brownian motion, and the drift $b:\\mathbb{R}\\to\\mathbb{R}$ and diffusion coefficient $\\sigma:\\mathbb{R}\\to\\mathbb{R}$ are globally Lipschitz and bounded functions. Let the sup norms be denoted by $\\|b\\|_{\\infty} := \\sup_{x\\in\\mathbb{R}} |b(x)|$ and $\\|\\sigma\\|_{\\infty} := \\sup_{x\\in\\mathbb{R}} |\\sigma(x)|$, and assume $T0$ is fixed.\n\nFor $p\\ge 1$, define the $p$-variation of a continuous function $Y:[0,T]\\to\\mathbb{R}$ by\n$$\nV_{p}(Y;[0,T]) \\;:=\\; \\sup_{\\Pi}\\;\\sum_{i=0}^{n-1} \\big| Y_{t_{i+1}} - Y_{t_{i}} \\big|^{p},\n$$\nwhere the supremum is taken over all finite partitions $\\Pi=\\{0=t_{0}t_{1}\\cdotst_{n}=T\\}$ of $[0,T]$.\n\nStarting from the decomposition of $X$ into its drift and martingale components, and using only foundational facts about bounded variation paths, continuous local martingales, and classical path properties of Brownian motion, do the following:\n\n1. Derive an almost sure upper bound on $V_{p}(X;[0,T])$ in terms of $V_{p}(W;[0,\\|\\sigma\\|_{\\infty}^{2}T])$, $T$, and the sup norms $\\|b\\|_{\\infty}$ and $\\|\\sigma\\|_{\\infty}$. Your bound should be explicit and obtained by first bounding the contribution of the drift path and then reducing the martingale part to a Brownian motion via a monotone time change.\n\n2. Determine the minimal threshold value $p_{\\star}$ such that, almost surely, $V_{p}(X;[0,T])\\infty$ for all $pp_{\\star}$ and $V_{p}(X;[0,T])=\\infty$ for all $p\\le p_{\\star}$.\n\nReport the threshold $p_{\\star}$ as your final answer. The final answer must be a single real number. No rounding is required.", "solution": "The stochastic differential equation is given in its differential form as $dX_{t} = b(X_{t})\\,dt + \\sigma(X_{t})\\,dW_{t}$ with initial condition $X_{0}\\in\\mathbb{R}$. In integral form, the solution $X_t$ over the time horizon $[0,T]$ is written as:\n$$\nX_{t} \\;=\\; X_{0} \\;+\\; \\int_{0}^{t} b(X_{s})\\,ds \\;+\\; \\int_{0}^{t} \\sigma(X_{s})\\,dW_{s}\n$$\nWe can decompose the process $X_t$ into a constant initial value $X_0$, a drift component $A_t$, and a martingale component $M_t$:\n$$\nA_{t} := \\int_{0}^{t} b(X_{s})\\,ds \\qquad \\text{and} \\qquad M_{t} := \\int_{0}^{t} \\sigma(X_{s})\\,dW_{s}\n$$\nThus, $X_t = X_0 + A_t + M_t$. The $p$-variation is invariant under addition of a constant, so $V_{p}(X;[0,T]) = V_{p}(A+M;[0,T])$.\n\nFor any two continuous functions $Y$ and $Z$, and for $p \\ge 1$, the function $f(x)=|x|^p$ is convex. A standard inequality for $p \\ge 1$ is $|a+b|^p \\le 2^{p-1}(|a|^p + |b|^p)$. Applying this to the increments of $A_t+M_t$ over an interval $[t_i, t_{i+1}]$ of a partition $\\Pi$:\n$$\n| (A_{t_{i+1}}+M_{t_{i+1}}) - (A_{t_{i}}+M_{t_{i}}) |^p = | (A_{t_{i+1}}-A_{t_{i}}) + (M_{t_{i+1}}-M_{t_{i}}) |^p \\le 2^{p-1} \\left( |A_{t_{i+1}}-A_{t_{i}}|^p + |M_{t_{i+1}}-M_{t_{i}}|^p \\right)\n$$\nSumming over all intervals in the partition and taking the supremum over all partitions $\\Pi$, we obtain a bound for the $p$-variation of the sum:\n$$\nV_{p}(X;[0,T]) \\;\\le\\; 2^{p-1} \\left( V_{p}(A;[0,T]) + V_{p}(M;[0,T]) \\right)\n$$\n\n### Part 1: Derivation of the Upper Bound\n\nWe will bound the $p$-variation of the drift and martingale components separately.\n\n**1. Bounding the $p$-variation of the drift component, $V_{p}(A;[0,T])$:**\nThe drift path is $A_t = \\int_0^t b(X_s)ds$. Since $b$ is bounded by $\\|b\\|_{\\infty}$, the path $A_t$ is Lipschitz continuous. For any $s, t \\in [0,T]$:\n$$\n|A_t - A_s| = \\left| \\int_s^t b(X_u)du \\right| \\le \\int_s^t |b(X_u)|du \\le \\|b\\|_{\\infty} |t-s|\n$$\nConsider any finite partition $\\Pi=\\{0=t_0  t_1  \\dots  t_n = T\\}$. The increment over $[t_i, t_{i+1}]$ is bounded by $|A_{t_{i+1}}-A_{t_{i}}| \\le \\|b\\|_{\\infty}(t_{i+1}-t_i)$.\nThe sum for the $p$-variation is:\n$$\n\\sum_{i=0}^{n-1} |A_{t_{i+1}}-A_{t_{i}}|^p \\le \\sum_{i=0}^{n-1} \\left( \\|b\\|_{\\infty}(t_{i+1}-t_i) \\right)^p = \\|b\\|_{\\infty}^{p} \\sum_{i=0}^{n-1} (t_{i+1}-t_i)^p\n$$\nFor $p \\ge 1$, we can use the inequality $\\sum_i h_i^p \\le (\\sum_i h_i) \\cdot (\\max_i h_i)^{p-1}$. A simpler bound is $\\sum (t_{i+1}-t_i)^p \\le T \\cdot (\\max_i(t_{i+1}-t_i))^{p-1}$, which is not partition-independent. Instead, we can bound the sum by $(\\sum_i (t_{i+1}-t_i)) (\\sup_i (t_{i+1}-t_i))^{p-1}$. The total variation ($1$-variation) is $V_1(A;[0,T]) \\le \\|b\\|_{\\infty}T$. For $p>1$, $V_p(A) \\le (V_1(A))^{p-1} \\sup_\\Pi \\sum |A_{t_{i+1}}-A_{t_i}| \\le (\\|b\\|_\\infty T)^{p-1} (\\|b\\|_\\infty T) = (\\|b\\|_\\infty T)^p$.\nTherefore, we have a simple upper bound for the $p$-variation of $A_t$:\n$$\nV_{p}(A;[0,T]) = \\sup_{\\Pi} \\sum_{i=0}^{n-1} |A_{t_{i+1}}-A_{t_{i}}|^p \\le (\\|b\\|_{\\infty}T)^p\n$$\n\n**2. Bounding the $p$-variation of the martingale component, $V_{p}(M;[0,T])$:**\nThe martingale component is $M_t = \\int_0^t \\sigma(X_s)dW_s$. This is a continuous local martingale. Its quadratic variation process is $\\langle M \\rangle_t = \\int_0^t \\sigma^2(X_s)ds$.\nBy the Dambis-Dubins-Schwarz theorem, there exists a standard Brownian motion, which we denote $\\tilde{W}$, such that $M_t = \\tilde{W}_{\\langle M \\rangle_t}$ for all $t \\ge 0$.\nThe process $\\tau(t) := \\langle M \\rangle_t$ is a continuous, non-decreasing time-change.\nThe $p$-variation of $M_t$ is given by:\n$$\nV_{p}(M;[0,T]) = \\sup_{\\Pi} \\sum_{i=0}^{n-1} |M_{t_{i+1}}-M_{t_i}|^p = \\sup_{\\Pi} \\sum_{i=0}^{n-1} |\\tilde{W}_{\\tau(t_{i+1})} - \\tilde{W}_{\\tau(t_i)}|^p\n$$\nLet a partition $\\Pi=\\{t_i\\}$ of $[0,T]$ be given. Let $s_i = \\tau(t_i)$. Since $\\tau(t)$ is continuous and non-decreasing, the set of points $\\{s_i\\}$ forms an ordered set $0=s_0 \\le s_1 \\le \\dots \\le s_n = \\tau(T)$. This set induces a partition of the interval $[0, \\tau(T)]$. The supremum over all partitions $\\Pi$ of $[0,T]$ is thus bounded by the supremum over all partitions of the time-changed interval $[0, \\tau(T)]$:\n$$\nV_{p}(M;[0,T]) \\le V_{p}(\\tilde{W}; [0, \\tau(T)])\n$$\nThe length of this new time interval, $\\tau(T)$, is a random variable. We can bound it using the fact that $\\sigma$ is bounded by $\\|\\sigma\\|_{\\infty}$:\n$$\n\\tau(T) = \\int_0^T \\sigma^2(X_s)ds \\le \\int_0^T \\|\\sigma\\|_{\\infty}^2 ds = \\|\\sigma\\|_{\\infty}^2 T\n$$\nThe $p$-variation is a non-decreasing function of the length of the interval. Therefore:\n$$\nV_{p}(\\tilde{W}; [0, \\tau(T)]) \\le V_{p}(\\tilde{W}; [0, \\|\\sigma\\|_{\\infty}^2 T])\n$$\nSince $\\tilde{W}$ is a standard Brownian motion, it has the same law as $W$. So, we can write the bound in terms of $W$:\n$$\nV_{p}(M;[0,T]) \\le V_{p}(W; [0, \\|\\sigma\\|_{\\infty}^2 T]) \\quad \\text{almost surely.}\n$$\n\n**3. Final Upper Bound:**\nCombining the bounds for the drift and martingale parts, we get the almost sure upper bound on $V_{p}(X;[0,T])$:\n$$\nV_{p}(X;[0,T]) \\le 2^{p-1} \\left( (\\|b\\|_{\\infty}T)^p + V_{p}(W; [0, \\|\\sigma\\|_{\\infty}^2 T]) \\right)\n$$\n\n### Part 2: Determination of the Threshold $p_{\\star}$\n\nA classical result from Paul Lévy concerning the path properties of Brownian motion states that, for any time interval $[0,S]$ with $S>0$, a standard Brownian motion $W$ has sample paths with:\n- Finite $p$-variation for all $p>2$, i.e., $V_p(W;[0,S])  \\infty$ a.s.\n- Infinite $p$-variation for all $p\\le2$, i.e., $V_p(W;[0,S]) = \\infty$ a.s.\n\nNow we analyze the finiteness of $V_p(X;[0,T])$. The drift component $A_t$ is a Lipschitz path, which means it has finite 1-variation. A path with finite q-variation also has finite p-variation for any $p > q$. Thus, $V_p(A;[0,T])$ is finite for all $p \\ge 1$. The process $X_t$ is the sum of a finite p-variation path $A_t$ and the path $M_t$. The finiteness of the p-variation of a sum is determined by the component with the 'roughest' path. Specifically, since $V_p(A;[0,T])$ is finite for any $p \\ge 1$, the sum $X_t = X_0 + A_t + M_t$ will have finite p-variation if and only if $M_t$ has finite p-variation. Thus, the threshold $p_{\\star}$ for $X_t$ is the same as for its martingale part $M_t$.\n\n**Case 1: $p > 2$**\nSince $p>2$, we know $V_p(W; [0, \\|\\sigma\\|_{\\infty}^2 T])  \\infty$ almost surely. From the bound derived in Part 1, we have\n$$\nV_p(M;[0,T]) \\le V_p(W; [0, \\|\\sigma\\|_{\\infty}^2 T])  \\infty \\quad \\text{a.s.}\n$$\nSince $V_p(M)$ is finite, the p-variation of $X$ is also finite. Thus, for $p>2$, $V_p(X;[0,T])  \\infty$ a.s.\n\n**Case 2: $p \\le 2$**\nWe need to show $V_p(X;[0,T]) = \\infty$ a.s., assuming the SDE is non-trivial (i.e., $\\sigma$ is not identically zero).\nLet's first establish this for the martingale part $M_t$. We want to show $V_p(M;[0,T]) = \\infty$ a.s. for $p \\le 2$. Unless $\\sigma(X_s)=0$ for almost every $s \\in [0,T]$ (a trivial case we exclude), the time-change $\\tau(T) = \\int_0^T \\sigma^2(X_s)ds > 0$ almost surely. Let $S=\\tau(T)$. The Brownian path $\\tilde{W}$ on $[0,S]$ has infinite $p$-variation for $p \\le 2$. We need to show this property is inherited by $M_t = \\tilde{W}_{\\tau(t)}$.\nFor any partition $\\Pi'=\\{0=s_0  s_1  \\dots  s_m=S\\}$ of $[0,S]$, we know $\\sum_{j=0}^{m-1} |\\tilde{W}_{s_{j+1}} - \\tilde{W}_{s_j}|^p$ can be made arbitrarily large by choosing a suitable partition.\nThe function $\\tau:[0,T] \\to [0,S]$ is continuous and surjective a.s. Let $t_j = \\min\\{u \\in [0,T] : \\tau(u) = s_j\\}$. This defines an ordered set of points $0=t_0 \\le t_1 \\le \\dots \\le t_m \\le T$. We can form a partition $\\Pi$ of $[0,T]$ containing these points. The variation sum over $\\Pi$ will be at least the sum over the increments between the points $t_j$:\n$$\nV_p(M;[0,T]) \\ge \\sum_{j=0}^{m-1} |M_{t_{j+1}} - M_{t_j}|^p = \\sum_{j=0}^{m-1} |\\tilde{W}_{\\tau(t_{j+1})} - \\tilde{W}_{\\tau(t_j)}|^p \\ge \\sum_{j=0}^{m-1} |\\tilde{W}_{s_{j+1}} - \\tilde{W}_{s_j}|^p\n$$\nSince the right-hand side can be made arbitrarily large by choosing partitions $\\Pi'$ of $[0,S]$, we must have $V_p(M;[0,T]) = \\infty$ a.s for $p \\le 2$.\nAs established earlier, the finiteness of $V_p(X)$ is equivalent to the finiteness of $V_p(M)$. Since $V_p(M;[0,T]) = \\infty$ for $p \\le 2$, it follows that $V_p(X;[0,T]) = \\infty$ for $p \\le 2$.\n\nCombining all cases, we find that $V_p(X;[0,T])  \\infty$ a.s. for $p>2$ and $V_p(X;[0,T]) = \\infty$ a.s. for $p \\le 2$.\nThe minimal threshold value is therefore $p_{\\star}=2$.", "answer": "$$\\boxed{2}$$", "id": "2994547"}, {"introduction": "The classical Itô theory is built on the framework of semimartingales, a class of processes that includes Brownian motion. This exercise [@problem_id:2994548] challenges that familiar landscape by introducing fractional Brownian motion with a Hurst index $H \\gt 1/2$. By analyzing its path properties, you will uncover the surprising fact that a process can be \"smoother\" than Brownian motion (having zero quadratic variation) yet still fail to be a semimartingale, thus falling outside the scope of classical Itô integration.", "problem": "Consider the centered Gaussian process $\\{B^{H}_{t}\\}_{t \\in [0,1]}$ called fractional Brownian motion with Hurst index $H \\in (1/2,1)$, defined by its covariance\n$$\n\\mathbb{E}\\big[B^{H}_{t} B^{H}_{s}\\big] \\;=\\; \\frac{1}{2}\\big(t^{2H} + s^{2H} - |t-s|^{2H}\\big),\n$$\nand with $B^{H}_{0} = 0$. It is known that fractional Brownian motion has stationary increments and is almost surely continuous, and for any $\\gamma \\in (0,H)$ it has sample paths that are Hölder continuous of order $\\gamma$ on $[0,1]$.\n\nDefine, for $n \\in \\mathbb{N}$, the uniform partition $\\pi_{n}$ of $[0,1]$ by $t_{i} = i/n$ and the associated quadratic variation along $\\pi_{n}$ by\n$$\nQ_{n}(B^{H}) \\;=\\; \\sum_{i=1}^{n} \\big( B^{H}_{t_{i}} - B^{H}_{t_{i-1}} \\big)^{2},\n$$\nand the total variation along $\\pi_{n}$ by\n$$\nV_{n}(B^{H}) \\;=\\; \\sum_{i=1}^{n} \\big| B^{H}_{t_{i}} - B^{H}_{t_{i-1}} \\big|.\n$$\nStart from the fundamental definitions of quadratic variation and total variation and from the covariance of fractional Brownian motion. Using only these bases, do the following:\n\n- Derive the behavior of $\\mathbb{E}\\big[Q_{n}(B^{H})\\big]$ as $n \\to \\infty$ and conclude the limit in probability of $Q_{n}(B^{H})$.\n- Derive the behavior of $\\mathbb{E}\\big[V_{n}(B^{H})\\big]$ as $n \\to \\infty$ and explain why the total variation of sample paths on $[0,1]$ is almost surely infinite.\n- Explain, from first principles, the implications of these path properties for defining an Itô integral $\\int_{0}^{1} X_{t} \\,\\mathrm{d}B^{H}_{t}$ in the classical semimartingale sense, and indicate a mathematically sound alternative notion of integration that can be used for integrators with Hölder regularity exceeding $1/2$.\n\nYour final reported value must be the limit (in probability) of $Q_{n}(B^{H})$ as $n \\to \\infty$. No rounding is required, and no physical units are involved. Express the final answer as a single real number.", "solution": "The problem requires an analysis of the path properties of fractional Brownian motion (fBm), $\\{B^{H}_{t}\\}_{t \\in [0,1]}$, with Hurst index $H \\in (1/2,1)$. We are asked to derive the behavior of its quadratic and total variation and discuss the implications for stochastic integration.\n\nThe process is defined as a centered Gaussian process with $B^{H}_{0} = 0$ and covariance function\n$$\n\\mathbb{E}\\big[B^{H}_{t} B^{H}_{s}\\big] \\;=\\; \\frac{1}{2}\\big(t^{2H} + s^{2H} - |t-s|^{2H}\\big).\n$$\nWe begin by deriving the variance of an increment of fBm. Since the process is centered, the mean of any increment $B^{H}_{t} - B^{H}_{s}$ is $0$. Therefore, its variance is:\n$$\n\\text{Var}(B^{H}_{t} - B^{H}_{s}) = \\mathbb{E}\\big[ (B^{H}_{t} - B^{H}_{s})^2 \\big] = \\mathbb{E}\\big[(B^{H}_{t})^2\\big] - 2\\mathbb{E}\\big[B^{H}_{t}B^{H}_{s}\\big] + \\mathbb{E}\\big[(B^{H}_{s})^2\\big].\n$$\nFrom the covariance function, setting $s=t$, we find the variance of $B^{H}_{t}$:\n$$\n\\mathbb{E}\\big[(B^{H}_{t})^2\\big] = \\frac{1}{2}\\big(t^{2H} + t^{2H} - |t-t|^{2H}\\big) = t^{2H}.\n$$\nSubstituting this and the covariance formula into the variance of the increment (assuming $t \\ge s$):\n$$\n\\text{Var}(B^{H}_{t} - B^{H}_{s}) = t^{2H} - 2 \\cdot \\frac{1}{2}\\big(t^{2H} + s^{2H} - (t-s)^{2H}\\big) + s^{2H}\n$$\n$$\n= t^{2H} - t^{2H} - s^{2H} + (t-s)^{2H} + s^{2H} = (t-s)^{2H}.\n$$\nThis shows that increments are stationary, and an increment over an interval of length $\\Delta t$ is a centered Gaussian random variable with variance $(\\Delta t)^{2H}$.\n\n**Part 1: Quadratic Variation**\n\nThe quadratic variation along the partition $\\pi_{n}$ is $Q_{n}(B^{H}) = \\sum_{i=1}^{n} ( B^{H}_{t_{i}} - B^{H}_{t_{i-1}} )^{2}$. We will find the limit of $Q_{n}(B^{H})$ in probability as $n \\to \\infty$.\n\nFirst, we compute the expectation of $Q_{n}(B^{H})$. By linearity of expectation:\n$$\n\\mathbb{E}\\big[Q_{n}(B^{H})\\big] = \\sum_{i=1}^{n} \\mathbb{E}\\big[ (B^{H}_{t_{i}} - B^{H}_{t_{i-1}})^{2} \\big].\n$$\nEach term in the sum is the variance of an increment over an interval of length $t_{i} - t_{i-1} = i/n - (i-1)/n = 1/n$. Using the variance formula derived above:\n$$\n\\mathbb{E}\\big[ (B^{H}_{t_{i}} - B^{H}_{t_{i-1}})^{2} \\big] = \\left(\\frac{1}{n}\\right)^{2H} = n^{-2H}.\n$$\nSumming over the $n$ intervals:\n$$\n\\mathbb{E}\\big[Q_{n}(B^{H})\\big] = \\sum_{i=1}^{n} n^{-2H} = n \\cdot n^{-2H} = n^{1-2H}.\n$$\nThe problem states that $H \\in (1/2, 1)$, which implies $2H > 1$ and thus $1-2H  0$. Therefore, the limit of the expectation is:\n$$\n\\lim_{n \\to \\infty} \\mathbb{E}\\big[Q_{n}(B^{H})\\big] = \\lim_{n \\to \\infty} n^{1-2H} = 0.\n$$\nSince $Q_{n}(B^{H})$ is a sum of squares, it is a non-negative random variable. For any non-negative random variable $X$ and any $\\epsilon > 0$, Markov's inequality states that $P(X \\ge \\epsilon) \\le \\mathbb{E}[X]/\\epsilon$. Applying this to $Q_{n}(B^{H})$:\n$$\nP\\big(Q_{n}(B^{H}) \\ge \\epsilon\\big) \\le \\frac{\\mathbb{E}\\big[Q_{n}(B^{H})\\big]}{\\epsilon} = \\frac{n^{1-2H}}{\\epsilon}.\n$$\nAs $n \\to \\infty$, since $1-2H  0$, the right-hand side converges to $0$. Thus, for any $\\epsilon > 0$:\n$$\n\\lim_{n \\to \\infty} P\\big(|Q_{n}(B^{H}) - 0| \\ge \\epsilon\\big) = 0.\n$$\nThis is the definition of convergence in probability. We conclude that $Q_{n}(B^{H})$ converges in probability to $0$. The quadratic variation of fBm on $[0,1]$ for $H>1/2$ is $0$.\n\n**Part 2: Total Variation**\n\nThe total variation along the partition $\\pi_{n}$ is $V_{n}(B^{H}) = \\sum_{i=1}^{n} |B^{H}_{t_{i}} - B^{H}_{t_{i-1}}|$. We examine its behavior as $n \\to \\infty$.\n\nBy linearity of expectation:\n$$\n\\mathbb{E}\\big[V_{n}(B^{H})\\big] = \\sum_{i=1}^{n} \\mathbb{E}\\big[ |B^{H}_{t_{i}} - B^{H}_{t_{i-1}}| \\big].\n$$\nEach increment $\\Delta_i B^H = B^{H}_{t_{i}} - B^{H}_{t_{i-1}}$ is a centered Gaussian random variable with variance $\\sigma_i^2 = n^{-2H}$. Its standard deviation is $\\sigma_i = n^{-H}$.\nFor a generic centered Gaussian random variable $X \\sim N(0, \\sigma^2)$, its expected absolute value is $\\mathbb{E}[|X|] = \\sigma \\sqrt{2/\\pi}$.\nApplying this to our increments:\n$$\n\\mathbb{E}\\big[ |\\Delta_i B^H| \\big] = n^{-H} \\sqrt{\\frac{2}{\\pi}}.\n$$\nSumming over the $n$ intervals:\n$$\n\\mathbb{E}\\big[V_{n}(B^{H})\\big] = \\sum_{i=1}^{n} n^{-H} \\sqrt{\\frac{2}{\\pi}} = n \\cdot n^{-H} \\sqrt{\\frac{2}{\\pi}} = n^{1-H} \\sqrt{\\frac{2}{\\pi}}.\n$$\nSince $H \\in (1/2, 1)$, we have $1-H \\in (0, 1/2)$, so $1-H > 0$. Therefore, the limit of the expectation is:\n$$\n\\lim_{n \\to \\infty} \\mathbb{E}\\big[V_{n}(B^{H})\\big] = \\lim_{n \\to \\infty} n^{1-H} \\sqrt{\\frac{2}{\\pi}} = \\infty.\n$$\nThe total variation of a sample path $B^H(\\omega)$ on $[0,1]$ is defined as $V(B^H)(\\omega) = \\sup_{\\pi} \\sum |B^H_{t_i}(\\omega) - B^H_{t_{i-1}}(\\omega)|$, where the supremum is over all partitions $\\pi$ of $[0,1]$. This can be written as the limit of $V_n(B^H)$ as the mesh of the partition goes to zero. The sequence of random variables $\\{V_n(B^H)\\}_{n \\in \\mathbb{N}}$ is non-decreasing for refining partitions. By the Monotone Convergence Theorem for expectations, $\\mathbb{E}[V(B^H)] = \\lim_{n \\to \\infty} \\mathbb{E}[V_n(B^H)] = \\infty$.\nA non-negative random variable with an infinite expectation must be infinite with a positive probability. For Gaussian processes like fBm, a stronger result holds: the convergence is almost sure. Since the expectation of the total variation diverges, the total variation itself must be almost surely infinite.\n\n**Part 3: Implications for Stochastic Integration**\n\nThe classical theory of Itô integration is built for integrators that are semimartingales. A continuous process is a semimartingale if and only if it can be decomposed as a sum of a continuous local martingale and a continuous process of finite variation (bounded variation, or BV).\n\nFrom Part 2, we established that the sample paths of $B^H$ have infinite total variation almost surely for $H \\in (1/2, 1)$. This means $B^H$ is not a process of finite variation.\n\nFrom Part 1, we showed that the quadratic variation of $B^H$ is zero. A continuous local martingale $M$ must have a non-decreasing quadratic variation process $[M,M]_t$. If $[M,M]_t = 0$ for all $t$, then the process must be constant, i.e., $M_t = M_0$ almost surely. Since $B^H$ is not a constant process (its variance is $t^{2H}$), it cannot be a non-trivial local martingale.\n\nSince $B^H$ is neither a finite variation process nor a local martingale, and it cannot be decomposed into a sum of the two, it is not a semimartingale for $H \\in (1/2, 1)$ (the case $H=1/2$ corresponds to standard Brownian motion, which is a martingale and thus a semimartingale).\n\nConsequently, the Itô integral $\\int_{0}^{1} X_{t} \\,\\mathrm{d}B^{H}_{t}$ cannot be defined in the classical semimartingale sense.\n\nA mathematically sound alternative is provided by theories that rely on the path regularity rather than martingale properties. The problem states that paths of $B^H$ are a.s. Hölder continuous of any order $\\gamma  H$. Since $H > 1/2$, we can choose a $\\gamma > 1/2$. The theory of Young integration allows for the pathwise definition of the integral $\\int f dg$ as a limit of Riemann-Stieltjes sums, provided that $f$ is $\\alpha$-Hölder continuous and $g$ is $\\beta$-Hölder continuous with $\\alpha + \\beta > 1$.\n\nFor the integral $\\int_{0}^{1} X_{t} \\,\\mathrm{d}B^{H}_{t}$, the integrator $B^H_t$ is $\\gamma$-Hölder for $\\gamma  H$. If the integrand process $X_t$ has sample paths that are $\\alpha$-Hölder continuous, the Young integral exists pathwise provided $\\alpha + \\gamma > 1$. As we can choose $\\gamma$ arbitrarily close to $H$, this condition becomes, for practical purposes, $\\alpha > 1-H$. Since $H > 1/2$, this requires $\\alpha$ to be greater than a value in $(0, 1/2)$. This pathwise integral, which does not possess the properties of the Itô integral (e.g., it does not follow an Itô-type formula but a classical differentiation rule), is a well-defined alternative for integrators like fBm with $H > 1/2$. More advanced theories like rough path integration extend this concept to cases where $H \\le 1/2$.", "answer": "$$\n\\boxed{0}\n$$", "id": "2994548"}]}