{"hands_on_practices": [{"introduction": "To begin our exploration of Malliavin calculus, we start with a foundational hands-on computation. This exercise focuses on the Doléans-Dade exponential, a key random variable in stochastic analysis, and asks you to compute its first and second Malliavin derivatives directly from the definition [@problem_id:3002272]. By then calculating its Malliavin-Sobolev norm, you will gain practical experience with the core definitions and see how the smoothness of this random variable is quantified within the framework of Sobolev spaces on Wiener space.", "problem": "Let $(\\Omega,\\mathcal{F},\\mathbb{P})$ be a complete probability space and let $H$ be a separable real Hilbert space with inner product $\\langle \\cdot,\\cdot \\rangle_{H}$ and norm $\\|\\cdot\\|_{H}$. Let $W:H\\to L^{2}(\\Omega)$ be an isonormal Gaussian process over $H$, meaning that for every $h\\in H$ the random variable $W(h)$ is centered Gaussian with variance $\\|h\\|_{H}^{2}$ and for every $h,g\\in H$ one has $\\mathbb{E}[W(h)W(g)]=\\langle h,g\\rangle_{H}$. Consider the space of smooth cylindrical random variables of the form $\\Phi=f(W(h_{1}),\\dots,W(h_{n}))$ with $h_{1},\\dots,h_{n}\\in H$ and $f\\in C_{b}^{\\infty}(\\mathbb{R}^{n})$, and define the Malliavin derivative $D\\Phi\\in L^{2}(\\Omega;H)$ and second Malliavin derivative $D^{2}\\Phi\\in L^{2}(\\Omega;H^{\\otimes 2})$ (where $H^{\\otimes 2}$ denotes the Hilbert tensor product) by the fundamental rules\n$$\nD\\Phi=\\sum_{i=1}^{n}\\partial_{i}f\\big(W(h_{1}),\\dots,W(h_{n})\\big)\\,h_{i},\\qquad\nD^{2}\\Phi=\\sum_{i,j=1}^{n}\\partial_{ij}f\\big(W(h_{1}),\\dots,W(h_{n})\\big)\\,h_{i}\\otimes h_{j}.\n$$\nLet $\\lambda\\in\\mathbb{R}$ and $h\\in H\\setminus\\{0\\}$. Define the random variable\n$$\nF=\\exp\\!\\big(\\lambda\\,W(h)-\\tfrac{\\lambda^{2}}{2}\\,\\|h\\|_{H}^{2}\\big).\n$$\nStarting from the above base definitions and using only fundamental properties of Gaussian random variables (including the moment generating function of a centered normal law), do the following:\n- Derive the expressions for the first and second Malliavin derivatives $DF$ and $D^{2}F$ as elements of $L^{2}(\\Omega;H)$ and $L^{2}(\\Omega;H^{\\otimes 2})$, respectively.\n- For arbitrary integers $k\\geq 0$ and real numbers $p\\geq 1$, verify that $F\\in \\mathbb{D}^{k,p}$, where $\\mathbb{D}^{k,p}$ is the Malliavin–Sobolev space of random variables with $k$ derivatives in $L^{p}$. Use the canonical norm\n$$\n\\|F\\|_{k,p}=\\Bigg(\\sum_{j=0}^{k}\\mathbb{E}\\!\\big[\\|D^{j}F\\|_{H^{\\otimes j}}^{p}\\big]\\Bigg)^{\\!1/p},\n$$\nwith the conventions $D^{0}F:=F$ and $\\|D^{0}F\\|_{H^{\\otimes 0}}:=|F|$, and provide an explicit closed-form expression for $\\|F\\|_{k,p}$ in terms of $\\lambda$, $p$, and $\\|h\\|_{H}$.\n\nYour final answer must be a single closed-form analytical expression that simultaneously reports the formulas for $DF$, $D^{2}F$, and $\\|F\\|_{k,p}$. No numerical approximation is required.", "solution": "The problem is subjected to validation.\n\n### Step 1: Extract Givens\n- A complete probability space $(\\Omega,\\mathcal{F},\\mathbb{P})$.\n- A separable real Hilbert space $H$ with inner product $\\langle \\cdot,\\cdot \\rangle_{H}$ and norm $\\|\\cdot\\|_{H}$.\n- An isonormal Gaussian process $W:H\\to L^{2}(\\Omega)$ such that $W(h)$ is a centered Gaussian random variable with variance $\\|h\\|_{H}^{2}$ and $\\mathbb{E}[W(h)W(g)]=\\langle h,g\\rangle_{H}$.\n- The space of smooth cylindrical random variables is of the form $\\Phi=f(W(h_{1}),\\dots,W(h_{n}))$ for $f\\in C_{b}^{\\infty}(\\mathbb{R}^{n})$ and $h_{1},\\dots,h_{n}\\in H$.\n- The first Malliavin derivative is defined as $D\\Phi=\\sum_{i=1}^{n}\\partial_{i}f\\big(W(h_{1}),\\dots,W(h_{n})\\big)\\,h_{i}$.\n- The second Malliavin derivative is defined as $D^{2}\\Phi=\\sum_{i,j=1}^{n}\\partial_{ij}f\\big(W(h_{1}),\\dots,W(h_{n})\\big)\\,h_{i}\\otimes h_{j}$.\n- The random variable to be analyzed is $F=\\exp\\!\\big(\\lambda\\,W(h)-\\tfrac{\\lambda^{2}}{2}\\,\\|h\\|_{H}^{2}\\big)$, with $\\lambda\\in\\mathbb{R}$ and $h\\in H\\setminus\\{0\\}$.\n- The Malliavin–Sobolev space $\\mathbb{D}^{k,p}$ for integers $k\\geq 0$ and real numbers $p\\geq 1$ is defined via the norm $\\|F\\|_{k,p}=\\Bigg(\\sum_{j=0}^{k}\\mathbb{E}\\!\\big[\\|D^{j}F\\|_{H^{\\otimes j}}^{p}\\big]\\Bigg)^{\\!1/p}$.\n- Conventions: $D^{0}F := F$, $H^{\\otimes 0} := \\mathbb{R}$, and $\\|D^{0}F\\|_{H^{\\otimes 0}} := |F|$.\n\n### Step 2: Validate Using Extracted Givens\nThe problem is well-posed and scientifically grounded within the mathematical theory of stochastic analysis, specifically Malliavin calculus. The definitions provided for the isonormal Gaussian process, Malliavin derivatives, and Malliavin-Sobolev spaces are standard. The random variable $F$ is a well-known object (a Doléans-Dade exponential), and its properties are a classic subject of study in this field. The problem statement is formal, self-contained, and objective, with all necessary information to proceed to a unique, verifiable solution. There are no contradictions, ambiguities, or violations of scientific or mathematical principles.\n\n### Step 3: Verdict and Action\nThe problem is valid. A complete solution will be provided.\n\n### Solution Derivation\nThe given random variable is $F=\\exp\\big(\\lambda\\,W(h)-\\tfrac{\\lambda^{2}}{2}\\,\\|h\\|_{H}^{2}\\big)$. We can express $F$ in the form of a cylindrical random variable $f(W(h))$ where $f: \\mathbb{R} \\to \\mathbb{R}$ is the function $f(x) = \\exp\\big(\\lambda x - \\tfrac{\\lambda^2}{2}\\|h\\|_H^2\\big)$. Although $f$ is not in $C_{b}^{\\infty}(\\mathbb{R})$ (it is not bounded), the definition of the Malliavin derivative can be extended to this case by a density argument. We proceed by formally applying the chain rule.\n\nThe derivatives of $f(x)$ with respect to $x$ are:\n$f'(x) = \\lambda \\exp\\big(\\lambda x - \\tfrac{\\lambda^2}{2}\\|h\\|_H^2\\big) = \\lambda f(x)$\n$f''(x) = \\lambda^2 \\exp\\big(\\lambda x - \\tfrac{\\lambda^2}{2}\\|h\\|_H^2\\big) = \\lambda^2 f(x)$\nAnd in general, for any integer $j \\geq 1$, the $j$-th derivative is $f^{(j)}(x) = \\lambda^j f(x)$.\n\n**1. First and Second Malliavin Derivatives $DF$ and $D^2F$**\n\nUsing the definition of the Malliavin derivative for a function of a single Gaussian variable $W(h)$, we have:\n$DF = f'(W(h)) h$\nSubstituting the expression for $f'(x)$:\n$DF = \\lambda f(W(h)) h = \\lambda F h$.\nThus, the first Malliavin derivative is:\n$DF = \\lambda \\exp\\big(\\lambda W(h) - \\tfrac{\\lambda^2}{2}\\|h\\|_H^2\\big) h$\n\nFor the second derivative, the rule gives:\n$D^2F = f''(W(h)) h \\otimes h$\nSubstituting the expression for $f''(x)$:\n$D^2F = \\lambda^2 f(W(h)) h \\otimes h = \\lambda^2 F h \\otimes h$.\nThus, the second Malliavin derivative is:\n$D^2F = \\lambda^2 \\exp\\big(\\lambda W(h) - \\tfrac{\\lambda^2}{2}\\|h\\|_H^2\\big) h \\otimes h$\n\n**2. General Derivative $D^j F$ and its Norm**\n\nBy induction, the $j$-th Malliavin derivative for an integer $j \\geq 0$ is given by:\n$D^j F = f^{(j)}(W(h)) h^{\\otimes j} = \\lambda^j f(W(h)) h^{\\otimes j} = \\lambda^j F h^{\\otimes j}$.\n\nWe need to compute the norm $\\|D^j F\\|_{H^{\\otimes j}}$. The norm of a simple tensor $v^{\\otimes j}$ in $H^{\\otimes j}$ is $\\|v^{\\otimes j}\\|_{H^{\\otimes j}} = \\|v\\|_H^j$.\n$D^j F$ is a random element in $L^p(\\Omega; H^{\\otimes j})$. Its norm is computed for a fixed $\\omega \\in \\Omega$:\n$\\|D^j F\\|_{H^{\\otimes j}} = \\|\\lambda^j F h^{\\otimes j}\\|_{H^{\\otimes j}} = |\\lambda^j F| \\|h^{\\otimes j}\\|_{H^{\\otimes j}} = |\\lambda|^j |F| \\|h\\|_H^j$.\nSince $F$ is an exponential, it is always positive, so $|F|=F$.\n$\\|D^j F\\|_{H^{\\otimes j}} = |\\lambda|^j F \\|h\\|_H^j$.\n\n**3. Calculation of $\\|F\\|_{k,p}$**\n\nThe norm is defined as $\\|F\\|_{k,p} = \\left(\\sum_{j=0}^{k}\\mathbb{E}\\big[\\|D^{j}F\\|_{H^{\\otimes j}}^{p}\\big]\\right)^{1/p}$.\nWe need to compute the expectation term $\\mathbb{E}\\big[\\|D^{j}F\\|_{H^{\\otimes j}}^{p}\\big]$.\n$\\mathbb{E}\\big[\\|D^{j}F\\|_{H^{\\otimes j}}^{p}\\big] = \\mathbb{E}\\Big[\\big(|\\lambda|^j F \\|h\\|_H^j\\big)^p\\Big] = \\big(|\\lambda|^j \\|h\\|_H^j\\big)^p \\mathbb{E}[F^p] = |\\lambda|^{jp} \\|h\\|_H^{jp} \\mathbb{E}[F^p]$.\n\nLet's compute $\\mathbb{E}[F^p]$.\n$F^p = \\left(\\exp\\big(\\lambda W(h) - \\tfrac{\\lambda^2}{2}\\|h\\|_H^2\\big)\\right)^p = \\exp\\big(p\\lambda W(h) - \\tfrac{p\\lambda^2}{2}\\|h\\|_H^2\\big)$.\n$\\mathbb{E}[F^p] = \\exp\\big(-\\tfrac{p\\lambda^2}{2}\\|h\\|_H^2\\big) \\mathbb{E}\\big[\\exp(p\\lambda W(h))\\big]$.\nThe random variable $W(h)$ is Gaussian with mean $0$ and variance $\\|h\\|_H^2$. The moment generating function of a Gaussian random variable $X \\sim \\mathcal{N}(0, \\sigma^2)$ is $\\mathbb{E}[\\exp(tX)] = \\exp(\\tfrac{1}{2}t^2 \\sigma^2)$.\nHere, $X=W(h)$, $\\sigma^2 = \\|h\\|_H^2$, and $t=p\\lambda$.\nSo, $\\mathbb{E}\\big[\\exp(p\\lambda W(h))\\big] = \\exp\\big(\\tfrac{1}{2}(p\\lambda)^2\\|h\\|_H^2\\big) = \\exp\\big(\\tfrac{p^2\\lambda^2}{2}\\|h\\|_H^2\\big)$.\n\nSubstituting this back:\n$\\mathbb{E}[F^p] = \\exp\\big(-\\tfrac{p\\lambda^2}{2}\\|h\\|_H^2\\big) \\exp\\big(\\tfrac{p^2\\lambda^2}{2}\\|h\\|_H^2\\big) = \\exp\\left(\\tfrac{\\lambda^2\\|h\\|_H^2}{2}(p^2-p)\\right)$.\nFor $p \\geq 1$, this expectation is finite, which confirms that $F \\in L^p(\\Omega)$.\n\nNow we have the term for the sum:\n$\\mathbb{E}\\big[\\|D^{j}F\\|_{H^{\\otimes j}}^{p}\\big] = |\\lambda|^{jp} \\|h\\|_H^{jp} \\exp\\left(\\tfrac{\\lambda^2\\|h\\|_H^2}{2}(p^2-p)\\right)$.\nSince this is finite for all $j \\geq 0$, we have verified that $F \\in \\mathbb{D}^{k,p}$ for any $k \\geq 0$ and $p \\geq 1$.\n\nFinally, we assemble the norm $\\|F\\|_{k,p}$:\n$\\|F\\|_{k,p}^p = \\sum_{j=0}^{k} \\mathbb{E}\\big[\\|D^{j}F\\|_{H^{\\otimes j}}^{p}\\big] = \\sum_{j=0}^{k} |\\lambda|^{jp} \\|h\\|_H^{jp} \\exp\\left(\\tfrac{\\lambda^2\\|h\\|_H^2}{2}(p^2-p)\\right)$\n$\\|F\\|_{k,p}^p = \\exp\\left(\\tfrac{\\lambda^2\\|h\\|_H^2}{2}(p^2-p)\\right) \\sum_{j=0}^{k} \\big(|\\lambda|^p \\|h\\|_H^p\\big)^j$.\n\nTaking the $p$-th root on both sides:\n$\\|F\\|_{k,p} = \\left( \\exp\\left(\\tfrac{\\lambda^2\\|h\\|_H^2}{2}(p^2-p)\\right) \\sum_{j=0}^{k} \\big(|\\lambda| \\|h\\|_H\\big)^{jp} \\right)^{1/p}$\n$\\|F\\|_{k,p} = \\exp\\left(\\tfrac{\\lambda^2\\|h\\|_H^2}{2p}(p^2-p)\\right) \\left( \\sum_{j=0}^{k} \\big(|\\lambda| \\|h\\|_H\\big)^{jp} \\right)^{1/p}$\n$\\|F\\|_{k,p} = \\exp\\left(\\tfrac{\\lambda^2\\|h\\|_H^2 (p-1)}{2}\\right) \\left( \\sum_{j=0}^{k} \\big(|\\lambda| \\|h\\|_H\\big)^{jp} \\right)^{1/p}$.\n\nThis expression is a complete, closed-form representation of the norm. It can be further simplified using the formula for a geometric sum, which results in a piecewise function depending on whether $|\\lambda| \\|h\\|_H = 1$. The form with the summation is more general and compact.\n\nThe required results are:\n1. $DF = \\lambda \\exp\\big(\\lambda W(h) - \\tfrac{\\lambda^2}{2}\\|h\\|_H^2\\big) h$\n2. $D^2F = \\lambda^2 \\exp\\big(\\lambda W(h) - \\tfrac{\\lambda^2}{2}\\|h\\|_H^2\\big) h \\otimes h$\n3. $\\|F\\|_{k,p} = \\left( \\sum_{j=0}^{k} (|\\lambda| \\|h\\|_H)^{jp} \\right)^{1/p} \\exp\\left(\\frac{1}{2}\\lambda^2\\|h\\|_H^2(p-1)\\right)$", "answer": "$$\n\\boxed{\\begin{pmatrix} \\lambda \\exp\\left(\\lambda W(h) - \\frac{\\lambda^2}{2}\\|h\\|_{H}^{2}\\right) h  \\lambda^2 \\exp\\left(\\lambda W(h) - \\frac{\\lambda^2}{2}\\|h\\|_{H}^{2}\\right) h \\otimes h  \\left( \\sum_{j=0}^{k} (|\\lambda| \\|h\\|_{H})^{jp} \\right)^{\\frac{1}{p}} \\exp\\left(\\frac{1}{2}\\lambda^2\\|h\\|_{H}^{2}(p-1)\\right) \\end{pmatrix}}\n$$", "id": "3002272"}, {"introduction": "After mastering the computation for a single function, we now investigate the action of the Malliavin derivative on the fundamental building blocks of $L^2(\\Omega)$: the Wiener chaos. This practice demonstrates that the iterated derivative, $D^k$, acts as a lowering operator on the chaos decomposition, a result that is central to the entire theory [@problem_id:3002269]. By deriving this relationship and its consequences for the norms of derivatives, you will uncover the elegant algebraic structure that the Malliavin derivative imposes on the space of random variables.", "problem": "Let $\\left(\\Omega,\\mathcal{F},\\mathbb{P}\\right)$ carry an isonormal Gaussian process $W=\\{W(h):h\\in H\\}$ over a real separable Hilbert space $H$, so that $\\mathbb{E}[W(h)W(g)]=\\langle h,g\\rangle_{H}$ for all $h,g\\in H$. Denote by $\\mathbb{D}^{1,2}$ the Malliavin Sobolev space of random variables with square-integrable Malliavin derivative, and define the Malliavin derivative $D:\\mathbb{D}^{1,2}\\to L^{2}(\\Omega;H)$ on smooth cylindrical functionals $F=\\varphi(W(h_{1}),\\dots,W(h_{m}))$ by\n$$\nD F=\\sum_{i=1}^{m}\\partial_{i}\\varphi\\!\\left(W(h_{1}),\\dots,W(h_{m})\\right)h_{i},\n$$\nextended by closure. Let $\\delta$ denote the Skorohod integral (divergence operator), the $L^{2}$-adjoint of $D$, and for $n\\ge 1$ let $I_{n}(f)$ be the order-$n$ multiple Wiener–Itô integral of a symmetric kernel $f\\in H^{\\otimes n}$, characterized by the chaos isometry $\\mathbb{E}[I_{n}(f)I_{m}(g)]=\\delta_{n,m}\\,n!\\,\\langle f,g\\rangle_{H^{\\otimes n}}$ and the identity $I_{n}(f)=\\delta^{n}(f)$ for deterministic $f$.\n\nFix integers $n\\ge 1$ and $1\\le k\\le n$, and a symmetric kernel $f\\in H^{\\otimes n}$. Consider the random variable $F:=I_{n}(f)$. Starting only from the fundamental definitions above (Gaussian isometry, the Malliavin derivative on smooth cylindrical functionals, the duality between $D$ and $\\delta$, and the chaos isometry), carry out the following tasks:\n\n1. Derive an explicit expression for the $k$-th Malliavin derivative $D^{k}F$ as an $H^{\\otimes k}$-valued random variable in terms of an $(n-k)$-fold multiple Wiener–Itô integral with deterministic kernel built from $f$. Your expression must be symmetrized in $H^{\\otimes k}$.\n\n2. Using the chaos isometry and your result from part 1, derive an exact identity for the second moment $\\mathbb{E}\\!\\left[\\|D^{k}F\\|_{H^{\\otimes k}}^{2}\\right]$ in terms of $n$, $k$, and $\\|f\\|_{H^{\\otimes n}}^{2}$.\n\n3. Finally, assume the normalization $\\|f\\|_{H^{\\otimes n}}^{2}=\\frac{1}{n!}$ so that $\\mathbb{E}[F^{2}]=1$. Compute the exact value of $\\mathbb{E}\\!\\left[\\|D^{k}F\\|_{H^{\\otimes k}}^{2}\\right]$ as a closed-form expression in $n$ and $k$. Provide your final answer as a single simplified analytic expression. No rounding is required.", "solution": "The problem is evaluated as valid as it is mathematically well-posed, scientifically grounded in the theory of stochastic analysis, and contains a complete and consistent set of definitions and conditions. We proceed with the solution.\n\nLet $F = I_n(f)$ for a symmetric kernel $f \\in H^{\\otimes n}$, where $n \\geq 1$ is an integer. The tasks are to derive the $k$-th Malliavin derivative $D^k F$, compute the second moment of its norm $\\mathbb{E}[\\|D^k F\\|_{H^{\\otimes k}}^2]$, and find the value of this moment under a specific normalization of $f$.\n\n**1. Derivation of the $k$-th Malliavin Derivative $D^k F$**\n\nThe Malliavin derivative $D$ is defined on smooth cylindrical functionals and extended by closure. Its action on the Wiener chaos is a fundamental property. For a random variable $G = I_m(g)$ with a symmetric kernel $g \\in H^{\\otimes m}$, the derivative $DG$ is an $H$-valued random variable. Its component in the direction of any $h \\in H$ is given by the action of the derivative operator $D_h = \\langle D\\cdot, h \\rangle_H$:\n$$\nD_h G = D_h I_m(g) = m I_{m-1}(g(\\cdot_1, \\dots, \\cdot_{m-1}, h))\n$$\nThis can be derived from the definition on smooth functionals by approximating $I_m(g)$ with Hermite polynomials of Gaussian random variables. Since this is a standard result that can be obtained from the provided definitions, we will use it as our starting point for the iterative derivation.\n\nLet $F=I_n(f)$. We compute the iterated derivatives $D^k F$ for $k=1, \\dots, n$.\nFor $k=1$:\n$DF$ is an $H$-valued random variable. For any $h_1 \\in H$, its component $\\langle DF, h_1 \\rangle_H$ is:\n$$\n\\langle DF, h_1 \\rangle_H = D_{h_1} I_n(f) = n I_{n-1}(f(\\cdot_1, \\dots, \\cdot_{n-1}, h_1))\n$$\nThis expression defines the $H$-valued random variable $DF$. We can write this more compactly. If we consider the kernel $f \\in H^{\\otimes n}$ as an element of $H^{\\otimes (n-1)} \\otimes H$, then $DF$ corresponds to the $(n-1)$-th order multiple integral of $n f$:\n$$\nDF = n I_{n-1}(f)\n$$\nwhere it is understood that $I_{n-1}$ acts on the first $n-1$ tensor components of $f$, yielding an $H$-valued random variable.\n\nFor $k=2$:\n$D^2 F = D(DF)$ is an $H^{\\otimes 2}$-valued random variable. For any $h_1, h_2 \\in H$, its component $\\langle D^2 F, h_2 \\otimes h_1 \\rangle_{H^{\\otimes 2}}$ is given by:\n$$\n\\langle D^2 F, h_2 \\otimes h_1 \\rangle_{H^{\\otimes 2}} = D_{h_2} \\langle DF, h_1 \\rangle_H = D_{h_2} \\left[ n I_{n-1}(f(\\cdot_1, \\dots, \\cdot_{n-1}, h_1)) \\right]\n$$\nLet $f_{h_1}(t_1, \\dots, t_{n-1}) = f(t_1, \\dots, t_{n-1}, h_1)$. This is a symmetric kernel in $H^{\\otimes (n-1)}$. Applying the derivative rule again:\n$$\nD_{h_2} [n I_{n-1}(f_{h_1})] = n (n-1) I_{n-2}(f_{h_1}(\\cdot_1, \\dots, \\cdot_{n-2}, h_2))\n$$\nSubstituting the definition of $f_{h_1}$:\n$$\nf_{h_1}(\\cdot_1, \\dots, \\cdot_{n-2}, h_2) = f(\\cdot_1, \\dots, \\cdot_{n-2}, h_2, h_1)\n$$\nThus,\n$$\n\\langle D^2 F, h_2 \\otimes h_1 \\rangle_{H^{\\otimes 2}} = n(n-1) I_{n-2}(f(\\cdot_1, \\dots, \\cdot_{n-2}, h_1, h_2))\n$$\nNote that since $f$ is symmetric in all its arguments, the right-hand side is symmetric in $h_1, h_2$, which implies that $D^2 F$ is a symmetric tensor-valued random variable.\n\nWe proceed by induction. Assume for some $k-1$ where $1 \\le k-1  n$:\n$$\n\\langle D^{k-1} F, h_{k-1} \\otimes \\dots \\otimes h_1 \\rangle_{H^{\\otimes (k-1)}} = \\frac{n!}{(n-k+1)!} I_{n-k+1}(f(\\cdot_1, \\dots, \\cdot_{n-k+1}, h_1, \\dots, h_{k-1}))\n$$\nThen, for $h_k \\in H$:\n\\begin{align*}\n\\langle D^k F, h_k \\otimes \\dots \\otimes h_1 \\rangle_{H^{\\otimes k}} = D_{h_k} \\langle D^{k-1} F, h_{k-1} \\otimes \\dots \\otimes h_1 \\rangle_{H^{\\otimes (k-1)}} \\\\\n= D_{h_k} \\left[ \\frac{n!}{(n-k+1)!} I_{n-k+1}(f(\\dots, h_1, \\dots, h_{k-1})) \\right] \\\\\n= \\frac{n!}{(n-k+1)!} (n-k+1) I_{n-k}(f(\\dots, h_1, \\dots, h_{k-1}, h_k)) \\\\\n= \\frac{n!}{(n-k)!} I_{n-k}(f(\\cdot_1, \\dots, \\cdot_{n-k}, h_1, \\dots, h_k))\n\\end{align*}\nThis formula defines the $H^{\\otimes k}$-valued random variable $D^k F$. As before, the symmetry of $f$ guarantees that $D^k F$ is a symmetric tensor. This can be written compactly by viewing $f \\in H^{\\otimes n}$ as an element of $H^{\\otimes(n-k)} \\otimes H^{\\otimes k}$:\n$$\nD^k F = \\frac{n!}{(n-k)!} I_{n-k}(f)\n$$\nThis expression represents an $H^{\\otimes k}$-valued random variable belonging to the $(n-k)$-th Wiener chaos. The kernel $f$ is symmetric in its first $n-k$ arguments (as it is fully symmetric), and the integral $I_{n-k}$ produces a value in $H^{\\otimes k}$. This is the explicit expression for the $k$-th Malliavin derivative.\n\n**2. Derivation of the Identity for $\\mathbb{E}[\\|D^k F\\|_{H^{\\otimes k}}^2]$**\n\nWe need to compute the second moment of the norm of the $H^{\\otimes k}$-valued random variable $U = D^k F = \\frac{n!}{(n-k)!} I_{n-k}(f)$. The problem provides the chaos isometry for scalar-valued integrals: $\\mathbb{E}[I_m(g)^2] = m!\\|g\\|_{H^{\\otimes m}}^2$ for a symmetric kernel $g \\in H^{\\otimes m}$. We extend this to an integral with values in a Hilbert space $K$. Let $K=H^{\\otimes k}$ and let $\\{e_j\\}_{j=1}^\\infty$ be an orthonormal basis for $K$. An element $U \\in L^2(\\Omega; K)$ can be expanded as $U = \\sum_j \\langle U, e_j \\rangle_K e_j$. Its norm squared is $\\|U\\|_K^2 = \\sum_j \\langle U, e_j \\rangle_K^2$.\nLet $U = I_m(g)$, where $g \\in H^{\\otimes m} \\otimes K$ has symmetry in its first $m$ arguments. Then $\\langle U, e_j \\rangle_K = I_m(\\langle g, e_j \\rangle_K)$. Let $g_j = \\langle g, e_j \\rangle_K$, which is a symmetric kernel in $H^{\\otimes m}$.\nUsing the linearity of expectation and the scalar chaos isometry:\n$$\n\\mathbb{E}[\\|U\\|_K^2] = \\mathbb{E}\\left[\\sum_j (I_m(g_j))^2\\right] = \\sum_j \\mathbb{E}[(I_m(g_j))^2] = \\sum_j m! \\|g_j\\|_{H^{\\otimes m}}^2 = m! \\sum_j \\|g_j\\|_{H^{\\otimes m}}^2\n$$\nBy Parseval's identity in the space $H^{\\otimes m} \\otimes K$, $\\sum_j \\|g_j\\|_{H^{\\otimes m}}^2 = \\|g\\|_{H^{\\otimes m} \\otimes K}^2$. So, for a $K$-valued integral, the isometry is $\\mathbb{E}[\\|I_m(g)\\|_K^2] = m! \\|g\\|_{H^{\\otimes m} \\otimes K}^2$.\n\nWe apply this to $D^k F = \\frac{n!}{(n-k)!} I_{n-k}(f)$. Here, $m=n-k$, $K=H^{\\otimes k}$, and the kernel for the integral is $f_I = \\frac{n!}{(n-k)!} f$. The kernel $f$ is viewed as an element of $H^{\\otimes (n-k)} \\otimes H^{\\otimes k}$. As $f$ is fully symmetric, it is symmetric in its first $n-k$ arguments, so the vector-valued isometry applies.\n\\begin{align*}\n\\mathbb{E}[\\|D^k F\\|_{H^{\\otimes k}}^2] = \\mathbb{E}\\left[\\left\\|\\frac{n!}{(n-k)!} I_{n-k}(f)\\right\\|_{H^{\\otimes k}}^2\\right] \\\\\n= \\left(\\frac{n!}{(n-k)!}\\right)^2 \\mathbb{E}\\left[\\|I_{n-k}(f)\\|_{H^{\\otimes k}}^2\\right] \\\\\n= \\left(\\frac{n!}{(n-k)!}\\right)^2 (n-k)! \\|f\\|_{H^{\\otimes (n-k)} \\otimes H^{\\otimes k}}^2\n\\end{align*}\nThe norm $\\|f\\|_{H^{\\otimes (n-k)} \\otimes H^{\\otimes k}}$ is simply the norm of $f$ in $H^{\\otimes n}$, i.e., $\\|f\\|_{H^{\\otimes n}}$.\n$$\n\\mathbb{E}[\\|D^k F\\|_{H^{\\otimes k}}^2] = \\frac{(n!)^2}{((n-k)!)^2} (n-k)! \\|f\\|_{H^{\\otimes n}}^2 = \\frac{(n!)^2}{(n-k)!} \\|f\\|_{H^{\\otimes n}}^2\n$$\nThis is the required identity.\n\n**3. Computation for Normalized Kernel**\n\nWe are given the normalization $\\|f\\|_{H^{\\otimes n}}^2 = \\frac{1}{n!}$, which ensures $\\mathbb{E}[F^2] = \\mathbb{E}[I_n(f)^2] = n!\\|f\\|_{H^{\\otimes n}}^2 = n! \\frac{1}{n!} = 1$.\nSubstituting this normalization into the result from part 2:\n$$\n\\mathbb{E}[\\|D^k F\\|_{H^{\\otimes k}}^2] = \\frac{(n!)^2}{(n-k)!} \\left(\\frac{1}{n!}\\right) = \\frac{n!}{(n-k)!}\n$$\nThis expression can also be written as the falling factorial $P(n,k) = n(n-1)\\dots(n-k+1)$. This is the final simplified analytic expression.", "answer": "$$\\boxed{\\frac{n!}{(n-k)!}}$$", "id": "3002269"}, {"introduction": "Having explored the derivative operator $D$, we now turn to its adjoint, the Skorokhod integral $\\delta$. This operator extends stochastic integration beyond the limits of Itô's theory, and this exercise provides a striking example of its power [@problem_id:3002238]. You will analyze a simple-looking process that is not adapted to the Brownian filtration, making it non-integrable in the Itô sense, and use the fundamental duality between $D$ and $\\delta$ to explicitly compute its Skorokhod integral.", "problem": "Let $\\{W_{t}\\}_{t \\in [0,1]}$ be a one-dimensional standard Brownian motion on a complete filtered probability space $(\\Omega,\\mathcal{F},\\{\\mathcal{F}_{t}\\}_{t \\in [0,1]},\\mathbb{P})$ with the natural (right-continuous, complete) filtration. Let $\\mathfrak{H} = L^{2}([0,1])$ and consider the isonormal Gaussian process $W(h) = \\int_{0}^{1} h(t)\\, \\mathrm{d}W_{t}$ for $h \\in \\mathfrak{H}$. Denote by $\\mathbb{D}^{1,2}$ the Malliavin-Sobolev space of square-integrable random variables with square-integrable Malliavin derivative, by $D$ the Malliavin derivative operator acting on smooth cylindrical functionals, and by $\\delta$ the Skorokhod integral defined as the $L^{2}$-adjoint of $D$ on $\\mathbb{D}^{1,2}$.\n\nDefine the process $u: \\Omega \\times [0,1] \\to \\mathbb{R}$ by $u_{t}(\\omega) = W_{1}(\\omega) \\mathbf{1}_{[0,1]}(t)$.\n\n1) Prove that $u \\in L^{2}(\\Omega \\times [0,1])$ and that $u$ is not progressively measurable with respect to $\\{\\mathcal{F}_{t}\\}_{t \\in [0,1]}$.\n\n2) Starting from the duality definition of the Skorokhod integral $\\delta$ as the adjoint of the Malliavin derivative $D$, show that $u$ belongs to the domain of $\\delta$ and compute $\\delta(u)$ explicitly as a random variable in terms of $W_{1}$.\n\n3) Compute the variance of $\\delta(u)$ and give the exact value.\n\nYour final answer should be the exact value of the variance from part 3 as a single real number. No rounding is required.", "solution": "The problem statement is a well-defined exercise in Malliavin calculus. It relies on standard definitions of the Malliavin derivative, the Skorokhod integral, and associated function spaces. All provided information is consistent and sufficient to proceed with a rigorous solution. The problem is deemed valid.\n\nThe solution is presented in three parts, corresponding to the three questions asked.\n\n### Part 1: Analysis of the process $u$\n\nFirst, we prove that the process $u_{t}(\\omega) = W_{1}(\\omega) \\mathbf{1}_{[0,1]}(t)$ belongs to the space $L^{2}(\\Omega \\times [0,1])$. This requires showing that the norm $\\|u\\|_{L^{2}(\\Omega \\times [0,1])}^{2} = \\mathbb{E}\\left[\\int_{0}^{1} |u_{t}|^{2} \\, \\mathrm{d}t\\right]$ is finite.\nWe substitute the definition of $u_{t}$:\n$$\n\\mathbb{E}\\left[\\int_{0}^{1} |u_{t}|^{2} \\, \\mathrm{d}t\\right] = \\mathbb{E}\\left[\\int_{0}^{1} |W_{1} \\mathbf{1}_{[0,1]}(t)|^{2} \\, \\mathrm{d}t\\right]\n$$\nSince $\\mathbf{1}_{[0,1]}(t) = 1$ for $t \\in [0,1]$, the expression simplifies to:\n$$\n\\mathbb{E}\\left[\\int_{0}^{1} W_{1}^{2} \\, \\mathrm{d}t\\right] = \\mathbb{E}\\left[W_{1}^{2} \\int_{0}^{1} 1 \\, \\mathrm{d}t\\right] = \\mathbb{E}[W_{1}^{2} \\cdot 1] = \\mathbb{E}[W_{1}^{2}]\n$$\nBy definition, $\\{W_{t}\\}_{t \\in [0,1]}$ is a standard Brownian motion, so $W_{1}$ is a standard normal random variable, $W_{1} \\sim N(0,1)$. The expectation of $W_{1}$ is $\\mathbb{E}[W_{1}] = 0$ and its variance is $\\text{Var}(W_{1}) = 1$. The second moment is given by $\\mathbb{E}[W_{1}^{2}] = \\text{Var}(W_{1}) + (\\mathbb{E}[W_{1}])^{2} = 1 + 0^{2} = 1$.\nTherefore,\n$$\n\\|u\\|_{L^{2}(\\Omega \\times [0,1])}^{2} = \\mathbb{E}[W_{1}^{2}] = 1\n$$\nSince $1  \\infty$, we conclude that $u \\in L^{2}(\\Omega \\times [0,1])$.\n\nSecond, we prove that $u$ is not progressively measurable with respect to the filtration $\\{\\mathcal{F}_{t}\\}_{t \\in [0,1]}$. A process $\\{X_{t}\\}_{t \\in [0,1]}$ is progressively measurable if, for every $t \\in [0,1]$, the mapping $(\\omega, s) \\mapsto X_{s}(\\omega)$ from $\\Omega \\times [0,t]$ to $\\mathbb{R}$ is measurable with respect to the product sigma-algebra $\\mathcal{F}_{t} \\otimes \\mathcal{B}([0,t])$. A necessary condition for a process to be progressively measurable is that it must be adapted to the filtration, meaning $X_{t}$ must be $\\mathcal{F}_{t}$-measurable for all $t \\in [0,1]$.\n\nLet us check if the process $u_{t}$ is adapted. For any $t \\in [0,1)$, we have $u_{t} = W_{1}$. For $u_{t}$ to be adapted, $W_{1}$ must be $\\mathcal{F}_{t}$-measurable for any $t \\in [0,1)$. However, consider a specific $t \\in (0,1)$. We can write $W_{1} = W_{t} + (W_{1} - W_{t})$. The term $W_{t}$ is $\\mathcal{F}_{t}$-measurable by definition of the filtration. The increment $W_{1} - W_{t}$ is independent of the sigma-algebra $\\mathcal{F}_{t}$. If $W_{1}$ were $\\mathcal{F}_{t}$-measurable, then the difference $W_{1} - W_{t}$ would also have to be $\\mathcal{F}_{t}$-measurable. A random variable that is measurable with respect to a sigma-algebra and simultaneously independent of it must be constant almost surely. But $W_{1} - W_{t}$ is a normal random variable with mean $0$ and variance $1-t > 0$, so it is not a constant. This is a contradiction.\nThus, for any $t \\in [0,1)$, $W_{1}$ is not $\\mathcal{F}_{t}$-measurable. This implies that the process $u_t$ is not adapted. Since a progressively measurable process must be adapted, we conclude that $u$ is not progressively measurable.\n\n### Part 2: Skorokhod Integral of $u$\n\nWe want to show that $u$ belongs to the domain of the Skorokhod integral, $\\text{Dom}(\\delta)$, and to compute $\\delta(u)$. The Skorokhod integral $\\delta(u)$ is defined as the unique random variable in $L^{2}(\\Omega)$ that satisfies the duality formula:\n$$\n\\mathbb{E}[F \\delta(u)] = \\mathbb{E}[\\langle u, DF \\rangle_{\\mathfrak{H}}] \\quad \\forall F \\in \\mathbb{D}^{1,2}\n$$\nwhere $\\langle \\cdot, \\cdot \\rangle_{\\mathfrak{H}}$ is the inner product in $\\mathfrak{H}=L^{2}([0,1])$. The existence of such a $\\delta(u) \\in L^2(\\Omega)$ is equivalent to $u \\in \\text{Dom}(\\delta)$. We compute the right-hand side for our process $u_{t} = W_{1}$:\n$$\n\\mathbb{E}[\\langle u, DF \\rangle_{\\mathfrak{H}}] = \\mathbb{E}\\left[\\int_{0}^{1} u_{t} (D_{t}F) \\, \\mathrm{d}t\\right] = \\mathbb{E}\\left[\\int_{0}^{1} W_{1} (D_{t}F) \\, \\mathrm{d}t\\right] = \\mathbb{E}\\left[W_{1} \\int_{0}^{1} D_{t}F \\, \\mathrm{d}t\\right]\n$$\nTo simplify this expression, we use the product rule for the Malliavin derivative on the product $F W_{1}$:\n$$\nD_{t}(F W_{1}) = F (D_{t}W_{1}) + W_{1} (D_{t}F)\n$$\nThe Malliavin derivative of $W_{1} = \\int_{0}^{1} 1 \\, \\mathrm{d}W_{s}$ is $D_{t}W_{1} = 1$ for $t \\in [0,1]$. Thus,\n$$\nD_{t}(F W_{1}) = F + W_{1} (D_{t}F)\n$$\nRearranging gives $W_{1} (D_{t}F) = D_{t}(F W_{1}) - F$. Substituting this into our expectation:\n$$\n\\mathbb{E}[\\langle u, DF \\rangle_{\\mathfrak{H}}] = \\mathbb{E}\\left[\\int_{0}^{1} (D_{t}(F W_{1}) - F) \\, \\mathrm{d}t\\right]\n$$\nBy linearity of expectation and integral, we have:\n$$\n\\mathbb{E}\\left[\\int_{0}^{1} D_{t}(F W_{1}) \\, \\mathrm{d}t\\right] - \\mathbb{E}\\left[\\int_{0}^{1} F \\, \\mathrm{d}t\\right] = \\mathbb{E}[\\langle \\mathbf{1}, D(F W_{1}) \\rangle_{\\mathfrak{H}}] - \\mathbb{E}[F]\n$$\nwhere $\\mathbf{1}$ denotes the constant function equal to $1$ on $[0,1]$. We can now apply the duality formula in reverse to the first term. For any random variable $G \\in \\mathbb{D}^{1,2}$, we have $\\mathbb{E}[\\langle h, DG \\rangle_{\\mathfrak{H}}] = \\mathbb{E}[G \\delta(h)]$ for $h \\in \\mathfrak{H}$. Let $h = \\mathbf{1}$ and $G = F W_{1}$. The Skorokhod integral of the deterministic function $h(t)=1$ is simply the Wiener integral:\n$$\n\\delta(\\mathbf{1}) = \\int_{0}^{1} 1 \\, \\mathrm{d}W_{t} = W_{1}\n$$\nSo, $\\mathbb{E}[\\langle \\mathbf{1}, D(F W_{1}) \\rangle_{\\mathfrak{H}}] = \\mathbb{E}[(F W_{1}) \\delta(\\mathbf{1})] = \\mathbb{E}[F W_{1}^{2}]$.\nSubstituting this result back, we get:\n$$\n\\mathbb{E}[\\langle u, DF \\rangle_{\\mathfrak{H}}] = \\mathbb{E}[F W_{1}^{2}] - \\mathbb{E}[F] = \\mathbb{E}[F(W_{1}^{2} - 1)]\n$$\nComparing this with the duality definition $\\mathbb{E}[F \\delta(u)]$, we can identify $\\delta(u)$. The random variable $Y = W_{1}^{2}-1$ is in $L^{2}(\\Omega)$ since $\\mathbb{E}[(W_{1}^{2}-1)^{2}] = \\mathbb{E}[W_{1}^{4} - 2W_{1}^{2} + 1] = 3 - 2(1) + 1 = 2  \\infty$. The map $F \\mapsto \\mathbb{E}[F(W_{1}^{2}-1)]$ is a continuous linear functional on $\\mathbb{D}^{1,2}$, which confirms that $u \\in \\text{Dom}(\\delta)$. By uniqueness, we identify the Skorokhod integral as:\n$$\n\\delta(u) = W_{1}^{2} - 1\n$$\nThis is the second Hermite polynomial of $W_{1}$.\n\n### Part 3: Variance of $\\delta(u)$\n\nWe are asked to compute the variance of $\\delta(u) = W_{1}^{2} - 1$. The variance of a random variable $Y$ is given by $\\text{Var}(Y) = \\mathbb{E}[Y^2] - (\\mathbb{E}[Y])^2$.\nFirst, we compute the expectation of $\\delta(u)$:\n$$\n\\mathbb{E}[\\delta(u)] = \\mathbb{E}[W_{1}^{2} - 1] = \\mathbb{E}[W_{1}^{2}] - 1\n$$\nAs established in Part 1, $\\mathbb{E}[W_{1}^{2}] = 1$. So,\n$$\n\\mathbb{E}[\\delta(u)] = 1 - 1 = 0\n$$\nSince the mean is zero, the variance is simply the second moment:\n$$\n\\text{Var}(\\delta(u)) = \\mathbb{E}[(\\delta(u))^{2}] = \\mathbb{E}[(W_{1}^{2} - 1)^{2}]\n$$\nExpanding the square, we get:\n$$\n\\mathbb{E}[(W_{1}^{2} - 1)^{2}] = \\mathbb{E}[W_{1}^{4} - 2W_{1}^{2} + 1] = \\mathbb{E}[W_{1}^{4}] - 2\\mathbb{E}[W_{1}^{2}] + 1\n$$\nWe already know $\\mathbb{E}[W_{1}^{2}]=1$. For a standard normal variable $Z \\sim N(0,1)$, the fourth moment is $\\mathbb{E}[Z^4] = 3$. Thus, $\\mathbb{E}[W_{1}^{4}]=3$.\nSubstituting these values:\n$$\n\\text{Var}(\\delta(u)) = 3 - 2(1) + 1 = 2\n$$\nAlternatively, we can use the Itô-Skorokhod isometry for a zero-mean process $u \\in \\text{Dom}(\\delta)$, which states:\n$$\n\\mathbb{E}[(\\delta(u))^{2}] = \\mathbb{E}\\left[\\int_{0}^{1} u_{t}^{2} \\, \\mathrm{d}t\\right] + \\mathbb{E}\\left[\\int_{0}^{1}\\int_{0}^{1} (D_{s}u_{t})(D_{t}u_{s}) \\, \\mathrm{d}s \\, \\mathrm{d}t\\right]\n$$\nThe process $u_{t} = W_{1}$ has mean $\\mathbb{E}[u_{t}]=0$. We calculated the first term in Part 1: $\\mathbb{E}\\left[\\int_{0}^{1} u_{t}^{2} \\, \\mathrm{d}t\\right] = 1$.\nFor the second term, we have $u_{t} = W_{1}$, so $D_{s}u_{t} = D_{s}W_{1} = 1$ for all $s,t \\in [0,1]$.\n$$\n\\mathbb{E}\\left[\\int_{0}^{1}\\int_{0}^{1} (1)(1) \\, \\mathrm{d}s \\, \\mathrm{d}t\\right] = \\mathbb{E}\\left[\\left(\\int_{0}^{1} \\mathrm{d}s\\right)\\left(\\int_{0}^{1} \\mathrm{d}t\\right)\\right] = \\mathbb{E}[1 \\cdot 1] = 1\n$$\nSumming the two terms gives $\\mathbb{E}[(\\delta(u))^{2}] = 1 + 1 = 2$. Since $\\mathbb{E}[\\delta(u)]=0$, this is also the variance. Both methods yield the same result.\nThe variance of $\\delta(u)$ is $2$.", "answer": "$$\n\\boxed{2}\n$$", "id": "3002238"}]}