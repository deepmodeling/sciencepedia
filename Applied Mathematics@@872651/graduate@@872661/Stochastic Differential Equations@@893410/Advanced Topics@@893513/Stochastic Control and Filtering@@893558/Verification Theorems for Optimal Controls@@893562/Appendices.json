{"hands_on_practices": [{"introduction": "The heart of a verification theorem lies in constructing an optimal feedback control from the Hamilton-Jacobi-Bellman (HJB) equation. This construction critically depends on our ability to find a control $u$ that minimizes the Hamiltonian expression for any given state and time. This first practice explores the fundamental analytical conditions that guarantee such a minimizer exists. By working through this problem, you will solidify your understanding of why assumptions like compactness of the control set or coercivity of the cost are not mere technicalities, but crucial underpinnings that make the entire verification framework viable [@problem_id:3005364].", "problem": "Consider a controlled stochastic differential equation on the finite horizon $[0,T]$ of the form\n$$\n\\mathrm{d}X_t = b(t,X_t,u_t)\\,\\mathrm{d}t + \\sigma(t,X_t,u_t)\\,\\mathrm{d}W_t, \\quad X_0 = x \\in \\mathbb{R}^d,\n$$\nwhere $W_t$ is a standard $d$-dimensional Brownian motion, $u_t$ is a control process taking values in a set $\\mathcal{U} \\subset \\mathbb{R}^m$, and the functions $b$ and $\\sigma$ satisfy standard Lipschitz continuity and linear growth conditions in $(x,u)$ that ensure existence and uniqueness of strong solutions for progressively measurable controls. The performance functional is\n$$\nJ(x;u) = \\mathbb{E}\\left[\\int_0^T \\ell(t,X_t,u_t)\\,\\mathrm{d}t + \\phi(X_T)\\right],\n$$\nwhere $\\ell$ and $\\phi$ are bounded from below and satisfy suitable measurability and continuity properties. An admissible control is any progressively measurable process $u_t$ with $u_t \\in \\mathcal{U}$ almost surely for each $t \\in [0,T]$, and such that the resulting state process $X_t$ is well-defined and $J(x;u)$ is finite.\n\nA verification theorem for the Hamilton–Jacobi–Bellman (HJB) framework asserts, under appropriate conditions, that if a candidate value function $V \\in C^{1,2}([0,T]\\times\\mathbb{R}^d)$ satisfies the HJB equation in the classical sense together with terminal condition $V(T,x)=\\phi(x)$, and if one can construct a measurable minimizing selector $(t,x) \\mapsto u^*(t,x)\\in \\mathcal{U}$ that attains the pointwise infimum associated with the Hamiltonian $H$, then the feedback control $\\hat{u}_t := u^*(t,X_t)$ is optimal and the value function is $V(t,x)$.\n\nIn this setting, assumptions on the admissible control set $\\mathcal{U}$ (such as compactness) and on the dependence in $u$ of the data $(b,\\sigma,\\ell)$ (such as coercivity and lower semicontinuity in $u$) are often imposed to ensure the existence of minimizers for the Hamiltonian and the measurability of selectors.\n\nWhich of the following statements about admissible control sets $\\mathcal{U}$ and the role of compactness or coercivity in $u$ in verification theorems is/are correct?\n\nA. If $\\mathcal{U}$ is compact and, for each $(t,x)$, the mappings $u \\mapsto b(t,x,u)$, $u \\mapsto \\sigma(t,x,u)$, and $u \\mapsto \\ell(t,x,u)$ are continuous, then the pointwise infimum in the Hamiltonian $H$ is attained for every $(t,x)$, and measurable selection theorems can be invoked to produce a measurable minimizing selector $(t,x) \\mapsto u^*(t,x)$; hence compactness directly supports the construction needed in verification.\n\nB. If $\\mathcal{U}$ is closed (not necessarily compact) and the map $u \\mapsto \\ell(t,x,u) + p \\cdot b(t,x,u) + \\tfrac{1}{2}\\mathrm{Tr}\\big(\\sigma(t,x,u)\\sigma(t,x,u)^\\top M\\big)$ is lower semicontinuous and coercive in $u$ uniformly in $(t,x,p,M)$, then the pointwise infimum in the Hamiltonian is attained in $\\mathcal{U}$, preventing minimizing sequences from escaping to infinity; thus coercivity can be used in lieu of compactness to verify existence of minimizers.\n\nC. When $\\sigma$ depends on $u$, compactness of $\\mathcal{U}$ is irrelevant to verification because the diffusion term does not influence the attainment of the infimum in the Hamiltonian; only the drift term matters for minimization.\n\nD. If the value function $V$ is twice continuously differentiable in $x$, then the pointwise infimum in the Hamiltonian is automatically attained even when $\\mathcal{U}$ is unbounded and there is no coercivity, because the second derivatives in $x$ regularize the optimization in $u$.\n\nE. Compactness of $\\mathcal{U}$ is needed solely for uniqueness of solutions to the HJB equation; it has no bearing on the existence of optimal controls or on the construction of measurable minimizing selectors.\n\nSelect all correct options. Your reasoning should begin from the core definitions of admissible controls and the verification framework and proceed through the implications for existence and measurability of minimizers without invoking shortcut formulas or unstated assumptions.", "solution": "The problem statement describes a standard stochastic optimal control problem in continuous time over a finite horizon $[0,T]$. The goal is to minimize a cost functional $J(x;u)$ by choosing an admissible control process $u_t$. The problem asks to evaluate statements regarding the assumptions on the control set $\\mathcal{U}$ and the data $(b, \\sigma, \\ell)$ that are used in verification theorems based on the Hamilton-Jacobi-Bellman (HJB) equation.\n\nThe HJB equation for the value function $V(t,x)$ is a partial differential equation given by:\n$$\n\\frac{\\partial V}{\\partial t}(t,x) + H(t, x, DV(t,x), D^2V(t,x)) = 0, \\quad \\text{for } (t,x) \\in [0,T) \\times \\mathbb{R}^d\n$$\nwith the terminal condition $V(T,x) = \\phi(x)$. The operator $DV$ denotes the gradient with respect to $x$, and $D^2V$ denotes the Hessian matrix. The Hamiltonian, $H$, is defined by a minimization over the control set $\\mathcal{U}$:\n$$\nH(t, x, p, M) = \\inf_{u \\in \\mathcal{U}} \\left\\{ \\ell(t,x,u) + p \\cdot b(t,x,u) + \\frac{1}{2}\\mathrm{Tr}\\left(\\sigma(t,x,u)\\sigma(t,x,u)^\\top M\\right) \\right\\}.\n$$\nA cornerstone of a verification theorem is the ability to construct an optimal feedback control $\\hat{u}_t = u^*(t, X_t)$ from a measurable function $(t,x) \\mapsto u^*(t,x)$ that attains the infimum in the Hamiltonian for each $(t,x)$. That is, $u^*(t,x)$ must be a minimizer of the expression in the curly braces, where $p=DV(t,x)$ and $M=D^2V(t,x)$. The existence and measurability of such a $u^*$ are therefore critical.\n\nWe now evaluate each option.\n\nA. If $\\mathcal{U}$ is compact and, for each $(t,x)$, the mappings $u \\mapsto b(t,x,u)$, $u \\mapsto \\sigma(t,x,u)$, and $u \\mapsto \\ell(t,x,u)$ are continuous, then the pointwise infimum in the Hamiltonian $H$ is attained for every $(t,x)$, and measurable selection theorems can be invoked to produce a measurable minimizing selector $(t,x) \\mapsto u^*(t,x)$; hence compactness directly supports the construction needed in verification.\n\nThis statement is **Correct**. For any fixed $(t,x)$ and for the corresponding gradient $p=DV(t,x)$ and Hessian $M=D^2V(t,x)$, we consider the function to be minimized over $u \\in \\mathcal{U}$:\n$$\nf(u) = \\ell(t,x,u) + p \\cdot b(t,x,u) + \\frac{1}{2}\\mathrm{Tr}\\left(\\sigma(t,x,u)\\sigma(t,x,u)^\\top M\\right).\n$$\nThe assumption that $b$, $\\sigma$, and $\\ell$ are continuous functions of $u$ implies that $f(u)$ is also a continuous function of $u$. The Weierstrass Extreme Value Theorem states that a continuous real-valued function on a non-empty compact set attains its infimum (i.e., a minimum exists). Since $\\mathcal{U}$ is assumed to be compact, for each $(t,x)$, there exists at least one $u^*(t,x) \\in \\mathcal{U}$ that minimizes $f(u)$. Furthermore, standard measurable selection theorems (e.g., the Kuratowski and Ryll-Nardzewski selection theorem) require certain topological properties of the control set (like being a Polish space, which any compact subset of $\\mathbb{R}^m$ is) and measurability/continuity properties of the function being optimized. The conditions stated (continuity in $u$ and implicit measurability in $(t,x)$) are the standard ingredients for applying such theorems to guarantee the existence of a *measurable* selector $(t,x) \\mapsto u^*(t,x)$. Thus, compactness of $\\mathcal{U}$ is a cornerstone assumption that ensures both the existence of a minimizer and the ability to construct a measurable one.\n\nB. If $\\mathcal{U}$ is closed (not necessarily compact) and the map $u \\mapsto \\ell(t,x,u) + p \\cdot b(t,x,u) + \\tfrac{1}{2}\\mathrm{Tr}\\big(\\sigma(t,x,u)\\sigma(t,x,u)^\\top M\\big)$ is lower semicontinuous and coercive in $u$ uniformly in $(t,x,p,M)$, then the pointwise infimum in the Hamiltonian is attained in $\\mathcal{U}$, preventing minimizing sequences from escaping to infinity; thus coercivity can be used in lieu of compactness to verify existence of minimizers.\n\nThis statement is **Correct**. This describes a standard alternative to the compactness assumption. A function $f(u)$ is coercive on $\\mathcal{U} \\subseteq \\mathbb{R}^m$ if $f(u) \\to \\infty$ as $\\|u\\| \\to \\infty$ for $u \\in \\mathcal{U}$. A fundamental result in optimization theory states that a lower semicontinuous (LSC) and coercive function on a non-empty closed subset of $\\mathbb{R}^m$ attains its infimum. The reasoning is as follows: let $\\{u_n\\}_{n \\in \\mathbb{N}}$ be a minimizing sequence in $\\mathcal{U}$. Because the function is coercive, the sequence $\\{u_n\\}$ must be bounded, otherwise the function values would tend to infinity, contradicting that it is a minimizing sequence. By the Bolzano-Weierstrass theorem, this bounded sequence has a convergent subsequence, say $u_{n_k} \\to u_0$. Since $\\mathcal{U}$ is closed, the limit point $u_0$ is in $\\mathcal{U}$. By the definition of lower semicontinuity, the function value at the limit point is less than or equal to the limit inferior of the function values along the sequence, which is the infimum. Thus, the infimum is attained at $u_0$. This demonstrates that coercivity serves the same purpose as compactness in ensuring a minimizing sequence remains in a bounded region, thereby guaranteeing the existence of a limit point where the minimum is achieved.\n\nC. When $\\sigma$ depends on $u$, compactness of $\\mathcal{U}$ is irrelevant to verification because the diffusion term does not influence the attainment of the infimum in the Hamiltonian; only the drift term matters for minimization.\n\nThis statement is **Incorrect**. The Hamiltonian involves minimizing the entire expression $\\ell(t,x,u) + p \\cdot b(t,x,u) + \\frac{1}{2}\\mathrm{Tr}\\left(\\sigma(t,x,u)\\sigma(t,x,u)^\\top M\\right)$ over $u \\in \\mathcal{U}$. If the diffusion coefficient $\\sigma$ depends on the control $u$, then the term $\\frac{1}{2}\\mathrm{Tr}\\left(\\sigma(t,x,u)\\sigma(t,x,u)^\\top M\\right)$ is generally a non-constant function of $u$. The minimization problem must account for how $u$ affects all three components: the running cost $\\ell$, the drift $b$, and the diffusion $\\sigma$. To claim that the diffusion term is irrelevant to the minimization is fundamentally wrong. For instance, in financial applications, controlling portfolio volatility (related to $\\sigma$) is a primary objective. The statement is false.\n\nD. If the value function $V$ is twice continuously differentiable in $x$, then the pointwise infimum in the Hamiltonian is automatically attained even when $\\mathcal{U}$ is unbounded and there is no coercivity, because the second derivatives in $x$ regularize the optimization in $u$.\n\nThis statement is **Incorrect**. The differentiability of the value function $V$ determines the coefficients $p = DV(t,x)$ and $M = D^2V(t,x)$ in the Hamiltonian optimization problem. However, the smoothness of $V$ does not alter the fundamental nature of the optimization with respect to $u$. If the function $f(u) = \\ell(t,x,u) + p \\cdot b(t,x,u) + \\frac{1}{2}\\mathrm{Tr}\\left(\\sigma(t,x,u)\\sigma(t,x,u)^\\top M\\right)$ does not possess properties that guarantee a minimum is attained on $\\mathcal{U}$ (e.g., continuous on a compact set, or LSC and coercive on a closed set), then a minimum may not exist. For a simple counterexample, let $\\ell=0$, $b(u)=-u^2$, $\\sigma=0$, and $\\mathcal{U}=\\mathbb{R}$. The expression to minimize is $-p u^2$. If $p>0$, this function is unbounded below on $\\mathbb{R}$, and its infimum of $-\\infty$ is never attained. The fact that $p$ might originate from a $C^2$ function $V$ is irrelevant to the non-existence of a minimizer for this sub-problem.\n\nE. Compactness of $\\mathcal{U}$ is needed solely for uniqueness of solutions to the HJB equation; it has no bearing on the existence of optimal controls or on the construction of measurable minimizing selectors.\n\nThis statement is **Incorrect**. It is incorrect on multiple counts. First, the uniqueness of solutions to the HJB equation is a complex topic, typically addressed in the framework of viscosity solutions, where comparison principles are the main tool. While properties of the Hamiltonian matter, compactness of $\\mathcal{U}$ is not the primary or sole condition for uniqueness. Second, as established in the analysis of option A, compactness of $\\mathcal{U}$ (combined with continuity of the data in $u$) is a standard and direct way to prove the existence of a pointwise minimizer for the Hamiltonian. This minimizer is the foundation for constructing an optimal control. Third, as also discussed for option A, the topological properties of a compact set are crucial for applying measurable selection theorems. Therefore, compactness has a direct and fundamental bearing on both the existence of optimal controls and the construction of measurable selectors. The statement is a complete misrepresentation of the role of compactness.\n\nFinal summary: statements A and B correctly describe the roles of compactness and coercivity, respectively, in ensuring the existence of a minimizer for the Hamiltonian, a critical step in verification theorems. Statements C, D, and E are fundamentally flawed.", "answer": "$$\\boxed{AB}$$", "id": "3005364"}, {"introduction": "Classical verification theorems lean heavily on the assumption that the value function is twice continuously differentiable ($C^{2,1}$), a property often ensured when the diffusion is uniformly non-degenerate. However, many practical models involve degenerate noise, where randomness does not directly influence every state variable, causing the HJB equation to become a degenerate parabolic PDE. This practice problem challenges you to consider the consequences of this degeneracy, revealing the limits of classical theory and motivating the essential shift to the modern framework of viscosity solutions [@problem_id:3005341].", "problem": "Consider a controlled stochastic differential equation given by the Itô stochastic differential equation\n$$\n\\mathrm{d}X_t = b\\big(X_t, a_t\\big)\\,\\mathrm{d}t + \\sigma\\big(X_t, a_t\\big)\\,\\mathrm{d}W_t,\n$$\nwhere $X_t \\in \\mathbb{R}^n$, the control process $a_t \\in A$ takes values in a compact control set $A$, $b:\\mathbb{R}^n \\times A \\to \\mathbb{R}^n$ and $\\sigma:\\mathbb{R}^n \\times A \\to \\mathbb{R}^{n \\times m}$ are continuous and sufficiently smooth in the spatial variable, and $W_t$ is a standard $m$-dimensional Brownian motion. Let the performance criterion be\n$$\nJ^{a} (t,x) \\;\\equiv\\; \\mathbb{E}\\Bigg[\\int_t^{T} \\ell\\big(X_s^{t,x,a}, a_s\\big)\\,\\mathrm{d}s \\;+\\; g\\big(X_T^{t,x,a}\\big)\\Bigg],\n$$\nwith running cost $\\ell:\\mathbb{R}^n \\times A \\to \\mathbb{R}$ and terminal cost $g:\\mathbb{R}^n \\to \\mathbb{R}$, and define the value function\n$$\nV(t,x) \\;\\equiv\\; \\inf_{a_\\cdot} J^{a}(t,x).\n$$\nUnder the dynamic programming principle, the associated Hamilton-Jacobi-Bellman (HJB) equation in the viscosity sense is the fully nonlinear second-order partial differential equation\n$$\n- V_t(t,x) \\;=\\; \\inf_{a \\in A}\\Big\\{ \\ell(x,a) + b(x,a)\\cdot \\nabla V(t,x) + \\tfrac{1}{2}\\,\\mathrm{tr}\\big(\\sigma(x,a)\\sigma(x,a)^{\\top} D^2 V(t,x)\\big)\\Big\\},\n$$\nwith terminal condition $V(T,x)=g(x)$. Suppose $\\sigma(x,a)$ may be rank-deficient for some $(x,a)$, so $\\sigma(x,a)\\sigma(x,a)^{\\top}$ fails to be uniformly positive definite. For each fixed control $a \\in A$, consider the second-order linear operator\n$$\n\\mathcal{L}^a u(x) \\;\\equiv\\; b(x,a)\\cdot \\nabla u(x) \\;+\\; \\tfrac{1}{2}\\,\\mathrm{tr}\\big(\\sigma(x,a)\\sigma(x,a)^{\\top} D^2 u(x)\\big),\n$$\nand assume a uniform hypoellipticity condition of Hörmander type: for each $a \\in A$ and each $x \\in \\mathbb{R}^n$, the Lie algebra generated by the column vector fields of $\\sigma(\\cdot,a)$ together with their iterated commutators with $b(\\cdot,a)$ spans $\\mathbb{R}^n$ at $x$.\n\nSelect all statements that correctly describe the impact of such degeneracy and hypoellipticity on regularity of the HJB equation and on verification methods.\n\nA. If the Hörmander condition holds uniformly in $a \\in A$, then the value function $V$ is necessarily $\\mathrm{C}^{2,1}$ in $(t,x)$, hence the classical verification theorem based on Itô’s formula with $V \\in \\mathrm{C}^{2,1}$ applies without further structural assumptions.\n\nB. In rank-deficient cases, even with Hörmander hypoellipticity for each frozen control, the HJB remains fully nonlinear; therefore the viscosity solution framework is the appropriate notion of solution, and verification relies on subsolution/supersolution characterizations and comparison principles rather than on $\\mathrm{C}^2$ regularity and classical Itô differentiation of $V$.\n\nC. If $\\sigma$ is rank-deficient and Hörmander fails, then the dynamic programming principle breaks down and verification cannot be performed in any sense.\n\nD. Adding a vanishing viscosity regularization by replacing $\\sigma$ with $\\sigma_\\varepsilon$ satisfying $\\sigma_\\varepsilon(x,a)\\sigma_\\varepsilon(x,a)^{\\top} = \\sigma(x,a)\\sigma(x,a)^{\\top} + \\varepsilon I$ and letting $\\varepsilon \\to 0$ always yields convergence of the classical $\\mathrm{C}^{2,1}$ solutions to the original value function, and classical verification follows in the limit.\n\nE. If $A$ is compact, the coefficients $b$, $\\sigma$, and $\\ell$ are smooth and bounded, and the uniform Hörmander bracket-generating condition holds for the controlled vector fields, then the value function $V$ is the unique bounded continuous viscosity solution; moreover, $V$ enjoys local quantitative regularity (such as local Lipschitz continuity and semiconcavity in $x$), which suffices to implement viscosity-based verification using superdifferentials and generalized gradients even when $D^2 V$ does not exist pointwise.", "solution": "The core of the problem lies in the interplay between three features of the HJB equation:\n1.  **Full Nonlinearity:** The `inf` operator over the control set $A$ makes the PDE fully nonlinear.\n2.  **Degenerate Parabolicity:** The diffusion matrix $\\sigma\\sigma^\\top$ may be rank-deficient, so the equation is not uniformly parabolic.\n3.  **Hypoellipticity:** The Hörmander condition ensures that noise, through its interaction with the drift, eventually propagates in all directions, which provides a regularizing effect for *linear* PDEs.\n\nThe central question is how the regularizing effect of hypoellipticity competes with the singularity-inducing nature of full nonlinearity. A fundamental result in the theory of fully nonlinear PDEs is that solutions are generally not twice differentiable, even when the underlying operators are uniformly elliptic. The nonlinearity itself (e.g., the switching nature of the `inf` operator) typically limits the regularity of the value function to, at best, Lipschitz continuity or semiconcavity, but not $C^2$. The hypoellipticity of the frozen-control operators $\\mathcal{L}^a$ is not sufficient to overcome this loss of regularity caused by the nonlinearity. This lack of classical ($C^{2,1}$) solutions is the primary motivation for the theory of viscosity solutions.\n\nWith this background, we evaluate each option.\n\n**A. If the Hörmander condition holds uniformly in $a \\in A$, then the value function $V$ is necessarily $\\mathrm{C}^{2,1}$ in $(t,x)$, hence the classical verification theorem based on Itô’s formula with $V \\in \\mathrm{C}^{2,1}$ applies without further structural assumptions.**\n\nThis statement is **Incorrect**. The Hörmander condition guarantees smoothness for solutions to *linear* hypoelliptic equations. The HJB equation is *fully nonlinear*. The infimum operation generally destroys $C^2$ regularity, and the value function $V$ is typically not a classical $C^{2,1}$ solution. Therefore, the classical verification theorem is not applicable.\n\n**B. In rank-deficient cases, even with Hörmander hypoellipticity for each frozen control, the HJB remains fully nonlinear; therefore the viscosity solution framework is the appropriate notion of solution, and verification relies on subsolution/supersolution characterizations and comparison principles rather than on $\\mathrm{C}^2$ regularity and classical Itô differentiation of $V$.**\n\nThis statement is **Correct**. It accurately summarizes the modern approach. The HJB equation is fully nonlinear, which prevents classical solutions, making the viscosity solution framework the correct and necessary setting. In this framework, uniqueness is established via comparison principles, and the verification theorem involves showing that the value function is the unique viscosity solution. This process relies on the definitions of subsolutions and supersolutions, not on classical differentiability.\n\n**C. If $\\sigma$ is rank-deficient and Hörmander fails, then the dynamic programming principle breaks down and verification cannot be performed in any sense.**\n\nThis statement is **Incorrect**. The Dynamic Programming Principle (DPP) is a fundamental property of the optimal control problem itself and holds under very general conditions, independent of regularity conditions like Hörmander's. While the failure of this condition can make the analysis of the HJB equation much more difficult (e.g., uniqueness of viscosity solutions may be lost or require different arguments), it does not imply that verification is impossible \"in any sense.\" For instance, in the deterministic case ($\\sigma=0$), Hörmander's condition fails, yet a rich theory of verification exists.\n\n**D. Adding a vanishing viscosity regularization by replacing $\\sigma$ with $\\sigma_\\varepsilon$ satisfying $\\sigma_\\varepsilon(x,a)\\sigma_\\varepsilon(x,a)^{\\top} = \\sigma(x,a)\\sigma(x,a)^{\\top} + \\varepsilon I$ and letting $\\varepsilon \\to 0$ always yields convergence of the classical $\\mathrm{C}^{2,1}$ solutions to the original value function, and classical verification follows in the limit.**\n\nThis statement is **Incorrect**. This technique, the \"vanishing viscosity method,\" is a powerful tool, but its description here is flawed. The solution $V^\\varepsilon$ to the regularized, uniformly parabolic problem is still a solution to a *fully nonlinear* HJB equation. As such, $V^\\varepsilon$ is generally not a classical $C^{2,1}$ solution. The method relies on the stability of viscosity solutions under limits, allowing one to prove that the limit of $V^\\varepsilon$ as $\\varepsilon \\to 0$ is a viscosity solution to the original degenerate equation.\n\n**E. If $A$ is compact, the coefficients $b$, $\\sigma$, and $\\ell$ are smooth and bounded, and the uniform Hörmander bracket-generating condition holds for the controlled vector fields, then the value function $V$ is the unique bounded continuous viscosity solution; moreover, $V$ enjoys local quantitative regularity (such as local Lipschitz continuity and semiconcavity in $x$), which suffices to implement viscosity-based verification using superdifferentials and generalized gradients even when $D^2 V$ does not exist pointwise.**\n\nThis statement is **Correct**. It provides a precise and sophisticated description of the state of the art. Under these assumptions, it is a standard result that the value function $V$ is the unique bounded continuous viscosity solution of the HJB equation. The hypoellipticity condition is often essential in proving the comparison principle needed for uniqueness. Furthermore, while $V$ is not $C^2$, it possesses higher regularity than mere continuity (typically local Lipschitz continuity and semiconcavity). This enhanced regularity is precisely what is needed to make the viscosity-based verification theorem rigorous, using tools like generalized Itô formulas and sub/superdifferentials to handle points of non-differentiability.", "answer": "$$\\boxed{BE}$$", "id": "3005341"}, {"introduction": "Having established that non-smoothness is a common feature of value functions, especially in degenerate problems, the central challenge becomes how to perform verification without a classical Itō's formula. A powerful strategy is to approximate the non-smooth value function with a sequence of smooth functions for which verification is possible. This problem asks you to lay out a rigorous blueprint for such an argument using the vanishing viscosity method. By detailing this multi-step proof strategy, you will gain hands-on experience with one of the most important techniques in the modern theory of HJB equations, learning how to rigorously connect the world of smooth approximants back to the original non-smooth problem [@problem_id:3005383].", "problem": "Consider a finite-horizon stochastic optimal control problem with controlled Itō diffusion on $\\mathbb{R}^{d}$: for a fixed terminal time $T>0$, an initial state $x \\in \\mathbb{R}^{d}$, and an admissible control process $u=(u_{t})_{t \\in [0,T]}$ valued in a compact metric control set $U$, the state $X^{u}=(X^{u}_{t})_{t \\in [0,T]}$ satisfies\n$$\n\\mathrm{d}X^{u}_{t} \\;=\\; b\\!\\left(X^{u}_{t},u_{t}\\right)\\,\\mathrm{d}t \\;+\\; \\sigma\\!\\left(X^{u}_{t},u_{t}\\right)\\,\\mathrm{d}W_{t}, \n\\qquad X^{u}_{0}=x,\n$$\nwhere $W$ is a $d_{W}$-dimensional standard Brownian motion, and $b:\\mathbb{R}^{d}\\times U \\to \\mathbb{R}^{d}$, $\\sigma:\\mathbb{R}^{d}\\times U \\to \\mathbb{R}^{d \\times d_{W}}$ are continuous in all variables and locally Lipschitz in the state variable uniformly in the control, with at most linear growth, ensuring strong existence and uniqueness of solutions. The performance criterion is\n$$\nJ(x;u) \\;=\\; \\mathbb{E}\\!\\left[ \\int_{0}^{T} L\\!\\left(X^{u}_{t},u_{t}\\right)\\,\\mathrm{d}t \\;+\\; g\\!\\left(X^{u}_{T}\\right) \\right],\n$$\nwhere $L:\\mathbb{R}^{d}\\times U \\to \\mathbb{R}$ and $g:\\mathbb{R}^{d}\\to\\mathbb{R}$ are continuous, with $L$ bounded from below and of at most quadratic growth in the state, and $g$ of at most quadratic growth. The value function is\n$$\nV(x) \\;=\\; \\inf_{u \\in \\mathcal{U}} J(x;u),\n$$\nwhere $\\mathcal{U}$ is the set of progressively measurable $U$-valued controls. Assume the dynamic programming principle holds, and that $V$ is a bounded, continuous viscosity solution of the Hamilton–Jacobi–Bellman (HJB) equation associated with this problem and terminal condition $V(T,\\cdot)=g(\\cdot)$, in the sense of Crandall–Lions viscosity solutions.\n\nA common verification strategy when $V$ lacks smoothness is to regularize $V$ via vanishing viscosity or mollification to obtain smooth approximations $V^{\\varepsilon}$, verify the optimality for $V^{\\varepsilon}$ using Itō’s formula, and pass to the limit $\\varepsilon \\to 0$. Which of the following options provide a correct and sufficient blueprint—comprising both steps and necessary conditions—for such a verification theorem to conclude the existence of an optimal Markov feedback control $u^{*}$ and the identity $J(x;u^{*})=V(x)$?\n\nA. Introduce a vanishing viscosity regularization of the HJB that preserves the terminal data and yields smooth approximants. Specifically, for each $\\varepsilon>0$, construct $V^{\\varepsilon}\\in C^{1,2}\\!\\left([0,T]\\times \\mathbb{R}^{d}\\right)$ solving a perturbed HJB with an additional uniformly elliptic term and the same terminal condition, and assume $V^{\\varepsilon}\\to V$ locally uniformly. Use measurable selection on $U$ to construct a Markov feedback $u^{\\varepsilon}(t,x)$ that minimizes the regularized Hamiltonian at each $(t,x)$, and apply Itō’s formula to $V^{\\varepsilon}\\!\\left(t,X^{u}_{t}\\right)$ for arbitrary admissible $u$ to derive $J(x;u)\\ge V^{\\varepsilon}(0,x)$, and $J(x;u^{\\varepsilon})=V^{\\varepsilon}(0,x)$ up to an error of order $\\varepsilon$. With uniform growth bounds on $b$, $\\sigma$, $L$, $g$ and compact $U$, use dominated convergence and stability of the controlled dynamics under feedback laws to pass $\\varepsilon\\to 0$, extract a limit feedback $u^{*}$, and conclude $J(x;u^{*})=V(0,x)$. Finally, invoke a comparison principle for the viscosity problem to identify $V$ uniquely with the value function.\n\nB. Mollify $V$ in the spatial variable by convolving with a standard smoothing kernel to obtain $V^{\\varepsilon}\\in C^{2}\\!\\left(\\mathbb{R}^{d}\\right)$ pointwise approximations at each time, without requiring $V^{\\varepsilon}$ to satisfy any perturbed HJB. Apply Itō’s formula to $V^{\\varepsilon}\\!\\left(t,X^{u}_{t}\\right)$ for arbitrary admissible $u$, deduce $J(x;u)\\ge V^{\\varepsilon}(0,x)$ from the formal HJB inequalities, and pass $\\varepsilon\\to 0$ using pointwise convergence alone to conclude $J(x;u^{*})=V(0,x)$ for a feedback minimizer.\n\nC. Approximate the compact control set $U$ by finite subsets $U_{n}$, solve the dynamic programming equation for each $U_{n}$ to obtain smooth value functions $V_{n}$, select exact minimizers $u^{(n)}$, and pass $n\\to\\infty$ to get a limiting control $u^{*}$ with $J(x;u^{*})=V(0,x)$, without requiring any regularity of $V$ or verification inequalities along the original dynamics. Rely on the compactness of $U$ to assert the limit exists and is optimal.\n\nD. Add a vanishing viscosity term to the HJB and verify $J(x;u)\\ge V^{\\varepsilon}(0,x)$ for arbitrary $u$, but do not assume any stability or comparison principle to relate $V^{\\varepsilon}$ back to $V$, and do not require convergence $V^{\\varepsilon}\\to V$. Conclude optimality by letting $\\varepsilon\\to 0$ formally.\n\nE. Assume $V$ is semiconcave so that Alexandrov’s theorem provides twice differentiability almost everywhere, and apply a generalized Itō formula directly to $V\\!\\left(t,X^{u}_{t}\\right)$ without approximation; obtain the verification inequality and conclude optimality for a feedback minimizer derived from pointwise minimization of the Hamiltonian, without any regularization or limit process.\n\nSelect all correct option(s).", "solution": "The question asks to identify a correct and sufficient blueprint for a verification theorem that uses a regularization strategy to handle a non-smooth value function $V$. The goal is to prove that $V(0,x)$ is the optimal cost and to construct an optimal feedback control. The core difficulty is that the value function $V$, as a viscosity solution, is generally not $C^{1,2}$, so the classical verification theorem, which relies on Itō's formula applied to $V$, is not directly applicable. A regularization approach seeks to approximate $V$ with a sequence of smooth functions $V^\\varepsilon$ for which Itō's formula can be used.\n\nLet's analyze the options based on this principle:\n\n**A. Introduce a vanishing viscosity regularization...**\nThis option presents a complete and standard procedure known as the \"vanishing viscosity\" method.\n1.  **Regularization:** It proposes solving a perturbed HJB equation, for example, $-\\partial_t V^\\varepsilon - \\inf\\{\\dots\\} - \\varepsilon \\Delta V^\\varepsilon = 0$. This added uniformly elliptic term $\\varepsilon \\Delta V^\\varepsilon$ ensures that the solution $V^\\varepsilon$ is smooth ($C^{1,2}$), allowing the use of Itō's formula.\n2.  **Convergence:** It correctly assumes that $V^\\varepsilon \\to V$ locally uniformly as $\\varepsilon \\to 0$. This is a cornerstone stability result in viscosity solution theory.\n3.  **Verification for the Approximant:** For each $\\varepsilon > 0$, one constructs an $\\varepsilon$-optimal feedback control $u^\\varepsilon(t,x)$ and uses Itō's formula on the smooth $V^\\varepsilon$. This leads to inequalities of the form $J(x;u) \\ge V^\\varepsilon(0,x) - O(\\varepsilon)$ for any control $u$, and $J(x;u^\\varepsilon) \\le V^\\varepsilon(0,x) + O(\\varepsilon)$ for the constructed control.\n4.  **Limit Argument:** It correctly identifies the need for a limiting argument. This involves showing that a subsequence of the controls $u^\\varepsilon$ converges (in a suitable sense) to a limit control $u^*$, and that the costs converge appropriately, leveraging stability properties of the SDE and dominated convergence. Taking the limit $\\varepsilon \\to 0$ in the inequalities above yields $J(x;u) \\ge V(0,x)$ for all $u$, and $J(x;u^*) \\le V(0,x)$.\n5.  **Conclusion:** This pair of inequalities proves that $V(0,x)$ is the value function and $u^*$ is an optimal control. The mention of the comparison principle to uniquely identify $V$ is also a key part of the full theory.\nThis blueprint is correct, rigorous, and sufficient.\n\n**B. Mollify V in the spatial variable...**\nThis approach is flawed. While mollification (convolving $V$ with a smooth kernel) does produce a smooth function $V^\\varepsilon$, this $V^\\varepsilon$ does not satisfy a useful PDE. The original HJB equation is satisfied by $V$ only in the weak viscosity sense. There is no reason for the mollified function $V^\\varepsilon$ to satisfy the HJB inequality in a pointwise sense, which is what would be needed to apply Itō's formula and get the desired verification inequality. This method lacks the crucial connection between the approximant and a PDE that allows for a controlled error analysis.\n\n**C. Approximate the compact control set U...**\nThis describes a different type of approximation scheme (control discretization), not a regularization of the value function as prompted. Furthermore, its description is problematic. It claims the resulting value functions $V_n$ are \"smooth,\" which is not guaranteed as the HJB equation for a finite control set can still be degenerate. More importantly, it hand-waves the final, crucial step of proving the limit is optimal, stating it relies on compactness alone, which is insufficient. It is not a valid verification blueprint.\n\n**D. Add a vanishing viscosity term... but do not require convergence V^ε → V...**\nThis describes a broken procedure. The entire purpose of constructing the sequence $V^\\varepsilon$ is that it approximates the true value function $V$. Without the convergence $V^\\varepsilon \\to V$, any inequality derived for $V^\\varepsilon$ is useless for drawing conclusions about $V$. Formally letting $\\varepsilon \\to 0$ without a proven convergence result is not a valid mathematical argument.\n\n**E. Assume V is semiconcave... and apply a generalized Itō formula...**\nThis describes a valid and powerful verification technique, but it is explicitly *not* a regularization method. The prompt asks for a blueprint based on regularization (like vanishing viscosity or mollification). This option states it proceeds \"without any regularization or limit process.\" Therefore, while scientifically correct as an alternative method, it does not answer the specific question asked.\n\nBased on this analysis, only option A provides a correct and sufficient blueprint for the regularization-based verification strategy described in the prompt.", "answer": "$$\\boxed{A}$$", "id": "3005383"}]}