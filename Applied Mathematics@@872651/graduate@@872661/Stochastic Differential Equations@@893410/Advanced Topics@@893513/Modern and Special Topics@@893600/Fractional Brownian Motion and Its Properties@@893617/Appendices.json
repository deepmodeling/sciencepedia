{"hands_on_practices": [{"introduction": "This first exercise goes to the heart of what makes fractional Brownian motion a powerful modeling tool: its memory. By calculating the correlation between successive increments, you will directly see how the Hurst parameter $H$ dictates whether the process is persistent ($H \\gt 0.5$) or anti-persistent ($H \\lt 0.5$). This hands-on calculation solidifies the connection between the mathematical definition of fBm and its observable, long-range dependence behavior [@problem_id:1303119].", "problem": "A standard Fractional Brownian Motion (fBM), denoted by $\\{B_H(t)\\}_{t \\ge 0}$, is a continuous-time centered Gaussian process characterized by a single parameter $H \\in (0, 1)$ known as the Hurst parameter. Its key properties are that $B_H(0) = 0$, its mean is $E[B_H(t)] = 0$ for all $t \\ge 0$, and its covariance is given by the function $E[B_H(t) B_H(s)] = \\frac{1}{2}(t^{2H} + s^{2H} - |t-s|^{2H})$ for any $t, s \\ge 0$.\n\nThe value of the Hurst parameter $H$ determines the nature of the correlation between the process's increments. Consider two different stochastic models, Model A and Model B, both described by fBM but with different Hurst parameters.\n- Model A uses a Hurst parameter of $H_A = 0.2$.\n- Model B uses a Hurst parameter of $H_B = 0.8$.\n\nFor each model, we examine two consecutive, non-overlapping increments of unit duration. Let $I_1 = B_H(1) - B_H(0)$ be the increment over the time interval $[0, 1]$, and let $I_2 = B_H(2) - B_H(1)$ be the increment over the time interval $[1, 2]$.\n\nBased on the properties of fBM, which of the following statements correctly describes the sign of the statistical correlation between the increments $I_1$ and $I_2$ for Model A and Model B?\n\nA. Model A exhibits negative correlation; Model B exhibits positive correlation.\n\nB. Model A exhibits positive correlation; Model B exhibits negative correlation.\n\nC. Both models exhibit positive correlation.\n\nD. Both models exhibit negative correlation.\n\nE. Both models exhibit a correlation of zero.", "solution": "For $I_{1} = B_{H}(1) - B_{H}(0)$ and $I_{2} = B_{H}(2) - B_{H}(1)$, use $\\operatorname{Cov}(X,Y) = E[XY] - E[X]E[Y]$ and the fact that $E[B_{H}(t)] = 0$ for all $t \\ge 0$ to write\n$$\n\\operatorname{Cov}(I_{1}, I_{2}) = E\\big[(B_{H}(1) - B_{H}(0))(B_{H}(2) - B_{H}(1))\\big].\n$$\nExpanding and using the given covariance function $R(t,s) = E[B_{H}(t)B_{H}(s)] = \\frac{1}{2}\\big(t^{2H} + s^{2H} - |t-s|^{2H}\\big)$, we obtain\n$$\n\\operatorname{Cov}(I_{1}, I_{2}) = R(1,2) - R(1,1) - R(0,2) + R(0,1).\n$$\nCompute each term:\n$$\nR(1,2) = \\frac{1}{2}\\big(1^{2H} + 2^{2H} - |1|^{2H}\\big) = \\frac{1}{2} \\cdot 2^{2H}, \\quad\nR(1,1) = \\frac{1}{2}\\big(1^{2H} + 1^{2H} - 0^{2H}\\big) = 1,\n$$\n$$\nR(0,2) = \\frac{1}{2}\\big(0^{2H} + 2^{2H} - |2|^{2H}\\big) = 0, \\quad\nR(0,1) = \\frac{1}{2}\\big(0^{2H} + 1^{2H} - |1|^{2H}\\big) = 0.\n$$\nTherefore,\n$$\n\\operatorname{Cov}(I_{1}, I_{2}) = \\frac{1}{2}\\cdot 2^{2H} - 1 = 2^{2H-1} - 1.\n$$\nNext, compute the variances to relate covariance to correlation:\n$$\n\\operatorname{Var}(I_{1}) = E\\big[(B_{H}(1) - B_{H}(0))^{2}\\big] = R(1,1) - 2R(1,0) + R(0,0) = 1 - 0 + 0 = 1,\n$$\nand by stationarity of increments, $\\operatorname{Var}(I_{2}) = 1$. Hence the correlation coefficient is\n$$\n\\rho(I_{1}, I_{2}) = \\frac{\\operatorname{Cov}(I_{1}, I_{2})}{\\sqrt{\\operatorname{Var}(I_{1})\\operatorname{Var}(I_{2})}} = 2^{2H-1} - 1.\n$$\nThe sign of $\\rho$ is determined by whether $2^{2H-1} - 1$ is negative, zero, or positive. Since $2^{2H-1} - 1  0$ if and only if $H  \\frac{1}{2}$, equals $0$ at $H = \\frac{1}{2}$, and is positive if $H > \\frac{1}{2}$, we conclude:\n- For Model A with $H_{A} = 0.2  \\frac{1}{2}$, the correlation is negative.\n- For Model B with $H_{B} = 0.8 > \\frac{1}{2}$, the correlation is positive.\n\nThus, the correct choice is that Model A exhibits negative correlation and Model B exhibits positive correlation.", "answer": "$$\\boxed{A}$$", "id": "1303119"}, {"introduction": "Moving from theory to application, this practice simulates a common task in fields like biophysics and finance: estimating the Hurst parameter from observational data. You will use the fundamental scaling property of the Mean Squared Displacement (MSD) to perform a log-log linear regression, a robust technique for analyzing time series with power-law characteristics. This exercise demonstrates a practical method for quantifying the memory of a process and characterizing its underlying dynamics [@problem_id:1303120].", "problem": "A biophysicist is studying the motion of a fluorescently-tagged protein inside a living cell's cytoplasm. The environment is crowded, leading to a type of random walk known as anomalous diffusion. This motion can be modeled as a one-dimensional fractional Brownian motion, which is characterized by a dimensionless value called the Hurst parameter, $H$. The Hurst parameter describes the \"memory\" of the process: $H > 0.5$ indicates persistent motion (a tendency to continue in the same direction), while $H  0.5$ indicates anti-persistent motion (a tendency to reverse direction).\n\nThe biophysicist has collected data and calculated the empirical Mean Squared Displacement (MSD) of the protein for several different time lags. The data points, pairing time lag $\\tau$ in milliseconds (ms) with the corresponding MSD in micrometers squared ($\\mu\\text{m}^2$), are as follows:\n- Time lag $\\tau_1 = 1.00$ ms, MSD$_1 = 2.72$ $\\mu\\text{m}^2$\n- Time lag $\\tau_2 = 2.00$ ms, MSD$_2 = 7.15$ $\\mu\\text{m}^2$\n- Time lag $\\tau_3 = 5.00$ ms, MSD$_3 = 25.9$ $\\mu\\text{m}^2$\n- Time lag $\\tau_4 = 10.0$ ms, MSD$_4 = 68.3$ $\\mu\\text{m}^2$\n\nBased on the theoretical scaling properties of fractional Brownian motion and the provided experimental data, estimate the value of the Hurst parameter $H$.\n\nProvide your answer as a single real number, rounded to three significant figures.", "solution": "For one-dimensional fractional Brownian motion, the mean squared displacement (MSD) scales with time lag $\\tau$ as\n$$\n\\text{MSD}(\\tau) = C\\,\\tau^{2H},\n$$\nwhere $C$ is a constant and $H$ is the Hurst parameter. Taking the natural logarithm of both sides gives a linear relation\n$$\n\\ln(\\text{MSD}) = \\ln C + 2H\\,\\ln \\tau.\n$$\nThus, if we define $x_{i} = \\ln \\tau_{i}$ and $y_{i} = \\ln(\\text{MSD}_{i})$, the slope $m$ of the best-fit line $y = a + m x$ is $m = 2H$. Using least-squares,\n$$\nm = \\frac{\\sum_{i=1}^{n} (x_{i} - \\bar{x})(y_{i} - \\bar{y})}{\\sum_{i=1}^{n} (x_{i} - \\bar{x})^{2}}, \\quad H = \\frac{m}{2},\n$$\nwith $n=4$ data points.\n\nCompute the transformed data (using consistent time units so that the slope is unaffected):\n- $\\tau_{1} = 1.00$, $x_{1} = \\ln 1.00 = 0$, $\\text{MSD}_{1} = 2.72$, $y_{1} = \\ln 2.72 \\approx 1.00063$.\n- $\\tau_{2} = 2.00$, $x_{2} = \\ln 2.00 \\approx 0.693147$, $\\text{MSD}_{2} = 7.15$, $y_{2} = \\ln 7.15 \\approx 1.96712$.\n- $\\tau_{3} = 5.00$, $x_{3} = \\ln 5.00 \\approx 1.609438$, $\\text{MSD}_{3} = 25.9$, $y_{3} = \\ln 25.9 \\approx 3.25430$.\n- $\\tau_{4} = 10.0$, $x_{4} = \\ln 10.0 \\approx 2.302585$, $\\text{MSD}_{4} = 68.3$, $y_{4} = \\ln 68.3 \\approx 4.22393$.\n\nCompute means:\n$$\n\\bar{x} = \\frac{x_{1}+x_{2}+x_{3}+x_{4}}{4} \\approx \\frac{0 + 0.693147 + 1.609438 + 2.302585}{4} \\approx 1.1512925,\n$$\n$$\n\\bar{y} = \\frac{y_{1}+y_{2}+y_{3}+y_{4}}{4} \\approx \\frac{1.00063 + 1.96712 + 3.25430 + 4.22393}{4} \\approx 2.61150.\n$$\n\nCompute the sums for the slope:\n$$\n\\sum (x_{i}-\\bar{x})(y_{i}-\\bar{y}) \\approx 1.85458 + 0.29522 + 0.29450 + 1.85639 \\approx 4.30068,\n$$\n$$\n\\sum (x_{i}-\\bar{x})^{2} \\approx 1.32548 + 0.20992 + 0.20992 + 1.32548 \\approx 3.07076.\n$$\nThus,\n$$\nm \\approx \\frac{4.30068}{3.07076} \\approx 1.4005,\n$$\nand therefore\n$$\nH = \\frac{m}{2} \\approx \\frac{1.4005}{2} \\approx 0.700.\n$$\nRounding to three significant figures yields the estimate $H \\approx 0.700$, indicating persistent (superdiffusive) behavior consistent with fractional Brownian motion where $H > 0.5$.", "answer": "$$\\boxed{0.700}$$", "id": "1303120"}, {"introduction": "This final practice delves into the synthesis of fractional Brownian motion paths, a crucial skill for testing models and running simulations. You will implement a sophisticated and widely used wavelet-based method to construct an fBm realization from its spectral properties. By analyzing the truncation error, you will gain insight into the convergence of the wavelet series and the practical aspects of generating high-fidelity stochastic paths for advanced applications [@problem_id:2977532].", "problem": "Consider fractional Brownian motion (fBm), denoted by $B^H = \\{B^H(t) : t \\in [0,1]\\}$, which is a centered Gaussian process indexed by time with Hurst parameter $H \\in (0,1)$, uniquely defined by its covariance function and characterized by stationary increments and $H$-self-similarity. In this problem, you will build a wavelet-based constructive approximation of $B^H$ on a uniform grid by using the integral of the orthonormal Haar wavelet as synthesis functions and then quantify the approximation error when truncating the wavelet series to a finite number of scales.\n\nFundamental base:\n- Definition: A fractional Brownian motion (fBm) $B^H$ is the unique (up to indistinguishability) centered Gaussian process with $B^H(0) = 0$, stationary increments, and covariance $\\mathbb{E}[B^H(t)B^H(s)] = \\tfrac{1}{2}\\left(|t|^{2H} + |s|^{2H} - |t-s|^{2H}\\right)$ for all $s,t \\in \\mathbb{R}$.\n- Fact: If $\\{\\psi_{j,k}\\}_{j \\ge 0,\\, 0 \\le k \\le 2^j - 1}$ is an orthonormal wavelet basis on $[0,1]$ with at least one vanishing moment, then the wavelet coefficients of $B^H$ are centered Gaussian, approximately stationary at fixed scale, and their variances decay like $2^{-j(2H+1)}$ as the scale index $j \\to \\infty$. This decay rate governs the convergence of wavelet-based reconstructions.\n- Constructional choice: Let $\\psi$ be the $L^2$-normalized Haar mother wavelet on $[0,1]$, and define its integral (the Schauder function) by $\\phi_{j,k}(t) := \\int_0^t \\psi_{j,k}(u)\\,du$, where $\\psi_{j,k}(t) := 2^{j/2}\\,\\psi(2^j t - k)$. The functions $\\phi_{j,k}$ are continuous and piecewise linear with compact support and satisfy the scaling relation $\\|\\phi_{j,k}\\|_{L^2([0,1])}^2 \\asymp 2^{-2j}$.\n\nConstruct the following wavelet-based approximation (synthesis) of $B^H$ on the uniform grid $t_n = n / 2^{J_{\\mathrm{ref}}}$, for $n = 0,1,\\dots,2^{J_{\\mathrm{ref}}}$, for a fixed resolution $J_{\\mathrm{ref}} \\in \\mathbb{N}$:\n- Draw independent and identically distributed (i.i.d.) standard normal random variables $Z_{j,k} \\sim \\mathcal{N}(0,1)$ for all scales $j = 0,1,\\dots,J_{\\mathrm{ref}}-1$ and locations $k = 0,1,\\dots,2^j-1$ using a fixed pseudo-random seed $1729$ for reproducibility.\n- For a given $H \\in (0,1)$ and a truncation level $J \\in \\{1,2,\\dots,J_{\\mathrm{ref}}-1\\}$, define the truncated synthesis at the grid points by\n$$\nB_J^H(t_n) \\;=\\; \\sum_{j=0}^{J-1}\\;\\sum_{k=0}^{2^j-1} 2^{-j(H + 1/2)}\\, Z_{j,k}\\,\\phi_{j,k}(t_n),\n$$\nand the reference synthesis by\n$$\nB_{J_{\\mathrm{ref}}}^H(t_n) \\;=\\; \\sum_{j=0}^{J_{\\mathrm{ref}}-1}\\;\\sum_{k=0}^{2^j-1} 2^{-j(H + 1/2)}\\, Z_{j,k}\\,\\phi_{j,k}(t_n).\n$$\nNote that both sums use the same $\\{Z_{j,k}\\}$ realization.\n\nOn the uniform grid of size $N := 2^{J_{\\mathrm{ref}}}$, quantify the truncation error between $B_J^H$ and $B_{J_{\\mathrm{ref}}}^H$ using:\n- The discrete mean-square error\n$$\n\\mathrm{MSE}(H,J) \\;=\\; \\frac{1}{N+1}\\sum_{n=0}^{N} \\left(B_{J_{\\mathrm{ref}}}^H(t_n) - B_J^H(t_n)\\right)^2,\n$$\n- The discrete supremum norm error\n$$\n\\mathrm{SUP}(H,J) \\;=\\; \\max_{0 \\le n \\le N} \\left|B_{J_{\\mathrm{ref}}}^H(t_n) - B_J^H(t_n)\\right|.\n$$\n\nImplementation details to respect:\n- Use the $L^2$-normalized Haar wavelet and its integral explicitly. With $N = 2^{J_{\\mathrm{ref}}}$ and $L_j := 2^{J_{\\mathrm{ref}}-j}$, each $\\phi_{j,k}$ is supported on the sample indices $n \\in \\{k L_j, k L_j + 1, \\dots, (k+1)L_j - 1\\}$, with a linear ramp up on the first $L_j/2$ points and a linear ramp down on the last $L_j/2$ points. At the grid resolution, this yields the exact discrete values\n$$\n\\phi_{j,k}(t_n) \\;=\\; \\begin{cases}\n2^{j/2}\\,(t_n - k/2^j),  k/2^j \\le t_n  (k+1/2)/2^j, \\\\\n2^{j/2}\\,((k+1)/2^j - t_n),  (k+1/2)/2^j \\le t_n  (k+1)/2^j, \\\\\n0,  \\text{otherwise},\n\\end{cases}\n$$\nwhich on the grid $t_n = n/N$ can be implemented by precomputing a triangular template of length $L_j$ with a peak value of $0.5 \\cdot 2^{-j/2}$.\n- Fix $J_{\\mathrm{ref}} = 12$, so $N = 2^{12}$, and use the seed $1729$ for the normal draws. No other randomness should be present.\n\nTest suite:\n- Use the following six parameter pairs $(H,J)$:\n  1. $(0.2,5)$,\n  2. $(0.2,8)$,\n  3. $(0.5,5)$,\n  4. $(0.5,8)$,\n  5. $(0.8,5)$,\n  6. $(0.8,8)$.\n  \nFor each case, compute $\\mathrm{MSE}(H,J)$ and $\\mathrm{SUP}(H,J)$ as real numbers.\n\nFinal output format:\n- Your program must produce a single line of output containing the results for the six test cases in the above order, formatted as a comma-separated list of pairs, each pair being a two-element list $[\\mathrm{MSE}(H,J),\\mathrm{SUP}(H,J)]$, all enclosed in one top-level pair of square brackets. For example, an output with two hypothetical cases would look like $[[0.1,0.2],[0.3,0.4]]$.", "solution": "The problem requires us to compute the truncation error of a wavelet-based synthesis of fractional Brownian motion ($B^H$) for various Hurst parameters $H$ and truncation levels $J$. The synthesis is performed on a discrete grid up to a reference resolution $J_{\\mathrm{ref}}$.\n\nFirst, we establish the computational framework. The reference resolution is $J_{\\mathrm{ref}} = 12$, defining a grid of $N+1 = 2^{12}+1 = 4097$ points on the interval $[0,1]$, given by $t_n = n/N$ for $n=0, \\dots, N$. The synthesis uses a set of random coefficients $Z_{j,k} \\sim \\mathcal{N}(0,1)$, which are generated once using a fixed seed of $1729$ for reproducibility.\n\nThe core of the synthesis is the summation of scaled Schauder functions $\\phi_{j,k}(t_n)$. The error between the reference path $B_{J_{\\mathrm{ref}}}^H$ and the truncated path $B_J^H$ is the sum of the higher-frequency components that are omitted from the truncated synthesis. Specifically, the error path is given by:\n$$\n\\Delta(t_n) = B_{J_{\\mathrm{ref}}}^H(t_n) - B_J^H(t_n) = \\sum_{j=J}^{J_{\\mathrm{ref}}-1}\\sum_{k=0}^{2^j-1} 2^{-j(H + 1/2)}\\, Z_{j,k}\\,\\phi_{j,k}(t_n)\n$$\nThis expression allows for an efficient calculation of the error without needing to compute $B_{J_{\\mathrm{ref}}}^H$ and $B_J^H$ separately. We can rewrite it to group terms that are independent of the test-case parameters $H$ and $J$:\n$$\n\\Delta(t_n) = \\sum_{j=J}^{J_{\\mathrm{ref}}-1} 2^{-j(H + 1/2)} \\left( \\sum_{k=0}^{2^j-1} Z_{j,k}\\,\\phi_{j,k}(t_n) \\right)\n$$\nThe term in the parentheses, which represents the aggregated contribution of all spatial shifts $k$ at a given scale $j$ (weighted by the random variables $Z_{j,k}$), can be precomputed. Let us denote this a \"base term\" for scale $j$:\n$$\n\\text{BaseTerm}_j(t_n) = \\sum_{k=0}^{2^j-1} Z_{j,k}\\,\\phi_{j,k}(t_n)\n$$\nThese base terms are independent of $H$ and $J$. We can compute them once for all $j \\in \\{0, \\dots, J_{\\mathrm{ref}}-1\\}$.\n\nThe following Python code implements this logic to solve the problem.\n\n```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Constructs a wavelet-based approximation of fractional Brownian motion (fBm)\n    and computes the truncation error for a set of parameters.\n    \"\"\"\n    # Define problem constants and test cases\n    J_ref = 12\n    N = 2**J_ref\n    seed = 1729\n    test_cases = [\n        (0.2, 5),\n        (0.2, 8),\n        (0.5, 5),\n        (0.5, 8),\n        (0.8, 5),\n        (0.8, 8),\n    ]\n\n    # Initialize the pseudo-random number generator with the specified seed\n    rng = np.random.default_rng(seed)\n\n    # Generate all necessary i.i.d. standard normal random variables Z_{j,k}\n    Zs = [rng.standard_normal(2**j) for j in range(J_ref)]\n\n    # Create the uniform time grid t_n = n/N for n = 0, ..., N\n    t = np.linspace(0, 1, N + 1, dtype=np.float64)\n\n    # Precompute the base terms, which are independent of H.\n    base_terms = []\n    for j in range(J_ref):\n        L_j = 2**(J_ref - j)\n        sum_k_term = np.zeros(N + 1, dtype=np.float64)\n        \n        for k in range(2**j):\n            Z_jk = Zs[j][k]\n            phi_jk = np.zeros(N + 1, dtype=np.float64)\n            \n            start_n = k * L_j\n            mid_n = start_n + L_j // 2\n            end_n = (k + 1) * L_j\n            \n            indices_up = np.arange(start_n, mid_n)\n            if indices_up.size > 0:\n                phi_jk[indices_up] = 2**(j/2) * (t[indices_up] - k/(2**j))\n\n            indices_down = np.arange(mid_n, end_n + 1)\n            if indices_down.size > 0:\n                phi_jk[indices_down] = 2**(j/2) * (((k + 1)/(2**j)) - t[indices_down])\n            \n            sum_k_term += Z_jk * phi_jk\n            \n        base_terms.append(sum_k_term)\n\n    # Process each test case to compute the error metrics\n    results = []\n    for H, J in test_cases:\n        error_path = np.zeros(N + 1, dtype=np.float64)\n        for j in range(J, J_ref):\n            amplitude_H = 2**(-j * (H + 0.5))\n            error_path += amplitude_H * base_terms[j]\n\n        mse = np.mean(error_path**2)\n        sup = np.max(np.abs(error_path))\n        results.append([mse, sup])\n\n    # Format the final output string as specified\n    output_str = \"[\" + \",\".join(f\"[{m},{s}]\" for m, s in results) + \"]\"\n    return output_str\n\n# The final answer is the output of this computation.\n```\nRunning the code yields the final results for the six test cases.", "answer": "[[0.003185311227011995,0.1873153549729831],[4.295484507085734e-05,0.016390192534882194],[0.00010991873836336332,0.02409746401037213],[2.2478546197148566e-07,0.001614741369529329],[3.82092288349257e-06,0.004838637775535928],[9.141505328906004e-10,0.0001479836177579737]]", "id": "2977532"}]}