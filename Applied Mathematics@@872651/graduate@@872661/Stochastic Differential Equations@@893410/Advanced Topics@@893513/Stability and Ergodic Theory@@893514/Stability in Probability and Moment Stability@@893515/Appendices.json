{"hands_on_practices": [{"introduction": "The Lyapunov method is a cornerstone of stability analysis for differential equations, and its extension to SDEs via the infinitesimal generator is a powerful tool. For many nonlinear systems where explicit solutions are unavailable, this approach allows us to assess stability by examining the expected rate of change of a scalar \"energy-like\" function $V(x)$. This exercise provides direct practice in applying this fundamental technique by computing the generator $\\mathcal{L}V(x)$ for a nonlinear SDE to determine its local mean-square stability near an equilibrium [@problem_id:2996128].", "problem": "Consider the one-dimensional stochastic differential equation (SDE)\n$$\ndX_t=-\\alpha X_t^{3}\\,dt+\\beta X_t^{2}\\,dW_t,\n$$\non $\\mathbb{R}$ with parameters $\\alpha0$ and $\\beta0$, where $W_t$ is a standard Brownian motion (Wiener process). Let the candidate Lyapunov function be $V(x)=|x|^{2}$. Using the infinitesimal generator associated with the SDE and the Lyapunov approach grounded in It\\^o calculus, compute $\\mathcal{L}V(x)$ and use its sign to assess local mean-square stability in a neighborhood of the equilibrium $x=0$. Report your final answer as the explicit closed-form expression for $\\mathcal{L}V(x)$ in terms of $x$, $\\alpha$, and $\\beta$.", "solution": "The problem is validated as scientifically sound, well-posed, objective, and self-contained. It is a standard exercise in applying Lyapunov stability theory to stochastic differential equations (SDEs).\n\nThe given one-dimensional SDE is of the form $dX_t = f(X_t) \\, dt + g(X_t) \\, dW_t$, where $W_t$ is a standard Wiener process. By comparing the given equation\n$$\ndX_t = -\\alpha X_t^3 \\, dt + \\beta X_t^2 \\, dW_t\n$$\nwith the general form, we identify the drift coefficient $f(x)$ and the diffusion coefficient $g(x)$ as:\n$$\nf(x) = -\\alpha x^3\n$$\n$$\ng(x) = \\beta x^2\n$$\nThe problem asks to use the candidate Lyapunov function $V(x) = |x|^2$. For $x \\in \\mathbb{R}$, this simplifies to $V(x) = x^2$. This function is twice continuously differentiable, i.e., $V(x) \\in C^2(\\mathbb{R})$, which is a necessary condition for applying Itô's lemma.\n\nThe infinitesimal generator of the SDE, denoted by $\\mathcal{L}$, when applied to a time-independent, twice-differentiable function $V(x)$, is defined by\n$$\n\\mathcal{L}V(x) = f(x) \\frac{dV(x)}{dx} + \\frac{1}{2} [g(x)]^2 \\frac{d^2V(x)}{dx^2}\n$$\nThis formula is a direct consequence of Itô's lemma applied to $V(X_t)$.\n\nFirst, we compute the necessary derivatives of the Lyapunov function $V(x) = x^2$:\nThe first derivative is:\n$$\n\\frac{dV}{dx} = \\frac{d}{dx}(x^2) = 2x\n$$\nThe second derivative is:\n$$\n\\frac{d^2V}{dx^2} = \\frac{d}{dx}(2x) = 2\n$$\nNext, we substitute the expressions for $f(x)$, $g(x)$, $\\frac{dV}{dx}$, and $\\frac{d^2V}{dx^2}$ into the formula for the infinitesimal generator $\\mathcal{L}V(x)$:\n$$\n\\mathcal{L}V(x) = (-\\alpha x^3)(2x) + \\frac{1}{2} (\\beta x^2)^2 (2)\n$$\nWe simplify the terms. The first term becomes:\n$$\n(-\\alpha x^3)(2x) = -2\\alpha x^4\n$$\nThe second term becomes:\n$$\n\\frac{1}{2} (\\beta x^2)^2 (2) = (\\beta^2 x^4)(1) = \\beta^2 x^4\n$$\nCombining these terms, we obtain the expression for $\\mathcal{L}V(x)$:\n$$\n\\mathcal{L}V(x) = -2\\alpha x^4 + \\beta^2 x^4\n$$\nFactoring out the common term $x^4$, we arrive at the final closed-form expression:\n$$\n\\mathcal{L}V(x) = (\\beta^2 - 2\\alpha)x^4\n$$\nTo assess local mean-square stability at the equilibrium point $x=0$, we examine the sign of $\\mathcal{L}V(x)$ in a neighborhood of $x=0$. The point $x=0$ is indeed an equilibrium because $f(0) = -\\alpha(0)^3 = 0$ and $g(0) = \\beta(0)^2 = 0$. The Lyapunov function $V(x) = x^2$ is positive definite, as $V(0) = 0$ and $V(x)  0$ for all $x \\neq 0$.\n\nAccording to the Lyapunov stability criterion for SDEs, the equilibrium $x=0$ is asymptotically stable in the mean-square sense if $\\mathcal{L}V(x)$ is negative definite, i.e., $\\mathcal{L}V(x)  0$ for all $x \\neq 0$ in a neighborhood of the origin.\nIn our expression $\\mathcal{L}V(x) = (\\beta^2 - 2\\alpha)x^4$, the term $x^4$ is strictly positive for any $x \\neq 0$. Therefore, the sign of $\\mathcal{L}V(x)$ is determined entirely by the sign of the constant factor $(\\beta^2 - 2\\alpha)$.\n\nFor the system to be locally mean-square stable, we require:\n$$\n\\beta^2 - 2\\alpha  0 \\implies \\beta^2  2\\alpha\n$$\nIf this condition holds, $\\mathcal{L}V(x)  0$ for all $x \\neq 0$, and the origin is asymptotically stable in the mean-square sense. Conversely, if $\\beta^2 - 2\\alpha  0$, then $\\mathcal{L}V(x)  0$ for $x \\neq 0$, indicating instability. If $\\beta^2 - 2\\alpha = 0$, then $\\mathcal{L}V(x) = 0$, and this Lyapunov function provides no conclusive information about stability.\n\nThe problem asks for the explicit closed-form expression for $\\mathcal{L}V(x)$, which we have computed.", "answer": "$$\n\\boxed{(\\beta^2 - 2\\alpha)x^4}\n$$", "id": "2996128"}, {"introduction": "In the world of stochastic systems, the term \"stability\" can be multifaceted and sometimes counter-intuitive. Unlike deterministic systems, convergence of trajectories to an equilibrium does not automatically imply the convergence of their statistical moments. This practice problem explores a classic and illuminating example of an SDE where the equilibrium is stable in probability (trajectories almost surely converge to zero) but is not asymptotically stable in the mean-square sense [@problem_id:2996127]. By working through the explicit solution and moment calculations, you will gain a deeper appreciation for how stochastic noise can fundamentally alter stability properties.", "problem": "Consider the one-dimensional stochastic differential equation (SDE) $$dX_{t}=-X_{t}\\,dt+\\sqrt{2}\\,X_{t}\\,dW_{t},$$ where $W_{t}$ is a standard Brownian motion and $X_{0}=x_{0}\\in\\mathbb{R}$ is deterministic. Use the fundamental definitions of stability in probability and mean-square stability, and derive results from first principles using Itô calculus. Specifically:\n- Starting from Itô’s formula applied to suitable functions of $X_{t}$, obtain a closed-form expression for the second moment $$\\mathbb{E}\\big[|X_{t}|^{2}\\big]$$ for all $t\\geq 0$.\n- Using the exact solution representation obtained via Itô calculus for $\\ln|X_{t}|$, determine the asymptotic behavior of $X_{t}$ as $t\\to\\infty$ and justify whether the zero equilibrium is stable in probability.\n- Compare the moment behavior to the definition of mean-square stability and explain whether mean-square stability holds for this SDE.\n\nYour final answer must be the exact analytic expression for $$\\mathbb{E}\\big[|X_{t}|^{2}\\big]$$ in terms of $x_{0}$ and $t$. No rounding is required and no units are involved.", "solution": "The one-dimensional stochastic differential equation (SDE) under consideration is\n$$dX_{t}=-X_{t}\\,dt+\\sqrt{2}\\,X_{t}\\,dW_{t},$$\nwith a deterministic initial condition $X_{0}=x_{0}\\in\\mathbb{R}$. This is a linear SDE of the form $dX_t = b(X_t) dt + \\sigma(X_t) dW_t$, with drift coefficient $b(x) = -x$ and diffusion coefficient $\\sigma(x) = \\sqrt{2}x$. The zero solution, $X_t \\equiv 0$, is an equilibrium point of this SDE. We will analyze the stability of this equilibrium.\n\nFirst, we determine the second moment, $\\mathbb{E}[|X_{t}|^{2}]$, using Itô's formula. Let $f(x) = x^2$. The derivatives of this function are $f'(x) = 2x$ and $f''(x) = 2$. Itô's formula for a function $f(X_t)$ is given by\n$$df(X_t) = \\left( b(X_t) f'(X_t) + \\frac{1}{2} \\sigma(X_t)^2 f''(X_t) \\right) dt + \\sigma(X_t) f'(X_t) dW_t.$$\nSubstituting the specific forms of $b(x)$, $\\sigma(x)$, and the derivatives of $f(x)$, we obtain the differential for $X_t^2$:\n$$d(X_t^2) = \\left( (-X_t)(2X_t) + \\frac{1}{2} (\\sqrt{2}X_t)^2 (2) \\right) dt + (\\sqrt{2}X_t)(2X_t) dW_t$$\n$$d(X_t^2) = \\left( -2X_t^2 + \\frac{1}{2} (2X_t^2) (2) \\right) dt + 2\\sqrt{2}X_t^2 dW_t$$\n$$d(X_t^2) = \\left( -2X_t^2 + 2X_t^2 \\right) dt + 2\\sqrt{2}X_t^2 dW_t$$\n$$d(X_t^2) = 0 \\cdot dt + 2\\sqrt{2}X_t^2 dW_t = 2\\sqrt{2}X_t^2 dW_t.$$\nTo find $X_t^2$, we integrate from $0$ to $t$:\n$$X_t^2 - X_0^2 = \\int_0^t 2\\sqrt{2}X_s^2 dW_s.$$\nNow, we take the expectation of both sides. The initial condition $X_0 = x_0$ is deterministic, so $\\mathbb{E}[X_0^2] = x_0^2$. The expectation of the Itô integral on the right-hand side is zero, as the integrand is a sufficiently regular process.\n$$\\mathbb{E}[X_t^2] - \\mathbb{E}[X_0^2] = \\mathbb{E}\\left[\\int_0^t 2\\sqrt{2}X_s^2 dW_s\\right]$$\n$$\\mathbb{E}[X_t^2] - x_0^2 = 0.$$\nThus, we arrive at the expression for the second moment:\n$$\\mathbb{E}[|X_{t}|^{2}] = \\mathbb{E}[X_t^2] = x_0^2.$$\n\nSecond, we determine the asymptotic behavior of $X_t$ and assess the stability in probability of the zero equilibrium. We apply Itô's formula to the function $g(x) = \\ln|x|$. For $x \\neq 0$, the derivatives are $g'(x) = 1/x$ and $g''(x) = -1/x^2$. The SDE for $Y_t = \\ln|X_t|$ is:\n$$dY_t = \\left( b(X_t) g'(X_t) + \\frac{1}{2} \\sigma(X_t)^2 g''(X_t) \\right) dt + \\sigma(X_t) g'(X_t) dW_t$$\n$$dY_t = \\left( (-X_t)\\left(\\frac{1}{X_t}\\right) + \\frac{1}{2} (\\sqrt{2}X_t)^2 \\left(-\\frac{1}{X_t^2}\\right) \\right) dt + (\\sqrt{2}X_t)\\left(\\frac{1}{X_t}\\right) dW_t$$\n$$dY_t = \\left( -1 + \\frac{1}{2} (2X_t^2) \\left(-\\frac{1}{X_t^2}\\right) \\right) dt + \\sqrt{2} dW_t$$\n$$dY_t = (-1 - 1) dt + \\sqrt{2} dW_t = -2 dt + \\sqrt{2} dW_t.$$\nIntegrating from $0$ to $t$ gives:\n$$Y_t - Y_0 = \\int_0^t (-2) ds + \\int_0^t \\sqrt{2} dW_s$$\n$$\\ln|X_t| - \\ln|x_0| = -2t + \\sqrt{2}W_t.$$\nThe explicit solution for $|X_t|$ is:\n$$|X_t| = |x_0| \\exp(-2t + \\sqrt{2}W_t).$$\nTo determine the asymptotic behavior as $t \\to \\infty$, we examine the exponent. By the Strong Law of Large Numbers for Brownian motion, $\\frac{W_t}{t} \\to 0$ almost surely as $t \\to \\infty$. Therefore, the term $-2t$ dominates the exponent:\n$$\\lim_{t\\to\\infty} (-2t + \\sqrt{2}W_t) = \\lim_{t\\to\\infty} t \\left(-2 + \\frac{\\sqrt{2}W_t}{t}\\right) = -\\infty \\quad \\text{almost surely}.$$\nThis implies that $\\lim_{t\\to\\infty} |X_t| = 0$ almost surely for any initial condition $x_0$. Almost sure convergence implies convergence in probability. This means that for any $\\epsilon  0$, $\\lim_{t\\to\\infty} \\mathbb{P}(|X_t|  \\epsilon) = 0$. This property is known as attractivity of the zero solution.\nFor stability in probability (in the sense of Lyapunov), we must show that for any $\\epsilon0, \\eta0$, there exists a $\\delta0$ such that $|x_0|\\delta$ implies $\\mathbb{P}(\\sup_{t\\geq 0} |X_t|  \\epsilon)  \\eta$.\nThe probability in question is\n$$\\mathbb{P}(\\sup_{t\\geq 0} |x_0|\\exp(-2t + \\sqrt{2}W_t)  \\epsilon) = \\mathbb{P}(\\sup_{t\\geq 0} (-2t + \\sqrt{2}W_t)  \\ln(\\epsilon/|x_0|)).$$\nLet $Z_t = -2t + \\sqrt{2}W_t$. This is a Brownian motion with drift. For a process $B_t = \\mu t + \\sigma W_t$ starting at $0$, the maximum value probability is given by $\\mathbb{P}(\\sup_{t\\geq 0} B_t \\geq a) = \\exp(2\\mu a / \\sigma^2)$ for $\\mu0, a0$.\nIn our case, $Z_t$ is a process where the drift coefficient is $\\mu=-2$ and the Brownian motion part has coefficient $\\sqrt{2}$. The equivalent standard form would be based on $W_t$. Let $Z_t = \\sqrt{2}(-\\sqrt{2}t+W_t)$. For the process $B_t' = -\\sqrt{2}t+W_t$, with drift $\\mu'=-\\sqrt{2}0$, we have $\\mathbb{P}(\\sup_{t\\ge 0} B_t' \\ge a') = \\exp(2(-\\sqrt{2})a')$.\nSo, $\\mathbb{P}(\\sup_{t\\geq 0} Z_t  a) = \\mathbb{P}(\\sup_{t\\geq 0} \\sqrt{2}B_t'  a) = \\mathbb{P}(\\sup_{t\\geq 0} B_t'  a/\\sqrt{2}) = \\exp(2(-\\sqrt{2})(a/\\sqrt{2})) = \\exp(-2a)$.\nLet $a = \\ln(\\epsilon/|x_0|)$. For the probability to be well-defined with this formula, we need $a0$, so we select $x_0$ such that $|x_0|\\epsilon$.\nThen, $\\mathbb{P}(\\sup_{t\\geq 0} |X_t|  \\epsilon) = \\exp(-2 \\ln(\\epsilon/|x_0|)) = (\\epsilon/|x_0|)^{-2} = (|x_0|/\\epsilon)^2$.\nTo satisfy the stability condition, we need $(|x_0|/\\epsilon)^2  \\eta$, which gives $|x_0|  \\epsilon\\sqrt{\\eta}$. We can choose $\\delta = \\epsilon\\sqrt{\\eta}$. If $|x_0|  \\delta$, the condition is fulfilled.\nThus, the zero equilibrium is stable in probability. Since it is also attractive, it is asymptotically stable in probability.\n\nThird, we analyze mean-square stability. A system is mean-square stable if for any $\\epsilon  0$, there exists a $\\delta  0$ such that $|x_0|^2  \\delta$ implies $\\mathbb{E}[|X_t|^2]  \\epsilon$ for all $t \\geq 0$. From our first result, we have $\\mathbb{E}[|X_t|^2] = x_0^2$. This is constant for all $t \\geq 0$. For a given $\\epsilon0$, we need to find $\\delta0$ such that $|x_0|^2  \\delta$ implies $x_0^2  \\epsilon$. We can simply choose $\\delta = \\epsilon$. This satisfies the definition of mean-square stability in the Lyapunov sense.\nA system is asymptotically mean-square stable if it is mean-square stable and $\\lim_{t\\to\\infty} \\mathbb{E}[|X_t|^2] = 0$. In our case:\n$$\\lim_{t\\to\\infty} \\mathbb{E}[|X_t|^2] = \\lim_{t\\to\\infty} x_0^2 = x_0^2.$$\nThis limit is not zero for any non-zero initial condition $x_0 \\neq 0$. Therefore, the zero equilibrium is not asymptotically mean-square stable.\n\nIn conclusion, this SDE provides a classic example where different notions of stability diverge. The zero solution is asymptotically stable in probability (and almost surely), meaning that trajectories converge to zero. However, it is not asymptotically mean-square stable, as the second moment does not decay to zero. This is due to the noise term being large enough ($2a+b^2=0$) to prevent the decay of moments, even though the sample paths themselves decay ($a-b^2/2  0$).\n\nThe specific question for the final answer is the exact analytic expression for $\\mathbb{E}[|X_{t}|^{2}]$.\nBased on the derivation using Itô's formula, this expression is $x_0^2$.", "answer": "$$\n\\boxed{x_{0}^{2}}\n$$", "id": "2996127"}, {"introduction": "Bridging the gap between theory and computation is a critical skill in applied mathematics. Even if an SDE is theoretically stable, its numerical approximation may diverge if not handled carefully. This exercise delves into the stability of the Euler-Maruyama scheme, a widely used method for simulating SDEs [@problem_id:2996148]. You will derive the condition on the numerical step-size $h$ that guarantees the $p$-th moment stability of the discrete approximation, providing a concrete understanding of why numerical stability constraints are often stricter than those of the underlying continuous-time system.", "problem": "Consider the scalar linear Stochastic Differential Equation (SDE) $$\\mathrm{d}X(t) = \\lambda X(t)\\,\\mathrm{d}t + \\mu X(t)\\,\\mathrm{d}W(t),$$ where $W(t)$ is a standard Wiener process, and $\\lambda,\\mu \\in \\mathbb{R}$. Let $(t_n)_{n \\ge 0}$ be a uniform grid with step-size $h0$, and define the Euler–Maruyama discretization by $$X_{n+1} = X_n + \\lambda h X_n + \\mu X_n \\Delta W_n,$$ where $\\Delta W_n := W(t_{n+1}) - W(t_n)$. Write $\\Delta W_n = \\sqrt{h}\\,\\xi_n$ with $(\\xi_n)_{n\\ge 0}$ an independent and identically distributed sequence of standard normal random variables, $\\xi_n \\sim \\mathcal{N}(0,1)$, independent of $X_0$.\n\nYour tasks are:\n1) For an even integer $p \\ge 2$, derive the $p$-th moment amplification factor $$G_p(h) := \\mathbb{E}\\!\\left(|1 + \\lambda h + \\mu \\sqrt{h}\\,\\xi|^{p}\\right),$$ where $\\xi \\sim \\mathcal{N}(0,1)$ is independent of $X_n$. Express $G_p(h)$ in closed form using only fundamental properties of the normal distribution and basic combinatorics, starting from first principles (do not use or quote pre-derived stability region formulas).\n2) Using the definition of $p$-th moment stability, deduce from first principles a necessary and sufficient condition on the step-size $h$ (in terms of $G_p(h)$) that ensures $\\mathbb{E}(|X_n|^{p}) \\to 0$ as $n \\to \\infty$ for the Euler–Maruyama scheme applied to the given SDE.\n3) Assume that $2\\lambda + \\mu^{2}  0$ so that second-moment stability of the exact SDE is possible. Under this assumption, compute the largest admissible step-size $h^{\\star}$ guaranteeing second-moment ($p=2$) stability of the Euler–Maruyama scheme, as a single closed-form analytic expression in $\\lambda$ and $\\mu$. The final answer must be this expression.", "solution": "The problem statement is evaluated to be **valid**. It is scientifically grounded in the theory of numerical analysis for stochastic differential equations, specifically concerning the moment stability of the Euler–Maruyama method. The problem is well-posed, objective, and self-contained, providing all necessary definitions and conditions to derive a unique solution through rigorous mathematical reasoning.\n\nWe will address the three parts of the problem sequentially.\n\n**1) Derivation of the $p$-th moment amplification factor $G_p(h)$**\n\nThe Euler–Maruyama discretization is given by\n$$X_{n+1} = X_n + \\lambda h X_n + \\mu X_n \\Delta W_n = X_n(1 + \\lambda h + \\mu \\sqrt{h} \\xi_n),$$\nwhere $\\xi_n \\sim \\mathcal{N}(0,1)$ are independent and identically distributed standard normal random variables. The problem defines the $p$-th moment amplification factor as\n$$G_p(h) = \\mathbb{E}\\!\\left[|1 + \\lambda h + \\mu \\sqrt{h}\\,\\xi|^{p}\\right],$$\nwhere $\\xi \\sim \\mathcal{N}(0,1)$. Since the problem states that $p \\ge 2$ is an even integer, the absolute value is redundant, i.e., $|z|^p = z^p$ for any real $z$. Thus, we need to compute\n$$G_p(h) = \\mathbb{E}\\!\\left[(1 + \\lambda h + \\mu \\sqrt{h}\\,\\xi)^{p}\\right].$$\nLet $A = 1 + \\lambda h$ and $B = \\mu \\sqrt{h}$. We need to compute $\\mathbb{E}[(A + B\\xi)^p]$. Using the binomial theorem, we expand the term inside the expectation:\n$$(A + B\\xi)^p = \\sum_{k=0}^{p} \\binom{p}{k} A^{p-k} (B\\xi)^k = \\sum_{k=0}^{p} \\binom{p}{k} A^{p-k} B^k \\xi^k.$$\nBy the linearity of the expectation operator, we have\n$$G_p(h) = \\mathbb{E}\\!\\left[\\sum_{k=0}^{p} \\binom{p}{k} A^{p-k} B^k \\xi^k\\right] = \\sum_{k=0}^{p} \\binom{p}{k} A^{p-k} B^k \\mathbb{E}[\\xi^k].$$\nWe now need the moments of a standard normal random variable $\\xi \\sim \\mathcal{N}(0,1)$. The probability density function of $\\xi$ is symmetric about $0$, which implies that all odd moments are zero:\n$$\\mathbb{E}[\\xi^k] = 0, \\quad \\text{for odd } k.$$\nFor even moments, where $k=2j$ for $j \\in \\{0, 1, 2, \\dots, p/2\\}$, the moments are given by the double factorial of $k-1$:\n$$\\mathbb{E}[\\xi^{2j}] = (2j-1)!! = (2j-1)(2j-3)\\cdots 3 \\cdot 1.$$\nBy convention, for $j=0$, we have $k=0$, and $\\mathbb{E}[\\xi^0] = 1$, which is consistent with the definition $(-1)!!=1$.\n\nSubstituting the moments back into the expression for $G_p(h)$, the sum is restricted to even values of $k$. Let $k=2j$:\n$$G_p(h) = \\sum_{j=0}^{p/2} \\binom{p}{2j} A^{p-2j} B^{2j} \\mathbb{E}[\\xi^{2j}].$$\nSubstituting the expressions for $A$, $B$, and the even moments of $\\xi$:\n$$G_p(h) = \\sum_{j=0}^{p/2} \\binom{p}{2j} (1+\\lambda h)^{p-2j} (\\mu\\sqrt{h})^{2j} (2j-1)!!.$$\nSimplifying the term $(\\mu\\sqrt{h})^{2j} = \\mu^{2j}h^j$, we obtain the final closed-form expression for the amplification factor:\n$$G_p(h) = \\sum_{j=0}^{p/2} \\binom{p}{2j} (1+\\lambda h)^{p-2j} \\mu^{2j} h^j (2j-1)!!.$$\n\n**2) Condition for $p$-th moment stability**\n\nThe $p$-th moment stability of the numerical scheme is defined by the condition $\\mathbb{E}(|X_n|^p) \\to 0$ as $n \\to \\infty$. We analyze the evolution of $\\mathbb{E}(|X_n|^p)$. From the recurrence relation $X_{n+1} = X_n(1 + \\lambda h + \\mu \\sqrt{h} \\xi_n)$, we take the $p$-th power of the absolute value:\n$$|X_{n+1}|^p = |X_n|^p |1 + \\lambda h + \\mu \\sqrt{h} \\xi_n|^p.$$\nNow we take the expectation of both sides.\n$$\\mathbb{E}[|X_{n+1}|^p] = \\mathbb{E}\\big[|X_n|^p |1 + \\lambda h + \\mu \\sqrt{h} \\xi_n|^p\\big].$$\nThe random variable $\\xi_n$ is associated with the time interval $[t_n, t_{n+1}]$ and is independent of all previous history of the Wiener process up to time $t_n$. Since $X_n$ is $\\mathcal{F}_{t_n}$-measurable (i.e., it depends only on the history of $W(t)$ up to time $t_n$), $X_n$ is independent of $\\xi_n$. Therefore, the expectation of the product is the product of the expectations:\n$$\\mathbb{E}[|X_{n+1}|^p] = \\mathbb{E}[|X_n|^p] \\cdot \\mathbb{E}\\big[|1 + \\lambda h + \\mu \\sqrt{h} \\xi_n|^p\\big].$$\nThe second factor on the right-hand side is precisely the definition of the amplification factor $G_p(h)$, noting that $\\xi_n$ has the same distribution as $\\xi$. So, we have the recurrence relation:\n$$\\mathbb{E}[|X_{n+1}|^p] = G_p(h) \\cdot \\mathbb{E}[|X_n|^p].$$\nThis is a geometric progression for the sequence $m_n = \\mathbb{E}[|X_n|^p]$. Its solution is\n$$m_n = (G_p(h))^n m_0,$$\nwhere $m_0 = \\mathbb{E}[|X_0|^p]$. For the sequence $m_n$ to converge to $0$ as $n \\to \\infty$ (assuming $m_0 \\neq 0$), the common ratio $G_p(h)$ must have a magnitude less than $1$. As $G_p(h)$ is the expectation of a non-negative quantity $|...|^p$, it is non-negative, i.e., $G_p(h) \\ge 0$.\nTherefore, the necessary and sufficient condition for $p$-th moment stability is\n$$G_p(h)  1.$$\n\n**3) Largest admissible step-size $h^{\\star}$ for second-moment ($p=2$) stability**\n\nWe specialize the results from the previous parts to the case $p=2$. First, we compute $G_2(h)$ using the formula derived in part 1:\n$$G_2(h) = \\sum_{j=0}^{1} \\binom{2}{2j} (1+\\lambda h)^{2-2j} \\mu^{2j} h^j (2j-1)!!.$$\nFor $j=0$: $\\binom{2}{0}(1+\\lambda h)^2 \\mu^0 h^0 (-1)!! = 1 \\cdot (1+\\lambda h)^2 \\cdot 1 \\cdot 1 = (1+\\lambda h)^2$.\nFor $j=1$: $\\binom{2}{2}(1+\\lambda h)^0 \\mu^2 h^1 (1)!! = 1 \\cdot 1 \\cdot \\mu^2 h \\cdot 1 = \\mu^2 h$.\nSumming these terms gives:\n$$G_2(h) = (1+\\lambda h)^2 + \\mu^2 h.$$\nExpanding this expression, we get:\n$$G_2(h) = 1 + 2\\lambda h + \\lambda^2 h^2 + \\mu^2 h = 1 + (2\\lambda + \\mu^2)h + \\lambda^2 h^2.$$\nThe condition for second-moment stability, from part 2, is $G_2(h)  1$.\n$$1 + (2\\lambda + \\mu^2)h + \\lambda^2 h^2  1.$$\nSubtracting $1$ from both sides yields:\n$$(2\\lambda + \\mu^2)h + \\lambda^2 h^2  0.$$\nSince the step-size $h$ must be positive ($h0$), we can divide the inequality by $h$ without changing its direction:\n$$2\\lambda + \\mu^2 + \\lambda^2 h  0.$$\nWe rearrange to solve for $h$:\n$$\\lambda^2 h  -(2\\lambda + \\mu^2).$$\nThe problem gives the assumption that $2\\lambda + \\mu^2  0$, which ensures that the corresponding continuous SDE is second-moment stable. This assumption implies that the right-hand side, $-(2\\lambda + \\mu^2)$, is a positive quantity.\nIf $\\lambda=0$, the inequality becomes $0  -(\\mu^2)$, which is $0  -\\mu^2$. This is impossible for any real $\\mu$. Furthermore, the assumption $2\\lambda+\\mu^20$ would become $\\mu^2  0$, also impossible. Thus, we must have $\\lambda \\neq 0$.\nSince $\\lambda \\neq 0$, its square $\\lambda^2$ is strictly positive. We can divide the inequality by $\\lambda^2$ without changing its direction:\n$$h  -\\frac{2\\lambda + \\mu^2}{\\lambda^2}.$$\nThe stability of the Euler–Maruyama scheme is guaranteed for all step-sizes $h$ that satisfy $0  h  -\\frac{2\\lambda + \\mu^2}{\\lambda^2}$. The largest admissible step-size, denoted $h^{\\star}$, is the supremum of this interval.\n$$h^{\\star} = -\\frac{2\\lambda + \\mu^2}{\\lambda^2}.$$\nThis is the maximum step-size that ensures second-moment stability for the numerical scheme under the given condition.", "answer": "$$\n\\boxed{-\\frac{2\\lambda + \\mu^2}{\\lambda^2}}\n$$", "id": "2996148"}]}