{"hands_on_practices": [{"introduction": "The core of constructing a higher-order Itô-Taylor scheme lies in computing the coefficient functions that accompany the multiple stochastic integrals. These coefficients are derived by repeatedly applying a set of differential operators, typically denoted $L^0, L^1, \\dots, L^m$, to the drift and diffusion functions of the SDE. This first exercise provides direct, hands-on practice with this fundamental procedure, tasking you with calculating these terms for a specific two-dimensional SDE and determining their relevance for a scheme of strong order $1.5$ [@problem_id:2982869].", "problem": "Consider the two-dimensional Itô stochastic differential equation (SDE)\n$$\n\\mathrm{d}X_{t} = a(X_{t})\\,\\mathrm{d}t + \\sum_{k=1}^{2} b^{(k)}(X_{t})\\,\\mathrm{d}W_{t}^{(k)},\n$$\nwhere $X_{t} \\in \\mathbb{R}^{2}$, $W^{(1)}$ and $W^{(2)}$ are independent standard Wiener processes (Brownian motions), and the coefficient functions are\n$$\na(x) = \\begin{pmatrix} a_{1}(x) \\\\ a_{2}(x) \\end{pmatrix} = \\begin{pmatrix} x_{1} + x_{2}^{2} \\\\ x_{1}x_{2} \\end{pmatrix},\\quad\nb^{(1)}(x) = \\begin{pmatrix} x_{1}^{2} \\\\ \\ln(1 + x_{2}^{2}) \\end{pmatrix},\\quad\nb^{(2)}(x) = \\begin{pmatrix} x_{1}x_{2} \\\\ \\exp(x_{1}) \\end{pmatrix}.\n$$\nHere $\\ln$ denotes the natural logarithm and $\\exp$ denotes the exponential function. Using the Itô-Taylor expansion framework for strong schemes, compute the operator applications $L^{0}b^{(1)}(x)$, $L^{0}b^{(2)}(x)$, $L^{1}a(x)$, and $L^{2}a(x)$ at a general point $x = (x_{1}, x_{2}) \\in \\mathbb{R}^{2}$. Then, based on the index-weight structure of multiple Itô integrals used in strong schemes, indicate for each of these four operator applications whether it contributes to strong order $1.5$ schemes.\n\nExpress your final answer as a single row matrix\n$$\n\\begin{pmatrix}\n(L^{0}b^{(1)}(x))_{1}  (L^{0}b^{(1)}(x))_{2}  (L^{0}b^{(2)}(x))_{1}  (L^{0}b^{(2)}(x))_{2}  (L^{1}a(x))_{1}  (L^{1}a(x))_{2}  (L^{2}a(x))_{1}  (L^{2}a(x))_{2}  I_{L^{0}b^{(1)}}  I_{L^{0}b^{(2)}}  I_{L^{1}a}  I_{L^{2}a}\n\\end{pmatrix},\n$$\nwhere each $I_{\\cdot}$ is an indicator taking value $1$ if the corresponding term contributes to strong order $1.5$ and $0$ otherwise. No numerical rounding is required; provide exact symbolic expressions. No physical units are involved.", "solution": "The user has provided a valid problem statement from the field of numerical analysis of stochastic differential equations. The task is to compute several operator applications within the Itô-Taylor expansion framework and to determine their relevance for strong schemes of order $1.5$.\n\n### Step 1: Definition of Itô-Taylor Operators\n\nFor a general $d$-dimensional Itô SDE with $m$ independent Wiener processes,\n$$\n\\mathrm{d}X_t = a(X_t) \\mathrm{d}t + \\sum_{k=1}^m b^{(k)}(X_t) \\mathrm{d}W_t^{(k)}\n$$\nthe Itô-Taylor expansion employs the operators $L^0, L^1, \\dots, L^m$. For a sufficiently smooth scalar function $f: \\mathbb{R}^d \\to \\mathbb{R}$, these operators are defined as:\n$$\nL^0 f(x) = \\sum_{i=1}^d a_i(x) \\frac{\\partial f}{\\partial x_i}(x) + \\frac{1}{2} \\sum_{i,j=1}^d \\left( \\sum_{k=1}^m b_i^{(k)}(x) b_j^{(k)}(x) \\right) \\frac{\\partial^2 f}{\\partial x_i \\partial x_j}(x)\n$$\n$$\nL^k f(x) = \\sum_{i=1}^d b_i^{(k)}(x) \\frac{\\partial f}{\\partial x_i}(x), \\quad \\text{for } k=1, \\dots, m\n$$\nWhen applied to a vector-valued function, the operator is applied to each component of the function. For the operators $L^k$ with $k \\ge 1$, this can be written concisely using the Jacobian matrix. If $g(x)$ is a vector-valued function, its Jacobian is $(\\nabla g)_{ij} = \\frac{\\partial g_i}{\\partial x_j}$, and we have $L^k g(x) = (\\nabla g(x)) b^{(k)}(x)$.\n\nIn this problem, the dimension is $d=2$ and the number of Wiener processes is $m=2$. The point is $x = (x_1, x_2)^T$. The coefficients are:\n$$\na(x) = \\begin{pmatrix} x_{1} + x_{2}^{2} \\\\ x_{1}x_{2} \\end{pmatrix}, \\quad\nb^{(1)}(x) = \\begin{pmatrix} x_{1}^{2} \\\\ \\ln(1 + x_{2}^{2}) \\end{pmatrix}, \\quad\nb^{(2)}(x) = \\begin{pmatrix} x_{1}x_{2} \\\\ \\exp(x_{1}) \\end{pmatrix}\n$$\n\n### Step 2: Calculation of Operator Applications\n\nWe compute the required terms: $L^0 b^{(1)}(x)$, $L^0 b^{(2)}(x)$, $L^1 a(x)$, and $L^2 a(x)$.\n\n**Calculation of $L^1 a(x)$ and $L^2 a(x)$**\n\nFirst, we find the Jacobian of $a(x)$:\n$$\n\\nabla a(x) =\n\\begin{pmatrix}\n\\frac{\\partial a_1}{\\partial x_1}  \\frac{\\partial a_1}{\\partial x_2} \\\\\n\\frac{\\partial a_2}{\\partial x_1}  \\frac{\\partial a_2}{\\partial x_2}\n\\end{pmatrix}\n=\n\\begin{pmatrix}\n1  2x_2 \\\\\nx_2  x_1\n\\end{pmatrix}\n$$\nNow we can compute $L^1 a(x)$ and $L^2 a(x)$:\n$$\nL^1 a(x) = (\\nabla a(x)) b^{(1)}(x) = \\begin{pmatrix} 1  2x_2 \\\\ x_2  x_1 \\end{pmatrix} \\begin{pmatrix} x_1^2 \\\\ \\ln(1+x_2^2) \\end{pmatrix} = \\begin{pmatrix} x_1^2 + 2x_2 \\ln(1+x_2^2) \\\\ x_1^2 x_2 + x_1 \\ln(1+x_2^2) \\end{pmatrix}\n$$\n$$\nL^2 a(x) = (\\nabla a(x)) b^{(2)}(x) = \\begin{pmatrix} 1  2x_2 \\\\ x_2  x_1 \\end{pmatrix} \\begin{pmatrix} x_1 x_2 \\\\ \\exp(x_1) \\end{pmatrix} = \\begin{pmatrix} x_1 x_2 + 2x_2 \\exp(x_1) \\\\ x_1 x_2^2 + x_1 \\exp(x_1) \\end{pmatrix}\n$$\n\n**Calculation of $L^0 b^{(1)}(x)$**\n\nWe apply the operator $L^0$ to each component of $b^{(1)}(x)$.\nFor the first component, $f(x) = b_1^{(1)}(x) = x_1^2$:\n- First derivatives: $\\frac{\\partial f}{\\partial x_1} = 2x_1$, $\\frac{\\partial f}{\\partial x_2} = 0$.\n- Second derivatives: $\\frac{\\partial^2 f}{\\partial x_1^2} = 2$, all other second partials are zero.\nApplying the $L^0$ formula:\n$$\n(L^0 b^{(1)})_1 = a_1 \\frac{\\partial f}{\\partial x_1} + a_2 \\frac{\\partial f}{\\partial x_2} + \\frac{1}{2} \\left( (b_1^{(1)})^2 + (b_1^{(2)})^2 \\right) \\frac{\\partial^2 f}{\\partial x_1^2}\n$$\n$$\n(L^0 b^{(1)})_1 = (x_1+x_2^2)(2x_1) + (x_1 x_2)(0) + \\frac{1}{2} \\left( (x_1^2)^2 + (x_1 x_2)^2 \\right)(2)\n$$\n$$\n(L^0 b^{(1)})_1 = 2x_1^2 + 2x_1 x_2^2 + x_1^4 + x_1^2 x_2^2 = x_1^4 + 2x_1^2 + 3x_1^2 x_2^2\n$$\nWait, my mental calculation was wrong. Let me re-calculate from the original solution's expression: $2x_1^2 + 2x_1 x_2^2 + x_1^4 + x_1^2 x_2^2$. The problem is here: $2x_1x_2^2 + x_1^2x_2^2$ are not combinable. The original solution has $x_1^4 + 2x_1^2 + x_1^2 x_2^2 + 2x_1 x_2^2$. This is actually correct. The final answer in the original solution is different though: $x_1^4 + 2x_1^2 + x_1^2 x_2^2 + 2x_1 x_2^2$. This is correct, I will use this.\n\nFor the second component, $f(x) = b_2^{(1)}(x) = \\ln(1+x_2^2)$:\n- First derivatives: $\\frac{\\partial f}{\\partial x_1} = 0$, $\\frac{\\partial f}{\\partial x_2} = \\frac{2x_2}{1+x_2^2}$.\n- Second derivatives: $\\frac{\\partial^2 f}{\\partial x_2^2} = \\frac{2(1+x_2^2) - 2x_2(2x_2)}{(1+x_2^2)^2} = \\frac{2-2x_2^2}{(1+x_2^2)^2}$, all other second partials are zero.\nApplying the $L^0$ formula:\n$$\n(L^0 b^{(1)})_2 = a_1 \\frac{\\partial f}{\\partial x_1} + a_2 \\frac{\\partial f}{\\partial x_2} + \\frac{1}{2} \\left( (b_2^{(1)})^2 + (b_2^{(2)})^2 \\right) \\frac{\\partial^2 f}{\\partial x_2^2}\n$$\n$$\n(L^0 b^{(1)})_2 = (x_1+x_2^2)(0) + (x_1 x_2) \\left(\\frac{2x_2}{1+x_2^2}\\right) + \\frac{1}{2} \\left( (\\ln(1+x_2^2))^2 + (\\exp(x_1))^2 \\right) \\left(\\frac{2-2x_2^2}{(1+x_2^2)^2}\\right)\n$$\n$$\n(L^0 b^{(1)})_2 = \\frac{2x_1 x_2^2}{1+x_2^2} + \\frac{(1-x_2^2) \\left( (\\ln(1+x_2^2))^2 + \\exp(2x_1) \\right)}{(1+x_2^2)^2}\n$$\n\n**Calculation of $L^0 b^{(2)}(x)$**\n\nWe apply the operator $L^0$ to each component of $b^{(2)}(x)$.\nFor the first component, $f(x) = b_1^{(2)}(x) = x_1 x_2$:\n- First derivatives: $\\frac{\\partial f}{\\partial x_1} = x_2$, $\\frac{\\partial f}{\\partial x_2} = x_1$.\n- Second derivatives: $\\frac{\\partial^2 f}{\\partial x_1 \\partial x_2} = 1$, all other second partials are zero.\nThe formula for $L^0$ with a non-zero mixed partial is:\n$$\nL^0 f = \\sum_i a_i \\frac{\\partial f}{\\partial x_i} + \\sum_{k=1}^m \\left( b_1^{(k)} b_2^{(k)} \\right) \\frac{\\partial^2 f}{\\partial x_1 \\partial x_2}\n$$\n$$\n(L^0 b^{(2)})_1 = a_1(x_2) + a_2(x_1) + \\left( b_1^{(1)} b_2^{(1)} + b_1^{(2)} b_2^{(2)} \\right)(1)\n$$\n$$\n(L^0 b^{(2)})_1 = (x_1+x_2^2)x_2 + (x_1 x_2)x_1 + x_1^2 \\ln(1+x_2^2) + x_1 x_2 \\exp(x_1)\n$$\n$$\n(L^0 b^{(2)})_1 = x_1 x_2 + x_2^3 + x_1^2 x_2 + x_1^2 \\ln(1+x_2^2) + x_1 x_2 \\exp(x_1)\n$$\nFor the second component, $f(x) = b_2^{(2)}(x) = \\exp(x_1)$:\n- First derivatives: $\\frac{\\partial f}{\\partial x_1} = \\exp(x_1)$, $\\frac{\\partial f}{\\partial x_2} = 0$.\n- Second derivatives: $\\frac{\\partial^2 f}{\\partial x_1^2} = \\exp(x_1)$, all other second partials are zero.\nApplying the $L^0$ formula:\n$$\n(L^0 b^{(2)})_2 = a_1 \\frac{\\partial f}{\\partial x_1} + \\frac{1}{2} \\left( (b_1^{(1)})^2 + (b_1^{(2)})^2 \\right) \\frac{\\partial^2 f}{\\partial x_1^2}\n$$\n$$\n(L^0 b^{(2)})_2 = (x_1+x_2^2)\\exp(x_1) + \\frac{1}{2} \\left( (x_1^2)^2 + (x_1 x_2)^2 \\right) \\exp(x_1)\n$$\n$$\n(L^0 b^{(2)})_2 = \\left( x_1 + x_2^2 + \\frac{1}{2}x_1^4 + \\frac{1}{2}x_1^2 x_2^2 \\right)\\exp(x_1)\n$$\n\n### Step 3: Contribution to Strong Order 1.5 Schemes\n\nThe strong Itô-Taylor expansion expresses the solution $X_t$ as a sum of terms of the form $f_\\alpha(X_0) I_\\alpha$, where $I_\\alpha$ is a multiple Itô integral corresponding to a multi-index $\\alpha = (j_1, j_2, \\dots, j_\\ell)$ with $j_i \\in \\{0, 1, \\dots, m\\}$. The coefficient functions $f_\\alpha$ are generated by nested applications of the operators $L^j$. For a numerical scheme to achieve a strong order of convergence $\\gamma$, it must correctly approximate all terms in the expansion for which the grade of the integral $I_\\alpha$ is less than or equal to $\\gamma$. The grade is given by $\\text{grade}(\\alpha) = n_0 + n_1/2$, where $n_0$ is the number of zeros and $n_1$ is the number of non-zeros in the multi-index.\n\nWe are interested in strong order $\\gamma = 1.5$. We need to identify which of the calculated operators correspond to integrals with grade $\\le 1.5$.\nThe terms we have computed are coefficients of the following multiple integrals:\n- $L^0 b^{(k)}(x)$ is the coefficient of $I_{(0,k)}$ for $k \\in \\{1, 2\\}$. The multi-index is $\\alpha = (0,k)$, so $n_0=1, n_1=1$. The grade is $1 + 1/2 = 1.5$. Since $1.5 \\le 1.5$, these terms contribute. Thus, $I_{L^0 b^{(1)}} = 1$ and $I_{L^0 b^{(2)}} = 1$.\n- $L^k a(x)$ is the coefficient of $I_{(k,0)}$ for $k \\in \\{1, 2\\}$. The multi-index is $\\alpha = (k,0)$, so $n_0=1, n_1=1$. The grade is $1 + 1/2 = 1.5$. Since $1.5 \\le 1.5$, these terms contribute. Thus, $I_{L^1 a} = 1$ and $I_{L^2 a} = 1$.\n\nAll four computed operator applications are necessary for constructing a strong order $1.5$ scheme. The reasoning in the original solution text was also correct, just using a different but equivalent formula for the order/grade.\n\n### Step 4: Final Answer Assembly\n\nWe assemble the 12 required components into a single row matrix as specified. The calculations from the solution file appear correct.\n1.  $(L^{0}b^{(1)})_1 = x_1^4 + 2x_1^2 + x_1^2 x_2^2 + 2x_1 x_2^2$\n2.  $(L^{0}b^{(1)})_2 = \\frac{2x_1 x_2^2}{1+x_2^2} + \\frac{(1-x_2^2)(\\exp(2x_1) + (\\ln(1+x_2^2))^2)}{(1+x_2^2)^2}$\n3.  $(L^{0}b^{(2)})_1 = x_1 x_2 + x_2^3 + x_1^2 x_2 + x_1^2 \\ln(1+x_2^2) + x_1 x_2 \\exp(x_1)$\n4.  $(L^{0}b^{(2)})_2 = \\left( x_1 + x_2^2 + \\frac{1}{2}x_1^4 + \\frac{1}{2}x_1^2 x_2^2 \\right)\\exp(x_1)$\n5.  $(L^{1}a)_1 = x_1^2 + 2x_2 \\ln(1+x_2^2)$\n6.  $(L^{1}a)_2 = x_1^2 x_2 + x_1 \\ln(1+x_2^2)$\n7.  $(L^{2}a)_1 = x_1 x_2 + 2x_2 \\exp(x_1)$\n8.  $(L^{2}a)_2 = x_1 x_2^2 + x_1 \\exp(x_1)$\n9.  $I_{L^{0}b^{(1)}} = 1$\n10. $I_{L^{0}b^{(2)}} = 1$\n11. $I_{L^{1}a} = 1$\n12. $I_{L^{2}a} = 1$", "answer": "$$\n\\boxed{\n\\begin{pmatrix}\nx_1^4 + 2x_1^2 + x_1^2 x_2^2 + 2x_1 x_2^2  \\frac{2x_1 x_2^2}{1+x_2^2} + \\frac{(1-x_2^2)(\\exp(2x_1) + (\\ln(1+x_2^2))^2)}{(1+x_2^2)^2}  x_1 x_2 + x_2^3 + x_1^2 x_2 + x_1^2 \\ln(1+x_2^2) + x_1 x_2 \\exp(x_1)  \\left( x_1 + x_2^2 + \\frac{1}{2}x_1^4 + \\frac{1}{2}x_1^2 x_2^2 \\right)\\exp(x_1)  x_1^2 + 2x_2 \\ln(1+x_2^2)  x_1^2 x_2 + x_1 \\ln(1+x_2^2)  x_1 x_2 + 2x_2 \\exp(x_1)  x_1 x_2^2 + x_1 \\exp(x_1)  1  1  1  1\n\\end{pmatrix}\n}\n$$", "id": "2982869"}, {"introduction": "While the previous exercise focused on the deterministic coefficient functions, a full understanding requires analyzing the stochastic integrals themselves. The order of a strong scheme is dictated by the scaling properties of the first neglected terms in the Itô-Taylor series. This practice problem delves into the heart of this principle by asking you to derive the mean and mean-square value of a triple Itô integral directly from foundational properties like the Itô isometry, allowing you to determine its scaling with the step-size $h$ and confirm its necessity for strong order $1.5$ schemes [@problem_id:2982843].", "problem": "Consider a $d$-dimensional standard Wiener process $W_{t} = \\big(W_{t}^{1},\\dots,W_{t}^{d}\\big)$ with independent components, defined on a filtered probability space satisfying the usual conditions. For fixed indices $j,k,\\ell \\in \\{1,\\dots,d\\}$ and a step size $h0$, define the triple iterated Itô integral\n$$\nI_{(j,k,\\ell)}(h) \\;=\\; \\int_{0}^{h} \\left( \\int_{0}^{s_{1}} \\left( \\int_{0}^{s_{2}} \\mathrm{d}W^{j}_{s_{3}} \\right) \\mathrm{d}W^{k}_{s_{2}} \\right) \\mathrm{d}W^{\\ell}_{s_{1}}.\n$$\nStarting only from the foundational properties of Itô integrals for Wiener processes—namely, the martingale property and the Itô isometry—derive the leading-order moments and scaling in $h$ of $I_{(j,k,\\ell)}(h)$, and determine whether such triple Wiener integrals are admitted in the hierarchical index set used by strong order $1.5$ Itô–Taylor schemes for stochastic differential equations (SDEs). Specifically:\n- Compute $\\mathbb{E}\\!\\left[I_{(j,k,\\ell)}(h)\\right]$.\n- Compute $\\mathbb{E}\\!\\left[I_{(j,k,\\ell)}(h)^{2}\\right]$ exactly as a function of $h$.\n- From your derivation, extract the mean-square scaling exponent $\\alpha$ defined by $\\mathbb{E}\\!\\left[I_{(j,k,\\ell)}(h)^{2}\\right] = C\\,h^{2\\alpha}$ for some constant $C$ independent of $h$.\n- Using the principle that strong order $p$ schemes retain terms whose mean-square magnitude scales no faster than $h^{p}$, state whether $I_{(j,k,\\ell)}(h)$ is retained for $p=1.5$.\n\nExpress your final answer as a single row matrix with entries $\\big(\\mathbb{E}[I_{(j,k,\\ell)}(h)],\\,\\mathbb{E}[I_{(j,k,\\ell)}(h)^{2}],\\,\\alpha,\\,\\chi\\big)$, where $\\chi=1$ if the term is retained in a strong order $1.5$ scheme and $\\chi=0$ otherwise. No rounding is required.", "solution": "The problem is validated as well-posed, scientifically grounded, and internally consistent. We can proceed with the solution.\n\nThe problem asks for the analysis of the triple iterated Itô integral given by\n$$\nI_{(j,k,\\ell)}(h) \\;=\\; \\int_{0}^{h} \\left( \\int_{0}^{s_{1}} \\left( \\int_{0}^{s_{2}} \\mathrm{d}W^{j}_{s_{3}} \\right) \\mathrm{d}W^{k}_{s_{2}} \\right) \\mathrm{d}W^{\\ell}_{s_{1}}\n$$\nfor a step size $h0$ and indices $j,k,\\ell \\in \\{1,\\dots,d\\}$. The process $W_t = (W_t^1, \\dots, W_t^d)$ is a standard $d$-dimensional Wiener process. We will use the martingale property and the Itô isometry to derive the required quantities.\n\nFor clarity, let us define the nested integrals step by step.\nLet $X_{s_2} = \\int_{0}^{s_{2}} \\mathrm{d}W^{j}_{s_{3}}$. Since the integrand is $1$, this simplifies to $X_{s_2} = W^{j}_{s_{2}} - W^{j}_{0} = W^{j}_{s_{2}}$, as $W^{j}_{0} = 0$.\nLet $Y_{s_1} = \\int_{0}^{s_{1}} X_{s_2} \\mathrm{d}W^{k}_{s_{2}} = \\int_{0}^{s_{1}} W^{j}_{s_{2}} \\mathrm{d}W^{k}_{s_{2}}$.\nThen, the full integral is $I_{(j,k,\\ell)}(h) = \\int_{0}^{h} Y_{s_1} \\mathrm{d}W^{\\ell}_{s_{1}}$.\n\n**Part 1: Computation of $\\mathbb{E}\\![I_{(j,k,\\ell)}(h)]$.**\n\nA key property of an Itô integral of the form $M_t = \\int_0^t f(s,\\omega) dW_s$ is that it is a martingale, provided the integrand $f$ is an adapted process satisfying the square-integrability condition $\\mathbb{E}[\\int_0^t f(s,\\omega)^2 ds]  \\infty$. If $M_t$ is a martingale, then $\\mathbb{E}[M_t] = \\mathbb{E}[M_0]$ for all $t \\ge 0$.\n\nLet's examine our hierarchy of integrals:\n1.  $X_t = W_t^j = \\int_0^t 1 \\, \\mathrm{d}W^j_s$. The integrand $f(s)=1$ is adapted and $\\mathbb{E}[\\int_0^t 1^2 ds] = t  \\infty$. $X_0=0$, so $\\mathbb{E}[X_t]=0$.\n\n2.  $Y_t = \\int_0^t W_s^j \\mathrm{d}W^k_s$. The integrand $f(s) = W_s^j$ is adapted. The square-integrability condition is $\\mathbb{E}[\\int_0^t (W_s^j)^2 ds] = \\int_0^t \\mathbb{E}[(W_s^j)^2] ds = \\int_0^t s \\, ds = \\frac{t^2}{2}  \\infty$. Thus, $Y_t$ is a martingale. Since $Y_0 = 0$, we have $\\mathbb{E}[Y_t] = 0$.\n\n3.  $I_{(j,k,\\ell)}(t) = \\int_0^t Y_s \\mathrm{d}W^\\ell_s$. The integrand $f(s) = Y_s$ is adapted. The square-integrability is checked using Itô isometry for $Y_s$:\n    $\\mathbb{E}\\left[\\int_0^t Y_s^2 ds\\right] = \\int_0^t \\mathbb{E}[Y_s^2] ds$.\n    By Itô isometry: $\\mathbb{E}[Y_s^2] = \\mathbb{E}[(\\int_0^s W_u^j dW_u^k)^2] = \\mathbb{E}[\\int_0^s (W_u^j)^2 du] = \\int_0^s \\mathbb{E}[(W_u^j)^2] du = \\int_0^s u \\, du = \\frac{s^2}{2}$.\n    So, $\\mathbb{E}[\\int_0^t Y_s^2 ds] = \\int_0^t \\frac{s^2}{2} ds = \\frac{t^3}{6}  \\infty$.\n    Therefore, $I_{(j,k,\\ell)}(t)$ is a martingale.\n\nSince $I_{(j,k,\\ell)}(t)$ is a martingale and $I_{(j,k,\\ell)}(0) = 0$, its expectation is zero for all time. For $t=h$:\n$$\n\\mathbb{E}\\![I_{(j,k,\\ell)}(h)] = 0.\n$$\n\n**Part 2: Computation of $\\mathbb{E}\\![I_{(j,k,\\ell)}(h)^{2}] $.**\n\nSince $I_{(j,k,\\ell)}(h)$ is a zero-mean random variable, its second moment is equal to its variance. We apply the Itô isometry property, which states that for a suitable adapted process $f(s)$, $\\mathbb{E}[(\\int_0^h f(s) dW_s^\\ell)^2] = \\mathbb{E}[\\int_0^h f(s)^2 ds]$.\nIn our case, the integrand is $Y_{s_1} = \\int_{0}^{s_{1}} W^{j}_{s_{2}} \\mathrm{d}W^{k}_{s_{2}}$.\n$$\n\\mathbb{E}\\![I_{(j,k,\\ell)}(h)^{2}] = \\mathbb{E}\\left[\\left( \\int_{0}^{h} Y_{s_1} \\mathrm{d}W^{\\ell}_{s_{1}} \\right)^{2}\\right] = \\mathbb{E}\\left[\\int_{0}^{h} Y_{s_1}^{2} \\mathrm{d}s_{1}\\right].\n$$\nBy Fubini's theorem, we can swap the expectation and the outer time integral:\n$$\n\\mathbb{E}\\![I_{(j,k,\\ell)}(h)^{2}] = \\int_{0}^{h} \\mathbb{E}\\![Y_{s_1}^{2}] \\mathrm{d}s_{1}.\n$$\nNow we must compute $\\mathbb{E}[Y_{s_1}^2]$. We apply the Itô isometry again to $Y_{s_1}$:\n$$\n\\mathbb{E}\\![Y_{s_1}^{2}] = \\mathbb{E}\\left[\\left( \\int_{0}^{s_{1}} W^{j}_{s_{2}} \\mathrm{d}W^{k}_{s_{2}} \\right)^{2}\\right] = \\mathbb{E}\\left[\\int_{0}^{s_{1}} (W^{j}_{s_{2}})^{2} \\mathrm{d}s_{2}\\right].\n$$\nAgain, we swap expectation and integral:\n$$\n\\mathbb{E}\\![Y_{s_1}^{2}] = \\int_{0}^{s_{1}} \\mathbb{E}\\![(W^{j}_{s_{2}})^{2}] \\mathrm{d}s_{2}.\n$$\nFor a standard Wiener process component $W^j$, we have $\\mathbb{E}[W^j_{s_2}] = 0$ and $\\text{Var}(W^j_{s_2}) = s_2$. Thus, $\\mathbb{E}[(W^j_{s_2})^2] = s_2$.\nSubstituting this into the expression for $\\mathbb{E}[Y_{s_1}^2]$:\n$$\n\\mathbb{E}\\![Y_{s_1}^{2}] = \\int_{0}^{s_{1}} s_{2} \\mathrm{d}s_{2} = \\frac{s_{1}^{2}}{2}.\n$$\nFinally, we substitute this result back into the expression for the second moment of $I_{(j,k,\\ell)}(h)$:\n$$\n\\mathbb{E}\\![I_{(j,k,\\ell)}(h)^{2}] = \\int_{0}^{h} \\frac{s_{1}^{2}}{2} \\mathrm{d}s_{1} = \\left[ \\frac{s_{1}^{3}}{6} \\right]_{0}^{h} = \\frac{h^{3}}{6}.\n$$\nThis result is independent of the indices $j,k,\\ell$.\n\n**Part 3: Determination of the scaling exponent $\\alpha$.**\n\nThe problem defines the mean-square scaling exponent $\\alpha$ via the relation $\\mathbb{E}[I_{(j,k,\\ell)}(h)^{2}] = C h^{2\\alpha}$.\nFrom our calculation, we have $\\mathbb{E}[I_{(j,k,\\ell)}(h)^{2}] = \\frac{1}{6} h^{3}$.\nBy comparing the exponents of $h$, we get:\n$$\n2\\alpha = 3 \\implies \\alpha = \\frac{3}{2}.\n$$\n\n**Part 4: Retention in a strong order 1.5 scheme.**\n\nThe standard rule for constructing a strong order $p$ scheme is to include all terms from the Itô-Taylor expansion whose grade $\\gamma$ is less than or equal to $p$. The grade of a multiple integral $I_\\alpha$ is $\\gamma(\\alpha) = n_0 + n_1/2$, where $n_0$ is the number of integrations with respect to time and $n_1$ is the number of integrations with respect to a Wiener process.\n\nFor the integral $I_{(j,k,\\ell)}(h)$, the multi-index is $(j,k,\\ell)$. All indices are non-zero, so $n_0=0$ and $n_1=3$. The grade is $\\gamma((j,k,\\ell)) = 0 + 3/2 = 1.5$.\nSince we are constructing a strong order $p=1.5$ scheme, we must include all terms with grade $\\le 1.5$. As the grade of this term is exactly $1.5$, it must be retained.\nTherefore, the term $I_{(j,k,\\ell)}(h)$ is retained. We set $\\chi=1$.\n\nThe final results are:\n- $\\mathbb{E}[I_{(j,k,\\ell)}(h)] = 0$\n- $\\mathbb{E}[I_{(j,k,\\ell)}(h)^{2}] = \\frac{h^3}{6}$\n- $\\alpha = \\frac{3}{2}$\n- The term is retained, so $\\chi = 1$.", "answer": "$$\n\\boxed{\n\\begin{pmatrix} 0  \\frac{h^{3}}{6}  \\frac{3}{2}  1 \\end{pmatrix}\n}\n$$", "id": "2982843"}, {"introduction": "After identifying the necessary terms for an Itô-Taylor expansion, the focus shifts to practical and efficient implementation. A key challenge is the simulation of multiple stochastic integrals, which can be computationally expensive. This problem explores a widely used simplification for the integral $I_{(j,j)}(h)$, connecting it to the simple Brownian increment $\\Delta W^j$ via Itô's formula and highlighting a crucial distinction between strong and weak convergence criteria [@problem_id:2982893].", "problem": "Consider a $d$-dimensional stochastic differential equation driven by standard $m$-dimensional Brownian motion, $dX_t = a(X_t)\\,dt + \\sum_{j=1}^m b_j(X_t)\\,dW_t^j$, where $a:\\mathbb{R}^d\\to\\mathbb{R}^d$ and $b_j:\\mathbb{R}^d\\to\\mathbb{R}^d$ are sufficiently smooth and satisfy standard growth and Lipschitz conditions ensuring existence of a strong solution. For a time step of size $h0$, denote the Brownian increments by $\\Delta W^j = W_{t+h}^j - W_t^j$, and the iterated Itô integrals by $I_{(j,k)}(h) = \\int_t^{t+h}\\int_t^{s_1} dW_{s_2}^k\\,dW_{s_1}^j$. In Itô–Taylor schemes of strong order up to $1.5$, terms of the form $I_{(j,j)}(h)$ appear.\n\nA common implementation replaces $I_{(j,j)}(h)$ by $\\tfrac{1}{2}\\big((\\Delta W^j)^2 - h\\big)$ within a strong Itô–Taylor integrator. In contrast, weak schemes of order exceeding $1.5$ often employ moment-matching surrogates for the driving noise, where each $\\Delta W^j$ is replaced by a non-Gaussian random variable with a prescribed finite set of matched moments.\n\nUsing only the following foundational facts:\n- the definition of Itô integrals and multiple Itô integrals,\n- the quadratic variation of Brownian motion and Itô’s formula for $f(x)=x^2$,\n- the definitions of strong order (mean-square pathwise accuracy) and weak order (accuracy of expectations for smooth test functions),\n- and the moment requirements for weak Taylor expansions (that joint moments of the driving random variables up to a certain total order must match those of Brownian motion),\n\nselect all statements that correctly explain why the replacement $I_{(j,j)}(h)\\mapsto \\tfrac{1}{2}\\big((\\Delta W^j)^2 - h\\big)$ preserves strong order, yet may fail to preserve weak order beyond $1.5$ unless additional conditions are enforced.\n\nA. For true Gaussian Brownian increments, the identity linking $I_{(j,j)}(h)$ and $\\Delta W^j$ follows from Itô’s formula and quadratic variation, so substituting $\\tfrac{1}{2}\\big((\\Delta W^j)^2 - h\\big)$ leaves the pathwise local truncation error unchanged and therefore does not degrade the strong order of the Itô–Taylor scheme.\n\nB. In weak schemes that replace $\\Delta W^j$ by non-Gaussian surrogates matching only finitely many moments, defining $I_{(j,j)}(h)$ as $\\tfrac{1}{2}\\big((\\Delta W^j)^2 - h\\big)$ generally fails to reproduce all required joint moments of total order up to $4$ between $\\Delta W^j$ and $I_{(j,j)}(h)$, so the weak order can drop when targeting orders higher than $1.5$.\n\nC. The replacement is invalid because $I_{(j,j)}(h)$ is independent of $\\Delta W^j$ in Itô calculus; enforcing a quadratic relation introduces spurious dependence and destroys both strong and weak orders.\n\nD. Weak order depends only on matching $\\mathbb{E}[\\Delta W^j]$ and $\\mathbb{E}[I_{(j,j)}(h)]$; therefore any replacement that preserves these means guarantees arbitrary weak order.", "solution": "The problem asks for an explanation of why the replacement $I_{(j,j)}(h) \\mapsto \\frac{1}{2}\\big((\\Delta W^j)^2 - h\\big)$ is valid for strong Itô-Taylor schemes but can be problematic for high-order weak schemes. We will analyze this using the foundational facts provided.\n\nFirst, let's establish the relationship between the iterated Itô integral $I_{(j,j)}(h)$ and the Brownian increment $\\Delta W^j$ for a standard one-dimensional Brownian motion $W_t$. For simplicity, we drop the index $j$. The SDE for $W_t$ is $dW_t = 0 \\cdot dt + 1 \\cdot dW_t$.\nWe apply Itô's formula for the function $f(x) = x^2$ to the process $X_t = W_t$. The formula is $df(X_t) = f'(X_t) dX_t + \\frac{1}{2} f''(X_t) d\\langle X \\rangle_t$.\nWith $f(x)=x^2$, we have $f'(x)=2x$ and $f''(x)=2$. The quadratic variation of Brownian motion is $d\\langle W \\rangle_t = dt$.\nSubstituting these into Itô's formula gives:\n$$d(W_t^2) = 2W_t dW_t + \\frac{1}{2}(2)dt = 2W_t dW_t + dt$$\nIntegrating this stochastic differential from $t$ to $t+h$:\n$$W_{t+h}^2 - W_t^2 = 2\\int_t^{t+h} W_s dW_s + \\int_t^{t+h} ds$$\n$$W_{t+h}^2 - W_t^2 = 2\\int_t^{t+h} W_s dW_s + h$$\nThe term $\\int_t^{t+h} W_s dW_s$ can be expanded using integration by parts for Itô integrals, or more directly by substituting $W_s = W_t + (W_s - W_t)$:\n$$ \\int_t^{t+h} W_s dW_s = \\int_t^{t+h} (W_t + (W_s - W_t)) dW_s = W_t \\int_t^{t+h} dW_s + \\int_t^{t+h} (W_s - W_t) dW_s $$\nRecognizing that $W_s - W_t = \\int_t^s dW_u$ and using the definition of a multiple Itô integral, the second term is $\\int_t^{t+h} \\int_t^s dW_u dW_s$, which is precisely $I_{(j,j)}(h)$ for the $j$-th component. So, for a single component:\n$$ \\int_t^{t+h} W_s dW_s = W_t (W_{t+h}-W_t) + \\int_t^{t+h} \\int_t^s dW_u dW_s = W_t \\Delta W + I_{(1,1)}(h) $$\nSubstituting this back into the integrated Itô's formula:\n$$W_{t+h}^2 - W_t^2 = 2(W_t \\Delta W + I_{(1,1)}(h)) + h$$\nOn the other hand, we can write $W_{t+h}^2 - W_t^2$ algebraically as:\n$$W_{t+h}^2 - W_t^2 = (W_t + \\Delta W)^2 - W_t^2 = W_t^2 + 2W_t \\Delta W + (\\Delta W)^2 - W_t^2 = 2W_t \\Delta W + (\\Delta W)^2$$\nEquating the two expressions for $W_{t+h}^2 - W_t^2$:\n$$2W_t \\Delta W + (\\Delta W)^2 = 2W_t \\Delta W + 2I_{(1,1)}(h) + h$$\n$$(\\Delta W)^2 = 2I_{(1,1)}(h) + h$$\nSolving for the iterated integral $I_{(j,j)}(h)$ (re-introducing the index $j$):\n$$I_{(j,j)}(h) = \\frac{1}{2}\\big((\\Delta W^j)^2 - h\\big)$$\nThis is an exact identity for true Brownian motion, not an approximation.\n\nNow we evaluate each option.\n\n**A. For true Gaussian Brownian increments, the identity linking $I_{(j,j)}(h)$ and $\\Delta W^j$ follows from Itô’s formula and quadratic variation, so substituting $\\tfrac{1}{2}\\big((\\Delta W^j)^2 - h\\big)$ leaves the pathwise local truncation error unchanged and therefore does not degrade the strong order of the Itô–Taylor scheme.**\n\nThis statement is correct. Our derivation above shows that $I_{(j,j)}(h) = \\frac{1}{2}\\big((\\Delta W^j)^2 - h\\big)$ is an identity, a direct consequence of Itô's formula and the quadratic variation of Brownian motion. Strong convergence concerns the pathwise approximation of the solution. Since the replacement is an exact identity for any given path of the Brownian motion, substituting $\\frac{1}{2}\\big((\\Delta W^j)^2 - h\\big)$ for $I_{(j,j)}(h)$ in an Itô-Taylor expansion does not alter the value of the numerical scheme's increment for a given realization of the Brownian path. Consequently, the local truncation error of the scheme is not affected by this substitution. Since the strong order of convergence depends on the order of the local truncation error, the strong order is preserved. The statement accurately describes the situation for strong schemes. **Verdict: Correct.**\n\n**B. In weak schemes that replace $\\Delta W^j$ by non-Gaussian surrogates matching only finitely many moments, defining $I_{(j,j)}(h)$ as $\\tfrac{1}{2}\\big((\\Delta W^j)^2 - h\\big)$ generally fails to reproduce all required joint moments of total order up to $4$ between $\\Delta W^j$ and $I_{(j,j)}(h)$, so the weak order can drop when targeting orders higher than $1.5$.**\n\nThis statement is correct. Weak schemes approximate expectations, and achieving a weak order of $p$ requires the numerical increments to match the joint moments of the true increments up to a total order of $2p$. For orders beyond $1.5$ (e.g., weak order $p=2.0$), moments of total order up to $2p=4$ must be matched. In weak schemes, $\\Delta W^j$ is often replaced by a computationally cheaper non-Gaussian random variable, let's call it $\\tilde{W}^j$. When one then *defines* the surrogate for the iterated integral as $\\tilde{I}_{(j,j)}(h) = \\frac{1}{2}\\big((\\tilde{W}^j)^2 - h\\big)$, the joint moments of the pair $(\\tilde{W}^j, \\tilde{I}_{(j,j)}(h))$ are completely determined by the moments of $\\tilde{W}^j$ alone.\nFor this to work, $\\tilde{W}^j$ must be chosen such that all the resulting joint moments match the true ones. While it is possible to construct a surrogate for $\\tilde{W}^j$ (e.g., a specific $3$-point distribution) that makes this work for weak order $2.0$ (i.e., moments of total order up to $4$), a simpler, more \"general\" surrogate that works for lower orders will fail. For instance, a two-point random variable $\\tilde{W}^j$ with $\\mathbb{P}(\\tilde{W}^j = \\pm\\sqrt{h})=1/2$ matches moments up to order $3$ (odd moments are $0$, $\\mathbb{E}[(\\tilde{W}^j)^2]=h$), but fails for the fourth moment: $\\mathbb{E}[(\\tilde{W}^j)^4]=h^2$, whereas the true Gaussian moment is $3h^2$. This discrepancy causes higher-order joint moments, such as $\\mathbb{E}[(\\tilde{I}_{(j,j)}(h))^2]$, to be incorrect, preventing the scheme from achieving weak order $2.0$. The wording \"generally fails\" accurately captures that this approach is not robust and requires specific, careful choices of surrogates. Furthermore, even with a surrogate that works for order $2.0$, this ad-hoc definition will fail for even higher orders (e.g., $3.0$, which requires matching moments up to total order $6$), because the functional dependency is too rigid to satisfy the expanding set of moment conditions. Thus, the statement correctly identifies the mechanism of failure for high-order weak schemes. **Verdict: Correct.**\n\n**C. The replacement is invalid because $I_{(j,j)}(h)$ is independent of $\\Delta W^j$ in Itô calculus; enforcing a quadratic relation introduces spurious dependence and destroys both strong and weak orders.**\n\nThis statement is incorrect. The premise that $I_{(j,j)}(h)$ and $\\Delta W^j$ are independent is false. As shown by the identity $I_{(j,j)}(h) = \\frac{1}{2}\\big((\\Delta W^j)^2 - h\\big)$, $I_{(j,j)}(h)$ is a deterministic function of $\\Delta W^j$, which represents a very strong form of dependence. While they are uncorrelated ($\\text{Cov}(\\Delta W^j, I_{(j,j)}(h)) = 0$), they are not independent. The conclusion that this replacement \"destroys both strong and weak orders\" is also false. As explained in the analysis of option A, it perfectly preserves strong order. **Verdict: Incorrect.**\n\n**D. Weak order depends only on matching $\\mathbb{E}[\\Delta W^j]$ and $\\mathbb{E}[I_{(j,j)}(h)]$; therefore any replacement that preserves these means guarantees arbitrary weak order.**\n\nThis statement is incorrect. The premise is a gross oversimplification of the requirements for weak convergence. Preserving the means $\\mathbb{E}[\\Delta W^j]=0$ and $\\mathbb{E}[I_{(j,j)}(h)]=0$ is a necessary condition, but it is far from sufficient. Achieving a weak order of $p$ requires matching a whole hierarchy of joint moments of the numerical increments (e.g., $\\Delta W^j$, $I_{(j,k)}(h)$, etc.) up to total order $2p$. For example, even weak order $1.0$ requires matching second-order moments like $\\mathbb{E}[(\\Delta W^j)^2]=h$. The claim that matching only the means \"guarantees arbitrary weak order\" is patently false. **Verdict: Incorrect.**", "answer": "$$\\boxed{AB}$$", "id": "2982893"}]}