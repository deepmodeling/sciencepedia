{"hands_on_practices": [{"introduction": "This first practice serves as a foundational check on the setup for proving the existence and uniqueness of solutions to stochastic differential equations (SDEs). It prompts you to verify that the Picard operator is well-defined on the correct space of stochastic processes, $\\mathcal{S}^2([0,T];\\mathbb{R}^d)$, and to recognize the overall strategy for extending local solutions to a global one. Understanding these mapping properties and the structure of the proof is the first step toward mastering the theory.", "problem": "Consider a filtered probability space $(\\Omega,\\mathcal{F},(\\mathcal{F}_t)_{t\\in[0,T]},\\mathbb{P})$ satisfying the usual conditions, and let $(W_t)_{t\\in[0,T]}$ be an $\\mathbb{R}^m$-valued standard Brownian motion adapted to $(\\mathcal{F}_t)_{t\\in[0,T]}$. Let $d$ and $m$ be fixed positive integers, and let $X_0$ be an $\\mathcal{F}_0$-measurable $\\mathbb{R}^d$-valued random variable with $\\mathbb{E}[|X_0|^2]\\infty$. Consider the stochastic integral equation\n$$\nX_t \\;=\\; X_0 \\;+\\; \\int_0^t b(s,X_s)\\,ds \\;+\\; \\int_0^t \\sigma(s,X_s)\\,dW_s,\\qquad t\\in[0,T],\n$$\nwhere $b:[0,T]\\times\\mathbb{R}^d\\to\\mathbb{R}^d$ and $\\sigma:[0,T]\\times\\mathbb{R}^d\\to\\mathbb{R}^{d\\times m}$ are jointly measurable and adapted in the sense that $b(t,X_t)$ and $\\sigma(t,X_t)$ are progressively measurable for any adapted process $(X_t)_{t\\in[0,T]}$. Assume the following global Lipschitz and linear growth conditions hold: there exist constants $L\\ge 0$ and $M\\ge 0$ such that for all $t\\in[0,T]$ and $x,y\\in\\mathbb{R}^d$,\n$$\n|b(t,x)-b(t,y)| \\;+\\; \\|\\sigma(t,x)-\\sigma(t,y)\\|_{\\mathrm{F}} \\;\\le\\; L\\,|x-y|,\n$$\nand\n$$\n|b(t,x)|^2 \\;+\\; \\|\\sigma(t,x)\\|_{\\mathrm{F}}^2 \\;\\le\\; M\\,\\big(1+|x|^2\\big),\n$$\nwhere $\\|\\cdot\\|_{\\mathrm{F}}$ denotes the Frobenius norm on $\\mathbb{R}^{d\\times m}$.\n\nDefine the mapping $\\Phi$ on a space of adapted processes by\n$$\n\\big(\\Phi(X)\\big)_t \\;:=\\; X_0 \\;+\\; \\int_0^t b(s,X_s)\\,ds \\;+\\; \\int_0^t \\sigma(s,X_s)\\,dW_s,\\qquad t\\in[0,T].\n$$\nConsider the following function spaces and norms:\n- $\\mathcal{S}^2([0,T];\\mathbb{R}^d)$ is the space of all $(\\mathcal{F}_t)$-adapted, continuous $\\mathbb{R}^d$-valued processes $X$ with finite norm\n$$\n\\|X\\|_{\\mathcal{S}^2_T} \\;:=\\; \\Big(\\mathbb{E}\\big[\\sup_{t\\in[0,T]}|X_t|^2\\big]\\Big)^{1/2}.\n$$\n- $\\mathcal{H}^2([0,T];\\mathbb{R}^d)$ is the space of all predictable $\\mathbb{R}^d$-valued processes $X$ with finite norm\n$$\n\\|X\\|_{\\mathcal{H}^2_T} \\;:=\\; \\Big(\\mathbb{E}\\big[\\int_0^T |X_t|^2\\,dt\\big]\\Big)^{1/2}.\n$$\n\nUsing only the foundational definitions of stochastic integrals, adaptedness, the global Lipschitz and linear growth conditions above, and well-tested inequalities for stochastic integrals such as the Burkholder–Davis–Gundy (BDG) inequality and Gronwall-type estimates, determine which of the following statements are true:\n\nA. Under the stated assumptions, the mapping $\\Phi$ takes $\\mathcal{S}^2([0,T];\\mathbb{R}^d)$ into itself, i.e., for any $X\\in\\mathcal{S}^2([0,T];\\mathbb{R}^d)$, one has $\\Phi(X)\\in\\mathcal{S}^2([0,T];\\mathbb{R}^d)$.\n\nB. There exists a time $T^\\star0$, depending only on the Lipschitz constant $L$ (and dimension-dependent BDG constants), such that for all $T\\in(0,T^\\star)$, the mapping $\\Phi$ is a strict contraction on $\\mathcal{S}^2([0,T];\\mathbb{R}^d)$ equipped with the norm $\\|\\cdot\\|_{\\mathcal{S}^2_T}$.\n\nC. Under the same assumptions, the mapping $\\Phi$ is a strict contraction on $\\mathcal{S}^2([0,T];\\mathbb{R}^d)$ for every $T0$.\n\nD. In $\\mathcal{H}^2([0,T];\\mathbb{R}^d)$ equipped with the norm $\\|\\cdot\\|_{\\mathcal{H}^2_T}$, the mapping $\\Phi$ is a strict contraction for any $T0$ under the stated assumptions.\n\nE. Even if $\\Phi$ is not a contraction on $\\mathcal{S}^2([0,T];\\mathbb{R}^d)$ for a given $T0$, one can still construct a unique strong solution on $[0,T]$ by performing Picard iteration on a finite partition of $[0,T]$ into subintervals on which $\\Phi$ is a contraction, and then use a Gronwall estimate to propagate uniqueness across subintervals.\n\nSelect all that apply.", "solution": "The problem statement is a standard formulation of the existence and uniqueness problem for a stochastic differential equation (SDE) under global Lipschitz and linear growth conditions. All components of the problem are well-defined and standard in the theory of SDEs. The problem is scientifically grounded, well-posed, and objective. We may proceed to the solution.\n\nWe analyze each statement individually. Let $X$ and $Y$ be processes in the appropriate function spaces.\n\n### Statement A\n\n**Statement A: Under the stated assumptions, the mapping $\\Phi$ takes $\\mathcal{S}^2([0,T];\\mathbb{R}^d)$ into itself, i.e., for any $X\\in\\mathcal{S}^2([0,T];\\mathbb{R}^d)$, one has $\\Phi(X)\\in\\mathcal{S}^2([0,T];\\mathbb{R}^d)$.**\n\nLet $X \\in \\mathcal{S}^2([0,T];\\mathbb{R}^d)$. This means $X$ is an adapted, continuous process such that $\\|X\\|_{\\mathcal{S}^2_T}^2 = \\mathbb{E}[\\sup_{t\\in[0,T]}|X_t|^2]  \\infty$. We need to show that $Y = \\Phi(X)$ also satisfies $\\|Y\\|_{\\mathcal{S}^2_T}  \\infty$. The process $Y_t$ is given by:\n$$ Y_t = X_0 + \\int_0^t b(s,X_s)\\,ds + \\int_0^t \\sigma(s,X_s)\\,dW_s $$\nUsing the inequality $(a+b+c)^2 \\le 3(a^2+b^2+c^2)$, we have for any $t\\in[0,T]$:\n$$ |Y_t|^2 \\le 3|X_0|^2 + 3\\left|\\int_0^t b(s,X_s)\\,ds\\right|^2 + 3\\left|\\int_0^t \\sigma(s,X_s)\\,dW_s\\right|^2 $$\nTaking the supremum over $t \\in [0,T]$ on both sides:\n$$ \\sup_{t\\in[0,T]}|Y_t|^2 \\le 3|X_0|^2 + 3\\sup_{t\\in[0,T]}\\left|\\int_0^t b(s,X_s)\\,ds\\right|^2 + 3\\sup_{t\\in[0,T]}\\left|\\int_0^t \\sigma(s,X_s)\\,dW_s\\right|^2 $$\nTaking the expectation:\n$$ \\mathbb{E}\\left[\\sup_{t\\in[0,T]}|Y_t|^2\\right] \\le 3\\mathbb{E}[|X_0|^2] + 3\\mathbb{E}\\left[\\sup_{t\\in[0,T]}\\left|\\int_0^t b(s,X_s)\\,ds\\right|^2\\right] + 3\\mathbb{E}\\left[\\sup_{t\\in[0,T]}\\left|\\int_0^t \\sigma(s,X_s)\\,dW_s\\right|^2\\right] $$\nWe analyze each term. $\\mathbb{E}[|X_0|^2]  \\infty$ is given.\n\nFor the Lebesgue integral term, by the Cauchy-Schwarz inequality for integrals:\n$$ \\left|\\int_0^t b(s,X_s)\\,ds\\right|^2 \\le \\left(\\int_0^t |b(s,X_s)|\\,ds\\right)^2 \\le \\left(\\int_0^t 1^2\\,ds\\right)\\left(\\int_0^t |b(s,X_s)|^2\\,ds\\right) = t\\int_0^t |b(s,X_s)|^2\\,ds $$\nTherefore, $\\sup_{t\\in[0,T]}\\left|\\int_0^t b(s,X_s)\\,ds\\right|^2 \\le T\\int_0^T |b(s,X_s)|^2\\,ds$. Using the linear growth condition $|b(t,x)|^2 \\le M(1+|x|^2)$:\n$$ \\mathbb{E}\\left[\\sup_{t\\in[0,T]}\\left|\\int_0^t \\dots\\right|^2\\right] \\le T\\mathbb{E}\\left[\\int_0^T M(1+|X_s|^2)\\,ds\\right] = TM \\int_0^T(1+\\mathbb{E}[|X_s|^2])\\,ds $$\nSince $\\mathbb{E}[|X_s|^2] \\le \\mathbb{E}[\\sup_{u\\in[0,T]}|X_u|^2] = \\|X\\|_{\\mathcal{S}^2_T}^2  \\infty$, this term is finite.\n\nFor the stochastic integral term, we use the Burkholder-Davis-Gundy (BDG) inequality for $p=2$, which states there is a constant $C_20$ such that:\n$$ \\mathbb{E}\\left[\\sup_{t\\in[0,T]}\\left|\\int_0^t \\sigma(s,X_s)\\,dW_s\\right|^2\\right] \\le C_2 \\mathbb{E}\\left[\\left\\langle\\int_0^\\cdot \\sigma dW\\right\\rangle_T\\right] = C_2 \\mathbb{E}\\left[\\int_0^T \\|\\sigma(s,X_s)\\|_{\\mathrm{F}}^2\\,ds\\right] $$\nUsing the linear growth condition $\\|\\sigma(t,x)\\|_{\\mathrm{F}}^2 \\le M(1+|x|^2)$:\n$$ \\mathbb{E}\\left[\\sup_{t\\in[0,T]}\\left|\\int_0^t \\dots\\right|^2\\right] \\le C_2 M \\mathbb{E}\\left[\\int_0^T (1+|X_s|^2)\\,ds\\right] = C_2 M \\int_0^T(1+\\mathbb{E}[|X_s|^2])\\,ds  \\infty $$\nCombining the bounds, we have shown that $\\mathbb{E}[\\sup_{t\\in[0,T]}|Y_t|^2]$ is bounded by a finite quantity that depends on $\\mathbb{E}[|X_0|^2]$, $\\|X\\|_{\\mathcal{S}^2_T}$, $T$, $M$, and $C_2$. Thus, if $X \\in \\mathcal{S}^2([0,T];\\mathbb{R}^d)$, then $\\Phi(X) \\in \\mathcal{S}^2([0,T];\\mathbb{R}^d)$.\n\n**Verdict on A: Correct**\n\n### Statements B and C\n\n**Statement B: There exists a time $T^\\star0$, depending only on the Lipschitz constant $L$ (and dimension-dependent BDG constants), such that for all $T\\in(0,T^\\star)$, the mapping $\\Phi$ is a strict contraction on $\\mathcal{S}^2([0,T];\\mathbb{R}^d)$ equipped with the norm $\\|\\cdot\\|_{\\mathcal{S}^2_T}$.**\n\n**Statement C: Under the same assumptions, the mapping $\\Phi$ is a strict contraction on $\\mathcal{S}^2([0,T];\\mathbb{R}^d)$ for every $T0$.**\n\nLet $X, Y \\in \\mathcal{S}^2([0,T];\\mathbb{R}^d)$. We analyze the norm of the difference $\\Phi(X)-\\Phi(Y)$:\n$$ (\\Phi(X))_t - (\\Phi(Y))_t = \\int_0^t (b(s,X_s)-b(s,Y_s))\\,ds + \\int_0^t (\\sigma(s,X_s)-\\sigma(s,Y_s))\\,dW_s $$\nLet $\\Delta X_t = X_t-Y_t$. Using the same procedure as for statement A:\n$$ \\|\\Phi(X)-\\Phi(Y)\\|_{\\mathcal{S}^2_T}^2 = \\mathbb{E}\\left[\\sup_{t\\in[0,T]}|(\\Phi(X))_t - (\\Phi(Y))_t|^2\\right] $$\n$$ \\le 2\\mathbb{E}\\left[\\sup_{t\\in[0,T]}\\left|\\int_0^t (b(s,X_s)-b(s,Y_s))\\,ds\\right|^2\\right] + 2\\mathbb{E}\\left[\\sup_{t\\in[0,T]}\\left|\\int_0^t (\\sigma(s,X_s)-\\sigma(s,Y_s))\\,dW_s\\right|^2\\right] $$\nUsing the global Lipschitz condition $|b(t,x)-b(t,y)| + \\|\\sigma(t,x)-\\sigma(t,y)\\|_{\\mathrm{F}} \\le L|x-y|$:\nThe Lebesgue integral term is bounded as:\n$$ \\mathbb{E}\\left[\\sup_{t\\in[0,T]}\\left|\\int_0^t\\dots\\right|^2\\right] \\le T\\mathbb{E}\\left[\\int_0^T |b(s,X_s)-b(s,Y_s)|^2\\,ds\\right] \\le T L^2 \\mathbb{E}\\left[\\int_0^T |\\Delta X_s|^2\\,ds\\right] \\le T^2 L^2 \\|\\Delta X\\|_{\\mathcal{S}^2_T}^2 $$\nThe stochastic integral term is bounded using BDG:\n$$ \\mathbb{E}\\left[\\sup_{t\\in[0,T]}\\left|\\int_0^t\\dots\\right|^2\\right] \\le C_2 \\mathbb{E}\\left[\\int_0^T \\|\\sigma(s,X_s)-\\sigma(s,Y_s)\\|_{\\mathrm{F}}^2\\,ds\\right] \\le C_2 L^2 \\mathbb{E}\\left[\\int_0^T |\\Delta X_s|^2\\,ds\\right] \\le C_2 T L^2 \\|\\Delta X\\|_{\\mathcal{S}^2_T}^2 $$\nCombining these, we get:\n$$ \\|\\Phi(X)-\\Phi(Y)\\|_{\\mathcal{S}^2_T}^2 \\le (2T^2 L^2 + 2C_2 T L^2) \\|\\Delta X\\|_{\\mathcal{S}^2_T}^2 = 2L^2(T^2+C_2 T)\\|X-Y\\|_{\\mathcal{S}^2_T}^2 $$\nFor $\\Phi$ to be a strict contraction, we need the factor $K(T) = 2L^2(T^2+C_2 T)$ to be strictly less than $1$.\nThe function $K(T)$ is continuous in $T$, and $K(0)=0$. For $L0$, we can choose $T  0$ small enough such that $K(T)  1$. Specifically, we need $T^2+C_2 T  1/(2L^2)$. The positive root of $T^2+C_2 T - 1/(2L^2)=0$ defines a threshold $T^\\star$. For any $T \\in (0, T^\\star)$, $\\Phi$ is a strict contraction. This confirms statement B.\n\nHowever, as $T$ increases, $K(T)$ also increases without bound. For any $L0$, we can find a $T$ large enough such that $K(T) \\ge 1$. For example, if $T = 1/(L\\sqrt{2})$, then $T^2 = 1/(2L^2)$, so $K(T) = 2L^2(1/(2L^2) + C_2/(L\\sqrt{2}))=1+2\\sqrt{2}C_2 L  1$. Therefore, $\\Phi$ is not a strict contraction for every $T0$. This refutes statement C.\n\n**Verdict on B: Correct**\n**Verdict on C: Incorrect**\n\n### Statement D\n\n**Statement D: In $\\mathcal{H}^2([0,T];\\mathbb{R}^d)$ equipped with the norm $\\|\\cdot\\|_{\\mathcal{H}^2_T}$, the mapping $\\Phi$ is a strict contraction for any $T0$ under the stated assumptions.**\n\nFirst, one must verify that $\\Phi$ maps $\\mathcal{H}^2$ to itself. Similar calculations as in A (but integrating over $t\\in[0,T]$ and using Fubini's theorem) confirm this.\nNow, we test for contraction in the norm $\\|Z\\|_{\\mathcal{H}^2_T}^2 = \\mathbb{E}[\\int_0^T |Z_t|^2\\,dt]$. Let $\\Delta Z_t = (\\Phi(X))_t - (\\Phi(Y))_t$.\n$$ \\|\\Delta Z\\|_{\\mathcal{H}^2_T}^2 = \\mathbb{E}\\left[\\int_0^T |\\Delta Z_t|^2\\,dt\\right] \\le 2\\mathbb{E}\\left[\\int_0^T \\left|\\int_0^t \\dots_b\\right|^2 dt\\right] + 2\\mathbb{E}\\left[\\int_0^T \\left|\\int_0^t \\dots_\\sigma\\right|^2 dt\\right] $$\nwhere $\\dots_b$ and $\\dots_\\sigma$ denote the respective integrands from the difference equation.\nFor the first term, using C-S, Fubini's theorem, and the Lipschitz condition:\n$$ \\mathbb{E}\\left[\\int_0^T \\left(t\\int_0^t |b_s-b'_s|^2 ds\\right) dt\\right] \\le L^2 \\mathbb{E}\\left[\\int_0^T t\\int_0^t |\\Delta X_s|^2 ds dt\\right] = L^2 \\mathbb{E}\\left[\\int_0^T |\\Delta X_s|^2 \\left(\\int_s^T t\\,dt\\right) ds\\right] $$\n$$ = L^2 \\mathbb{E}\\left[\\int_0^T |\\Delta X_s|^2 \\frac{T^2-s^2}{2} ds\\right] \\le \\frac{L^2T^2}{2} \\mathbb{E}\\left[\\int_0^T |\\Delta X_s|^2 ds\\right] = \\frac{L^2T^2}{2} \\|X-Y\\|_{\\mathcal{H}^2_T}^2 $$\nFor the second term, using Ito's isometry, Fubini's theorem, and the Lipschitz condition:\n$$ \\mathbb{E}\\left[\\int_0^T \\left|\\int_0^t \\dots_\\sigma\\right|^2 dt\\right] = \\int_0^T \\mathbb{E}\\left[\\left|\\int_0^t \\dots_\\sigma\\right|^2\\right] dt = \\int_0^T \\mathbb{E}\\left[\\int_0^t \\|\\sigma_s-\\sigma'_s\\|_{\\mathrm{F}}^2 ds\\right] dt $$\n$$ \\le L^2 \\mathbb{E}\\left[\\int_0^T \\int_0^t |\\Delta X_s|^2 ds dt\\right] = L^2 \\mathbb{E}\\left[\\int_0^T |\\Delta X_s|^2 (T-s) ds\\right] \\le L^2 T \\|X-Y\\|_{\\mathcal{H}^2_T}^2 $$\nCombining these bounds:\n$$ \\|\\Phi(X)-\\Phi(Y)\\|_{\\mathcal{H}^2_T}^2 \\le \\left(2\\cdot\\frac{L^2T^2}{2} + 2\\cdot L^2 T\\right) \\|X-Y\\|_{\\mathcal{H}^2_T}^2 = L^2(T^2+2T) \\|X-Y\\|_{\\mathcal{H}^2_T}^2 $$\nThe contraction factor $K'(T) = L^2(T^2+2T)$ is not less than $1$ for all $T0$. Similar to the $\\mathcal{S}^2$ case, this only holds for small $T$. Therefore, statement D is false.\n\n**Verdict on D: Incorrect**\n\n### Statement E\n\n**Statement E: Even if $\\Phi$ is not a contraction on $\\mathcal{S}^2([0,T];\\mathbb{R}^d)$ for a given $T0$, one can still construct a unique strong solution on $[0,T]$ by performing Picard iteration on a finite partition of $[0,T]$ into subintervals on which $\\Phi$ is a contraction, and then use a Gronwall estimate to propagate uniqueness across subintervals.**\n\nThis statement describes the standard proof of global existence and uniqueness for SDEs with globally Lipschitz coefficients.\n1.  **Existence via Partitioning:** As established in B, for any given $L$, there exists a $T^\\star  0$ such that for any time interval of length less than $T^\\star$, the map $\\Phi$ (suitably defined on that interval) is a contraction on the corresponding space $\\mathcal{S}^2$. By the Banach fixed-point theorem, this guarantees a unique local solution. To obtain a solution on a larger interval $[0,T]$, we can partition it as $0=t_0  t_1  \\dots  t_N=T$ where $t_{k+1}-t_k  T^\\star$. A solution is constructed on $[0, t_1]$. The value $X_{t_1}$ serves as the initial condition for a new SDE on $[t_1, t_2]$, for which a solution can be constructed. This procedure is repeated or \"stitched\" together to form a solution on the entire interval $[0,T]$. This is the essence of \"performing Picard iteration on a finite partition...\".\n\n2.  **Uniqueness via Gronwall's Inequality:** To show that the constructed solution is the *unique* solution on $[0,T]$, suppose $X_t$ and $Y_t$ are two solutions. Let $\\phi(t) = \\mathbb{E}[|X_t - Y_t|^2]$. Following an argument similar to B but without suprema (and using Ito isometry instead of BDG), we find:\n    $$ \\phi(t) = \\mathbb{E}[|X_t - Y_t|^2] \\le \\mathbb{E}\\left[t\\int_0^t L^2|X_s-Y_s|^2 ds\\right] + \\mathbb{E}\\left[\\int_0^t L^2|X_s-Y_s|^2 ds\\right] $$\n    $$ \\phi(t) \\le L^2(t+1)\\int_0^t \\mathbb{E}[|X_s-Y_s|^2] ds = L^2(t+1)\\int_0^t \\phi(s) ds $$\n    Since $t \\le T$, we have $\\phi(t) \\le L^2(T+1)\\int_0^t \\phi(s) ds$. We have $\\phi(0) = \\mathbb{E}[|X_0-Y_0|^2] = 0$. By the integral form of Gronwall's inequality, this implies $\\phi(t)=0$ for all $t\\in[0,T]$, establishing uniqueness. While the statement's phrasing \"propagate uniqueness across subintervals\" is slightly informal, it correctly captures the essence of how the local existence arguments are combined with a global uniqueness proof (via Gronwall's inequality) to ensure a single, unique solution on the entire interval $[0,T]$.\n\nThe procedure described is a valid and standard method in SDE theory.\n\n**Verdict on E: Correct**", "answer": "$$\\boxed{ABE}$$", "id": "2990637"}, {"introduction": "Building on the foundational setup, this exercise delves deeper into the key analytical tools underpinning the existence and uniqueness theorem. You will explore why the Picard operator is only a contraction on a sufficiently small time interval and how the linear growth condition, combined with Gronwall's inequality, yields crucial a priori moment bounds for solutions. This practice reinforces the critical interplay between the Lipschitz and linear growth conditions in guaranteeing well-behaved solutions.", "problem": "Consider a filtered probability space $(\\Omega,\\mathcal{F},(\\mathcal{F}_{t})_{t\\in[0,T]},\\mathbb{P})$ satisfying the usual conditions and supporting an $m$-dimensional standard Brownian motion $W=(W_{t})_{t\\in[0,T]}$. Fix $d\\in\\mathbb{N}$ and consider the stochastic differential equation in integral form\n$$\nX_{t} \\;=\\; X_{0} \\;+\\; \\int_{0}^{t} b(s,X_{s})\\,ds \\;+\\; \\int_{0}^{t} \\sigma(s,X_{s})\\,dW_{s}, \\qquad t\\in[0,T],\n$$\nwhere $b:[0,T]\\times\\mathbb{R}^{d}\\to\\mathbb{R}^{d}$ and $\\sigma:[0,T]\\times\\mathbb{R}^{d}\\to\\mathbb{R}^{d\\times m}$ are Borel measurable and progressively measurable in the time variable. Assume the following global Lipschitz and linear growth conditions: there exists a constant $L0$ such that for all $t\\in[0,T]$ and $x,y\\in\\mathbb{R}^{d}$,\n$$\n\\lvert b(t,x)-b(t,y)\\rvert \\;+\\; \\lVert \\sigma(t,x)-\\sigma(t,y)\\rVert_{\\mathrm{F}} \\;\\le\\; L\\,\\lvert x-y\\rvert,\n$$\nand there exists a constant $K0$ such that for all $t\\in[0,T]$ and $x\\in\\mathbb{R}^{d}$,\n$$\n\\lvert b(t,x)\\rvert^{2} \\;+\\; \\lVert \\sigma(t,x)\\rVert_{\\mathrm{F}}^{2} \\;\\le\\; K\\big(1+\\lvert x\\rvert^{2}\\big).\n$$\nLet $X_{0}$ be $(\\mathcal{F}_{0})$-measurable with $\\mathbb{E}\\lvert X_{0}\\rvert^{2}\\infty$. Define the Picard iteration $(X^{(n)})_{n\\in\\mathbb{N}}$ by $X^{(0)}_{t}\\equiv X_{0}$ and\n$$\nX^{(n+1)}_{t} \\;=\\; X_{0} \\;+\\; \\int_{0}^{t} b\\big(s,X^{(n)}_{s}\\big)\\,ds \\;+\\; \\int_{0}^{t} \\sigma\\big(s,X^{(n)}_{s}\\big)\\,dW_{s}, \\qquad t\\in[0,T].\n$$\nConsider the mapping $\\Phi$ acting on progressively measurable processes with finite norm\n$$\n\\Vert X\\Vert \\;:=\\; \\Big(\\mathbb{E}\\,\\sup_{0\\le t\\le T} \\lvert X_{t}\\rvert^{2}\\Big)^{1/2},\n$$\ndefined by\n$$\n\\big(\\Phi(X)\\big)_{t} \\;:=\\; X_{0} \\;+\\; \\int_{0}^{t} b(s,X_{s})\\,ds \\;+\\; \\int_{0}^{t} \\sigma(s,X_{s})\\,dW_{s}.\n$$\nUsing only foundational tools such as the integral form of the stochastic differential equation, Itô's isometry for stochastic integrals, the Burkholder–Davis–Gundy (BDG) inequality, and Gronwall's inequality, determine which of the following statements are true. Select all that apply.\n\nA. For any $T0$, the mapping $\\Phi$ is a contraction in the norm $\\Vert\\cdot\\Vert$ on the space of progressively measurable processes, and hence the Picard iteration converges in $\\Vert\\cdot\\Vert$ to a unique fixed point on $[0,T]$.\n\nB. There exists $T^{\\ast}0$, depending only on $L$ and universal constants, such that for all $T\\in(0,T^{\\ast})$, the mapping $\\Phi$ is a contraction in the norm $\\Vert\\cdot\\Vert$, so the Picard iteration converges in $\\Vert\\cdot\\Vert$ to a unique fixed point on $[0,T]$.\n\nC. Under the stated global Lipschitz and linear growth conditions and $\\mathbb{E}\\lvert X_{0}\\rvert^{2}\\infty$, there exists a constant $C(T)$ depending on $L$, $K$, and $T$ such that any solution $X$ satisfies the moment bound $\\mathbb{E}\\,\\sup_{0\\le t\\le T} \\lvert X_{t}\\rvert^{2} \\le C(T)\\,\\big(1+\\mathbb{E}\\lvert X_{0}\\rvert^{2}\\big)$.\n\nD. If $b$ and $\\sigma$ are locally Lipschitz in the spatial variable and satisfy the linear growth condition, then pathwise uniqueness holds on $[0,T]$ for nonexplosive solutions.\n\nE. If $b$ and $\\sigma$ are merely measurable and satisfy the linear growth condition (but not any Lipschitz condition), then the Picard iteration $(X^{(n)})_{n\\in\\mathbb{N}}$ still converges in the norm $\\Vert\\cdot\\Vert$ to a solution on any $[0,T]$.", "solution": "The problem statement presents a classical setup for a stochastic differential equation (SDE) under global Lipschitz and linear growth conditions. The core of the problem is to evaluate several standard theoretical results concerning the existence, uniqueness, and properties of solutions to such an SDE, particularly in the context of Picard iteration. The problem is well-posed and scientifically sound, based on foundational principles of stochastic calculus. We shall proceed to analyze each statement using the prescribed tools.\n\nLet $X$ and $Y$ be two progressively measurable processes belonging to the space $\\mathcal{S}_T := \\{ Z \\text{ progressively measurable} : \\Vert Z \\Vert^2 = \\mathbb{E} \\sup_{0 \\le t \\le T} \\lvert Z_t \\rvert^2  \\infty \\}$. This space, equipped with the norm $\\Vert\\cdot\\Vert$, is a Banach space. The mapping $\\Phi$ is defined as:\n$$\n(\\Phi(Z))_t = X_0 + \\int_0^t b(s, Z_s) ds + \\int_0^t \\sigma(s, Z_s) dW_s.\n$$\nA solution to the SDE is a fixed point of $\\Phi$.\n\nFirst, let us estimate the distance between $\\Phi(X)$ and $\\Phi(Y)$ in the norm $\\Vert\\cdot\\Vert$:\n$$\n(\\Phi(X))_t - (\\Phi(Y))_t = \\int_0^t (b(s,X_s) - b(s,Y_s)) ds + \\int_0^t (\\sigma(s,X_s) - \\sigma(s,Y_s)) dW_s.\n$$\nUsing the inequality $(a+b)^2 \\le 2a^2 + 2b^2$, we have for any $t \\in [0,T]$:\n$$\n\\lvert (\\Phi(X))_t - (\\Phi(Y))_t \\rvert^2 \\le 2 \\left\\lvert \\int_0^t (b(s,X_s) - b(s,Y_s)) ds \\right\\rvert^2 + 2 \\left\\lvert \\int_0^t (\\sigma(s,X_s) - \\sigma(s,Y_s)) dW_s \\right\\rvert^2.\n$$\nTaking the supremum over $t \\in [0,T]$ and then the expectation:\n$$\n\\Vert \\Phi(X) - \\Phi(Y) \\Vert^2 \\le 2 \\mathbb{E} \\sup_{0 \\le t \\le T} \\left\\lvert \\int_0^t (b(s,X_s) - b(s,Y_s)) ds \\right\\rvert^2 + 2 \\mathbb{E} \\sup_{0 \\le t \\le T} \\left\\lvert \\int_0^t (\\sigma(s,X_s) - \\sigma(s,Y_s)) dW_s \\right\\rvert^2.\n$$\nFor the drift term, using the Cauchy-Schwarz inequality:\n$$\n\\sup_{0 \\le t \\le T} \\left\\lvert \\int_0^t \\dots ds \\right\\rvert^2 \\le \\sup_{0 \\le t \\le T} \\left( t \\int_0^t \\lvert b(s,X_s) - b(s,Y_s) \\rvert^2 ds \\right) \\le T \\int_0^T L^2 \\lvert X_s - Y_s \\rvert^2 ds.\n$$\nTaking expectation, we get $T L^2 \\int_0^T \\mathbb{E} \\lvert X_s - Y_s \\rvert^2 ds \\le T L^2 \\int_0^T \\Vert X-Y \\Vert^2 ds = T^2 L^2 \\Vert X-Y \\Vert^2$.\n\nFor the diffusion term, using the Burkholder-Davis-Gundy (BDG) inequality, there exists a universal constant $C_{BDG}  0$ such that:\n$$\n\\mathbb{E} \\sup_{0 \\le t \\le T} \\left\\lvert \\int_0^t \\dots dW_s \\right\\rvert^2 \\le C_{BDG} \\mathbb{E} \\int_0^T \\lVert \\sigma(s,X_s) - \\sigma(s,Y_s) \\rVert_{\\mathrm{F}}^2 ds.\n$$\nUsing the Lipschitz condition, this is bounded by $C_{BDG} L^2 \\mathbb{E} \\int_0^T \\lvert X_s - Y_s \\rvert^2 ds \\le C_{BDG} L^2 T \\Vert X-Y \\Vert^2$.\n\nCombining these bounds, we get:\n$$\n\\Vert \\Phi(X) - \\Phi(Y) \\Vert^2 \\le 2(T^2 L^2 + C_{BDG} T L^2) \\Vert X-Y \\Vert^2 = 2 L^2 (T^2 + C_{BDG} T) \\Vert X-Y \\Vert^2.\n$$\nThe mapping $\\Phi$ is a contraction if $2 L^2 (T^2 + C_{BDG} T)  1$.\n\n**Analysis of Option A:**\nThe statement claims that for any $T  0$, $\\Phi$ is a contraction. The condition for contraction is $2 L^2 (T^2 + C_{BDG} T)  1$. The term $2 L^2 (T^2 + C_{BDG} T)$ is a strictly increasing function of $T$ for $T0$. For any given $L0$, one can choose $T$ large enough to violate this condition. For instance, if $T  1/(\\sqrt{2}L)$, then $T^2  1/(2L^2)$, so $2L^2T^2  1$, making the contraction condition false. Therefore, $\\Phi$ is not a contraction for all $T0$. The convergence of Picard iterations on arbitrary intervals $[0,T]$ is typically proven by showing that some power $\\Phi^k$ of the map is a contraction, or by using a weighted norm, not by $\\Phi$ itself being a contraction.\nVerdict: **Incorrect**.\n\n**Analysis of Option B:**\nThe statement claims there exists a small enough time horizon $T^*  0$ for which $\\Phi$ is a contraction. Let $f(T) = 2 L^2 (T^2 + C_{BDG} T)$. We have $f(T) \\to 0$ as $T \\to 0^+$. Since $f(T)$ is continuous and increasing for $T0$, there must exist some $T^*  0$ such that for all $T \\in (0, T^*)$, we have $f(T)  1$. This $T^*$ depends on $L$ and the universal constant $C_{BDG}$. For such a $T$, $\\Phi$ is a contraction mapping on the Banach space $\\mathcal{S}_T$. By the Banach fixed-point theorem, $\\Phi$ has a unique fixed point, and the Picard iteration $X^{(n+1)} = \\Phi(X^{(n)})$ converges to this fixed point in the norm $\\Vert\\cdot\\Vert$.\nVerdict: **Correct**.\n\n**Analysis of Option C:**\nThis statement concerns an a priori moment bound for any solution $X$. We start from the integral form of the SDE:\n$$\nX_t = X_0 + \\int_0^t b(s,X_s) ds + \\int_0^t \\sigma(s,X_s) dW_s.\n$$\nUsing $(a+b+c)^2 \\le 3(a^2+b^2+c^2)$, we bound $\\sup_{0 \\le t \\le u} \\lvert X_t \\rvert^2$ for any $u \\in [0,T]$:\n$$\n\\mathbb{E} \\sup_{0 \\le t \\le u} \\lvert X_t \\rvert^2 \\le 3 \\mathbb{E}\\lvert X_0 \\rvert^2 + 3 \\mathbb{E} \\sup_{0 \\le t \\le u} \\left\\lvert \\int_0^t b(s,X_s) ds \\right\\rvert^2 + 3 \\mathbb{E} \\sup_{0 \\le t \\le u} \\left\\lvert \\int_0^t \\sigma(s,X_s) dW_s \\right\\rvert^2.\n$$\nUsing Cauchy-Schwarz, BDG, and the linear growth condition $\\lvert b(t,x)\\rvert^2 + \\lVert\\sigma(t,x)\\rVert_{\\mathrm{F}}^2 \\le K(1+\\lvert x\\rvert^2)$:\n$$\n\\mathbb{E} \\sup_{0 \\le t \\le u} \\left\\lvert \\dots \\right\\rvert^2 \\le 3 \\mathbb{E}\\lvert X_0 \\rvert^2 + 3 T \\mathbb{E}\\int_0^u \\lvert b(s,X_s) \\rvert^2 ds + 3 C_{BDG} \\mathbb{E}\\int_0^u \\lVert \\sigma(s,X_s) \\rVert_{\\mathrm{F}}^2 ds.\n$$\n$$\n\\le 3 \\mathbb{E}\\lvert X_0 \\rvert^2 + 3(T K + C_{BDG} K) \\int_0^u \\mathbb{E}(1+\\lvert X_s \\rvert^2) ds.\n$$\nLet $\\psi(u) = \\mathbb{E} \\sup_{0 \\le t \\le u} \\lvert X_t \\rvert^2$. Since $\\mathbb{E}\\lvert X_s \\rvert^2 \\le \\psi(s)$, we get for $u \\in [0,T]$:\n$$\n\\psi(u) \\le 3 \\mathbb{E}\\lvert X_0 \\rvert^2 + 3K(T+C_{BDG}) \\int_0^u (1+\\psi(s)) ds.\n$$\nLet $A = 3\\mathbb{E}\\lvert X_0 \\rvert^2$ and $C' = 3K(T+C_{BDG})$. The inequality is $\\psi(u) \\le A + C'u + C'\\int_0^u \\psi(s)ds$.\nBy the integral form of Gronwall's inequality, we have $\\psi(u) \\le (A+C'u) + \\int_0^u C'(A+C's) e^{C'(u-s)} ds$. A simpler argument is to let $g(u) = A+C'u + C' \\int_0^u \\psi(s)ds$, so $\\psi(u) \\le g(u)$. Then $g'(u) = C' + C'\\psi(u) \\le C' + C'g(u)$. Solving this differential inequality leads to a bound for $g(u)$, and thus $\\psi(u)$.\nThe bound will be of the form $\\psi(T) \\le C(T)(1+\\mathbb{E}|X_0|^2)$ for a constant $C(T)$ depending on $K$ and $T$. The statement indicates a dependency on $L$, $K$, and $T$, which is not contradictory as a function of $K$ and $T$ is trivially also a function of $L$, $K$, and $T$.\nVerdict: **Correct**.\n\n**Analysis of Option D:**\nThe statement concerns pathwise uniqueness under local Lipschitz and linear growth conditions. Let $X$ and $Y$ be two nonexplosive solutions with the same initial condition $X_0 = Y_0$. Let $D_t = X_t - Y_t$. For any integer $R  0$, define the stopping time $\\tau_R = \\inf\\{t \\in [0,T] : \\lvert X_t \\rvert \\ge R \\text{ or } \\lvert Y_t \\rvert \\ge R \\}$, with $\\inf \\emptyset = T$. Since solutions are nonexplosive, $\\tau_R \\to T$ almost surely as $R \\to \\infty$.\nFor $t \\in [0,T]$, consider the stopped process difference $D_{t \\wedge \\tau_R}$.\n$$\nD_{t \\wedge \\tau_R} = \\int_0^{t \\wedge \\tau_R} (b(s,X_s) - b(s,Y_s)) ds + \\int_0^{t \\wedge \\tau_R} (\\sigma(s,X_s) - \\sigma(s,Y_s)) dW_s.\n$$\nFor any $s \\le t \\wedge \\tau_R$, we have $\\lvert X_s \\rvert  R$ and $\\lvert Y_s \\rvert  R$. By the local Lipschitz condition, there is a constant $L_R$ such that $\\lvert b(s,X_s) - b(s,Y_s) \\rvert + \\lVert \\sigma(s,X_s) - \\sigma(s,Y_s) \\rVert_{\\mathrm{F}} \\le L_R \\lvert D_s \\rvert$.\nLet $f(t) = \\mathbb{E} \\lvert D_{t \\wedge \\tau_R} \\rvert^2$. Using Itô's isometry and Cauchy-Schwarz:\n$$\nf(t) = \\mathbb{E} \\left\\lvert \\int_0^t \\mathbb{1}_{s \\le \\tau_R} (b(s,X_s) - \\dots) ds \\right\\rvert^2 + \\mathbb{E} \\left\\lvert \\int_0^t \\mathbb{1}_{s \\le \\tau_R} (\\sigma(s,X_s) - \\dots) dW_s \\right\\rvert^2\n$$\n$$\nf(t) \\le T \\mathbb{E} \\int_0^t \\mathbb{1}_{s \\le \\tau_R} L_R^2 \\lvert D_s \\rvert^2 ds + \\mathbb{E} \\int_0^t \\mathbb{1}_{s \\le \\tau_R} L_R^2 \\lvert D_s \\rvert^2 ds\n$$\n$$\nf(t) \\le (T+1)L_R^2 \\int_0^t \\mathbb{E}\\lvert D_{s \\wedge \\tau_R} \\rvert^2 ds = (T+1)L_R^2 \\int_0^t f(s) ds.\n$$\nSince $f(0) = \\mathbb{E}\\lvert D_0 \\rvert^2 = 0$, Gronwall's inequality implies $f(t) = 0$ for all $t \\in [0,T]$.\nThis means $X_{t \\wedge \\tau_R} = Y_{t \\wedge \\tau_R}$ almost surely for all $t$. As this holds for any $R$, and $\\tau_R \\to T$ a.s., we conclude that $X_t = Y_t$ almost surely for all $t \\in [0,T]$. The linear growth condition ensures solutions are nonexplosive, so the premise of the statement is consistent.\nVerdict: **Correct**.\n\n**Analysis of Option E:**\nThis statement claims that Picard iteration converges even without a Lipschitz condition, provided linear growth holds. This is false. The Lipschitz condition is fundamental to the proof of convergence, as it ensures that the operator $\\Phi$ is a contraction on a small interval (or that one of its powers is). Without any modulus of continuity condition on the coefficients, the Picard sequence is not guaranteed to be a Cauchy sequence.\nConsider the deterministic ordinary differential equation $\\frac{dx}{dt} = \\sqrt{\\lvert x \\rvert}$ with $x(0)=0$, which can be viewed as an SDE with $\\sigma=0$. The coefficient $b(x)=\\sqrt{\\lvert x \\rvert}$ is not Lipschitz at $0$ but satisfies a linear growth condition. The Picard iteration starts with $X^{(0)}_t = 0$. Then $X^{(1)}_t = \\int_0^t b(X^{(0)}_s) ds = 0$, and so on. The sequence converges to the trivial solution $X_t=0$. However, $X_t = t^2/4$ is another solution. The iteration fails to find this solution. More critically, the iteration is not guaranteed to converge at all in general cases. For instance, for the SDE $dX_t=\\text{sgn}(X_t)dW_t$ (with $\\text{sgn}(0)=1$), the Picard sequence does not converge. Therefore, the statement is false.\nVerdict: **Incorrect**.", "answer": "$$\\boxed{BCD}$$", "id": "2990634"}, {"introduction": "To solidify the abstract concepts, this final practice asks you to work with a concrete linear SDE, a cornerstone model in stochastic analysis. You will apply the Picard iteration method to this specific example, derive bounds on the iterates, and then compare your results with the exact solution's moments obtained via Itô's formula. This exercise provides an invaluable link between the general theory and explicit, hands-on computation.", "problem": "Let $(\\Omega,\\mathcal{F},(\\mathcal{F}_t)_{t \\ge 0},\\mathbb{P})$ be a filtered probability space supporting a one-dimensional standard Brownian motion $W=(W_t)_{t \\ge 0}$. Consider the linear stochastic differential equation (SDE)\n$$\ndX_t \\;=\\; \\alpha \\, X_t \\, dt \\;+\\; \\beta \\, X_t \\, dW_t, \n\\qquad X_0 \\;=\\; x_0,\n$$\nwhere $\\alpha,\\beta \\in \\mathbb{R}$ are fixed constants and $x_0 \\in \\mathbb{R}$ is deterministic. Define the Picard iteration $(X^{(n)})_{n \\ge 0}$ by\n$$\nX^{(0)}_t \\;=\\; x_0,\n\\qquad\nX^{(n+1)}_t \\;=\\; x_0 \\;+\\; \\int_{0}^{t} \\alpha \\, X^{(n)}_s \\, ds \\;+\\; \\int_{0}^{t} \\beta \\, X^{(n)}_s \\, dW_s,\n\\quad n \\ge 0.\n$$\nUsing only the defining properties of the Itô integral, the Itô isometry for square-integrable martingales, and the deterministic Gronwall inequality, carry out the following steps for a fixed but arbitrary finite horizon $T0$:\n- Establish that each Picard iterate $X^{(n)}$ is well-defined, adapted, and square-integrable, and derive an explicit bound of the form\n$$\n\\mathbb{E}\\big[|X^{(n)}_t|^{2}\\big] \\;\\le\\; A \\, \\exp\\!\\big(B\\,t\\big)\n\\quad \\text{for all } t \\in [0,T],\n$$\nfor some constants $A,B0$ depending only on $\\alpha,\\beta,x_0$, and $T$. Provide explicit choices of $A$ and $B$ that you can justify by your estimates.\n- Using your bounds and a contraction argument on sufficiently small time intervals, argue that the Picard iteration converges (hence the SDE has a unique solution) in the space $L^{2}\\big([0,T] \\times \\Omega\\big)$.\n\nThen, for the limiting solution $X$, compute $\\mathbb{E}\\big[|X_t|^{2}\\big]$ exactly for each $t \\ge 0$ and determine the smallest constant $C \\in \\mathbb{R}$ such that\n$$\n\\mathbb{E}\\big[|X_t|^{2}\\big] \\;\\le\\; |x_0|^{2} \\, \\exp\\!\\big(C\\,t\\big)\n\\quad \\text{for all } t \\ge 0.\n$$\nReport the value of $C$ as a closed-form analytic expression.", "solution": "This problem asks us to analyze the Picard iteration for a linear SDE, establish uniform bounds, argue for convergence, and then find an exact expression for the second moment of the solution.\n\n#### Uniform Bound on Picard Iterates\n\nWe want to find positive constants $A$ and $B$ such that $\\mathbb{E}[|X^{(n)}_t|^2] \\le A e^{Bt}$ for all $n \\ge 0$ and $t \\in [0,T]$. Let $\\phi_n(t) = \\mathbb{E}[|X^{(n)}_t|^2]$.\nFor $n=0$, $\\phi_0(t) = \\mathbb{E}[|x_0|^2] = |x_0|^2$, which is constant and thus bounded.\n\nFor $n \\ge 0$, we have\n$$\nX^{(n+1)}_t = x_0 + \\int_0^t \\alpha X^{(n)}_s ds + \\int_0^t \\beta X^{(n)}_s dW_s.\n$$\nUsing the inequality $(a+b+c)^2 \\le 3(a^2+b^2+c^2)$, we get\n$$\n|X^{(n+1)}_t|^2 \\le 3|x_0|^2 + 3\\left(\\int_0^t \\alpha X^{(n)}_s ds\\right)^2 + 3\\left(\\int_0^t \\beta X^{(n)}_s dW_s\\right)^2.\n$$\nTaking expectations and applying the Cauchy-Schwarz inequality to the drift integral and Itô isometry to the stochastic integral:\n\\begin{align*}\n\\phi_{n+1}(t)  \\le 3|x_0|^2 + 3\\alpha^2 \\mathbb{E}\\left[\\left(\\int_0^t X^{(n)}_s ds\\right)^2\\right] + 3\\beta^2 \\mathbb{E}\\left[\\left(\\int_0^t X^{(n)}_s dW_s\\right)^2\\right] \\\\\n \\le 3|x_0|^2 + 3\\alpha^2 \\mathbb{E}\\left[\\left(\\int_0^t 1^2 ds\\right)\\left(\\int_0^t |X^{(n)}_s|^2 ds\\right)\\right] + 3\\beta^2 \\mathbb{E}\\left[\\int_0^t |X^{(n)}_s|^2 ds\\right] \\\\\n \\le 3|x_0|^2 + 3\\alpha^2 t \\int_0^t \\phi_n(s) ds + 3\\beta^2 \\int_0^t \\phi_n(s) ds \\\\\n \\le 3|x_0|^2 + (3\\alpha^2 T + 3\\beta^2) \\int_0^t \\phi_n(s) ds.\n\\end{align*}\nLet's choose $A = 3|x_0|^2$ and $B = 3\\alpha^2 T + 3\\beta^2$. To ensure $A, B > 0$ as requested, we can handle the trivial cases. If $x_0=0$, $\\alpha=0, \\beta=0$, then $X_t \\equiv 0$, and any $A,B>0$ work. Assume a non-trivial case. We can choose $A = 3|x_0|^2+1$ and $B = 3\\alpha^2 T + 3\\beta^2+1$.\n\nWe prove $\\phi_n(t) \\le A e^{Bt}$ by induction.\nBase case $n=0$: $\\phi_0(t) = |x_0|^2 \\le 3|x_0|^2+1 \\le A e^{Bt}$, since $A,B>0$.\nInductive step: Assume $\\phi_n(t) \\le A e^{Bt}$. Then\n$$\n\\phi_{n+1}(t) \\le (A-1) + (B-1) \\int_0^t \\phi_n(s) ds \\le A-1 + (B-1) \\int_0^t A e^{Bs} ds = A-1 + A\\frac{B-1}{B}(e^{Bt}-1).\n$$\nWe need to show $A-1 + A\\frac{B-1}{B}(e^{Bt}-1) \\le A e^{Bt}$.\n$$\nA-1 \\le A e^{Bt} - A\\frac{B-1}{B}e^{Bt} + A\\frac{B-1}{B} = \\frac{A}{B}e^{Bt} + A - \\frac{A}{B}.\n$$\nThis simplifies to $-1 \\le \\frac{A}{B}(e^{Bt}-1)$, which is true since $A,B>0$ and $e^{Bt} \\ge 1$.\nThus, we have found suitable constants $A = 3|x_0|^2+1$ and $B=3\\alpha^2T+3\\beta^2+1$.\n\n#### Convergence Argument\n\nThe SDE has a unique solution if the Picard operator $\\Phi$ defined by\n$$\n(\\Phi(Y))_t = x_0 + \\int_0^t \\alpha Y_s ds + \\int_0^t \\beta Y_s dW_s\n$$\nis a contraction on a suitable Banach space. We consider the space $L^2([0,\\tau]\\times\\Omega)$ for some $\\tau \\in (0,T]$, with norm $\\|Y\\|^2_{L^2} = \\mathbb{E}[\\int_0^\\tau |Y_s|^2 ds]$.\nLet $Y,Z$ be in this space.\n$$\n(\\Phi(Y))_t - (\\Phi(Z))_t = \\int_0^t \\alpha(Y_s - Z_s)ds + \\int_0^t \\beta(Y_s-Z_s)dW_s.\n$$\nTaking the $L^2$ norm of the difference:\n\\begin{align*}\n\\|\\Phi(Y) - \\Phi(Z)\\|^2_{L^2} = \\mathbb{E}\\left[\\int_0^\\tau |(\\Phi(Y))_t - (\\Phi(Z))_t|^2 dt\\right] \\\\\n\\le 2\\mathbb{E}\\left[\\int_0^\\tau \\alpha^2 \\left(\\int_0^t (Y_s - Z_s)ds\\right)^2 dt\\right] + 2\\mathbb{E}\\left[\\int_0^\\tau \\left(\\int_0^t \\beta(Y_s - Z_s)dW_s\\right)^2 dt\\right].\n\\end{align*}\nUsing Cauchy-Schwarz on the first term and Itô isometry on the second:\n$$\n\\le 2\\alpha^2 \\mathbb{E}\\left[\\int_0^\\tau t \\int_0^t |Y_s-Z_s|^2 ds dt\\right] + 2\\beta^2 \\mathbb{E}\\left[\\int_0^\\tau \\int_0^t |Y_s-Z_s|^2 ds dt\\right].\n$$\nUsing Fubini's theorem:\n$$\n\\le 2\\alpha^2 \\int_0^\\tau \\mathbb{E}[|Y_s-Z_s|^2] \\left(\\int_s^\\tau t dt\\right) ds + 2\\beta^2 \\int_0^\\tau \\mathbb{E}[|Y_s-Z_s|^2] (\\tau-s) ds\n$$\n$$\n\\le 2\\alpha^2 \\int_0^\\tau \\mathbb{E}[|Y_s-Z_s|^2] \\frac{\\tau^2-s^2}{2} ds + 2\\beta^2 \\tau \\int_0^\\tau \\mathbb{E}[|Y_s-Z_s|^2] ds\n$$\n$$\n\\le \\left(\\alpha^2 \\tau^2 + 2\\beta^2 \\tau\\right) \\mathbb{E}\\left[\\int_0^\\tau |Y_s-Z_s|^2 ds\\right] = (\\alpha^2 \\tau^2 + 2\\beta^2 \\tau) \\|Y-Z\\|^2_{L^2}.\n$$\nThe factor $K(\\tau) = \\alpha^2 \\tau^2 + 2\\beta^2 \\tau$ goes to $0$ as $\\tau \\to 0$. We can choose $\\tau > 0$ small enough such that $K(\\tau)  1$. Then $\\Phi$ is a contraction on $L^2([0,\\tau]\\times\\Omega)$. By the Banach fixed-point theorem, a unique solution exists on $[0, \\tau]$. This local solution can be extended to the full interval $[0,T]$ by partitioning $[0,T]$ into subintervals of length less than $\\tau$ and repeatedly applying the argument.\n\n#### Exact Second Moment and the Constant $C$\n\nTo find the exact second moment, we apply Itô's formula to the process $f(X_t) = X_t^2$.\nWe have $f'(x) = 2x$ and $f''(x) = 2$.\n$$\ndX_t^2 = f'(X_t)dX_t + \\frac{1}{2}f''(X_t)(dX_t)^2.\n$$\nThe quadratic variation is $(dX_t)^2 = (\\beta X_t dW_t)^2 = \\beta^2 X_t^2 dt$.\nSo,\n$$\ndX_t^2 = 2X_t(\\alpha X_t dt + \\beta X_t dW_t) + \\frac{1}{2}(2)(\\beta^2 X_t^2 dt)\n$$\n$$\ndX_t^2 = (2\\alpha X_t^2 + \\beta^2 X_t^2)dt + 2\\beta X_t^2 dW_t = (2\\alpha + \\beta^2)X_t^2 dt + 2\\beta X_t^2 dW_t.\n$$\nIntegrating from $0$ to $t$:\n$$\nX_t^2 = x_0^2 + (2\\alpha + \\beta^2)\\int_0^t X_s^2 ds + 2\\beta \\int_0^t X_s^2 dW_s.\n$$\nNow, take the expectation. The Itô integral term has zero expectation, provided $\\mathbb{E}[\\int_0^t (2\\beta X_s^2)^2 ds]  \\infty$, which holds under our uniform bounds.\nLet $m(t) = \\mathbb{E}[X_t^2]$. Then\n$$\nm(t) = x_0^2 + (2\\alpha + \\beta^2)\\int_0^t m(s)ds.\n$$\nThis is a linear ordinary differential equation in integral form. Differentiating with respect to $t$ gives:\n$$\nm'(t) = (2\\alpha + \\beta^2)m(t), \\quad \\text{with initial condition } m(0) = x_0^2.\n$$\nThe solution is\n$$\nm(t) = \\mathbb{E}[|X_t|^2] = |x_0|^2 \\exp\\big((2\\alpha + \\beta^2)t\\big).\n$$\nWe want to find the smallest constant $C$ such that $\\mathbb{E}[|X_t|^2] \\le |x_0|^2 \\exp(Ct)$ for all $t \\ge 0$. From the exact solution, we see that this inequality holds with equality if we choose $C = 2\\alpha + \\beta^2$. Any smaller value of $C$ would violate the inequality for large $t$.\nTherefore, the smallest such constant is $C = 2\\alpha + \\beta^2$.", "answer": "$$\n\\boxed{2\\alpha + \\beta^{2}}\n$$", "id": "2990636"}]}