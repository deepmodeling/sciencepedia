{"hands_on_practices": [{"introduction": "The primary function of the universal property is to transform bilinear maps into more manageable linear ones. This exercise [@problem_id:1562106] provides a direct and tangible application, demonstrating how a specific bilinear map defined on a space of polynomials is uniquely represented as a linear functional on the corresponding tensor product space. By working through this concrete example, you will translate the abstract definition of the universal property into a practical computational tool.", "problem": "Let $P_1[x]$ be the real vector space of polynomials with real coefficients of degree at most one. A general element in this space has the form $p(x) = ax+b$. Consider the bilinear map $B: P_1[x] \\times P_1[x] \\to \\mathbb{R}$ defined by $B(ax+b, cx+d) = ad-bc$. The universal property of the tensor product ensures that this bilinear map induces a unique linear functional $L: P_1[x] \\otimes P_1[x] \\to \\mathbb{R}$ satisfying $L(p \\otimes q) = B(p, q)$ for all $p, q \\in P_1[x]$.\n\nA general element $T$ in the tensor product space $P_1[x] \\otimes P_1[x]$ can be uniquely written in terms of the basis $\\{1 \\otimes 1, 1 \\otimes x, x \\otimes 1, x \\otimes x\\}$ as:\n$$T = c_{00}(1 \\otimes 1) + c_{01}(1 \\otimes x) + c_{10}(x \\otimes 1) + c_{11}(x \\otimes x)$$\nwhere $c_{00}, c_{01}, c_{10}, c_{11}$ are real coefficients.\n\nFind the expression for $L(T)$ in terms of these coefficients.", "solution": "We use the linear functional $L: P_{1}[x] \\otimes P_{1}[x] \\to \\mathbb{R}$ determined by the universal property of the tensor product via $L(p \\otimes q) = B(p,q)$, where $B(ax+b, cx+d) = ad - bc$. The polynomials $1$ and $x$ correspond to coefficient pairs $(a,b)=(0,1)$ and $(1,0)$, respectively.\n\nEvaluate $L$ on the basis tensors using $L(p \\otimes q)=B(p,q)$:\n$$L(1 \\otimes 1)=B(1,1)=0 \\cdot 1 - 1 \\cdot 0=0,$$\n$$L(1 \\otimes x)=B(1,x)=0 \\cdot 0 - 1 \\cdot 1=-1,$$\n$$L(x \\otimes 1)=B(x,1)=1 \\cdot 1 - 0 \\cdot 0=1,$$\n$$L(x \\otimes x)=B(x,x)=1 \\cdot 0 - 0 \\cdot 1=0.$$\n\nBy linearity of $L$,\n$$L(T)=c_{00}L(1 \\otimes 1)+c_{01}L(1 \\otimes x)+c_{10}L(x \\otimes 1)+c_{11}L(x \\otimes x)=0 \\cdot c_{00}+(-1)c_{01}+1 \\cdot c_{10}+0 \\cdot c_{11}=c_{10}-c_{01}.$$", "answer": "$$\\boxed{c_{10}-c_{01}}$$", "id": "1562106"}, {"introduction": "Beyond simple computation, the universal property is a powerful tool for exploring and defining the inherent structure of tensor product spaces. This practice [@problem_id:1562102] invites you to use the universal property to construct a fundamental linear map—the antisymmetrizer—and then to characterize its kernel. This process reveals a deep connection between bilinearity and the decomposition of $A \\otimes A$ into its symmetric and antisymmetric subspaces, a cornerstone concept in fields like differential geometry and representation theory.", "problem": "Let $A$ be a real vector space of dimension $n \\geq 2$. The tensor product space $A \\otimes A$ is itself a real vector space. Consider the bilinear map $B: A \\times A \\to A \\otimes A$ defined by the relation $B(v_1, v_2) = v_1 \\otimes v_2 - v_2 \\otimes v_1$ for all vectors $v_1, v_2 \\in A$.\n\nAccording to the universal property of the tensor product, there exists a unique linear map $\\Phi: A \\otimes A \\to A \\otimes A$ such that for any pure tensor $v_1 \\otimes v_2 \\in A \\otimes A$, its image under $\\Phi$ is given by $\\Phi(v_1 \\otimes v_2) = B(v_1, v_2)$.\n\nLet the swap map $\\tau: A \\otimes A \\to A \\otimes A$ be the unique linear map defined by its action on pure tensors as $\\tau(v_1 \\otimes v_2) = v_2 \\otimes v_1$. We define two important subspaces of $A \\otimes A$:\n1.  The space of symmetric tensors of rank 2, denoted $S^2(A)$, which is the set of all tensors $T \\in A \\otimes A$ such that $\\tau(T) = T$.\n2.  The space of antisymmetric tensors of rank 2, denoted $\\Lambda^2(A)$, which is the set of all tensors $T \\in A \\otimes A$ such that $\\tau(T) = -T$.\n\nWhich of the following subspaces of $A \\otimes A$ correctly describes the kernel of the linear map $\\Phi$?\n\nA. The space of symmetric tensors, $S^2(A)$.\n\nB. The space of antisymmetric tensors, $\\Lambda^2(A)$.\n\nC. The intersection of the symmetric and antisymmetric subspaces, $S^2(A) \\cap \\Lambda^2(A)$.\n\nD. The entire tensor product space, $A \\otimes A$.", "solution": "By the universal property of the tensor product, the bilinear map $B(v_{1},v_{2})=v_{1}\\otimes v_{2}-v_{2}\\otimes v_{1}$ induces a unique linear map $\\Phi: A\\otimes A \\to A\\otimes A$ satisfying, for all pure tensors,\n$$\n\\Phi(v_{1}\\otimes v_{2})=v_{1}\\otimes v_{2}-v_{2}\\otimes v_{1}.\n$$\nLet $\\tau: A\\otimes A \\to A\\otimes A$ be the swap map defined by $\\tau(v_{1}\\otimes v_{2})=v_{2}\\otimes v_{1}$. Since pure tensors span $A\\otimes A$ and both sides are linear, it follows that for all $T\\in A\\otimes A$,\n$$\n\\Phi(T)=(\\operatorname{id}_{A\\otimes A}-\\tau)(T).\n$$\n\nWe compute the kernel of $\\Phi$:\n$$\n\\ker(\\Phi)=\\{T\\in A\\otimes A : \\Phi(T)=0\\}=\\{T\\in A\\otimes A : (\\operatorname{id}_{A\\otimes A}-\\tau)(T)=0\\}.\n$$\nThe condition $(\\operatorname{id}_{A\\otimes A}-\\tau)(T)=0$ is equivalent to $\\tau(T)=T$. By definition, this is precisely the condition that $T$ is symmetric, i.e.,\n$$\n\\ker(\\Phi)=\\{T\\in A\\otimes A : \\tau(T)=T\\}=S^{2}(A).\n$$\n\nFor completeness, note that $\\tau$ is an involution, $\\tau^{2}=\\operatorname{id}_{A\\otimes A}$, so $A\\otimes A$ decomposes into the direct sum of the $+1$ and $-1$ eigenspaces of $\\tau$, namely $S^{2}(A)$ and $\\Lambda^{2}(A)$, respectively. The kernel of $\\operatorname{id}_{A\\otimes A}-\\tau$ is the $+1$ eigenspace $S^{2}(A)$, which confirms the conclusion.\n\nTherefore, the correct choice is the space of symmetric tensors, $S^{2}(A)$.", "answer": "$$\\boxed{A}$$", "id": "1562102"}, {"introduction": "The concepts of tensor products extend powerfully into the realm of infinite-dimensional Hilbert spaces, which are essential in quantum mechanics and functional analysis. This challenge problem [@problem_id:1562135] first illustrates how the inner product on a tensor product of Hilbert spaces is naturally defined. It then confronts the critical analytic subtlety of completeness, asking you to calculate the approximation error when representing a vector that lies only in the completed space by its projection onto a subspace of the original algebraic tensor product.", "problem": "Let $\\mathcal{H}_1$ and $\\mathcal{H}_2$ be two infinite-dimensional separable Hilbert spaces over the field of complex numbers $\\mathbb{C}$. Let $\\{e_n\\}_{n \\in \\mathbb{N}^+}$ be a complete orthonormal basis for $\\mathcal{H}_1$ and $\\{f_n\\}_{n \\in \\mathbb{N}^+}$ be a complete orthonormal basis for $\\mathcal{H}_2$.\n\nThe algebraic tensor product, denoted by $\\mathcal{V} = \\mathcal{H}_1 \\otimes_{\\text{alg}} \\mathcal{H}_2$, is the vector space consisting of all finite linear combinations of elementary tensors of the form $u \\otimes v$ for $u \\in \\mathcal{H}_1$ and $v \\in \\mathcal{H}_2$. This space $\\mathcal{V}$ can be made into a pre-Hilbert space by equipping it with the inner product that is defined on elementary tensors by the relation $\\langle u_1 \\otimes v_1, u_2 \\otimes v_2 \\rangle = \\langle u_1, u_2 \\rangle_{\\mathcal{H}_1} \\langle v_1, v_2 \\rangle_{\\mathcal{H}_2}$ and then extended to all of $\\mathcal{V}$ by sesquilinearity. The norm is given by $\\|\\Psi\\|^2 = \\langle \\Psi, \\Psi \\rangle$.\n\nThis pre-Hilbert space is not complete. To illustrate this, consider the sequence of vectors $(\\Psi_N)_{N \\in \\mathbb{N}^+}$ in $\\mathcal{V}$ defined by\n$$\n\\Psi_N = \\sum_{n=1}^{N} \\frac{1}{n^{3/2}} e_n \\otimes f_n\n$$\nThis sequence is a Cauchy sequence, and its limit, which we denote by $\\Psi_\\infty$, exists in the Hilbert space completion of $\\mathcal{V}$ but is not an element of $\\mathcal{V}$ itself.\n\nLet $S_2$ be the two-dimensional subspace of $\\mathcal{V}$ spanned by the vectors $\\{e_1 \\otimes f_1, e_2 \\otimes f_2\\}$. The concept of best approximation from approximation theory states that there exists a unique vector $\\Phi_{best}$ in any finite-dimensional subspace that is closest to a given vector.\n\nCalculate the squared distance between the limit vector $\\Psi_\\infty$ and its best approximation in the subspace $S_2$. Express your answer as a closed-form analytic expression.", "solution": "The problem asks for the squared distance between the vector $\\Psi_\\infty$ and its best approximation in the subspace $S_2$. In a Hilbert space setting, the best approximation of a vector onto a subspace is its orthogonal projection. Let $\\Phi_{best}$ be the best approximation of $\\Psi_\\infty$ in $S_2$. Then $\\Phi_{best} = \\text{Proj}_{S_2}(\\Psi_\\infty)$. The squared distance is $D^2 = \\|\\Psi_\\infty - \\Phi_{best}\\|^2$.\n\nFirst, we identify the limit vector $\\Psi_\\infty$. The sequence is defined as $\\Psi_N = \\sum_{n=1}^{N} \\frac{1}{n^{3/2}} e_n \\otimes f_n$. The limit of this sequence in the completion of $\\mathcal{V}$ is the infinite series:\n$$\n\\Psi_\\infty = \\sum_{n=1}^{\\infty} \\frac{1}{n^{3/2}} e_n \\otimes f_n\n$$\nThis series converges because the sum of the squares of the coefficients converges: $\\sum_{n=1}^{\\infty} \\left| \\frac{1}{n^{3/2}} \\right|^2 = \\sum_{n=1}^{\\infty} \\frac{1}{n^3} = \\zeta(3) < \\infty$.\n\nNext, we characterize the subspace $S_2$. It is spanned by $\\{e_1 \\otimes f_1, e_2 \\otimes f_2\\}$. Let's check if this spanning set is orthonormal.\n$$\n\\langle e_1 \\otimes f_1, e_1 \\otimes f_1 \\rangle = \\langle e_1, e_1 \\rangle_{\\mathcal{H}_1} \\langle f_1, f_1 \\rangle_{\\mathcal{H}_2} = 1 \\cdot 1 = 1\n$$\n$$\n\\langle e_2 \\otimes f_2, e_2 \\otimes f_2 \\rangle = \\langle e_2, e_2 \\rangle_{\\mathcal{H}_1} \\langle f_2, f_2 \\rangle_{\\mathcal{H}_2} = 1 \\cdot 1 = 1\n$$\n$$\n\\langle e_1 \\otimes f_1, e_2 \\otimes f_2 \\rangle = \\langle e_1, e_2 \\rangle_{\\mathcal{H}_1} \\langle f_1, f_2 \\rangle_{\\mathcal{H}_2} = 0 \\cdot 0 = 0\n$$\nSo, the set $\\{e_1 \\otimes f_1, e_2 \\otimes f_2\\}$ forms an orthonormal basis for the subspace $S_2$.\n\nNow, we compute the orthogonal projection of $\\Psi_\\infty$ onto $S_2$. The formula for the projection onto a subspace with an orthonormal basis $\\{b_1, b_2\\}$ is $\\text{Proj}_{S_2}(\\Psi) = \\langle \\Psi, b_1 \\rangle b_1 + \\langle \\Psi, b_2 \\rangle b_2$.\n$$\n\\Phi_{best} = \\text{Proj}_{S_2}(\\Psi_\\infty) = \\langle \\Psi_\\infty, e_1 \\otimes f_1 \\rangle (e_1 \\otimes f_1) + \\langle \\Psi_\\infty, e_2 \\otimes f_2 \\rangle (e_2 \\otimes f_2)\n$$\nLet's calculate the inner product coefficients.\nThe elements $\\{e_i \\otimes f_j\\}_{i,j \\in \\mathbb{N}^+}$ form a complete orthonormal basis for the completed Hilbert space.\nIn particular, the set $\\{e_n \\otimes f_n\\}_{n \\in \\mathbb{N}^+}$ is an orthonormal set.\n$$\n\\langle \\Psi_\\infty, e_1 \\otimes f_1 \\rangle = \\left\\langle \\sum_{n=1}^{\\infty} \\frac{1}{n^{3/2}} e_n \\otimes f_n, e_1 \\otimes f_1 \\right\\rangle = \\sum_{n=1}^{\\infty} \\frac{1}{n^{3/2}} \\langle e_n \\otimes f_n, e_1 \\otimes f_1 \\rangle\n$$\nDue to orthonormality, $\\langle e_n \\otimes f_n, e_1 \\otimes f_1 \\rangle = \\delta_{n1}$. The sum collapses to the $n=1$ term.\n$$\n\\langle \\Psi_\\infty, e_1 \\otimes f_1 \\rangle = \\frac{1}{1^{3/2}} = 1\n$$\nSimilarly, for the second coefficient:\n$$\n\\langle \\Psi_\\infty, e_2 \\otimes f_2 \\rangle = \\left\\langle \\sum_{n=1}^{\\infty} \\frac{1}{n^{3/2}} e_n \\otimes f_n, e_2 \\otimes f_2 \\right\\rangle = \\frac{1}{2^{3/2}}\n$$\nSo, the best approximation vector is:\n$$\n\\Phi_{best} = 1 \\cdot (e_1 \\otimes f_1) + \\frac{1}{2^{3/2}} (e_2 \\otimes f_2) = e_1 \\otimes f_1 + \\frac{1}{2\\sqrt{2}} e_2 \\otimes f_2\n$$\n\nFinally, we calculate the squared distance $D^2 = \\|\\Psi_\\infty - \\Phi_{best}\\|^2$.\nThe difference vector is:\n$$\n\\Psi_\\infty - \\Phi_{best} = \\left(\\sum_{n=1}^{\\infty} \\frac{1}{n^{3/2}} e_n \\otimes f_n\\right) - \\left(e_1 \\otimes f_1 + \\frac{1}{2^{3/2}} e_2 \\otimes f_2\\right)\n$$\n$$\n= (1-1)e_1\\otimes f_1 + \\left(\\frac{1}{2^{3/2}} - \\frac{1}{2^{3/2}}\\right)e_2\\otimes f_2 + \\sum_{n=3}^{\\infty} \\frac{1}{n^{3/2}} e_n \\otimes f_n\n$$\n$$\n\\Psi_\\infty - \\Phi_{best} = \\sum_{n=3}^{\\infty} \\frac{1}{n^{3/2}} e_n \\otimes f_n\n$$\nThe squared norm is the sum of the squares of the coefficients in this orthonormal expansion:\n$$\nD^2 = \\left\\| \\sum_{n=3}^{\\infty} \\frac{1}{n^{3/2}} e_n \\otimes f_n \\right\\|^2 = \\sum_{n=3}^{\\infty} \\left| \\frac{1}{n^{3/2}} \\right|^2 = \\sum_{n=3}^{\\infty} \\frac{1}{n^3}\n$$\nThis sum can be expressed in terms of the Riemann zeta function, $\\zeta(s) = \\sum_{n=1}^\\infty \\frac{1}{n^s}$.\n$$\n\\sum_{n=3}^{\\infty} \\frac{1}{n^3} = \\left(\\sum_{n=1}^{\\infty} \\frac{1}{n^3}\\right) - \\frac{1}{1^3} - \\frac{1}{2^3} = \\zeta(3) - 1 - \\frac{1}{8}\n$$\n$$\nD^2 = \\zeta(3) - \\frac{9}{8}\n$$\nThis is the final closed-form analytic expression for the squared distance.", "answer": "$$\\boxed{\\zeta(3) - \\frac{9}{8}}$$", "id": "1562135"}]}