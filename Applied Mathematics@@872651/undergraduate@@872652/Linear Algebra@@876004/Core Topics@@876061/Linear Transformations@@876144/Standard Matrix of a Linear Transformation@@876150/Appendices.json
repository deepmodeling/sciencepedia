{"hands_on_practices": [{"introduction": "The most fundamental way to determine the standard matrix of a linear transformation is to observe its effect on the standard basis vectors of the domain. Each basis vector is transformed into a column vector, and these columns collectively form the standard matrix. This exercise offers a direct application of this core principle, using a \"consecutive difference operator\" to illustrate how a simple rule applied to input vectors translates into a structured matrix representation.", "problem": "Consider a linear transformation $T$ from $\\mathbb{R}^5$ to $\\mathbb{R}^4$, which can be thought of as a \"consecutive difference operator\". For any vector $\\mathbf{x} = (x_1, x_2, x_3, x_4, x_5)$ in $\\mathbb{R}^5$, the transformation $T$ is defined as:\n$$T(\\mathbf{x}) = (x_2 - x_1, x_3 - x_2, x_4 - x_3, x_5 - x_4)$$\nDetermine the standard matrix for this linear transformation $T$.", "solution": "Let $A$ be the standard matrix of $T$. For the standard basis vectors $\\{e_{1},e_{2},e_{3},e_{4},e_{5}\\}$ of $\\mathbb{R}^{5}$, the $j$-th column of $A$ is $T(e_{j})$, because for any $\\mathbf{x}=\\sum_{j=1}^{5}x_{j}e_{j}$, linearity gives $T(\\mathbf{x})=\\sum_{j=1}^{5}x_{j}T(e_{j})=A\\mathbf{x}$.\n\nCompute each $T(e_{j})$ using $T(x_{1},x_{2},x_{3},x_{4},x_{5})=(x_{2}-x_{1},x_{3}-x_{2},x_{4}-x_{3},x_{5}-x_{4})$:\n- $e_{1}=(1,0,0,0,0)$, so $T(e_{1})=(0-1,0-0,0-0,0-0)=(-1,0,0,0)$.\n- $e_{2}=(0,1,0,0,0)$, so $T(e_{2})=(1-0,0-1,0-0,0-0)=(1,-1,0,0)$.\n- $e_{3}=(0,0,1,0,0)$, so $T(e_{3})=(0-0,1-0,0-1,0-0)=(0,1,-1,0)$.\n- $e_{4}=(0,0,0,1,0)$, so $T(e_{4})=(0-0,0-0,1-0,0-1)=(0,0,1,-1)$.\n- $e_{5}=(0,0,0,0,1)$, so $T(e_{5})=(0-0,0-0,0-0,1-0)=(0,0,0,1)$.\n\nThus the standard matrix $A$ has columns $T(e_{1}),\\dots,T(e_{5})$, i.e.,\n$$\nA=\\begin{pmatrix}\n-1 & 1 & 0 & 0 & 0 \\\\\n0 & -1 & 1 & 0 & 0 \\\\\n0 & 0 & -1 & 1 & 0 \\\\\n0 & 0 & 0 & -1 & 1\n\\end{pmatrix}.\n$$", "answer": "$$\\boxed{\\begin{pmatrix}-1 & 1 & 0 & 0 & 0 \\\\ 0 & -1 & 1 & 0 & 0 \\\\ 0 & 0 & -1 & 1 & 0 \\\\ 0 & 0 & 0 & -1 & 1\\end{pmatrix}}$$", "id": "1390582"}, {"introduction": "Linear transformations can be combined to create more complex operations, a process known as composition. A powerful feature of matrix representation is that the composition of transformations corresponds to the multiplication of their standard matrices. This practice challenges you to find the matrix for a composite transformation, which involves a cross product and a geometric reflection, reinforcing the link between abstract operations and concrete matrix arithmetic.", "problem": "Consider two linear transformations, $T$ and $S$, both mapping vectors in $\\mathbb{R}^3$ to vectors in $\\mathbb{R}^3$.\n\nThe first transformation, $T$, is defined by the cross product of a fixed, non-zero vector $\\mathbf{c} = (c_1, c_2, c_3)$ with its input vector $\\mathbf{v}$. Specifically, $T(\\mathbf{v}) = \\mathbf{c} \\times \\mathbf{v}$.\n\nThe second transformation, $S$, reflects any input vector across the $xy$-plane.\n\nA third transformation, $L$, is defined as the composition of $S$ and $T$, such that $L(\\mathbf{v}) = S(T(\\mathbf{v}))$.\n\nDetermine the standard matrix for the composite linear transformation $L$.", "solution": "We seek the standard matrix of the composite linear transformation $L = S \\circ T$ on $\\mathbb{R}^{3}$, where $T(\\mathbf{v}) = \\mathbf{c} \\times \\mathbf{v}$ with fixed nonzero $\\mathbf{c} = (c_{1}, c_{2}, c_{3})$, and $S$ is the reflection across the $xy$-plane.\n\nFirst, represent $T$ as a matrix with respect to the standard basis. For $\\mathbf{v} = (v_{1}, v_{2}, v_{3})^{\\mathsf{T}}$, the cross product $\\mathbf{c} \\times \\mathbf{v}$ has components\n$$\n\\mathbf{c} \\times \\mathbf{v} = \\begin{pmatrix}\nc_{2}v_{3} - c_{3}v_{2} \\\\\nc_{3}v_{1} - c_{1}v_{3} \\\\\nc_{1}v_{2} - c_{2}v_{1}\n\\end{pmatrix}.\n$$\nThus the standard matrix of $T$ is the skew-symmetric matrix\n$$\nA_{T} = \\begin{pmatrix}\n0 & -c_{3} & c_{2} \\\\\nc_{3} & 0 & -c_{1} \\\\\n-c_{2} & c_{1} & 0\n\\end{pmatrix},\n$$\nsince $A_{T}\\begin{pmatrix} v_{1}\\\\ v_{2}\\\\ v_{3} \\end{pmatrix} = \\mathbf{c} \\times \\mathbf{v}$.\n\nNext, the reflection $S$ across the $xy$-plane maps $(x,y,z)$ to $(x,y,-z)$, so its standard matrix is\n$$\nA_{S} = \\begin{pmatrix}\n1 & 0 & 0 \\\\\n0 & 1 & 0 \\\\\n0 & 0 & -1\n\\end{pmatrix}.\n$$\n\nThe standard matrix of the composition $L = S \\circ T$ is the product\n$$\nA_{L} = A_{S} A_{T}.\n$$\nCompute this product by multiplying on the left by $A_{S}$, which scales the first and second rows of $A_{T}$ by $1$ and the third row by $-1$:\n$$\nA_{L} = \\begin{pmatrix}\n1 & 0 & 0 \\\\\n0 & 1 & 0 \\\\\n0 & 0 & -1\n\\end{pmatrix}\n\\begin{pmatrix}\n0 & -c_{3} & c_{2} \\\\\nc_{3} & 0 & -c_{1} \\\\\n-c_{2} & c_{1} & 0\n\\end{pmatrix}\n=\n\\begin{pmatrix}\n0 & -c_{3} & c_{2} \\\\\nc_{3} & 0 & -c_{1} \\\\\nc_{2} & -c_{1} & 0\n\\end{pmatrix}.\n$$\nTherefore, the standard matrix for $L$ is the matrix above.", "answer": "$$\\boxed{\\begin{pmatrix}\n0 & -c_{3} & c_{2} \\\\\nc_{3} & 0 & -c_{1} \\\\\nc_{2} & -c_{1} & 0\n\\end{pmatrix}}$$", "id": "1390590"}, {"introduction": "Beyond representing individual transformations, standard matrices allow us to explore the algebraic relationships between different operators. This advanced exercise investigates a family of transformations defined by how they scale vectors within a subspace and its orthogonal complement. By relating this general transformation to the matrix of an orthogonal projection, you will derive a formula that elegantly connects seemingly disparate operations like projection and reflection.", "problem": "Let $W$ be a non-trivial subspace of the Euclidean space $\\mathbb{R}^n$. Any vector $\\mathbf{x} \\in \\mathbb{R}^n$ can be uniquely expressed as the sum of a vector in $W$ and a vector in its orthogonal complement $W^{\\perp}$, such that $\\mathbf{x} = \\mathbf{x}_{W} + \\mathbf{x}_{W^{\\perp}}$, where $\\mathbf{x}_{W} \\in W$ and $\\mathbf{x}_{W^{\\perp}} \\in W^{\\perp}$.\n\nConsider a family of linear transformations $L_{c_1, c_2}: \\mathbb{R}^n \\to \\mathbb{R}^n$, parameterized by two real scalars $c_1$ and $c_2$. The action of this transformation on any vector $\\mathbf{x} \\in \\mathbb{R}^n$ is defined by scaling its components in $W$ and $W^{\\perp}$:\n$$L_{c_1, c_2}(\\mathbf{x}) = c_1 \\mathbf{x}_{W} + c_2 \\mathbf{x}_{W^{\\perp}}$$\nThis family of transformations includes well-known operators. For instance, if $c_1=1$ and $c_2=0$, $L_{1,0}$ is the orthogonal projection onto $W$. If $c_1=1$ and $c_2=-1$, $L_{1,-1}$ is the reflection across $W$.\n\nLet $P$ be the standard matrix for the orthogonal projection from $\\mathbb{R}^n$ onto the subspace $W$, and let $I$ be the $n \\times n$ identity matrix.\n\nDetermine the standard matrix, $A$, of the linear transformation $L_{c_1, c_2}$ in terms of $P$, $I$, $c_1$, and $c_2$.", "solution": "Let $W \\subset \\mathbb{R}^{n}$ be a non-trivial subspace and $P$ the orthogonal projection matrix onto $W$. By definition of $P$, for any $\\mathbf{x} \\in \\mathbb{R}^{n}$, the orthogonal decomposition satisfies\n$$\n\\mathbf{x}_{W} = P\\mathbf{x}, \\quad \\mathbf{x}_{W^{\\perp}} = (I - P)\\mathbf{x}, \\quad \\text{and} \\quad \\mathbf{x} = P\\mathbf{x} + (I-P)\\mathbf{x}.\n$$\nThe linear transformation $L_{c_{1},c_{2}}$ acts by\n$$\nL_{c_{1},c_{2}}(\\mathbf{x}) = c_{1}\\mathbf{x}_{W} + c_{2}\\mathbf{x}_{W^{\\perp}} = c_{1}P\\mathbf{x} + c_{2}(I - P)\\mathbf{x}.\n$$\nSince every linear transformation has a standard matrix $A$ satisfying $L_{c_{1},c_{2}}(\\mathbf{x}) = A\\mathbf{x}$ for all $\\mathbf{x}$, comparing yields\n$$\nA = c_{1}P + c_{2}(I - P).\n$$\nBy distributing and regrouping terms, this can be written equivalently as\n$$\nA = c_{2}I + (c_{1} - c_{2})P.\n$$\nEither form expresses the standard matrix in terms of $P$, $I$, $c_{1}$, and $c_{2}$.", "answer": "$$\\boxed{c_{2}I + (c_{1} - c_{2})P}$$", "id": "1390597"}]}