{"hands_on_practices": [{"introduction": "Before we can explore the properties of linear transformations, we must be able to identify them. This exercise challenges our intuition by presenting a 'sorting' operator and asking a critical question: does it satisfy the fundamental axioms of linearity? By testing for additivity and scalar homogeneity, you will solidify your understanding of what truly defines a linear map [@problem_id:1368367].", "problem": "In certain data analysis algorithms, an operator is used to rank numerical features. Consider such an operator, a transformation $T: \\mathbb{R}^4 \\to \\mathbb{R}^4$, which takes a 4-dimensional vector $\\mathbf{v}$ and outputs a new vector $T(\\mathbf{v})$ whose components are the components of $\\mathbf{v}$ sorted in descending order. For example, if $\\mathbf{v} = (2, -7, 5, 1)$, then $T(\\mathbf{v}) = (5, 2, 1, -7)$.\n\nFor this operator to be compatible with a wide range of standard linear algebraic techniques, it must be a linear transformation. Your task is to determine whether $T$ is linear. Select the correct statement and justification from the options below.\n\nA. Yes, $T$ is linear because rearranging components is a reversible operation, which is a property of linear transformations.\n\nB. No, $T$ is not linear because it fails the additivity property, i.e., $T(\\mathbf{u} + \\mathbf{v}) = T(\\mathbf{u}) + T(\\mathbf{v})$ holds, but the scalar multiplication property $T(c\\mathbf{u}) = cT(\\mathbf{u})$ fails for some vectors and scalars.\n\nC. No, $T$ is not linear because it fails the scalar multiplication property, i.e., $T(c\\mathbf{u}) = cT(\\mathbf{u})$ holds, but the additivity property $T(\\mathbf{u} + \\mathbf{v}) = T(\\mathbf{u}) + T(\\mathbf{v})$ fails for some vectors.\n\nD. No, $T$ is not linear because it fails both the additivity and the scalar multiplication properties.\n\nE. Yes, $T$ is linear because for the zero vector $\\mathbf{0} = (0, 0, 0, 0)$, $T(\\mathbf{0}) = \\mathbf{0}$, which is a sufficient condition for linearity.", "solution": "We recall that a transformation $T: \\mathbb{R}^{4} \\to \\mathbb{R}^{4}$ is linear if and only if, for all $\\mathbf{u}, \\mathbf{v} \\in \\mathbb{R}^{4}$ and all scalars $c \\in \\mathbb{R}$,\n$$\nT(\\mathbf{u}+\\mathbf{v})=T(\\mathbf{u})+T(\\mathbf{v})\n\\quad\\text{and}\\quad\nT(c\\mathbf{u})=c\\,T(\\mathbf{u}).\n$$\nHere $T$ sorts the components of its input in descending order.\n\nFirst, we show the scalar multiplication property fails for some scalars. Choose $\\mathbf{u}=(u_{1},u_{2},u_{3},u_{4})$ with strictly increasing entries $u_{1}u_{2}u_{3}u_{4}$. Then\n$$\nT(\\mathbf{u})=(u_{4},u_{3},u_{2},u_{1}).\n$$\nLet $c0$. Because multiplying by a negative scalar reverses inequalities, we have $cu_{1}cu_{2}cu_{3}cu_{4}$, hence\n$$\nT(c\\mathbf{u})=(cu_{1},cu_{2},cu_{3},cu_{4}),\n$$\nwhile\n$$\nc\\,T(\\mathbf{u})=c(u_{4},u_{3},u_{2},u_{1})=(cu_{4},cu_{3},cu_{2},cu_{1}).\n$$\nSince $cu_{1}cu_{2}cu_{3}cu_{4}$ are strictly ordered, it follows that\n$$\nT(c\\mathbf{u})\\neq c\\,T(\\mathbf{u}).\n$$\nTherefore, the scalar multiplication property fails, so $T$ is not linear.\n\nNext, we show the additivity property also fails for some vectors. Let $a,b\\in\\mathbb{R}$ with $a0$ and $b0$, and define\n$$\n\\mathbf{u}=(a,0,0,0),\\qquad \\mathbf{v}=(0,b,0,0).\n$$\nThen\n$$\nT(\\mathbf{u})=(a,0,0,0),\\qquad T(\\mathbf{v})=(b,0,0,0),\n$$\nso\n$$\nT(\\mathbf{u})+T(\\mathbf{v})=(a+b,0,0,0).\n$$\nBut\n$$\n\\mathbf{u}+\\mathbf{v}=(a,b,0,0),\n$$\nand sorting in descending order gives\n$$\nT(\\mathbf{u}+\\mathbf{v})=(\\max\\{a,b\\},\\min\\{a,b\\},0,0).\n$$\nBecause $a0$ and $b0$, we have $\\min\\{a,b\\}0$, so\n$$\nT(\\mathbf{u}+\\mathbf{v})\\neq (a+b,0,0,0)=T(\\mathbf{u})+T(\\mathbf{v}).\n$$\nThus additivity also fails.\n\nSince both the scalar multiplication and additivity properties fail, $T$ is not linear, and the correct choice is that it fails both properties.", "answer": "$$\\boxed{D}$$", "id": "1368367"}, {"introduction": "One of the most elegant aspects of linear algebra is the bridge it builds between algebraic properties and geometric intuition. This problem invites you to use the Rank-Nullity Theorem, a cornerstone of the subject, to deduce the geometric nature of a transformation's kernel. You will see how knowing a transformation is surjective allows you to precisely describe a key subspace in its domain [@problem_id:1368335].", "problem": "Consider a linear transformation $T$ that maps vectors from a 3-dimensional Euclidean space to a 2-dimensional Euclidean space, denoted as $T: \\mathbb{R}^3 \\to \\mathbb{R}^2$. The transformation is known to be surjective, which means that its image is the entire codomain $\\mathbb{R}^2$. The kernel of this transformation, $\\ker(T)$, is defined as the set of all vectors $\\mathbf{v}$ in the domain $\\mathbb{R}^3$ such that $T(\\mathbf{v}) = \\mathbf{0}$, where $\\mathbf{0}$ is the zero vector in $\\mathbb{R}^2$.\n\nBased on this information, which of the following options provides the correct and most complete geometric description of the kernel of $T$?\n\nA. A line passing through the origin in $\\mathbb{R}^3$.\n\nB. The single point at the origin in $\\mathbb{R}^3$.\n\nC. A plane passing through the origin in $\\mathbb{R}^3$.\n\nD. A line passing through the origin in $\\mathbb{R}^2$.\n\nE. The entire space $\\mathbb{R}^3$.", "solution": "The problem asks for the geometric description of the kernel of a surjective linear transformation $T: \\mathbb{R}^3 \\to \\mathbb{R}^2$. To solve this, we will use the Rank-Nullity Theorem.\n\nThe Rank-Nullity Theorem states that for any linear transformation $T: V \\to W$, where $V$ is a finite-dimensional vector space, the following relationship holds:\n$$\n\\dim(\\ker(T)) + \\dim(\\text{Im}(T)) = \\dim(V)\n$$\nHere, $\\dim(\\ker(T))$ is the dimension of the kernel of $T$ (the nullity), $\\dim(\\text{Im}(T))$ is the dimension of the image or range of $T$ (the rank), and $\\dim(V)$ is the dimension of the domain.\n\nIn our specific problem, the linear transformation is $T: \\mathbb{R}^3 \\to \\mathbb{R}^2$.\nThe domain is $V = \\mathbb{R}^3$. Its dimension is $\\dim(\\mathbb{R}^3) = 3$.\n\nThe problem states that the transformation $T$ is surjective. A surjective transformation is one for which the image is equal to the codomain. In this case, the codomain is $\\mathbb{R}^2$.\nTherefore, the image of $T$ is $\\text{Im}(T) = \\mathbb{R}^2$.\nThe dimension of the image (the rank of $T$) is the dimension of this space:\n$$\n\\dim(\\text{Im}(T)) = \\dim(\\mathbb{R}^2) = 2\n$$\n\nNow we can substitute the known dimensions into the Rank-Nullity Theorem equation:\n$$\n\\dim(\\ker(T)) + \\dim(\\text{Im}(T)) = \\dim(\\text{Domain})\n$$\n$$\n\\dim(\\ker(T)) + 2 = 3\n$$\n\nSolving for the dimension of the kernel, we find:\n$$\n\\dim(\\ker(T)) = 3 - 2 = 1\n$$\nSo, the kernel of $T$ is a 1-dimensional subspace of the domain, $\\mathbb{R}^3$.\n\nLet's interpret this result geometrically.\n- Any subspace must contain the origin.\n- A 1-dimensional subspace of $\\mathbb{R}^3$ is a line passing through the origin.\n- A 2-dimensional subspace of $\\mathbb{R}^3$ is a plane passing through the origin.\n- A 0-dimensional subspace of $\\mathbb{R}^3$ is just the origin itself, $\\{\\mathbf{0}\\}$.\n\nSince $\\dim(\\ker(T)) = 1$, the kernel is a line passing through the origin in $\\mathbb{R}^3$.\n\nNow let's evaluate the given options:\nA. A line passing through the origin in $\\mathbb{R}^3$. This corresponds to a 1-dimensional subspace of $\\mathbb{R}^3$, which matches our conclusion.\nB. The single point at the origin in $\\mathbb{R}^3$. This corresponds to a 0-dimensional kernel. This would be true if $T$ were injective (one-to-one), but this is not possible for a linear map from $\\mathbb{R}^3$ to $\\mathbb{R}^2$.\nC. A plane passing through the origin in $\\mathbb{R}^3$. This corresponds to a 2-dimensional kernel. This would imply the rank is 1, meaning the transformation is not surjective.\nD. A line passing through the origin in $\\mathbb{R}^2$. This is incorrect because the kernel is a subspace of the domain, $\\mathbb{R}^3$, not the codomain, $\\mathbb{R}^2$.\nE. The entire space $\\mathbb{R}^3$. This would mean the kernel has dimension 3, which implies the rank is 0. This describes the zero transformation ($T(\\mathbf{v}) = \\mathbf{0}$ for all $\\mathbf{v}$), which is not surjective onto $\\mathbb{R}^2$.\n\nTherefore, the correct geometric description is a line passing through the origin in $\\mathbb{R}^3$.", "answer": "$$\\boxed{A}$$", "id": "1368335"}, {"introduction": "Linear transformations are not confined to vectors in $\\mathbb{R}^n$; they operate on diverse vector spaces, including those of matrices and polynomials. This practice will sharpen your computational skills by tasking you with finding the kernel of such a transformation. You will translate the abstract definition of the kernel into a concrete system of linear equations and find a basis for its solution space [@problem_id:1368349].", "problem": "Let $M_{2}(\\mathbb{R})$ be the vector space of all $2 \\times 2$ matrices with real entries, and let $P_{1}(t)$ be the vector space of all polynomials in the variable $t$ of degree at most 1 with real coefficients. Consider the linear transformation $L: M_{2}(\\mathbb{R}) \\to P_{1}(t)$ defined by\n$$\nL\\left( \\begin{pmatrix} a  b \\\\ c  d \\end{pmatrix} \\right) = (a-d) + (b+c)t\n$$\nwhere $a, b, c, d$ are real numbers.\n\nWhich of the following sets forms a basis for the kernel of the linear transformation $L$?\n\nA. $\\left\\{ \\begin{pmatrix} 1  0 \\\\ 0  -1 \\end{pmatrix}, \\begin{pmatrix} 0  1 \\\\ -1  0 \\end{pmatrix} \\right\\}$\n\nB. $\\left\\{ \\begin{pmatrix} 1  0 \\\\ 0  1 \\end{pmatrix}, \\begin{pmatrix} 0  1 \\\\ -1  0 \\end{pmatrix} \\right\\}$\n\nC. $\\left\\{ \\begin{pmatrix} 1  0 \\\\ 0  1 \\end{pmatrix}, \\begin{pmatrix} 0  1 \\\\ 1  0 \\end{pmatrix} \\right\\}$\n\nD. $\\left\\{ \\begin{pmatrix} 1  1 \\\\ -1  1 \\end{pmatrix} \\right\\}$\n\nE. $\\left\\{ \\begin{pmatrix} 1  0 \\\\ 0  1 \\end{pmatrix}, \\begin{pmatrix} 0  1 \\\\ -1  0 \\end{pmatrix}, \\begin{pmatrix} 1  1 \\\\ -1  1 \\end{pmatrix} \\right\\}$", "solution": "The kernel of a linear transformation $L$, denoted $\\ker(L)$, is the set of all vectors in the domain that map to the zero vector in the codomain. In this case, the domain is the space of $2 \\times 2$ matrices, $M_{2}(\\mathbb{R})$, and the codomain is the space of polynomials of degree at most one, $P_{1}(t)$.\n\nThe zero vector in $P_{1}(t)$ is the zero polynomial, $0 + 0t$.\nWe are looking for all matrices $M = \\begin{pmatrix} a  b \\\\ c  d \\end{pmatrix}$ such that $L(M) = 0$.\n\nSetting the output of the transformation to the zero polynomial gives:\n$$\nL\\left( \\begin{pmatrix} a  b \\\\ c  d \\end{pmatrix} \\right) = (a-d) + (b+c)t = 0 + 0t\n$$\n\nFor two polynomials to be equal, their corresponding coefficients must be equal. This yields a system of two linear equations:\n1. The constant term must be zero: $a - d = 0$\n2. The coefficient of $t$ must be zero: $b + c = 0$\n\nFrom these equations, we can express two of the variables in terms of the other two.\nFrom equation (1), we have $a = d$.\nFrom equation (2), we have $c = -b$.\n\nThis means that any matrix in the kernel of $L$ must be of the form:\n$$\nM = \\begin{pmatrix} a  b \\\\ c  d \\end{pmatrix} = \\begin{pmatrix} a  b \\\\ -b  a \\end{pmatrix}\n$$\nwhere $a$ and $b$ can be any real numbers.\n\nTo find a basis for the kernel, we need to find a set of linearly independent matrices that span this subspace. We can express the general form of a matrix in the kernel as a linear combination of simpler matrices by separating the parameters $a$ and $b$:\n$$\n\\begin{pmatrix} a  b \\\\ -b  a \\end{pmatrix} = \\begin{pmatrix} a  0 \\\\ 0  a \\end{pmatrix} + \\begin{pmatrix} 0  b \\\\ -b  0 \\end{pmatrix} = a \\begin{pmatrix} 1  0 \\\\ 0  1 \\end{pmatrix} + b \\begin{pmatrix} 0  1 \\\\ -1  0 \\end{pmatrix}\n$$\nThis shows that any matrix in the kernel can be written as a linear combination of the two matrices $\\begin{pmatrix} 1  0 \\\\ 0  1 \\end{pmatrix}$ and $\\begin{pmatrix} 0  1 \\\\ -1  0 \\end{pmatrix}$. Therefore, the set $S = \\left\\{ \\begin{pmatrix} 1  0 \\\\ 0  1 \\end{pmatrix}, \\begin{pmatrix} 0  1 \\\\ -1  0 \\end{pmatrix} \\right\\}$ spans the kernel of $L$.\n\nNext, we must check if this set is linearly independent. We set a linear combination of the vectors in $S$ equal to the zero matrix and solve for the scalar coefficients $k_1$ and $k_2$:\n$$\nk_1 \\begin{pmatrix} 1  0 \\\\ 0  1 \\end{pmatrix} + k_2 \\begin{pmatrix} 0  1 \\\\ -1  0 \\end{pmatrix} = \\begin{pmatrix} 0  0 \\\\ 0  0 \\end{pmatrix}\n$$\nPerforming the scalar multiplication and addition on the left side gives:\n$$\n\\begin{pmatrix} k_1  k_2 \\\\ -k_2  k_1 \\end{pmatrix} = \\begin{pmatrix} 0  0 \\\\ 0  0 \\end{pmatrix}\n$$\nEquating the corresponding entries gives $k_1 = 0$ and $k_2 = 0$. Since the only solution is the trivial solution, the matrices are linearly independent.\n\nBecause the set $S$ both spans the kernel and is linearly independent, it is a basis for the kernel of $L$.\nComparing this result with the given choices, we find that it matches option B.\n\nLet's briefly analyze the other options:\n- A: $\\left\\{ \\begin{pmatrix} 1  0 \\\\ 0  -1 \\end{pmatrix}, \\begin{pmatrix} 0  1 \\\\ -1  0 \\end{pmatrix} \\right\\}$. The first matrix corresponds to $a=-d$, which is incorrect.\n- C: $\\left\\{ \\begin{pmatrix} 1  0 \\\\ 0  1 \\end{pmatrix}, \\begin{pmatrix} 0  1 \\\\ 1  0 \\end{pmatrix} \\right\\}$. The second matrix has $c=b$, which contradicts $c=-b$ (unless $b=c=0$).\n- D: $\\left\\{ \\begin{pmatrix} 1  1 \\\\ -1  1 \\end{pmatrix} \\right\\}$. This set is linearly independent, and the matrix is in the kernel (with $a=1, b=1$). However, it does not span the kernel, as the kernel is two-dimensional. For example, the matrix $\\begin{pmatrix} 1  0 \\\\ 0  1 \\end{pmatrix}$ is in the kernel but is not a scalar multiple of $\\begin{pmatrix} 1  1 \\\\ -1  1 \\end{pmatrix}$. So, it's not a basis.\n- E: $\\left\\{ \\begin{pmatrix} 1  0 \\\\ 0  1 \\end{pmatrix}, \\begin{pmatrix} 0  1 \\\\ -1  0 \\end{pmatrix}, \\begin{pmatrix} 1  1 \\\\ -1  1 \\end{pmatrix} \\right\\}$. This set spans the kernel, but it is not linearly independent because the third matrix is the sum of the first two. A basis must be linearly independent.", "answer": "$$\\boxed{B}$$", "id": "1368349"}]}