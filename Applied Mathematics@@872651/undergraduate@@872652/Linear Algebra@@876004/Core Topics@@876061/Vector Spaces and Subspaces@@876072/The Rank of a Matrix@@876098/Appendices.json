{"hands_on_practices": [{"introduction": "The most direct way to determine a matrix's rank is by reducing it to row echelon form and counting the number of non-zero rows. This exercise [@problem_id:19450] provides hands-on practice with this fundamental algorithm. You will see how the value of a single entry can determine whether a row becomes zero during elimination, thereby controlling the final rank of the matrix.", "problem": "### Problem: Finding a Parameter to Fix the Rank of a Matrix\n\nThe **rank** of a matrix is a fundamental concept in linear algebra, representing the number of linearly independent rows (or columns) in the matrix. A common method to determine the rank is to transform the matrix into its **row echelon form** using elementary row operations. The rank is then simply the number of non-zero rows in the resulting echelon form matrix. A matrix is in row echelon form if:\n1. All rows consisting entirely of zeros are at the bottom.\n2. The leading non-zero entry (called a pivot) of a non-zero row is to the right of the leading entry of the row above it.\n\nConsider the following $3 \\times 3$ matrix $A$, which contains a variable parameter $z$:\n$$\nA = \\begin{pmatrix} 1  2  3 \\\\ 2  5  0 \\\\ 1  2  z \\end{pmatrix}\n$$\n\nYour task is to find the specific value of $z$ for which the rank of the matrix $A$ is exactly 2.", "solution": "We apply elementary row operations to $A$:\n$$\nA=\\begin{pmatrix}123\\\\250\\\\12z\\end{pmatrix}.\n$$\nPerform $R_2\\to R_2-2R_1$ and $R_3\\to R_3-R_1$ to obtain\n$$\n\\begin{pmatrix}\n123\\\\\n01-6\\\\\n00z-3\n\\end{pmatrix}.\n$$\nIn this row echelon form the pivots are $1$, $1$, and $z-3$. Therefore \n$$\\rank(A)=2\\iff z-3=0\\iff z=3.$$", "answer": "$$\\boxed{3}$$", "id": "19450"}, {"introduction": "The rank of a matrix is not just a computational result; it is deeply tied to the matrix's structure. This problem [@problem_id:1397961] invites you to reason about the rank of a general upper triangular matrix. By thinking about the positions of the pivots and the definition of linear independence, you can determine the rank without performing any explicit row operations, highlighting the connection between rank and the determinant.", "problem": "Let $A$ be a $4 \\times 4$ matrix with real entries. The matrix $A$ is known to be upper triangular, which means that all entries below the main diagonal are zero. Furthermore, it is given that exactly one of the entries on the main diagonal of $A$ is zero, while the other three diagonal entries are non-zero. Determine the rank of matrix $A$.", "solution": "Let $A=\\left[a_{ij}\\right]$ be $4 \\times 4$ and upper triangular, so $a_{ij}=0$ for all $ij$. Exactly one diagonal entry is zero and the other three diagonal entries are nonzero.\n\nFirst, we show that the rank is at least the number of nonzero diagonal entries. Let $S=\\{i \\in \\{1,2,3,4\\} : a_{ii} \\neq 0\\}$, so $|S|=3$. For each $i \\in S$, consider the $i$-th row vector $r_{i}$. Because $A$ is upper triangular, in row $i$ all entries in columns $1,\\dots,i-1$ are zero and $a_{ii}\\neq 0$, so the leading (leftmost) nonzero entry of $r_{i}$ is at column $i$. Suppose there is a linear dependence $\\sum_{i \\in S} c_{i} r_{i}=0$. Let $i_{0}$ be the minimal index in $S$ with $c_{i_{0}} \\neq 0$. Looking at column $i_{0}$ of the combination, all rows $r_{j}$ with $ji_{0}$ have zero in column $i_{0}$ (since $A$ is upper triangular), while $r_{i_{0}}$ has $a_{i_{0}i_{0}}\\neq 0$ in that column. Hence the entry in column $i_{0}$ of the sum is $c_{i_{0}} a_{i_{0}i_{0}}=0$, which forces $c_{i_{0}}=0$, a contradiction. Therefore, the rows $\\{r_{i}: i \\in S\\}$ are linearly independent and\n$$\n\\operatorname{rank}(A) \\geq |S| = 3.\n$$\n\nNext, for any triangular matrix, the determinant equals the product of the diagonal entries:\n$$\n\\det(A)=\\prod_{i=1}^{4} a_{ii}.\n$$\nSince exactly one diagonal entry is zero, this product is zero, so $\\det(A)=0$. Hence $A$ is singular and cannot have full rank, so\n$$\n\\operatorname{rank}(A) \\leq 3.\n$$\n\nCombining the two inequalities gives\n$$\n\\operatorname{rank}(A)=3.\n$$", "answer": "$$\\boxed{3}$$", "id": "1397961"}, {"introduction": "A deeper understanding of linear algebra comes from knowing not just how to compute quantities, but also what is and isn't possible. This exercise [@problem_id:1397977] challenges you to think about the properties of rank, specifically how it behaves when a matrix is multiplied by itself. By analyzing the relationship between the column space of a matrix $A$ and its square $A^2$, you can deduce which rank transformation is impossible, reinforcing key theoretical concepts like invertibility.", "problem": "Let $A$ be a square matrix of size $3 \\times 3$ with real-valued entries. The rank of a matrix is defined as the dimension of the vector space spanned by its columns. Consider the relationship between the rank of $A$, denoted as $\\text{rank}(A)$, and the rank of its square, $A^2$, denoted as $\\text{rank}(A^2)$. Which one of the following scenarios is mathematically impossible?\n\nA. $\\text{rank}(A) = 2$ and $\\text{rank}(A^2) = 1$\n\nB. $\\text{rank}(A) = 3$ and $\\text{rank}(A^2) = 2$\n\nC. $\\text{rank}(A) = 1$ and $\\text{rank}(A^2) = 1$\n\nD. $\\text{rank}(A) = 2$ and $\\text{rank}(A^2) = 2$\n\nE. $\\text{rank}(A) = 1$ and $\\text{rank}(A^2) = 0$", "solution": "Let $A$ be a $3 \\times 3$ real matrix. Set $r=\\operatorname{rank}(A)$ and $s=\\operatorname{rank}(A^{2})$. Two general facts hold:\n1) Since $\\operatorname{im}(A^{2}) \\subseteq \\operatorname{im}(A)$, we have\n$$\n\\operatorname{rank}(A^{2}) \\leq \\operatorname{rank}(A), \\quad \\text{i.e., } s \\leq r.\n$$\n2) If $A$ is invertible, then so is $A^{2}$, hence\n$$\n\\operatorname{rank}(A)=3 \\implies \\operatorname{rank}(A^{2})=3.\n$$\nTherefore, the scenario $r=3$ and $s=2$ is impossible.\n\nWe now verify that the remaining scenarios are realizable by explicit constructions:\n\nA. $r=2$, $s=1$: Take $A$ similar to $\\operatorname{diag}(J_{2}(0),[\\lambda])$ with $\\lambda \\neq 0$, where $J_{2}(0)=\\begin{pmatrix}0  1 \\\\ 0  0\\end{pmatrix}$. Then $\\operatorname{rank}(J_{2}(0))=1$, so $\\operatorname{rank}(A)=1+1=2$. Also $J_{2}(0)^{2}=0$, hence $A^{2}$ is similar to $\\operatorname{diag}(0,[\\lambda^{2}])$, giving $\\operatorname{rank}(A^{2})=1$.\n\nC. $r=1$, $s=1$: Let $A=uv^{\\top}$ with $u,v \\in \\mathbb{R}^{3}$ and $v^{\\top}u \\neq 0$. Then\n$$A^{2}=u(v^{\\top}u)v^{\\top}=(v^{\\top}u)A,$$\nso $\\operatorname{rank}(A^{2})=\\operatorname{rank}(A)=1$.\n\nD. $r=2$, $s=2$: Take $A=\\operatorname{diag}(0,\\lambda,\\mu)$ with $\\lambda,\\mu \\neq 0$. Then $\\operatorname{rank}(A)=2$ and $A^{2}=\\operatorname{diag}(0,\\lambda^{2},\\mu^{2})$ has $\\operatorname{rank}(A^{2})=2$.\n\nE. $r=1$, $s=0$: Let $A=uv^{\\top}$ with $v^{\\top}u=0$. Then\n$$A^{2}=u(v^{\\top}u)v^{\\top}=0,$$\nso $\\operatorname{rank}(A)=1$ and $\\operatorname{rank}(A^{2})=0$.\n\nThus, the only impossible case is $r=3$ and $s=2$.", "answer": "$$\\boxed{B}$$", "id": "1397977"}]}