{"hands_on_practices": [{"introduction": "The column space of a matrix is a fundamental concept, representing all possible outputs of the linear transformation defined by the matrix. A crucial first step in analyzing this space is to find a basis—a minimal set of vectors that spans the entire space. This practice will guide you through the standard and most reliable method for finding a basis for a column space by using row reduction to identify the pivot columns of the matrix [@problem_id:1354326].", "problem": "Consider the matrix $A$ defined as:\n$$\nA = \\begin{pmatrix}\n1  2  1  0 \\\\\n-2  -4  1  -3 \\\\\n3  6  1  2\n\\end{pmatrix}\n$$\nThe column space of $A$, denoted as $\\text{Col}(A)$, is the subspace of $\\mathbb{R}^3$ spanned by the column vectors of $A$. Find a basis for $\\text{Col}(A)$.\n\nPresent your answer as a single matrix whose columns are the basis vectors, ordered from left to right corresponding to their order of appearance in the original matrix $A$.", "solution": "Let the columns of $A$ be $c_{1},c_{2},c_{3},c_{4}$, where\n$$\nc_{1}=\\begin{pmatrix}1\\\\-2\\\\3\\end{pmatrix},\\quad\nc_{2}=\\begin{pmatrix}2\\\\-4\\\\6\\end{pmatrix},\\quad\nc_{3}=\\begin{pmatrix}1\\\\1\\\\1\\end{pmatrix},\\quad\nc_{4}=\\begin{pmatrix}0\\\\-3\\\\2\\end{pmatrix}.\n$$\nBy definition, $\\text{Col}(A)=\\text{span}\\{c_{1},c_{2},c_{3},c_{4}\\}$. A basis for $\\text{Col}(A)$ is obtained by selecting a maximal set of linearly independent columns of $A$. A standard method is to compute the reduced row echelon form (RREF) of $A$; the pivot columns of the RREF indicate which original columns of $A$ form a basis for $\\text{Col}(A)$, in their original order.\n\nPerform row operations on $A$:\n$$\nA=\\begin{pmatrix}\n1  2  1  0 \\\\\n-2  -4  1  -3 \\\\\n3  6  1  2\n\\end{pmatrix}\n\\;\\xrightarrow{R_{2}\\leftarrow R_{2}+2R_{1},\\;R_{3}\\leftarrow R_{3}-3R_{1}}\\;\n\\begin{pmatrix}\n1  2  1  0 \\\\\n0  0  3  -3 \\\\\n0  0  -2  2\n\\end{pmatrix}.\n$$\nNormalize the pivot in column $3$ and eliminate below and above:\n$$\n\\begin{pmatrix}\n1  2  1  0 \\\\\n0  0  3  -3 \\\\\n0  0  -2  2\n\\end{pmatrix}\n\\;\\xrightarrow{R_{2}\\leftarrow \\frac{1}{3}R_{2}}\\;\n\\begin{pmatrix}\n1  2  1  0 \\\\\n0  0  1  -1 \\\\\n0  0  -2  2\n\\end{pmatrix}\n\\;\\xrightarrow{R_{3}\\leftarrow R_{3}+2R_{2}}\\;\n\\begin{pmatrix}\n1  2  1  0 \\\\\n0  0  1  -1 \\\\\n0  0  0  0\n\\end{pmatrix}\n\\;\\xrightarrow{R_{1}\\leftarrow R_{1}-R_{2}}\\;\n\\begin{pmatrix}\n1  2  0  1 \\\\\n0  0  1  -1 \\\\\n0  0  0  0\n\\end{pmatrix}.\n$$\nThis is in reduced row echelon form. The leading $1$’s (pivots) are in columns $1$ and $3$. Therefore, the pivot columns of the original matrix $A$ are columns $1$ and $3$, and these columns form a basis for $\\text{Col}(A)$, ordered by their appearance in $A$:\n$$\n\\begin{pmatrix}\n1  1 \\\\\n-2  1 \\\\\n3  1\n\\end{pmatrix}.\n$$", "answer": "$$\\boxed{\\begin{pmatrix}1  1 \\\\ -2  1 \\\\ 3  1\\end{pmatrix}}$$", "id": "1354326"}, {"introduction": "After learning how to compute a basis, we can explore deeper properties of a matrix's fundamental subspaces. This thought experiment investigates the surprising and restrictive conditions that must be met for a matrix's column space, $\\text{Col}(A)$, to be identical to its null space, $\\text{Nul}(A)$. Solving this problem requires a clear understanding of the definitions of these spaces and a key result in linear algebra: the rank-nullity theorem [@problem_id:1354309].", "problem": "Let $A$ be a matrix of size $m \\times n$ with real entries. The column space of $A$, denoted $\\text{Col}(A)$, is the subspace of $\\mathbb{R}^m$ spanned by the columns of $A$. The null space of $A$, denoted $\\text{Nul}(A)$, is the subspace of $\\mathbb{R}^n$ consisting of all vectors $\\vec{x}$ such that $A\\vec{x} = \\vec{0}$.\n\nConsider the specific condition that the column space of $A$ is exactly equal to the null space of $A$, i.e., $\\text{Col}(A) = \\text{Nul}(A)$. Which one of the following statements must be true for any matrix $A$ that satisfies this condition?\n\nA. The matrix $A$ must be a square matrix ($m=n$) and its number of columns $n$ must be an even integer.\n\nB. The matrix $A$ must be a non-square matrix ($m \\neq n$) and its number of columns $n$ must be an even integer.\n\nC. The matrix $A$ must be the zero matrix.\n\nD. Such a matrix $A$ cannot exist.\n\nE. The matrix $A$ must be a square matrix ($m=n$) and its number of columns $n$ can be any positive integer.", "solution": "Let $A$ be an $m \\times n$ real matrix. By definition, $\\text{Col}(A) \\subseteq \\mathbb{R}^{m}$ and $\\text{Nul}(A) \\subseteq \\mathbb{R}^{n}$. If $\\text{Col}(A) = \\text{Nul}(A)$ as subspaces, then they must lie in the same ambient space, which forces $m = n$. Thus $A$ must be square.\n\nLet $r = \\operatorname{rank}(A) = \\dim(\\text{Col}(A))$. By the rank-nullity theorem for the linear transformation $T:\\mathbb{R}^{n} \\to \\mathbb{R}^{n}$ defined by $A$, we have\n$$\n\\dim(\\text{Col}(A)) + \\dim(\\text{Nul}(A)) = n,\n$$\nthat is,\n$$\nr + \\dim(\\text{Nul}(A)) = n.\n$$\nGiven the condition $\\text{Col}(A) = \\text{Nul}(A)$, their dimensions are equal:\n$$\n\\dim(\\text{Nul}(A)) = \\dim(\\text{Col}(A)) = r.\n$$\nHence\n$$\nr + r = n \\implies 2r = n,\n$$\nso $n$ must be an even integer.\n\nTherefore, any matrix $A$ with $\\text{Col}(A) = \\text{Nul}(A)$ must be square and have an even number of columns. This eliminates options B, C, D, and E:\n- B is false because $m \\neq n$ contradicts equality of subspaces in different ambient spaces.\n- C is false since the zero matrix has $\\text{Col}(A) = \\{0\\}$ and $\\text{Nul}(A) = \\mathbb{R}^{n}$, which are equal only if $n=0$.\n- D is false because such matrices exist for even $n$; for example, a block diagonal matrix with $\\frac{n}{2}$ Jordan blocks $\\begin{pmatrix}0  1 \\\\ 0  0\\end{pmatrix}$ satisfies $\\text{Col}(A) = \\text{Nul}(A)$.\n- E is false because $n$ cannot be any positive integer; it must be even.\n\nThus, the statement that must be true is that $A$ is square and $n$ is even.", "answer": "$$\\boxed{A}$$", "id": "1354309"}, {"introduction": "A powerful application of our understanding of subspaces is to analyze how they relate to one another, for example, by finding their intersection. This exercise presents a robust procedure for finding a basis for the intersection of two column spaces, $\\text{Col}(A) \\cap \\text{Col}(B)$. The method involves setting up a homogeneous system of equations that cleverly combines the two matrices, providing a practical tool for more advanced problems in linear algebra [@problem_id:1354270].", "problem": "Consider the vector space $\\mathbb{R}^4$. Let $U$ be the subspace spanned by the columns of matrix $A$, and let $W$ be the subspace spanned by the columns of matrix $B$, where\n$$\nA = \\begin{pmatrix} 1  0 \\\\ 0  1 \\\\ 1  0 \\\\ 0  1 \\end{pmatrix} \\quad \\text{and} \\quad B = \\begin{pmatrix} 2  1 \\\\ 1  0 \\\\ 0  -1 \\\\ 2  1 \\end{pmatrix}.\n$$\nThese subspaces $U$ and $W$ are also known as the column spaces, $\\text{Col}(A)$ and $\\text{Col}(B)$, respectively. Find a basis for the intersection of these two subspaces, $U \\cap W$.\n\nWhich of the following sets constitutes a basis for $U \\cap W$?\n\nA. $\\left\\{ \\begin{pmatrix} 1 \\\\ 1 \\\\ 1 \\\\ 1 \\end{pmatrix} \\right\\}$\n\nB. $\\left\\{ \\begin{pmatrix} 1 \\\\ 0 \\\\ 1 \\\\ 0 \\end{pmatrix} \\right\\}$\n\nC. $\\left\\{ \\begin{pmatrix} -1 \\\\ -1 \\\\ -1 \\\\ 1 \\end{pmatrix} \\right\\}$\n\nD. $\\left\\{ \\begin{pmatrix} 1 \\\\ 1 \\\\ 1 \\\\ 1 \\end{pmatrix}, \\begin{pmatrix} 1 \\\\ 0 \\\\ 1 \\\\ 0 \\end{pmatrix} \\right\\}$\n\nE. $\\left\\{ \\begin{pmatrix} 0 \\\\ 0 \\\\ 0 \\\\ 0 \\end{pmatrix} \\right\\}$", "solution": "A vector $\\mathbf{v}$ is in the intersection of the subspaces $U$ and $W$, denoted $U \\cap W$, if and only if $\\mathbf{v}$ is in both $U$ and $W$.\n\nA vector $\\mathbf{v}$ is in $U = \\text{Col}(A)$ if it can be written as a linear combination of the columns of $A$. That is, there exists a vector $\\mathbf{x} = \\begin{pmatrix} x_1 \\\\ x_2 \\end{pmatrix}$ such that $\\mathbf{v} = A\\mathbf{x}$.\n\nSimilarly, a vector $\\mathbf{v}$ is in $W = \\text{Col}(B)$ if there exists a vector $\\mathbf{y} = \\begin{pmatrix} y_1 \\\\ y_2 \\end{pmatrix}$ such that $\\mathbf{v} = B\\mathbf{y}$.\n\nFor a vector $\\mathbf{v}$ to be in the intersection, we must have $A\\mathbf{x} = B\\mathbf{y}$ for some coefficient vectors $\\mathbf{x}$ and $\\mathbf{y}$. This equation can be rewritten as a homogeneous linear system:\n$$\nA\\mathbf{x} - B\\mathbf{y} = \\mathbf{0}\n$$\nWe can express this in matrix form as:\n$$\n\\begin{pmatrix} A  -B \\end{pmatrix} \\begin{pmatrix} \\mathbf{x} \\\\ \\mathbf{y} \\end{pmatrix} = \\mathbf{0}\n$$\nLet's construct the augmented matrix $M = \\begin{pmatrix} A  -B \\end{pmatrix}$:\n$$\nM = \\left( \\begin{array}{cc|cc} 1  0  -2  -1 \\\\ 0  1  -1  0 \\\\ 1  0  0  1 \\\\ 0  1  -2  -1 \\end{array} \\right)\n$$\nTo find the vectors $\\begin{pmatrix} \\mathbf{x} \\\\ \\mathbf{y} \\end{pmatrix}$ that satisfy the equation, we need to find the null space of $M$. We do this by reducing $M$ to its reduced row echelon form (RREF).\n\nLet's start the row reduction process.\n$R_3 \\to R_3 - R_1$:\n$$\n\\left( \\begin{array}{cccc} 1  0  -2  -1 \\\\ 0  1  -1  0 \\\\ 0  0  2  2 \\\\ 0  1  -2  -1 \\end{array} \\right)\n$$\n$R_4 \\to R_4 - R_2$:\n$$\n\\left( \\begin{array}{cccc} 1  0  -2  -1 \\\\ 0  1  -1  0 \\\\ 0  0  2  2 \\\\ 0  0  -1  -1 \\end{array} \\right)\n$$\n$R_3 \\to \\frac{1}{2}R_3$:\n$$\n\\left( \\begin{array}{cccc} 1  0  -2  -1 \\\\ 0  1  -1  0 \\\\ 0  0  1  1 \\\\ 0  0  -1  -1 \\end{array} \\right)\n$$\n$R_4 \\to R_4 + R_3$:\n$$\n\\left( \\begin{array}{cccc} 1  0  -2  -1 \\\\ 0  1  -1  0 \\\\ 0  0  1  1 \\\\ 0  0  0  0 \\end{array} \\right)\n$$\nThis is the row echelon form. To get the RREF, we eliminate the non-zero entries above the pivots.\n$R_1 \\to R_1 + 2R_3$:\n$$\n\\left( \\begin{array}{cccc} 1  0  0  1 \\\\ 0  1  -1  0 \\\\ 0  0  1  1 \\\\ 0  0  0  0 \\end{array} \\right)\n$$\n$R_2 \\to R_2 + R_3$:\n$$\n\\left( \\begin{array}{cccc} 1  0  0  1 \\\\ 0  1  0  1 \\\\ 0  0  1  1 \\\\ 0  0  0  0 \\end{array} \\right)\n$$\nThis is the RREF of $M$. The system of equations for the null space vector $\\begin{pmatrix} x_1  x_2  y_1  y_2 \\end{pmatrix}^T$ is:\n$x_1 + y_2 = 0 \\implies x_1 = -y_2$\n$x_2 + y_2 = 0 \\implies x_2 = -y_2$\n$y_1 + y_2 = 0 \\implies y_1 = -y_2$\nThe variable $y_2$ is a free variable. Let $y_2 = t$ for some scalar $t$. Then the general solution is:\n$$\n\\begin{pmatrix} x_1 \\\\ x_2 \\\\ y_1 \\\\ y_2 \\end{pmatrix} = \\begin{pmatrix} -t \\\\ -t \\\\ -t \\\\ t \\end{pmatrix} = t \\begin{pmatrix} -1 \\\\ -1 \\\\ -1 \\\\ 1 \\end{pmatrix}\n$$\nThe null space of $M$ is a one-dimensional subspace spanned by the vector $\\begin{pmatrix} -1  -1  -1  1 \\end{pmatrix}^T$. This vector provides the coefficients for the linear combinations.\n\nTo find the actual basis vectors for the intersection $U \\cap W$, we use these coefficients. We can either calculate $A\\mathbf{x}$ or $B\\mathbf{y}$. Let's use $A\\mathbf{x}$. From the basis vector of the null space, we have $\\mathbf{x} = \\begin{pmatrix} x_1 \\\\ x_2 \\end{pmatrix} = \\begin{pmatrix} -1 \\\\ -1 \\end{pmatrix}$.\n$$\n\\mathbf{v} = A\\mathbf{x} = \\begin{pmatrix} 1  0 \\\\ 0  1 \\\\ 1  0 \\\\ 0  1 \\end{pmatrix} \\begin{pmatrix} -1 \\\\ -1 \\end{pmatrix} = \\begin{pmatrix} (1)(-1) + (0)(-1) \\\\ (0)(-1) + (1)(-1) \\\\ (1)(-1) + (0)(-1) \\\\ (0)(-1) + (1)(-1) \\end{pmatrix} = \\begin{pmatrix} -1 \\\\ -1 \\\\ -1 \\\\ -1 \\end{pmatrix}\n$$\nAs a check, let's use $B\\mathbf{y}$. From the basis vector of the null space, we have $\\mathbf{y} = \\begin{pmatrix} y_1 \\\\ y_2 \\end{pmatrix} = \\begin{pmatrix} -1 \\\\ 1 \\end{pmatrix}$.\n$$\n\\mathbf{v} = B\\mathbf{y} = \\begin{pmatrix} 2  1 \\\\ 1  0 \\\\ 0  -1 \\\\ 2  1 \\end{pmatrix} \\begin{pmatrix} -1 \\\\ 1 \\end{pmatrix} = \\begin{pmatrix} (2)(-1) + (1)(1) \\\\ (1)(-1) + (0)(1) \\\\ (0)(-1) + (-1)(1) \\\\ (2)(-1) + (1)(1) \\end{pmatrix} = \\begin{pmatrix} -1 \\\\ -1 \\\\ -1 \\\\ -1 \\end{pmatrix}\n$$\nBoth calculations yield the same vector, as expected. The intersection $U \\cap W$ is the set of all scalar multiples of this vector. A basis for this one-dimensional subspace is any non-zero vector in it.\nSo, a basis for $U \\cap W$ is $\\left\\{ \\begin{pmatrix} -1 \\\\ -1 \\\\ -1 \\\\ -1 \\end{pmatrix} \\right\\}$.\n\nAny non-zero scalar multiple of this vector is also a valid basis. Option A provides the vector $\\begin{pmatrix} 1 \\\\ 1 \\\\ 1 \\\\ 1 \\end{pmatrix}$, which is $-1$ times our calculated basis vector. Thus, it is a valid basis for the intersection.\n\nLet's review the other options:\nB. The vector $\\begin{pmatrix} 1 \\\\ 0 \\\\ 1 \\\\ 0 \\end{pmatrix}$ is the first column of $A$. It is not in $\\text{Col}(B)$ because the system $B\\mathbf{y} = \\begin{pmatrix} 1 \\\\ 0 \\\\ 1 \\\\ 0 \\end{pmatrix}$ is inconsistent.\nC. The vector $\\begin{pmatrix} -1 \\\\ -1 \\\\ -1 \\\\ 1 \\end{pmatrix}$ is a basis vector for the null space of $\\begin{pmatrix} A  -B \\end{pmatrix}$. This vector of coefficients is in $\\mathbb{R}^4$, but it is not an element of the intersection $U \\cap W$. This is a common mistake.\nD. This set contains two vectors. Since we found the dimension of the intersection to be 1, a basis cannot contain two vectors.\nE. This is the trivial subspace. We found a non-zero vector in the intersection, so the intersection is non-trivial.\n\nTherefore, the correct choice is A.", "answer": "$$\\boxed{A}$$", "id": "1354270"}]}