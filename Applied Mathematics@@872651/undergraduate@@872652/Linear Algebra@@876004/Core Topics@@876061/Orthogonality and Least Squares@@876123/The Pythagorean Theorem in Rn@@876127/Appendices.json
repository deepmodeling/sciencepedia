{"hands_on_practices": [{"introduction": "This exercise serves as a fundamental check of your understanding. Before we can apply the Pythagorean theorem in $\\mathbb{R}^n$, we must ensure its core condition—orthogonality—is met. This problem guides you through first establishing orthogonality between two vectors and then directly using the theorem to find the length of their sum, reinforcing the direct link between the geometric concept of perpendicularity and the algebraic condition $u \\cdot v = 0$ [@problem_id:1397488].", "problem": "Consider two vectors in the Euclidean space $\\mathbb{R}^3$, defined as $u = (1, 2, -3)$ and $v = (5, k, 1)$, where $k$ is an unknown real scalar. If the vectors $u$ and $v$ are orthogonal with respect to the standard dot product, what is the value of the squared Euclidean norm of their sum, $\\|u+v\\|^2$?", "solution": "Orthogonality under the standard dot product means $u \\cdot v = 0$. Compute the dot product:\n$$\nu \\cdot v = (1,2,-3)\\cdot(5,k,1) = 1\\cdot 5 + 2\\cdot k + (-3)\\cdot 1 = 5 + 2k - 3 = 2 + 2k.\n$$\nSet this equal to zero and solve for $k$:\n$$\n2 + 2k = 0 \\implies k = -1.\n$$\nThen the sum is\n$$\nu+v = (1+5,\\,2+(-1),\\,-3+1) = (6,\\,1,\\,-2).\n$$\nThe squared Euclidean norm is the dot product of the vector with itself:\n$$\n\\|u+v\\|^{2} = (6)^{2} + (1)^{2} + (-2)^{2} = 36 + 1 + 4 = 41.\n$$\nAs a consistency check, using the identity $\\|u+v\\|^{2} = \\|u\\|^{2} + \\|v\\|^{2} + 2\\,u\\cdot v$ and $u\\cdot v=0$ gives $\\|u+v\\|^{2} = \\|u\\|^{2} + \\|v\\|^{2} = (1^{2}+2^{2}+(-3)^{2}) + (5^{2}+(-1)^{2}+1^{2}) = 14 + 27 = 41$, which agrees.", "answer": "$$\\boxed{41}$$", "id": "1397488"}, {"introduction": "The power of the Pythagorean theorem in higher dimensions extends beyond just two vectors. This practice demonstrates how the theorem generalizes to find the squared norm of a linear combination of any number of mutually orthogonal vectors [@problem_id:1397523]. By seeing that all cross-product terms in the expansion of $\\| \\sum c_i v_i \\|^2$ vanish due to orthogonality, you will gain a deeper appreciation for the structure and simplicity that orthogonal bases bring to vector computations.", "problem": "Let $u$, $v$, and $w$ be three mutually orthogonal vectors in the Euclidean space $\\mathbb{R}^n$. The norms of these vectors are given as $\\|u\\| = 2$, $\\|v\\| = 4$, and $\\|w\\| = 5$. Consider a new vector $z$ defined by the linear combination $z = 3u - 2v + w$.\n\nCalculate the squared norm of the vector $z$, denoted as $\\|z\\|^2$.", "solution": "Let $u,v,w \\in \\mathbb{R}^{n}$ be mutually orthogonal, so $u \\cdot v = u \\cdot w = v \\cdot w = 0$. Define $z = 3u - 2v + w$. By definition of the squared norm,\n$$\n\\|z\\|^{2} = z \\cdot z = (3u - 2v + w) \\cdot (3u - 2v + w).\n$$\nUsing bilinearity and the identity $(a+b+c)\\cdot(a+b+c) = a\\cdot a + b\\cdot b + c\\cdot c + 2(a\\cdot b + a\\cdot c + b\\cdot c)$, set $a=3u$, $b=-2v$, $c=w$ to obtain\n$$\n\\|z\\|^{2} = (3u)\\cdot(3u) + (-2v)\\cdot(-2v) + w\\cdot w + 2\\big[(3u)\\cdot(-2v) + (3u)\\cdot w + (-2v)\\cdot w\\big].\n$$\nOrthogonality implies the cross terms vanish, so\n$$\n\\|z\\|^{2} = 9(u\\cdot u) + 4(v\\cdot v) + (w\\cdot w) = 9\\|u\\|^{2} + 4\\|v\\|^{2} + \\|w\\|^{2}.\n$$\nSubstitute the given norms $\\|u\\|=2$, $\\|v\\|=4$, $\\|w\\|=5$:\n$$\n\\|z\\|^{2} = 9\\cdot 2^{2} + 4\\cdot 4^{2} + 5^{2} = 9\\cdot 4 + 4\\cdot 16 + 25 = 36 + 64 + 25 = 125.\n$$\nTherefore, the squared norm of $z$ is $125$.", "answer": "$$\\boxed{125}$$", "id": "1397523"}, {"introduction": "One of the most powerful applications of orthogonality is in vector decomposition, where we break a vector down into components along specific directions or within subspaces. This problem explores the relationship between a vector and its orthogonal projections, using the Pythagorean theorem to analyze how a vector's \"energy,\" represented by its squared norm, is distributed across orthogonal subspaces [@problem_id:1397486]. This concept is not merely abstract; it forms the bedrock of methods like the Gram-Schmidt process and least-squares approximations, which are essential in fields from data science to engineering.", "problem": "Consider the vector space $\\mathbb{R}^4$ equipped with the standard dot product, which is defined as $u \\cdot v = u_1 v_1 + u_2 v_2 + u_3 v_3 + u_4 v_4$ for vectors $u = (u_1, u_2, u_3, u_4)$ and $v = (v_1, v_2, v_3, v_4)$. The norm of a vector $v$ is given by $\\|v\\| = \\sqrt{v \\cdot v}$.\n\nLet the vector $v$ be defined as $v = (3, 1, -1, 3)$.\n\nLet $W_1$ be the subspace of $\\mathbb{R}^4$ spanned by the set of vectors $\\{b_1, b_2\\}$, where $b_1 = (1, 0, 1, 0)$ and $b_2 = (0, 1, 0, 1)$.\nLet $W_2$ be the subspace of $\\mathbb{R}^4$ spanned by the vector $b_3 = (1, 0, -1, 0)$.\n\nLet $p_1$ be the orthogonal projection of the vector $v$ onto the subspace $W_1$, and let $p_2$ be the orthogonal projection of $v$ onto the subspace $W_2$.\n\nCalculate the value of the quantity $\\Delta = \\|v\\|^2 - (\\|p_1\\|^2 + \\|p_2\\|^2)$.", "solution": "We use the standard dot product on $\\mathbb{R}^{4}$ and the projection formula. For any nonzero $b$, the orthogonal projection of $v$ onto $\\operatorname{span}\\{b\\}$ is $\\operatorname{proj}_{b}(v) = \\frac{v \\cdot b}{b \\cdot b} b$, and its squared norm is\n$$\n\\|\\operatorname{proj}_{b}(v)\\|^{2} = \\frac{(v \\cdot b)^{2}}{b \\cdot b}.\n$$\nFirst, verify orthogonality of the given spanning vectors:\n$$\nb_{1} \\cdot b_{2} = (1,0,1,0) \\cdot (0,1,0,1) = 0,\\quad\nb_{1} \\cdot b_{3} = (1,0,1,0) \\cdot (1,0,-1,0) = 1-1=0,\\quad\nb_{2} \\cdot b_{3} = (0,1,0,1) \\cdot (1,0,-1,0) = 0.\n$$\nThus $b_{1}, b_{2}, b_{3}$ are mutually orthogonal, with\n$$\n\\|b_{1}\\|^{2} = b_{1} \\cdot b_{1} = 2,\\quad \\|b_{2}\\|^{2} = 2,\\quad \\|b_{3}\\|^{2} = 2.\n$$\nCompute the inner products with $v=(3,1,-1,3)$:\n$$\nv \\cdot b_{1} = (3,1,-1,3) \\cdot (1,0,1,0) = 3+(-1)=2,\\quad\nv \\cdot b_{2} = (3,1,-1,3) \\cdot (0,1,0,1) = 1+3=4,\\quad\nv \\cdot b_{3} = (3,1,-1,3) \\cdot (1,0,-1,0) = 3+1=4.\n$$\nSince $W_{1}=\\operatorname{span}\\{b_{1},b_{2}\\}$ with an orthogonal basis, the squared norm of the projection $p_{1}$ is\n$$\n\\|p_{1}\\|^{2} \\;=\\; \\frac{(v \\cdot b_{1})^{2}}{\\|b_{1}\\|^{2}} \\;+\\; \\frac{(v \\cdot b_{2})^{2}}{\\|b_{2}\\|^{2}}\n\\;=\\; \\frac{2^{2}}{2} + \\frac{4^{2}}{2} \\;=\\; 2 + 8 \\;=\\; 10.\n$$\nFor $W_{2}=\\operatorname{span}\\{b_{3}\\}$, the squared norm of the projection $p_{2}$ is\n$$\n\\|p_{2}\\|^{2} \\;=\\; \\frac{(v \\cdot b_{3})^{2}}{\\|b_{3}\\|^{2}} \\;=\\; \\frac{4^{2}}{2} \\;=\\; 8.\n$$\nCompute the squared norm of $v$:\n$$\n\\|v\\|^{2} = 3^{2} + 1^{2} + (-1)^{2} + 3^{2} = 9+1+1+9 = 20.\n$$\nTherefore,\n$$\n\\Delta \\;=\\; \\|v\\|^{2} - \\left(\\|p_{1}\\|^{2} + \\|p_{2}\\|^{2}\\right) \\;=\\; 20 - (10+8) \\;=\\; 2.\n$$\nAs a consistency check, since $W_{1}$ and $W_{2}$ are orthogonal (because $b_{3}$ is orthogonal to $b_{1}$ and $b_{2}$), $\\Delta$ equals the squared norm of the projection of $v$ onto the orthogonal complement of $W_{1} \\oplus W_{2}$, which indeed equals $2$.", "answer": "$$\\boxed{2}$$", "id": "1397486"}]}