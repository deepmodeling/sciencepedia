{"hands_on_practices": [{"introduction": "Our first practice exercise provides an intuitive entry point into orthogonal complements. We consider a subspace $W$ in $\\mathbb{R}^4$ defined by a simple, single condition on its vectors' components. This problem [@problem_id:1380272] illustrates how the algebraic definition of the orthogonal complement, $W^{\\perp}$, often corresponds to a clear geometric conceptâ€”in this case, the line spanned by the normal vector to a hyperplane.", "problem": "Consider the vector space $\\mathbb{R}^4$ equipped with the standard Euclidean dot product. Let $W$ be the subspace of all vectors $\\mathbf{x} = (x_1, x_2, x_3, x_4)$ in $\\mathbb{R}^4$ whose components sum to zero. The orthogonal complement of $W$, denoted by $W^{\\perp}$, is the set of all vectors in $\\mathbb{R}^4$ that are orthogonal to every vector in $W$.\n\nWhich of the following sets constitutes a basis for the subspace $W^{\\perp}$?\n\nA. $\\{(1, 1, 1, 1)\\}$\n\nB. $\\{(1, -1, 0, 0), (0, 1, -1, 0), (0, 0, 1, -1)\\}$\n\nC. $\\{(1, 1, -1, -1)\\}$\n\nD. $\\{(1, 0, 0, 0), (0, 1, 0, 0), (0, 0, 1, 0), (0, 0, 0, 1)\\}$\n\nE. $\\{(0, 0, 0, 0)\\}$", "solution": "Let $W=\\{(x_{1},x_{2},x_{3},x_{4})\\in\\mathbb{R}^{4}:x_{1}+x_{2}+x_{3}+x_{4}=0\\}$ with the standard Euclidean dot product. By definition, $W^{\\perp}=\\{\\mathbf{v}\\in\\mathbb{R}^{4}:\\mathbf{v}\\cdot\\mathbf{w}=0\\text{ for all }\\mathbf{w}\\in W\\}$. Let $\\mathbf{v}=(a,b,c,d)\\in W^{\\perp}$. Since $(1,-1,0,0)\\in W$ (because $1-1+0+0=0$), orthogonality gives\n$$\n\\mathbf{v}\\cdot(1,-1,0,0)=a-b=0\\implies a=b.\n$$\nSimilarly, $(1,0,-1,0)\\in W$ and $(1,0,0,-1)\\in W$ yield\n$$\n\\mathbf{v}\\cdot(1,0,-1,0)=a-c=0\\implies a=c,\\quad \\mathbf{v}\\cdot(1,0,0,-1)=a-d=0\\implies a=d.\n$$\nThus $a=b=c=d$, so $\\mathbf{v}=t(1,1,1,1)$ for some scalar $t$. Conversely, if $\\mathbf{v}=t(1,1,1,1)$ and $\\mathbf{w}=(x_{1},x_{2},x_{3},x_{4})\\in W$, then\n$$\n\\mathbf{v}\\cdot\\mathbf{w}=t(x_{1}+x_{2}+x_{3}+x_{4})=t\\cdot 0=0,\n$$\nso every such $\\mathbf{v}$ lies in $W^{\\perp}$. Therefore,\n$$\nW^{\\perp}=\\operatorname{span}\\{(1,1,1,1)\\},\n$$\nwhich is one-dimensional, and a basis is given by $\\{(1,1,1,1)\\}$. Among the options, this corresponds to A. For completeness, the vectors in B and C lie in $W$ (their components sum to zero) rather than in $W^{\\perp}$, D spans all of $\\mathbb{R}^{4}$ and cannot be a basis for the one-dimensional $W^{\\perp}$, and E is not a basis since the zero vector cannot form a basis.", "answer": "$$\\boxed{A}$$", "id": "1380272"}, {"introduction": "Building on the conceptual foundation, this next exercise focuses on the core computational skill of finding vectors in an orthogonal complement. Here, the subspace $W$ is defined by a set of spanning vectors, a common scenario in linear algebra. To solve this problem [@problem_id:14920], you will translate the condition of orthogonality into a system of linear equations, a fundamental technique for working with subspaces.", "problem": "Consider the real vector space $V = \\mathbb{R}^4$ equipped with the standard Euclidean inner product (dot product). Let $W$ be a subspace of $V$ spanned by the vectors $\\mathbf{v}_1$ and $\\mathbf{v}_2$, where:\n$$\n\\mathbf{v}_1 = \\begin{pmatrix} 1 \\\\ 2 \\\\ 0 \\\\ 1 \\end{pmatrix}, \\quad \\mathbf{v}_2 = \\begin{pmatrix} 0 \\\\ 1 \\\\ 1 \\\\ -1 \\end{pmatrix}\n$$\nThe orthogonal complement of $W$, denoted as $W^\\perp$, is defined as the set of all vectors in $V$ that are orthogonal to every vector in $W$. That is:\n$$\nW^\\perp = \\{ \\mathbf{x} \\in V \\mid \\mathbf{x} \\cdot \\mathbf{w} = 0 \\text{ for all } \\mathbf{w} \\in W \\}\n$$\nGiven two symbolic constants, $a$ and $b$, derive the unique vector $\\mathbf{u} \\in W^\\perp$ whose third component is $a$ and whose fourth component is $b$.", "solution": "We seek a vector $u=(x_1,x_2,x_3,x_4)\\in W^\\perp$ with $x_3=a$ and $x_4=b$. Orthogonality to $\\mathbf v_1$ and $\\mathbf v_2$ gives\n$$u\\cdot v_1 = x_1 + 2x_2 + b = 0,$$\n$$u\\cdot v_2 = x_2 + a - b = 0.$$\nFrom the second equation,\n$$x_2 = b - a.$$\nSubstitute into the first:\n$$x_1 = -b - 2x_2 = -b - 2(b - a) = 2a - 3b.$$\nHence\n$$u = \\begin{pmatrix} 2a - 3b \\\\ b - a \\\\ a \\\\ b \\end{pmatrix}.$$", "answer": "$$\\boxed{\\begin{pmatrix}2a-3b \\\\ b-a \\\\ a \\\\ b\\end{pmatrix}}$$", "id": "14920"}, {"introduction": "To truly master the concept of orthogonality, we must see it in action beyond the familiar confines of Euclidean space. This final practice [@problem_id:1873488] takes us into the vector space of $2 \\times 2$ matrices, equipped with the Frobenius inner product. By finding the orthogonal complement of the subspace of diagonal matrices, you will solidify your understanding that orthogonality is a general property defined by any inner product, applicable to a wide variety of mathematical objects.", "problem": "Consider the vector space $V = M_2(\\mathbb{R})$ of all $2 \\times 2$ matrices with real entries. This space is equipped with the Frobenius inner product, defined for any two matrices $A, B \\in V$ as $\\langle A, B \\rangle = \\text{tr}(A^T B)$, where $\\text{tr}(M)$ denotes the trace of a matrix $M$ and $A^T$ is the transpose of $A$.\n\nLet $W$ be the subspace of $V$ consisting of all diagonal matrices. The orthogonal complement of $W$, denoted by $W^\\perp$, is the set of all matrices in $V$ that are orthogonal to every matrix in $W$.\n\nWhich of the following statements provides the correct description of the subspace $W^\\perp$?\n\nA. The subspace of all symmetric matrices in $V$.\n\nB. The subspace of all skew-symmetric matrices in $V$.\n\nC. The subspace of all matrices in $V$ with a trace of zero.\n\nD. The subspace of all matrices in $V$ with all main diagonal entries equal to zero.\n\nE. The subspace consisting only of the $2 \\times 2$ zero matrix.", "solution": "Let $V = M_{2}(\\mathbb{R})$ with inner product $\\langle A, B \\rangle = \\operatorname{tr}(A^{T}B)$. Let $W$ be the subspace of all diagonal matrices. We seek $W^{\\perp} = \\{A \\in V : \\langle A, D \\rangle = 0 \\text{ for all } D \\in W\\}$.\n\nTake an arbitrary matrix $A \\in V$ and write\n$$\nA = \\begin{pmatrix} a & b \\\\ c & d \\end{pmatrix}.\n$$\nAn arbitrary element of $W$ is a diagonal matrix\n$$\nD = \\begin{pmatrix} x & 0 \\\\ 0 & y \\end{pmatrix},\n$$\nwith $x, y \\in \\mathbb{R}$. Compute the inner product:\n$$\n\\langle A, D \\rangle = \\operatorname{tr}(A^{T}D).\n$$\nFirst compute $A^{T} = \\begin{pmatrix} a & c \\\\ b & d \\end{pmatrix}$. Then\n$$\nA^{T}D = \\begin{pmatrix} a & c \\\\ b & d \\end{pmatrix} \\begin{pmatrix} x & 0 \\\\ 0 & y \\end{pmatrix} = \\begin{pmatrix} ax & cy \\\\ bx & dy \\end{pmatrix}.\n$$\nTaking the trace gives\n$$\n\\operatorname{tr}(A^{T}D) = ax + dy.\n$$\nTherefore,\n$$\n\\langle A, D \\rangle = ax + dy.\n$$\nFor $A$ to be in $W^{\\perp}$, we require $\\langle A, D \\rangle = 0$ for all choices of $x, y \\in \\mathbb{R}$. The expression $ax + dy$ equals zero for all $x, y$ if and only if $a = 0$ and $d = 0$. The entries $b$ and $c$ are unrestricted.\n\nHence\n$$\nW^{\\perp} = \\left\\{ \\begin{pmatrix} 0 & b \\\\ c & 0 \\end{pmatrix} : b, c \\in \\mathbb{R} \\right\\},\n$$\nwhich is precisely the subspace of all matrices in $V$ with both main diagonal entries equal to zero. Among the given options, this corresponds to option D. The other options are not equal to this set: symmetric or skew-symmetric matrices are proper subsets or supersets of different nature, the trace-zero condition allows diagonal nonzero matrices with $x + y = 0$, and the zero matrix alone is too small.", "answer": "$$\\boxed{D}$$", "id": "1873488"}]}