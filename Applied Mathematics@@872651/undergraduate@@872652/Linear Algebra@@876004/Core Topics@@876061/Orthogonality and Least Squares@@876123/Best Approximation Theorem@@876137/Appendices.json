{"hands_on_practices": [{"introduction": "The Best Approximation Theorem provides a powerful geometric framework, but it's crucial to remember that concepts like 'distance' and 'orthogonality' are defined by the inner product. This first exercise moves beyond the standard dot product to a weighted inner product in $\\mathbb{R}^3$. By solving for the best approximation in this setting [@problem_id:1350609], you will practice the fundamental mechanics of orthogonal projection and reinforce the idea that geometric intuition must adapt to the underlying algebraic structure.", "problem": "Consider the real vector space $\\mathbb{R}^3$ equipped with a non-standard inner product defined by $\\langle \\mathbf{x}, \\mathbf{y} \\rangle = 3x_1y_1 + 2x_2y_2 + x_3y_3$ for any vectors $\\mathbf{x} = (x_1, x_2, x_3)$ and $\\mathbf{y} = (y_1, y_2, y_3)$ in $\\mathbb{R}^3$. Let $W$ be a subspace of $\\mathbb{R}^3$ spanned by the set of vectors $\\{\\mathbf{v}_1, \\mathbf{v}_2\\}$, where $\\mathbf{v}_1 = (1, 1, 1)$ and $\\mathbf{v}_2 = (0, 1, 2)$.\n\nGiven the vector $\\mathbf{u} = (1, 1, 0)$, determine the shortest distance between $\\mathbf{u}$ and the subspace $W$. The distance is defined by the norm induced by the given inner product, i.e., $d(\\mathbf{x}, \\mathbf{y}) = \\|\\mathbf{x} - \\mathbf{y}\\| = \\sqrt{\\langle \\mathbf{x} - \\mathbf{y}, \\mathbf{x} - \\mathbf{y} \\rangle}$.\n\nExpress your answer as a single real number, rounded to three significant figures.", "solution": "We work in $\\mathbb{R}^{3}$ with inner product $\\langle \\mathbf{x}, \\mathbf{y} \\rangle = 3x_{1}y_{1} + 2x_{2}y_{2} + x_{3}y_{3}$, inducing the norm $\\|\\mathbf{x}\\| = \\sqrt{\\langle \\mathbf{x}, \\mathbf{x} \\rangle}$. The shortest distance from $\\mathbf{u}$ to $W$ is $\\|\\mathbf{u} - \\mathbf{p}\\|$, where $\\mathbf{p}$ is the orthogonal projection of $\\mathbf{u}$ onto $W = \\operatorname{span}\\{\\mathbf{v}_{1}, \\mathbf{v}_{2}\\}$ with respect to this inner product. The projection $\\mathbf{p}$ satisfies $\\langle \\mathbf{u} - \\mathbf{p}, \\mathbf{v}_{i} \\rangle = 0$ for $i=1,2$. Writing $\\mathbf{p} = a_{1}\\mathbf{v}_{1} + a_{2}\\mathbf{v}_{2}$, the coefficients solve the normal equations $G\\mathbf{a} = \\mathbf{b}$, where $G_{ij} = \\langle \\mathbf{v}_{i}, \\mathbf{v}_{j} \\rangle$ and $b_{i} = \\langle \\mathbf{u}, \\mathbf{v}_{i} \\rangle$.\n\nWith $\\mathbf{v}_{1} = (1,1,1)$, $\\mathbf{v}_{2} = (0,1,2)$, and $\\mathbf{u} = (1,1,0)$, compute\n$$\ng_{11} = \\langle \\mathbf{v}_{1}, \\mathbf{v}_{1} \\rangle = 3+2+1 = 6,\\quad\ng_{12} = \\langle \\mathbf{v}_{1}, \\mathbf{v}_{2} \\rangle = 0+2+2 = 4,\\quad\ng_{22} = \\langle \\mathbf{v}_{2}, \\mathbf{v}_{2} \\rangle = 0+2+4 = 6,\n$$\nso $G = \\begin{pmatrix}6 & 4 \\\\ 4 & 6\\end{pmatrix}$. Also\n$$\nb_{1} = \\langle \\mathbf{u}, \\mathbf{v}_{1} \\rangle = 3+2+0 = 5,\\quad\nb_{2} = \\langle \\mathbf{u}, \\mathbf{v}_{2} \\rangle = 0+2+0 = 2,\n$$\nso $\\mathbf{b} = \\begin{pmatrix}5 \\\\ 2\\end{pmatrix}$. Solve\n$$\n\\begin{pmatrix}6 & 4 \\\\ 4 & 6\\end{pmatrix}\\begin{pmatrix}a_{1} \\\\ a_{2}\\end{pmatrix} = \\begin{pmatrix}5 \\\\ 2\\end{pmatrix}.\n$$\nFrom $6a_{1}+4a_{2}=5$ and $4a_{1}+6a_{2}=2$, subtraction gives $2a_{1}-2a_{2}=3$, hence $a_{1}=a_{2}+\\frac{3}{2}$. Substituting into $4a_{1}+6a_{2}=2$ yields $10a_{2}+6=2$, so $a_{2}=-\\frac{2}{5}$ and $a_{1}=\\frac{11}{10}$.\n\nThus\n$$\n\\mathbf{p} = a_{1}\\mathbf{v}_{1}+a_{2}\\mathbf{v}_{2} = \\left(\\frac{11}{10},\\, \\frac{7}{10},\\, \\frac{3}{10}\\right),\n\\quad\n\\mathbf{r} = \\mathbf{u} - \\mathbf{p} = \\left(-\\frac{1}{10},\\, \\frac{3}{10},\\, -\\frac{3}{10}\\right).\n$$\nThe squared distance is\n$$\n\\|\\mathbf{r}\\|^{2} = \\langle \\mathbf{r}, \\mathbf{r} \\rangle = 3\\left(\\frac{1}{10}\\right)^{2} + 2\\left(\\frac{3}{10}\\right)^{2} + \\left(\\frac{3}{10}\\right)^{2} = \\frac{3}{100} + \\frac{18}{100} + \\frac{9}{100} = \\frac{3}{10}.\n$$\nTherefore the shortest distance is\n$$\n\\|\\mathbf{r}\\| = \\sqrt{\\frac{3}{10}}.\n$$\nNumerically, $\\sqrt{\\frac{3}{10}} \\approx 0.5477225575$, which rounded to three significant figures is $0.548$.", "answer": "$$\\boxed{0.548}$$", "id": "1350609"}, {"introduction": "The true power of the Best Approximation Theorem becomes apparent when we move from finite-dimensional vectors to infinite-dimensional function spaces. In this problem, we will treat continuous functions as vectors and use an inner product defined by an integral to find the best polynomial approximation for $f(t) = \\exp(t)$. This practice [@problem_id:1350611] bridges linear algebra and calculus, demonstrating a fundamental technique used in numerical analysis and signal processing.", "problem": "Let $V$ be the vector space of continuous real-valued functions defined on the interval $[-1, 1]$. This space is endowed with the inner product defined by $\\langle f, g \\rangle = \\int_{-1}^{1} f(t)g(t) dt$.\n\nConsider the subspace $W$ of $V$ which consists of all quadratic polynomials $p(t)$ that satisfy the condition $p(0) = 0$.\n\nYour task is to find the specific polynomial $p(t)$ in the subspace $W$ that provides the best approximation to the function $f(t) = \\exp(t)$ over the interval $[-1, 1]$. The \"best approximation\" is defined as the polynomial $p(t) \\in W$ that minimizes the squared distance $\\| f - p \\|^2$, where the norm $\\| \\cdot \\|$ is induced by the given inner product.\n\nExpress your answer as a polynomial in the variable $t$.", "solution": "We seek the orthogonal projection of $f(t)=\\exp(t)$ onto the subspace $W=\\{p(t)=a t + b t^{2}\\}$ of $V$, with inner product $\\langle f,g\\rangle=\\int_{-1}^{1} f(t)g(t)\\,dt$. By the orthogonality principle for best approximation in an inner product space, the error $f-p$ must be orthogonal to $W$. Using the basis $\\{t,t^{2}\\}$ of $W$, this gives the normal equations\n$$\n\\langle \\exp - (a t + b t^{2}),\\, t\\rangle=0,\\qquad \\langle \\exp - (a t + b t^{2}),\\, t^{2}\\rangle=0.\n$$\nEquivalently,\n$$\n\\langle \\exp, t\\rangle = a \\langle t,t\\rangle + b \\langle t^{2},t\\rangle,\\qquad\n\\langle \\exp, t^{2}\\rangle = a \\langle t,t^{2}\\rangle + b \\langle t^{2},t^{2}\\rangle.\n$$\nCompute the Gram matrix entries:\n$$\n\\langle t,t\\rangle=\\int_{-1}^{1} t^{2}\\,dt=\\frac{2}{3},\\quad\n\\langle t^{2},t\\rangle=\\int_{-1}^{1} t^{3}\\,dt=0,\\quad\n\\langle t^{2},t^{2}\\rangle=\\int_{-1}^{1} t^{4}\\,dt=\\frac{2}{5}.\n$$\nThus the equations decouple to\n$$\na=\\frac{\\langle \\exp, t\\rangle}{\\langle t,t\\rangle},\\qquad b=\\frac{\\langle \\exp, t^{2}\\rangle}{\\langle t^{2},t^{2}\\rangle}.\n$$\nNow compute the needed inner products. First,\n$$\n\\langle \\exp, t\\rangle=\\int_{-1}^{1} t \\exp(t)\\,dt.\n$$\nUsing integration by parts with $u=t$, $dv=\\exp(t)\\,dt$ (so $du=dt$, $v=\\exp(t)$), we find\n$$\n\\int t \\exp(t)\\,dt = t \\exp(t) - \\int \\exp(t)\\,dt = (t-1)\\exp(t) + C,\n$$\nhence\n$$\n\\langle \\exp, t\\rangle = \\left[(t-1)\\exp(t)\\right]_{-1}^{1} = 0 - \\left[(-2)\\exp(-1)\\right] = 2 \\exp(-1).\n$$\nNext,\n$$\n\\langle \\exp, t^{2}\\rangle=\\int_{-1}^{1} t^{2} \\exp(t)\\,dt.\n$$\nIntegrating by parts with $u=t^{2}$, $dv=\\exp(t)\\,dt$ (so $du=2t\\,dt$, $v=\\exp(t)$), we obtain\n$$\n\\int t^{2} \\exp(t)\\,dt = t^{2} \\exp(t) - \\int 2 t \\exp(t)\\,dt.\n$$\nUsing the earlier result $\\int t \\exp(t)\\,dt = (t-1)\\exp(t)$, we get\n$$\n\\int t^{2} \\exp(t)\\,dt = t^{2} \\exp(t) - 2 (t-1)\\exp(t) = \\exp(t)\\,(t^{2} - 2 t + 2) + C,\n$$\ntherefore\n$$\n\\langle \\exp, t^{2}\\rangle = \\left[\\exp(t)\\,(t^{2} - 2 t + 2)\\right]_{-1}^{1} = \\exp(1)\\cdot 1 - \\exp(-1)\\cdot 5 = \\exp(1) - 5 \\exp(-1).\n$$\nSubstituting back,\n$$\na=\\frac{2 \\exp(-1)}{2/3}=3 \\exp(-1),\\qquad b=\\frac{\\exp(1) - 5 \\exp(-1)}{2/5}=\\frac{5}{2}\\bigl(\\exp(1) - 5 \\exp(-1)\\bigr).\n$$\nHence the best-approximating polynomial in $W$ is\n$$\np(t)=a t + b t^{2} = 3 \\exp(-1)\\, t + \\frac{5}{2}\\bigl(\\exp(1) - 5 \\exp(-1)\\bigr) t^{2}.\n$$\nThis polynomial satisfies $p(0)=0$ and minimizes $\\| \\exp - p \\|^{2}$ over $W$.", "answer": "$$\\boxed{3 \\exp(-1)\\, t + \\frac{5}{2}\\bigl(\\exp(1) - 5 \\exp(-1)\\bigr) t^{2}}$$", "id": "1350611"}, {"introduction": "Real-world applications often involve systems that change over time. This exercise models such a scenario, where a state vector follows a linear trajectory and we need to find the point in time when it is closest to a desired 'stable' subspace. To solve this [@problem_id:1350608], you will combine the concept of orthogonal projection with calculus-based optimization, illustrating how the Best Approximation Theorem can be a key component in solving dynamic problems.", "problem": "In a control systems simulation, the state of a component is described by a vector in $\\mathbb{R}^4$. A particular test protocol dictates that the component's state vector, $\\mathbf{y}(t)$, follows a linear trajectory over a parameter $t$. This trajectory is given by the equation $\\mathbf{y}(t) = \\mathbf{a} + t\\mathbf{b}$, where $\\mathbf{a}$ and $\\mathbf{b}$ are constant vectors in $\\mathbb{R}^4$.\n\nThe system has a designated \"stable operating region,\" which is a vector subspace $W$ of $\\mathbb{R}^4$. For optimal performance and safety, the component's state vector $\\mathbf{y}(t)$ should remain as close as possible to this subspace at all times. The distance between a vector and a subspace is defined as the minimum Euclidean distance from the vector to any point within the subspace.\n\nGiven the initial state vector $\\mathbf{a} = \\begin{pmatrix} 3 \\\\ 1 \\\\ 2 \\\\ 4 \\end{pmatrix}$, the direction vector $\\mathbf{b} = \\begin{pmatrix} 1 \\\\ 2 \\\\ 3 \\\\ 0 \\end{pmatrix}$, and the stable subspace $W$ defined as the span of the orthogonal vectors $\\mathbf{u}_1 = \\begin{pmatrix} 1 \\\\ 1 \\\\ 0 \\\\ 0 \\end{pmatrix}$ and $\\mathbf{u}_2 = \\begin{pmatrix} 0 \\\\ 0 \\\\ 1 \\\\ 1 \\end{pmatrix}$, determine the exact value of the parameter $t$ for which the state vector $\\mathbf{y}(t)$ is closest to the subspace $W$.", "solution": "We are given $\\mathbf{y}(t)=\\mathbf{a}+t\\mathbf{b}$ with $\\mathbf{a}=\\begin{pmatrix}3\\\\1\\\\2\\\\4\\end{pmatrix}$ and $\\mathbf{b}=\\begin{pmatrix}1\\\\2\\\\3\\\\0\\end{pmatrix}$, and the subspace $W=\\operatorname{span}\\{\\mathbf{u}_{1},\\mathbf{u}_{2}\\}$ where $\\mathbf{u}_{1}=\\begin{pmatrix}1\\\\1\\\\0\\\\0\\end{pmatrix}$ and $\\mathbf{u}_{2}=\\begin{pmatrix}0\\\\0\\\\1\\\\1\\end{pmatrix}$. Since $\\mathbf{u}_{1}\\perp\\mathbf{u}_{2}$, the orthogonal complement is $W^{\\perp}=\\{(x_{1},x_{2},x_{3},x_{4})^{\\top}:x_{1}+x_{2}=0,\\ x_{3}+x_{4}=0\\}=\\operatorname{span}\\{\\mathbf{w}_{1},\\mathbf{w}_{2}\\}$ with $\\mathbf{w}_{1}=\\begin{pmatrix}1\\\\-1\\\\0\\\\0\\end{pmatrix}$ and $\\mathbf{w}_{2}=\\begin{pmatrix}0\\\\0\\\\1\\\\-1\\end{pmatrix}$. The distance from $\\mathbf{y}(t)$ to $W$ equals the norm of the projection of $\\mathbf{y}(t)$ onto $W^{\\perp}$.\n\nBecause $\\mathbf{w}_{1}\\perp\\mathbf{w}_{2}$ and $\\mathbf{w}_{i}\\cdot\\mathbf{w}_{i}=2$, the orthogonal projection onto $W^{\\perp}$ is\n$$\nP_{W^{\\perp}}\\mathbf{v}=\\frac{\\mathbf{v}\\cdot\\mathbf{w}_{1}}{\\mathbf{w}_{1}\\cdot\\mathbf{w}_{1}}\\,\\mathbf{w}_{1}+\\frac{\\mathbf{v}\\cdot\\mathbf{w}_{2}}{\\mathbf{w}_{2}\\cdot\\mathbf{w}_{2}}\\,\\mathbf{w}_{2}\n=\\frac{\\mathbf{v}\\cdot\\mathbf{w}_{1}}{2}\\,\\mathbf{w}_{1}+\\frac{\\mathbf{v}\\cdot\\mathbf{w}_{2}}{2}\\,\\mathbf{w}_{2}.\n$$\nLet $\\mathbf{c}=P_{W^{\\perp}}\\mathbf{a}$ and $\\mathbf{d}=P_{W^{\\perp}}\\mathbf{b}$. Then $P_{W^{\\perp}}\\mathbf{y}(t)=\\mathbf{c}+t\\mathbf{d}$ and minimizing the distance to $W$ is equivalent to minimizing $\\|\\mathbf{c}+t\\mathbf{d}\\|$.\n\nCompute $\\mathbf{c}$:\n$$\n\\mathbf{a}\\cdot\\mathbf{w}_{1}=3-1=2,\\quad \\mathbf{a}\\cdot\\mathbf{w}_{2}=2-4=-2,\n$$\n$$\n\\mathbf{c}=\\frac{2}{2}\\mathbf{w}_{1}+\\frac{-2}{2}\\mathbf{w}_{2}=\\mathbf{w}_{1}-\\mathbf{w}_{2}=\\begin{pmatrix}1\\\\-1\\\\-1\\\\1\\end{pmatrix}.\n$$\n\nCompute $\\mathbf{d}$:\n$$\n\\mathbf{b}\\cdot\\mathbf{w}_{1}=1-2=-1,\\quad \\mathbf{b}\\cdot\\mathbf{w}_{2}=3-0=3,\n$$\n$$\n\\mathbf{d}=\\frac{-1}{2}\\mathbf{w}_{1}+\\frac{3}{2}\\mathbf{w}_{2}=\\begin{pmatrix}-\\frac{1}{2}\\\\ \\frac{1}{2}\\\\ \\frac{3}{2}\\\\ -\\frac{3}{2}\\end{pmatrix}.\n$$\n\nLet $f(t)=\\|\\mathbf{c}+t\\mathbf{d}\\|^{2}=(\\mathbf{c}+t\\mathbf{d})\\cdot(\\mathbf{c}+t\\mathbf{d})=\\mathbf{c}\\cdot\\mathbf{c}+2t\\,\\mathbf{c}\\cdot\\mathbf{d}+t^{2}\\mathbf{d}\\cdot\\mathbf{d}$. The minimizer satisfies $f'(t)=2\\,\\mathbf{c}\\cdot\\mathbf{d}+2t\\,\\mathbf{d}\\cdot\\mathbf{d}=0$, hence\n$$\nt^{\\ast}=-\\frac{\\mathbf{c}\\cdot\\mathbf{d}}{\\mathbf{d}\\cdot\\mathbf{d}}.\n$$\nCompute the inner products:\n$$\n\\mathbf{c}\\cdot\\mathbf{d}=1\\left(-\\frac{1}{2}\\right)+(-1)\\left(\\frac{1}{2}\\right)+(-1)\\left(\\frac{3}{2}\\right)+1\\left(-\\frac{3}{2}\\right)\n=-\\frac{1}{2}-\\frac{1}{2}-\\frac{3}{2}-\\frac{3}{2}=-4,\n$$\n$$\n\\mathbf{d}\\cdot\\mathbf{d}=\\left(\\frac{1}{2}\\right)^{2}+\\left(\\frac{1}{2}\\right)^{2}+\\left(\\frac{3}{2}\\right)^{2}+\\left(\\frac{3}{2}\\right)^{2}\n=\\frac{1}{4}+\\frac{1}{4}+\\frac{9}{4}+\\frac{9}{4}=\\frac{20}{4}=5.\n$$\nTherefore,\n$$\nt^{\\ast}=-\\frac{-4}{5}=\\frac{4}{5}.\n$$", "answer": "$$\\boxed{\\frac{4}{5}}$$", "id": "1350608"}]}