{"hands_on_practices": [{"introduction": "This problem tackles the foundational step of any least-squares analysis: translating a real-world modeling scenario into the language of linear algebra. By fitting a polynomial to a set of data points, you will practice constructing the normal equations, which provide the optimal solution. This exercise [@problem_id:1371660] builds a concrete link between an inconsistent system $A\\mathbf{x}=\\mathbf{b}$ and the practical task of data fitting.", "problem": "A signal processing engineer is analyzing a noisy signal. They hypothesize that a segment of the signal, $y(t)$, can be approximated by a quadratic polynomial of the form $p(t) = c_0 + c_1 t + c_2 t^2$, where $t$ is time in seconds. To determine the unknown coefficients $c_0, c_1, c_2$, the engineer has collected four data samples $(t_i, y_i)$:\n$$(0, 1.0), (1, 0.5), (2, 2.0), (3, 4.5)$$\nPlugging these data points into the model creates an over-determined system of linear equations $A\\mathbf{x} = \\mathbf{b}$, where $\\mathbf{x} = \\begin{pmatrix} c_0 \\\\ c_1 \\\\ c_2 \\end{pmatrix}$. The matrix $A$ is constructed using the basis functions of the polynomial evaluated at the sample times, and the vector $\\mathbf{b}$ contains the observed signal values.\n\nThe principle of least squares states that the best approximation is found when the error vector, $\\mathbf{e} = \\mathbf{b} - A\\mathbf{x}$, is orthogonal to the column space of $A$. This orthogonality condition translates into a solvable system of linear equations of the form $M\\mathbf{x} = \\mathbf{v}$.\n\nYour task is to determine the matrix $M$ and the vector $\\mathbf{v}$ for this system. Which of the following options represents the correct pair $(M, \\mathbf{v})$?\n\nA. $M = \\begin{pmatrix} 4 & 6 & 14 \\\\ 6 & 14 & 36 \\\\ 14 & 36 & 98 \\end{pmatrix}, \\mathbf{v} = \\begin{pmatrix} 8 \\\\ 18 \\\\ 49 \\end{pmatrix}$\n\nB. $M = \\begin{pmatrix} 14 & 36 & 98 \\\\ 36 & 98 & 258 \\\\ 98 & 258 & 794 \\end{pmatrix}, \\mathbf{v} = \\begin{pmatrix} 18 \\\\ 49 \\\\ 138.5 \\end{pmatrix}$\n\nC. $M = \\begin{pmatrix} 4 & 6 & 14 \\\\ 6 & 14 & 36 \\\\ 14 & 36 & 98 \\end{pmatrix}, \\mathbf{v} = \\begin{pmatrix} 8.0 \\\\ 18.0 \\\\ 45.0 \\end{pmatrix}$\n\nD. $M = \\begin{pmatrix} 4 & 6 & 14 \\\\ 6 & 14 & 36 \\\\ 14 & 36 & 98 \\end{pmatrix}, \\mathbf{v} = \\begin{pmatrix} 6 \\\\ 14 \\\\ 36 \\end{pmatrix}$\n\nE. $M = \\begin{pmatrix} 4 & 6 & 14 \\\\ 6 & 14 & 36 \\\\ 14 & 36 & 108 \\end{pmatrix}, \\mathbf{v} = \\begin{pmatrix} 8 \\\\ 18 \\\\ 49 \\end{pmatrix}$", "solution": "We model the data with $p(t)=c_{0}+c_{1}t+c_{2}t^{2}$. Using the sample times $t\\in\\{0,1,2,3\\}$, the design matrix $A$ has rows $[1,\\ t,\\ t^{2}]$ evaluated at each $t$, and $\\mathbf{b}$ collects the corresponding $y$-values:\n$$\nA=\\begin{pmatrix}\n1 & 0 & 0\\\\\n1 & 1 & 1\\\\\n1 & 2 & 4\\\\\n1 & 3 & 9\n\\end{pmatrix},\\qquad\n\\mathbf{b}=\\begin{pmatrix}\n1.0\\\\\n0.5\\\\\n2.0\\\\\n4.5\n\\end{pmatrix}.\n$$\nThe least-squares solution satisfies the normal equations\n$$\nA^{\\top}A\\,\\mathbf{x}=A^{\\top}\\mathbf{b},\n$$\nso $M=A^{\\top}A$ and $\\mathbf{v}=A^{\\top}\\mathbf{b}$.\n\nCompute the sums over the sample times $t_{i}\\in\\{0,1,2,3\\}$:\n$$\nS_{0}=\\sum 1=4,\\quad S_{1}=\\sum t_{i}=0+1+2+3=6,\\quad S_{2}=\\sum t_{i}^{2}=0+1+4+9=14,\n$$\n$$\nS_{3}=\\sum t_{i}^{3}=0+1+8+27=36,\\quad S_{4}=\\sum t_{i}^{4}=0+1+16+81=98.\n$$\nThus\n$$\nM=A^{\\top}A=\\begin{pmatrix}\nS_{0} & S_{1} & S_{2}\\\\\nS_{1} & S_{2} & S_{3}\\\\\nS_{2} & S_{3} & S_{4}\n\\end{pmatrix}\n=\\begin{pmatrix}\n4 & 6 & 14\\\\\n6 & 14 & 36\\\\\n14 & 36 & 98\n\\end{pmatrix}.\n$$\n\nNow compute $\\mathbf{v}=A^{\\top}\\mathbf{b}$ by components:\n$$\nv_{0}=\\sum y_{i}=1.0+0.5+2.0+4.5=8.0,\n$$\n$$\nv_{1}=\\sum t_{i}y_{i}=0\\cdot 1.0+1\\cdot 0.5+2\\cdot 2.0+3\\cdot 4.5=0.5+4.0+13.5=18.0,\n$$\n$$\nv_{2}=\\sum t_{i}^{2}y_{i}=0^{2}\\cdot 1.0+1^{2}\\cdot 0.5+2^{2}\\cdot 2.0+3^{2}\\cdot 4.5=0+0.5+8.0+40.5=49.0.\n$$\nTherefore,\n$$\n\\mathbf{v}=\\begin{pmatrix}8 \\\\ 18 \\\\ 49\\end{pmatrix}.\n$$\nComparing with the options, this corresponds to option A.", "answer": "$$\\boxed{A}$$", "id": "1371660"}, {"introduction": "Solving the normal equations can be computationally intensive, but what if our basis signals are chosen carefully? This practice explores a powerful special case where the columns of the matrix $A$ are orthogonal. You will discover how this orthogonality dramatically simplifies the problem by making the matrix $A^TA$ diagonal, turning a complex system of equations into a straightforward calculation and highlighting the immense value of orthogonal bases in computation and analysis [@problem_id:1371641].", "problem": "A laboratory instrument records a signal at four consecutive, equally spaced time intervals. The resulting measurements are compiled into a vector $b \\in \\mathbb{R}^4$. According to theory, a 'pure' signal, devoid of noise, must be a linear combination of three specific basis signals. These basis signals are given as the columns of the matrix $A$. The specific matrices are:\n$$\nA = \\begin{pmatrix} 1 & 1 & 1 \\\\ 1 & -1 & 1 \\\\ 1 & 1 & -1 \\\\ 1 & -1 & -1 \\end{pmatrix}, \\quad b = \\begin{pmatrix} 1 \\\\ 2 \\\\ 3 \\\\ 4 \\end{pmatrix}\n$$\nThe observed vector $b$ is presumed to be a pure signal corrupted by noise, and therefore does not lie in the subspace spanned by the columns of $A$. To recover the most likely pure signal, we must find the vector in the column space of $A$ that is closest to $b$. This is known as the orthogonal projection of $b$ onto the column space of $A$.\n\nFind the coordinate vector $\\hat{x} \\in \\mathbb{R}^3$ of this projection, relative to the basis given by the columns of $A$. Express your answer as an exact column vector.", "solution": "We seek the orthogonal projection of $b$ onto the column space of $A$, which is the least-squares solution $\\hat{x}$ of $A \\hat{x} \\approx b$. This satisfies the normal equations\n$$\nA^{T}A\\,\\hat{x} \\;=\\; A^{T}b.\n$$\nLet the columns of $A$ be $c_{1},c_{2},c_{3}$, where\n$$\nc_{1}=\\begin{pmatrix}1\\\\1\\\\1\\\\1\\end{pmatrix},\\quad\nc_{2}=\\begin{pmatrix}1\\\\-1\\\\1\\\\-1\\end{pmatrix},\\quad\nc_{3}=\\begin{pmatrix}1\\\\1\\\\-1\\\\-1\\end{pmatrix}.\n$$\nCompute the Gram matrix entries $c_{i}\\cdot c_{j}$:\n$$\nc_{1}\\cdot c_{1}=4,\\quad c_{2}\\cdot c_{2}=4,\\quad c_{3}\\cdot c_{3}=4,\n$$\n$$\nc_{1}\\cdot c_{2}=0,\\quad c_{1}\\cdot c_{3}=0,\\quad c_{2}\\cdot c_{3}=0.\n$$\nHence,\n$$\nA^{T}A \\;=\\; \\begin{pmatrix}4&0&0\\\\0&4&0\\\\0&0&4\\end{pmatrix} \\;=\\; 4I_{3}.\n$$\nNext compute $A^{T}b$, whose entries are $c_{i}\\cdot b$ with $b=\\begin{pmatrix}1\\\\2\\\\3\\\\4\\end{pmatrix}$:\n$$\nc_{1}\\cdot b = 1+2+3+4=10,\\quad\nc_{2}\\cdot b = 1-2+3-4=-2,\\quad\nc_{3}\\cdot b = 1+2-3-4=-4,\n$$\nso\n$$\nA^{T}b \\;=\\; \\begin{pmatrix}10\\\\-2\\\\-4\\end{pmatrix}.\n$$\nSolving the normal equations gives\n$$\n4I_{3}\\,\\hat{x} \\;=\\; \\begin{pmatrix}10\\\\-2\\\\-4\\end{pmatrix}\n\\;\\;\\Longrightarrow\\;\\;\n\\hat{x} \\;=\\; \\frac{1}{4}\\begin{pmatrix}10\\\\-2\\\\-4\\end{pmatrix}\n\\;=\\; \\begin{pmatrix}\\frac{5}{2} \\\\ -\\frac{1}{2} \\\\ -1\\end{pmatrix}.\n$$\nTherefore, the coordinate vector of the orthogonal projection of $b$ onto the column space of $A$, relative to the given basis, is $\\hat{x}=\\begin{pmatrix}\\frac{5}{2}\\\\ -\\frac{1}{2}\\\\ -1\\end{pmatrix}$.", "answer": "$$\\boxed{\\begin{pmatrix}\\frac{5}{2}\\\\ -\\frac{1}{2}\\\\ -1\\end{pmatrix}}$$", "id": "1371641"}, {"introduction": "While the normal equations provide a theoretical solution, directly computing $(A^T A)^{-1}$ can be numerically unstable for ill-conditioned matrices. This exercise introduces a more robust and efficient method used in modern computational software: the QR factorization. By leveraging the properties of orthogonal matrices, you will see how the normal equations $A^TA\\hat{\\mathbf{x}} = A^T\\mathbf{b}$ simplify to an equivalent upper-triangular system $R\\hat{\\mathbf{x}} = Q^T\\mathbf{b}$, providing a taste of how numerical linear algebra is applied in practice [@problem_id:1371662].", "problem": "Consider an overdetermined linear system $A\\mathbf{x} = \\mathbf{b}$, for which an exact solution for the vector $\\mathbf{x} = \\begin{pmatrix} x_1 & x_2 & x_3 \\end{pmatrix}^T$ may not exist. We are interested in finding the least-squares solution $\\hat{\\mathbf{x}}$, which is the vector that minimizes the Euclidean norm of the residual, $\\|A\\hat{\\mathbf{x}} - \\mathbf{b}\\|$. The matrix $A$ and vector $\\mathbf{b}$ for this problem are given as:\n$$\nA = \\begin{pmatrix} 1 & -1 & 1 \\\\ 1 & 0 & 0 \\\\ 1 & 1 & 1 \\\\ 1 & 2 & 4 \\end{pmatrix}, \\quad \\mathbf{b} = \\begin{pmatrix} 1 \\\\ 0 \\\\ 2 \\\\ 4 \\end{pmatrix}\n$$\nThe QR factorization of $A$ is provided as $A=QR$, where $Q$ is a matrix with orthonormal columns and $R$ is an upper-triangular matrix:\n$$\nQ = \\begin{pmatrix} \\frac{1}{2} & -\\frac{3\\sqrt{5}}{10} & \\frac{1}{2} \\\\ \\frac{1}{2} & -\\frac{\\sqrt{5}}{10} & -\\frac{1}{2} \\\\ \\frac{1}{2} & \\frac{\\sqrt{5}}{10} & -\\frac{1}{2} \\\\ \\frac{1}{2} & \\frac{3\\sqrt{5}}{10} & \\frac{1}{2} \\end{pmatrix}, \\quad R = \\begin{pmatrix} 2 & 1 & 3 \\\\ 0 & \\sqrt{5} & \\sqrt{5} \\\\ 0 & 0 & 2 \\end{pmatrix}\n$$\nThe normal equations $A^T A \\hat{\\mathbf{x}} = A^T \\mathbf{b}$ for this least-squares problem can be transformed, by leveraging the provided QR factorization, into an equivalent but much simpler upper-triangular system of the form $R\\hat{\\mathbf{x}} = \\mathbf{d}$.\n\nDetermine the vector $\\mathbf{d}$ in this simplified system. Express your answer as a column vector with exact entries.", "solution": "We seek the least-squares solution to $A\\mathbf{x}=\\mathbf{b}$ using the provided QR factorization $A=QR$, where $Q$ has orthonormal columns, i.e., $Q^{T}Q=I$. The normal equations are\n$$\nA^{T}A\\hat{\\mathbf{x}}=A^{T}\\mathbf{b}.\n$$\nSubstituting $A=QR$ gives\n$$\n(R^{T}Q^{T})(QR)\\hat{\\mathbf{x}}=R^{T}Q^{T}\\mathbf{b}\\quad\\Rightarrow\\quad R^{T}R\\hat{\\mathbf{x}}=R^{T}Q^{T}\\mathbf{b}.\n$$\nLeft-multiplying both sides by $(R^{T})^{-1}$ yields the equivalent upper-triangular system\n$$\nR\\hat{\\mathbf{x}}=Q^{T}\\mathbf{b}.\n$$\nTherefore the desired vector is $\\mathbf{d}=Q^{T}\\mathbf{b}$. With\n$$\nQ=\\begin{pmatrix}\n\\frac{1}{2} & -\\frac{3\\sqrt{5}}{10} & \\frac{1}{2} \\\\\n\\frac{1}{2} & -\\frac{\\sqrt{5}}{10} & -\\frac{1}{2} \\\\\n\\frac{1}{2} & \\frac{\\sqrt{5}}{10} & -\\frac{1}{2} \\\\\n\\frac{1}{2} & \\frac{3\\sqrt{5}}{10} & \\frac{1}{2}\n\\end{pmatrix},\\quad\n\\mathbf{b}=\\begin{pmatrix}1\\\\0\\\\2\\\\4\\end{pmatrix},\n$$\ncompute each component $d_{i}=(Q^{T}\\mathbf{b})_{i}=\\sum_{j=1}^{4}Q_{j,i}b_{j}$:\n$$\nd_{1}=\\frac{1}{2}\\cdot 1+\\frac{1}{2}\\cdot 0+\\frac{1}{2}\\cdot 2+\\frac{1}{2}\\cdot 4=\\frac{7}{2},\n$$\n$$\nd_{2}=-\\frac{3\\sqrt{5}}{10}\\cdot 1-\\frac{\\sqrt{5}}{10}\\cdot 0+\\frac{\\sqrt{5}}{10}\\cdot 2+\\frac{3\\sqrt{5}}{10}\\cdot 4\n=\\left(-3+0+2+12\\right)\\frac{\\sqrt{5}}{10}=\\frac{11\\sqrt{5}}{10},\n$$\n$$\nd_{3}=\\frac{1}{2}\\cdot 1-\\frac{1}{2}\\cdot 0-\\frac{1}{2}\\cdot 2+\\frac{1}{2}\\cdot 4=\\frac{3}{2}.\n$$\nThus,\n$$\n\\mathbf{d}=\\begin{pmatrix}\\frac{7}{2} \\\\ \\frac{11\\sqrt{5}}{10} \\\\ \\frac{3}{2}\\end{pmatrix}.\n$$", "answer": "$$\\boxed{\\begin{pmatrix}\\frac{7}{2}\\\\ \\frac{11\\sqrt{5}}{10}\\\\ \\frac{3}{2}\\end{pmatrix}}$$", "id": "1371662"}]}