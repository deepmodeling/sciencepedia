{"hands_on_practices": [{"introduction": "The power of a transition matrix lies in its ability to predict future states. This first exercise demonstrates how to calculate probabilities over multiple time steps by using matrix multiplication. You will see that even if a direct transition between two states is impossible in one step, a path may open up over a longer period, a key insight into the connectivity of a system [@problem_id:1375578].", "problem": "A simplified model for user navigation on a new social media platform considers three possible states a user can be in during any given minute:\n1.  **State 1: Browsing Feed**\n2.  **State 2: Creating a Post**\n3.  **State 3: Private Messaging**\n\nThe transitions between these states follow a Markov chain model. The one-step transition probabilities for a one-minute interval are given as follows:\n\n*   A user who is **Browsing Feed** has a 0.7 probability of continuing to browse, a 0.2 probability of starting to create a post, and a 0.1 probability of switching to private messaging.\n*   A user who is **Creating a Post** has a 0.4 probability of continuing to create and a 0.6 probability of returning to browse the feed. It is impossible for them to switch directly to private messaging in one minute.\n*   A user who is in **Private Messaging** has a 0.5 probability of remaining in messaging and a 0.5 probability of returning to browse the feed. It is impossible for them to switch directly to creating a post in one minute.\n\nSuppose a user is currently in the **'Creating a Post'** state. What is the probability that this user will be in the **'Private Messaging'** state after exactly two minutes? Express your answer as a decimal.", "solution": "Let the states be indexed as 1 for Browsing Feed, 2 for Creating a Post, and 3 for Private Messaging. Following the convention used in this article, we construct a column-stochastic transition matrix $T$, where the entry $T_{ij}$ is the probability of transitioning *to* state $i$ *from* state $j$. Based on the problem description:\n*   From State 1 (Browsing): Transitions to State 1 (0.7), State 2 (0.2), State 3 (0.1). This forms the first column.\n*   From State 2 (Creating): Transitions to State 1 (0.6), State 2 (0.4). This forms the second column.\n*   From State 3 (Messaging): Transitions to State 1 (0.5), State 3 (0.5). This forms the third column.\n\nThe resulting transition matrix $T$ is:\n$$\nT=\\begin{pmatrix}\n0.7 & 0.6 & 0.5 \\\\\n0.2 & 0.4 & 0 \\\\\n0.1 & 0 & 0.5\n\\end{pmatrix}\n$$\nWe are asked for the probability that a user starting in state 2 ('Creating a Post') will be in state 3 ('Private Messaging') after exactly two minutes. This probability is given by the entry $(T^2)_{32}$ of the matrix $T^2$. The entry $(T^k)_{ij}$ gives the probability of being in state $i$ after $k$ steps, starting from state $j$.\n\nWe can calculate the entry $(T^2)_{32}$ by taking the dot product of the 3rd row of $T$ and the 2nd column of $T$:\n$$\n(T^2)_{32} = \\sum_{k=1}^{3} T_{3k}T_{k2} = T_{31}T_{12} + T_{32}T_{22} + T_{33}T_{32}\n$$\nSubstituting the values from the matrix $T$:\n$$\n(T^2)_{32} = (0.1)(0.6) + (0)(0.4) + (0.5)(0) = 0.06\n$$\nAlternatively, a two-step path from state 2 to state 3 must go through an intermediate state. The only possible path is $2 \\to 1 \\to 3$. The probability of this path is the product of the probabilities of each step: $T_{12} \\times T_{31} = 0.6 \\times 0.1 = 0.06$. All other two-step paths from 2 to 3 have a probability of zero.", "answer": "$$\\boxed{0.06}$$", "id": "1375578"}, {"introduction": "Beyond predicting the next few steps, we are often interested in the long-term behavior of a system. This practice guides you through finding the steady-state distribution of a Markov chain, which describes the probabilities of being in each state after the system has run for a long time. You will solve the fundamental eigenvector equation $P\\pi = \\pi$ to find this equilibrium and uncover a perhaps surprising result about biased random walks on a symmetric structure [@problem_id:1375543].", "problem": "A particle moves on the four vertices of a square, which are labeled $V_1, V_2, V_3, V_4$ in counter-clockwise order. At each discrete time step, the particle must move from its current vertex to one of its two adjacent vertices. The movement rule is biased: from any vertex, the probability of moving to the adjacent vertex in the counter-clockwise direction is twice the probability of moving to the adjacent vertex in the clockwise direction. A particle cannot remain at its current vertex in a given step. Determine the long-term, steady-state probability distribution for the particle's location. Express your answer as a row vector $[p_1, p_2, p_3, p_4]$, where $p_i$ is the probability of finding the particle at vertex $V_i$.", "solution": "Let the state of the system be the location of the particle. The state space is $S = \\{V_1, V_2, V_3, V_4\\}$. We are looking for the steady-state probability distribution, which we can represent as a column vector $\\pi = [p_1, p_2, p_3, p_4]^T$, where $p_i$ is the long-term probability of finding the particle at vertex $V_i$. The sum of these probabilities must be 1, i.e., $p_1 + p_2 + p_3 + p_4 = 1$.\n\nFirst, we determine the transition probabilities. From any vertex, the particle can move to its counter-clockwise (ccw) neighbor or its clockwise (cw) neighbor. Let $p_{ccw}$ and $p_{cw}$ be the probabilities for these moves, respectively. The problem states that $p_{ccw} = 2 p_{cw}$. Since the particle must move to an adjacent vertex, the probabilities must sum to one: $p_{ccw} + p_{cw} = 1$.\nSubstituting the first relation into the second gives $2 p_{cw} + p_{cw} = 1$, which simplifies to $3 p_{cw} = 1$, so $p_{cw} = \\frac{1}{3}$. Consequently, $p_{ccw} = 2 \\times \\frac{1}{3} = \\frac{2}{3}$.\nThe probability of staying at the same vertex is 0.\n\nNext, we construct the transition matrix $P$. We will use the convention where the state vector is a column vector $\\mathbf{x}$, and its evolution is described by $\\mathbf{x}_{k+1} = P \\mathbf{x}_k$. In this convention, the entry $P_{ij}$ of the matrix is the probability of transitioning from state $j$ to state $i$. The columns of the matrix must sum to 1.\n\nLet's determine the columns of $P$:\n- Column 1 (from $V_1$): The particle can move to $V_2$ (ccw, prob $\\frac{2}{3}$) or $V_4$ (cw, prob $\\frac{1}{3}$). So, $P_{21} = \\frac{2}{3}$ and $P_{41} = \\frac{1}{3}$.\n- Column 2 (from $V_2$): The particle can move to $V_3$ (ccw, prob $\\frac{2}{3}$) or $V_1$ (cw, prob $\\frac{1}{3}$). So, $P_{32} = \\frac{2}{3}$ and $P_{12} = \\frac{1}{3}$.\n- Column 3 (from $V_3$): The particle can move to $V_4$ (ccw, prob $\\frac{2}{3}$) or $V_2$ (cw, prob $\\frac{1}{3}$). So, $P_{43} = \\frac{2}{3}$ and $P_{23} = \\frac{1}{3}$.\n- Column 4 (from $V_4$): The particle can move to $V_1$ (ccw, prob $\\frac{2}{3}$) or $V_3$ (cw, prob $\\frac{1}{3}$). So, $P_{14} = \\frac{2}{3}$ and $P_{34} = \\frac{1}{3}$.\n\nAll other entries are zero. The transition matrix $P$ is:\n$$\nP = \\begin{pmatrix}\n0 & \\frac{1}{3} & 0 & \\frac{2}{3} \\\\\n\\frac{2}{3} & 0 & \\frac{1}{3} & 0 \\\\\n0 & \\frac{2}{3} & 0 & \\frac{1}{3} \\\\\n\\frac{1}{3} & 0 & \\frac{2}{3} & 0\n\\end{pmatrix}\n$$\nThe steady-state distribution vector $\\pi$ is the eigenvector of $P$ corresponding to the eigenvalue $\\lambda=1$. Thus, it must satisfy the equation $P\\pi = \\pi$, which can be rewritten as $(P-I)\\pi = \\mathbf{0}$, where $I$ is the identity matrix and $\\mathbf{0}$ is the zero vector.\n$$\n\\begin{pmatrix}\n-1 & \\frac{1}{3} & 0 & \\frac{2}{3} \\\\\n\\frac{2}{3} & -1 & \\frac{1}{3} & 0 \\\\\n0 & \\frac{2}{3} & -1 & \\frac{1}{3} \\\\\n\\frac{1}{3} & 0 & \\frac{2}{3} & -1\n\\end{pmatrix}\n\\begin{pmatrix} p_1 \\\\ p_2 \\\\ p_3 \\\\ p_4 \\end{pmatrix}\n=\n\\begin{pmatrix} 0 \\\\ 0 \\\\ 0 \\\\ 0 \\end{pmatrix}\n$$\nThis gives us a system of linear equations:\n1. $-p_1 + \\frac{1}{3}p_2 + \\frac{2}{3}p_4 = 0 \\implies 3p_1 = p_2 + 2p_4$\n2. $\\frac{2}{3}p_1 - p_2 + \\frac{1}{3}p_3 = 0 \\implies 3p_2 = 2p_1 + p_3$\n3. $\\frac{2}{3}p_2 - p_3 + \\frac{1}{3}p_4 = 0 \\implies 3p_3 = 2p_2 + p_4$\n4. $\\frac{1}{3}p_1 + \\frac{2}{3}p_3 - p_4 = 0 \\implies 3p_4 = p_1 + 2p_3$\n\nLet's solve this system. From equation (2), $p_3 = 3p_2 - 2p_1$. Substitute this into equation (4):\n$3p_4 = p_1 + 2(3p_2 - 2p_1) = p_1 + 6p_2 - 4p_1 = 6p_2 - 3p_1$.\nSo, $p_4 = 2p_2 - p_1$.\n\nNow, substitute the expressions for $p_3$ and $p_4$ into equation (3):\n$3(3p_2 - 2p_1) = 2p_2 + (2p_2 - p_1)$\n$9p_2 - 6p_1 = 4p_2 - p_1$\n$5p_2 = 5p_1 \\implies p_1 = p_2$.\n\nNow that we know $p_1 = p_2$, we can find the other probabilities in terms of $p_1$:\n$p_4 = 2p_2 - p_1 = 2p_1 - p_1 = p_1$.\n$p_3 = 3p_2 - 2p_1 = 3p_1 - 2p_1 = p_1$.\nThis shows that all four probabilities are equal: $p_1 = p_2 = p_3 = p_4$.\n\nFinally, we use the normalization condition: $p_1 + p_2 + p_3 + p_4 = 1$.\nSubstituting our finding: $p_1 + p_1 + p_1 + p_1 = 1 \\implies 4p_1 = 1 \\implies p_1 = \\frac{1}{4}$.\nTherefore, the steady-state probability distribution is $p_1=p_2=p_3=p_4=\\frac{1}{4}$.\n\nThe steady-state distribution is uniform. This might seem counter-intuitive given the biased movement. However, we can observe that the transition matrix $P$ is doubly stochastic (both its columns and its rows sum to 1). For any finite, irreducible Markov chain, if the transition matrix is doubly stochastic, the unique stationary distribution is the uniform distribution. Our chain is finite and irreducible, so this theorem applies and confirms our result.\n\nThe final answer, expressed as a row vector, is $[\\frac{1}{4}, \\frac{1}{4}, \\frac{1}{4}, \\frac{1}{4}]$.", "answer": "$$\\boxed{[\\frac{1}{4}, \\frac{1}{4}, \\frac{1}{4}, \\frac{1}{4}]}$$", "id": "1375543"}, {"introduction": "Not all systems approach their long-term equilibrium slowly; some converge instantly. This final practice explores a special but important type of Markov chain where the next state is completely independent of the current state. This scenario reveals how a transition matrix with a specific structure—in this case, a rank-1 matrix—causes the system to jump to its steady-state distribution in a single step, regardless of its starting point [@problem_id:1375584].", "problem": "Three technology companies, Alpha, Beta, and Gamma, compete in a specialized software market. The market share of these companies is represented by a column vector $x = \\begin{pmatrix} x_A \\\\ x_B \\\\ x_G \\end{pmatrix}$, where $x_A, x_B, x_G$ are the fractions of the market held by each company, respectively, and $x_A + x_B + x_G = 1$. The evolution of market share from one month to the next is modeled by a stochastic transition matrix $P$, such that if the market share vector is $x_k$ in month $k$, it becomes $x_{k+1} = P x_k$ in month $k+1$.\n\nRecently, a major security flaw was found and patched in all three software products, triggering a massive, industry-wide re-evaluation by all customers. Market analysts have determined that this event completely resets brand loyalty. For the transition to the next month, regardless of which software a customer is currently using, they will choose Alpha's product with a probability of 0.25, Beta's product with a probability of 0.60, and Gamma's product with a probability of 0.15.\n\nOn the day of this event, two competing market analysis firms release different reports on the current market shares:\n- Firm 1 estimates the shares as: Alpha=50%, Beta=20%, Gamma=30%.\n- Firm 2 estimates the shares as: Alpha=10%, Beta=80%, Gamma=10%.\n\nAssuming the reset-event transition dynamics described above, what are the predicted market shares for each firm's scenario at the start of the next month? The answers are given as (Share vector from Firm 1's estimate, Share vector from Firm 2's estimate).\n\nA. ( (0.50, 0.20, 0.30), (0.10, 0.80, 0.10) )\n\nB. ( (0.25, 0.60, 0.15), (0.25, 0.60, 0.15) )\n\nC. ( (0.325, 0.44, 0.235), (0.22, 0.64, 0.14) )\n\nD. ( (0.30, 0.50, 0.20), (0.30, 0.50, 0.20) )\n\nE. It is impossible to determine the outcome without knowing which firm's report is accurate.", "solution": "We model next-month market shares by $x_{k+1} = P x_{k}$, where $x_{k}$ is a column vector with entries summing to $1$. The event “completely resets brand loyalty,” meaning that regardless of the current product, a customer chooses Alpha with probability $0.25$, Beta with probability $0.60$, and Gamma with probability $0.15$ in the next month.\n\nThis implies that every column of the transition matrix $P$ equals the same probability vector\n$$\nv = \\begin{pmatrix} 0.25 \\\\ 0.60 \\\\ 0.15 \\end{pmatrix}.\n$$\nThe full transition matrix is:\n$$\nP = \\begin{pmatrix} 0.25 & 0.25 & 0.25 \\\\ 0.60 & 0.60 & 0.60 \\\\ 0.15 & 0.15 & 0.15 \\end{pmatrix}\n$$\nFor any initial market share vector $x_{k} = \\begin{pmatrix} x_A \\\\ x_B \\\\ x_G \\end{pmatrix}$ with $x_{A} + x_{B} + x_{G} = 1$, we have\n$$\nx_{k+1} = P x_{k} = \\begin{pmatrix} 0.25 & 0.25 & 0.25 \\\\ 0.60 & 0.60 & 0.60 \\\\ 0.15 & 0.15 & 0.15 \\end{pmatrix} \\begin{pmatrix} x_A \\\\ x_B \\\\ x_G \\end{pmatrix} = \\begin{pmatrix} 0.25(x_A+x_B+x_G) \\\\ 0.60(x_A+x_B+x_G) \\\\ 0.15(x_A+x_B+x_G) \\end{pmatrix}\n$$\nSince $x_{A} + x_{B} + x_{G} = 1$, it follows that\n$$\nx_{k+1} = \\begin{pmatrix} 0.25 \\\\ 0.60 \\\\ 0.15 \\end{pmatrix},\n$$\nindependent of $x_{k}$.\n\nTherefore, starting from either Firm 1’s estimate $\\begin{pmatrix} 0.50 \\\\ 0.20 \\\\ 0.30 \\end{pmatrix}$ or Firm 2’s estimate $\\begin{pmatrix} 0.10 \\\\ 0.80 \\\\ 0.10 \\end{pmatrix}$, the next month’s shares are\n$$\n\\begin{pmatrix} 0.25 \\\\ 0.60 \\\\ 0.15 \\end{pmatrix},\n$$\nmatching option B.", "answer": "$$\\boxed{B}$$", "id": "1375584"}]}