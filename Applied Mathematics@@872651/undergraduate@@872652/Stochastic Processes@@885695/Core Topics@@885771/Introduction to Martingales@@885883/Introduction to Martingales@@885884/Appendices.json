{"hands_on_practices": [{"introduction": "The first step in mastering martingales is to build a strong intuition for the core definition. This exercise [@problem_id:1310299] provides a perfect test case by examining a symmetric random walk on a circular graph. While the local movement seems perfectly fair, you will investigate whether the process representing the particle's position, $X_n$, truly satisfies the martingale property, paying close attention to the behavior at the 'boundary' points of the circle.", "problem": "A particle performs a symmetric random walk on a set of $N$ vertices arranged in a circle, labeled $0, 1, 2, \\dots, N-1$. Let the position of the particle at time step $n$ be the discrete-time stochastic process $\\{X_n\\}_{n \\ge 0}$, where $n$ is a non-negative integer. The state space of the process is the set of vertices $S = \\{0, 1, \\dots, N-1\\}$, where $N$ is a fixed integer and $N \\ge 3$.\n\nAt each time step, the particle moves from its current vertex $k$ to an adjacent vertex. It moves clockwise to vertex $(k+1) \\pmod N$ with probability $1/2$ and counter-clockwise to vertex $(k-1) \\pmod N$ with probability $1/2$. The initial position $X_0$ can be any vertex in $S$.\n\nLet $\\{\\mathcal{F}_n\\}_{n \\ge 0}$ be the natural filtration generated by the process, i.e., $\\mathcal{F}_n = \\sigma(X_0, X_1, \\dots, X_n)$.\n\nWhich one of the following statements accurately describes the stochastic process $\\{X_n\\}_{n \\ge 0}$ with respect to the filtration $\\{\\mathcal{F}_n\\}_{n \\ge 0}$?\n\nA. $\\{X_n\\}$ is a martingale for all integers $N \\ge 3$.\nB. $\\{X_n\\}$ is a martingale, but only for even values of $N \\ge 3$.\nC. $\\{X_n\\}$ is not a martingale for any integer $N \\ge 3$.\nD. $\\{X_n\\}$ is a submartingale for all integers $N \\ge 3$.\nE. $\\{X_n\\}$ is a supermartingale for all integers $N \\ge 3$.", "solution": "We recall the martingale definition: an integrable, adapted process $\\{X_{n}\\}$ with respect to a filtration $\\{\\mathcal{F}_{n}\\}$ is a martingale if and only if\n$$\n\\mathbb{E}\\!\\left[X_{n+1}\\mid \\mathcal{F}_{n}\\right]=X_{n}\\quad\\text{a.s.}\n$$\nIt is a submartingale if $\\mathbb{E}\\!\\left[X_{n+1}\\mid \\mathcal{F}_{n}\\right]\\geq X_{n}$ a.s., and a supermartingale if $\\mathbb{E}\\!\\left[X_{n+1}\\mid \\mathcal{F}_{n}\\right]\\leq X_{n}$ a.s. The process $\\{X_{n}\\}$ is adapted to its natural filtration by construction, and is integrable because $0\\leq X_{n}\\leq N-1$ for all $n$.\n\nBecause the process is a time-homogeneous Markov chain on the cycle with transition probabilities depending only on the current state, we have\n$$\n\\mathbb{E}\\!\\left[X_{n+1}\\mid \\mathcal{F}_{n}\\right]=\\mathbb{E}\\!\\left[X_{n+1}\\mid X_{n}\\right].\n$$\nFor a current state $k\\in S=\\{0,1,\\dots,N-1\\}$, the next state equals $(k+1)\\bmod N$ with probability $\\frac{1}{2}$ and $(k-1)\\bmod N$ with probability $\\frac{1}{2}$. Denote by $\\tilde{k\\pm1}$ the representative in $\\{0,1,\\dots,N-1\\}$ of $(k\\pm1)\\bmod N$. Then\n$$\n\\mathbb{E}\\!\\left[X_{n+1}\\mid X_{n}=k\\right]=\\frac{1}{2}\\,\\tilde{k+1}+\\frac{1}{2}\\,\\tilde{k-1}.\n$$\nFor interior states $k\\in\\{1,2,\\dots,N-2\\}$, there is no wrap-around and $\\tilde{k+1}=k+1$, $\\tilde{k-1}=k-1$, hence\n$$\n\\mathbb{E}\\!\\left[X_{n+1}\\mid X_{n}=k\\right]=\\frac{1}{2}(k+1)+\\frac{1}{2}(k-1)=k.\n$$\nAt the boundary states the wrap-around matters. For $k=0$, the neighbors are $1$ and $N-1$, so\n$$\n\\mathbb{E}\\!\\left[X_{n+1}\\mid X_{n}=0\\right]=\\frac{1}{2}\\cdot 1+\\frac{1}{2}\\cdot (N-1)=\\frac{N}{2}\\neq 0\\quad\\text{for any }N\\geq 3.\n$$\nFor $k=N-1$, the neighbors are $0$ and $N-2$, so\n$$\n\\mathbb{E}\\!\\left[X_{n+1}\\mid X_{n}=N-1\\right]=\\frac{1}{2}\\cdot 0+\\frac{1}{2}\\cdot (N-2)=\\frac{N-2}{2}\\neq N-1\\quad\\text{for any }N\\geq 3.\n$$\nTherefore the martingale condition fails at $k=0$ and $k=N-1$ for all integers $N\\geq 3$, so $\\{X_{n}\\}$ is not a martingale for any such $N$.\n\nIt is also neither a submartingale nor a supermartingale uniformly in $N\\geq 3$: at $k=0$ one has\n$$\n\\mathbb{E}\\!\\left[X_{n+1}\\mid X_{n}=0\\right]=\\frac{N}{2}>0=X_{n},\n$$\nwhich violates the supermartingale inequality, while at $k=N-1$ one has\n$$\n\\mathbb{E}\\!\\left[X_{n+1}\\mid X_{n}=N-1\\right]=\\frac{N-2}{2}N-1=X_{n},\n$$\nwhich violates the submartingale inequality.\n\nHence the correct choice is that $\\{X_{n}\\}$ is not a martingale for any integer $N\\geq 3$.", "answer": "$$\\boxed{C}$$", "id": "1310299"}, {"introduction": "Not all processes that evolve randomly are martingales; some have a built-in tendency to increase or decrease. This problem [@problem_id:1310304] introduces the concept of a submartingale through the classic coupon collector's problem. By analyzing the number of distinct items collected over time, $C_n$, you will calculate the expected change in the process at each step and see why it consistently trends upwards, making it a quintessential example of a submartingale.", "problem": "Consider an urn containing $N$ balls, uniquely numbered from $1$ to $N$, where $N \\ge 2$. We perform a sequence of draws from the urn. At each discrete time step $n = 1, 2, 3, \\dots$, a ball is drawn, its number is recorded, and it is then returned to the urn. Let $X_n$ be the number on the ball drawn at step $n$. The sequence of draws $\\{X_n\\}_{n \\ge 1}$ consists of independent and identically distributed random variables, with each ball number having a probability of $1/N$ of being drawn.\n\nLet $C_n$ be the random variable representing the count of distinct ball numbers observed in the first $n$ draws. That is, $C_n = |\\{X_1, X_2, \\dots, X_n\\}|$. We define $C_0 = 0$. Let $\\mathcal{F}_n = \\sigma(X_1, \\dots, X_n)$ for $n \\ge 1$ be the natural filtration generated by the sequence of draws, with $\\mathcal{F}_0 = \\{\\emptyset, \\Omega\\}$ being the trivial sigma-algebra.\n\nWhich of the following statements correctly describes the stochastic process $\\{C_n\\}_{n \\ge 0}$ with respect to the filtration $\\{\\mathcal{F}_n\\}_{n \\ge 0}$?\n\nA. $\\{C_n\\}_{n \\ge 0}$ is a martingale.\nB. $\\{C_n\\}_{n \\ge 0}$ is a submartingale, but not a martingale.\nC. $\\{C_n\\}_{n \\ge 0}$ is a supermartingale, but not a martingale.\nD. The process is neither a martingale, a submartingale, nor a supermartingale.", "solution": "We first verify that $\\{C_{n}\\}_{n \\ge 0}$ is adapted and integrable with respect to $\\{\\mathcal{F}_{n}\\}_{n \\ge 0}$. For each $n$, $C_{n}$ is a measurable function of $(X_{1},\\dots,X_{n})$, hence $\\mathcal{F}_{n}$-measurable. Also, $0 \\le C_{n} \\le N$ almost surely, so $C_{n}$ is integrable.\n\nDefine the indicator variable\n$$\nI_{n+1}=\\mathbf{1}\\{X_{n+1} \\notin \\{X_{1},\\dots,X_{n}\\}\\}.\n$$\nBy definition, the number of distinct values after $n+1$ draws increases by $1$ if and only if the $(n+1)$-st draw is a new value not seen before. Therefore,\n$$\nC_{n+1}=C_{n}+I_{n+1}.\n$$\nCondition on $\\mathcal{F}_{n}$. Let $S_{n}=\\{X_{1},\\dots,X_{n}\\}$ denote the set of observed values up to time $n$, so that $|S_{n}|=C_{n}$. Because $X_{n+1}$ is independent of $\\mathcal{F}_{n}$ and uniformly distributed on $\\{1,\\dots,N\\}$, the conditional probability that $X_{n+1}$ is new is the proportion of values not yet seen:\n$$\n\\mathbb{P}(I_{n+1}=1 \\mid \\mathcal{F}_{n})=\\mathbb{P}(X_{n+1}\\notin S_{n} \\mid \\mathcal{F}_{n})=\\frac{N-C_{n}}{N}.\n$$\nTaking conditional expectations gives\n$$\n\\mathbb{E}[C_{n+1}\\mid \\mathcal{F}_{n}]\n=\\mathbb{E}[C_{n}+I_{n+1}\\mid \\mathcal{F}_{n}]\n=C_{n}+\\mathbb{E}[I_{n+1}\\mid \\mathcal{F}_{n}]\n=C_{n}+\\frac{N-C_{n}}{N}\n=1+\\left(1-\\frac{1}{N}\\right)C_{n}.\n$$\nHence,\n$$\n\\mathbb{E}[C_{n+1}\\mid \\mathcal{F}_{n}]-C_{n}=\\frac{N-C_{n}}{N}\\ge 0,\n$$\nwith equality if and only if $C_{n}=N$. Therefore, $\\{C_{n}\\}$ is a submartingale. It is not a martingale because on the event $\\{C_{n}N\\}$ (which has positive probability for finite $n$), one has\n$$\n\\mathbb{E}[C_{n+1}\\mid \\mathcal{F}_{n}]C_{n}.\n$$\nIt is not a supermartingale because $\\mathbb{E}[C_{n+1}\\mid \\mathcal{F}_{n}]\\ge C_{n}$ almost surely, with strict inequality on $\\{C_{n}N\\}$.\n\nTherefore, the correct choice is that $\\{C_{n}\\}_{n \\ge 0}$ is a submartingale but not a martingale.", "answer": "$$\\boxed{B}$$", "id": "1310304"}, {"introduction": "Moving beyond simply identifying martingales, this practice [@problem_id:1310309] challenges you to actively construct one from a process that is not. You are presented with a gambling game where the wealth process, $W_n$, is inherently biased and tasked with finding a predictable 'compensating' process, $A_n$, that removes this bias. This exercise provides a hands-on introduction to the powerful idea of decomposition, showing how any submartingale can be viewed as a true martingale plus a predictable, increasing process representing its 'drift'.", "problem": "A gambler starts with an initial wealth $W_0 > 0$. At each discrete time step $n=1, 2, 3, \\dots$, the gambler plays a game based on the roll of a fair six-sided die. Let $W_{n-1}$ denote the gambler's wealth just before the $n$-th roll. The rules of the game are as follows:\n\n- If the die shows a 1 or a 2 (with probability $1/3$), the gambler's wealth is halved, so their new wealth is $W_n = \\frac{1}{2}W_{n-1}$.\n- If the die shows a 3, 4, 5, or 6 (with probability $2/3$), the gambler's wealth increases by a fraction $\\alpha = 1/2$, so their new wealth is $W_n = (1 + 1/2)W_{n-1} = \\frac{3}{2}W_{n-1}$.\n\nLet $(\\mathcal{F}_n)_{n \\geq 0}$ be the natural filtration generated by the sequence of die rolls, where $\\mathcal{F}_0$ is the trivial sigma-algebra. The wealth process $(W_n)_{n \\geq 0}$ is not a martingale with respect to this filtration.\n\nYour task is to find the unique \"compensating\" process $(A_n)_{n \\geq 0}$ that makes the overall game fair in a specific sense. Find the predictable process $A_n$, with $A_0=0$, such that the new process defined by $M_n = W_n - A_n$ is a martingale with respect to the filtration $(\\mathcal{F}_n)_{n \\geq 0}$. A process $(A_n)$ is predictable if, for each $n \\geq 1$, the value of $A_n$ is known at time $n-1$ (i.e., $A_n$ is $\\mathcal{F}_{n-1}$-measurable).\n\nProvide a closed-form expression for $A_n$ for $n \\geq 1$. Your answer should be in terms of the history of the wealth process, namely $W_0, W_1, \\dots, W_{n-1}$.", "solution": "The problem asks us to find a predictable process $A_n$ with $A_0=0$ such that $M_n = W_n - A_n$ is a martingale with respect to the filtration $(\\mathcal{F}_n)_{n \\geq 0}$.\n\nThe definition of a martingale states that for all $n \\geq 1$, the process $M_n$ must satisfy $E[M_n | \\mathcal{F}_{n-1}] = M_{n-1}$.\n\nLet's substitute the definition of $M_n$ into this equation:\n$$\nE[W_n - A_n | \\mathcal{F}_{n-1}] = W_{n-1} - A_{n-1}\n$$\n\nUsing the linearity of conditional expectation, we can split the term on the left side:\n$$\nE[W_n | \\mathcal{F}_{n-1}] - E[A_n | \\mathcal{F}_{n-1}] = W_{n-1} - A_{n-1}\n$$\n\nThe process $A_n$ is defined as being predictable. This means that for any $n \\ge 1$, $A_n$ is $\\mathcal{F}_{n-1}$-measurable. A variable that is measurable with respect to a sigma-algebra is treated as a constant when taking conditional expectation with respect to that sigma-algebra. Therefore, $E[A_n | \\mathcal{F}_{n-1}] = A_n$.\n\nSubstituting this back into our equation, we get:\n$$\nE[W_n | \\mathcal{F}_{n-1}] - A_n = W_{n-1} - A_{n-1}\n$$\n\nWe can rearrange this equation to find a recurrence relation for $A_n$:\n$$\nA_n - A_{n-1} = E[W_n | \\mathcal{F}_{n-1}] - W_{n-1}\n$$\n\nNow, we need to compute $E[W_n | \\mathcal{F}_{n-1}]$. The wealth at time $n$, $W_n$, depends on the wealth at time $n-1$, $W_{n-1}$, and the outcome of the $n$-th die roll. At time $n-1$, the value of $W_{n-1}$ is known, so it is $\\mathcal{F}_{n-1}$-measurable and can be factored out of the conditional expectation.\n\nLet $X_n$ be the outcome of the $n$-th die roll. The process $W_n$ can be written as $W_n = W_{n-1} \\cdot f(X_n)$, where $f(X_n)$ is the multiplicative factor.\nThe factor $f(X_n)$ is $\\frac{1}{2}$ if $X_n \\in \\{1, 2\\}$ and $\\frac{3}{2}$ if $X_n \\in \\{3, 4, 5, 6\\}$.\n\nSo, we have:\n$$\nE[W_n | \\mathcal{F}_{n-1}] = E[W_{n-1} \\cdot f(X_n) | \\mathcal{F}_{n-1}] = W_{n-1} E[f(X_n) | \\mathcal{F}_{n-1}]\n$$\n\nSince the die rolls are independent, the outcome of the $n$-th roll $X_n$ is independent of the past rolls $(X_1, \\dots, X_{n-1})$, and thus independent of the filtration $\\mathcal{F}_{n-1}$. Therefore, the conditional expectation of $f(X_n)$ is just its unconditional expectation:\n$$\nE[f(X_n) | \\mathcal{F}_{n-1}] = E[f(X_n)]\n$$\n\nWe can calculate $E[f(X_n)]$ using the probabilities of the outcomes:\n$$\nE[f(X_n)] = P(X_n \\in \\{1, 2\\}) \\cdot \\left(\\frac{1}{2}\\right) + P(X_n \\in \\{3, 4, 5, 6\\}) \\cdot \\left(\\frac{3}{2}\\right)\n$$\n$$\nE[f(X_n)] = \\left(\\frac{2}{6}\\right) \\cdot \\left(\\frac{1}{2}\\right) + \\left(\\frac{4}{6}\\right) \\cdot \\left(\\frac{3}{2}\\right) = \\left(\\frac{1}{3}\\right) \\cdot \\left(\\frac{1}{2}\\right) + \\left(\\frac{2}{3}\\right) \\cdot \\left(\\frac{3}{2}\\right)\n$$\n$$\nE[f(X_n)] = \\frac{1}{6} + 1 = \\frac{7}{6}\n$$\n\nSo, the conditional expectation of $W_n$ is:\n$$\nE[W_n | \\mathcal{F}_{n-1}] = W_{n-1} \\cdot \\frac{7}{6}\n$$\n(This confirms that $W_n$ is a submartingale, as $E[W_n | \\mathcal{F}_{n-1}]  W_{n-1}$.)\n\nNow we substitute this result back into our recurrence relation for $A_n$:\n$$\nA_n - A_{n-1} = \\frac{7}{6}W_{n-1} - W_{n-1} = \\frac{1}{6}W_{n-1}\n$$\n\nThis gives us the increment of the process $A_n$. To find $A_n$ itself, we can write it as a sum of its increments, starting from $A_0$.\n$$\nA_n = A_0 + \\sum_{k=1}^{n} (A_k - A_{k-1})\n$$\n\nWe are given $A_0=0$. Substituting the expression for the increments:\n$$\nA_n = 0 + \\sum_{k=1}^{n} \\left(\\frac{1}{6}W_{k-1}\\right)\n$$\n\nThis sum can be written out by changing the index of summation. Let $j=k-1$. When $k=1$, $j=0$. When $k=n$, $j=n-1$.\n$$\nA_n = \\frac{1}{6} \\sum_{j=0}^{n-1} W_j\n$$\nReplacing the dummy index $j$ back with $k$ for convention gives the final expression for the compensating process:\n$$\nA_n = \\frac{1}{6} \\sum_{k=0}^{n-1} W_k\n$$\nThis expression for $A_n$ depends only on $W_0, W_1, \\ldots, W_{n-1}$, which are all known at time $n-1$, confirming that $A_n$ is a predictable process.", "answer": "$$\\boxed{\\frac{1}{6}\\sum_{k=0}^{n-1} W_k}$$", "id": "1310309"}]}