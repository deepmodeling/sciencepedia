{"hands_on_practices": [{"introduction": "This first exercise grounds the concept of transience in a practical, real-world scenario. By modeling the lifecycle of industrial equipment as a simple Markov chain [@problem_id:1347265], we can clearly see how certain states act as temporary stages on the way to a permanent outcome. This practice illustrates the fundamental definition of a transient state: a state from which there is a non-zero probability of never returning.", "problem": "A simplified model for the operational status of a piece of industrial equipment is described by a discrete-time Markov chain with three states:\n- State 1: Operational\n- State 2: Requires Maintenance\n- State 3: Permanently Failed\n\nThe equipment's state is evaluated at the end of each day. The transition probabilities between states are as follows:\n- If the equipment is in State 1 (Operational) on a given day, there is a 0.7 probability it will remain in State 1 and a 0.3 probability it will move to State 2 on the next day.\n- If the equipment is in State 2 (Requires Maintenance), there is a 0.5 probability it will be repaired and move back to State 1, and a 0.5 probability it will fail and move to State 3 on the next day. It never remains in State 2 for a second consecutive day.\n- If the equipment reaches State 3 (Permanently Failed), it remains in that state forever.\n\nA state is defined as transient if, starting from this state, there is a non-zero probability that the process will never return to it. Based on the transition probabilities provided, identify the a complete set of all transient states for this Markov chain.\n\nA. {2}\nB. {3}\nC. {1, 3}\nD. {1, 2}\nE. The set of transient states is empty.", "solution": "Let the states be labeled as $1$ (Operational), $2$ (Requires Maintenance), and $3$ (Permanently Failed). The one-step transition matrix is\n$$\nP=\\begin{pmatrix}\n0.7  0.3  0 \\\\\n0.5  0  0.5 \\\\\n0  0  1\n\\end{pmatrix}.\n$$\nA state $i$ is transient if, starting from $i$, there is a positive probability that the chain never returns to $i$. Formally, with $T_{i}^{+}=\\inf\\{n\\ge 1:X_{n}=i\\}$, state $i$ is transient if $\\mathbb{P}_{i}(T_{i}^{+}=\\infty)0$.\n\nConsider state $1$. A return to $1$ occurs as soon as $X_{1}=1$. Hence, to have no return at any $n\\ge 1$, the chain must avoid $1$ at time $1$, which forces $X_{1}=2$, and then immediately move to $3$ at time $2$ so that it can never visit $1$ later (since $3$ is absorbing). Therefore,\n$$\n\\mathbb{P}_{1}(T_{1}^{+}=\\infty)=\\mathbb{P}(1\\to 2)\\,\\mathbb{P}(2\\to 3)=0.3\\times 0.5=0.150,\n$$\nso state $1$ is transient.\n\nConsider state $2$. From $2$ the chain moves to $3$ with probability $0.5$, and since $3$ is absorbing, this precludes any future return to $2$. Thus,\n$$\n\\mathbb{P}_{2}(T_{2}^{+}=\\infty)\\ge \\mathbb{P}(2\\to 3)=0.50,\n$$\nso state $2$ is transient.\n\nConsider state $3$. Since $3$ is absorbing, $X_{1}=3$ with probability $1$, hence the chain returns to $3$ at time $1$ with probability $1$, and\n$$\n\\mathbb{P}_{3}(T_{3}^{+}=\\infty)=0.\n$$\nTherefore, state $3$ is not transient (it is recurrent).\n\nThe complete set of transient states is $\\{1,2\\}$, corresponding to option D.", "answer": "$$\\boxed{D}$$", "id": "1347265"}, {"introduction": "We now move to a classic model in probability theory: the random walk with absorbing barriers, often known as the Gambler's Ruin problem [@problem_id:1347263]. This practice solidifies the idea that a state is transient if there is a non-zero probability of \"escaping\" to an absorbing state before returning to the start. Calculating this escape probability is a key skill in analyzing stochastic processes and provides a formal proof of transience.", "problem": "A particle is constrained to move along a one-dimensional line of discrete sites, labeled by the integers $\\{0, 1, 2, \\dots, N\\}$, where $N$ is an integer greater than 2. The particle's movement is described by a simple symmetric random walk. At each discrete time step, if the particle is at a site $k$ where $0  k  N$, it moves to site $k-1$ with probability $p=1/2$ or to site $k+1$ with probability $q=1/2$.\n\nThe sites at the ends of the line, $0$ and $N$, are absorbing barriers. This means that if the particle ever reaches site $0$ or site $N$, it remains at that site for all subsequent time steps.\n\nIn the context of stochastic processes, states of a system are classified as either recurrent or transient. These are defined as follows:\n- A state $j$ is **recurrent** if a particle starting in state $j$ is guaranteed to eventually return to state $j$. The probability of returning is exactly 1.\n- A state $j$ is **transient** if a particle starting in state $j$ has a non-zero probability of never returning to state $j$. The probability of returning is strictly less than 1.\n\nConsider an arbitrary starting site $i$ such that $0  i  N$. Based on the definitions provided, how should state $i$ be classified?\n\nA. State $i$ is recurrent.\nB. State $i$ is transient.\nC. State $i$ is absorbing.\nD. The classification of state $i$ depends on the specific numerical values of $i$ and $N$.", "solution": "We consider the simple symmetric random walk on the finite set of sites $\\{0,1,\\dots,N\\}$ with absorbing barriers at $0$ and $N$. For a starting site $i$ with $0iN$, we classify state $i$ by computing the probability $r$ that the walk ever returns to $i$ after starting at $i$. By definition, state $i$ is recurrent if and only if $r=1$, and transient if and only if $r1$.\n\nUse first-step analysis (law of total probability). From $i$, the first step goes to $i-1$ with probability $\\frac{1}{2}$ or to $i+1$ with probability $\\frac{1}{2}$. After this first step:\n- If the walk is at $i-1$, it returns to $i$ before absorption if and only if it hits $i$ before $0$.\n- If the walk is at $i+1$, it returns to $i$ before absorption if and only if it hits $i$ before $N$.\n\nLet $r$ denote the return probability. Then\n$$\nr=\\frac{1}{2}\\,\\mathbb{P}_{i-1}\\!\\left(\\tau_{i}\\tau_{0}\\right)+\\frac{1}{2}\\,\\mathbb{P}_{i+1}\\!\\left(\\tau_{i}\\tau_{N}\\right),\n$$\nwhere $\\tau_{j}$ is the hitting time of state $j$.\n\nFor the unbiased random walk on an interval with absorbing endpoints, the standard gamblerâ€™s ruin hitting probabilities give, for $ab$ and $k\\in\\{a,\\dots,b\\}$,\n$$\n\\mathbb{P}_{k}\\!\\left(\\tau_{b}\\tau_{a}\\right)=\\frac{k-a}{b-a},\\qquad \\mathbb{P}_{k}\\!\\left(\\tau_{a}\\tau_{b}\\right)=\\frac{b-k}{b-a}.\n$$\nApplying this with $(a,b)=(0,i)$ and $k=i-1$ yields\n$$\n\\mathbb{P}_{i-1}\\!\\left(\\tau_{i}\\tau_{0}\\right)=\\frac{(i-1)-0}{i-0}=\\frac{i-1}{i},\n$$\nand with $(a,b)=(i,N)$ and $k=i+1$ yields\n$$\n\\mathbb{P}_{i+1}\\!\\left(\\tau_{i}\\tau_{N}\\right)=\\frac{N-(i+1)}{N-i}=\\frac{N-i-1}{N-i}.\n$$\nTherefore,\n$$\nr=\\frac{1}{2}\\left(\\frac{i-1}{i}\\right)+\\frac{1}{2}\\left(\\frac{N-i-1}{N-i}\\right)\n=\\frac{1}{2}\\left(1-\\frac{1}{i}\\right)+\\frac{1}{2}\\left(1-\\frac{1}{N-i}\\right)\n=1-\\frac{1}{2}\\left(\\frac{1}{i}+\\frac{1}{N-i}\\right).\n$$\nSince $0iN$, we have $i\\geq 1$ and $N-i\\geq 1$, hence $\\frac{1}{i}+\\frac{1}{N-i}0$, which implies $r1$.\n\nThus, the probability of ever returning to $i$ is strictly less than $1$, so state $i$ is transient. It is also not absorbing because $0iN$ by assumption.\n\nTherefore, the correct classification is option B.", "answer": "$$\\boxed{B}$$", "id": "1347263"}, {"introduction": "Our final practice explores a more profound reason for transience that arises in infinite systems. This exercise challenges you to analyze a random walk on an infinite tree and calculate the expected number of returns to the starting point [@problem_id:1347267]. A finite expected number of returns is a powerful indicator of transience, revealing that the vast number of new paths on the tree's geometry makes returning home an unlikely event in the long run, even without a designated \"trap\" state.", "problem": "An infinite $d$-regular tree is an infinite, connected, acyclic graph where every vertex has a degree (number of neighbors) equal to $d$. Consider a particle performing a simple symmetric random walk on a such a tree, where $d$ is an integer and $d \\ge 3$. The particle starts at an arbitrary vertex, which we label as the origin $o$. At each discrete time step, the particle moves from its current vertex to one of its $d$ adjacent vertices, with each neighbor being chosen with equal probability $\\frac{1}{d}$.\n\nCalculate the expected total number of times the particle returns to its starting vertex $o$ throughout its entire trajectory. Note that the initial position at time $t=0$ does not count as a return. Your final answer should be a closed-form analytic expression in terms of $d$.", "solution": "Let $X_{t}$ be the simple symmetric random walk on the infinite $d$-regular tree, started at the origin $o$. Write $R$ for the total number of returns to $o$ (excluding $t=0$). We first compute the probability $f$ that, starting from $o$, the walk ever returns to $o$ at least once.\n\nProject the walk to its distance from $o$, $D_{t}=\\operatorname{dist}(X_{t},o)$. Then $D_{0}=0$, and the first step sends the walk to some neighbor so $D_{1}=1$. For $k\\geq 1$, from any vertex at distance $k$ from $o$, there is exactly one neighbor at distance $k-1$ and $d-1$ neighbors at distance $k+1$. Hence, for $k\\geq 1$,\n$$\n\\mathbb{P}(D_{t+1}=k-1\\,|\\,D_{t}=k)=\\frac{1}{d},\\qquad \\mathbb{P}(D_{t+1}=k+1\\,|\\,D_{t}=k)=\\frac{d-1}{d}.\n$$\nThus $(D_{t})_{t\\geq 1}$ is a biased random walk on $\\{0,1,2,\\dots\\}$ with downward step probability $q=\\frac{1}{d}$ and upward step probability $p=\\frac{d-1}{d}$, and $0$ is absorbing for the event of return to $o$.\n\nLet $h(k)$ be the probability that, starting from $D_{1}=k$, the chain ever hits $0$. Then\n$$\nh(0)=1,\\qquad h(k)=\\frac{1}{d}h(k-1)+\\frac{d-1}{d}h(k+1)\\quad\\text{for all }k\\geq 1.\n$$\nSeek solutions of the form $h(k)=r^{k}$. Substituting gives\n$$\nr=\\frac{1}{d}+\\frac{d-1}{d}r^{2}\\quad\\Longleftrightarrow\\quad (d-1)r^{2}-dr+1=0.\n$$\nThe roots are\n$$\nr=\\frac{d\\pm(d-2)}{2(d-1)}\\in\\left\\{1,\\ \\frac{1}{d-1}\\right\\}.\n$$\nTherefore the general solution is $h(k)=A\\cdot 1^{k}+B\\left(\\frac{1}{d-1}\\right)^{k}$. Since $p>q$ for $d\\geq 3$, the probability of ever hitting $0$ must satisfy $\\lim_{k\\to\\infty}h(k)=0$, which forces $A=0$. Using $h(0)=1$ gives $B=1$. Hence\n$$\nh(k)=\\left(\\frac{1}{d-1}\\right)^{k},\\qquad\\text{so}\\qquad f=\\mathbb{P}_{o}(\\text{return to }o)=h(1)=\\frac{1}{d-1}.\n$$\n\nTo compute $\\mathbb{E}[R]$, use the renewal property at $o$. Conditioned on being at $o$, the probability of at least one further return is $f$, and after a return the process restarts from $o$. Let $m=\\mathbb{E}[R]$. Then\n$$\nm=f\\left(1+m\\right),\n$$\nbecause with probability $f$ there is a first return contributing $1$, after which the expected additional number of returns is again $m$. Solving,\n$$\nm=\\frac{f}{1-f}=\\frac{\\frac{1}{d-1}}{1-\\frac{1}{d-1}}=\\frac{1}{d-2}.\n$$\n\nTherefore, the expected total number of returns to $o$ (excluding the initial time) is $\\frac{1}{d-2}$.", "answer": "$$\\boxed{\\frac{1}{d-2}}$$", "id": "1347267"}]}