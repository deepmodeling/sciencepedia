{"hands_on_practices": [{"introduction": "To begin, let's explore a classic problem involving a random walk on a graph. This exercise, featuring a spider on a cube, is a perfect starting point for understanding mean hitting time. By exploiting the cube's symmetry, we can simplify the problem significantly, reducing the number of states to consider based on their distance from the target. This practice [@problem_id:1318153] masterfully illustrates the power of first-step analysis, a fundamental technique where we set up a system of linear equations to find the expected time to reach a goal.", "problem": "A spider is situated at one vertex of a wire-frame cube, which consists of 8 vertices and 12 edges of equal length. The spider begins to move along the edges of the cube. At each vertex, the spider randomly and with equal probability chooses one of the three connecting edges to walk along to the next vertex. This process is repeated at each subsequent vertex.\n\nThe spider's goal is to reach the vertex that is diagonally opposite to its starting vertex. Calculate the expected number of steps (i.e., edges traversed) the spider must take to reach its destination for the first time.", "solution": "Model the spiderâ€™s motion as a simple random walk on the 3-dimensional hypercube graph. By symmetry, the expected time to hit the target depends only on the graph distance from the target vertex. Let $E_{d}$ be the expected number of steps to first reach the target when starting from a vertex at distance $d$ from it, where $d \\in \\{0,1,2,3\\}$. Clearly, $E_{0}=0$.\n\nOn the hypercube, each step flips exactly one coordinate, so the distance from the target changes by $\\pm 1$ at each step. From a vertex at distance $d$, there are $d$ neighbors at distance $d-1$ (flipping one of the $d$ differing coordinates) and $3-d$ neighbors at distance $d+1$ (flipping one of the $3-d$ matching coordinates). Since each of the $3$ edges is chosen with probability $\\frac{1}{3}$, the first-step recursion for $d=1,2,3$ is\n$$\nE_{d} \\;=\\; 1 \\;+\\; \\frac{d}{3}\\,E_{d-1} \\;+\\; \\frac{3-d}{3}\\,E_{d+1},\n$$\nwith boundary condition $E_{0}=0$ and no $E_{4}$ term needed because $\\frac{3-d}{3}=0$ when $d=3$.\n\nWriting these explicitly:\n$$\nE_{1} \\;=\\; 1 \\;+\\; \\frac{1}{3}E_{0} \\;+\\; \\frac{2}{3}E_{2} \\;=\\; 1 \\;+\\; \\frac{2}{3}E_{2},\n$$\n$$\nE_{2} \\;=\\; 1 \\;+\\; \\frac{2}{3}E_{1} \\;+\\; \\frac{1}{3}E_{3},\n$$\n$$\nE_{3} \\;=\\; 1 \\;+\\; E_{2}.\n$$\n\nSubstitute $E_{3}=1+E_{2}$ into the equation for $E_{2}$:\n$$\nE_{2} \\;=\\; 1 \\;+\\; \\frac{2}{3}E_{1} \\;+\\; \\frac{1}{3}(1+E_{2})\n\\;=\\; \\frac{4}{3} \\;+\\; \\frac{2}{3}E_{1} \\;+\\; \\frac{1}{3}E_{2}.\n$$\nRearrange:\n$$\nE_{2} - \\frac{1}{3}E_{2} \\;=\\; \\frac{4}{3} \\;+\\; \\frac{2}{3}E_{1}\n\\;\\;\\Rightarrow\\;\\; \\frac{2}{3}E_{2} \\;=\\; \\frac{4}{3} \\;+\\; \\frac{2}{3}E_{1}\n\\;\\;\\Rightarrow\\;\\; E_{2} \\;=\\; 2 + E_{1}.\n$$\nSubstitute into the equation for $E_{1}$:\n$$\nE_{1} \\;=\\; 1 \\;+\\; \\frac{2}{3}E_{2}\n\\;=\\; 1 \\;+\\; \\frac{2}{3}(2 + E_{1})\n\\;=\\; 1 \\;+\\; \\frac{4}{3} \\;+\\; \\frac{2}{3}E_{1}\n\\;=\\; \\frac{7}{3} \\;+\\; \\frac{2}{3}E_{1}.\n$$\nThus\n$$\nE_{1} - \\frac{2}{3}E_{1} \\;=\\; \\frac{7}{3}\n\\;\\;\\Rightarrow\\;\\; \\frac{1}{3}E_{1} \\;=\\; \\frac{7}{3}\n\\;\\;\\Rightarrow\\;\\; E_{1} \\;=\\; 7.\n$$\nThen\n$$\nE_{2} \\;=\\; 2 + E_{1} \\;=\\; 9,\n\\qquad\nE_{3} \\;=\\; 1 + E_{2} \\;=\\; 10.\n$$\n\nThe spider starts at distance $3$ from the target (opposite vertex), so the expected number of steps is $E_{3}=10$.", "answer": "$$\\boxed{10}$$", "id": "1318153"}, {"introduction": "Moving from a tangible geometric space, our next practice explores a more abstract state space grounded in number theory. Here, we investigate the expected number of die rolls required for the cumulative sum to become a multiple of 5. This problem [@problem_id:1318167] introduces the elegant concept of a Markov chain on a finite set of remainders (modulo 5). It provides an excellent opportunity to apply a different, powerful tool: Kac's recurrence theorem, which connects the mean hitting time to the chain's stationary distribution, offering a highly efficient path to the solution.", "problem": "In a simplified model of a data transmission protocol, a stream of data packets is sent sequentially. Each packet contains a numerical value. A running checksum is maintained, which is the cumulative sum of the numerical values of all packets received so far. The protocol requires that for a transmission to be considered complete, the final checksum must be a multiple of 5.\n\nSuppose a test data stream is generated where the numerical value of each packet is an integer drawn randomly and uniformly from the set $\\{1, 2, 3, 4, 5, 6\\}$. The process starts with a checksum of 0 before any packets are received.\n\nWhat is the expected number of packets that must be received until the running checksum is first a non-zero multiple of 5? Present the answer as a single exact number.", "solution": "Let $X_{1}, X_{2}, \\ldots$ be i.i.d. with $\\mathbb{P}(X_{k}=j)=\\frac{1}{6}$ for $j \\in \\{1,2,3,4,5,6\\}$, and let the running checksum be $S_{n}=\\sum_{k=1}^{n} X_{k}$. Define the process modulo $5$ by $Y_{n}=S_{n} \\bmod 5 \\in \\{0,1,2,3,4\\}$, with $Y_{0}=0$. We seek the expected hitting time\n$$\nT=\\min\\{n \\ge 1 : Y_{n}=0\\}.\n$$\nThe step distribution modulo $5$ is given by\n$$\n\\mathbb{P}(X \\equiv 0 \\bmod 5)=\\frac{1}{6},\\quad \\mathbb{P}(X \\equiv 1 \\bmod 5)=\\frac{1}{3},\\quad \\mathbb{P}(X \\equiv 2 \\bmod 5)=\\frac{1}{6},\\quad \\mathbb{P}(X \\equiv 3 \\bmod 5)=\\frac{1}{6},\\quad \\mathbb{P}(X \\equiv 4 \\bmod 5)=\\frac{1}{6}.\n$$\nTherefore $\\{Y_{n}\\}$ is a Markov chain on $\\{0,1,2,3,4\\}$ with transition probabilities\n$$\nP_{r,s}=\\mathbb{P}(Y_{n+1}=s \\mid Y_{n}=r)=p_{(s-r)\\bmod 5},\n$$\nwhere $(p_{0},p_{1},p_{2},p_{3},p_{4})=\\left(\\frac{1}{6},\\frac{1}{3},\\frac{1}{6},\\frac{1}{6},\\frac{1}{6}\\right)$. This transition matrix is circulant with each column sum equal to $1$, since for fixed $s$,\n$$\n\\sum_{r=0}^{4} P_{r,s}=\\sum_{r=0}^{4} p_{(s-r)\\bmod 5}=\\sum_{k=0}^{4} p_{k}=1.\n$$\nHence the uniform distribution $\\pi$ with $\\pi_{r}=\\frac{1}{5}$ is stationary:\n$$\n\\sum_{r=0}^{4} \\pi_{r} P_{r,s}=\\frac{1}{5} \\sum_{r=0}^{4} P_{r,s}=\\frac{1}{5}.\n$$\nThe chain is irreducible because $p_{1}>0$ implies any state can be reached from any other by repeated $+1$ steps modulo $5$. Being finite, it is also positive recurrent. By the standard Markov chain recurrence theorem (Kac's formula), the expected return time to state $i$ starting from $i$ is\n$$\n\\mathbb{E}_{i}[T_{i}^{+}]=\\frac{1}{\\pi_{i}}.\n$$\nTaking $i=0$ gives\n$$\n\\mathbb{E}[T]=\\frac{1}{\\pi_{0}}=\\frac{1}{1/5}=5.\n$$\nThis $T$ is exactly the number of packets until the checksum is first a non-zero multiple of $5$ (time at least $1$), and the possibility of drawing $X=5$ corresponds to an immediate return in one step, which is correctly included by this formula.", "answer": "$$\\boxed{5}$$", "id": "1318167"}, {"introduction": "Our final exercise delves into the important field of sequence pattern matching, a common application of stochastic processes. We calculate the expected number of coin tosses needed to observe the specific pattern 'Heads-Tails-Heads' for the first time. The key to solving this problem [@problem_id:1318139] lies in defining the states of our process based on the partial progress made toward completing the target sequence. This practice hones your ability to model processes where history matters, particularly in how overlaps within the pattern affect the transitions between states.", "problem": "A biased coin is tossed repeatedly. The probability of landing heads (H) is $p$, where $0 < p < 1$. The probability of landing tails (T) is therefore $1-p$. The tosses are independent events. Calculate the expected number of tosses required to observe the sequence 'Heads-Tails-Heads' (HTH) for the first time. Your answer should be a closed-form analytic expression in terms of $p$.", "solution": "Let the target pattern be HTH and define states by the length of the longest suffix of the observed sequence that matches a prefix of HTH:\n- State $0$: no match,\n- State $1$: suffix $H$,\n- State $2$: suffix $HT$,\n- State $3$: absorbing state (pattern HTH observed).\n\nLet $E_{i}$ be the expected additional number of tosses to reach state $3$ starting from state $i$. We seek $E_{0}$.\n\nTransitions:\n- From state $0$: with probability $p$ go to state $1$ (on $H$), with probability $1-p$ stay in state $0$ (on $T$). Thus\n$$\nE_{0} = 1 + p E_{1} + (1-p) E_{0}.\n$$\n- From state $1$: with probability $p$ stay in state $1$ (on $H$, suffix $H$ remains), with probability $1-p$ go to state $2$ (on $T$, suffix $HT$). Thus\n$$\nE_{1} = 1 + p E_{1} + (1-p) E_{2}.\n$$\n- From state $2$: with probability $p$ go to state $3$ (on $H$, pattern completed), with probability $1-p$ go to state $0$ (on $T$, no matching prefix). Thus\n$$\nE_{2} = 1 + p \\cdot 0 + (1-p) E_{0} = 1 + (1-p) E_{0}.\n$$\n\nSolve the system. From the first equation,\n$$\nE_{0} - (1-p) E_{0} = 1 + p E_{1} \\quad \\Rightarrow \\quad p E_{0} = 1 + p E_{1} \\quad \\Rightarrow \\quad E_{0} = \\frac{1}{p} + E_{1}.\n$$\nFrom the second equation,\n$$\nE_{1} - p E_{1} = 1 + (1-p) E_{2} \\quad \\Rightarrow \\quad (1-p) E_{1} = 1 + (1-p) E_{2} \\quad \\Rightarrow \\quad E_{1} = \\frac{1}{1-p} + E_{2}.\n$$\nSubstitute $E_{2} = 1 + (1-p) E_{0}$ into the expression for $E_{1}$ to get\n$$\nE_{1} = \\frac{1}{1-p} + 1 + (1-p) E_{0}.\n$$\nInsert this into $E_{0} = \\frac{1}{p} + E_{1}$:\n$$\nE_{0} = \\frac{1}{p} + \\frac{1}{1-p} + 1 + (1-p) E_{0}.\n$$\nRearrange to solve for $E_{0}$:\n$$\nE_{0} - (1-p) E_{0} = \\frac{1}{p} + \\frac{1}{1-p} + 1 \\quad \\Rightarrow \\quad p E_{0} = \\frac{1}{p} + \\frac{1}{1-p} + 1,\n$$\n$$\nE_{0} = \\frac{1}{p^{2}} + \\frac{1}{p(1-p)} + \\frac{1}{p} = \\frac{1+p-p^{2}}{p^{2}(1-p)}.\n$$\nTherefore, the expected number of tosses required to first observe HTH is $\\frac{1+p-p^{2}}{p^{2}(1-p)}$.", "answer": "$$\\boxed{\\frac{1+p-p^{2}}{p^{2}\\left(1-p\\right)}}$$", "id": "1318139"}]}