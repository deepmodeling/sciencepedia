{"hands_on_practices": [{"introduction": "Our exploration begins with a system exhibiting perfect symmetry, a common feature in many real-world networks and load-balancing systems. This exercise models a job-shuffling algorithm in a cloud computing cluster, providing a tangible context for understanding doubly stochastic matrices. By analyzing this system, you will confirm the intuitive idea that if all states are treated equally, the long-term probability of being in any one state is the same, leading to a uniform stationary distribution [@problem_id:1300471].", "problem": "A small cloud computing cluster consists of $N=5$ identical servers, labeled 1 through 5. To ensure even utilization, a dynamic \"job shuffling\" algorithm is implemented. At the end of each discrete time interval, a single computational job currently running on a server is evaluated for migration. The algorithm's rule is as follows: with probability $\\alpha = 0.6$, the job remains on its current server; with probability $1-\\alpha$, the job is migrated. If a migration decision is made, the job is moved to one of the other $N-1$ servers, with each destination server being chosen with equal probability.\n\nThis process can be modeled as a finite-state Markov chain, where the state of the system is the server number on which the job resides. Let $P$ be the transition matrix for this chain. A stationary distribution is a probability row vector $\\pi = (\\pi_1, \\pi_2, \\dots, \\pi_N)$ whose components sum to one, representing the long-term probabilities of finding the job on each server, and which satisfies the equation $\\pi P = \\pi$.\n\nAssuming the system has been running for a very long time and has reached equilibrium, determine the stationary distribution $\\pi = (\\pi_1, \\pi_2, \\pi_3, \\pi_4, \\pi_5)$. Present your answer as a row matrix of exact fractions.", "solution": "Let the state space of the Markov chain be $S = \\{1, 2, 3, 4, 5\\}$, representing the server on which the job is located. We need to find the stationary distribution $\\pi = (\\pi_1, \\pi_2, \\pi_3, \\pi_4, \\pi_5)$.\n\nFirst, we construct the $5 \\times 5$ transition matrix $P$, where the entry $P_{ij}$ is the probability of transitioning from state $i$ to state $j$ in one time step. The problem provides the following information:\n- The number of servers is $N=5$.\n- The probability of a job staying on its current server is $\\alpha = 0.6$.\n- The probability of a job being migrated is $1-\\alpha = 0.4$.\n- If migrated from server $i$, the job moves to any other server $j \\neq i$ with equal probability. There are $N-1 = 4$ other servers.\n\nFrom these rules, we can determine the elements of the transition matrix $P$:\n1.  The diagonal elements $P_{ii}$ represent the probability of staying in state $i$. This is given as $\\alpha$.\n    $$P_{ii} = \\alpha = 0.6$$\n2.  The off-diagonal elements $P_{ij}$ (for $i \\neq j$) represent the probability of moving from state $i$ to state $j$. This occurs if the job is migrated (with probability $1-\\alpha$) and server $j$ is chosen as the destination from the $N-1$ possibilities.\n    $$P_{ij} = \\frac{1-\\alpha}{N-1} = \\frac{1 - 0.6}{5 - 1} = \\frac{0.4}{4} = 0.1$$\n\nSo, the transition matrix $P$ is:\n$$\nP = \\begin{pmatrix}\n0.6  0.1  0.1  0.1  0.1 \\\\\n0.1  0.6  0.1  0.1  0.1 \\\\\n0.1  0.1  0.6  0.1  0.1 \\\\\n0.1  0.1  0.1  0.6  0.1 \\\\\n0.1  0.1  0.1  0.1  0.6\n\\end{pmatrix}\n$$\n\nA stationary distribution $\\pi$ must satisfy $\\pi P = \\pi$ and $\\sum_{i=1}^{5} \\pi_i = 1$.\n\nWe can solve this system of linear equations. The equation $\\pi P = \\pi$ gives:\n$$\n(\\pi_1, \\pi_2, \\pi_3, \\pi_4, \\pi_5)\n\\begin{pmatrix}\n0.6  0.1  0.1  0.1  0.1 \\\\\n0.1  0.6  0.1  0.1  0.1 \\\\\n0.1  0.1  0.6  0.1  0.1 \\\\\n0.1  0.1  0.1  0.6  0.1 \\\\\n0.1  0.1  0.1  0.1  0.6\n\\end{pmatrix}\n= (\\pi_1, \\pi_2, \\pi_3, \\pi_4, \\pi_5)\n$$\nThis yields a system of equations. For the first component:\n$$\n\\pi_1 = 0.6\\pi_1 + 0.1\\pi_2 + 0.1\\pi_3 + 0.1\\pi_4 + 0.1\\pi_5\n$$\nDue to the complete symmetry of the transition matrix, the equations for $\\pi_2, \\pi_3, \\pi_4, \\pi_5$ will have the same structure. This symmetry implies that the components of the stationary distribution must be equal: $\\pi_1 = \\pi_2 = \\pi_3 = \\pi_4 = \\pi_5$.\n\nLet's verify this. A more direct approach is to check the properties of matrix $P$. A matrix is called doubly stochastic if it is a stochastic matrix (all entries are non-negative and all rows sum to 1) and all its columns also sum to 1.\n\nLet's check the row sums of $P$:\nFor any row $i$, the sum is $P_{ii} + \\sum_{j \\neq i} P_{ij} = \\alpha + (N-1) \\frac{1-\\alpha}{N-1} = \\alpha + (1-\\alpha) = 1$.\nSpecifically, $0.6 + 4 \\times 0.1 = 0.6 + 0.4 = 1$. So, $P$ is a stochastic matrix.\n\nNow, let's check the column sums of $P$:\nFor any column $j$, the sum is $P_{jj} + \\sum_{i \\neq j} P_{ij} = \\alpha + (N-1) \\frac{1-\\alpha}{N-1} = \\alpha + (1-\\alpha) = 1$.\nSpecifically, $0.6 + 4 \\times 0.1 = 0.6 + 0.4 = 1$. So, $P$ is also a doubly stochastic matrix.\n\nA key theorem in the theory of Markov chains states that if a finite-state, irreducible, and aperiodic Markov chain has a doubly stochastic transition matrix $P$, then its unique stationary distribution is the uniform distribution.\n- The chain is irreducible because $P_{ij}  0$ for all $i, j$, meaning any state can be reached from any other state in one step.\n- The chain is aperiodic because $P_{ii}  0$ for all $i$.\n\nFor a state space with $N$ states, the uniform distribution is given by $\\pi_i = 1/N$ for all $i=1, \\dots, N$.\nIn our case, $N=5$, so the stationary distribution is:\n$$ \\pi_i = \\frac{1}{5} \\quad \\text{for } i=1, 2, 3, 4, 5. $$\nAs decimal fractions, this is $\\pi_i = 0.2$. As exact fractions, it is $1/5$.\n\nThe stationary distribution vector is therefore:\n$$ \\pi = \\left(\\frac{1}{5}, \\frac{1}{5}, \\frac{1}{5}, \\frac{1}{5}, \\frac{1}{5}\\right) $$\nNotice that the specific value of $\\alpha=0.6$ does not affect the final stationary distribution, as long as the problem structure leads to a doubly stochastic matrix.\n\nWe can check this solution with the equation $\\pi P = \\pi$:\nLet $\\pi = (\\frac{1}{5}, \\frac{1}{5}, \\frac{1}{5}, \\frac{1}{5}, \\frac{1}{5})$. The first component of the product $\\pi P$ is:\n$$ (\\pi P)_1 = \\sum_{i=1}^5 \\pi_i P_{i1} = \\frac{1}{5}(0.6) + \\frac{1}{5}(0.1) + \\frac{1}{5}(0.1) + \\frac{1}{5}(0.1) + \\frac{1}{5}(0.1) $$\n$$ (\\pi P)_1 = \\frac{1}{5} (0.6 + 0.1 + 0.1 + 0.1 + 0.1) = \\frac{1}{5}(1) = \\frac{1}{5} $$\nThis equals $\\pi_1$. By symmetry, this holds for all components. Thus, $\\pi P = \\pi$ is satisfied. Also, $\\sum \\pi_i = 5 \\times \\frac{1}{5} = 1$. The solution is correct.", "answer": "$$\\boxed{\\begin{pmatrix} \\frac{1}{5}  \\frac{1}{5}  \\frac{1}{5}  \\frac{1}{5}  \\frac{1}{5} \\end{pmatrix}}$$", "id": "1300471"}, {"introduction": "Not all systems settle into a dynamic equilibrium across all states; some are destined for a final, irreversible state. This problem introduces the critical concept of an absorbing state through a simplified weather model that includes a permanent \"Drought\" condition. By examining the transition dynamics, you will discover how such a state inevitably captures the entire probability mass over time, demonstrating that the only stationary distribution is one concentrated entirely on that absorbing state [@problem_id:1300497].", "problem": "A meteorologist develops a simplified three-state model for daily weather patterns in a specific region. The possible states are Sunny (S), Rainy (R), and a special long-term state, Drought (D). This model is represented as a discrete-time Markov chain. The transitions between states are governed by the following rules:\n\n1.  If the weather is Sunny on a given day, on the next day it will be Sunny with probability $p_{SS}$, Rainy with probability $p_{SR}$, and the region will enter a Drought state with probability $p_{SD}$. The sum of these probabilities is one: $p_{SS} + p_{SR} + p_{SD} = 1$.\n2.  If the weather is Rainy on a given day, on the next day it will be Sunny with probability $p_{RS}$ or Rainy with probability $p_{RR}$. The sum is one: $p_{RS} + p_{RR} = 1$. There is no direct transition from Rainy to Drought.\n3.  Once the region is in the Drought state, it remains in the Drought state permanently.\n\nAll transition probabilities $p_{SR}$, $p_{SD}$, and $p_{RS}$ are strictly greater than zero and less than one.\n\nA stationary distribution of a Markov chain is a probability distribution that remains unchanged over time. For this weather model, what is the unique stationary distribution $\\pi = (\\pi_S, \\pi_R, \\pi_D)$, where $\\pi_S$, $\\pi_R$, and $\\pi_D$ are the long-term probabilities of being in the Sunny, Rainy, and Drought states, respectively?\n\nA. $\\pi = (0, 0, 1)$\n\nB. $\\pi = (1, 0, 0)$\n\nC. $\\pi = \\left(\\frac{p_{RS}}{p_{RS}+p_{SR}}, \\frac{p_{SR}}{p_{RS}+p_{SR}}, 0\\right)$\n\nD. A unique stationary distribution does not exist for this model.\n\nE. The stationary distribution depends on the initial state of the weather.", "solution": "Let the state space of the Markov chain be $\\mathcal{S} = \\{S, R, D\\}$. The stationary distribution $\\pi = (\\pi_S, \\pi_R, \\pi_D)$ must satisfy two conditions:\n1.  $\\pi P = \\pi$, where $P$ is the transition probability matrix.\n2.  $\\pi_S + \\pi_R + \\pi_D = 1$.\n\nFirst, we construct the transition matrix $P$ from the problem description. The states are ordered as (S, R, D).\n$$\nP = \\begin{pmatrix}\np_{SS}  p_{SR}  p_{SD} \\\\\np_{RS}  p_{RR}  0 \\\\\n0  0  1\n\\end{pmatrix}\n$$\nThe condition $\\pi P = \\pi$ expands into a system of linear equations:\n$$\n(\\pi_S, \\pi_R, \\pi_D) \\begin{pmatrix}\np_{SS}  p_{SR}  p_{SD} \\\\\np_{RS}  p_{RR}  0 \\\\\n0  0  1\n\\end{pmatrix} = (\\pi_S, \\pi_R, \\pi_D)\n$$\n\nThis gives us the following three equations:\n1.  $\\pi_S p_{SS} + \\pi_R p_{RS} = \\pi_S$\n2.  $\\pi_S p_{SR} + \\pi_R p_{RR} = \\pi_R$\n3.  $\\pi_S p_{SD} + \\pi_D (1) = \\pi_D$\n\nLet's analyze the third equation:\n$\\pi_S p_{SD} + \\pi_D = \\pi_D$\nSubtracting $\\pi_D$ from both sides gives:\n$\\pi_S p_{SD} = 0$\n\nThe problem states that the probability of transitioning from Sunny to Drought, $p_{SD}$, is strictly greater than zero. For the product $\\pi_S p_{SD}$ to be zero, it must be that $\\pi_S = 0$.\n\nNow, let's substitute $\\pi_S = 0$ into the first equation:\n$(0) p_{SS} + \\pi_R p_{RS} = (0)$\n$\\pi_R p_{RS} = 0$\n\nThe problem also states that the probability of transitioning from Rainy to Sunny, $p_{RS}$, is strictly greater than zero. For the product $\\pi_R p_{RS}$ to be zero, it must be that $\\pi_R = 0$.\n\nFinally, we use the normalization condition that the sum of the probabilities in the stationary distribution must be 1:\n$\\pi_S + \\pi_R + \\pi_D = 1$\nSubstituting the values we found for $\\pi_S$ and $\\pi_R$:\n$0 + 0 + \\pi_D = 1$\nThis implies $\\pi_D = 1$.\n\nTherefore, the unique stationary distribution for this system is $\\pi = (0, 0, 1)$.\n\nConceptually, the state D is an absorbing state because once entered, it cannot be left ($p_{DD}=1$). The other states, S and R, are transient. Since there is a non-zero probability of reaching the absorbing state D from every transient state (from R one can go to S, and from S one can go to D), the system will eventually, with probability 1, be absorbed into state D. The stationary distribution represents the long-term behavior of the system. As time goes to infinity, the probability of being in any of the transient states (S or R) approaches zero, and the probability of being in the absorbing state (D) approaches one.", "answer": "$$\\boxed{A}$$", "id": "1300497"}, {"introduction": "Markov chains on infinite state spaces pose unique challenges; for instance, a simple symmetric random walk on a 2D grid ($\\mathbb{Z}^2$) is known to be null recurrent and lacks a stationary distribution. This exercise presents a thought-provoking modification: introducing a small probability of \"resetting\" the particle to the origin at each step. You will investigate how this seemingly minor change fundamentally alters the chain's properties, inducing positive recurrence and thereby guaranteeing the existence of a unique stationary distribution [@problem_id:1300482].", "problem": "A classic result in the theory of random walks states that a Simple Symmetric Random Walk (SSRW) on the integer lattice $\\mathbb{Z}^2$ is recurrent but does not possess a stationary distribution. In an SSRW, a particle at any site moves to one of its four nearest neighbors with equal probability.\n\nConsider a modified random walk on $\\mathbb{Z}^2$. At each time step, the particle's movement is determined by a two-stage process:\n1. A coin is tossed, which lands on \"Reset\" with probability $\\epsilon$ or \"Walk\" with probability $1-\\epsilon$, where $0  \\epsilon  1$ is a fixed constant.\n2. If the outcome is \"Reset\", the particle is moved directly to the origin $(0,0)$. If the outcome is \"Walk\", the particle performs one step of a standard SSRW from its current location.\n\nThis modification introduces a global \"pull\" towards the origin. Is this change sufficient to guarantee the existence of a stationary distribution for the process, for any valid choice of $\\epsilon$? Choose the option that provides the correct conclusion and justification.\n\nA. No, because any Markov chain on an infinite state space like $\\mathbb{Z}^2$ cannot have a normalizable stationary distribution.\n\nB. No, because the underlying Simple Symmetric Random Walk on $\\mathbb{Z}^2$ is null recurrent, and this property is preserved by the modification since $\\epsilon$ can be arbitrarily small.\n\nC. Yes, because for any $0  \\epsilon  1$, the reset mechanism ensures the chain becomes positive recurrent, which is a sufficient condition for the existence of a stationary distribution.\n\nD. Yes, but its existence is conditional on the reset probability $\\epsilon$ being sufficiently large (e.g., greater than 1/2) to overcome the diffusive nature of the walk.\n\nE. No, because the modification makes the chain periodic, and a periodic chain on an infinite state space cannot have a stationary distribution.", "solution": "Let $\\{X_n\\}_{n\\ge 0}$ be the Markov chain on $\\mathbb{Z}^2$ with transition kernel defined by the two-stage mechanism:\n- With probability $\\epsilon$, $X_{n+1}=0$.\n- With probability $1-\\epsilon$, $X_{n+1}$ is obtained by one step of an SSRW from $X_n$.\n\nIrreducibility: For any $x, y \\in \\mathbb{Z}^2$, the particle at $x$ can go to the origin $0$ in one step with probability $\\epsilon > 0$. From $0$, it is possible to reach any other site $y$ via a sequence of SSRW steps. For any fixed path of length $n$ from $0$ to $y$, the probability to follow that path without any reset is $((1-\\epsilon)/4)^n > 0$. Hence there exists a path of non-zero probability from any $x$ to any $y$, so the chain is irreducible.\n\nAperiodicity: Since there is a probability $\\epsilon > 0$ of resetting to the origin, the transition probability from the origin to itself, $P(0,0)$, is at least $\\epsilon$. A non-zero probability of staying in a state ($P(0,0)>0$) is sufficient to prove that the state is aperiodic. Since the chain is irreducible, all states share this property, and the chain is aperiodic.\n\nPositive recurrence: Let $T_0^+$ be the first return time to the origin, starting from the origin: $T_0^+ = \\inf\\{n \\ge 1: X_n=0 \\mid X_0=0\\}$. The probability of *not* returning to the origin in a single step is at most $1-\\epsilon$ (the probability of not getting a \"Reset\" outcome). Therefore, for any $n \\ge 1$, the probability of not having returned to the origin by step $n$ is bounded above by the probability of not having a single \"Reset\" outcome in $n$ steps:\n$$ \\mathbb{P}(T_0^+ > n \\mid X_0=0) \\le (1-\\epsilon)^n $$\nThe mean recurrence time of the origin is given by $\\mathbb{E}[T_0^+] = \\sum_{n=0}^{\\infty} \\mathbb{P}(T_0^+ > n)$. Using our bound:\n$$ \\mathbb{E}[T_0^+] \\le \\sum_{n=0}^{\\infty} (1-\\epsilon)^n = \\frac{1}{1 - (1-\\epsilon)} = \\frac{1}{\\epsilon} $$\nSince $0  \\epsilon  1$, the mean recurrence time is finite ($\\mathbb{E}[T_0^+]  \\infty$). An irreducible chain is positive recurrent if and only if the mean recurrence time for any state is finite. Thus, the chain is positive recurrent.\n\nExistence and uniqueness of a stationary distribution: For an irreducible Markov chain on a countable state space, being positive recurrent is the necessary and sufficient condition for the existence of a unique stationary distribution. Since we have shown the chain to be irreducible, aperiodic, and positive recurrent for any $0  \\epsilon  1$, a unique stationary distribution is guaranteed to exist.\n\nConsequently, the correct choice is C.\n- A is false: Positive recurrent chains on infinite state spaces do have normalizable stationary distributions.\n- B is false: The reset mechanism fundamentally changes the recurrence property from null to positive by ensuring a finite mean return time to the origin.\n- D is false: The existence is guaranteed for any $\\epsilon > 0$, no matter how small.\n- E is false: The chain is aperiodic due to the self-loop at the origin.", "answer": "$$\\boxed{C}$$", "id": "1300482"}]}