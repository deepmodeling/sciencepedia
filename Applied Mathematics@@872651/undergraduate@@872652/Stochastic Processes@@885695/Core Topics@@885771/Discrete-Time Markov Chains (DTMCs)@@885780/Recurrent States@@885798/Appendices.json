{"hands_on_practices": [{"introduction": "Understanding recurrence often begins with the most fundamental systems. This first practice problem [@problem_id:1329896] models a system's parity as a simple two-state Markov chain, providing a concrete scenario to apply core definitions. By solving this, you will practice the crucial skill of calculating the mean recurrence time for a state by first finding the chain's stationary distribution, directly linking long-run probabilities to expected return times.", "problem": "A simplified model for an adaptive digital system involves a counter whose parity (even or odd) determines the system's operational mode. The system's state is tracked by an internal counter, which starts at 0. At each time step, a random integer is generated by a specific pseudo-random number generator (PRNG) and added to the counter. The choice of PRNG mode depends on the current parity of the counter.\n\n- If the counter's current value is even, the system uses PRNG Mode E. In this mode, the probability of generating an odd integer is $q_E = 1/3$.\n- If the counter's current value is odd, the system uses PRNG Mode O. In this mode, the probability of generating an odd integer is $q_O = 3/4$.\n\nThe system is considered to be in state 'E' if the counter's value is even, and in state 'O' if the counter's value is odd. Which of the following statements is correct regarding state 'E' and its mean recurrence time, which is the expected number of steps for the system, starting in state 'E', to return to state 'E' for the first time?\n\nA. The state 'E' is a transient state.\n\nB. The state 'E' is recurrent, and the expected number of steps to return is $13/9$.\n\nC. The state 'E' is recurrent, and the expected number of steps to return is $13/4$.\n\nD. The state 'E' is recurrent, and the expected number of steps to return is $9/13$.\n\nE. The state 'E' is recurrent, and the expected number of steps to return is $2$.", "solution": "Interpret the parity of the counter as a two-state time-homogeneous Markov chain with states $E$ (even) and $O$ (odd). Adding an odd integer flips the parity; adding an even integer keeps the parity.\n\nFrom the problem:\n- In state $E$, the probability of generating an odd integer is $q_{E} = \\frac{1}{3}$, hence\n$$\nP(E \\to O) = \\frac{1}{3}, \\quad P(E \\to E) = 1 - \\frac{1}{3} = \\frac{2}{3}.\n$$\n- In state $O$, the probability of generating an odd integer is $q_{O} = \\frac{3}{4}$, hence\n$$\nP(O \\to E) = \\frac{3}{4}, \\quad P(O \\to O) = 1 - \\frac{3}{4} = \\frac{1}{4}.\n$$\n\nAll transition probabilities are strictly positive between the two states, so the chain is irreducible. Since $P(E \\to E) = \\frac{2}{3} > 0$ and $P(O \\to O) = \\frac{1}{4} > 0$, the chain is aperiodic. Any irreducible finite Markov chain is positive recurrent; thus state $E$ is recurrent.\n\nLet the stationary distribution be $(\\pi_{E}, \\pi_{O})$ with $\\pi_{E} + \\pi_{O} = 1$ and $\\pi = \\pi P$. Using the $E$-component of $\\pi = \\pi P$,\n$$\n\\pi_{E} = \\pi_{E}\\left(\\frac{2}{3}\\right) + \\pi_{O}\\left(\\frac{3}{4}\\right).\n$$\nRearrange to get\n$$\n\\pi_{E} - \\frac{2}{3}\\pi_{E} = \\frac{3}{4}\\pi_{O} \\quad \\Longrightarrow \\quad \\frac{1}{3}\\pi_{E} = \\frac{3}{4}\\pi_{O}.\n$$\nMultiply both sides by $12$ to clear denominators:\n$$\n4\\pi_{E} = 9\\pi_{O}.\n$$\nUsing $\\pi_{E} + \\pi_{O} = 1$, substitute $\\pi_{O} = 1 - \\pi_{E}$:\n$$\n4\\pi_{E} = 9(1 - \\pi_{E}) \\quad \\Longrightarrow \\quad 4\\pi_{E} = 9 - 9\\pi_{E} \\quad \\Longrightarrow \\quad 13\\pi_{E} = 9,\n$$\nhence\n$$\n\\pi_{E} = \\frac{9}{13}.\n$$\n\nFor an irreducible positive recurrent Markov chain, the mean recurrence time to state $E$ equals $1/\\pi_{E}$. Therefore,\n$$\n\\text{Mean recurrence time to } E = \\frac{1}{\\pi_{E}} = \\frac{13}{9}.\n$$\nThus, $E$ is recurrent and its expected return time is $\\frac{13}{9}$, which corresponds to option B.", "answer": "$$\\boxed{B}$$", "id": "1329896"}, {"introduction": "Moving beyond two-state systems, we can apply the principles of recurrence to more complex models with many states. This problem [@problem_id:1329929] uses the example of bit-flips in a digital memory bank, which can be modeled as a birth-death process—a special but important type of Markov chain. This exercise will guide you through using the principle of detailed balance to find the stationary distribution for an $(L+1)$-state system, reinforcing the connection between stationary probabilities and mean recurrence times in a more general context.", "problem": "A simplified model for the reliability of a digital memory bank considers it as a string of $L$ bits. Due to environmental factors, the memory is subject to random bit-flip errors. At each discrete time step, one bit is selected uniformly at random from the $L$ available positions, and its value is flipped (a 0 becomes a 1, and a 1 becomes a 0).\n\nLet the system be initialized in the \"all-ones\" state, which is the bit string consisting of $L$ ones. This process can be described by a Markov chain whose states are characterized by the number of '1's in the bit string. For any finite $L$, every state in this chain is recurrent, meaning that if the system starts in a particular state, it is certain to eventually return to it.\n\nYour task is to calculate the mean (expected) number of time steps required for the system, starting from the \"all-ones\" state, to return to this \"all-ones\" state for the first time. Express your answer as a closed-form analytic expression in terms of $L$.", "solution": "Model the chain by the number of ones, $k\\in\\{0,1,\\ldots,L\\}$. From state $k$, one of the $L$ bits is flipped uniformly at random, so the transition probabilities are\n$$\nP(k\\to k+1)=\\frac{L-k}{L}\\quad\\text{for }kL,\\qquad P(k\\to k-1)=\\frac{k}{L}\\quad\\text{for }k0,\n$$\nwith no other moves possible. This is a finite, irreducible birth–death chain and thus positive recurrent.\n\nWe first find its stationary distribution $\\pi=\\{\\pi_{k}\\}_{k=0}^{L}$ using detailed balance. Reversibility requires\n$$\n\\pi_{k}\\,P(k\\to k+1)=\\pi_{k+1}\\,P(k+1\\to k)\\quad\\text{for }k=0,1,\\ldots,L-1,\n$$\nthat is,\n$$\n\\pi_{k}\\cdot\\frac{L-k}{L}=\\pi_{k+1}\\cdot\\frac{k+1}{L}.\n$$\nThis simplifies to the recurrence\n$$\n\\frac{\\pi_{k+1}}{\\pi_{k}}=\\frac{L-k}{k+1}.\n$$\nIterating from $k=0$ yields\n$$\n\\pi_{k}=\\pi_{0}\\prod_{j=0}^{k-1}\\frac{L-j}{j+1}=\\pi_{0}\\binom{L}{k}.\n$$\nNormalization $\\sum_{k=0}^{L}\\pi_{k}=1$ gives\n$$\n1=\\pi_{0}\\sum_{k=0}^{L}\\binom{L}{k}=\\pi_{0}\\,2^{L}\\quad\\Longrightarrow\\quad \\pi_{0}=2^{-L},\n$$\nhence\n$$\n\\pi_{k}=2^{-L}\\binom{L}{k}\\quad\\text{for all }k.\n$$\n\nThe all-ones bitstring corresponds uniquely to $k=L$. For an irreducible positive recurrent Markov chain with stationary distribution $\\pi$, Kac’s lemma states that the mean recurrence time to a state equals the reciprocal of its stationary probability. Therefore, the mean time to return to $k=L$ is\n$$\n\\mathbb{E}[\\text{first return time to }k=L]=\\frac{1}{\\pi_{L}}=\\frac{1}{2^{-L}\\binom{L}{L}}=2^{L}.\n$$\nAlthough the chain is periodic with period $2$, Kac’s formula for the mean recurrence time still holds, so the result is valid.\n\nThus, starting from the all-ones state, the expected number of steps to return to it for the first time is $2^{L}$.", "answer": "$$\\boxed{2^{L}}$$", "id": "1329929"}, {"introduction": "Recurrence and transience reveal their most profound properties in infinite state spaces, like particles moving on a lattice. This final problem [@problem_id:1329934] presents a hypothetical interacting particle system and challenges you to determine when they are guaranteed to meet again. The key to this problem lies in a powerful modeling technique: reducing a complex, multi-particle system to a simpler, single-particle random walk, and then applying one of the classic results of probability theory regarding the dimension-dependent nature of random walks.", "problem": "Consider a hypothetical physical system involving two interacting particles, a \"zeton\" and an \"anti-zeton,\" on an infinite $d$-dimensional cubic lattice, represented by the integer coordinates $\\mathbb{Z}^d$. Let their positions at a discrete time step $n$ be denoted by the vectors $X_n \\in \\mathbb{Z}^d$ and $Y_n \\in \\mathbb{Z}^d$. The particles are created in a \"collision state,\" meaning they start at the same location. Their subsequent evolution is governed by the following rules:\n\n1.  **Independent Random Walks**: As long as the particles are at different sites ($X_n \\neq Y_n$), they each perform an independent, simple symmetric random walk. In a simple symmetric random walk on $\\mathbb{Z}^d$, a particle at a site $\\vec{v}$ moves to one of its $2d$ nearest neighboring sites $\\vec{v} \\pm \\vec{e_i}$ (where $\\{\\vec{e_1}, \\dots, \\vec{e_d}\\}$ is the standard basis), with each of the $2d$ possible moves being chosen with equal probability $1/(2d)$.\n\n2.  **Annihilation-Re-creation Interaction**: If the particles meet at the same site ($X_n = Y_n$), they are said to \"annihilate.\" This event triggers a special re-creation rule for the next step. If $X_n = Y_n = \\vec{k}$, their positions at time $n+1$ are set to $X_{n+1} = \\vec{k} + \\vec{\\zeta}$ and $Y_{n+1} = \\vec{k} - \\vec{\\zeta}$. The step vector $\\vec{\\zeta}$ is chosen uniformly at random from the $2d$ possible nearest-neighbor step vectors $\\{\\pm \\vec{e_1}, \\dots, \\pm \\vec{e_d}\\}$. This interaction rule supersedes the standard random walk dynamics for the step immediately following a collision.\n\nA \"collision state\" is any configuration of the system where $X_n = Y_n$. A Markov process is said to be recurrent to a set of states if, starting from that set, the probability of eventually returning to it is 1. In this context, we define the collision state to be recurrent if, after one collision, a subsequent collision is guaranteed to occur at some later time. If this probability is less than 1, the collision state is transient.\n\nFor which integer dimensions $d \\ge 1$ is the collision state recurrent?\n\nA. For $d = 1$ only.\n\nB. For $d = 2$ only.\n\nC. For $d = 1$ and $d = 2$.\n\nD. For $d \\ge 3$ only.\n\nE. For all dimensions $d \\ge 1$.", "solution": "Define the difference process $D_{n}=X_{n}-Y_{n}\\in \\mathbb{Z}^{d}$. A collision at time $n$ is equivalent to $D_{n}=0$. We analyze $D_{n}$ to determine whether, starting from a collision, the process returns to $D=0$ with probability $1$.\n\nWhen $D_{n}\\neq 0$, the particles move independently by simple symmetric nearest-neighbor steps. Let $U_{n}$ and $V_{n}$ denote their steps at time $n$, where each of $U_{n}$ and $V_{n}$ is uniformly distributed on $\\{\\pm \\vec{e}_{1},\\dots,\\pm \\vec{e}_{d}\\}$ and they are independent. Then\n$$\nD_{n+1}-D_{n}=U_{n}-V_{n}.\n$$\nIt follows that\n$$\n\\mathbb{E}[D_{n+1}-D_{n}]=\\mathbb{E}[U_{n}]-\\mathbb{E}[V_{n}]=0,\n$$\nand, using independence,\n$$\n\\operatorname{Cov}(D_{n+1}-D_{n})=\\operatorname{Cov}(U_{n})+\\operatorname{Cov}(V_{n}),\n$$\nwhich is a finite, positive-definite matrix, since each $U_{n}$ (and $V_{n}$) takes one of the $2d$ unit vectors with equal probability. Hence, away from $0$, $D_{n}$ is a symmetric, spatially homogeneous random walk on $\\mathbb{Z}^{d}$ with mean zero and finite second moment. The increment distribution allows $D_{n+1}-D_{n}=0$ with positive probability (when $U_{n}=V_{n}$), making the walk lazy; laziness does not affect recurrence versus transience.\n\nAt a collision time $n$ with $D_{n}=0$, the special rule imposes\n$$\nX_{n+1}= \\vec{k}+\\vec{\\zeta},\\quad Y_{n+1}= \\vec{k}-\\vec{\\zeta}\\quad \\text{with }\\vec{\\zeta}\\text{ uniform on }\\{\\pm \\vec{e}_{1},\\dots,\\pm \\vec{e}_{d}\\},\n$$\nso\n$$\nD_{n+1}=X_{n+1}-Y_{n+1}=2\\vec{\\zeta}.\n$$\nThus, starting from a collision, the post-collision state of the difference is $D_{1}=2\\vec{\\zeta}$, uniformly among the $2d$ vectors $\\{\\pm 2\\vec{e}_{1},\\dots,\\pm 2\\vec{e}_{d}\\}$. From time $1$ onward and until a possible next collision, $D_{n}$ evolves by the independent-walk rule above, i.e., with increments $U_{n}-V_{n}$.\n\nTherefore, the event that there is a subsequent collision is exactly the event that the symmetric random walk $D_{n}$, started from a fixed nonzero position (specifically one of the $\\pm 2\\vec{e}_{i}$), ever hits $0$. By the Chung–Fuchs recurrence criterion (a generalization of Pólya’s theorem), any mean-zero symmetric random walk on $\\mathbb{Z}^{d}$ with finite second moment is recurrent if and only if $d\\leq 2$, and is transient if $d\\geq 3$. In particular, for $d=1$ and $d=2$, the hitting probability of the origin from any starting point is $1$, while for $d\\geq 3$ it is strictly less than $1$.\n\nConsequently, starting from a collision, the probability of a subsequent collision is $1$ if and only if $d=1$ or $d=2$, and it is less than $1$ for $d\\geq 3$. Hence the collision state is recurrent exactly in dimensions $d=1$ and $d=2$.", "answer": "$$\\boxed{C}$$", "id": "1329934"}]}