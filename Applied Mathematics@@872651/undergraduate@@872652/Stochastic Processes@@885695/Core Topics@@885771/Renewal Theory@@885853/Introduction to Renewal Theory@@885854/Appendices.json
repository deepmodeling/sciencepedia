{"hands_on_practices": [{"introduction": "A core application of renewal theory is to determine the long-run frequency of recurring events. This practice [@problem_id:1367478] uses the intuitive scenario of a traffic light system to apply the Elementary Renewal Theorem. By modeling the start of the green light as a renewal event, you will calculate the average rate of renewals, a fundamental skill in analyzing cyclical systems.", "problem": "Consider an advanced traffic-light system controlling a single intersection. The light cycles through green, yellow, and red phases. The duration of the green phase is a fixed constant $t_g$, and the duration of the yellow phase is a fixed constant $t_y$.\n\nTo improve traffic flow, the duration of the red phase is adaptive. After the yellow light ends, the system waits for a suitable gap in the cross-traffic before switching to green. This waiting time, which constitutes the red phase duration, is a random variable. We model the durations of successive red phases, denoted by $X_k$ for $k=1, 2, 3, \\ldots$, as independent and identically distributed random variables. Each $X_k$ follows an exponential distribution with a mean duration of $\\tau_r$.\n\nLet the process begin at time $t=0$ with the start of the first green light. The sequence of times at which the green light subsequently turns on constitutes a renewal process. The renewal function, $m(t)$, gives the expected number of renewals (i.e., green light initiations) that have occurred in the time interval $(0, t]$.\n\nDetermine the long-term average rate of green light initiations. In other words, find the limit $\\lim_{t\\to\\infty} \\frac{m(t)}{t}$. Express your answer as a symbolic expression in terms of $t_g$, $t_y$, and $\\tau_r$.", "solution": "Define the sequence of renewal epochs as the start times of consecutive green phases. Let $Y_{k}$ denote the inter-renewal time between the $k$-th and $(k+1)$-th green initiations. By the problem description, each cycle consists of a fixed green duration $t_{g}$, a fixed yellow duration $t_{y}$, and a random red duration $X_{k}$, where $\\{X_{k}\\}_{k\\geq 1}$ are independent and identically distributed with an exponential distribution of mean $\\tau_{r}$. Therefore,\n$$\nY_{k}=t_{g}+t_{y}+X_{k}.\n$$\nBecause the $X_{k}$ are i.i.d. and $t_{g},t_{y}$ are constants, the $Y_{k}$ are i.i.d. as well. The mean inter-renewal time is\n$$\n\\mu=\\mathbb{E}[Y_{k}]=\\mathbb{E}[t_{g}+t_{y}+X_{k}]=t_{g}+t_{y}+\\mathbb{E}[X_{k}]=t_{g}+t_{y}+\\tau_{r}.\n$$\nLet $m(t)$ be the renewal function, the expected number of renewals (green initiations) in $(0,t]$. By the elementary renewal theorem, for a renewal process with i.i.d. inter-renewal times having finite mean $\\mu$, the long-run renewal rate exists and is given by\n$$\n\\lim_{t\\to\\infty}\\frac{m(t)}{t}=\\frac{1}{\\mu}.\n$$\nSubstituting $\\mu=t_{g}+t_{y}+\\tau_{r}$ yields\n$$\n\\lim_{t\\to\\infty}\\frac{m(t)}{t}=\\frac{1}{t_{g}+t_{y}+\\tau_{r}}.\n$$", "answer": "$$\\boxed{\\frac{1}{t_{g}+t_{y}+\\tau_{r}}}$$", "id": "1367478"}, {"introduction": "Beyond long-term averages, it's often essential to understand the exact expected number of events that have occurred by a specific time. This exercise [@problem_id:1367484] delves into the structure of a discrete-time renewal process by asking you to derive the renewal function $m(n)$. You will discover the unique implications of the memoryless property of the geometric distribution, which leads to a surprisingly simple and elegant result.", "problem": "Consider a simplified model for a user's activity on a social media platform. The time is measured in discrete days, indexed by $t=1, 2, 3, \\ldots$. A \"renewal event\" in this model corresponds to the user making a new post.\n\nThe times between consecutive posts, denoted by the random variables $X_1, X_2, X_3, \\ldots$, are assumed to be independent and identically distributed. Each inter-posting time $X_i$ follows a geometric distribution with a probability mass function given by:\n$$P(X=k) = p(1-p)^{k-1} \\quad \\text{for } k=1, 2, 3, \\ldots$$\nHere, $p$ is a constant representing the daily probability of making a post, given that no post has been made since the previous one. The value of $p$ is in the range $0  p \\le 1$.\n\nThe time of the first post is $S_1 = X_1$, the time of the second post is $S_2 = X_1 + X_2$, and in general, the time of the $j$-th post is $S_j = \\sum_{i=1}^{j} X_i$.\n\nLet $N(n)$ be the total number of posts made in the time interval from day 1 to day $n$, inclusive. The renewal function, $m(n)$, is defined as the expected number of posts up to day $n$, i.e., $m(n) = E[N(n)]$.\n\nDetermine a simple, closed-form expression for the renewal function $m(n)$ in terms of the integer $n$ and the probability $p$.", "solution": "The problem asks for the renewal function $m(n) = E[N(n)]$, where $N(n)$ is the total number of posts (renewals) up to time $n$.\n\nWe can express the total number of renewals, $N(n)$, as a sum of indicator variables. Let $I_k$ be an indicator variable such that $I_k=1$ if a renewal occurs at time $k$, and $I_k=0$ otherwise. Then, the total number of renewals up to time $n$ is given by:\n$$N(n) = \\sum_{k=1}^{n} I_k$$\nBy the linearity of expectation, the renewal function $m(n)$ can be written as:\n$$m(n) = E[N(n)] = E\\left[\\sum_{k=1}^{n} I_k\\right] = \\sum_{k=1}^{n} E[I_k]$$\nThe expectation of an indicator variable is the probability of the event it indicates. Let $u_k = E[I_k] = P(\\text{a renewal occurs at time } k)$. Then the renewal function is the sum of these renewal probabilities:\n$$m(n) = \\sum_{k=1}^{n} u_k$$\nTo find $m(n)$, we first need to determine the renewal probability $u_k$ for any time $k \\ge 1$.\n\nA renewal occurs at time $k$ if either the first renewal occurs at time $k$, or a renewal occurred at some earlier time $j  k$ and the next inter-renewal period was exactly $k-j$. This relationship can be expressed using the discrete renewal equation for the probabilities $u_k$. Let $f_k = P(X=k)$ be the probability mass function of the inter-renewal times. The equation is:\n$$u_k = f_k + \\sum_{j=1}^{k-1} u_j f_{k-j}$$\nIn our case, the inter-renewal times are geometrically distributed with $f_k = p(1-p)^{k-1}$ for $k \\ge 1$. We can compute the first few values of $u_k$ to find a pattern.\n\nFor $k=1$:\n$$u_1 = f_1 = p(1-p)^{1-1} = p$$\nFor $k=2$:\n$$u_2 = f_2 + u_1 f_1 = p(1-p) + (p)(p) = p - p^2 + p^2 = p$$\nFor $k=3$:\n$$u_3 = f_3 + u_1 f_2 + u_2 f_1 = p(1-p)^2 + (p)(p(1-p)) + (p)(p) = p(1-2p+p^2) + p^2 - p^3 + p^2 = p - 2p^2 + p^3 + 2p^2 - p^3 = p$$\nThe pattern suggests that $u_k=p$ for all $k \\ge 1$. We can prove this is the correct solution by substituting $u_j = p$ into the right-hand side of the renewal equation and showing that it equals $p$.\n\nAssume $u_j = p$ for all $j  k$. The right-hand side of the renewal equation for $u_k$ becomes:\n$$f_k + \\sum_{j=1}^{k-1} p \\cdot f_{k-j} = p(1-p)^{k-1} + p \\sum_{j=1}^{k-1} p(1-p)^{k-j-1}$$\nLet's analyze the summation term. Let the index of summation be $i = k-j$. As $j$ goes from $1$ to $k-1$, $i$ goes from $k-1$ down to $1$.\n$$\\sum_{j=1}^{k-1} p(1-p)^{k-j-1} = \\sum_{i=1}^{k-1} p(1-p)^{i-1} = p \\sum_{i=0}^{k-2} (1-p)^{i}$$\nThe sum is a finite geometric series with first term $a=1$, ratio $r=1-p$, and $k-1$ terms. The sum is $\\frac{a(1-r^{k-1})}{1-r}$.\n$$p \\sum_{i=0}^{k-2} (1-p)^{i} = p \\cdot \\frac{1 - (1-p)^{k-1}}{1 - (1-p)} = p \\cdot \\frac{1 - (1-p)^{k-1}}{p} = 1 - (1-p)^{k-1}$$\nSubstituting this result back into the expression for $u_k$:\n$$u_k = p(1-p)^{k-1} + p \\left( 1 - (1-p)^{k-1} \\right)$$\n$$u_k = p(1-p)^{k-1} + p - p(1-p)^{k-1}$$\n$$u_k = p$$\nThus, we have proven that the renewal probability $u_k$ is constant and equal to $p$ for all $k \\ge 1$. This remarkable result is a consequence of the memoryless property of the geometric distribution. At any point in time, the probability of a renewal occurring is independent of the time elapsed since the last renewal, and is simply $p$.\n\nNow we can compute the renewal function $m(n)$:\n$$m(n) = \\sum_{k=1}^{n} u_k = \\sum_{k=1}^{n} p$$\nSince $p$ is a constant, this sum is straightforward:\n$$m(n) = np$$\nSo, the expected number of posts up to day $n$ is simply the product of $n$ and the daily posting probability $p$.", "answer": "$$\\boxed{np}$$", "id": "1367484"}, {"introduction": "A common operation in stochastic modeling is to merge independent processes, but does this preserve the renewal property? This problem [@problem_id:1367497] challenges you to investigate this question directly, serving as a critical test of your understanding of the defining properties of a renewal process. By analyzing the inter-arrival times of a merged process, you will explore the crucial condition of independence and discover a key subtlety in the theory.", "problem": "Consider two independent renewal processes, Process A and Process B. The processes begin at time $t=0$. The sequence of inter-renewal times for Process A is given by $\\{A_i\\}_{i \\ge 1}$, where the $A_i$ are independent and identically distributed (i.i.d.) random variables. Similarly, the inter-renewal times for Process B are an i.i.d. sequence $\\{B_i\\}_{i \\ge 1}$. The probability mass functions for these inter-renewal times are identical and are given by:\n$$ P(A_i = 1) = \\frac{1}{2}, \\quad P(A_i = 2) = \\frac{1}{2} $$\n$$ P(B_i = 1) = \\frac{1}{2}, \\quad P(B_i = 2) = \\frac{1}{2} $$\nThe time of the first event for Process A is $A_1$, the second is $A_1+A_2$, and so on. The same applies to Process B.\n\nA new merged process, Process S, is created by the superposition of Process A and Process B. The event times of Process S, denoted by $\\{T_k\\}_{k \\ge 1}$, are the unique, ordered event times from the combination of both processes. The inter-arrival times for Process S are defined as $Z_k = T_k - T_{k-1}$ for $k \\ge 1$, where $T_0 = 0$.\n\nAnalyze Process S and determine which of the following statements is/are true.\n\nA. The merged process S is a renewal process.\n\nB. The expected value of the first inter-arrival time in the merged process is $E[Z_1] = 1$.\n\nC. The probability that the first inter-arrival time in the merged process is 1 is $P(Z_1=1) = 3/4$.\n\nD. The inter-arrival times $Z_1, Z_2, Z_3, \\dots$ of the merged process are not an independent sequence of random variables.", "solution": "Let $A=\\{A_{i}\\}_{i\\geq 1}$ and $B=\\{B_{i}\\}_{i\\geq 1}$ be independent renewal processes with i.i.d. inter-renewal times satisfying $P(A_{i}=1)=\\frac{1}{2}$, $P(A_{i}=2)=\\frac{1}{2}$ and $P(B_{i}=1)=\\frac{1}{2}$, $P(B_{i}=2)=\\frac{1}{2}$. In the merged process $S$, the first inter-arrival time is the time to the first event among both processes, so $Z_{1}=\\min(A_{1},B_{1})$.\n\nSince $A_{1}$ and $B_{1}$ are independent and each takes values in $\\{1,2\\}$, we have\n$$\nP(Z_{1}=1)=P(\\min(A_{1},B_{1})=1)=1-P(A_{1}=2,B_{1}=2)=1-\\frac{1}{4}=\\frac{3}{4},\n$$\nand\n$$\nP(Z_{1}=2)=P(A_{1}=2,B_{1}=2)=\\frac{1}{4}.\n$$\nTherefore,\n$$\nE[Z_{1}]=1\\cdot P(Z_{1}=1)+2\\cdot P(Z_{1}=2)=1\\cdot\\frac{3}{4}+2\\cdot\\frac{1}{4}=\\frac{5}{4}.\n$$\nThis establishes that statement C is true and statement B is false.\n\nTo analyze dependence of successive inter-arrival times, split on how $T_{1}$ occurs. There are three disjoint cases:\n(i) $A_{1}=1$ and $B_{1}=1$ (a tie at time $1$) with probability $\\frac{1}{4}$; then both processes renew at time $1$, and $Z_{2}$ has the same distribution as $Z_{1}$, hence $P(Z_{2}=2\\mid \\text{case (i)})=\\frac{1}{4}$.\n(ii) Exactly one of $A_{1},B_{1}$ equals $1$ and the other equals $2$ (a non-tie at time $1$) with probability $\\frac{1}{2}$; then at time $1$ one process restarts and the other has a residual time $1$, so the next event occurs after time $1$ for sure, giving $P(Z_{2}=2\\mid \\text{case (ii)})=0$.\n(iii) $A_{1}=2$ and $B_{1}=2$ (a tie at time $2$) with probability $\\frac{1}{4}$; then both processes renew at time $2$, so again $P(Z_{2}=2\\mid \\text{case (iii)})=\\frac{1}{4}$.\n\nBy the law of total probability,\n$$\nP(Z_{2}=2)=\\frac{1}{4}\\cdot\\frac{1}{4}+\\frac{1}{2}\\cdot 0+\\frac{1}{4}\\cdot\\frac{1}{4}=\\frac{1}{8}.\n$$\nConditioning on $Z_{1}=1$ restricts to cases (i) and (ii). Since $P(Z_{1}=1)=\\frac{3}{4}$, the conditional probabilities of the cases are $P(\\text{case (i)}\\mid Z_{1}=1)=\\frac{(1/4)}{(3/4)}=\\frac{1}{3}$ and $P(\\text{case (ii)}\\mid Z_{1}=1)=\\frac{(1/2)}{(3/4)}=\\frac{2}{3}$. Thus\n$$\nP(Z_{2}=2\\mid Z_{1}=1)=\\frac{1}{3}\\cdot\\frac{1}{4}+\\frac{2}{3}\\cdot 0=\\frac{1}{12}\\neq \\frac{1}{8}=P(Z_{2}=2).\n$$\nHence $Z_{1},Z_{2},\\dots$ are not independent, so statement D is true. Since in a renewal process the inter-arrival times must be i.i.d., the merged process $S$ is not a renewal process; therefore statement A is false.\n\nCollecting conclusions: C and D are true; A and B are false.", "answer": "$$\\boxed{CD}$$", "id": "1367497"}]}