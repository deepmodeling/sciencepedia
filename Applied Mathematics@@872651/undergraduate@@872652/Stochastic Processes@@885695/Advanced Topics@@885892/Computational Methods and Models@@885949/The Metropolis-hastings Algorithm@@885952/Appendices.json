{"hands_on_practices": [{"introduction": "The core of the Metropolis-Hastings algorithm is the decision to accept or reject a proposed move. This first exercise provides a direct, hands-on calculation of this acceptance probability in a straightforward setting. By working with a discrete Poisson distribution and a symmetric proposal, you will apply the simplified Metropolis acceptance rule, which forms the foundation of the more general algorithm [@problem_id:1962612].", "problem": "A statistician is implementing a Markov Chain Monte Carlo (MCMC) simulation to generate samples from a target probability distribution. The chosen target distribution is a Poisson distribution, which models the number of events, $k$, occurring in a fixed interval of time or space. The probability mass function for a Poisson distribution is given by:\n$$ P(k; \\lambda) = \\frac{\\lambda^k e^{-\\lambda}}{k!} $$\nwhere $\\lambda$ is the average rate of events. For this specific simulation, the parameter is set to $\\lambda = 5$.\n\nThe simulation uses the Metropolis-Hastings algorithm with a symmetric proposal distribution, meaning the probability of proposing a move from state $k_1$ to state $k_2$ is the same as proposing a move from $k_2$ to $k_1$.\n\nSuppose the current state of the chain is $k=5$. The algorithm then proposes a move to a new state, $k'=6$.\n\nCalculate the acceptance probability for this proposed move from $k=5$ to $k'=6$. Express your answer as a decimal rounded to three significant figures.", "solution": "In the Metropolis-Hastings algorithm with a symmetric proposal distribution, the acceptance probability for a proposed move from state $k$ to $k'$ is\n$$\n\\alpha = \\min\\left(1, \\frac{\\pi(k')}{\\pi(k)}\\right),\n$$\nwhere $\\pi(\\cdot)$ is the target probability mass function. For a Poisson distribution with parameter $\\lambda$, the PMF is\n$$\n\\pi(k) = \\frac{\\lambda^{k} \\exp(-\\lambda)}{k!}.\n$$\nTherefore, the ratio simplifies as\n$$\n\\frac{\\pi(k')}{\\pi(k)} = \\frac{\\lambda^{k'} \\exp(-\\lambda) / k'!}{\\lambda^{k} \\exp(-\\lambda) / k!} = \\lambda^{k'-k} \\frac{k!}{k'!}.\n$$\nWith $k=5$, $k'=6$, and $\\lambda=5$, we have $k'-k=1$ and $6! = 6 \\cdot 5!$, so\n$$\n\\frac{\\pi(6)}{\\pi(5)} = \\lambda \\cdot \\frac{5!}{6!} = \\lambda \\cdot \\frac{1}{6} = \\frac{5}{6}.\n$$\nHence, the acceptance probability is\n$$\n\\alpha = \\min\\left(1, \\frac{5}{6}\\right) = \\frac{5}{6}.\n$$\nExpressed as a decimal rounded to three significant figures, this is $0.833$.", "answer": "$$\\boxed{0.833}$$", "id": "1962612"}, {"introduction": "The full Metropolis-Hastings algorithm includes a correction term that accounts for asymmetries in the proposal distribution. This practice demonstrates why this \"Hastings correction\" is not merely a technical detail but a crucial component for correctness. By analyzing a hypothetical case where the simplified rule is mistakenly applied to an asymmetric proposal, you will see how the resulting Markov chain fails to converge to the intended target distribution [@problem_id:1343405].", "problem": "An analyst is implementing a Markov Chain Monte Carlo (MCMC) algorithm to sample from a discrete target probability distribution $\\pi$ defined over three states: $S_1$, $S_2$, and $S_3$. The target distribution is given by:\n$$\n\\pi(S_1) = \\frac{1}{2}, \\quad \\pi(S_2) = \\frac{1}{3}, \\quad \\pi(S_3) = \\frac{1}{6}\n$$\nThe analyst designs a deterministic, cyclic proposal mechanism described by the proposal distribution $Q(x,y)$. From a state $S_i$, it always proposes the next state in the cycle $S_1 \\to S_2 \\to S_3 \\to S_1$. Specifically, the non-zero proposal probabilities are $Q(S_1, S_2) = 1$, $Q(S_2, S_3) = 1$, and $Q(S_3, S_1) = 1$.\n\nHowever, in setting up the acceptance probability $\\alpha(x,y)$, the analyst mistakenly uses the simplified Metropolis acceptance rule:\n$$\n\\alpha(x,y) = \\min\\left(1, \\frac{\\pi(y)}{\\pi(x)}\\right)\n$$\nwhich is generally only valid when the proposal distribution $Q(x,y)$ is symmetric.\n\nThe resulting Markov chain converges to a stationary distribution, let's call it $\\pi'$, which is different from the intended target distribution $\\pi$. Calculate the long-run probability that the chain is in state $S_2$. Express your answer as a fraction in simplest form.", "solution": "We construct the Markov chain induced by the deterministic proposal and the mistaken Metropolis acceptance rule. For states $S_{1}, S_{2}, S_{3}$, the proposal is $S_{1}\\to S_{2}\\to S_{3}\\to S_{1}$, and the acceptance probability used is\n$$\n\\alpha(x,y)=\\min\\left(1,\\frac{\\pi(y)}{\\pi(x)}\\right).\n$$\nGiven $\\pi(S_{1})=\\frac{1}{2}$, $\\pi(S_{2})=\\frac{1}{3}$, and $\\pi(S_{3})=\\frac{1}{6}$, the acceptance probabilities for proposed moves are:\n$$\n\\alpha(S_{1},S_{2})=\\min\\left(1,\\frac{\\pi(S_{2})}{\\pi(S_{1})}\\right)=\\min\\left(1,\\frac{\\frac{1}{3}}{\\frac{1}{2}}\\right)=\\frac{2}{3},\n$$\n$$\n\\alpha(S_{2},S_{3})=\\min\\left(1,\\frac{\\pi(S_{3})}{\\pi(S_{2})}\\right)=\\min\\left(1,\\frac{\\frac{1}{6}}{\\frac{1}{3}}\\right)=\\frac{1}{2},\n$$\n$$\n\\alpha(S_{3},S_{1})=\\min\\left(1,\\frac{\\pi(S_{1})}{\\pi(S_{3})}\\right)=\\min\\left(1,\\frac{\\frac{1}{2}}{\\frac{1}{6}}\\right)=1.\n$$\nThus, the transition probabilities (accept or stay) are:\n- From $S_{1}$: $P(S_{1}\\to S_{2})=\\frac{2}{3}$, $P(S_{1}\\to S_{1})=\\frac{1}{3}$.\n- From $S_{2}$: $P(S_{2}\\to S_{3})=\\frac{1}{2}$, $P(S_{2}\\to S_{2})=\\frac{1}{2}$.\n- From $S_{3}$: $P(S_{3}\\to S_{1})=1$.\n\nHence the transition matrix $P$ in the order $(S_{1},S_{2},S_{3})$ is\n$$\nP=\\begin{pmatrix}\n\\frac{1}{3}  \\frac{2}{3}  0 \\\\\n0  \\frac{1}{2}  \\frac{1}{2} \\\\\n1  0  0\n\\end{pmatrix}.\n$$\nLet the stationary distribution be $\\pi'=(a,b,c)$ with $a+b+c=1$ and $\\pi'=\\pi'P$. The stationarity equations are:\n$$\na=a\\cdot\\frac{1}{3}+b\\cdot 0+c\\cdot 1,\\quad\nb=a\\cdot\\frac{2}{3}+b\\cdot\\frac{1}{2}+c\\cdot 0,\\quad\nc=a\\cdot 0+b\\cdot\\frac{1}{2}+c\\cdot 0.\n$$\nFrom the third equation, $c=\\frac{b}{2}$. From the first equation, $a=\\frac{a}{3}+c$, hence $c=a-\\frac{a}{3}=\\frac{2a}{3}$. Equating the two expressions for $c$ gives $\\frac{b}{2}=\\frac{2a}{3}$, so $b=\\frac{4a}{3}$. Using $a+b+c=1$ with $c=\\frac{2a}{3}$ yields\n$$\na+\\frac{4a}{3}+\\frac{2a}{3}=a+2a=3a=1\\quad\\Rightarrow\\quad a=\\frac{1}{3},\n$$\nand therefore\n$$\nb=\\frac{4}{9},\\qquad c=\\frac{2}{9}.\n$$\nThus the long-run probability of being in state $S_{2}$ is $b=\\frac{4}{9}$.", "answer": "$$\\boxed{\\frac{4}{9}}$$", "id": "1343405"}, {"introduction": "Beyond the mathematical correctness of the algorithm lies the art of designing an efficient sampler. This final practice moves into this practical domain by exploring one of the most common challenges in MCMC: sampling from a distribution with multiple modes. This thought experiment on a bimodal distribution highlights how the choice of proposal step size can dramatically affect the sampler's ability to explore the entire target space, introducing key concepts like chain mixing and autocorrelation [@problem_id:1962668].", "problem": "A data scientist is analyzing the posterior probability distribution for a parameter $\\theta$ of a complex climate model. The analysis reveals that the posterior distribution, denoted as $p(\\theta)$, is bimodal, with two distinct peaks of high probability located at $\\theta_A$ and $\\theta_B$, separated by a wide region of very low probability. To explore this distribution and estimate properties like the posterior mean, the scientist employs the Metropolis-Hastings (M-H) algorithm.\n\nThe M-H sampler is initialized with a starting value $\\theta_0$ located within the high-probability region around the first peak, $\\theta_A$. A symmetric proposal distribution $q(\\theta' | \\theta) = \\mathcal{N}(\\theta' | \\theta, \\sigma^2)$ is used, where $\\mathcal{N}$ is a normal distribution centered at the current state $\\theta$ with a standard deviation $\\sigma$, which represents the proposal step size. The scientist, aiming for a high acceptance rate, chooses a very small value for $\\sigma$ relative to the distance between the two modes, $|\\theta_A - \\theta_B|$.\n\nAfter running the M-H sampler for a very large number of iterations, which of the following descriptions most accurately characterizes the expected outcome of this simulation?\n\nA. The sampler will efficiently find the global maximum of the posterior distribution $p(\\theta)$ and remain there, thus providing an excellent point estimate for the parameter.\nB. The acceptance rate for proposed states will be very low, causing the chain to remain near the initial state $\\theta_0$ and explore very little of the parameter space.\nC. The generated chain of samples will be highly autocorrelated, and its histogram will largely represent the shape of the mode around $\\theta_A$, while failing to discover the mode around $\\theta_B$.\nD. The samples will alternate between the two modes in a systematic fashion, jumping from the region of $\\theta_A$ to the region of $\\theta_B$ and back again with regular frequency.\nE. The states of the chain will be nearly independent of one another, indicating that the sampler has successfully converged to the true bimodal posterior distribution.", "solution": "We analyze the Metropolis-Hastings (M-H) sampler with a symmetric proposal and very small proposal scale relative to the distance between two separated modes of the posterior $p(\\theta)$ at $\\theta_{A}$ and $\\theta_{B}$.\n\nFor a symmetric proposal $q(\\theta' \\mid \\theta) = \\mathcal{N}(\\theta' \\mid \\theta, \\sigma^{2})$, the Metropolis-Hastings acceptance probability is\n$$\na(\\theta \\rightarrow \\theta') = \\min\\left\\{1, \\frac{p(\\theta')}{p(\\theta)}\\right\\}.\n$$\nThe chain is initialized at $\\theta_{0}$ in the high-probability region around $\\theta_{A}$. Because $\\sigma$ is chosen to be very small compared to the separation $|\\theta_{A} - \\theta_{B}|$, proposed moves satisfy $|\\theta' - \\theta| = O(\\sigma)$ and thus remain very close to the current state. In a high-probability region near a mode, $p(\\theta')$ is close to $p(\\theta)$ for small steps, so\n$$\n\\frac{p(\\theta')}{p(\\theta)} \\approx 1,\n$$\nimplying that $a(\\theta \\rightarrow \\theta') \\approx 1$ and the local acceptance rate is high. Hence, option B (very low acceptance rate) is contradicted by the small-step, within-mode behavior.\n\nNext, consider transitions between the modes. The probability to directly propose a state near $\\theta_{B}$ from a current state near $\\theta_{A}$ under the Gaussian proposal is\n$$\nq(\\theta_{B} \\mid \\theta) \\propto \\exp\\left(-\\frac{|\\theta_{B} - \\theta|^{2}}{2 \\sigma^{2}}\\right).\n$$\nSince $\\sigma \\ll |\\theta_{A} - \\theta_{B}|$, this proposal probability is exponentially small in $|\\theta_{A} - \\theta_{B}|^{2} / \\sigma^{2}$. Therefore, direct jumps across the low-probability valley are essentially never proposed on practical time scales. Alternatively, crossing the valley via many small steps requires repeatedly proposing moves into regions where $p(\\theta') \\ll p(\\theta)$, for which\n$$\na(\\theta \\rightarrow \\theta') = \\min\\left\\{1, \\frac{p(\\theta')}{p(\\theta)}\\right\\} \\ll 1,\n$$\nso such steps are overwhelmingly rejected. Consequently, the chain becomes effectively trapped near $\\theta_{A}$ for a very long time, failing to discover $\\theta_{B}$ in practice.\n\nBecause moves are very local and the chain stays within the same mode, successive samples are highly autocorrelated. The empirical histogram thus reflects the local shape around $\\theta_{A}$ but does not capture the separated mode near $\\theta_{B}$. This rules out option E (independence and successful convergence) and option D (regular alternation between modes). Option A is incorrect because M-H is a sampler targeting $p(\\theta)$, not an optimizer; moreover, with small steps and bimodality, it neither efficiently finds nor remains at a global maximum.\n\nTherefore, the most accurate description is that the chain exhibits high autocorrelation, predominantly samples the neighborhood of $\\theta_{A}$, and fails to discover the second mode $\\theta_{B}$.\n\nThe correct choice is C.", "answer": "$$\\boxed{C}$$", "id": "1962668"}]}