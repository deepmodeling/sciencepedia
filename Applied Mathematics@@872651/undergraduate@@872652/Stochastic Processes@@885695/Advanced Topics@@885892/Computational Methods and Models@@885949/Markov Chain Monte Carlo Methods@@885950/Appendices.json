{"hands_on_practices": [{"introduction": "The heart of the Metropolis algorithm is its decision-making process at each step. This practice [@problem_id:1371728] provides a concrete exercise in calculating the acceptance probability, the core mechanism that guides the Markov chain's exploration of the target distribution. Mastering this calculation is the first step toward understanding how MCMC samplers balance moving to higher-probability regions with occasionally exploring lower-probability ones.", "problem": "A data scientist is implementing a Markov Chain Monte Carlo (MCMC) simulation to draw samples from a posterior probability distribution for a parameter $x$. The target distribution, $\\pi(x)$, is proportional to the exponential of the negative absolute value of the parameter, such that $\\pi(x) \\propto \\exp(-|x|)$.\n\nThe scientist uses the Metropolis algorithm with a symmetric proposal distribution $q(x'|x)$, where the probability of proposing a new state $x'$ given the current state $x$ is equal to the probability of proposing $x$ given $x'$ (i.e., $q(x'|x) = q(x|x')$).\n\nSuppose that at a certain step in the simulation, the current state of the chain is $x = 1.5$. The algorithm then proposes a move to a new candidate state $x' = 2.0$.\n\nCalculate the acceptance probability for this specific move. Your answer should be a dimensionless real number. Round your final answer to four significant figures.", "solution": "The Metropolis acceptance probability for a move from $x$ to $x'$ with a symmetric proposal $q(x'|x)=q(x|x')$ is\n$$\n\\alpha(x \\to x')=\\min\\left(1,\\frac{\\pi(x')q(x|x')}{\\pi(x)q(x'|x)}\\right)=\\min\\left(1,\\frac{\\pi(x')}{\\pi(x)}\\right).\n$$\nGiven the target distribution $\\pi(x)\\propto \\exp(-|x|)$, the ratio simplifies to\n$$\n\\frac{\\pi(x')}{\\pi(x)}=\\frac{\\exp(-|x'|)}{\\exp(-|x|)}=\\exp\\!\\left(-\\left(|x'|-|x|\\right)\\right).\n$$\nWith $x=1.5$ and $x'=2.0$, we have $|x|=1.5$ and $|x'|=2.0$, so\n$$\n\\frac{\\pi(x')}{\\pi(x)}=\\exp\\!\\left(-\\left(2.0-1.5\\right)\\right)=\\exp(-0.5).\n$$\nTherefore,\n$$\n\\alpha(x \\to x')=\\min\\left(1,\\exp(-0.5)\\right)=\\exp(-0.5).\n$$\nNumerically, $\\exp(-0.5)\\approx 0.6065$ when rounded to four significant figures.", "answer": "$$\\boxed{0.6065}$$", "id": "1371728"}, {"introduction": "Beyond the basic mechanics, the efficiency of a Metropolis sampler depends critically on its tuning parameters. This problem [@problem_id:1932810] shifts focus from calculation to conceptual understanding, exploring the crucial trade-off in selecting the proposal distribution's width. By analyzing the consequences of steps that are too small or too large, you will develop an intuition for diagnosing sampler performance and achieving efficient exploration of the state space.", "problem": "An analyst is using a Markov Chain Monte Carlo (MCMC) method, specifically the Random Walk Metropolis algorithm, to generate samples from a continuous, unimodal target probability density function $\\pi(x)$ defined on the real line. The algorithm proceeds as follows: given the current state of the chain is $x^{(t)}$, a new candidate state $x'$ is proposed from a symmetric proposal distribution $q(x'|x^{(t)})$. For this specific implementation, the proposal is generated by adding a random perturbation: $x' = x^{(t)} + \\epsilon$, where $\\epsilon$ is drawn from a Normal distribution with mean 0 and standard deviation $\\sigma$, i.e., $\\epsilon \\sim N(0, \\sigma^2)$. The proposed state $x'$ is then accepted as the next state, $x^{(t+1)} = x'$, with probability $\\alpha(x', x^{(t)}) = \\min\\left(1, \\frac{\\pi(x')}{\\pi(x^{(t)})}\\right)$. If the proposal is rejected, the chain remains at the current state, i.e., $x^{(t+1)} = x^{(t)}$.\n\nThe analyst is experimenting with two different settings for the proposal distribution's standard deviation:\n1.  A very narrow proposal distribution, where $\\sigma = \\sigma_{small}$ is a very small positive number.\n2.  A very wide proposal distribution, where $\\sigma = \\sigma_{large}$ is a very large positive number.\n\nAssume the chain has been initialized in a region of non-negligible probability (e.g., near the mode of $\\pi(x)$). Which of the following statements most accurately describes the expected behavior of the MCMC chain in these two scenarios?\n\nA. The narrow proposal ($\\sigma_{small}$) will lead to a low acceptance rate and slow exploration. The wide proposal ($\\sigma_{large}$) will lead to a high acceptance rate and fast exploration.\n\nB. Both proposal widths will lead to similar acceptance rates, but the chain using the wide proposal ($\\sigma_{large}$) will explore the state space much more quickly than the chain using the narrow proposal ($\\sigma_{small}$).\n\nC. The narrow proposal ($\\sigma_{small}$) will result in a very high acceptance rate, but the chain will explore the state space very slowly. The wide proposal ($\\sigma_{large}$) will result in a very low acceptance rate, causing the chain to remain stuck at the same state for many iterations.\n\nD. The narrow proposal ($\\sigma_{small}$) will lead to a high acceptance rate and fast exploration. The wide proposal ($\\sigma_{large}$) will lead to a low acceptance rate and slow exploration.\n\nE. The width of the proposal distribution has a negligible effect on the algorithm's performance; both the acceptance rate and the speed of exploration are primarily determined by the properties of the target distribution $\\pi(x)$.", "solution": "The problem asks us to analyze the behavior of the Random Walk Metropolis algorithm, concentrating on how the width (standard deviation $\\sigma$) of the proposal distribution $N(0, \\sigma^2)$ affects the chain's acceptance rate and its ability to explore the state space of a target distribution $\\pi(x)$.\n\nThe acceptance probability for a proposed move from $x^{(t)}$ to $x'$ is given by $\\alpha(x', x^{(t)}) = \\min\\left(1, \\frac{\\pi(x')}{\\pi(x^{(t)})}\\right)$. Let's analyze the two cases separately.\n\n**Case 1: Narrow Proposal Distribution ($\\sigma = \\sigma_{small}$)**\n\nWhen the standard deviation $\\sigma_{small}$ is very small, the random perturbation $\\epsilon$ drawn from $N(0, \\sigma_{small}^2)$ will also be very small in magnitude. This means the proposed state, $x' = x^{(t)} + \\epsilon$, will be very close to the current state $x^{(t)}$.\n\nSince the target distribution $\\pi(x)$ is continuous, if $x'$ is very close to $x^{(t)}$, then the value of the probability density at these two points, $\\pi(x')$ and $\\pi(x^{(t)})$, will be very similar.\nConsequently, the ratio $\\frac{\\pi(x')}{\\pi(x^{(t)})}$ will be very close to 1.\n\nThe acceptance probability is $\\alpha(x', x^{(t)}) = \\min\\left(1, \\frac{\\pi(x')}{\\pi(x^{(t)})}\\right)$. Since the ratio is close to 1, the acceptance probability $\\alpha$ will be very high (close to 1). This means that almost every proposed move will be accepted.\n\nHowever, since each accepted move is just a tiny step away from the previous position, the chain moves through the state space very slowly. This is an inefficient way to explore the full range of the target distribution $\\pi(x)$, especially the tails. The chain exhibits high autocorrelation, meaning successive samples are highly dependent, and it takes a very large number of iterations to obtain a representative set of independent samples. This constitutes very slow exploration.\n\n**Case 2: Wide Proposal Distribution ($\\sigma = \\sigma_{large}$)**\n\nWhen the standard deviation $\\sigma_{large}$ is very large, the random perturbation $\\epsilon$ will often be large in magnitude. This means the proposed state $x' = x^{(t)} + \\epsilon$ is likely to be very far from the current state $x^{(t)}$.\n\nWe are given that the target distribution $\\pi(x)$ is unimodal and the chain starts in a region of high probability (near the mode). When the chain is in such a region, $\\pi(x^{(t)})$ is relatively large. A large jump from $x^{(t)}$ is very likely to land in a region far out in the tails of the distribution, where the probability density is extremely low. Thus, it is highly probable that $\\pi(x') \\ll \\pi(x^{(t)})$.\n\nIn this scenario, the ratio $\\frac{\\pi(x')}{\\pi(x^{(t)})}$ will be very close to 0.\n\nThe acceptance probability is $\\alpha(x', x^{(t)}) = \\min\\left(1, \\frac{\\pi(x')}{\\pi(x^{(t)})}\\right)$. Since the ratio is very small, the acceptance probability $\\alpha$ will also be very small. This means that the vast majority of proposed moves will be rejected.\n\nWhen a proposal is rejected, the chain does not move: $x^{(t+1)} = x^{(t)}$. Therefore, for a wide proposal distribution, the chain will remain stuck at the same state for many consecutive iterations, waiting for a rare proposal that happens to land in another high-probability region. This is also a very inefficient way to explore the state space.\n\n**Conclusion and Evaluation of Options:**\n\n-   A narrow proposal gives a **high acceptance rate** but **slow exploration**.\n-   A wide proposal gives a **low acceptance rate** and **slow exploration** (because the chain gets stuck).\n\nLet's evaluate the given options based on this analysis:\n\n-   **A:** Incorrect. It claims a wide proposal leads to a high acceptance rate.\n-   **B:** Incorrect. It claims both have similar acceptance rates.\n-   **C:** This statement correctly captures both behaviors. The narrow proposal leads to a high acceptance rate but slow exploration. The wide proposal leads to a very low acceptance rate, causing the chain to get stuck. This is the most accurate description.\n-   **D:** Incorrect. It claims a narrow proposal leads to fast exploration.\n-   **E:** Incorrect. The width of the proposal distribution is a critical tuning parameter that profoundly affects the algorithm's performance.\n\nTherefore, the most accurate statement is C.", "answer": "$$\\boxed{C}$$", "id": "1932810"}, {"introduction": "While the Metropolis algorithm is versatile, some problems are better suited to a different MCMC strategy: the Gibbs sampler. This method excels in multidimensional settings by breaking a complex problem into a series of simpler, one-dimensional draws. This practice [@problem_id:1316600] focuses on the essential prerequisite for Gibbs sampling—deriving the full conditional distributions from a joint probability function—revealing the mathematical foundation that makes this powerful technique possible.", "problem": "Consider a system of two types of interacting particles, A and B. Let the random variables $X$ and $Y$ represent the number of particles of type A and type B, respectively. The state space for the pair $(X, Y)$ is the set of all pairs of non-negative integers, i.e., $(x, y)$ where $x, y \\in \\{0, 1, 2, \\ldots\\}$. The joint probability mass function of observing a specific state $(x, y)$ is known to be proportional to the function\n$$\nf(x, y) = \\frac{\\alpha^x \\beta^y}{x! y!} \\exp(-\\lambda x y)\n$$\nwhere $\\alpha$, $\\beta$, and $\\lambda$ are positive real constants representing inherent creation rates and an interaction strength.\n\nYour task is to derive the conditional probability mass functions $P(X=x | Y=y)$ for a fixed $y$, and $P(Y=y | X=x)$ for a fixed $x$. Present your final answer as a pair of symbolic expressions for these two probabilities.", "solution": "The problem asks for the conditional probability mass functions (PMFs) $P(X=x | Y=y)$ and $P(Y=y | X=x)$ for a joint distribution where $P(X=x, Y=y) \\propto f(x, y)$.\n\nThe fundamental definition of conditional probability for discrete random variables is:\n$$\nP(X=x | Y=y) = \\frac{P(X=x, Y=y)}{P(Y=y)}\n$$\nThe marginal PMF $P(Y=y)$ is found by summing the joint PMF over all possible values of $X$:\n$$\nP(Y=y) = \\sum_{x'=0}^{\\infty} P(X=x', Y=y)\n$$\nSince the joint PMF is proportional to $f(x, y)$, we can write $P(X=x, Y=y) = C \\cdot f(x, y)$, where $C$ is a normalization constant that does not depend on $x$ or $y$. Substituting this into the conditional probability formula, we get:\n$$\nP(X=x | Y=y) = \\frac{C \\cdot f(x, y)}{\\sum_{x'=0}^{\\infty} C \\cdot f(x', y)} = \\frac{f(x, y)}{\\sum_{x'=0}^{\\infty} f(x', y)}\n$$\nThis shows that we can find the conditional distribution without needing to compute the overall normalization constant $C$.\n\nFirst, let's derive $P(X=x | Y=y)$.\nThe numerator is $f(x, y) = \\frac{\\alpha^x \\beta^y}{x! y!} \\exp(-\\lambda x y)$.\nThe denominator is the sum over all possible values of $x'$ for a fixed $y$:\n$$\n\\sum_{x'=0}^{\\infty} f(x', y) = \\sum_{x'=0}^{\\infty} \\frac{\\alpha^{x'} \\beta^y}{x' ! y!} \\exp(-\\lambda x' y)\n$$\nFor this summation, $y$ is a constant. We can factor out all terms that do not depend on the summation index $x'$:\n$$\n\\sum_{x'=0}^{\\infty} f(x', y) = \\frac{\\beta^y}{y!} \\sum_{x'=0}^{\\infty} \\frac{\\alpha^{x'}}{x'!} \\exp(-\\lambda x' y) = \\frac{\\beta^y}{y!} \\sum_{x'=0}^{\\infty} \\frac{(\\alpha \\exp(-\\lambda y))^{x'}}{x'!}\n$$\nThe summation has the form of the Taylor series for the exponential function, $\\sum_{k=0}^{\\infty} \\frac{z^k}{k!} = \\exp(z)$. In our case, $z = \\alpha \\exp(-\\lambda y)$. Therefore, the sum is:\n$$\n\\sum_{x'=0}^{\\infty} f(x', y) = \\frac{\\beta^y}{y!} \\exp(\\alpha \\exp(-\\lambda y))\n$$\nNow we can write the conditional probability:\n$$\nP(X=x | Y=y) = \\frac{\\frac{\\alpha^x \\beta^y}{x! y!} \\exp(-\\lambda x y)}{\\frac{\\beta^y}{y!} \\exp(\\alpha \\exp(-\\lambda y))}\n$$\nThe terms $\\frac{\\beta^y}{y!}$ cancel out, leaving:\n$$\nP(X=x | Y=y) = \\frac{\\alpha^x \\exp(-\\lambda x y)}{x! \\exp(\\alpha \\exp(-\\lambda y))} = \\frac{(\\alpha \\exp(-\\lambda y))^x}{x!} \\exp(-\\alpha \\exp(-\\lambda y))\n$$\nThis is the PMF of a Poisson distribution with parameter $\\alpha \\exp(-\\lambda y)$.\n\nNext, let's derive $P(Y=y | X=x)$. The procedure is symmetric.\n$$\nP(Y=y | X=x) = \\frac{f(x, y)}{\\sum_{y'=0}^{\\infty} f(x, y')}\n$$\nThe denominator is the sum over all possible values of $y'$ for a fixed $x$:\n$$\n\\sum_{y'=0}^{\\infty} f(x, y') = \\sum_{y'=0}^{\\infty} \\frac{\\alpha^x \\beta^{y'}}{x! y'!} \\exp(-\\lambda x y')\n$$\nFactoring out terms that do not depend on the summation index $y'$:\n$$\n\\sum_{y'=0}^{\\infty} f(x, y') = \\frac{\\alpha^x}{x!} \\sum_{y'=0}^{\\infty} \\frac{\\beta^{y'}}{y'!} \\exp(-\\lambda x y') = \\frac{\\alpha^x}{x!} \\sum_{y'=0}^{\\infty} \\frac{(\\beta \\exp(-\\lambda x))^{y'}}{y'!}\n$$\nAgain, using the Taylor series for the exponential function with $z = \\beta \\exp(-\\lambda x)$:\n$$\n\\sum_{y'=0}^{\\infty} f(x, y') = \\frac{\\alpha^x}{x!} \\exp(\\beta \\exp(-\\lambda x))\n$$\nNow we write the conditional probability:\n$$\nP(Y=y | X=x) = \\frac{\\frac{\\alpha^x \\beta^y}{x! y!} \\exp(-\\lambda x y)}{\\frac{\\alpha^x}{x!} \\exp(\\beta \\exp(-\\lambda x))}\n$$\nThe terms $\\frac{\\alpha^x}{x!}$ cancel out, leaving:\n$$\nP(Y=y | X=x) = \\frac{\\beta^y \\exp(-\\lambda x y)}{y! \\exp(\\beta \\exp(-\\lambda x))} = \\frac{(\\beta \\exp(-\\lambda x))^y}{y!} \\exp(-\\beta \\exp(-\\lambda x))\n$$\nThis is the PMF of a Poisson distribution with parameter $\\beta \\exp(-\\lambda x)$.", "answer": "$$\n\\boxed{\\begin{pmatrix} \\frac{(\\alpha \\exp(-\\lambda y))^{x}}{x!} \\exp(-\\alpha \\exp(-\\lambda y))  \\frac{(\\beta \\exp(-\\lambda x))^{y}}{y!} \\exp(-\\beta \\exp(-\\lambda x)) \\end{pmatrix}}\n$$", "id": "1316600"}]}