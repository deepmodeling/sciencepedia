{"hands_on_practices": [{"introduction": "The first step in analyzing a branching process is understanding its expected behavior. This exercise provides a foundational practice in calculating the mean population size over several generations [@problem_id:1317895]. By applying the fundamental formula $\\mathbb{E}[Z_n] = \\mu^n$, you will see how the average population size evolves, in this case for a subcritical process where extinction is the likely long-term outcome.", "problem": "A team of conservation biologists is studying the population dynamics of a newly discovered, extremely rare species of bioluminescent fungus. They model the growth of the fungal population using a Galton-Watson branching process. Let $Z_n$ represent the number of distinct fungal colonies in generation $n$. The study begins with a single viable colony, so the population at generation zero is $Z_0 = 1$.\n\nEach colony, after completing its life cycle, produces a random number of new offspring colonies. Based on extensive lab observations, the biologists have determined that the mean number of offspring produced by any single colony is $\\mu = 0.75$.\n\nAssuming the process starts with this single colony, calculate the expected number of fungal colonies in the 6th generation. Report your answer as a numerical value, rounded to four significant figures.", "solution": "We are given a Galton-Watson branching process with $Z_{0}=1$ and mean offspring number $\\mu=0.75$. In a Galton-Watson process, the expected population size satisfies the recursion\n$$\n\\mathbb{E}[Z_{n+1}\\mid Z_{n}] = \\mu Z_{n}.\n$$\nTaking expectations and using the law of total expectation gives\n$$\n\\mathbb{E}[Z_{n+1}] = \\mathbb{E}[\\mathbb{E}[Z_{n+1}\\mid Z_{n}]] = \\mathbb{E}[\\mu Z_{n}] = \\mu\\,\\mathbb{E}[Z_{n}].\n$$\nWith the initial condition $\\mathbb{E}[Z_{0}] = Z_{0} = 1$, this first-order linear recurrence solves to\n$$\n\\mathbb{E}[Z_{n}] = \\mu^{n}.\n$$\nFor $n=6$ and $\\mu=0.75$, we have\n$$\n\\mathbb{E}[Z_{6}] = (0.75)^{6} = \\left(\\frac{3}{4}\\right)^{6} = \\frac{3^{6}}{4^{6}} = \\frac{729}{4096} = 0.177978515625.\n$$\nRounded to four significant figures, this is $0.1780$.", "answer": "$$\\boxed{0.1780}$$", "id": "1317895"}, {"introduction": "While the mean provides a sense of the average population trajectory, the variance is crucial for understanding the uncertainty and potential fluctuations in population size. This problem challenges you to compute both the mean and the variance for a process with a Poisson-distributed number of offspring, a common model in many real-world applications [@problem_id:1317871]. Mastering this requires using the recursive relationship for variance, offering a deeper insight into the volatility inherent in stochastic population growth.", "problem": "In a materials science experiment, a single, newly-designed self-replicating nanobot is introduced into a suitable growth medium at generation $n=0$. In each subsequent generation, every nanobot present produces a random number of new, identical nanobots before it becomes inert. The number of 'offspring' produced by any single nanobot is independent of all others and follows a Poisson distribution with a mean of $\\lambda = 1.5$.\n\nLet $Z_n$ denote the total number of nanobots present in generation $n$. Starting with $Z_0=1$, calculate the mean and the variance of the nanobot population size at generation $n=3$.\n\nReport your answers for the mean and the variance, in that order, as a pair of numerical values rounded to four significant figures.", "solution": "We model the population $\\{Z_{n}\\}_{n \\geq 0}$ as a Galton–Watson branching process with one initial ancestor $Z_{0}=1$. Each individual produces an independent number of offspring $X$ with $X \\sim \\text{Poisson}(\\lambda)$, so\n$$\n\\mathbb{E}[X]=\\lambda,\\qquad \\operatorname{Var}(X)=\\lambda.\n$$\nGiven $Z_{n}$, the next generation is\n$$\nZ_{n+1}=\\sum_{i=1}^{Z_{n}} X_{n,i},\n$$\nwhere $\\{X_{n,i}\\}$ are i.i.d. copies of $X$, independent of $Z_{n}$. Conditional on $Z_{n}$, $Z_{n+1}$ is a sum of $Z_{n}$ independent Poisson$\\left(\\lambda\\right)$ variables, hence\n$$\n\\mathbb{E}[Z_{n+1}\\mid Z_{n}] = \\lambda Z_{n},\\qquad \\operatorname{Var}(Z_{n+1}\\mid Z_{n})=\\lambda Z_{n}.\n$$\n\nMean. Taking expectations gives the recursion\n$$\n\\mathbb{E}[Z_{n+1}] = \\lambda \\mathbb{E}[Z_{n}],\\quad \\mathbb{E}[Z_{0}]=1,\n$$\nwhose solution is\n$$\n\\mathbb{E}[Z_{n}] = \\lambda^{n}.\n$$\nThus for $n=3$,\n$$\n\\mathbb{E}[Z_{3}] = \\lambda^{3}.\n$$\n\nVariance. By the law of total variance,\n$$\n\\operatorname{Var}(Z_{n+1}) = \\mathbb{E}[\\operatorname{Var}(Z_{n+1}\\mid Z_{n})] + \\operatorname{Var}(\\mathbb{E}[Z_{n+1}\\mid Z_{n}])\n= \\mathbb{E}[\\lambda Z_{n}] + \\operatorname{Var}(\\lambda Z_{n})\n= \\lambda \\mathbb{E}[Z_{n}] + \\lambda^{2} \\operatorname{Var}(Z_{n}).\n$$\nSince $\\mathbb{E}[Z_{n}] = \\lambda^{n}$ and $\\operatorname{Var}(Z_{0})=0$, we obtain the recursion\n$$\n\\operatorname{Var}(Z_{n+1}) = \\lambda^{n+1} + \\lambda^{2} \\operatorname{Var}(Z_{n}).\n$$\nIterating up to $n=3$:\n$$\n\\operatorname{Var}(Z_{1}) = \\lambda^{1},\n$$\n$$\n\\operatorname{Var}(Z_{2}) = \\lambda^{2} + \\lambda^{2}\\operatorname{Var}(Z_{1}) = \\lambda^{2} + \\lambda^{3},\n$$\n$$\n\\operatorname{Var}(Z_{3}) = \\lambda^{3} + \\lambda^{2}\\operatorname{Var}(Z_{2}) = \\lambda^{3} + \\lambda^{2}(\\lambda^{2} + \\lambda^{3}) = \\lambda^{3} + \\lambda^{4} + \\lambda^{5}.\n$$\n\nWith $\\lambda=1.5$, the mean and variance at generation $n=3$ are\n$$\n\\mathbb{E}[Z_{3}] = (1.5)^{3} = 3.375,\n$$\n$$\n\\operatorname{Var}(Z_{3}) = (1.5)^{3} + (1.5)^{4} + (1.5)^{5} = 16.03125.\n$$\nRounded to four significant figures, these are $3.375$ and $16.03$.", "answer": "$$\\boxed{\\begin{pmatrix}3.375  16.03\\end{pmatrix}}$$", "id": "1317871"}, {"introduction": "The mean ($\\mu$) and variance ($\\sigma^2$) of the offspring distribution are the building blocks for analyzing a branching process, but how are they determined from the underlying reproductive rules? This practice introduces the powerful technique of using a Probability Generating Function (PGF) to find these essential parameters [@problem_id:1317910]. By working directly with the PGF, you will learn to connect the microscopic details of reproduction to the macroscopic dynamics of the population, a fundamental skill in stochastic modeling.", "problem": "In a simplified model of fault propagation within a large-scale distributed computing network, an initial fault in a single node at generation 0 ($X_0 = 1$) can spread to other nodes in discrete time steps. A faulty node, during a single time step, attempts to communicate with $k$ other distinct, healthy nodes. For each of these $k$ communications, there is a probability $p$ that the fault is successfully transmitted, with each transmission being an independent event. After this propagation step, the source node is isolated and considered removed. The number of new nodes that become faulty, caused by a single faulty node, is a random variable whose statistical properties are described by its Probability Generating Function (PGF), $G(s)$.\n\nFor this specific propagation model, the PGF of the offspring distribution (i.e., the number of new faulty nodes generated by a single faulty node) is given by:\n$$G(s) = (1-p+ps)^k$$\nwhere $k$ is a positive integer and $0  p  1$.\n\nLet $X_n$ denote the number of faulty nodes in generation $n$. Assuming the process starts with a single faulty node, $X_0 = 1$, determine a closed-form expression for the variance of the number of faulty nodes at generation 2, $Var(X_2)$, in terms of the parameters $p$ and $k$.", "solution": "The process is a Galton–Watson branching process with offspring PGF $G(s)=(1-p+ps)^{k}$. For an offspring distribution with PGF $G$, the mean and variance of the number of offspring $Z$ are given by\n$$\\mathbb{E}[Z]=G'(1), \\quad \\mathrm{Var}(Z)=G''(1)+G'(1)-\\left(G'(1)\\right)^{2}.$$\nCompute derivatives:\n$$G'(s)=k p (1-p+p s)^{k-1}, \\quad G''(s)=k (k-1) p^{2} (1-p+p s)^{k-2}.$$\nEvaluating at $s=1$ gives\n$$m \\equiv \\mathbb{E}[Z]=G'(1)=k p, \\quad G''(1)=k (k-1) p^{2},$$\nso\n$$\\sigma^{2} \\equiv \\mathrm{Var}(Z)=k (k-1) p^{2}+k p - (k p)^{2}=k p (1-p).$$\nWith $X_{0}=1$, we have $X_{1}\\sim$ offspring distribution, hence $\\mathbb{E}[X_{1}]=m$ and $\\mathrm{Var}(X_{1})=\\sigma^{2}$. The generation-$2$ count can be written as\n$$X_{2}=\\sum_{i=1}^{X_{1}} Z_{i},$$\nwhere the $Z_{i}$ are independent copies of the offspring variable, independent of $X_{1}$. Then\n$$\\mathbb{E}[X_{2}\\mid X_{1}]=m X_{1}, \\quad \\mathrm{Var}(X_{2}\\mid X_{1})=\\sigma^{2} X_{1}.$$\nUsing the law of total expectation and the law of total variance,\n$$\\mathbb{E}[X_{2}]=\\mathbb{E}[\\,\\mathbb{E}[X_{2}\\mid X_{1}]\\,]=m\\,\\mathbb{E}[X_{1}]=m^{2},$$\n$$\\mathrm{Var}(X_{2})=\\mathbb{E}[\\mathrm{Var}(X_{2}\\mid X_{1})]+\\mathrm{Var}(\\mathbb{E}[X_{2}\\mid X_{1}])=\\sigma^{2}\\mathbb{E}[X_{1}]+m^{2}\\mathrm{Var}(X_{1})=\\sigma^{2} m + m^{2}\\sigma^{2}=\\sigma^{2} m (1+m).$$\nSubstituting $m=k p$ and $\\sigma^{2}=k p (1-p)$ yields\n$$\\mathrm{Var}(X_{2})=k p (1-p)\\,k p\\,(1+k p)=k^{2} p^{2} (1-p)(1+k p).$$", "answer": "$$\\boxed{k^{2} p^{2} (1-p)\\left(1+k p\\right)}$$", "id": "1317910"}]}