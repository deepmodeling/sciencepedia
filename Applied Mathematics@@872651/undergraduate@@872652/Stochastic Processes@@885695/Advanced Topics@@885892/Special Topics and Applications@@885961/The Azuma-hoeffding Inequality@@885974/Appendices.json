{"hands_on_practices": [{"introduction": "To begin, we explore the most fundamental application of a concentration inequality, often known as Hoeffding's inequality. This exercise [@problem_id:1336259] examines the sum of independent and identically distributed variables, a scenario akin to a series of fair coin flips. By calculating a bound on the deviation from the expected number of successes, you will develop a core intuition for how random outcomes tend to cluster around their average, a principle that underpins many results in statistics and machine learning.", "problem": "An autonomous system is designed to perform a series of $n$ independent binary tasks. For each task, the system has two possible actions, and only one of them is correct. In its initial, untrained state, the system chooses an action for each task completely at random, with each of the two actions being equally likely. After each task, the system receives feedback indicating whether its chosen action was correct.\n\nLet $C_n$ denote the total number of correctly performed tasks out of the total $n$ tasks. The expected number of successes is $E[C_n]$. We are interested in the probability that the actual number of successes deviates significantly from this expectation.\n\nFor a given positive real number $t$, find a non-trivial upper bound for the probability $P(|C_n - E[C_n]| \\geq t)$. Your answer should be an analytical expression in terms of $n$ and $t$.", "solution": "Define indicator variables $X_{i}$ for $i \\in \\{1,\\dots,n\\}$ by $X_{i}=1$ if the system performs task $i$ correctly and $X_{i}=0$ otherwise. Since in the untrained state each task’s action is chosen uniformly at random from two equally likely options and tasks are independent, the variables $X_{i}$ are independent and identically distributed with $P(X_{i}=1)=\\frac{1}{2}$ and $P(X_{i}=0)=\\frac{1}{2}$. Thus $X_{i} \\in [0,1]$ almost surely and $E[X_{i}]=\\frac{1}{2}$ for all $i$.\n\nThe total number of correctly performed tasks is the sum\n$$\nC_{n}=\\sum_{i=1}^{n} X_{i},\n$$\nand its expectation is\n$$\nE[C_{n}]=\\sum_{i=1}^{n} E[X_{i}]=\\sum_{i=1}^{n} \\frac{1}{2}=\\frac{n}{2}.\n$$\n\nWe apply Hoeffding’s inequality for sums of independent bounded random variables. If $X_{i}$ are independent with $a_{i} \\leq X_{i} \\leq b_{i}$ almost surely, and $S_{n}=\\sum_{i=1}^{n} X_{i}$, then for any $t0$,\n$$\nP\\big(|S_{n}-E[S_{n}]|\\geq t\\big) \\leq 2 \\exp\\left(-\\frac{2 t^{2}}{\\sum_{i=1}^{n} (b_{i}-a_{i})^{2}}\\right).\n$$\nHere, $a_{i}=0$ and $b_{i}=1$ for all $i$, so $\\sum_{i=1}^{n} (b_{i}-a_{i})^{2}=n$. Substituting $S_{n}=C_{n}$ and this bound into Hoeffding’s inequality yields the non-trivial deviation bound\n$$\nP\\big(|C_{n}-E[C_{n}]|\\geq t\\big) \\leq 2 \\exp\\left(-\\frac{2 t^{2}}{n}\\right).\n$$\nThis is an analytical expression in terms of $n$ and $t$ and applies for all $t0$.", "answer": "$$\\boxed{2 \\exp\\left(-\\frac{2 t^{2}}{n}\\right)}$$", "id": "1336259"}, {"introduction": "Moving beyond the simple case of identical variables, this practice problem introduces a more realistic scenario where independent events have varying impacts. We will analyze the total computational load on a server farm where each server contributes a different amount [@problem_id:1336240]. This exercise demonstrates the flexibility of the inequality, showing how it accommodates sums of independent variables that are bounded differently, a common feature in many engineering and financial models.", "problem": "A data center operates a cluster of $n=200$ independent servers. For server $i$, where $i=1, 2, \\ldots, 200$, its computational load, if active, is quantified by a fixed score $c_i = \\frac{i}{200}$. On any given day, each server $i$ has a probability of being active of exactly $1/2$, independently of all other servers. The total load on the system is the sum of the scores of all active servers.\n\nWe are interested in the stability of the system's total load. Calculate a theoretical upper bound for the probability that the total daily load deviates from its expected value by at least $10.0$ units.\n\nRound your final answer to three significant figures.", "solution": "Let $X_{i}$ be the indicator that server $i$ is active on a given day, so $X_{i} \\sim \\text{Bernoulli}(1/2)$ independently for $i=1,2,\\ldots,200$. The load contribution of server $i$ is $c_{i}X_{i}$ with $c_{i}=\\frac{i}{200}$, so the total load is\n$$\nS=\\sum_{i=1}^{200} c_{i}X_{i}.\n$$\nThe expected total load is\n$$\n\\mathbb{E}[S]=\\sum_{i=1}^{200} c_{i}\\mathbb{E}[X_{i}]=\\frac{1}{2}\\sum_{i=1}^{200} c_{i}=\\frac{1}{2}\\cdot \\frac{1}{200}\\sum_{i=1}^{200} i=\\frac{1}{2}\\cdot \\frac{1}{200}\\cdot \\frac{200\\cdot 201}{2}=\\frac{201}{4}.\n$$\nWe seek an upper bound on $\\mathbb{P}(|S-\\mathbb{E}[S]|\\geq 10)$. Since each summand $Y_{i}=c_{i}X_{i}$ lies in the interval $[0,c_{i}]$, Hoeffding’s inequality for independent bounded variables gives\n$$\n\\mathbb{P}\\big(|S-\\mathbb{E}[S]|\\geq t\\big)\\leq 2\\exp\\left(-\\frac{2t^{2}}{\\sum_{i=1}^{200} (c_{i}-0)^{2}}\\right)=2\\exp\\left(-\\frac{2t^{2}}{\\sum_{i=1}^{200} c_{i}^{2}}\\right).\n$$\nCompute the denominator:\n$$\n\\sum_{i=1}^{200} c_{i}^{2}=\\sum_{i=1}^{200}\\left(\\frac{i}{200}\\right)^{2}=\\frac{1}{200^{2}}\\sum_{i=1}^{200} i^{2}=\\frac{1}{40000}\\cdot \\frac{200\\cdot 201\\cdot 401}{6}=\\frac{80601}{1200}.\n$$\nWith $t=10$, the bound becomes\n$$\n\\mathbb{P}\\big(|S-\\mathbb{E}[S]|\\geq 10\\big)\\leq 2\\exp\\left(-\\frac{2\\cdot 10^{2}}{\\frac{80601}{1200}}\\right)=2\\exp\\left(-\\frac{240000}{80601}\\right).\n$$\nNumerically evaluating the right-hand side and rounding to three significant figures gives approximately $0.102$.", "answer": "$$\\boxed{0.102}$$", "id": "1336240"}, {"introduction": "This final exercise reveals the full power of the Azuma-Hoeffding inequality by tackling a process with inherent dependencies. Here, the outcome of one event directly influences the probabilities of the next, a structure that simple independence assumptions cannot capture [@problem_id:1336222]. By identifying and analyzing the underlying martingale structure, you will see how this powerful tool provides strong concentration bounds even when variables are not independent, unlocking its use for analyzing complex, evolving systems.", "problem": "A game of chance consists of a sequence of $n$ coin flips. The outcome of the $i$-th flip is denoted by a random variable $X_i$, with $X_i=1$ if the result is heads and $X_i=0$ if it is tails.\n\nThe probability of heads is not constant. For the first flip ($i=1$), the probability of heads is $p_1 = p$. For any subsequent flip $i  1$, the probability of heads, $p_i$, is determined by the outcome of the preceding flip, $X_{i-1}$, as follows:\n- If flip $i-1$ was heads ($X_{i-1}=1$), then $p_i = p - \\delta$.\n- If flip $i-1$ was tails ($X_{i-1}=0$), then $p_i = p + \\delta$.\n\nThe parameters $p$ and $\\delta$ are constants satisfying $0  \\delta  \\min(p, 1-p)$.\n\nA player participates in a betting game based on these flips. At the start of each round $i$ (from $1$ to $n$), the player pays a fee of $p_i$ dollars to play. If the coin flip results in heads ($X_i=1$), the player receives a payout of 1 dollar. If it results in tails ($X_i=0$), the player receives nothing. Let $W_n$ be the player's total net winnings after all $n$ rounds.\n\nFind a simple upper bound for the probability that the magnitude of the player's total net winnings is at least $t$, where $t$ is a positive constant. Express your answer in terms of $n$ and $t$.", "solution": "Let $X_{i}\\in\\{0,1\\}$ be the outcome of flip $i$, and let $p_{i}$ be the fee paid at the start of round $i$, with $p_{1}=p$ and, for $i1$, $p_{i}=p-\\delta$ if $X_{i-1}=1$ and $p_{i}=p+\\delta$ if $X_{i-1}=0$. The net gain in round $i$ is $X_{i}-p_{i}$, so the total net winnings after $n$ rounds are\n$$\nW_{n}=\\sum_{i=1}^{n}\\left(X_{i}-p_{i}\\right).\n$$\nLet $\\mathcal{F}_{i}=\\sigma(X_{1},\\ldots,X_{i})$ be the natural filtration. By construction of the process, for each $i$,\n$$\n\\mathbb{E}\\left[X_{i}\\mid\\mathcal{F}_{i-1}\\right]=p_{i},\n$$\nhence\n$$\n\\mathbb{E}\\left[X_{i}-p_{i}\\mid\\mathcal{F}_{i-1}\\right]=0.\n$$\nTherefore $\\{W_{i}\\}_{i=0}^{n}$ with $W_{0}=0$ and $W_{i}=\\sum_{j=1}^{i}(X_{j}-p_{j})$ is a martingale.\n\nThe increments satisfy the almost-sure bounds\n$$\n-p_{i}\\leq X_{i}-p_{i}\\leq 1-p_{i},\n$$\nso their range length is\n$$\n(1-p_{i})-(-p_{i})=1\\quad\\text{for every }i.\n$$\nApplying the Azuma–Hoeffding inequality for martingales with differences bounded in intervals $[a_{i},b_{i}]$, which states that\n$$\n\\mathbb{P}\\left(W_{n}\\geq t\\right)\\leq\\exp\\left(-\\frac{2t^{2}}{\\sum_{i=1}^{n}(b_{i}-a_{i})^{2}}\\right),\n$$\nand using $b_{i}-a_{i}=1$ for all $i$, we obtain the one-sided bound\n$$\n\\mathbb{P}\\left(W_{n}\\geq t\\right)\\leq\\exp\\left(-\\frac{2t^{2}}{n}\\right).\n$$\nBy symmetry (or applying the same bound to $-W_{n}$), we get\n$$\n\\mathbb{P}\\left(W_{n}\\leq -t\\right)\\leq\\exp\\left(-\\frac{2t^{2}}{n}\\right).\n$$\nCombining the two tails yields the desired two-sided bound\n$$\n\\mathbb{P}\\left(|W_{n}|\\geq t\\right)\\leq 2\\exp\\left(-\\frac{2t^{2}}{n}\\right).\n$$\nThis bound depends only on $n$ and $t$, as required.", "answer": "$$\\boxed{2\\exp\\left(-\\frac{2t^{2}}{n}\\right)}$$", "id": "1336222"}]}