{"hands_on_practices": [{"introduction": "The power of the Gamma distribution lies in its flexibility, controlled by the shape parameter $\\alpha$ and rate parameter $\\lambda$. These parameters directly determine fundamental statistical properties like the mean and variance. This first exercise provides a practical application, showing how to reverse-engineer the values of $\\alpha$ and $\\lambda$ from known mean and variance, a common task when fitting a distribution to observed data. [@problem_id:1398490]", "problem": "The lifetime of a particular model of electronic component is modeled as a random variable, $X$, where $X$ is measured in thousands of hours. The probability distribution of $X$ is known to be a Gamma distribution. A random variable $Y$ that follows a Gamma distribution with a shape parameter $\\alpha > 0$ and a rate parameter $\\lambda > 0$, denoted as $Y \\sim \\Gamma(\\alpha, \\lambda)$, has an expected value (mean) given by $E[Y] = \\frac{\\alpha}{\\lambda}$ and a variance given by $\\text{Var}(Y) = \\frac{\\alpha}{\\lambda^2}$.\n\nFrom extensive testing on a large sample of these components, the mean lifetime is determined to be 10,000 hours, and the variance of their lifetimes is 20,000,000 hours$^2$.\n\nFind the shape parameter, $\\alpha$, and the rate parameter, $\\lambda$, for the probability distribution of the component's lifetime $X$.", "solution": "Let $T$ denote the lifetime in hours and $X$ denote the lifetime in thousands of hours, so $X=\\frac{T}{10^{3}}$. Using linearity of expectation and the scaling rule for variance, we have\n$$E[X]=\\frac{E[T]}{10^{3}}, \\quad \\text{Var}(X)=\\frac{\\text{Var}(T)}{10^{6}}.$$\nGiven $E[T]=10{,}000$ hours and $\\text{Var}(T)=20{,}000{,}000$ hours$^{2}$, it follows that\n$$E[X]=\\frac{10{,}000}{10^{3}}=10, \\quad \\text{Var}(X)=\\frac{20{,}000{,}000}{10^{6}}=20.$$\n\nAssuming $X \\sim \\Gamma(\\alpha,\\lambda)$ with rate parameter $\\lambda$, the mean and variance are\n$$E[X]=\\frac{\\alpha}{\\lambda}, \\quad \\text{Var}(X)=\\frac{\\alpha}{\\lambda^{2}}.$$\nSet these equal to the empirical values:\n$$\\frac{\\alpha}{\\lambda}=10, \\quad \\frac{\\alpha}{\\lambda^{2}}=20.$$\nFrom $\\frac{\\alpha}{\\lambda}=10$ we get $\\alpha=10\\lambda$. Substitute into the variance equation:\n$$\\frac{10\\lambda}{\\lambda^{2}}=20 \\quad \\Longrightarrow \\quad \\frac{10}{\\lambda}=20 \\quad \\Longrightarrow \\quad \\lambda=\\frac{1}{2}.$$\nThen\n$$\\alpha=10\\left(\\frac{1}{2}\\right)=5.$$\n\nTherefore, the shape and rate parameters are $\\alpha=5$ and $\\lambda=\\frac{1}{2}$.", "answer": "$$\\boxed{\\begin{pmatrix}5  \\frac{1}{2}\\end{pmatrix}}$$", "id": "1398490"}, {"introduction": "The formulas for the mean and variance of a Gamma distribution are foundational, but where do they come from? The moment generating function (MGF) is a powerful mathematical tool that 'encodes' all the moments of a distribution. By differentiating the MGF, we can systematically derive these key properties, offering a deeper insight into the distribution's structure. This practice guides you through the derivation of the variance, a fundamental exercise in theoretical probability. [@problem_id:8017]", "problem": "A continuous random variable $X$ is said to follow a Gamma distribution with shape parameter $\\alpha > 0$ and rate parameter $\\lambda > 0$, denoted as $X \\sim \\text{Gamma}(\\alpha, \\lambda)$, if its probability density function (PDF) is given by:\n$$f(x; \\alpha, \\lambda) = \\frac{\\lambda^\\alpha}{\\Gamma(\\alpha)} x^{\\alpha-1} e^{-\\lambda x}$$\nfor $x > 0$, and $f(x) = 0$ for $x \\leq 0$. Here, $\\Gamma(\\alpha)$ is the Gamma function.\n\nThe moment generating function (MGF) of this distribution, for $t  \\lambda$, is given by:\n$$M_X(t) = E[e^{tX}] = \\left(\\frac{\\lambda}{\\lambda - t}\\right)^\\alpha = (1 - t/\\lambda)^{-\\alpha}$$\nThe moments of the random variable $X$ can be found by taking derivatives of the MGF and evaluating them at $t=0$. Specifically, the $k$-th moment is given by $E[X^k] = M_X^{(k)}(0)$, where $M_X^{(k)}(t)$ is the $k$-th derivative of $M_X(t)$ with respect to $t$.\n\nThe variance of a random variable $X$ is defined as:\n$$\\text{Var}(X) = E[X^2] - (E[X])^2$$\nUsing the provided moment generating function and the relationships above, derive the variance of the Gamma distribution, $\\text{Var}(X)$, in terms of the parameters $\\alpha$ and $\\lambda$. For this derivation, you may find it more convenient to use the form $M_X(t) = \\lambda^\\alpha (\\lambda - t)^{-\\alpha}$.", "solution": "The goal is to derive the variance of a Gamma distributed random variable $X$ using its moment generating function (MGF), $M_X(t)$. The variance is given by $\\text{Var}(X) = E[X^2] - (E[X])^2$. We must first find the first two moments, $E[X]$ and $E[X^2]$.\n\nThe MGF of the Gamma($\\alpha, \\lambda$) distribution is provided as:\n$$M_X(t) = \\lambda^\\alpha (\\lambda - t)^{-\\alpha}$$\nThe first moment, $E[X]$, is the first derivative of the MGF evaluated at $t=0$.\n$$E[X] = M_X'(0)$$\nFirst, we find the derivative of $M_X(t)$ with respect to $t$ using the chain rule:\n$$M_X'(t) = \\frac{d}{dt} \\left[ \\lambda^\\alpha (\\lambda - t)^{-\\alpha} \\right]$$\n$$M_X'(t) = \\lambda^\\alpha \\cdot (-\\alpha)(\\lambda - t)^{-\\alpha-1} \\cdot (-1)$$\n$$M_X'(t) = \\alpha \\lambda^\\alpha (\\lambda - t)^{-\\alpha-1}$$\nNow, we evaluate this derivative at $t=0$:\n$$M_X'(0) = \\alpha \\lambda^\\alpha (\\lambda - 0)^{-\\alpha-1} = \\alpha \\lambda^\\alpha \\lambda^{-\\alpha-1}$$\n$$M_X'(0) = \\alpha \\lambda^{\\alpha - (\\alpha+1)} = \\alpha \\lambda^{-1} = \\frac{\\alpha}{\\lambda}$$\nThus, the first moment (the mean) is:\n$$E[X] = \\frac{\\alpha}{\\lambda}$$\n\nNext, we find the second moment, $E[X^2]$, by taking the second derivative of the MGF and evaluating it at $t=0$.\n$$E[X^2] = M_X''(0)$$\nWe differentiate $M_X'(t)$ with respect to $t$:\n$$M_X''(t) = \\frac{d}{dt} \\left[ \\alpha \\lambda^\\alpha (\\lambda - t)^{-\\alpha-1} \\right]$$\n$$M_X''(t) = \\alpha \\lambda^\\alpha \\cdot (-\\alpha-1)(\\lambda - t)^{-\\alpha-2} \\cdot (-1)$$\n$$M_X''(t) = \\alpha(\\alpha+1) \\lambda^\\alpha (\\lambda - t)^{-\\alpha-2}$$\nNow, we evaluate this second derivative at $t=0$:\n$$M_X''(0) = \\alpha(\\alpha+1) \\lambda^\\alpha (\\lambda - 0)^{-\\alpha-2} = \\alpha(\\alpha+1) \\lambda^\\alpha \\lambda^{-\\alpha-2}$$\n$$M_X''(0) = \\alpha(\\alpha+1) \\lambda^{\\alpha - (\\alpha+2)} = \\alpha(\\alpha+1) \\lambda^{-2} = \\frac{\\alpha(\\alpha+1)}{\\lambda^2}$$\nThus, the second moment is:\n$$E[X^2] = \\frac{\\alpha(\\alpha+1)}{\\lambda^2}$$\n\nFinally, we use the formula for the variance, $\\text{Var}(X) = E[X^2] - (E[X])^2$, and substitute the moments we have calculated.\n$$\\text{Var}(X) = \\frac{\\alpha(\\alpha+1)}{\\lambda^2} - \\left(\\frac{\\alpha}{\\lambda}\\right)^2$$\n$$\\text{Var}(X) = \\frac{\\alpha^2 + \\alpha}{\\lambda^2} - \\frac{\\alpha^2}{\\lambda^2}$$\n$$\\text{Var}(X) = \\frac{(\\alpha^2 + \\alpha) - \\alpha^2}{\\lambda^2}$$\n$$\\text{Var}(X) = \\frac{\\alpha}{\\lambda^2}$$\nThis is the variance of the Gamma distribution.", "answer": "$$\\boxed{\\frac{\\alpha}{\\lambda^2}}$$", "id": "8017"}, {"introduction": "In real-world applications, we rarely know the true parameters of a distribution; instead, we must estimate them from a sample of data. The Method of Moments provides an intuitive and powerful technique for this task by equating theoretical moments (like $E[T]$) with their sample counterparts (like the sample mean $\\bar{T}$). This exercise formalizes this concept, guiding you to derive the general estimators for the Gamma distribution's parameters, a crucial step in moving from probability theory to statistical inference. [@problem_id:1919300]", "problem": "The operational lifetime of a specialized communications satellite component is modeled as a random variable $T$ that follows a Gamma distribution. The probability density function (PDF) for $T$ is given by:\n$$ f(t; \\alpha, \\lambda) = \\frac{\\lambda^{\\alpha}}{\\Gamma(\\alpha)} t^{\\alpha-1} \\exp(-\\lambda t), \\quad \\text{for } t  0 $$\nwhere $\\alpha  0$ is the shape parameter and $\\lambda  0$ is the rate parameter. To estimate these parameters from experimental data, a standard statistical technique involves matching the theoretical moments of the distribution to the corresponding moments calculated from a data sample.\n\nSuppose a random sample of $n$ component lifetimes, $T_1, T_2, \\ldots, T_n$, is collected. Let the sample mean be denoted by $\\bar{T} = \\frac{1}{n}\\sum_{i=1}^n T_i$, and let the second raw sample moment (the sample mean of the squares) be denoted by $M_2 = \\frac{1}{n}\\sum_{i=1}^n T_i^2$.\n\nFind the expressions for the estimators of the parameters, $\\hat{\\alpha}$ and $\\hat{\\lambda}$, that are obtained by setting the theoretical mean $E[T]$ equal to $\\bar{T}$ and the theoretical second moment $E[T^2]$ equal to $M_2$. You are given that for a Gamma distribution with parameters $\\alpha$ and $\\lambda$, the theoretical mean is $E[T] = \\frac{\\alpha}{\\lambda}$ and the theoretical variance is $\\text{Var}(T) = \\frac{\\alpha}{\\lambda^2}$. The final answer should be a pair of expressions, one for $\\hat{\\alpha}$ and one for $\\hat{\\lambda}$, in terms of $\\bar{T}$ and $M_2$.", "solution": "We are given that $T$ follows a Gamma distribution with parameters $\\alpha$ and $\\lambda$, with theoretical mean $E[T]=\\frac{\\alpha}{\\lambda}$ and variance $\\text{Var}(T)=\\frac{\\alpha}{\\lambda^{2}}$. The second moment about the origin is related to the mean and variance by $E[T^{2}]=\\text{Var}(T)+\\left(E[T]\\right)^{2}$. Therefore,\n$$\nE[T^{2}] \\;=\\; \\frac{\\alpha}{\\lambda^{2}} \\;+\\; \\left(\\frac{\\alpha}{\\lambda}\\right)^{2}\n\\;=\\; \\frac{\\alpha(1+\\alpha)}{\\lambda^{2}}.\n$$\n\nThe method of moments sets the theoretical moments equal to the corresponding sample moments. Let $\\bar{T}=\\frac{1}{n}\\sum_{i=1}^{n}T_{i}$ and $M_{2}=\\frac{1}{n}\\sum_{i=1}^{n}T_{i}^{2}$. Then we solve\n$$\n\\frac{\\alpha}{\\lambda}=\\bar{T}, \\qquad \\frac{\\alpha(1+\\alpha)}{\\lambda^{2}}=M_{2}.\n$$\nFrom $\\frac{\\alpha}{\\lambda}=\\bar{T}$ we obtain $\\lambda=\\frac{\\alpha}{\\bar{T}}$. Substituting this into the second equation gives\n$$\nM_{2} \\;=\\; \\frac{\\alpha(1+\\alpha)}{\\left(\\frac{\\alpha}{\\bar{T}}\\right)^{2}}\n\\;=\\; \\bar{T}^{2}\\,\\frac{1+\\alpha}{\\alpha}.\n$$\nRearranging,\n$$\nM_{2}\\alpha \\;=\\; \\bar{T}^{2}(1+\\alpha)\n\\;\\;\\Longrightarrow\\;\\; \\alpha(M_{2}-\\bar{T}^{2}) \\;=\\; \\bar{T}^{2}\n\\;\\;\\Longrightarrow\\;\\; \\hat{\\alpha} \\;=\\; \\frac{\\bar{T}^{2}}{M_{2}-\\bar{T}^{2}}.\n$$\nFinally, substitute into $\\lambda=\\frac{\\alpha}{\\bar{T}}$ to obtain\n$$\n\\hat{\\lambda} \\;=\\; \\frac{\\hat{\\alpha}}{\\bar{T}} \\;=\\; \\frac{\\bar{T}}{M_{2}-\\bar{T}^{2}}.\n$$\nThese are the method-of-moments estimators expressed in terms of $\\bar{T}$ and $M_{2}$.", "answer": "$$\\boxed{\\begin{pmatrix} \\frac{\\bar{T}^{2}}{M_{2}-\\bar{T}^{2}}  \\frac{\\bar{T}}{M_{2}-\\bar{T}^{2}} \\end{pmatrix}}$$", "id": "1919300"}]}