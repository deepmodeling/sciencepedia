{"hands_on_practices": [{"introduction": "Let's begin with a foundational exercise to solidify your understanding of the most basic properties of the chi-square distribution. This practice focuses on the direct relationship between a chi-square variable's degrees of freedom ($k$), its mean ($E[X]=k$), and its variance ($\\text{Var}(X)=2k$). Mastering this simple but crucial connection is the first step toward applying the distribution in more complex scenarios. [@problem_id:2324]", "problem": "A random variable $X$ is known to follow a chi-squared distribution, denoted as $X \\sim \\chi^2(k)$, where $k$ is the number of degrees of freedom. The chi-squared distribution is a continuous probability distribution widely used in statistical inference.\n\nThe fundamental properties of a chi-squared distribution with $k$ degrees of freedom are its mean (expected value) and variance:\n- Mean: $E[X] = k$\n- Variance: $\\text{Var}(X) = 2k$\n\nGiven that a specific chi-squared random variable $X$ has a mean value of $\\mu = 6$, derive the variance of $X$.", "solution": "For $X\\sim\\chi^2(k)$ we have the standard results  \n$$E[X]=k,\\qquad \\mathrm{Var}(X)=2k.$$  \nWe are given $E[X]=\\mu=6$, hence  \n$$k=6.$$  \nSubstituting into the variance formula gives  \n$$\\mathrm{Var}(X)=2k=2\\cdot6=12.$$", "answer": "$$\\boxed{12}$$", "id": "2324"}, {"introduction": "Building on the basics, we now explore the fundamental origin of the chi-square distribution as a sum of squared normal variables. This problem [@problem_id:1288558] investigates how the distribution behaves under a linear transformation of its underlying standard normal components. By working through this exercise, you will uncover an important invariance property that provides deeper insight into why the sum of squared normal variables is such a fundamental quantity in statistics.", "problem": "Let $X_1$ and $X_2$ be two independent random variables, each following a standard normal distribution, denoted as $N(0, 1)$. Consider two new random variables, $Y_1$ and $Y_2$, which are linear transformations of $X_1$ and $X_2$ defined as follows:\n\n$$Y_1 = \\frac{1}{\\sqrt{2}} (X_1 + X_2)$$\n$$Y_2 = \\frac{1}{\\sqrt{2}} (X_1 - X_2)$$\n\nNow, let a third random variable, $Z$, be defined as the sum of the squares of $Y_1$ and $Y_2$:\n\n$$Z = Y_1^2 + Y_2^2$$\n\nWhich of the following describes the probability distribution of the random variable $Z$?\n\nA. A standard normal distribution, $N(0, 1)$.\n\nB. A chi-square distribution with 1 degree of freedom, $\\chi^2(1)$.\n\nC. A chi-square distribution with 2 degrees of freedom, $\\chi^2(2)$.\n\nD. An F-distribution with $(1, 1)$ degrees of freedom.\n\nE. A Student's t-distribution with 2 degrees of freedom.", "solution": "Let $X=(X_{1},X_{2})^{\\top}$ with $X_{1}$ and $X_{2}$ independent and $X_{i}\\sim N(0,1)$. Then $X\\sim N_{2}(0,I_{2})$, where $I_{2}$ is the $2\\times 2$ identity matrix.\n\nDefine the linear transformation $Y=AX$ with\n$$\nA=\\frac{1}{\\sqrt{2}}\\begin{pmatrix}1  1\\\\ 1  -1\\end{pmatrix},\\quad Y=\\begin{pmatrix}Y_{1}\\\\ Y_{2}\\end{pmatrix}.\n$$\nCompute $AA^{\\top}$:\n$$\nAA^{\\top}=\\frac{1}{2}\\begin{pmatrix}1  1\\\\ 1  -1\\end{pmatrix}\\begin{pmatrix}1  1\\\\ 1  -1\\end{pmatrix}^{\\top}\n=\\frac{1}{2}\\begin{pmatrix}1  1\\\\ 1  -1\\end{pmatrix}\\begin{pmatrix}1  1\\\\ 1  -1\\end{pmatrix}\n=\\frac{1}{2}\\begin{pmatrix}2  0\\\\ 0  2\\end{pmatrix}\n=I_{2}.\n$$\nThus $A$ is orthogonal. Since $X\\sim N_{2}(0,I_{2})$, it follows that $Y\\sim N_{2}(0,AI_{2}A^{\\top})=N_{2}(0,I_{2})$. Therefore $Y_{1}$ and $Y_{2}$ are independent and each has distribution $N(0,1)$.\n\nNow compute $Z$:\n$$\nZ=Y_{1}^{2}+Y_{2}^{2}=\\frac{1}{2}\\left((X_{1}+X_{2})^{2}+(X_{1}-X_{2})^{2}\\right)\n=\\frac{1}{2}\\left(2X_{1}^{2}+2X_{2}^{2}\\right)=X_{1}^{2}+X_{2}^{2}.\n$$\nSince $X_{1}$ and $X_{2}$ are independent $N(0,1)$, by the definition of the chi-square distribution, the sum of squares of two independent standard normal variables has a chi-square distribution with $2$ degrees of freedom. Hence $Z\\sim \\chi^{2}(2)$, which corresponds to option C.", "answer": "$$\\boxed{C}$$", "id": "1288558"}, {"introduction": "This practice bridges the gap between the theoretical definition of the chi-square distribution and its practical use in statistical analysis. By modeling a hypothetical \"agitation metric\" as a sum of squared random measurements, you will see how the distribution naturally arises in modeling physical systems. The core task [@problem_id:1288599] is to determine a critical threshold for this metric, a common procedure in quality control and hypothesis testing used to flag statistically significant events.", "problem": "In a materials science experiment designed to study thermal fluctuations, a device measures microscopic displacements in a crystal lattice. The measurement system consists of 10 independent sensors. The displacement measurement from each sensor, $X_i$ for $i=1, 2, \\dots, 10$, after being properly calibrated and normalized, is accurately modeled as an independent random variable from a standard normal distribution, $N(0, 1)$.\n\nTo quantify the total thermal agitation within the observed region, an aggregate \"agitation metric\" $A$ is computed. This metric is defined as the sum of the squares of the individual normalized displacement measurements:\n$$\nA = \\sum_{i=1}^{10} X_i^2\n$$\nA critical system state is flagged if this agitation metric $A$ surpasses a certain threshold, $a_{crit}$. This threshold is carefully selected so that the probability of it being exceeded due to random thermal fluctuations alone is precisely 0.05.\n\nYou are provided with the following data points for the probability distribution that governs the sum of squares of 10 independent standard normal variables:\n- The value that is exceeded with a probability of 0.950 is 3.940.\n- The value that is exceeded with a probability of 0.050 is 18.307.\n- The value that is exceeded with a probability of 0.010 is 23.209.\n\nDetermine the value of the threshold $a_{crit}$.", "solution": "Each sensor reading $X_{i}$ is modeled as independent $N(0,1)$. A fundamental result in probability states that the sum of squares of $k$ independent standard normal variables follows a chi-square distribution with $k$ degrees of freedom. Therefore,\n$$\nA=\\sum_{i=1}^{10}X_{i}^{2}\\sim \\chi^{2}(10).\n$$\nThe critical threshold $a_{crit}$ is defined by the requirement that the probability of exceeding it due to random fluctuations is $0.05$, i.e.,\n$$\n\\mathbb{P}(Aa_{crit})=0.05.\n$$\nFor a continuous distribution, this is equivalent to $a_{crit}$ being the upper-tail critical value (the $0.95$ quantile) of the $\\chi^{2}(10)$ distribution. From the provided tabulated values for the distribution governing $A$, the value that is exceeded with probability $0.050$ is $18.307$. Hence,\n$$\na_{crit}=18.307.\n$$", "answer": "$$\\boxed{18.307}$$", "id": "1288599"}]}