{"hands_on_practices": [{"introduction": "Taylor's theorem guarantees the existence of an intermediate point $c$ in the remainder formula, but it does not provide a general method to find it. This first exercise demystifies the abstract nature of $c$ by guiding you through its explicit calculation for a simple polynomial function. By equating the exact error of the approximation with its representation in the Cauchy form, you will solve for the precise value of this intermediate point, making the theorem's statement concrete [@problem_id:1328777].", "problem": "According to Taylor's theorem, if a function $f$ is sufficiently differentiable, it can be approximated near a point $a$ by its Taylor polynomial $T_n(x)$. The error, or remainder term $R_n(x) = f(x) - T_n(x)$, can be expressed in several forms. The Cauchy form of the remainder for the Taylor expansion of order $n$ around the point $a$ is given by\n$$R_n(x) = \\frac{f^{(n+1)}(c)}{n!}(x-c)^n(x-a)$$\nfor some number $c$ strictly between $a$ and $x$.\n\nConsider the function $f(x) = x^3$. We are interested in its first-order Taylor expansion ($n=1$) around the point $a=1$. For this specific function, expansion order, and expansion point, determine the exact value of the intermediate point $c$ that arises from the Cauchy form of the remainder when evaluated at $x=2$.", "solution": "We use the Cauchy form of the remainder for the Taylor expansion of order $n=1$ about $a=1$:\n$$R_{1}(x)=\\frac{f^{(2)}(c)}{1!}(x-c)^{1}(x-a)=f^{(2)}(c)(x-c)(x-a),$$\nfor some $c$ strictly between $a$ and $x$.\n\nFor $f(x)=x^{3}$, we compute the derivatives:\n$$f'(x)=3x^{2}, \\quad f''(x)=6x.$$\nThe first-order Taylor polynomial at $a=1$ is\n$$T_{1}(x)=f(1)+f'(1)(x-1)=1+3(x-1)=3x-2.$$\nThus the remainder at $x=2$ is\n$$R_{1}(2)=f(2)-T_{1}(2)=8-(3\\cdot 2-2)=8-4=4.$$\nBy the Cauchy form,\n$$R_{1}(2)=f''(c)(2-c)(2-1)=6c(2-c).$$\nEquating these gives\n$$6c(2-c)=4,$$\nwhich simplifies to\n$$12c-6c^{2}=4,$$\n$$-6c^{2}+12c-4=0,$$\n$$3c^{2}-6c+2=0.$$\nApplying the quadratic formula,\n$$c=\\frac{6\\pm\\sqrt{36-24}}{6}=\\frac{6\\pm\\sqrt{12}}{6}=\\frac{6\\pm 2\\sqrt{3}}{6}=1\\pm\\frac{\\sqrt{3}}{3}.$$\nSince $c$ must lie strictly between $1$ and $2$, we select\n$$c=1+\\frac{\\sqrt{3}}{3}.$$", "answer": "$$\\boxed{1+\\frac{\\sqrt{3}}{3}}$$", "id": "1328777"}, {"introduction": "Beyond just quantifying the error in a Taylor approximation, it is often crucial to know whether the approximation is an overestimate or an underestimate. This practice demonstrates how the structure of the Cauchy form of the remainder can be used to determine the sign of the error, $R_n(x)$, without needing to compute its exact value. By analyzing the signs of the components of the remainder for the function $f(x) = \\cos(x)$, you will gain valuable qualitative insight into the nature of the approximation [@problem_id:1328782].", "problem": "According to Taylor's theorem, a function $f(x)$ that is sufficiently differentiable can be approximated near a point $a$ by its Taylor polynomial $P_n(x)$. The error in this approximation is given by a remainder term $R_n(x)$, such that $f(x) = P_n(x) + R_n(x)$. One form of the remainder, for a function $f$ that is $(n+1)$ times differentiable on an open interval $I$ containing $a$, is the Cauchy form:\n$$R_n(x) = \\frac{f^{(n+1)}(c)}{n!}(x-a)(x-c)^n$$\nfor some number $c$ strictly between $a$ and $x$.\n\nLet $f(x) = \\cos(x)$ and let $P_2(x)$ be its quadratic Maclaurin polynomial (i.e., the Taylor polynomial of degree 2 centered at $a=0$). By analyzing the sign of the Cauchy remainder term $R_2(x)$, determine if $P_2(x)$ provides an overestimate or an underestimate of $f(x)$ on the open interval $(0, \\frac{\\pi}{2})$.\n\nChoose the correct statement from the options below.\n\nA. $P_2(x)$ is an overestimate of $f(x)$ on the entire interval $(0, \\frac{\\pi}{2})$.\n\nB. $P_2(x)$ is an underestimate of $f(x)$ on the entire interval $(0, \\frac{\\pi}{2})$.\n\nC. $P_2(x)$ is an overestimate on $(0, \\frac{\\pi}{4})$ and an underestimate on $(\\frac{\\pi}{4}, \\frac{\\pi}{2})$.\n\nD. $P_2(x)$ is an underestimate on $(0, \\frac{\\pi}{4})$ and an overestimate on $(\\frac{\\pi}{4}, \\frac{\\pi}{2})$.\n\nE. $P_2(x)$ is exactly equal to $f(x)$ on the entire interval $(0, \\frac{\\pi}{2})$.", "solution": "We take $f(x)=\\cos(x)$ and its quadratic Maclaurin polynomial $P_{2}(x)$ given by the Taylor expansion at $a=0$:\n$$\nP_{2}(x)=f(0)+f'(0)x+\\frac{f''(0)}{2!}x^{2}.\n$$\nSince $f(0)=1$, $f'(x)=-\\sin(x)$ so $f'(0)=0$, and $f''(x)=-\\cos(x)$ so $f''(0)=-1$, we obtain\n$$\nP_{2}(x)=1-\\frac{x^{2}}{2}.\n$$\nBy the Cauchy form of the remainder with $n=2$ and $a=0$,\n$$\nR_{2}(x)=\\frac{f^{(3)}(c)}{2!}\\,x\\,(x-c)^{2}\n$$\nfor some $c$ strictly between $0$ and $x$. For $f(x)=\\cos(x)$, we have $f^{(3)}(x)=\\sin(x)$, hence\n$$\nR_{2}(x)=\\frac{\\sin(c)}{2}\\,x\\,(x-c)^{2}.\n$$\nOn the interval $x\\in(0,\\frac{\\pi}{2})$, we have $x0$ and $c\\in(0,x)\\subset(0,\\frac{\\pi}{2})$, which implies $\\sin(c)0$ and $(x-c)^{2}0$. Therefore $R_{2}(x)0$ for all $x\\in(0,\\frac{\\pi}{2})$. Since $f(x)=P_{2}(x)+R_{2}(x)$, it follows that $f(x)P_{2}(x)$ on $(0,\\frac{\\pi}{2})$, so $P_{2}(x)$ underestimates $f(x)$ on the entire interval.\n\nThus the correct choice is B.", "answer": "$$\\boxed{B}$$", "id": "1328782"}, {"introduction": "The intermediate point $c$ in the Cauchy remainder formula typically has a complex dependence on the function $f$, the evaluation point $x$, and the expansion order $n$. This exercise reverses the typical problem-solving direction by asking what we can deduce about a function if its intermediate point follows a simple, prescribed rule. By assuming the relationship $c = x/2$ holds for a first-order expansion, you will use a functional-differential equation to discover the entire family of functions that satisfy this condition, revealing the deep structural link between a function and its approximation error [@problem_id:1328769].", "problem": "According to Taylor's theorem, for a sufficiently differentiable function $f(x)$, the first-order expansion around $a=0$ is given by $f(x) = f(0) + f'(0)x + R_1(x)$, where $R_1(x)$ is the remainder term. In its Cauchy form, the remainder is expressed as $R_1(x) = f''(c)(x-c)x$ for some number $c$ strictly between $0$ and $x$.\n\nConsider a function $f(x)$ that is three times continuously differentiable (i.e., $f \\in C^3(\\mathbb{R})$). This function has a special property: for any non-zero $x$ in the domain of $f$, the value of the intermediate point $c$ in the Cauchy form of its first-order remainder is always $c=x/2$.\n\nGiven that $f(0) = C_0$, $f'(0) = C_1$, and $f''(0) = C_2$, determine the expression for $f(x)$. Your answer should be in terms of $x$ and the constants $C_0, C_1, C_2$.", "solution": "The problem provides the first-order Taylor expansion of a function $f(x)$ around $a=0$:\n$$f(x) = f(0) + f'(0)x + R_1(x)$$\nThe remainder term, $R_1(x)$, is given in its Cauchy form as:\n$$R_1(x) = f''(c)(x-c)x$$\nwhere $c$ is a number between $0$ and $x$.\n\nThe problem states that for the specific function $f(x)$ in question, the intermediate point $c$ is always given by $c = x/2$. We can substitute this into the expression for the remainder:\n$$R_1(x) = f''(x/2)\\left(x-\\frac{x}{2}\\right)x = f''(x/2)\\left(\\frac{x}{2}\\right)x = \\frac{x^2}{2}f''(x/2)$$\n\nNow, we can substitute this specific form of $R_1(x)$ back into the Taylor expansion equation. We can also express $R_1(x)$ directly from the expansion as $R_1(x) = f(x) - f(0) - f'(0)x$. Equating the two expressions for $R_1(x)$ gives us a functional-differential equation for $f(x)$:\n$$f(x) - f(0) - f'(0)x = \\frac{x^2}{2} f''(x/2)$$\n\nTo solve for $f(x)$, we can assume that $f(x)$ has a Taylor series representation around $x=0$, which is justified by the smoothness condition ($f \\in C^3$). Let the Taylor series be:\n$$f(x) = \\sum_{k=0}^{\\infty} \\frac{f^{(k)}(0)}{k!} x^k$$\nLet's denote the derivatives at zero as $d_k = f^{(k)}(0)$. The series is $f(x) = \\sum_{k=0}^{\\infty} \\frac{d_k}{k!} x^k$.\nThe left-hand side (LHS) of our functional equation is:\n$$f(x) - f(0) - f'(0)x = \\left(\\sum_{k=0}^{\\infty} \\frac{d_k}{k!} x^k\\right) - d_0 - d_1 x = \\sum_{k=2}^{\\infty} \\frac{d_k}{k!} x^k$$\n\nFor the right-hand side (RHS), we first need the second derivative of $f(x)$:\n$$f''(x) = \\frac{d}{dx^2} \\left(\\sum_{k=0}^{\\infty} \\frac{d_k}{k!} x^k\\right) = \\sum_{k=2}^{\\infty} \\frac{d_k}{k!} k(k-1) x^{k-2} = \\sum_{k=2}^{\\infty} \\frac{d_k}{(k-2)!} x^{k-2}$$\nNow, we evaluate this at $x/2$:\n$$f''(x/2) = \\sum_{k=2}^{\\infty} \\frac{d_k}{(k-2)!} \\left(\\frac{x}{2}\\right)^{k-2} = \\sum_{k=2}^{\\infty} \\frac{d_k}{(k-2)! 2^{k-2}} x^{k-2}$$\nFinally, we multiply by $x^2/2$ to get the RHS:\n$$\\frac{x^2}{2} f''(x/2) = \\frac{x^2}{2} \\sum_{k=2}^{\\infty} \\frac{d_k}{(k-2)! 2^{k-2}} x^{k-2} = \\sum_{k=2}^{\\infty} \\frac{d_k}{2 \\cdot (k-2)! 2^{k-2}} x^k = \\sum_{k=2}^{\\infty} \\frac{d_k}{(k-2)! 2^{k-1}} x^k$$\n\nNow we equate the coefficients of the power series for the LHS and RHS for each power of $x^k$ where $k \\ge 2$:\n$$\\frac{d_k}{k!} = \\frac{d_k}{(k-2)! 2^{k-1}}$$\nThis can be rewritten as:\n$$d_k \\left( \\frac{1}{k!} - \\frac{1}{(k-2)! 2^{k-1}} \\right) = 0$$\n$$d_k \\left( \\frac{1}{k(k-1)(k-2)!} - \\frac{1}{(k-2)! 2^{k-1}} \\right) = 0$$\nFor this equation to hold, for each $k \\ge 2$, either $d_k=0$ or the term in the parenthesis must be zero. Let's analyze the term in the parenthesis:\n$$\\frac{1}{k(k-1)} = \\frac{1}{2^{k-1}} \\quad \\implies \\quad k(k-1) = 2^{k-1}$$\n\nLet's test this equality for integer values of $k \\ge 2$:\n- For $k=2$: $2(2-1) = 2$. And $2^{2-1} = 2^1 = 2$. The equality holds.\n- For $k=3$: $3(3-1) = 6$. And $2^{3-1} = 2^2 = 4$. The equality does not hold ($6 \\neq 4$).\n- For $k=4$: $4(4-1) = 12$. And $2^{4-1} = 2^3 = 8$. The equality does not hold ($12 \\neq 8$).\n\nFor $k \\ge 4$, the exponential function $2^{k-1}$ grows much faster than the quadratic function $k(k-1)$. We can prove by induction that $2^{k-1} > k(k-1)$ for $k \\ge 6$ (and we can check $k=4,5$ manually). Thus, the equality $k(k-1) = 2^{k-1}$ only holds for $k=2$.\n\nSo, our coefficient equation $d_k \\left( \\frac{1}{k(k-1)} - \\frac{1}{2^{k-1}} \\right) = 0$ implies:\n- For $k=2$: $d_2 \\left( \\frac{1}{2} - \\frac{1}{2} \\right) = 0 \\implies d_2 \\cdot 0 = 0$. This gives no restriction on $d_2$; it can be any arbitrary value.\n- For $k \\ge 3$: Since $k(k-1) \\neq 2^{k-1}$, the term in the parenthesis is non-zero. Therefore, we must have $d_k = 0$.\n\nThis means that all derivatives of $f(x)$ at $x=0$ of order 3 and higher are zero: $f^{(k)}(0) = 0$ for $k \\ge 3$.\nConsequently, the Taylor series for $f(x)$ terminates, and the function must be a polynomial of degree at most 2:\n$$f(x) = \\frac{d_0}{0!}x^0 + \\frac{d_1}{1!}x^1 + \\frac{d_2}{2!}x^2 = d_0 + d_1 x + \\frac{d_2}{2} x^2$$\n\nThe problem provides the values for the first three derivatives at $x=0$:\n$d_0 = f(0) = C_0$\n$d_1 = f'(0) = C_1$\n$d_2 = f''(0) = C_2$\n\nSubstituting these constants into our expression for $f(x)$:\n$$f(x) = C_0 + C_1 x + \\frac{C_2}{2} x^2$$\nThis is the general form of any $C^3$ function satisfying the given condition.", "answer": "$$\n\\boxed{C_0 + C_1 x + \\frac{C_2}{2} x^{2}}\n$$", "id": "1328769"}]}