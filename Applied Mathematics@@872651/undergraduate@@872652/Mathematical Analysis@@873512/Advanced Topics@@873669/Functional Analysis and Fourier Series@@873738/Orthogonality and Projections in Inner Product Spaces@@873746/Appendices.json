{"hands_on_practices": [{"introduction": "We often visualize orthogonal projections in the familiar Euclidean plane using our geometric intuition from the standard dot product. However, the true power of inner product spaces lies in their abstract structure. This practice challenges our intuition by introducing a non-standard inner product on $\\mathbb{R}^2$, demonstrating that the concepts of 'length' and 'angle'—and therefore projection—are defined by the inner product itself, forcing a direct application of the formal projection formula. [@problem_id:2309886]", "problem": "Consider the real vector space $\\mathbb{R}^2$. An inner product on this space is defined as follows: for any two vectors $\\mathbf{a} = (a_1, a_2)$ and $\\mathbf{b} = (b_1, b_2)$, their inner product is given by $\\langle \\mathbf{a}, \\mathbf{b} \\rangle = 2a_1b_1 + a_1b_2 + a_2b_1 + a_2b_2$.\n\nLet two vectors in this space be defined as $\\mathbf{v} = (1, 0)$ and $\\mathbf{u} = (1, 1)$.\n\nFind the orthogonal projection of the vector $\\mathbf{v}$ onto the vector $\\mathbf{u}$, which is denoted as $\\text{proj}_{\\mathbf{u}} \\mathbf{v}$. Present your answer as a row vector with two components.", "solution": "The orthogonal projection of a vector $\\mathbf{v}$ onto a non-zero vector $\\mathbf{u}$ in an inner product space is given by the formula:\n$$\n\\text{proj}_{\\mathbf{u}} \\mathbf{v} = \\frac{\\langle \\mathbf{v}, \\mathbf{u} \\rangle}{\\langle \\mathbf{u}, \\mathbf{u} \\rangle} \\mathbf{u}\n$$\nWe are given the vectors $\\mathbf{v} = (1, 0)$ and $\\mathbf{u} = (1, 1)$, and the inner product definition $\\langle (a_1, a_2), (b_1, b_2) \\rangle = 2a_1b_1 + a_1b_2 + a_2b_1 + a_2b_2$.\n\nFirst, we need to compute the inner product $\\langle \\mathbf{v}, \\mathbf{u} \\rangle$.\nHere, $\\mathbf{v}$ corresponds to $\\mathbf{a}=(a_1, a_2) = (1, 0)$ and $\\mathbf{u}$ corresponds to $\\mathbf{b}=(b_1, b_2) = (1, 1)$.\nSubstituting these values into the inner product definition:\n$$\n\\langle \\mathbf{v}, \\mathbf{u} \\rangle = \\langle (1, 0), (1, 1) \\rangle = 2(1)(1) + (1)(1) + (0)(1) + (0)(1)\n$$\n$$\n\\langle \\mathbf{v}, \\mathbf{u} \\rangle = 2 + 1 + 0 + 0 = 3\n$$\n\nNext, we need to compute the inner product $\\langle \\mathbf{u}, \\mathbf{u} \\rangle$, which is the squared norm of $\\mathbf{u}$ with respect to this inner product, $\\|\\mathbf{u}\\|^2$.\nHere, both $\\mathbf{a}$ and $\\mathbf{b}$ in the formula are the vector $\\mathbf{u}=(1, 1)$. So, $(a_1, a_2) = (1, 1)$ and $(b_1, b_2) = (1, 1)$.\nSubstituting these values:\n$$\n\\langle \\mathbf{u}, \\mathbf{u} \\rangle = \\langle (1, 1), (1, 1) \\rangle = 2(1)(1) + (1)(1) + (1)(1) + (1)(1)\n$$\n$$\n\\langle \\mathbf{u}, \\mathbf{u} \\rangle = 2 + 1 + 1 + 1 = 5\n$$\n\nNow we can substitute these results back into the projection formula:\n$$\n\\text{proj}_{\\mathbf{u}} \\mathbf{v} = \\frac{3}{5} \\mathbf{u}\n$$\nSince $\\mathbf{u} = (1, 1)$, we perform the scalar multiplication:\n$$\n\\text{proj}_{\\mathbf{u}} \\mathbf{v} = \\frac{3}{5} (1, 1) = \\left(\\frac{3}{5}, \\frac{3}{5}\\right)\n$$\nThe orthogonal projection of $\\mathbf{v}$ onto $\\mathbf{u}$ is the vector $\\left(\\frac{3}{5}, \\frac{3}{5}\\right)$.", "answer": "$$\\boxed{\\begin{pmatrix} \\frac{3}{5} & \\frac{3}{5} \\end{pmatrix}}$$", "id": "2309886"}, {"introduction": "The concept of projection extends elegantly from finite-dimensional vectors to infinite-dimensional function spaces, where it becomes a powerful tool for approximation. This exercise asks you to find the 'best fit' for the function $h(x) = x$ using a combination of sine and cosine functions. This is not just an abstract calculation; it is the fundamental principle behind Fourier series, used to decompose complex signals into simpler, periodic components. [@problem_id:2309922]", "problem": "Consider the real vector space $V$ consisting of all continuous functions defined on the closed interval $[-\\pi, \\pi]$. This space is equipped with an inner product defined for any two functions $f(x)$ and $g(x)$ in $V$ as:\n$$\n\\langle f, g \\rangle = \\int_{-\\pi}^{\\pi} f(x)g(x) \\, dx\n$$\nLet $W$ be the subspace of $V$ spanned by the functions $u_1(x) = \\cos(x)$ and $u_2(x) = \\sin(x)$.\n\nDetermine the orthogonal projection of the function $h(x) = x$ onto the subspace $W$. Express your answer as a function of $x$.", "solution": "The problem asks for the orthogonal projection of the function $h(x) = x$ onto the subspace $W$ spanned by $u_1(x) = \\cos(x)$ and $u_2(x) = \\sin(x)$. The inner product space is the space of continuous functions on $[-\\pi, \\pi]$ with the inner product $\\langle f, g \\rangle = \\int_{-\\pi}^{\\pi} f(x)g(x) \\, dx$.\n\nThe formula for the orthogonal projection of a vector $h$ onto a subspace $W$ spanned by an orthogonal basis $\\{u_1, u_2, \\dots, u_n\\}$ is given by:\n$$\n\\text{proj}_W(h) = \\sum_{i=1}^{n} \\frac{\\langle h, u_i \\rangle}{\\langle u_i, u_i \\rangle} u_i\n$$\nIn our case, $W$ is spanned by $\\{u_1(x) = \\cos(x), u_2(x) = \\sin(x)\\}$. We first need to check if this set forms an orthogonal basis for $W$. To do this, we compute the inner product $\\langle u_1, u_2 \\rangle$.\n$$\n\\langle u_1, u_2 \\rangle = \\int_{-\\pi}^{\\pi} \\cos(x)\\sin(x) \\, dx\n$$\nThe integrand $f(x) = \\cos(x)\\sin(x)$ is an odd function because $f(-x) = \\cos(-x)\\sin(-x) = \\cos(x)(-\\sin(x)) = -f(x)$. The integral of an odd function over a symmetric interval like $[-\\pi, \\pi]$ is zero.\nAlternatively, one can use the identity $\\sin(2x) = 2\\sin(x)\\cos(x)$:\n$$\n\\int_{-\\pi}^{\\pi} \\frac{1}{2}\\sin(2x) \\, dx = \\frac{1}{2} \\left[ -\\frac{1}{2}\\cos(2x) \\right]_{-\\pi}^{\\pi} = -\\frac{1}{4} [\\cos(2\\pi) - \\cos(-2\\pi)] = -\\frac{1}{4} [1 - 1] = 0\n$$\nSince $\\langle u_1, u_2 \\rangle = 0$, the functions are orthogonal. Thus, $\\{u_1, u_2\\}$ is an orthogonal basis for $W$.\n\nNow we can use the projection formula:\n$$\n\\text{proj}_W(h) = \\frac{\\langle h, u_1 \\rangle}{\\langle u_1, u_1 \\rangle} u_1(x) + \\frac{\\langle h, u_2 \\rangle}{\\langle u_2, u_2 \\rangle} u_2(x)\n$$\nWe need to compute four inner products.\n\n1.  **Compute $\\langle u_1, u_1 \\rangle$**:\n    $$\n    \\langle u_1, u_1 \\rangle = \\int_{-\\pi}^{\\pi} \\cos^{2}(x) \\, dx\n    $$\n    Using the half-angle identity $\\cos^{2}(x) = \\frac{1 + \\cos(2x)}{2}$:\n    $$\n    \\int_{-\\pi}^{\\pi} \\frac{1 + \\cos(2x)}{2} \\, dx = \\frac{1}{2} \\left[ x + \\frac{1}{2}\\sin(2x) \\right]_{-\\pi}^{\\pi} = \\frac{1}{2} \\left[ (\\pi + \\frac{1}{2}\\sin(2\\pi)) - (-\\pi + \\frac{1}{2}\\sin(-2\\pi)) \\right] = \\frac{1}{2} [\\pi - (-\\pi)] = \\pi\n    $$\n\n2.  **Compute $\\langle u_2, u_2 \\rangle$**:\n    $$\n    \\langle u_2, u_2 \\rangle = \\int_{-\\pi}^{\\pi} \\sin^{2}(x) \\, dx\n    $$\n    Using the half-angle identity $\\sin^{2}(x) = \\frac{1 - \\cos(2x)}{2}$:\n    $$\n    \\int_{-\\pi}^{\\pi} \\frac{1 - \\cos(2x)}{2} \\, dx = \\frac{1}{2} \\left[ x - \\frac{1}{2}\\sin(2x) \\right]_{-\\pi}^{\\pi} = \\frac{1}{2} \\left[ (\\pi - \\frac{1}{2}\\sin(2\\pi)) - (-\\pi - \\frac{1}{2}\\sin(-2\\pi)) \\right] = \\frac{1}{2} [\\pi - (-\\pi)] = \\pi\n    $$\n\n3.  **Compute $\\langle h, u_1 \\rangle$**:\n    $$\n    \\langle h, u_1 \\rangle = \\int_{-\\pi}^{\\pi} h(x)u_1(x) \\, dx = \\int_{-\\pi}^{\\pi} x \\cos(x) \\, dx\n    $$\n    The integrand $f(x) = x\\cos(x)$ is an odd function because $h(x)=x$ is odd and $u_1(x)=\\cos(x)$ is even, so their product is odd. The integral of an odd function over a symmetric interval is zero. Therefore, $\\langle h, u_1 \\rangle = 0$.\n\n4.  **Compute $\\langle h, u_2 \\rangle$**:\n    $$\n    \\langle h, u_2 \\rangle = \\int_{-\\pi}^{\\pi} h(x)u_2(x) \\, dx = \\int_{-\\pi}^{\\pi} x \\sin(x) \\, dx\n    $$\n    The integrand $f(x) = x\\sin(x)$ is an even function because both $h(x)=x$ and $u_2(x)=\\sin(x)$ are odd, so their product is even. We use integration by parts, with $\\int u \\, dv = uv - \\int v \\, du$. Let $u = x$ and $dv = \\sin(x)dx$. Then $du = dx$ and $v = -\\cos(x)$.\n    $$\n    \\int x \\sin(x) \\, dx = -x\\cos(x) - \\int (-\\cos(x)) \\, dx = -x\\cos(x) + \\sin(x)\n    $$\n    Now, we evaluate the definite integral:\n    $$\n    \\int_{-\\pi}^{\\pi} x \\sin(x) \\, dx = \\left[ -x\\cos(x) + \\sin(x) \\right]_{-\\pi}^{\\pi}\n    $$\n    $$\n    = (-\\pi\\cos(\\pi) + \\sin(\\pi)) - (-(-\\pi)\\cos(-\\pi) + \\sin(-\\pi))\n    $$\n    $$\n    = (-\\pi(-1) + 0) - (\\pi(-1) + 0) = \\pi - (-\\pi) = 2\\pi\n    $$\n    So, $\\langle h, u_2 \\rangle = 2\\pi$.\n\nNow we substitute these values back into the projection formula:\n$$\n\\text{proj}_W(h) = \\frac{0}{\\pi} \\cos(x) + \\frac{2\\pi}{\\pi} \\sin(x) = 0 \\cdot \\cos(x) + 2 \\cdot \\sin(x) = 2\\sin(x)\n$$\nThe orthogonal projection of $h(x)=x$ onto the subspace spanned by $\\cos(x)$ and $\\sin(x)$ is $2\\sin(x)$.", "answer": "$$\\boxed{2\\sin(x)}$$", "id": "2309922"}, {"introduction": "The abstract framework of inner product spaces is not limited to vectors or functions; it can also provide geometric insights into spaces of other mathematical objects, like matrices. In this practice, we equip the space of $2 \\times 2$ matrices with the Frobenius inner product. You will discover that finding the component of a matrix orthogonal to the subspace of symmetric matrices provides a beautiful geometric interpretation of the decomposition of a matrix into its symmetric and skew-symmetric parts. [@problem_id:2309898]", "problem": "Consider the vector space $V = M_{2 \\times 2}(\\mathbb{R})$ of all $2 \\times 2$ matrices with real entries. This space is equipped with the Frobenius inner product, defined as $\\langle A, B \\rangle = \\operatorname{tr}(A^T B)$ for any two matrices $A, B \\in V$, where $\\operatorname{tr}(M)$ denotes the trace of a matrix $M$. Let $S$ be the subspace of $V$ consisting of all symmetric matrices.\n\nGiven the matrix $A = \\begin{pmatrix} 1 & 2 \\\\ 3 & 4 \\end{pmatrix}$, find its component that is orthogonal to the subspace $S$.\n\nPresent your answer, which will be a $2 \\times 2$ matrix $\\begin{pmatrix} a & b \\\\ c & d \\end{pmatrix}$, as a row matrix of its components in the format $\\begin{pmatrix} a & b & c & d \\end{pmatrix}$.", "solution": "Let $V = M_{2 \\times 2}(\\mathbb{R})$ be the vector space of $2 \\times 2$ real matrices, and let $S$ be the subspace of symmetric matrices. The given matrix is $A = \\begin{pmatrix} 1 & 2 \\\\ 3 & 4 \\end{pmatrix}$. We are asked to find the component of $A$ that is orthogonal to the subspace $S$.\n\nAny vector $A$ in an inner product space can be uniquely decomposed into two components: one that lies in a subspace $S$ and one that is orthogonal to it. This is written as $A = A_S + A_{S^\\perp}$, where $A_S = \\operatorname{proj}_S(A)$ is the orthogonal projection of $A$ onto $S$, and $A_{S^\\perp}$ is the component of $A$ orthogonal to $S$. We need to find $A_{S^\\perp}$, which can be calculated as $A_{S^\\perp} = A - \\operatorname{proj}_S(A)$.\n\nOur first step is to find the orthogonal projection of $A$ onto $S$. To do this, we need an orthogonal basis for the subspace $S$. A general symmetric $2 \\times 2$ matrix has the form $\\begin{pmatrix} x & y \\\\ y & z \\end{pmatrix}$. We can write this as a linear combination of basis matrices:\n$$\n\\begin{pmatrix} x & y \\\\ y & z \\end{pmatrix} = x \\begin{pmatrix} 1 & 0 \\\\ 0 & 0 \\end{pmatrix} + z \\begin{pmatrix} 0 & 0 \\\\ 0 & 1 \\end{pmatrix} + y \\begin{pmatrix} 0 & 1 \\\\ 1 & 0 \\end{pmatrix}\n$$\nSo, a basis for $S$ is $\\{B_1, B_2, B_3\\}$, where $B_1 = \\begin{pmatrix} 1 & 0 \\\\ 0 & 0 \\end{pmatrix}$, $B_2 = \\begin{pmatrix} 0 & 0 \\\\ 0 & 1 \\end{pmatrix}$, and $B_3 = \\begin{pmatrix} 0 & 1 \\\\ 1 & 0 \\end{pmatrix}$.\n\nNext, we check if this basis is orthogonal with respect to the Frobenius inner product, $\\langle X, Y \\rangle = \\operatorname{tr}(X^T Y)$. Since the basis matrices are symmetric, $X^T = X$.\n$$\n\\langle B_1, B_2 \\rangle = \\operatorname{tr}(B_1^T B_2) = \\operatorname{tr}(B_1 B_2) = \\operatorname{tr}\\left( \\begin{pmatrix} 1 & 0 \\\\ 0 & 0 \\end{pmatrix} \\begin{pmatrix} 0 & 0 \\\\ 0 & 1 \\end{pmatrix} \\right) = \\operatorname{tr}\\left( \\begin{pmatrix} 0 & 0 \\\\ 0 & 0 \\end{pmatrix} \\right) = 0\n$$\n$$\n\\langle B_1, B_3 \\rangle = \\operatorname{tr}(B_1^T B_3) = \\operatorname{tr}(B_1 B_3) = \\operatorname{tr}\\left( \\begin{pmatrix} 1 & 0 \\\\ 0 & 0 \\end{pmatrix} \\begin{pmatrix} 0 & 1 \\\\ 1 & 0 \\end{pmatrix} \\right) = \\operatorname{tr}\\left( \\begin{pmatrix} 0 & 1 \\\\ 0 & 0 \\end{pmatrix} \\right) = 0\n$$\n$$\n\\langle B_2, B_3 \\rangle = \\operatorname{tr}(B_2^T B_3) = \\operatorname{tr}(B_2 B_3) = \\operatorname{tr}\\left( \\begin{pmatrix} 0 & 0 \\\\ 0 & 1 \\end{pmatrix} \\begin{pmatrix} 0 & 1 \\\\ 1 & 0 \\end{pmatrix} \\right) = \\operatorname{tr}\\left( \\begin{pmatrix} 0 & 0 \\\\ 1 & 0 \\end{pmatrix} \\right) = 0\n$$\nThe basis is indeed orthogonal. The formula for the orthogonal projection of $A$ onto $S$ is:\n$$\n\\operatorname{proj}_S(A) = \\frac{\\langle A, B_1 \\rangle}{\\langle B_1, B_1 \\rangle} B_1 + \\frac{\\langle A, B_2 \\rangle}{\\langle B_2, B_2 \\rangle} B_2 + \\frac{\\langle A, B_3 \\rangle}{\\langle B_3, B_3 \\rangle} B_3\n$$\nWe compute the required inner products. First, the denominators (squared norms of basis vectors):\n$$\n\\langle B_1, B_1 \\rangle = \\operatorname{tr}(B_1^T B_1) = \\operatorname{tr}(B_1^2) = \\operatorname{tr}\\left( \\begin{pmatrix} 1 & 0 \\\\ 0 & 0 \\end{pmatrix} \\right) = 1\n$$\n$$\n\\langle B_2, B_2 \\rangle = \\operatorname{tr}(B_2^T B_2) = \\operatorname{tr}(B_2^2) = \\operatorname{tr}\\left( \\begin{pmatrix} 0 & 0 \\\\ 0 & 1 \\end{pmatrix} \\right) = 1\n$$\n$$\n\\langle B_3, B_3 \\rangle = \\operatorname{tr}(B_3^T B_3) = \\operatorname{tr}(B_3^2) = \\operatorname{tr}\\left( \\begin{pmatrix} 0 & 1 \\\\ 1 & 0 \\end{pmatrix}^2 \\right) = \\operatorname{tr}\\left( \\begin{pmatrix} 1 & 0 \\\\ 0 & 1 \\end{pmatrix} \\right) = 2\n$$\nNext, the numerators. For $A = \\begin{pmatrix} 1 & 2 \\\\ 3 & 4 \\end{pmatrix}$, its transpose is $A^T = \\begin{pmatrix} 1 & 3 \\\\ 2 & 4 \\end{pmatrix}$.\n$$\n\\langle A, B_1 \\rangle = \\operatorname{tr}(A^T B_1) = \\operatorname{tr}\\left( \\begin{pmatrix} 1 & 3 \\\\ 2 & 4 \\end{pmatrix} \\begin{pmatrix} 1 & 0 \\\\ 0 & 0 \\end{pmatrix} \\right) = \\operatorname{tr}\\left( \\begin{pmatrix} 1 & 0 \\\\ 2 & 0 \\end{pmatrix} \\right) = 1\n$$\n$$\n\\langle A, B_2 \\rangle = \\operatorname{tr}(A^T B_2) = \\operatorname{tr}\\left( \\begin{pmatrix} 1 & 3 \\\\ 2 & 4 \\end{pmatrix} \\begin{pmatrix} 0 & 0 \\\\ 0 & 1 \\end{pmatrix} \\right) = \\operatorname{tr}\\left( \\begin{pmatrix} 0 & 3 \\\\ 0 & 4 \\end{pmatrix} \\right) = 4\n$$\n$$\n\\langle A, B_3 \\rangle = \\operatorname{tr}(A^T B_3) = \\operatorname{tr}\\left( \\begin{pmatrix} 1 & 3 \\\\ 2 & 4 \\end{pmatrix} \\begin{pmatrix} 0 & 1 \\\\ 1 & 0 \\end{pmatrix} \\right) = \\operatorname{tr}\\left( \\begin{pmatrix} 3 & 1 \\\\ 4 & 2 \\end{pmatrix} \\right) = 3+2 = 5\n$$\nNow, we can assemble the projection:\n$$\n\\operatorname{proj}_S(A) = \\frac{1}{1} B_1 + \\frac{4}{1} B_2 + \\frac{5}{2} B_3 = 1 \\begin{pmatrix} 1 & 0 \\\\ 0 & 0 \\end{pmatrix} + 4 \\begin{pmatrix} 0 & 0 \\\\ 0 & 1 \\end{pmatrix} + \\frac{5}{2} \\begin{pmatrix} 0 & 1 \\\\ 1 & 0 \\end{pmatrix}\n$$\n$$\n\\operatorname{proj}_S(A) = \\begin{pmatrix} 1 & 0 \\\\ 0 & 0 \\end{pmatrix} + \\begin{pmatrix} 0 & 0 \\\\ 0 & 4 \\end{pmatrix} + \\begin{pmatrix} 0 & 5/2 \\\\ 5/2 & 0 \\end{pmatrix} = \\begin{pmatrix} 1 & 5/2 \\\\ 5/2 & 4 \\end{pmatrix}\n$$\nFinally, we find the orthogonal component $A_{S^\\perp}$ by subtracting the projection from the original matrix $A$:\n$$\nA_{S^\\perp} = A - \\operatorname{proj}_S(A) = \\begin{pmatrix} 1 & 2 \\\\ 3 & 4 \\end{pmatrix} - \\begin{pmatrix} 1 & 5/2 \\\\ 5/2 & 4 \\end{pmatrix}\n$$\n$$\nA_{S^\\perp} = \\begin{pmatrix} 1-1 & 2 - 5/2 \\\\ 3 - 5/2 & 4-4 \\end{pmatrix} = \\begin{pmatrix} 0 & 4/2 - 5/2 \\\\ 6/2 - 5/2 & 0 \\end{pmatrix} = \\begin{pmatrix} 0 & -1/2 \\\\ 1/2 & 0 \\end{pmatrix}\n$$\nThis resulting matrix is skew-symmetric, which is expected as the space of skew-symmetric matrices is the orthogonal complement of the space of symmetric matrices.\n\nThe resulting matrix is $\\begin{pmatrix} a & b \\\\ c & d \\end{pmatrix} = \\begin{pmatrix} 0 & -1/2 \\\\ 1/2 & 0 \\end{pmatrix}$. Following the specified output format, we present this as a row matrix.", "answer": "$$\\boxed{\\begin{pmatrix} 0 & -\\frac{1}{2} & \\frac{1}{2} & 0 \\end{pmatrix}}$$", "id": "2309898"}]}