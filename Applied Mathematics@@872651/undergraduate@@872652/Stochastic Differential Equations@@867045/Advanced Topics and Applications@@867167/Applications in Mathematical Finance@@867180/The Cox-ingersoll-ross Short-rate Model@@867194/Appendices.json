{"hands_on_practices": [{"introduction": "Before exploring the full complexity of a stochastic process, it is essential to understand its average behavior. This practice guides you through deriving the expected future interest rate in the Cox-Ingersoll-Ross model [@problem_id:3080150]. By applying fundamental properties of stochastic integrals, you will transform the random SDE into a deterministic differential equation for the mean, revealing the model's core mean-reverting property.", "problem": "Consider the Cox–Ingersoll–Ross short-rate model, in which the short rate process $\\{r_t\\}_{t \\geq 0}$ satisfies the stochastic differential equation (SDE)\n$$\ndr_t \\;=\\; \\kappa\\big(\\theta - r_t\\big)\\,dt \\;+\\; \\sigma \\sqrt{r_t}\\,dW_t,\n$$\nwhere $\\kappa0$, $\\theta0$, and $\\sigma0$ are constants, $r_0 \\ge 0$ is the given initial short rate, and $\\{W_t\\}_{t \\ge 0}$ is a standard Brownian motion. Assume that the solution $\\{r_t\\}_{t \\ge 0}$ is strictly nonnegative and has finite first moment for each $t0$. Using only the foundational properties of Itô integrals (in particular, that the Itô integral has zero expectation under suitable integrability) and the linearity of expectation, derive the ordinary differential equation satisfied by the first moment $m_1(t)=\\mathbb{E}[r_t \\mid r_0]$, and solve it subject to the initial condition $m_1(0)=r_0$. Provide your final answer as a single closed-form analytic expression for $m_1(t)$ in terms of $t$, $\\kappa$, $\\theta$, and $r_0$. No numerical approximation is required.", "solution": "The problem as stated constitutes a valid, well-posed mathematical exercise in the field of stochastic differential equations. All parameters are clearly defined, the objective is unambiguous, and the framework relies on established scientific principles of the Cox-Ingersoll-Ross model. We shall proceed with the derivation.\n\nThe Cox-Ingersoll-Ross process for the short rate $\\{r_t\\}_{t \\geq 0}$ is described by the stochastic differential equation (SDE):\n$$\ndr_t = \\kappa(\\theta - r_t)dt + \\sigma \\sqrt{r_t}dW_t\n$$\nwhere $\\kappa$, $\\theta$, and $\\sigma$ are positive constants, $r_0 \\ge 0$ is the initial rate, and $\\{W_t\\}_{t \\ge 0}$ is a standard Brownian motion. We are asked to find the first moment, $m_1(t) = \\mathbb{E}[r_t \\mid r_0]$.\n\nFirst, we express the SDE in its integral form by integrating from time $s=0$ to $s=t$:\n$$\n\\int_{0}^{t} dr_s = \\int_{0}^{t} \\kappa(\\theta - r_s)ds + \\int_{0}^{t} \\sigma \\sqrt{r_s}dW_s\n$$\nThis yields:\n$$\nr_t - r_0 = \\int_{0}^{t} \\kappa(\\theta - r_s)ds + \\int_{0}^{t} \\sigma \\sqrt{r_s}dW_s\n$$\nRearranging for $r_t$, we get:\n$$\nr_t = r_0 + \\int_{0}^{t} \\kappa(\\theta - r_s)ds + \\int_{0}^{t} \\sigma \\sqrt{r_s}dW_s\n$$\nNow, we take the conditional expectation of both sides with respect to the information at time $t=0$, which is equivalent to conditioning on the given value of $r_0$.\n$$\n\\mathbb{E}[r_t \\mid r_0] = \\mathbb{E}\\left[r_0 + \\int_{0}^{t} \\kappa(\\theta - r_s)ds + \\int_{0}^{t} \\sigma \\sqrt{r_s}dW_s \\mid r_0\\right]\n$$\nUsing the linearity of the expectation operator, we can separate the terms:\n$$\n\\mathbb{E}[r_t \\mid r_0] = \\mathbb{E}[r_0 \\mid r_0] + \\mathbb{E}\\left[\\int_{0}^{t} \\kappa(\\theta - r_s)ds \\mid r_0\\right] + \\mathbb{E}\\left[\\int_{0}^{t} \\sigma \\sqrt{r_s}dW_s \\mid r_0\\right]\n$$\nLet us analyze each term on the right-hand side.\nBy definition, $m_1(t) = \\mathbb{E}[r_t \\mid r_0]$. Since $r_0$ is a known constant at time $t=0$, its expectation is itself: $\\mathbb{E}[r_0 \\mid r_0] = r_0$.\n\nFor the second term, which involves a standard Riemann integral, we can interchange the expectation and integration operators (by Fubini's theorem, applicable here).\n$$\n\\mathbb{E}\\left[\\int_{0}^{t} \\kappa(\\theta - r_s)ds \\mid r_0\\right] = \\int_{0}^{t} \\mathbb{E}[\\kappa(\\theta - r_s) \\mid r_0]ds\n$$\nUsing the linearity of expectation again inside the integral:\n$$\n\\int_{0}^{t} (\\mathbb{E}[\\kappa\\theta \\mid r_0] - \\mathbb{E}[\\kappa r_s \\mid r_0])ds = \\int_{0}^{t} (\\kappa\\theta - \\kappa\\mathbb{E}[r_s \\mid r_0])ds = \\int_{0}^{t} (\\kappa\\theta - \\kappa m_1(s))ds\n$$\nThe third term is the expectation of an Itô stochastic integral. A fundamental property of the Itô integral is that for any suitable adapted process $X_s$, the expectation of its integral with respect to Brownian motion is zero: $\\mathbb{E}\\left[\\int_{0}^{t} X_s dW_s\\right] = 0$. The necessary condition is that the integrand satisfies $\\mathbb{E}\\left[\\int_{0}^{t} X_s^2 ds\\right]  \\infty$. In our case, the integrand is $X_s = \\sigma\\sqrt{r_s}$. The condition becomes $\\mathbb{E}\\left[\\int_{0}^{t} (\\sigma\\sqrt{r_s})^2 ds\\right] = \\sigma^2 \\int_{0}^{t} \\mathbb{E}[r_s]ds  \\infty$. Since the problem statement assumes that the first moment $m_1(s) = \\mathbb{E}[r_s]$ is finite for each $s0$ and is a continuous function of time (which we will confirm), this integral is finite for any finite $t$. Thus, the property applies:\n$$\n\\mathbb{E}\\left[\\int_{0}^{t} \\sigma \\sqrt{r_s}dW_s \\mid r_0\\right] = 0\n$$\nSubstituting these results back into the equation for the expectation, we obtain an integral equation for $m_1(t)$:\n$$\nm_1(t) = r_0 + \\int_{0}^{t} (\\kappa\\theta - \\kappa m_1(s))ds\n$$\nTo convert this integral equation into an ordinary differential equation (ODE), we differentiate both sides with respect to $t$. Applying the Fundamental Theorem of Calculus to the integral term:\n$$\n\\frac{d}{dt}m_1(t) = \\frac{d}{dt}r_0 + \\frac{d}{dt}\\left(\\int_{0}^{t} (\\kappa\\theta - \\kappa m_1(s))ds\\right)\n$$\nSince $r_0$ is a constant, its derivative is zero. This yields:\n$$\n\\frac{dm_1(t)}{dt} = \\kappa\\theta - \\kappa m_1(t)\n$$\nThis is a first-order linear non-homogeneous ODE, which can be rearranged into the standard form:\n$$\n\\frac{dm_1(t)}{dt} + \\kappa m_1(t) = \\kappa\\theta\n$$\nThe initial condition is $m_1(0) = \\mathbb{E}[r_0 \\mid r_0] = r_0$.\nWe solve this ODE using an integrating factor, $I(t)$, defined as:\n$$\nI(t) = \\exp\\left(\\int \\kappa dt\\right) = \\exp(\\kappa t)\n$$\nMultiplying the entire ODE by $I(t)$:\n$$\n\\exp(\\kappa t)\\frac{dm_1(t)}{dt} + \\kappa\\exp(\\kappa t) m_1(t) = \\kappa\\theta\\exp(\\kappa t)\n$$\nThe left-hand side is the result of the product rule for differentiation applied to $\\exp(\\kappa t)m_1(t)$:\n$$\n\\frac{d}{dt}\\left[\\exp(\\kappa t) m_1(t)\\right] = \\kappa\\theta\\exp(\\kappa t)\n$$\nNow, we integrate both sides from $s=0$ to $s=t$:\n$$\n\\int_{0}^{t} \\frac{d}{ds}\\left[\\exp(\\kappa s) m_1(s)\\right]ds = \\int_{0}^{t} \\kappa\\theta\\exp(\\kappa s)ds\n$$\n$$\n\\left[\\exp(\\kappa s) m_1(s)\\right]_{0}^{t} = \\kappa\\theta \\left[\\frac{1}{\\kappa}\\exp(\\kappa s)\\right]_{0}^{t}\n$$\n$$\n\\exp(\\kappa t) m_1(t) - \\exp(0) m_1(0) = \\theta \\left[\\exp(\\kappa t) - \\exp(0)\\right]\n$$\nSubstituting the initial condition $m_1(0) = r_0$ and noting $\\exp(0)=1$:\n$$\n\\exp(\\kappa t) m_1(t) - r_0 = \\theta(\\exp(\\kappa t) - 1)\n$$\nSolving for $\\exp(\\kappa t) m_1(t)$:\n$$\n\\exp(\\kappa t) m_1(t) = r_0 - \\theta + \\theta\\exp(\\kappa t)\n$$\nFinally, we isolate $m_1(t)$ by dividing by $\\exp(\\kappa t)$ (or multiplying by $\\exp(-\\kappa t)$):\n$$\nm_1(t) = (r_0 - \\theta)\\exp(-\\kappa t) + \\theta\n$$\nThis is the closed-form analytic expression for the first moment of the CIR process. It shows that the expected short rate, $\\mathbb{E}[r_t]$, mean-reverts exponentially from its initial value $r_0$ towards the long-run mean $\\theta$ at a rate determined by $\\kappa$.", "answer": "$$\n\\boxed{\\theta + (r_0 - \\theta)\\exp(-\\kappa t)}\n$$", "id": "3080150"}, {"introduction": "Understanding the average path of the interest rate is only half the story; we must also quantify its uncertainty. This exercise builds on the previous one by challenging you to calculate the variance of the CIR process [@problem_id:3080159]. You will use Itô's lemma, a fundamental tool in stochastic calculus, to derive and solve an ODE for the second moment, thereby obtaining an explicit formula for the model's volatility.", "problem": "Consider the Cox–Ingersoll–Ross short-rate model, where the short rate $r_t$ evolves under the stochastic differential equation (SDE)\n$$\ndr_t \\;=\\; \\kappa\\left(\\theta - r_t\\right) \\, dt \\;+\\; \\sigma \\sqrt{r_t}\\, dW_t,\n$$\nwith $\\kappa0$, $\\theta0$, $\\sigma0$, initial condition $r_0 \\ge 0$, and $W_t$ a standard Wiener process. Let $m_1(t) = \\mathbb{E}[\\,r_t \\mid r_0\\,]$ and $m_2(t) = \\mathbb{E}[\\,r_t^2 \\mid r_0\\,]$ denote the first and second conditional moments, respectively.\n\nStarting from the fundamental definitions of conditional expectation, Itô’s lemma applied to the function $f(r) = r^2$, and the properties of Itô integrals, derive a linear ordinary differential equation (ODE) satisfied by $m_2(t)$ together with its initial condition. Then, solve this ODE consistently with the dynamics of $m_1(t)$ implied by the given SDE to obtain an explicit, closed-form expression for the conditional variance\n$$\n\\operatorname{Var}\\!\\left(r_t \\mid r_0\\right) \\;=\\; m_2(t) - \\big(m_1(t)\\big)^2\n$$\nas a function of $\\kappa$, $\\theta$, $\\sigma$, $t$, and $r_0$. Express your final answer as a single analytic expression. No rounding is required.", "solution": "The problem requires the derivation of the conditional variance of the Cox-Ingersoll-Ross (CIR) process. The short rate $r_t$ is governed by the stochastic differential equation (SDE):\n$$\ndr_t = \\kappa(\\theta - r_t) \\, dt + \\sigma \\sqrt{r_t}\\, dW_t\n$$\nwhere $\\kappa  0$, $\\theta  0$, $\\sigma  0$, $r_0 \\ge 0$, and $W_t$ is a standard Wiener process. We are asked to find $\\operatorname{Var}(r_t \\mid r_0) = m_2(t) - (m_1(t))^2$, where $m_1(t) = \\mathbb{E}[r_t \\mid r_0]$ and $m_2(t) = \\mathbb{E}[r_t^2 \\mid r_0]$.\n\nFirst, as instructed, we derive the ordinary differential equation (ODE) for the second moment, $m_2(t)$. We apply Itô's lemma to the function $f(r_t) = r_t^2$. The partial derivatives are $f_r = 2r_t$ and $f_{rr} = 2$.\nThe general form of Itô's lemma for a function $f(t, x_t)$ applied to an Itô process $dx_t = a(t, x_t)dt + b(t, x_t)dW_t$ is\n$$\ndf = \\left( \\frac{\\partial f}{\\partial t} + a \\frac{\\partial f}{\\partial x} + \\frac{1}{2} b^2 \\frac{\\partial^2 f}{\\partial x^2} \\right) dt + b \\frac{\\partial f}{\\partial x} dW_t.\n$$\nIn our case, $f$ does not depend explicitly on $t$, and the process is $r_t$ with drift $a(r_t) = \\kappa(\\theta - r_t)$ and diffusion $b(r_t) = \\sigma \\sqrt{r_t}$.\nThus, the SDE for $r_t^2$ is:\n$$\nd(r_t^2) = \\left( (2r_t) \\cdot \\kappa(\\theta - r_t) + \\frac{1}{2}(2) \\cdot (\\sigma\\sqrt{r_t})^2 \\right) dt + (2r_t) \\cdot (\\sigma\\sqrt{r_t}) dW_t\n$$\n$$\nd(r_t^2) = (2\\kappa\\theta r_t - 2\\kappa r_t^2 + \\sigma^2 r_t) dt + 2\\sigma r_t^{3/2} dW_t\n$$\n$$\nd(r_t^2) = ((2\\kappa\\theta + \\sigma^2)r_t - 2\\kappa r_t^2) dt + 2\\sigma r_t^{3/2} dW_t\n$$\nTo find the ODE for $m_2(t) = \\mathbb{E}[r_t^2 \\mid r_0]$, we take the conditional expectation of the integral form of this SDE:\n$$\n\\mathbb{E}[r_t^2 \\mid r_0] = \\mathbb{E}[r_0^2 \\mid r_0] + \\mathbb{E}\\left[\\int_0^t ((2\\kappa\\theta + \\sigma^2)r_s - 2\\kappa r_s^2) ds \\;\\middle|\\; r_0\\right] + \\mathbb{E}\\left[\\int_0^t 2\\sigma r_s^{3/2} dW_s \\;\\middle|\\; r_0\\right]\n$$\nThe expectation of the Itô integral term is zero. Using the linearity of expectation and Fubini's theorem, we get:\n$$\nm_2(t) = r_0^2 + \\int_0^t \\left( (2\\kappa\\theta + \\sigma^2)\\mathbb{E}[r_s \\mid r_0] - 2\\kappa\\mathbb{E}[r_s^2 \\mid r_0] \\right) ds\n$$\n$$\nm_2(t) = r_0^2 + \\int_0^t ((2\\kappa\\theta + \\sigma^2)m_1(s) - 2\\kappa m_2(s)) ds\n$$\nDifferentiating with respect to $t$ gives the linear ODE for $m_2(t)$:\n$$\n\\frac{dm_2}{dt} = (2\\kappa\\theta + \\sigma^2)m_1(t) - 2\\kappa m_2(t)\n$$\nThe initial condition is $m_2(0) = \\mathbb{E}[r_0^2 \\mid r_0] = r_0^2$.\n\nTo proceed, we need an expression for $m_1(t)$. We find its governing ODE by taking the expectation of the original SDE for $r_t$:\n$$\n\\mathbb{E}[r_t \\mid r_0] = \\mathbb{E}[r_0 \\mid r_0] + \\mathbb{E}\\left[\\int_0^t \\kappa(\\theta - r_s) ds \\;\\middle|\\; r_0\\right] + \\mathbb{E}\\left[\\int_0^t \\sigma \\sqrt{r_s} dW_s \\;\\middle|\\; r_0\\right]\n$$\n$$\nm_1(t) = r_0 + \\int_0^t \\kappa(\\theta - m_1(s)) ds\n$$\nDifferentiating with respect to $t$ yields the ODE for $m_1(t)$:\n$$\n\\frac{dm_1}{dt} = \\kappa(\\theta - m_1(t)) \\quad \\text{or} \\quad \\frac{dm_1}{dt} + \\kappa m_1(t) = \\kappa\\theta\n$$\nwith initial condition $m_1(0) = \\mathbb{E}[r_0 \\mid r_0] = r_0$. This is a first-order linear ODE with integrating factor $\\exp(\\kappa t)$. The solution is:\n$$\nm_1(t) = \\theta + (r_0 - \\theta)\\exp(-\\kappa t) = r_0 \\exp(-\\kappa t) + \\theta(1 - \\exp(-\\kappa t))\n$$\nNow, we find an ODE for the variance, $V(t) = \\operatorname{Var}(r_t \\mid r_0) = m_2(t) - (m_1(t))^2$. Differentiating with respect to $t$:\n$$\n\\frac{dV}{dt} = \\frac{dm_2}{dt} - 2m_1(t)\\frac{dm_1}{dt}\n$$\nSubstituting the ODEs for $m_1(t)$ and $m_2(t)$:\n$$\n\\frac{dV}{dt} = \\left( (2\\kappa\\theta + \\sigma^2)m_1(t) - 2\\kappa m_2(t) \\right) - 2m_1(t) \\left( \\kappa\\theta - \\kappa m_1(t) \\right)\n$$\n$$\n\\frac{dV}{dt} = 2\\kappa\\theta m_1(t) + \\sigma^2 m_1(t) - 2\\kappa m_2(t) - 2\\kappa\\theta m_1(t) + 2\\kappa (m_1(t))^2\n$$\n$$\n\\frac{dV}{dt} = \\sigma^2 m_1(t) - 2\\kappa \\left( m_2(t) - (m_1(t))^2 \\right)\n$$\n$$\n\\frac{dV}{dt} = \\sigma^2 m_1(t) - 2\\kappa V(t)\n$$\nThis gives a first-order linear ODE for the variance $V(t)$:\n$$\n\\frac{dV}{dt} + 2\\kappa V(t) = \\sigma^2 m_1(t)\n$$\nThe initial condition is $V(0) = \\operatorname{Var}(r_0 \\mid r_0) = 0$, since $r_0$ is a given constant.\nSubstitute the solution for $m_1(t)$ into the ODE for $V(t)$:\n$$\n\\frac{dV}{dt} + 2\\kappa V(t) = \\sigma^2 \\left( \\theta + (r_0 - \\theta)\\exp(-\\kappa t) \\right)\n$$\nThe integrating factor for this ODE is $\\exp(2\\kappa t)$. Multiplying the equation by this factor:\n$$\n\\exp(2\\kappa t)\\frac{dV}{dt} + 2\\kappa \\exp(2\\kappa t)V(t) = \\sigma^2 \\left( \\theta\\exp(2\\kappa t) + (r_0 - \\theta)\\exp(\\kappa t) \\right)\n$$\n$$\n\\frac{d}{dt}\\left( V(t)\\exp(2\\kappa t) \\right) = \\sigma^2 \\theta\\exp(2\\kappa t) + \\sigma^2(r_0 - \\theta)\\exp(\\kappa t)\n$$\nIntegrate both sides from $0$ to $t$:\n$$\n\\int_0^t \\frac{d}{ds}\\left( V(s)\\exp(2\\kappa s) \\right) ds = \\int_0^t \\left( \\sigma^2 \\theta\\exp(2\\kappa s) + \\sigma^2(r_0 - \\theta)\\exp(\\kappa s) \\right) ds\n$$\n$$\nV(t)\\exp(2\\kappa t) - V(0)\\exp(0) = \\sigma^2 \\theta \\left[ \\frac{\\exp(2\\kappa s)}{2\\kappa} \\right]_0^t + \\sigma^2(r_0 - \\theta) \\left[ \\frac{\\exp(\\kappa s)}{\\kappa} \\right]_0^t\n$$\nSince $V(0) = 0$:\n$$\nV(t)\\exp(2\\kappa t) = \\frac{\\sigma^2 \\theta}{2\\kappa}(\\exp(2\\kappa t) - 1) + \\frac{\\sigma^2(r_0 - \\theta)}{\\kappa}(\\exp(\\kappa t) - 1)\n$$\nFinally, multiplying by $\\exp(-2\\kappa t)$ to solve for $V(t)$:\n$$\nV(t) = \\frac{\\sigma^2 \\theta}{2\\kappa}(1 - \\exp(-2\\kappa t)) + \\frac{\\sigma^2(r_0 - \\theta)}{\\kappa}(\\exp(-\\kappa t) - \\exp(-2\\kappa t))\n$$\nThis expression can be rearranged to a more standard form. Let us group terms by $r_0$ and $\\theta$:\n$$\nV(t) = \\frac{\\sigma^2 r_0}{\\kappa}(\\exp(-\\kappa t) - \\exp(-2\\kappa t)) + \\frac{\\sigma^2 \\theta}{2\\kappa}(1 - \\exp(-2\\kappa t)) - \\frac{\\sigma^2 \\theta}{\\kappa}(\\exp(-\\kappa t) - \\exp(-2\\kappa t))\n$$\n$$\nV(t) = \\frac{\\sigma^2 r_0}{\\kappa}(\\exp(-\\kappa t) - \\exp(-2\\kappa t)) + \\frac{\\sigma^2 \\theta}{2\\kappa}(1 - \\exp(-2\\kappa t) - 2\\exp(-\\kappa t) + 2\\exp(-2\\kappa t))\n$$\n$$\nV(t) = \\frac{\\sigma^2 r_0}{\\kappa}(\\exp(-\\kappa t) - \\exp(-2\\kappa t)) + \\frac{\\sigma^2 \\theta}{2\\kappa}(1 - 2\\exp(-\\kappa t) + \\exp(-2\\kappa t))\n$$\nRecognizing the perfect square $(1-x)^2 = 1 - 2x + x^2$:\n$$\nV(t) = \\frac{\\sigma^2 r_0}{\\kappa}(\\exp(-\\kappa t) - \\exp(-2\\kappa t)) + \\frac{\\sigma^2 \\theta}{2\\kappa}(1 - \\exp(-\\kappa t))^2\n$$\nThis is the closed-form expression for the conditional variance.", "answer": "$$\n\\boxed{\\frac{\\sigma^{2} r_{0}}{\\kappa}\\left(\\exp(-\\kappa t) - \\exp(-2\\kappa t)\\right) + \\frac{\\sigma^{2} \\theta}{2\\kappa}\\left(1 - \\exp(-\\kappa t)\\right)^{2}}\n$$", "id": "3080159"}, {"introduction": "While analytical formulas for the mean and variance are powerful, many real-world applications require simulating entire paths of the interest rate. This advanced practice moves from pure analysis to computational implementation, showing how to construct an exact simulation scheme for the CIR model [@problem_id:3080108]. You will uncover the model's connection to the noncentral chi-square distribution and use it to write code that generates numerically exact sample paths, a crucial skill for modern quantitative finance.", "problem": "Consider the Cox–Ingersoll–Ross (CIR) short-rate model defined by the stochastic differential equation\n$$\ndr_t \\;=\\; \\kappa \\bigl(\\theta - r_t\\bigr)\\,dt \\;+\\; \\sigma \\sqrt{r_t}\\, dW_t,\n$$\nwhere $\\,\\kappa gt; 0\\,$ is the mean-reversion speed, $\\,\\theta gt; 0\\,$ is the long-run level, $\\,\\sigma gt; 0\\,$ is the volatility parameter, and $\\,\\{W_t\\}_{t \\ge 0}\\,$ is a standard Brownian motion. The aim is to construct an exact simulation scheme for the transition $\\,r_{t+\\Delta}\\,$ conditional on $\\,r_t\\,$ by leveraging a distributional identity involving the noncentral chi-square distribution.\n\nYour tasks are:\n\n1. Starting from the stochastic differential equation and using a valid transformation and Itô’s formula, derive the exact one-step transition mechanism that allows sampling $\\,r_{t+\\Delta}\\,$ given $\\,r_t\\,$ by drawing a single sample from a noncentral chi-square distribution and applying an appropriate scaling. Your derivation must begin from the model definition and fundamental properties of the squared Bessel process, without stating the final parameters at the outset.\n\n2. Based on your derivation, design an algorithm that, for given parameters $\\,(\\kappa,\\theta,\\sigma,r_t,\\Delta)\\,$, computes:\n   - the degrees of freedom $\\,\\nu\\,$ of the noncentral chi-square distribution,\n   - the noncentrality parameter $\\,\\lambda\\,$,\n   - the scale factor $\\,c\\,$\n   such that $\\,r_{t+\\Delta} = c \\cdot X\\,$ where $\\,X\\,$ follows a noncentral chi-square distribution with parameters $\\,(\\nu,\\lambda)\\,$.\n\n3. Implement a program that, for each test case below, performs the following steps:\n   - Compute $\\,\\nu\\,$, $\\,\\lambda\\,$, and $\\,c\\,$ according to your derived scheme.\n   - Use a pseudorandom number generator with the fixed seed $\\,123456\\,$ to generate $\\,N\\,$ independent samples of $\\,X\\,$ from the noncentral chi-square distribution with parameters $\\,(\\nu,\\lambda)\\,$, and map them to samples of $\\,r_{t+\\Delta}\\,$ via the scale $\\,c\\,$.\n   - Compute the sample mean of the simulated $\\,r_{t+\\Delta}\\,$ and, independently, compute the theoretical conditional mean $\\,\\mathbb{E}[r_{t+\\Delta}\\mid r_t]\\,$ implied by the model.\n   - For each test case, report a pair $[\\text{theoretical mean}, \\text{Monte Carlo mean}]$, with each entry rounded to $\\,6\\,$ decimal places.\n\nUse the following test suite of parameter sets, each specified as an ordered tuple $\\,(\\kappa,\\theta,\\sigma,r_t,\\Delta)\\,$:\n- Test A (general case): $(0.5,\\;0.04,\\;0.1,\\;0.03,\\;1.0)$\n- Test B (zero current short rate): $(1.2,\\;0.05,\\;0.3,\\;0.0,\\;0.5)$\n- Test C (near the Feller boundary $\\,2\\kappa\\theta = \\sigma^2\\,$): $(0.7,\\;0.02,\\;0.167332005,\\;0.015,\\;3.0)$\n- Test D (very short time step): $(0.3,\\;0.06,\\;0.4,\\;0.08,\\;0.01)$\n\nImplementation requirements:\n- Use $\\,N = 200{,}000\\,$ simulations per test case and the fixed seed $\\,123456\\,$ for reproducibility.\n- The final output must be a single line containing the results for all test cases as a comma-separated list of lists, in the exact format\n$$\n\\bigl[[m_{A}^{\\text{theory}}, m_{A}^{\\text{MC}}], [m_{B}^{\\text{theory}}, m_{B}^{\\text{MC}}], [m_{C}^{\\text{theory}}, m_{C}^{\\text{MC}}], [m_{D}^{\\text{theory}}, m_{D}^{\\text{MC}}]\\bigr],\n$$\nwhere each $\\,m^{\\text{theory}}\\,$ and $\\,m^{\\text{MC}}\\,$ is rounded to $\\,6\\,$ decimal places. Your program should produce a single line of output containing exactly this list format (for example, $\\,[[0.012345,0.012346],[\\dots],\\dots]\\,$), with no extra text.\n\nNotes:\n- All quantities are dimensionless; no physical units are involved.\n- Angles are not used.\n- Percentages must not be used; express any proportions in decimal form.", "solution": "The problem requires the derivation and implementation of an exact simulation scheme for the Cox-Ingersoll-Ross (CIR) process. The CIR process, denoted by $r_t$, models the evolution of a short-term interest rate and is defined by the following stochastic differential equation (SDE):\n$$\ndr_t \\;=\\; \\kappa \\bigl(\\theta - r_t\\bigr)\\,dt \\;+\\; \\sigma \\sqrt{r_t}\\, dW_t\n$$\nwhere $\\kappa  0$ is the speed of mean reversion, $\\theta  0$ is the long-term mean level, $\\sigma  0$ is the volatility parameter, and $\\{W_t\\}_{t \\ge 0}$ is a standard one-dimensional Brownian motion. The objective is to sample the value of the process at time $t+\\Delta$, $r_{t+\\Delta}$, conditional on its value at time $t$, $r_t$. The exact transition law is known to be related to the noncentral chi-square distribution.\n\nWe will first derive this relationship from fundamental principles, then formulate a numerical algorithm, and finally verify it against the known theoretical conditional mean.\n\n**1. Derivation of the Exact Transition Law**\n\nThe key to understanding the distributional properties of the CIR process lies in its connection to squared Ornstein-Uhlenbeck (OU) processes, which in turn are related to squared Bessel processes. This connection provides a constructive path to the transition law.\n\nLet us postulate that the CIR process $r_t$ can be represented as a scaled sum of squares of $\\nu$ independent, identical Ornstein-Uhlenbeck processes, where $\\nu$ is a parameter to be determined. Let $\\{X_i(t)\\}_{i=1}^\\nu$ be $\\nu$ independent OU processes satisfying the SDE:\n$$\ndX_i(t) = -\\frac{1}{2}\\kappa X_i(t)\\,dt + \\frac{1}{2}\\sigma\\,dW_i(t)\n$$\nwhere $\\{W_i(t)\\}_{i=1}^\\nu$ are independent standard Brownian motions.\n\nConsider the process $R_t = \\sum_{i=1}^{\\nu} X_i(t)^2$. We apply Itô's formula to $f(x) = x^2$ for each $X_i(t)$:\n$$\nd(X_i^2) = 2X_i dX_i + \\frac{1}{2}(2)(dX_i)^2\n$$\nThe quadratic variation is $(dX_i)^2 = \\left(\\frac{1}{2}\\sigma\\,dW_i(t)\\right)^2 = \\frac{1}{4}\\sigma^2\\,dt$. Substituting the SDE for $dX_i$:\n$$\nd(X_i^2) = 2X_i\\left(-\\frac{1}{2}\\kappa X_i(t)\\,dt + \\frac{1}{2}\\sigma\\,dW_i(t)\\right) + \\frac{1}{4}\\sigma^2\\,dt\n$$\n$$\nd(X_i^2) = -\\kappa X_i(t)^2\\,dt + \\sigma X_i(t)\\,dW_i(t) + \\frac{1}{4}\\sigma^2\\,dt\n$$\nSumming over all $\\nu$ processes from $i=1$ to $\\nu$:\n$$\ndR_t = d\\left(\\sum_{i=1}^{\\nu} X_i^2\\right) = \\sum_{i=1}^{\\nu} d(X_i^2) = \\sum_{i=1}^{\\nu} \\left(-\\kappa X_i^2\\,dt + \\sigma X_i\\,dW_i + \\frac{1}{4}\\sigma^2\\,dt\\right)\n$$\n$$\ndR_t = -\\kappa \\left(\\sum_{i=1}^{\\nu} X_i^2\\right)dt + \\frac{\\nu\\sigma^2}{4}\\,dt + \\sigma \\sum_{i=1}^{\\nu} X_i\\,dW_i\n$$\nRecognizing $R_t = \\sum X_i^2$, we have:\n$$\ndR_t = \\left(\\frac{\\nu\\sigma^2}{4} - \\kappa R_t\\right)dt + \\sigma \\sum_{i=1}^{\\nu} X_i\\,dW_i\n$$\nThe stochastic term can be rewritten. Let $d\\widetilde{W}_t = \\frac{\\sum_{i=1}^{\\nu} X_i\\,dW_i}{\\sqrt{\\sum_{i=1}^{\\nu} X_i^2}} = \\frac{\\sum_{i=1}^{\\nu} X_i\\,dW_i}{\\sqrt{R_t}}$. By Lévy's characterization theorem, since the $dW_i$ are independent and the sum of squared coefficients is $\\sum X_i^2/R_t = 1$, $\\widetilde{W}_t$ is a standard Brownian motion. Therefore, the stochastic term is $\\sigma\\sqrt{R_t}\\,d\\widetilde{W}_t$.\nThe SDE becomes:\n$$\ndR_t = \\kappa \\left(\\frac{\\nu\\sigma^2}{4\\kappa} - R_t\\right)dt + \\sigma\\sqrt{R_t}\\,d\\widetilde{W}_t\n$$\nThis SDE for $R_t$ matches the CIR SDE for $r_t$ if we identify $R_t$ with $r_t$ and set the long-term mean $\\theta = \\frac{\\nu\\sigma^2}{4\\kappa}$. This gives us the degrees of freedom parameter:\n$$\n\\nu = \\frac{4\\kappa\\theta}{\\sigma^2}\n$$\nThis derivation holds rigorously for integer $\\nu$, but the resulting transition distribution is valid for any $\\nu  0$.\n\nNow, we derive the distribution of $r_{t+\\Delta}$ conditional on $r_t$. The solution to the OU SDE for $X_i$ over the interval $[t, t+\\Delta]$ with initial value $X_i(t)$ is:\n$$\nX_i(t+\\Delta) = X_i(t)e^{-\\frac{1}{2}\\kappa\\Delta} + \\frac{\\sigma}{2}\\int_t^{t+\\Delta} e^{-\\frac{1}{2}\\kappa(t+\\Delta-s)}\\,dW_i(s)\n$$\nConditional on $X_i(t)$, the value $X_i(t+\\Delta)$ is a normally distributed random variable. Its conditional mean is:\n$$\n\\mathbb{E}[X_i(t+\\Delta) | X_i(t)] = X_i(t)e^{-\\frac{1}{2}\\kappa\\Delta}\n$$\nIts conditional variance is independent of $X_i(t)$:\n$$\n\\text{Var}[X_i(t+\\Delta) | X_i(t)] = \\mathbb{E}\\left[\\left(\\frac{\\sigma}{2}\\int_t^{t+\\Delta} e^{-\\frac{1}{2}\\kappa(t+\\Delta-s)}\\,dW_i(s)\\right)^2\\right] = \\frac{\\sigma^2}{4}\\int_t^{t+\\Delta} e^{-\\kappa(t+\\Delta-s)}\\,ds\n$$\nLet $u = t+\\Delta-s$, so $du = -ds$. The integral becomes $\\int_0^{\\Delta} e^{-\\kappa u}\\,du = \\frac{1}{\\kappa}(1-e^{-\\kappa\\Delta})$.\n$$\n\\text{Var}[X_i(t+\\Delta) | X_i(t)] = \\frac{\\sigma^2}{4\\kappa}(1-e^{-\\kappa\\Delta})\n$$\nThe value $r_{t+\\Delta} = \\sum_{i=1}^\\nu X_i(t+\\Delta)^2$ is the sum of squares of $\\nu$ independent, normal random variables with differing means but identical variances. Let $V = \\text{Var}[X_i(t+\\Delta) | X_i(t)]$.\nThen $X_i(t+\\Delta) \\sim \\mathcal{N}\\left(X_i(t)e^{-\\frac{1}{2}\\kappa\\Delta}, V\\right)$. We can write $X_i(t+\\Delta) = \\sqrt{V}Z_i$, where $Z_i \\sim \\mathcal{N}\\left(\\frac{X_i(t)e^{-\\frac{1}{2}\\kappa\\Delta}}{\\sqrt{V}}, 1\\right)$. Thus,\n$$\nr_{t+\\Delta} = \\sum_{i=1}^\\nu (\\sqrt{V}Z_i)^2 = V \\sum_{i=1}^\\nu Z_i^2\n$$\nThe sum $\\sum_{i=1}^\\nu Z_i^2$ follows a noncentral chi-square distribution, $\\chi'^2(\\nu, \\lambda)$, with $\\nu$ degrees of freedom and noncentrality parameter $\\lambda$ given by the sum of the squares of the means of the $Z_i$ variables:\n$$\n\\lambda = \\sum_{i=1}^\\nu \\left(\\frac{X_i(t)e^{-\\frac{1}{2}\\kappa\\Delta}}{\\sqrt{V}}\\right)^2 = \\frac{e^{-\\kappa\\Delta}}{V} \\sum_{i=1}^\\nu X_i(t)^2 = \\frac{e^{-\\kappa\\Delta}}{V} r_t\n$$\nTherefore, $r_{t+\\Delta}$ is distributed as $c \\cdot X$ where $X \\sim \\chi'^2(\\nu, \\lambda)$, with the parameters:\n1.  **Scale factor, $c$**: $c = V = \\frac{\\sigma^2(1-e^{-\\kappa\\Delta})}{4\\kappa}$\n2.  **Degrees of freedom, $\\nu$**: $\\nu = \\frac{4\\kappa\\theta}{\\sigma^2}$\n3.  **Noncentrality parameter, $\\lambda$**: $\\lambda = \\frac{r_t e^{-\\kappa\\Delta}}{c} = \\frac{4\\kappa r_t e^{-\\kappa\\Delta}}{\\sigma^2(1-e^{-\\kappa\\Delta})}$\n\nThis constitutes the exact sampling scheme: given $r_t$, we compute $(\\nu, \\lambda, c)$, draw a random sample $X$ from $\\chi'^2(\\nu, \\lambda)$, and find the new rate as $r_{t+\\Delta} = c \\cdot X$.\n\n**2. Theoretical Conditional Mean**\n\nWe can verify these parameters by calculating the theoretical conditional expectation of $r_{t+\\Delta}$. The expectation of a noncentral chi-square variable $X \\sim \\chi'^2(\\nu, \\lambda)$ is $\\mathbb{E}[X] = \\nu + \\lambda$.\nThus, the conditional expectation of $r_{t+\\Delta}$ is:\n$$\n\\mathbb{E}[r_{t+\\Delta} \\mid r_t] = \\mathbb{E}[c \\cdot X] = c \\cdot (\\nu + \\lambda)\n$$\nSubstituting our derived expressions for $c$, $\\nu$, and $\\lambda$:\n$$\n\\mathbb{E}[r_{t+\\Delta} \\mid r_t] = \\frac{\\sigma^2(1-e^{-\\kappa\\Delta})}{4\\kappa} \\left( \\frac{4\\kappa\\theta}{\\sigma^2} + \\frac{r_t e^{-\\kappa\\Delta}}{c} \\right)\n$$\n$$\n\\mathbb{E}[r_{t+\\Delta} \\mid r_t] = \\frac{\\sigma^2(1-e^{-\\kappa\\Delta})}{4\\kappa} \\frac{4\\kappa\\theta}{\\sigma^2} + \\frac{\\sigma^2(1-e^{-\\kappa\\Delta})}{4\\kappa} \\frac{r_t e^{-\\kappa\\Delta}}{\\frac{\\sigma^2(1-e^{-\\kappa\\Delta})}{4\\kappa}}\n$$\n$$\n\\mathbb{E}[r_{t+\\Delta} \\mid r_t] = \\theta(1-e^{-\\kappa\\Delta}) + r_t e^{-\\kappa\\Delta}\n$$\nThis is the well-known analytic formula for the conditional mean of the CIR process, which confirms the correctness of our derived parameters $(\\nu, \\lambda, c)$.\n\n**3. Algorithm and Simulation Design**\n\nBased on the above derivation, the algorithm for each test case $(\\kappa, \\theta, \\sigma, r_t, \\Delta)$ is as follows:\n\n1.  **Parameter Calculation**:\n    - Compute the degrees of freedom: $\\nu = \\frac{4\\kappa\\theta}{\\sigma^2}$.\n    - Compute the scale factor: $c = \\frac{\\sigma^2(1 - e^{-\\kappa\\Delta})}{4\\kappa}$.\n    - Compute the noncentrality parameter: $\\lambda = \\frac{r_t e^{-\\kappa\\Delta}}{c}$.\n\n2.  **Theoretical Mean Calculation**:\n    - Compute the theoretical conditional mean: $m^{\\text{theory}} = r_t e^{-\\kappa\\Delta} + \\theta(1-e^{-\\kappa\\Delta})$.\n\n3.  **Monte Carlo Simulation**:\n    - Initialize a pseudorandom number generator with a fixed seed ($123456$).\n    - Generate $N = 200,000$ independent samples, $\\{X_j\\}_{j=1}^N$, from the noncentral chi-square distribution $\\chi'^2(\\nu, \\lambda)$.\n    - Transform these samples into samples of the future rate: $\\{r_{t+\\Delta, j}\\}_{j=1}^N$, where $r_{t+\\Delta, j} = c \\cdot X_j$.\n    - Compute the sample mean (Monte Carlo mean): $m^{\\text{MC}} = \\frac{1}{N} \\sum_{j=1}^{N} r_{t+\\Delta, j}$.\n\n4.  **Reporting**:\n    - For each test case, report the pair $[m^{\\text{theory}}, m^{\\text{MC}}]$, with both values rounded to $6$ decimal places.\n\nThis procedure will be implemented for the provided test cases.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.stats import ncx2\n\ndef solve():\n    \"\"\"\n    Implements the exact simulation of the Cox-Ingersoll-Ross (CIR) model\n    and compares the Monte Carlo mean with the theoretical conditional mean.\n    \"\"\"\n    \n    # Define the test cases from the problem statement.\n    # Each tuple is in the format (kappa, theta, sigma, r_t, delta)\n    test_cases = [\n        (0.5, 0.04, 0.1, 0.03, 1.0),            # Test A (general case)\n        (1.2, 0.05, 0.3, 0.0, 0.5),             # Test B (zero current short rate)\n        (0.7, 0.02, 0.167332005, 0.015, 3.0),   # Test C (near Feller boundary)\n        (0.3, 0.06, 0.4, 0.08, 0.01),           # Test D (very short time step)\n    ]\n\n    # Simulation parameters\n    N = 200000\n    SEED = 123456\n    \n    # Initialize the random number generator\n    rng = np.random.default_rng(SEED)\n\n    results_for_print = []\n\n    for case in test_cases:\n        kappa, theta, sigma, r_t, delta = case\n\n        # 1. Calculate the theoretical conditional mean\n        exp_neg_kappa_delta = np.exp(-kappa * delta)\n        theoretical_mean = r_t * exp_neg_kappa_delta + theta * (1 - exp_neg_kappa_delta)\n\n        # 2. Compute parameters for the noncentral chi-square distribution\n        \n        # Degrees of freedom (nu)\n        nu = 4 * kappa * theta / (sigma**2)\n        \n        # Denominator for c and lambda\n        # This is c * (4*kappa/sigma**2)\n        one_minus_exp = 1 - exp_neg_kappa_delta\n\n        # Scale factor (c)\n        c = (sigma**2 * one_minus_exp) / (4 * kappa)\n        \n        # Noncentrality parameter (lambda)\n        # Handle c=0 case to avoid division by zero, which happens if kappa or delta are very large.\n        # Although not in test cases, it's good practice.\n        if c  1e-16:\n            lam = (r_t * exp_neg_kappa_delta) / c\n        else: # If c is effectively zero, r_t e^(-kappa*delta) must also be zero for a finite lambda.\n            lam = 0.0\n\n        # Special case for r_t = 0 implies lambda = 0\n        if r_t == 0.0:\n            lam = 0.0\n\n        # 3. Perform Monte Carlo simulation\n        \n        # Generate N samples from the noncentral chi-square distribution\n        # scipy.stats.ncx2 takes df=degrees_of_freedom, nc=noncentrality_parameter\n        non_central_chi_sq_samples = ncx2.rvs(df=nu, nc=lam, size=N, random_state=rng)\n        \n        # Map samples to r_{t+delta} samples via the scale factor c\n        r_t_delta_samples = c * non_central_chi_sq_samples\n        \n        # Compute the sample mean\n        monte_carlo_mean = np.mean(r_t_delta_samples)\n        \n        # 4. Store the rounded results\n        # The required output format is a list, e.g., [0.123456, 0.123457]\n        # We format it to a string '[v1,v2]' to have control over spacing.\n        formatted_pair = f\"[{theoretical_mean:.6f},{monte_carlo_mean:.6f}]\"\n        results_for_print.append(formatted_pair)\n\n    # Final print statement in the exact required format.\n    # The format is a list of lists of numbers.\n    # Example: [[0.012345,0.012346],[...],...]\n    print(f\"[[{','.join(results_for_print)}]]\")\n\nsolve()\n```", "id": "3080108"}]}