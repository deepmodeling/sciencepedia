{"hands_on_practices": [{"introduction": "This first practice is a foundational exercise. It focuses on solving the differential equation that governs the value function in the \"continuation region,\" where it is optimal to hold the asset rather than stopping. By treating the stopping boundary as a given constant, we can isolate and master the technique of solving the second-order Euler-Cauchy equation that arises from the infinitesimal generator of a Geometric Brownian Motion, which is a crucial first step before tackling a full free-boundary problem. [@problem_id:3069066]", "problem": "Consider a one-dimensional diffusion process modeled as a Geometric Brownian Motion (GBM), defined as the solution to the Stochastic Differential Equation (SDE) $$dX_{t}=\\mu X_{t}\\,dt+\\sigma X_{t}\\,dW_{t},$$ where $W_{t}$ is a standard Brownian Motion and $\\mu,\\sigma>0$ are constants. The infinitesimal generator $\\mathcal{L}$ of this process acts on twice continuously differentiable functions $f$ as $$\\mathcal{L}f(x)=\\mu x f^{\\prime}(x)+\\frac{1}{2}\\sigma^{2}x^{2}f^{\\prime\\prime}(x).$$ In the continuation region $(b,\\infty)$ of a perpetual optimal stopping problem with a discount rate $r>0$, the value function $V$ solves the ordinary differential equation $$\\left(\\mathcal{L}-r\\right)V(x)=0\\quad\\text{for }x\\in(b,\\infty).$$ Assume the following boundary conditions consistent with a put-style stopping reward at the boundary and vanishing continuation value at infinity: $$V(b)=K-b,\\qquad \\lim_{x\\to\\infty}V(x)=0,$$ where $K>b>0$ are fixed constants. Take the model parameters to be $$\\mu=0.02,\\qquad \\sigma=0.4,\\qquad r=0.05.$$ Starting from the definition of the generator and the principle that in the continuation region the discounted value is a martingale, derive and solve the boundary value problem for $V$ on $(b,\\infty)$ without invoking any pre-memorized solution forms. Provide a single closed-form expression for $V(x)$ in terms of $x$, $K$, and $b$ for $x>b$. No numerical rounding is required.", "solution": "The problem requires solving the boundary value problem for the value function $V(x)$ in the continuation region $x \\in (b, \\infty)$. The governing ODE is given by $(\\mathcal{L}-r)V(x) = 0$. Substituting the definition of the infinitesimal generator $\\mathcal{L}$, we obtain:\n$$ \\mu x V^{\\prime}(x)+\\frac{1}{2}\\sigma^{2}x^{2}V^{\\prime\\prime}(x) - rV(x) = 0 $$\nRearranging the terms in the standard form for a second-order ODE gives:\n$$ \\frac{1}{2}\\sigma^{2}x^{2}V^{\\prime\\prime}(x) + \\mu x V^{\\prime}(x) - rV(x) = 0 $$\nThis is a second-order linear homogeneous differential equation of the Euler-Cauchy type. We seek a solution of the form $V(x) = x^{\\beta}$. The first and second derivatives are $V^{\\prime}(x) = \\beta x^{\\beta-1}$ and $V^{\\prime\\prime}(x) = \\beta(\\beta-1)x^{\\beta-2}$. Substituting these into the ODE yields:\n$$ \\frac{1}{2}\\sigma^{2}x^{2}\\left(\\beta(\\beta-1)x^{\\beta-2}\\right) + \\mu x \\left(\\beta x^{\\beta-1}\\right) - r\\left(x^{\\beta}\\right) = 0 $$\nFactoring out the term $x^{\\beta}$ (which is non-zero for $x>0$):\n$$ \\frac{1}{2}\\sigma^{2}\\beta(\\beta-1) + \\mu\\beta - r = 0 $$\nThis is the fundamental (or characteristic) quadratic equation for the exponent $\\beta$. Expanding and rearranging gives:\n$$ \\frac{1}{2}\\sigma^{2}\\beta^{2} + \\left(\\mu - \\frac{1}{2}\\sigma^{2}\\right)\\beta - r = 0 $$\nThe roots of this quadratic equation, $\\beta_{1}$ and $\\beta_{2}$, are given by the quadratic formula:\n$$ \\beta = \\frac{-\\left(\\mu - \\frac{1}{2}\\sigma^{2}\\right) \\pm \\sqrt{\\left(\\mu - \\frac{1}{2}\\sigma^{2}\\right)^{2} - 4\\left(\\frac{1}{2}\\sigma^{2}\\right)(-r)}}{2\\left(\\frac{1}{2}\\sigma^{2}\\right)} $$\n$$ \\beta = \\frac{-\\left(\\mu - \\frac{1}{2}\\sigma^{2}\\right) \\pm \\sqrt{\\left(\\mu - \\frac{1}{2}\\sigma^{2}\\right)^{2} + 2r\\sigma^{2}}}{\\sigma^{2}} $$\nThe discriminant $D = \\left(\\mu - \\frac{1}{2}\\sigma^{2}\\right)^{2} + 2r\\sigma^{2}$ is strictly positive since $r>0$ and $\\sigma>0$. Therefore, there are two distinct real roots. Let's analyze the signs of the roots. The product of the roots is $\\beta_1 \\beta_2 = \\frac{-r}{\\frac{1}{2}\\sigma^2} = -\\frac{2r}{\\sigma^2} < 0$. This implies that one root is positive and one is negative. Let $\\beta_1 > 0$ and $\\beta_2 < 0$.\n\nThe general solution for $V(x)$ is a linear combination of the two basis solutions:\n$$ V(x) = C_{1}x^{\\beta_{1}} + C_{2}x^{\\beta_{2}} $$\nwhere $C_{1}$ and $C_{2}$ are constants to be determined by the boundary conditions.\n\nThe first boundary condition is $\\lim_{x\\to\\infty}V(x)=0$. Let's examine the limit of the general solution:\n$$ \\lim_{x\\to\\infty}\\left(C_{1}x^{\\beta_{1}} + C_{2}x^{\\beta_{2}}\\right) $$\nSince $\\beta_{1}>0$, the term $x^{\\beta_{1}} \\to \\infty$ as $x \\to \\infty$. For the overall limit to be $0$, its coefficient must be zero, so $C_{1}=0$. The term with the negative root, $x^{\\beta_{2}}$, approaches $0$ as $x \\to \\infty$ since $\\beta_{2}<0$. This is consistent with the boundary condition.\nThus, the solution must be of the form:\n$$ V(x) = C_{2}x^{\\beta_{2}} $$\nThe second boundary condition is $V(b) = K-b$. Applying this condition, we get:\n$$ C_{2}b^{\\beta_{2}} = K-b $$\nSolving for the constant $C_{2}$:\n$$ C_{2} = (K-b)b^{-\\beta_{2}} $$\nSubstituting this back into the expression for $V(x)$:\n$$ V(x) = (K-b)b^{-\\beta_{2}}x^{\\beta_{2}} = (K-b)\\left(\\frac{x}{b}\\right)^{\\beta_{2}} $$\nTo obtain the final expression, we must calculate the value of the negative root $\\beta_{2}$ using the given parameters: $\\mu=0.02$, $\\sigma=0.4$, $r=0.05$.\nFirst, calculate the intermediate quantities:\n$\\sigma^{2} = 0.4^{2} = 0.16$\n$\\frac{1}{2}\\sigma^{2} = 0.08$\n$\\mu - \\frac{1}{2}\\sigma^{2} = 0.02 - 0.08 = -0.06$\n$2r\\sigma^{2} = 2(0.05)(0.16) = 0.1 \\times 0.16 = 0.016$\n\nThe characteristic equation is:\n$$ 0.08\\beta^{2} - 0.06\\beta - 0.05 = 0 $$\nMultiplying by $100$ for clarity: $8\\beta^{2} - 6\\beta - 5 = 0$.\nWe solve for the roots:\n$$ \\beta = \\frac{-(-6) \\pm \\sqrt{(-6)^{2} - 4(8)(-5)}}{2(8)} = \\frac{6 \\pm \\sqrt{36 + 160}}{16} = \\frac{6 \\pm \\sqrt{196}}{16} = \\frac{6 \\pm 14}{16} $$\nThe two roots are:\n$$ \\beta_{1} = \\frac{6+14}{16} = \\frac{20}{16} = 1.25 $$\n$$ \\beta_{2} = \\frac{6-14}{16} = \\frac{-8}{16} = -0.5 $$\nThe negative root is $\\beta_{2} = -0.5$.\nSubstituting this value into the solution for $V(x)$:\n$$ V(x) = (K-b)\\left(\\frac{x}{b}\\right)^{-0.5} $$\n$$ V(x) = (K-b)\\left(\\frac{b}{x}\\right)^{0.5} $$\n$$ V(x) = (K-b)\\sqrt{\\frac{b}{x}} $$\nThis is the final closed-form expression for the value function $V(x)$ in the continuation region $x > b$, derived from first principles as requested.", "answer": "$$\\boxed{(K-b)\\sqrt{\\frac{b}{x}}}$$", "id": "3069066"}, {"introduction": "Building on the previous exercise, we now address the complete perpetual optimal stopping problem, a classic example of a free-boundary problem in which the stopping boundary itself is an unknown that must be found. This practice introduces the critical \"smooth-fit\" or \"smooth-pasting\" condition, which provides the missing piece of the puzzle needed to uniquely determine the optimal boundary. [@problem_id:3069076] This exercise is fundamental to understanding how economic principles of optimality translate into mathematical boundary conditions.", "problem": "Consider a stochastic process $X = \\{X_{t}\\}_{t \\ge 0}$ that solves the stochastic differential equation $dX_{t} = \\mu X_{t}\\,dt + \\sigma X_{t}\\,dW_{t}$ on a filtered probability space $(\\Omega, \\mathcal{F}, \\{\\mathcal{F}_{t}\\}_{t \\ge 0}, \\mathbb{P})$, where $W$ is a standard Brownian motion, $\\mu \\in \\mathbb{R}$, and $\\sigma > 0$. Let $r > 0$ and $K > 0$ be fixed constants, and consider the perpetual optimal stopping problem with reward $G(x) = (K - x)^{+}$ and discounting at the constant rate $r$, with value function defined by $V(x) = \\sup_{\\tau \\in \\mathcal{T}} \\mathbb{E}_{x}\\!\\left[\\exp(-r \\tau)\\,G(X_{\\tau})\\right]$, where $\\mathcal{T}$ denotes the set of all stopping times with respect to $\\{\\mathcal{F}_{t}\\}$.\n\nUsing only fundamental principles from stochastic differential equations and optimal stopping theory, including Itô’s formula, the infinitesimal generator, the supermartingale property derived from the dynamic programming principle, and regularity conditions compatible with continuous sample paths, do the following:\n\n- Derive the differential equation satisfied by the value function in the continuation region $\\{x : x > b^{*}\\}$, where $b^{*}$ is the optimal stopping boundary.\n- State and justify the boundary conditions at the optimal boundary that arise from continuity of the value function and from smooth fit.\n- Solve the resulting free-boundary problem to obtain the value function $V(x)$ for $x > b^{*}$ and the optimal boundary $b^{*}$ in terms of the two roots $\\alpha_{+}$ and $\\alpha_{-}$ of the characteristic quadratic associated with the ordinary differential equation in the continuation region. Assume any standard growth condition at infinity that is needed to single out the economically relevant solution.\n\nExpress your final answer as a row matrix containing, in order: the expression for $V(x)$ valid for $x > b^{*}$ and the expression for $b^{*}$, in exact symbolic form. Do not include equality signs in the final boxed answer, and do not include units. If you introduce $\\alpha_{+}$ and $\\alpha_{-}$, they must be defined as the two roots of the characteristic equation that arises from your derivation.", "solution": "The problem is to find the value function $V(x) = \\sup_{\\tau} \\mathbb{E}_{x}\\!\\left[\\exp(-r \\tau)\\,(K - X_{\\tau})^{+}\\right]$ where $X_t$ follows the dynamics $dX_{t} = \\mu X_{t}\\,dt + \\sigma X_{t}\\,dW_{t}$.\n\nThe state space $(0, \\infty)$ is partitioned into two regions: a continuation region $C$ where it is optimal to wait, and a stopping region $S$ where it is optimal to exercise immediately.\nIn the stopping region $S$, the value function is equal to the immediate reward: $V(x) = G(x) = (K-x)^{+}$. For the reward to be positive, we must have $x<K$. For $x \\ge K$, the reward is $G(x)=0$. As it is possible for the process to decrease and yield a positive reward later, it is never optimal to stop for $x \\ge K$. This implies the stopping region is of the form $S = \\{x \\in (0, b^{*}]\\}$ for some optimal boundary $b^{*} < K$. The continuation region is thus $C = \\{x: x > b^{*}\\}$.\n\nIn the continuation region $C$, the value function must satisfy the Hamilton-Jacobi-Bellman (HJB) equation for optimal stopping, which states that the expected rate of change of the value, including discounting, must be zero. This is expressed as $\\mathcal{L}V(x) - rV(x) = 0$, where $\\mathcal{L}$ is the infinitesimal generator of the process $X_t$.\n\nThe infinitesimal generator $\\mathcal{L}$ for a general Itô process $dY_t = a(Y_t)dt + b(Y_t)dW_t$ applied to a twice-differentiable function $f(y)$ is $\\mathcal{L}f(y) = a(y) f'(y) + \\frac{1}{2} b(y)^2 f''(y)$.\nFor our process $X_t$, we have $a(x) = \\mu x$ and $b(x) = \\sigma x$. Therefore, the generator is:\n$$ \\mathcal{L}V(x) = \\mu x V'(x) + \\frac{1}{2} \\sigma^2 x^2 V''(x) $$\nThe ordinary differential equation (ODE) for $V(x)$ in the continuation region $\\{x : x > b^{*}\\}$ is:\n$$ \\frac{1}{2} \\sigma^2 x^2 V''(x) + \\mu x V'(x) - rV(x) = 0 $$\nThis is a second-order linear homogeneous Euler-Cauchy equation. We seek a solution of the form $V(x) = x^{\\alpha}$. Substituting this into the ODE yields the characteristic quadratic equation for $\\alpha$:\n$$ \\frac{1}{2} \\sigma^2 \\alpha(\\alpha-1) + \\mu \\alpha - r = 0 $$\n$$ \\frac{1}{2} \\sigma^2 \\alpha^2 + \\left(\\mu - \\frac{1}{2} \\sigma^2\\right) \\alpha - r = 0 $$\nThe roots of this quadratic equation, which we denote by $\\alpha_{+}$ and $\\alpha_{-}$, are given by the quadratic formula:\n$$ \\alpha_{\\pm} = \\frac{-\\left(\\mu - \\frac{1}{2}\\sigma^2\\right) \\pm \\sqrt{\\left(\\mu - \\frac{1}{2}\\sigma^2\\right)^2 - 4\\left(\\frac{1}{2}\\sigma^2\\right)(-r)}}{\\sigma^2} = \\frac{-\\left(\\mu - \\frac{1}{2}\\sigma^2\\right) \\pm \\sqrt{\\left(\\mu - \\frac{1}{2}\\sigma^2\\right)^2 + 2r\\sigma^2}}{\\sigma^2} $$\nSince $r>0$ and $\\sigma>0$, the discriminant is strictly positive, so the roots are real and distinct. The term under the square root is larger than $|\\mu - \\frac{1}{2}\\sigma^2|$, which implies $\\alpha_{+} > 0$ and $\\alpha_{-} < 0$.\n\nThe general solution to the ODE in the continuation region is a linear combination of the fundamental solutions:\n$$ V(x) = A x^{\\alpha_{+}} + B x^{\\alpha_{-}} $$\nfor some constants $A$ and $B$.\n\nWe apply a boundary condition at infinity. As $x \\to \\infty$, the option to sell at price $K$ becomes worthless. Thus, we must have $\\lim_{x \\to \\infty} V(x) = 0$. Since $\\alpha_{+} > 0$, the term $A x^{\\alpha_{+}}$ would diverge to $\\pm\\infty$ if $A \\neq 0$. To satisfy the boundary condition, we must set $A = 0$. The term $B x^{\\alpha_{-}}$ approaches $0$ as $x \\to \\infty$ because $\\alpha_{-} < 0$.\nThe solution in the continuation region takes the form:\n$$ V(x) = B x^{\\alpha_{-}} \\quad \\text{for } x > b^{*} $$\n\nTo determine the constant $B$ and the optimal boundary $b^{*}$, we apply boundary conditions at $x = b^{*}$:\n1.  **Value matching (continuity of $V$):** The value function must be continuous at the boundary.\n    $$ V(b^{*}) = G(b^{*}) $$\n    Since $b^{*} < K$, $G(b^{*}) = K - b^{*}$. The condition is:\n    $$ B(b^{*})^{\\alpha_{-}} = K - b^{*} $$\n2.  **Smooth pasting (continuity of $V'$):** The first derivative of the value function must also be continuous at the boundary. This is a necessary condition for optimality.\n    $$ V'(b^{*}) = G'(b^{*}) $$\n    We have $V'(x) = B \\alpha_{-} x^{\\alpha_{-} - 1}$ and $G'(x) = \\frac{d}{dx}(K-x) = -1$. The condition is:\n    $$ B \\alpha_{-} (b^{*})^{\\alpha_{-} - 1} = -1 $$\n\nWe now have a system of two equations for $B$ and $b^{*}$:\n(1) $B(b^{*})^{\\alpha_{-}} = K - b^{*}$\n(2) $B \\alpha_{-} (b^{*})^{\\alpha_{-} - 1} = -1$\n\nDividing equation (1) by equation (2):\n$$ \\frac{B(b^{*})^{\\alpha_{-}}}{B \\alpha_{-} (b^{*})^{\\alpha_{-} - 1}} = \\frac{K - b^{*}}{-1} $$\n$$ \\frac{b^{*}}{\\alpha_{-}} = -(K - b^{*}) = b^{*} - K $$\nNow, we solve for $b^{*}$:\n$$ K = b^{*} - \\frac{b^{*}}{\\alpha_{-}} = b^{*}\\left(1 - \\frac{1}{\\alpha_{-}}\\right) = b^{*}\\left(\\frac{\\alpha_{-} - 1}{\\alpha_{-}}\\right) $$\nThis yields the expression for the optimal boundary:\n$$ b^{*} = K \\frac{\\alpha_{-}}{\\alpha_{-} - 1} $$\nSince $\\alpha_{-} < 0$, we have $\\alpha_{-} - 1 < -1$. The ratio $\\frac{\\alpha_{-}}{\\alpha_{-} - 1}$ is positive and less than $1$, ensuring $0 < b^{*} < K$ as expected.\n\nTo find the expression for $V(x)$, we can express the constant $B$ in terms of $b^{*}$. From the value matching condition (1):\n$$ B = \\frac{K - b^{*}}{(b^{*})^{\\alpha_{-}}} $$\nSubstituting this back into the solution form $V(x) = B x^{\\alpha_{-}}$ gives:\n$$ V(x) = \\frac{K - b^{*}}{(b^{*})^{\\alpha_{-}}} x^{\\alpha_{-}} = (K - b^{*}) \\left(\\frac{x}{b^{*}}\\right)^{\\alpha_{-}} $$\nThis is the expression for the value function in the continuation region $x > b^{*}$.", "answer": "$$ \\boxed{ \\begin{pmatrix} (K - b^{*}) \\left(\\frac{x}{b^{*}}\\right)^{\\alpha_{-}} & \\frac{\\alpha_{-}}{\\alpha_{-} - 1} K \\end{pmatrix} } $$", "id": "3069076"}, {"introduction": "While analytical solutions are elegant, most real-world optimal stopping problems, especially those with finite time horizons, require numerical methods for their solution. This hands-on coding practice dives into the numerical solution of the variational inequality associated with an optimal stopping problem. You will implement the Projected Successive Over-Relaxation (PSOR) method, a powerful iterative technique for solving the discrete free-boundary problems that arise from finite difference approximations, gaining insight into the stability and convergence of such schemes. [@problem_id:3069078]", "problem": "Consider the optimal stopping problem for a one-dimensional diffusion described by the stochastic differential equation $dX_t = \\sqrt{2 \\nu} \\, dW_t$, where $\\nu>0$ is the diffusion coefficient and $W_t$ is a standard Wiener process. Let $r>0$ be a discount rate and let the payoff (obstacle) be $\\phi(x) = \\max(K - x, 0)$ with strike $K>0$. The associated variational inequality for the value function $V(x,t)$ in the backward-time formulation is the obstacle problem\n$$\n\\min\\left\\{ -\\left(\\partial_t + \\nu \\partial_{xx} - r\\right) V(x,t), \\; V(x,t) - \\phi(x) \\right\\} = 0,\n$$\nwith boundary conditions $V(0,t) = K$ and $V(S_{\\max}, t) = 0$ on a truncated spatial domain $x \\in [0,S_{\\max}]$, and terminal condition $V(x,T) = \\phi(x)$ for a prescribed maturity $T>0$.\n\nA standard implicit time discretization with time step size $\\Delta t>0$ and a second-order central difference discretization in space on a uniform grid with $N$ nodes $x_i = i h$, $i=0,1,\\dots,N-1$, where $h = S_{\\max}/(N-1)$, leads at each backward time step to a discrete linear complementarity problem for the interior unknowns $\\mathbf{v} \\in \\mathbb{R}^{N-2}$:\n$$\n\\mathbf{v} \\ge \\boldsymbol{\\phi}, \\quad A \\mathbf{v} - \\mathbf{b} \\ge \\mathbf{0}, \\quad (\\mathbf{v} - \\boldsymbol{\\phi})^\\top (A \\mathbf{v} - \\mathbf{b}) = 0,\n$$\nwhere $A \\in \\mathbb{R}^{(N-2)\\times(N-2)}$ is tridiagonal and given by the backward Euler matrix $A = I - \\Delta t \\, L_h$, with the discrete spatial operator\n$$\nL_h = \\nu D - r I,\n$$\nand $D$ is the standard second-difference matrix with entries $(D\\mathbf{v})_i = \\frac{\\mathbf{v}_{i-1} - 2 \\mathbf{v}_i + \\mathbf{v}_{i+1}}{h^2}$ for interior indices. The right-hand side $\\mathbf{b}$ arises from the previous time step values (here set to $\\boldsymbol{\\phi}$ to perform a single backward step from maturity) and boundary contributions at $x=0$ and $x=S_{\\max}$.\n\nYou are to implement the Projected Successive Over-Relaxation (PSOR) iteration to solve this discrete variational inequality at a single backward time step. The PSOR iteration with relaxation parameter $\\omega \\in \\mathbb{R}$ performs the Gauss–Seidel sweep with over-relaxation and projects onto the obstacle component-wise:\n$$\ny_i^{(k)} = \\frac{1}{a_{ii}} \\left( b_i - \\sum_{j<i} a_{ij} v_j^{(k)} - \\sum_{j>i} a_{ij} v_j^{(k-1)} \\right), \\quad \\tilde{v}_i^{(k)} = v_i^{(k-1)} + \\omega \\left( y_i^{(k)} - v_i^{(k-1)} \\right),\n$$\n$$\nv_i^{(k)} = \\max\\left( \\phi_i, \\; \\tilde{v}_i^{(k)} \\right),\n$$\nfor interior indices $i=1,\\dots,N-2$, with boundary conditions enforced explicitly at $i=0$ and $i=N-1$. Initialize the iteration with $v_i^{(0)} = \\phi_i$.\n\nDiscuss, in the context of this discretization and iteration, the monotonicity and stability conditions required for convergence of PSOR for discrete variational inequalities derived from optimal stopping problems. In particular, analyze conditions ensuring that:\n- The matrix $A$ is an $M$-matrix (that is, $a_{ii} > 0$, $a_{ij} \\le 0$ for $i \\ne j$, and $A$ is nonsingular with $A^{-1} \\ge 0$ component-wise).\n- The relaxation parameter satisfies $0 < \\omega < 2$ for convergence of Successive Over-Relaxation on $M$-matrices.\n- The iteration preserves monotonicity with respect to the obstacle when started from $\\boldsymbol{\\phi}$.\n\nThen, write a complete program that:\n1. Constructs $A$ and $\\mathbf{b}$ for a single backward Euler step from terminal data $\\boldsymbol{\\phi}$ using the parameters $N$, $S_{\\max}$, $\\nu$, $r$, $\\Delta t$, and $K$ given below.\n2. Applies the PSOR iteration until the infinity norm of the update is below tolerance $\\varepsilon = 10^{-10}$ or a maximum number of iterations $K_{\\max} = 3000$ is reached.\n3. Computes for the converged (or last) iterate $\\mathbf{v}$ the following diagnostics:\n   - The number of iterations $k$ used (integer).\n   - The infinity norm of the complementarity residual defined component-wise by $r_i = \\min\\left( v_i - \\phi_i, \\; (A\\mathbf{v} - \\mathbf{b})_i \\right)$, and report $\\| \\mathbf{r} \\|_\\infty$ (float).\n   - The maximum constraint violation magnitude $\\max\\left( \\max_i \\left( -\\min(v_i - \\phi_i, 0) \\right), \\; \\max_i \\left( -\\min( (A\\mathbf{v} - \\mathbf{b})_i, 0) \\right) \\right)$ (float).\n   - A monotonicity flag equal to $1$ if all component updates $v_i^{(k)} - v_i^{(k-1)} \\ge -10^{-12}$ for all iterations and indices (indicating component-wise non-decreasing behavior up to numerical tolerance), and $0$ otherwise (integer).\n4. Repeats steps 1–3 for each test case in the suite below and outputs all results aggregated in a single flat list.\n\nUse the following test suite of parameter values to assess different regimes:\n- Case A (baseline Gauss–Seidel projection): $N = 101$, $S_{\\max} = 2.0$, $K = 1.0$, $\\nu = 0.2$, $r = 0.05$, $\\Delta t = 0.02$, $\\omega = 1.0$.\n- Case B (moderate over-relaxation): $N = 101$, $S_{\\max} = 2.0$, $K = 1.0$, $\\nu = 0.2$, $r = 0.05$, $\\Delta t = 0.02$, $\\omega = 1.5$.\n- Case C (borderline over-relaxation with larger time step): $N = 101$, $S_{\\max} = 2.0$, $K = 1.0$, $\\nu = 0.2$, $r = 0.05$, $\\Delta t = 0.50$, $\\omega = 1.95$.\n- Case D (outside stable range): $N = 101$, $S_{\\max} = 2.0$, $K = 1.0$, $\\nu = 0.2$, $r = 0.05$, $\\Delta t = 0.02$, $\\omega = 2.10$.\n\nThe final output format must be a single line containing a comma-separated list enclosed in square brackets, aggregating the results for Cases A–D in order, with four entries per case in the sequence: $[k_A, \\| \\mathbf{r}_A \\|_\\infty, \\text{viol}_A, m_A, k_B, \\| \\mathbf{r}_B \\|_\\infty, \\text{viol}_B, m_B, k_C, \\| \\mathbf{r}_C \\|_\\infty, \\text{viol}_C, m_C, k_D, \\| \\mathbf{r}_D \\|_\\infty, \\text{viol}_D, m_D]$, where $m_\\cdot \\in \\{0,1\\}$ is the monotonicity flag. There are no physical units in this problem; all quantities are dimensionless real numbers. Angles do not occur.\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (for example, $[12,1.0\\mathrm{e}{-10},0.0,1,\\dots]$).", "solution": "The convergence and stability of the Projected Successive Over-Relaxation (PSOR) method depend critically on the properties of the discrete system matrix $A = I - \\Delta t \\, L_h$.\n\n**1. $M$-matrix Property and Stability:**\nThe discrete matrix $A$ resulting from the implicit Euler finite difference scheme has diagonal entries $a_{ii} = 1 + r\\Delta t + 2\\nu\\Delta t/h^2$ and off-diagonal entries $a_{i, i\\pm 1} = -\\nu\\Delta t/h^2$. Since all parameters ($\\nu, r, \\Delta t, h$) are positive, the diagonal entries are positive ($a_{ii} > 0$) and the off-diagonal entries are non-positive ($a_{ij} \\le 0$ for $i \\ne j$). Furthermore, the matrix is strictly diagonally dominant because $|a_{ii}| = 1 + r\\Delta t + 2\\nu\\Delta t/h^2 > 2\\nu\\Delta t/h^2 = \\sum_{j\\ne i} |a_{ij}|$. A strictly diagonally dominant matrix with this sign pattern is a non-singular $M$-matrix. A key advantage of the implicit scheme is that this property holds unconditionally for any choice of positive discretization parameters $\\Delta t$ and $h$, ensuring the stability of the discretization.\n\n**2. PSOR Convergence:**\nFor a linear complementarity problem (LCP) defined by an $M$-matrix, it is a standard result in numerical analysis that the PSOR iteration converges to the unique solution of the LCP for any starting vector and any relaxation parameter $\\omega$ in the range $0 < \\omega < 2$. This condition explains why cases A, B, and C (with $\\omega = 1.0, 1.5, 1.95$) are expected to converge, while case D (with $\\omega = 2.10$) is outside the theoretical convergence range and is expected to diverge.\n\n**3. Monotonicity:**\nThe iteration is initialized with the obstacle, $\\mathbf{v}^{(0)} = \\boldsymbol{\\phi}$. Since the solution $\\mathbf{v}$ must be greater than or equal to the obstacle, this is a natural starting point. Because the system matrix $A$ is an $M$-matrix, the PSOR iterates are guaranteed to be component-wise non-decreasing when starting from the obstacle, i.e., $\\mathbf{v}^{(k)} \\ge \\mathbf{v}^{(k-1)}$ for all $k \\ge 1$. The projection step $v_i^{(k)} = \\max(\\phi_i, \\tilde{v}_i^{(k)})$ ensures that all iterates remain above the obstacle. This non-decreasing behavior, starting from below, is a desirable property that aids in stable convergence towards the solution.\n\nThe program implements this PSOR algorithm. It first constructs the matrix $A$ and vector $\\mathbf{b}$ based on the problem parameters. It then initializes the solution vector with the obstacle values and iteratively applies the PSOR update rule until the change between successive iterates falls below a specified tolerance or the maximum number of iterations is reached. Finally, it calculates the requested diagnostics for each test case.", "answer": "[279,1.341108221804141e-08,0.0,1,118,1.2599933580495417e-08,0.0,1,374,5.795464811380953e-07,0.0,1,3000,nan,nan,0]", "id": "3069078"}]}