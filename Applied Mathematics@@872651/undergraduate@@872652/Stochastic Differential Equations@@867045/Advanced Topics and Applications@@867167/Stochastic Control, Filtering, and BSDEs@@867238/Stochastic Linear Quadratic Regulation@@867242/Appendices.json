{"hands_on_practices": [{"introduction": "This first exercise lays the groundwork for solving stochastic linear quadratic regulation problems. Starting from the Hamilton-Jacobi-Bellman (HJB) equation for a scalar system, you will derive the corresponding Algebraic Riccati Equation (ARE). This practice will not only give you experience in solving the ARE but will also guide you in applying the crucial concept of closed-loop stability to select the unique, physically meaningful solution.", "problem": "Consider the scalar controlled Ornstein–Uhlenbeck process governed by the stochastic differential equation\n$$\n\\mathrm{d}X_t = a X_t\\,\\mathrm{d}t + b U_t\\,\\mathrm{d}t + \\sigma\\,\\mathrm{d}W_t,\n$$\nwhere $a<0$, $b\\neq 0$, $\\sigma \\in \\mathbb{R}$, and $(W_t)_{t\\ge 0}$ is a standard Wiener process. For a given finite horizon $T>0$, the performance index is\n$$\nJ_T(x_0;U) = \\mathbb{E}\\left[\\int_{0}^{T} \\big(q X_t^2 + r U_t^2\\big)\\,\\mathrm{d}t\\right],\n$$\nwith $q>0$ and $r>0$. Assume the value function has the quadratic form $V(t,x)=P(t)\\,x^2 + c(t)$ with terminal condition $V(T,x)=0$.\n\nStarting from the dynamic programming principle and the Hamilton–Jacobi–Bellman equation for this finite-horizon problem, derive the ordinary differential equation that $P(t)$ must satisfy. Then, by considering the infinite-horizon limit $T\\to\\infty$ under the standing assumptions ($a<0$, $q>0$, $r>0$, $b\\neq 0$), determine the constant steady-state coefficient $P_{\\infty}$ that solves the resulting algebraic equation and select the stabilizing solution that makes the closed-loop drift $a - \\frac{b^2}{r} P_{\\infty}$ strictly negative.\n\nExpress your final answer as a single closed-form analytic expression for $P_{\\infty}$ in terms of $a$, $b$, $q$, and $r$. No numerical evaluation or rounding is required. The final answer must be a single expression.", "solution": "The problem statement is a standard formulation of a scalar finite-horizon stochastic linear quadratic regulator (SLQR) problem, and its extension to the infinite-horizon case. All provided data, conditions, and parameters are consistent, scientifically sound, and well-posed within the established framework of stochastic control theory. The problem is valid.\n\nThe value function for this problem is defined as\n$$\nV(t, x) = \\min_{U} \\mathbb{E}\\left[\\int_{t}^{T} \\big(q X_s^2 + r U_s^2\\big)\\,\\mathrm{d}s \\;\\Bigg|\\; X_t=x\\right].\n$$\nThe value function $V(t,x)$ must satisfy the Hamilton-Jacobi-Bellman (HJB) partial differential equation:\n$$\n-\\frac{\\partial V}{\\partial t}(t,x) = \\min_{U} \\left\\{ (ax + bU)\\frac{\\partial V}{\\partial x}(t,x) + \\frac{1}{2}\\sigma^2 \\frac{\\partial^2 V}{\\partial x^2}(t,x) + qx^2 + rU^2 \\right\\},\n$$\nwith the terminal condition $V(T,x) = 0$.\n\nWe are given the ansatz that the value function has the quadratic form $V(t,x) = P(t)x^2 + c(t)$. We compute its partial derivatives:\n$$\n\\frac{\\partial V}{\\partial t} = \\dot{P}(t)x^2 + \\dot{c}(t), \\quad \\frac{\\partial V}{\\partial x} = 2P(t)x, \\quad \\frac{\\partial^2 V}{\\partial x^2} = 2P(t).\n$$\nSubstituting these into the HJB equation yields:\n$$\n-\\left(\\dot{P}(t)x^2 + \\dot{c}(t)\\right) = \\min_{U} \\left\\{ (ax + bU)(2P(t)x) + \\frac{1}{2}\\sigma^2(2P(t)) + qx^2 + rU^2 \\right\\}.\n$$\n$$\n-\\dot{P}(t)x^2 - \\dot{c}(t) = \\min_{U} \\left\\{ 2aP(t)x^2 + 2bP(t)xU + \\sigma^2P(t) + qx^2 + rU^2 \\right\\}.\n$$\nTo find the optimal control $U_t^*$, we minimize the expression in the curly braces with respect to $U$. The expression is a convex quadratic in $U$, so its minimum is found by setting its first derivative with respect to $U$ to zero:\n$$\n\\frac{\\partial}{\\partial U} \\left(rU^2 + 2bP(t)xU + \\dots \\right) = 2rU + 2bP(t)x = 0.\n$$\nSince $r>0$, this gives the unique optimal control:\n$$\nU_t^* = -\\frac{b P(t)}{r} X_t.\n$$\nNow, we substitute this optimal control back into the HJB equation:\n$$\n-\\dot{P}(t)x^2 - \\dot{c}(t) = 2aP(t)x^2 + 2bP(t)x\\left(-\\frac{bP(t)x}{r}\\right) + \\sigma^2P(t) + qx^2 + r\\left(-\\frac{bP(t)x}{r}\\right)^2.\n$$\nSimplifying the right-hand side:\n$$\n-\\dot{P}(t)x^2 - \\dot{c}(t) = 2aP(t)x^2 - \\frac{2b^2P(t)^2}{r}x^2 + \\sigma^2P(t) + qx^2 + \\frac{b^2P(t)^2}{r}x^2.\n$$\nCombine terms:\n$$\n-\\dot{P}(t)x^2 - \\dot{c}(t) = \\left(2aP(t) - \\frac{b^2P(t)^2}{r} + q\\right)x^2 + \\sigma^2P(t).\n$$\nThis equation must hold for all $x \\in \\mathbb{R}$. By separating the terms that depend on $x^2$ from the constant terms, we obtain a system of two ordinary differential equations (ODEs):\n1.  $-\\dot{P}(t) = q + 2aP(t) - \\frac{b^2}{r}P(t)^2$\n2.  $-\\dot{c}(t) = \\sigma^2P(t)$\n\nThe terminal condition $V(T,x) = P(T)x^2 + c(T) = 0$ for all $x$ implies the boundary conditions $P(T)=0$ and $c(T)=0$. The first equation is the differential Riccati equation for $P(t)$.\n\nFor the infinite-horizon problem ($T \\to \\infty$), we seek a steady-state solution where the value function is time-invariant. This implies that $P(t)$ becomes a constant, which we denote by $P_{\\infty}$. In this steady state, its time derivative is zero, $\\dot{P}(t) = 0$. The differential Riccati equation reduces to the continuous-time Algebraic Riccati Equation (ARE):\n$$\n0 = q + 2aP_{\\infty} - \\frac{b^2}{r}P_{\\infty}^2.\n$$\nRearranging this into a standard quadratic form $Ax^2+Bx+C=0$ for $P_{\\infty}$:\n$$\n\\frac{b^2}{r}P_{\\infty}^2 - 2aP_{\\infty} - q = 0.\n$$\nWe solve for $P_{\\infty}$ using the quadratic formula:\n$$\nP_{\\infty} = \\frac{-(-2a) \\pm \\sqrt{(-2a)^2 - 4\\left(\\frac{b^2}{r}\\right)(-q)}}{2\\left(\\frac{b^2}{r}\\right)} = \\frac{2a \\pm \\sqrt{4a^2 + \\frac{4b^2q}{r}}}{\\frac{2b^2}{r}}.\n$$\nSimplifying this expression:\n$$\nP_{\\infty} = \\frac{r}{b^2}\\left(a \\pm \\sqrt{a^2 + \\frac{b^2q}{r}}\\right).\n$$\nThe problem requires selecting the solution that stabilizes the closed-loop system. The steady-state optimal control is $U_t^* = -\\frac{b P_{\\infty}}{r} X_t$. Substituting this into the SDE for $X_t$ gives the closed-loop dynamics:\n$$\n\\mathrm{d}X_t = a X_t\\,\\mathrm{d}t + b\\left(-\\frac{b P_{\\infty}}{r} X_t\\right)\\,\\mathrm{d}t + \\sigma\\,\\mathrm{d}W_t = \\left(a - \\frac{b^2 P_{\\infty}}{r}\\right)X_t\\,\\mathrm{d}t + \\sigma\\,\\mathrm{d}W_t.\n$$\nFor the process to be stable, the closed-loop drift coefficient, $a_{cl} = a - \\frac{b^2 P_{\\infty}}{r}$, must be strictly negative. Let's test the two solutions for $P_{\\infty}$.\n\nCase 1: $P_{\\infty,1} = \\frac{r}{b^2}\\left(a + \\sqrt{a^2 + \\frac{b^2q}{r}}\\right)$\n$$\na_{cl,1} = a - \\frac{b^2}{r} \\left[ \\frac{r}{b^2}\\left(a + \\sqrt{a^2 + \\frac{b^2q}{r}}\\right) \\right] = a - \\left(a + \\sqrt{a^2 + \\frac{b^2q}{r}}\\right) = -\\sqrt{a^2 + \\frac{b^2q}{r}}.\n$$\nSince $b \\neq 0$, $q > 0$, and $r > 0$, the term $\\frac{b^2q}{r}$ is positive. Thus, $a^2 + \\frac{b^2q}{r} > 0$, and its square root is a positive real number. Therefore, $a_{cl,1} < 0$, which corresponds to a stable closed-loop system.\n\nCase 2: $P_{\\infty,2} = \\frac{r}{b^2}\\left(a - \\sqrt{a^2 + \\frac{b^2q}{r}}\\right)$\n$$\na_{cl,2} = a - \\frac{b^2}{r} \\left[ \\frac{r}{b^2}\\left(a - \\sqrt{a^2 + \\frac{b^2q}{r}}\\right) \\right] = a - \\left(a - \\sqrt{a^2 + \\frac{b^2q}{r}}\\right) = +\\sqrt{a^2 + \\frac{b^2q}{r}}.\n$$\nThis drift coefficient is strictly positive, $a_{cl,2} > 0$, which corresponds to an unstable closed-loop system.\n\nFurthermore, the value function must be non-negative, which requires $P_{\\infty} \\ge 0$. Given $a<0$, we have $|a|=-a$. The term under the square root satisfies $\\sqrt{a^2 + \\frac{b^2q}{r}} > \\sqrt{a^2} = |a| = -a$.\nFor $P_{\\infty,1}$, the term $a + \\sqrt{a^2 + \\frac{b^2q}{r}} > a + (-a) = 0$. Since $\\frac{r}{b^2}>0$, $P_{\\infty,1}$ is positive.\nFor $P_{\\infty,2}$, the term $a - \\sqrt{a^2 + \\frac{b^2q}{r}}$ is negative since $a<0$ and $-\\sqrt{\\cdot}<0$. Thus $P_{\\infty,2}$ is negative.\nBoth the stability requirement and the positivity of the value function select the same solution. The correct steady-state coefficient is $P_{\\infty,1}$.", "answer": "$$\\boxed{\\frac{r}{b^2}\\left(a + \\sqrt{a^2 + \\frac{b^2q}{r}}\\right)}$$", "id": "3077803"}, {"introduction": "Once an optimal control law is in place, the next step is to evaluate its performance. This exercise guides you through the process of characterizing the steady-state behavior of a system under optimal stochastic LQR control. By calculating the stationary variance, you will gain a quantitative understanding of the residual system fluctuations and see explicitly how they depend on the intensity of the random noise.", "problem": "Consider the scalar controlled Itô Stochastic Differential Equation (SDE)\n$$\n\\mathrm{d}x_t = a\\,x_t\\,\\mathrm{d}t + b\\,u_t\\,\\mathrm{d}t + \\sigma\\,\\mathrm{d}W_t,\n$$\nwhere $a \\in \\mathbb{R}$, $b \\neq 0$, $\\sigma > 0$, and $\\{W_t\\}_{t \\ge 0}$ is a standard Wiener process. The performance criterion is the infinite-horizon ergodic average cost\n$$\nJ(u) \\;=\\; \\limsup_{T \\to \\infty} \\frac{1}{T}\\,\\mathbb{E}\\!\\left[\\int_0^T \\big(q\\,x_t^2 + r\\,u_t^2\\big)\\,\\mathrm{d}t\\right],\n$$\nwith $q>0$ and $r>0$. Assume full state observation and restrict attention to time-invariant state-feedback controls of the form $u_t = \\pi(x_t)$ that render the closed-loop system mean-square stable.\n\nStarting from the dynamic programming principle and the Hamilton–Jacobi–Bellman (HJB) equation for the ergodic cost, derive the optimal infinite-horizon Linear Quadratic Regulator (LQR) feedback law, and show that the closed-loop dynamics are Ornstein–Uhlenbeck. Then, compute the stationary (steady-state) variance $\\operatorname{Var}_{\\pi}(x_t)$ of $x_t$ under the optimal feedback as an explicit function of $a$, $b$, $q$, $r$, and $\\sigma$. Finally, explain qualitatively how the stationary variance depends on the diffusion intensity $\\sigma$. \n\nYour final reported answer must be the single closed-form expression for the steady-state variance $\\operatorname{Var}_{\\pi}(x_t)$ in terms of $a$, $b$, $q$, $r$, and $\\sigma$. No rounding is required.", "solution": "The problem specified is a continuous-time, infinite-horizon, scalar stochastic linear quadratic regulator (LQR) problem with an ergodic (average cost) performance criterion. We begin by validating the problem statement.\n\nThe givens are:\n- The state dynamics, a linear Itô Stochastic Differential Equation (SDE): $\\mathrm{d}x_t = a\\,x_t\\,\\mathrm{d}t + b\\,u_t\\,\\mathrm{d}t + \\sigma\\,\\mathrm{d}W_t$, with parameters $a \\in \\mathbb{R}$, $b \\neq 0$, and $\\sigma > 0$.\n- The cost functional: $J(u) = \\limsup_{T \\to \\infty} \\frac{1}{T}\\,\\mathbb{E}\\!\\left[\\int_0^T (q\\,x_t^2 + r\\,u_t^2)\\,\\mathrm{d}t\\right]$, with weighting factors $q>0$ and $r>0$.\n- The class of admissible controls: time-invariant state-feedback laws $u_t = \\pi(x_t)$ that ensure mean-square stability of the closed-loop system.\n\nThe problem is scientifically grounded, well-posed, and objective. It is a canonical problem in stochastic control theory. The system is controllable (since $b \\neq 0$), and the cost function is convex with positive definite weighting on state and control, which guarantees the existence of a unique optimal and stabilizing control law. The problem is therefore valid.\n\nWe proceed with the solution, starting from the dynamic programming principle for the ergodic cost problem. This principle leads to the Hamilton–Jacobi–Bellman (HJB) equation. For a given state $x$ and control $u$, the cost rate is $L(x, u) = q\\,x^2 + r\\,u^2$. The infinitesimal generator of the SDE, acting on a twice-differentiable function $V(x)$, is given by\n$$\n\\mathcal{A}^u V(x) = (a\\,x + b\\,u)\\frac{\\mathrm{d}V}{\\mathrm{d}x} + \\frac{1}{2}\\sigma^2\\frac{\\mathrm{d}^2V}{\\mathrm{d}x^2}.\n$$\nThe HJB equation for the optimal average cost $\\rho$ is\n$$\n\\rho = \\min_{u \\in \\mathbb{R}} \\left\\{ q\\,x^2 + r\\,u^2 + \\mathcal{A}^u V(x) \\right\\},\n$$\nwhere $V(x)$ is the relative value function. Substituting the generator, we have\n$$\n\\rho = \\min_{u \\in \\mathbb{R}} \\left\\{ q\\,x^2 + r\\,u^2 + (a\\,x + b\\,u)V'(x) + \\frac{1}{2}\\sigma^2V''(x) \\right\\}.\n$$\nThe expression inside the minimum is a convex quadratic function of $u$. The minimum is found by setting the partial derivative with respect to $u$ to zero:\n$$\n\\frac{\\partial}{\\partial u} \\left[ r\\,u^2 + b\\,u\\,V'(x) \\right] = 2\\,r\\,u + b\\,V'(x) = 0.\n$$\nThis yields the optimal control law in feedback form:\n$$\nu^*(x) = -\\frac{b}{2r}V'(x).\n$$\nWe substitute this optimal control back into the HJB equation:\n$$\n\\rho = q\\,x^2 + r\\left(-\\frac{b}{2r}V'(x)\\right)^2 + \\left(a\\,x + b\\left(-\\frac{b}{2r}V'(x)\\right)\\right)V'(x) + \\frac{1}{2}\\sigma^2V''(x).\n$$\nSimplifying the expression gives\n$$\n\\rho = q\\,x^2 + \\frac{b^2}{4r}(V'(x))^2 + a\\,x\\,V'(x) - \\frac{b^2}{2r}(V'(x))^2 + \\frac{1}{2}\\sigma^2V''(x),\n$$\n$$\n\\rho = q\\,x^2 + a\\,x\\,V'(x) - \\frac{b^2}{4r}(V'(x))^2 + \\frac{1}{2}\\sigma^2V''(x).\n$$\nFor a linear system with a quadratic cost, we hypothesize a quadratic relative value function of the form $V(x) = \\frac{1}{2}Px^2$, where $P$ is a constant to be determined. The derivatives are $V'(x) = Px$ and $V''(x) = P$. Substituting these into the HJB equation:\n$$\n\\rho = q\\,x^2 + a\\,x\\,(Px) - \\frac{b^2}{4r}(Px)^2 + \\frac{1}{2}\\sigma^2P.\n$$\nCollecting terms in powers of $x$:\n$$\n\\rho = \\left(q + aP - \\frac{b^2P^2}{4r}\\right)x^2 + \\frac{1}{2}\\sigma^2P.\n$$\nThis equation must hold for all $x \\in \\mathbb{R}$. This is only possible if the coefficient of the $x^2$ term is zero. This requirement yields the scalar algebraic Riccati equation (ARE):\n$$\nq + aP - \\frac{b^2P^2}{4r} = 0 \\quad \\implies \\quad \\frac{b^2}{4r}P^2 - aP - q = 0.\n$$\nThe solutions for $P$ from this quadratic equation are\n$$\nP = \\frac{a \\pm \\sqrt{a^2 - 4\\left(\\frac{b^2}{4r}\\right)(-q)}}{2\\left(\\frac{b^2}{4r}\\right)} = \\frac{a \\pm \\sqrt{a^2 + \\frac{b^2q}{r}}}{\\frac{b^2}{2r}} = \\frac{2r}{b^2}\\left(a \\pm \\sqrt{a^2 + \\frac{b^2q}{r}}\\right).\n$$\nThe problem requires a control that renders the system mean-square stable. The optimal control is $u_t = u^*(x_t) = -\\frac{b}{2r}V'(x_t) = -\\frac{b P}{2r}x_t$. The closed-loop SDE becomes\n$$\n\\mathrm{d}x_t = \\left(a - \\frac{b^2P}{2r}\\right)x_t\\,\\mathrm{d}t + \\sigma\\,\\mathrm{d}W_t.\n$$\nFor mean-square stability of this linear SDE, the drift coefficient must be negative: $a_{cl} = a - \\frac{b^2P}{2r} < 0$.\nSince $q>0$, $r>0$, we have $\\sqrt{a^2 + b^2q/r} > \\sqrt{a^2} = |a|$.\nThe solution $P_{-} = \\frac{2r}{b^2}\\left(a - \\sqrt{a^2 + \\frac{b^2q}{r}}\\right)$ is negative, because $a < \\sqrt{a^2 + \\dots}$. A negative $P$ would imply a negative value (cost), which is inconsistent for a cost function with $q>0, r>0$.\nThe other solution, $P_{+} = \\frac{2r}{b^2}\\left(a + \\sqrt{a^2 + \\frac{b^2q}{r}}\\right)$, is positive, since $a + \\sqrt{a^2+\\dots} > a+|a| \\ge 0$. Let's check the stability condition with $P=P_{+}$:\n$$\na_{cl} = a - \\frac{b^2}{2r} P_{+} = a - \\frac{b^2}{2r} \\frac{2r}{b^2}\\left(a + \\sqrt{a^2 + \\frac{b^2q}{r}}\\right) = a - \\left(a + \\sqrt{a^2 + \\frac{b^2q}{r}}\\right) = -\\sqrt{a^2 + \\frac{b^2q}{r}}.\n$$\nSince $b \\neq 0$, $q > 0$, $r > 0$, the term under the square root is strictly positive, so $a_{cl} < 0$. Thus, $P = P_{+}$ is the unique positive definite solution to the ARE that provides a stabilizing feedback control.\n\nThe closed-loop system is described by the SDE\n$$\n\\mathrm{d}x_t = a_{cl}\\,x_t\\,\\mathrm{d}t + \\sigma\\,\\mathrm{d}W_t, \\quad \\text{where} \\quad a_{cl} = -\\sqrt{a^2 + \\frac{b^2q}{r}}.\n$$\nThis is the equation for an Ornstein–Uhlenbeck (OU) process, which has the general form $\\mathrm{d}X_t = -\\theta X_t \\mathrm{d}t + \\nu \\mathrm{d}W_t$. In our case, the mean-reversion rate is $\\theta = -a_{cl} > 0$ and the volatility is $\\nu = \\sigma$.\n\nAn OU process has a stationary (or ergodic) distribution, which is a Gaussian distribution with mean $0$ and variance $\\operatorname{Var}(X) = \\frac{\\nu^2}{2\\theta}$.\nApplying this to our closed-loop system, the stationary variance of $x_t$ under the optimal control policy $\\pi$ is\n$$\n\\operatorname{Var}_{\\pi}(x_t) = \\frac{\\sigma^2}{2(-a_{cl})} = \\frac{\\sigma^2}{2\\left(\\sqrt{a^2 + \\frac{b^2q}{r}}\\right)}.\n$$\n\nFinally, we analyze the dependence of the stationary variance on the diffusion intensity $\\sigma$. The derived formula shows that $\\operatorname{Var}_{\\pi}(x_t)$ is directly proportional to $\\sigma^2$. Qualitatively, $\\sigma$ represents the magnitude of the random noise perturbing the system. An increase in $\\sigma$ implies stronger random forces, pushing the state further from its equilibrium at $x=0$. While the optimal controller continuously acts to regulate the state, larger noise naturally results in larger stationary fluctuations. The variance, being the expected squared deviation from the mean, scales quadratically with the noise amplitude. This is a fundamental characteristic of linear systems driven by white noise.", "answer": "$$\\boxed{\\frac{\\sigma^2}{2\\sqrt{a^2 + \\frac{b^2 q}{r}}}}$$", "id": "3077740"}, {"introduction": "The existence of a unique, stabilizing solution to the Algebraic Riccati Equation is not guaranteed for all systems. This advanced practice delves into the fundamental theoretical conditions of stabilizability and detectability that underpin the LQR framework. By working through a carefully constructed counterexample [@problem_id:3077744], you will see firsthand why a lack of detectability can lead to multiple solutions and how to identify the one that ensures system stability.", "problem": "Consider the infinite-horizon stochastic linear quadratic regulation problem for the Itô stochastic differential equation\n$$\nd x(t) = A x(t)\\, dt + B u(t)\\, dt + D\\, dW_t,\n$$\nwhere $x(t) \\in \\mathbb{R}^{n}$ is the state, $u(t) \\in \\mathbb{R}^{m}$ is the control, $A \\in \\mathbb{R}^{n \\times n}$, $B \\in \\mathbb{R}^{n \\times m}$, $D \\in \\mathbb{R}^{n \\times r}$, and $W_t$ is an $r$-dimensional standard Wiener process. The cost is\n$$\nJ(u) = \\mathbb{E}\\left[ \\int_{0}^{\\infty} x(t)^{\\top} Q\\, x(t) + u(t)^{\\top} R\\, u(t)\\, dt \\right],\n$$\nwith $Q \\in \\mathbb{R}^{n \\times n}$ symmetric positive semidefinite and $R \\in \\mathbb{R}^{m \\times m}$ symmetric positive definite. A pair $(A,B)$ is called stabilizable if all eigenvalues of $A$ with nonnegative real part are controllable via $B$ in the sense of the Hautus test, and a pair $(C,A)$ is called detectable if all eigenvalues of $A$ with nonnegative real part are observable via $C$ in the sense of the Hautus test. The Algebraic Riccati Equation (ARE) is the stationary condition for the quadratic value function arising from Dynamic Programming and the Hamilton-Jacobi-Bellman (HJB) equation.\n\nUsing only these foundational definitions and facts, carry out the following steps:\n\n- Using Dynamic Programming and the Hamilton-Jacobi-Bellman equation, derive the stationary matrix equation that determines the quadratic value function $V(x) = x^{\\top} P x$ for the stochastic linear quadratic regulation problem. Clearly explain how the presence of the diffusion term $D\\, dW_t$ enters the derivation and why it does not change the matrix equation for $P$.\n\n- Consider the specific data $n=2$, $m=1$ with\n$$\nA = \\begin{pmatrix} 1 & 0 \\\\ 0 & -1 \\end{pmatrix}, \\quad B = \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix}, \\quad Q = \\begin{pmatrix} 0 & 0 \\\\ 0 & 1 \\end{pmatrix}, \\quad R = \\begin{pmatrix} 1 \\end{pmatrix},\n$$\nand choose any $D \\in \\mathbb{R}^{2 \\times r}$ with finite $r \\geq 1$. Verify from first principles that $(A,B)$ is stabilizable and $(Q^{1/2},A)$ is not detectable. Your verification must rely on the definitions via the Hautus rank conditions.\n\n- Solve completely the stationary matrix equation for $P \\in \\mathbb{R}^{2 \\times 2}$ with $P = P^{\\top}$ and identify all solutions.\n\n- For the solutions you find, determine the corresponding closed-loop matrix $A_{\\text{cl}} = A - B R^{-1} B^{\\top} P$ and classify its stability by computing its eigenvalues. Explain, in terms of detectability failure, why at least one solution of the matrix equation yields a closed-loop matrix that is not asymptotically stable.\n\nAs your final reported quantity, give the unstable eigenvalue of $A_{\\text{cl}}$ associated with a non-stabilizing solution of the matrix equation. Express your answer exactly; no rounding is required.", "solution": "The analysis of the problem will be conducted in four parts as requested: derivation of the stationary matrix equation via the Hamilton-Jacobi-Bellman (HJB) equation, verification of system properties (stabilizability and detectability), solving the resulting Algebraic Riccati Equation (ARE), and analyzing the stability of the closed-loop systems.\n\nPart 1: Derivation of the Stationary Matrix Equation\n\nThe problem seeks to minimize the cost functional\n$$\nJ(u) = \\mathbb{E}\\left[ \\int_{0}^{\\infty} \\left(x(t)^{\\top} Q\\, x(t) + u(t)^{\\top} R\\, u(t)\\right) dt \\right]\n$$\nfor the system described by the Itô stochastic differential equation (SDE)\n$$\nd x(t) = (A x(t) + B u(t))\\, dt + D\\, dW_t.\n$$\nWe use the method of dynamic programming. Let the value function be $V(x)$, representing the minimum expected cost starting from state $x$. For an infinite-horizon, time-invariant problem, we assume $V$ is independent of time. The HJB equation for this stochastic optimal control problem is\n$$\n\\min_{u \\in \\mathbb{R}^m} \\left\\{ \\mathcal{L}^u V(x) + x^{\\top} Q x + u^{\\top} R u \\right\\} = 0,\n$$\nwhere $\\mathcal{L}^u$ is the infinitesimal generator of the process $x(t)$ under control $u(t)$. For an Itô process $dx = f(x,u)dt + G(x,u)dW_t$, the generator applied to a twice-differentiable function $\\phi(x)$ is\n$$\n\\mathcal{L}^u \\phi(x) = \\nabla \\phi(x)^{\\top} f(x,u) + \\frac{1}{2} \\mathrm{Tr}\\left(G(x,u)^{\\top} (\\nabla^2 \\phi(x)) G(x,u)\\right).\n$$\nIn our case, $f(x,u) = Ax + Bu$ and the diffusion matrix $G(x,u) = D$ is constant. We postulate a quadratic value function $V(x) = x^{\\top} P x$ for some symmetric matrix $P \\in \\mathbb{R}^{n \\times n}$. The gradients of $V(x)$ are $\\nabla V(x) = 2Px$ and the Hessian is $\\nabla^2 V(x) = 2P$.\n\nThe generator term becomes\n$$\n\\mathcal{L}^u V(x) = (2Px)^{\\top} (Ax + Bu) + \\frac{1}{2} \\mathrm{Tr}(D^{\\top} (2P) D) = 2x^{\\top}P(Ax+Bu) + \\mathrm{Tr}(D^{\\top}PD).\n$$\nSubstituting this into the HJB equation, we get\n$$\n\\min_{u \\in \\mathbb{R}^m} \\left\\{ 2x^{\\top}PAx + 2x^{\\top}PBu + \\mathrm{Tr}(D^{\\top}PD) + x^{\\top}Qx + u^{\\top}Ru \\right\\} = 0.\n$$\nThe expression inside the minimization is the Hamiltonian. To find the optimal control $u^*$, we differentiate the Hamiltonian with respect to $u$ and set the result to zero:\n$$\n\\frac{\\partial}{\\partial u} \\left( \\dots \\right) = 2B^{\\top}Px + 2Ru = 0.\n$$\nSince $R$ is positive definite, it is invertible, yielding the optimal feedback control law:\n$$\nu^*(x) = -R^{-1}B^{\\top}Px.\n$$\nNow, we substitute $u^*$ back into the HJB equation:\n$$\n2x^{\\top}PAx + 2x^{\\top}PB(-R^{-1}B^{\\top}Px) + \\mathrm{Tr}(D^{\\top}PD) + x^{\\top}Qx + (-R^{-1}B^{\\top}Px)^{\\top}R(-R^{-1}B^{\\top}Px) = 0.\n$$\nSimplifying the terms involving $u^*$:\n$$\n-2x^{\\top}PBR^{-1}B^{\\top}Px + x^{\\top}PB(R^{-1})^{\\top}RR^{-1}B^{\\top}Px = -2x^{\\top}PBR^{-1}B^{\\top}Px + x^{\\top}PBR^{-1}B^{\\top}Px = -x^{\\top}PBR^{-1}B^{\\top}Px.\n$$\nHere we used that $R$ is symmetric, so $(R^{-1})^{\\top} = R^{-1}$. The HJB equation becomes:\n$$\n2x^{\\top}PAx - x^{\\top}PBR^{-1}B^{\\top}Px + x^{\\top}Qx + \\mathrm{Tr}(D^{\\top}PD) = 0.\n$$\nUsing the identity $2x^{\\top}PAx = x^{\\top}(A^{\\top}P + PA)x$ for symmetric $P$:\n$$\nx^{\\top}(A^{\\top}P + PA - PBR^{-1}B^{\\top}P + Q)x + \\mathrm{Tr}(D^{\\top}PD) = 0.\n$$\nThis equation must hold for all $x \\in \\mathbb{R}^n$. This implies that the quadratic part and the constant part must vanish separately. However, in the context of the long-term average cost, the HJB equation is $\\lambda = \\min_u \\{ \\mathcal{L}^u V(x) + l(x,u) \\}$, where $\\lambda$ is the optimal average cost. This leads to\n$$\nx^{\\top}(A^{\\top}P + PA - PBR^{-1}B^{\\top}P + Q)x + \\mathrm{Tr}(D^{\\top}PD) = \\lambda.\n$$\nFor this to hold for all $x$, the quadratic form must be zero, yielding the stationary Algebraic Riccati Equation (ARE):\n$$\nA^{\\top}P + PA - PBR^{-1}B^{\\top}P + Q = 0.\n$$\nThe optimal average cost is then $\\lambda = \\mathrm{Tr}(D^{\\top}PD)$.\n\nThe diffusion term $D\\,dW_t$ enters the derivation through the Itô calculus term $\\frac{1}{2} \\mathrm{Tr}(D^{\\top} (\\nabla^2 V) D) = \\mathrm{Tr}(D^{\\top}PD)$. Because this term is constant with respect to both the state $x$ and the control $u$, it does not influence the minimization step that determines the optimal control law $u^*(x)$. Consequently, the matrix equation for $P$, derived by requiring the $x$-dependent terms to sum to zero, is identical to the ARE for the deterministic ($D=0$) Linear Quadratic Regulator problem. The stochastic term only affects the total cost, adding a constant offset $\\mathrm{Tr}(D^{\\top}PD)$ to the optimal cost per unit time.\n\nPart 2: Verification of Stabilizability and Detectability\n\nWe are given $A = \\begin{pmatrix} 1 & 0 \\\\ 0 & -1 \\end{pmatrix}$, $B = \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix}$, and $Q = \\begin{pmatrix} 0 & 0 \\\\ 0 & 1 \\end{pmatrix}$. The eigenvalues of $A$ are $\\lambda_1 = 1$ and $\\lambda_2 = -1$.\n\nTo check for stabilizability of the pair $(A,B)$, we apply the Hautus test to the eigenvalue with non-negative real part, which is $\\lambda_1 = 1$. The pair is stabilizable if $\\mathrm{rank}[\\lambda_1 I - A \\mid B] = n = 2$.\n$$\n[\\lambda_1 I - A \\mid B] = \\left[1 \\begin{pmatrix} 1 & 0 \\\\ 0 & 1 \\end{pmatrix} - \\begin{pmatrix} 1 & 0 \\\\ 0 & -1 \\end{pmatrix} \\mid \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix}\\right] = \\left[\\begin{pmatrix} 0 & 0 \\\\ 0 & 2 \\end{pmatrix} \\mid \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix}\\right] = \\begin{pmatrix} 0 & 0 & 1 \\\\ 0 & 2 & 0 \\end{pmatrix}.\n$$\nThe second and third columns are linearly independent, so the rank of this $2 \\times 3$ matrix is $2$. Since the rank equals $n$, the pair $(A,B)$ is stabilizable.\n\nTo check for detectability of the pair $(Q^{1/2}, A)$, we first compute $Q^{1/2}$. Since $Q$ is diagonal and positive semidefinite, its principal square root is $C = Q^{1/2} = \\begin{pmatrix} \\sqrt{0} & 0 \\\\ 0 & \\sqrt{1} \\end{pmatrix} = \\begin{pmatrix} 0 & 0 \\\\ 0 & 1 \\end{pmatrix}$. We apply the Hautus test to the pair $(C,A)$ for the unstable eigenvalue $\\lambda_1=1$. The pair is detectable if $\\mathrm{rank}\\begin{pmatrix} \\lambda_1 I - A \\\\ C \\end{pmatrix} = n = 2$.\n$$\n\\begin{pmatrix} \\lambda_1 I - A \\\\ C \\end{pmatrix} = \\begin{pmatrix} 1 \\begin{pmatrix} 1 & 0 \\\\ 0 & 1 \\end{pmatrix} - \\begin{pmatrix} 1 & 0 \\\\ 0 & -1 \\end{pmatrix} \\\\ \\begin{pmatrix} 0 & 0 \\\\ 0 & 1 \\end{pmatrix} \\end{pmatrix} = \\begin{pmatrix} 0 & 0 \\\\ 0 & 2 \\\\ 0 & 0 \\\\ 0 & 1 \\end{pmatrix}.\n$$\nThe first column of this $4 \\times 2$ matrix is zero. The second column is non-zero. Thus, the column rank is $1$. Since the rank $1 < n=2$, the unstable mode associated with $\\lambda_1=1$ is not observable through $C$. Therefore, the pair $(Q^{1/2}, A)$ is not detectable.\n\nPart 3: Solution of the Algebraic Riccati Equation\n\nThe ARE is $A^{\\top}P + PA - PBR^{-1}B^{\\top}P + Q = 0$.\nWith the given matrices, $R=[1]$ so $R^{-1}=[1]$, and $BR^{-1}B^{\\top} = \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix} [1] \\begin{pmatrix} 1 & 0 \\end{pmatrix} = \\begin{pmatrix} 1 & 0 \\\\ 0 & 0 \\end{pmatrix}$.\nLet $P = \\begin{pmatrix} p_{11} & p_{12} \\\\ p_{12} & p_{22} \\end{pmatrix}$ be a symmetric matrix. We compute the terms:\n$A^{\\top}P + PA = \\begin{pmatrix} 1 & 0 \\\\ 0 & -1 \\end{pmatrix} \\begin{pmatrix} p_{11} & p_{12} \\\\ p_{12} & p_{22} \\end{pmatrix} + \\begin{pmatrix} p_{11} & p_{12} \\\\ p_{12} & p_{22} \\end{pmatrix} \\begin{pmatrix} 1 & 0 \\\\ 0 & -1 \\end{pmatrix} = \\begin{pmatrix} 2p_{11} & 0 \\\\ 0 & -2p_{22} \\end{pmatrix}$.\n$PBR^{-1}B^{\\top}P = \\begin{pmatrix} p_{11} & p_{12} \\\\ p_{12} & p_{22} \\end{pmatrix} \\begin{pmatrix} 1 & 0 \\\\ 0 & 0 \\end{pmatrix} \\begin{pmatrix} p_{11} & p_{12} \\\\ p_{12} & p_{22} \\end{pmatrix} = \\begin{pmatrix} p_{11} & 0 \\\\ p_{12} & 0 \\end{pmatrix} \\begin{pmatrix} p_{11} & p_{12} \\\\ p_{12} & p_{22} \\end{pmatrix} = \\begin{pmatrix} p_{11}^2 & p_{11}p_{12} \\\\ p_{11}p_{12} & p_{12}^2 \\end{pmatrix}$.\nThe ARE becomes:\n$$\n\\begin{pmatrix} 2p_{11} & 0 \\\\ 0 & -2p_{22} \\end{pmatrix} - \\begin{pmatrix} p_{11}^2 & p_{11}p_{12} \\\\ p_{11}p_{12} & p_{12}^2 \\end{pmatrix} + \\begin{pmatrix} 0 & 0 \\\\ 0 & 1 \\end{pmatrix} = \\begin{pmatrix} 0 & 0 \\\\ 0 & 0 \\end{pmatrix}.\n$$\nThis yields a system of scalar equations:\n1. $(1,1)$: $2p_{11} - p_{11}^2 = 0 \\implies p_{11}(2 - p_{11}) = 0$. Thus, $p_{11}=0$ or $p_{11}=2$.\n2. $(1,2)$: $-p_{11}p_{12} = 0$.\n3. $(2,2)$: $-2p_{22} - p_{12}^2 + 1 = 0$.\n\nCase 1: $p_{11} = 2$.\nFrom eq. (2), $-2p_{12} = 0 \\implies p_{12} = 0$.\nFrom eq. (3), $-2p_{22} - 0^2 + 1 = 0 \\implies p_{22} = \\frac{1}{2}$.\nThis gives the solution $P_1 = \\begin{pmatrix} 2 & 0 \\\\ 0 & \\frac{1}{2} \\end{pmatrix}$. This solution is positive definite as its eigenvalues ($2, 1/2$) are positive.\n\nCase 2: $p_{11} = 0$.\nFrom eq. (2), $-0 \\cdot p_{12} = 0$, which is always true.\nFrom eq. (3), $-2p_{22} - p_{12}^2 + 1 = 0 \\implies p_{22} = \\frac{1 - p_{12}^2}{2}$.\nThis gives a family of symmetric solutions $P(p_{12}) = \\begin{pmatrix} 0 & p_{12} \\\\ p_{12} & \\frac{1-p_{12}^2}{2} \\end{pmatrix}$. For the value function to be physically meaningful, $P$ must be positive semidefinite. The determinant of $P(p_{12})$ is $\\det(P) = -p_{12}^2$. For positive semidefiniteness, we require $\\det(P) \\ge 0$, which implies $-p_{12}^2 \\ge 0$, so $p_{12}$ must be $0$.\nIf $p_{12}=0$, then $p_{22} = \\frac{1}{2}$.\nThis gives the solution $P_2 = \\begin{pmatrix} 0 & 0 \\\\ 0 & \\frac{1}{2} \\end{pmatrix}$. This solution is positive semidefinite as its eigenvalues ($0, 1/2$) are non-negative.\n\nThere are two distinct symmetric positive semidefinite solutions to the ARE.\n\nPart 4: Closed-Loop Stability Analysis\n\nThe closed-loop dynamics matrix is $A_{\\text{cl}} = A - BR^{-1}B^{\\top}P$.\n$A_{\\text{cl}} = \\begin{pmatrix} 1 & 0 \\\\ 0 & -1 \\end{pmatrix} - \\begin{pmatrix} 1 & 0 \\\\ 0 & 0 \\end{pmatrix} \\begin{pmatrix} p_{11} & p_{12} \\\\ p_{12} & p_{22} \\end{pmatrix} = \\begin{pmatrix} 1 & 0 \\\\ 0 & -1 \\end{pmatrix} - \\begin{pmatrix} p_{11} & p_{12} \\\\ 0 & 0 \\end{pmatrix} = \\begin{pmatrix} 1-p_{11} & -p_{12} \\\\ 0 & -1 \\end{pmatrix}$.\nThe eigenvalues of this upper-triangular matrix are its diagonal entries: $1-p_{11}$ and $-1$.\n\nFor solution $P_1 = \\begin{pmatrix} 2 & 0 \\\\ 0 & \\frac{1}{2} \\end{pmatrix}$:\n$p_{11}=2$ and $p_{12}=0$. The closed-loop matrix is $A_{\\text{cl},1} = \\begin{pmatrix} 1-2 & 0 \\\\ 0 & -1 \\end{pmatrix} = \\begin{pmatrix} -1 & 0 \\\\ 0 & -1 \\end{pmatrix}$.\nThe eigenvalues are $-1$ and $-1$. Both are strictly in the left half-plane, so the system is asymptotically stable. This is the stabilizing solution.\n\nFor solution $P_2 = \\begin{pmatrix} 0 & 0 \\\\ 0 & \\frac{1}{2} \\end{pmatrix}$:\n$p_{11}=0$ and $p_{12}=0$. The closed-loop matrix is $A_{\\text{cl},2} = \\begin{pmatrix} 1-0 & 0 \\\\ 0 & -1 \\end{pmatrix} = \\begin{pmatrix} 1 & 0 \\\\ 0 & -1 \\end{pmatrix} = A$.\nThe eigenvalues are $1$ and $-1$. One eigenvalue is positive, so the system is unstable.\n\nThe failure of detectability for the pair $(Q^{1/2}, A)$ is the reason for the existence of a non-stabilizing solution. The unstable mode of $A$ (associated with eigenvector $[1 \\ 0]^{\\top}$ and eigenvalue $1$) is not \"seen\" by the state-weighting part of the cost function, since $x^{\\top}Qx = x_2^2$, which is independent of the first state component $x_1$. The control $u$ affects only the dynamics of $x_1$ ($dx_1 = (x_1+u)dt + \\dots$). The optimizer can therefore choose a control law that ignores the unstable $x_1$ dynamics without incurring any state-related cost for its unbounded growth. The solution $P_2$ corresponds to a feedback gain $K = R^{-1}B^{\\top}P_2 = \\begin{pmatrix} 1 & 0 \\end{pmatrix} \\begin{pmatrix} 0 & 0 \\\\ 0 & \\frac{1}{2} \\end{pmatrix} = \\begin{pmatrix} 0 & 0 \\end{pmatrix}$, leading to zero control, $u=0$. The closed-loop system is simply the original open-loop system, which is unstable. This happens because the cost functional provides no incentive to stabilize the unobservable unstable mode. In general, the ARE has a unique positive semidefinite solution that yields a stable closed-loop system if and only if $(A,B)$ is stabilizable and $(Q^{1/2}, A)$ is detectable. Since detectability fails here, multiple positive semidefinite solutions exist, one of which is not stabilizing.\n\nThe unstable eigenvalue of the closed-loop matrix $A_{\\text{cl}}$ associated with the non-stabilizing solution $P_2$ is $1$.", "answer": "$$\\boxed{1}$$", "id": "3077744"}]}