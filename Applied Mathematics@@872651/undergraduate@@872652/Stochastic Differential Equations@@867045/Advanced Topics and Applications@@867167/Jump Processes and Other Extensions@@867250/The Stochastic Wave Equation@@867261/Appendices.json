{"hands_on_practices": [{"introduction": "A powerful technique for analyzing linear partial differential equations on bounded domains is the method of eigenfunction expansion. This practice [@problem_id:3081813] applies this core idea to the stochastic wave equation, breaking it down into an infinite set of simpler stochastic harmonic oscillators, one for each spatial mode. By solving for a single mode and calculating its expected energy using the Itô isometry, you will gain direct insight into how stochastic forcing drives the growth of the solution over time.", "problem": "Consider the stochastic wave equation on the interval $(0,\\pi)$ with homogeneous Dirichlet boundary conditions,\n$$\n\\partial_{tt} u(t,x) \\;=\\; \\partial_{xx} u(t,x) \\;+\\; \\dot{W}(t,x), \\quad (t,x)\\in (0,\\infty)\\times (0,\\pi),\n$$\nwith initial data $u(0,x)=u_0(x)$ and $\\partial_t u(0,x)=v_0(x)$, where $u_0,v_0\\in L^2(0,\\pi)$. The driving term $\\dot{W}$ is a Gaussian, white-in-time, spatially-correlated noise given via the expansion\n$$\n\\dot{W}(t,x)\\;=\\;\\sum_{n=1}^{\\infty} \\sigma_n\\, e_n(x)\\, \\dot{\\beta}_n(t),\n$$\nwhere $(\\beta_n)_{n\\ge 1}$ are independent standard Brownian motions, $(e_n)_{n\\ge 1}$ is the complete orthonormal system of eigenfunctions of the Dirichlet Laplacian on $(0,\\pi)$ given by $e_n(x)=\\sqrt{\\tfrac{2}{\\pi}}\\sin(nx)$ with eigenvalues $n^2$, and $(\\sigma_n)_{n\\ge 1}$ is a sequence of nonnegative coefficients such that $\\sum_{n=1}^{\\infty}\\sigma_n^2\\infty$. For each $n\\ge 1$, define the $n$th Fourier mode by\n$$\nu_n(t)\\;=\\;\\int_{0}^{\\pi} u(t,x)\\,e_n(x)\\,dx,\n$$\nand denote $a_n=\\int_{0}^{\\pi} u_0(x)\\,e_n(x)\\,dx$ and $b_n=\\int_{0}^{\\pi} v_0(x)\\,e_n(x)\\,dx$.\n\nStarting only from the eigenfunction expansion of the Dirichlet Laplacian, the representation of $\\dot{W}$ above, and the Itô isometry for stochastic integrals, derive the explicit expression for the second moment $\\mathbb{E}\\,|u_n(t)|^2$ of the $n$th mode at time $t0$ in terms of $a_n$, $b_n$, $n$, $t$, and $\\sigma_n$. Give your final answer as a single closed-form analytic expression. Do not provide an inequality or an equation to be solved.", "solution": "The problem statement is validated as scientifically grounded, well-posed, objective, self-contained, and consistent. It represents a standard problem in the theory of stochastic partial differential equations. The derivation will proceed as requested.\n\nThe stochastic wave equation is given by\n$$\n\\partial_{tt} u(t,x) = \\partial_{xx} u(t,x) + \\dot{W}(t,x)\n$$\nfor $(t,x)\\in (0,\\infty)\\times (0,\\pi)$, with homogeneous Dirichlet boundary conditions $u(t,0) = u(t,\\pi) = 0$, and initial conditions $u(0,x)=u_0(x)$, $\\partial_t u(0,x)=v_0(x)$.\n\nThe core of the method is to project the equation onto the complete orthonormal system of eigenfunctions $(e_n)_{n\\ge 1}$ of the Dirichlet Laplacian on $(0,\\pi)$. The eigenfunctions are $e_n(x) = \\sqrt{\\frac{2}{\\pi}}\\sin(nx)$, and they satisfy $-\\partial_{xx} e_n(x) = n^2 e_n(x)$.\n\nWe express the solution $u(t,x)$ as a Fourier series with time-dependent coefficients, which are precisely the modes $u_n(t)$:\n$$\nu(t,x) = \\sum_{n=1}^{\\infty} u_n(t) e_n(x), \\quad \\text{where} \\quad u_n(t) = \\int_{0}^{\\pi} u(t,x) e_n(x) dx.\n$$\nThe noise term $\\dot{W}(t,x)$ is already given in this basis:\n$$\n\\dot{W}(t,x) = \\sum_{n=1}^{\\infty} \\sigma_n e_n(x) \\dot{\\beta}_n(t).\n$$\nSubstituting these expansions into the stochastic wave equation, we have:\n$$\n\\sum_{n=1}^{\\infty} \\frac{d^2 u_n}{dt^2}(t) e_n(x) = \\sum_{n=1}^{\\infty} u_n(t) \\partial_{xx} e_n(x) + \\sum_{n=1}^{\\infty} \\sigma_n e_n(x) \\dot{\\beta}_n(t).\n$$\nUsing the eigenfunction property $\\partial_{xx} e_n(x) = -n^2 e_n(x)$, the equation becomes:\n$$\n\\sum_{n=1}^{\\infty} \\ddot{u}_n(t) e_n(x) = \\sum_{n=1}^{\\infty} (-n^2 u_n(t)) e_n(x) + \\sum_{n=1}^{\\infty} \\sigma_n e_n(x) \\dot{\\beta}_n(t).\n$$\nBy the orthogonality of the eigenfunctions $(e_n)_{n\\ge 1}$, we can equate the coefficients for each mode $n \\ge 1$. This decouples the partial differential equation into a system of independent stochastic ordinary differential equations (SODEs):\n$$\n\\ddot{u}_n(t) + n^2 u_n(t) = \\sigma_n \\dot{\\beta}_n(t).\n$$\nThis is the equation for a stochastic harmonic oscillator. The initial conditions for each mode are obtained by projecting the initial data onto the basis:\n$$\nu_n(0) = \\int_{0}^{\\pi} u_0(x) e_n(x) dx = a_n,\n$$\n$$\n\\dot{u}_n(0) = \\int_{0}^{\\pi} v_0(x) e_n(x) dx = b_n.\n$$\nThe solution to this second-order linear SODE can be found using the method of variation of parameters (Duhamel's principle). The solution is the sum of the solution to the homogeneous equation satisfying the initial conditions and a particular solution corresponding to the stochastic forcing. The homogeneous solution is $u_{n,h}(t) = a_n \\cos(nt) + \\frac{b_n}{n}\\sin(nt)$. The stochastic particular solution is given by the stochastic convolution integral:\n$$\nu_n(t) = \\left(a_n \\cos(nt) + \\frac{b_n}{n}\\sin(nt)\\right) + \\frac{\\sigma_n}{n} \\int_{0}^{t} \\sin(n(t-s)) d\\beta_n(s).\n$$\nWe denote the deterministic part as $D_n(t) = a_n \\cos(nt) + \\frac{b_n}{n}\\sin(nt)$ and the stochastic part as $S_n(t) = \\frac{\\sigma_n}{n} \\int_{0}^{t} \\sin(n(t-s)) d\\beta_n(s)$. Thus, $u_n(t) = D_n(t) + S_n(t)$.\n\nWe are asked to compute the second moment $\\mathbb{E}\\,|u_n(t)|^2$. Since all functions and parameters ($u_0, v_0, \\sigma_n, \\beta_n$) are real-valued, the solution mode $u_n(t)$ is also real-valued. Therefore, $|u_n(t)|^2 = u_n(t)^2$.\n$$\n\\mathbb{E}[u_n(t)^2] = \\mathbb{E}[(D_n(t) + S_n(t))^2] = \\mathbb{E}[D_n(t)^2 + 2D_n(t)S_n(t) + S_n(t)^2].\n$$\nBy linearity of expectation,\n$$\n\\mathbb{E}[u_n(t)^2] = \\mathbb{E}[D_n(t)^2] + 2\\mathbb{E}[D_n(t)S_n(t)] + \\mathbb{E}[S_n(t)^2].\n$$\nThe term $D_n(t)$ is deterministic. The expectation of the Itô integral $S_n(t)$ is zero, i.e., $\\mathbb{E}[S_n(t)] = 0$. Consequently, the cross-term vanishes:\n$$\n\\mathbb{E}[D_n(t)S_n(t)] = D_n(t) \\mathbb{E}[S_n(t)] = 0.\n$$\nThis leaves us with:\n$$\n\\mathbb{E}[u_n(t)^2] = D_n(t)^2 + \\mathbb{E}[S_n(t)^2] = \\left(a_n \\cos(nt) + \\frac{b_n}{n}\\sin(nt)\\right)^2 + \\mathbb{E}\\left[ \\left(\\frac{\\sigma_n}{n} \\int_{0}^{t} \\sin(n(t-s)) d\\beta_n(s)\\right)^2 \\right].\n$$\nTo compute the expectation of the squared stochastic integral, we apply the Itô isometry, as stipulated. The Itô isometry states that for a square-integrable deterministic function $f(s)$, $\\mathbb{E}[(\\int_0^t f(s) d\\beta(s))^2] = \\int_0^t f(s)^2 ds$. Applying this to our case:\n$$\n\\mathbb{E}[S_n(t)^2] = \\left(\\frac{\\sigma_n}{n}\\right)^2 \\int_{0}^{t} \\sin^2(n(t-s)) ds.\n$$\nWe now evaluate the integral:\n$$\n\\int_{0}^{t} \\sin^2(n(t-s)) ds = \\int_{0}^{t} \\frac{1 - \\cos(2n(t-s))}{2} ds.\n$$\n$$\n= \\frac{1}{2} \\left[ s - \\frac{-\\sin(2n(t-s))}{2n} \\right]_0^t = \\frac{1}{2} \\left[ \\left(t + \\frac{\\sin(0)}{2n}\\right) - \\left(0 + \\frac{\\sin(2nt)}{2n}\\right) \\right].\n$$\n$$\n= \\frac{1}{2} \\left( t - \\frac{\\sin(2nt)}{2n} \\right) = \\frac{t}{2} - \\frac{\\sin(2nt)}{4n}.\n$$\nSubstituting this back into the expression for $\\mathbb{E}[S_n(t)^2]$:\n$$\n\\mathbb{E}[S_n(t)^2] = \\frac{\\sigma_n^2}{n^2} \\left( \\frac{t}{2} - \\frac{\\sin(2nt)}{4n} \\right).\n$$\nFinally, combining the deterministic and stochastic contributions, we obtain the explicit expression for the second moment of the $n$th mode:\n$$\n\\mathbb{E}\\,|u_n(t)|^2 = \\left( a_n \\cos(nt) + \\frac{b_n}{n} \\sin(nt) \\right)^2 + \\frac{\\sigma_n^2}{n^2} \\left( \\frac{t}{2} - \\frac{\\sin(2nt)}{4n} \\right).\n$$\nThis expression is the final closed-form answer, derived as required from the specified first principles.", "answer": "$$\n\\boxed{\\left( a_n \\cos(nt) + \\frac{b_n}{n} \\sin(nt) \\right)^{2} + \\frac{\\sigma_n^{2}}{n^{2}} \\left( \\frac{t}{2} - \\frac{\\sin(2nt)}{4n} \\right)}\n$$", "id": "3081813"}, {"introduction": "Having examined a single mode, we now broaden our perspective to the behavior of the entire system and contrast it with another fundamental model. This practice [@problem_id:3081826] challenges you to compare the long-term energy evolution of the stochastic wave equation with that of the stochastic heat equation, both driven by the same random noise. This comparative analysis is crucial for understanding the distinct physical behaviors of conservative hyperbolic systems versus dissipative parabolic systems.", "problem": "Consider the bounded domain $D=(0,\\pi)$ with homogeneous Dirichlet boundary conditions. Let $\\{\\varphi_k\\}_{k\\ge 1}$ be the orthonormal eigenfunctions of the Dirichlet Laplacian $-\\Delta$ on $D$ with corresponding eigenvalues $\\{\\lambda_k\\}_{k\\ge 1}$, where $\\lambda_k=k^2$ and $-\\Delta \\varphi_k=\\lambda_k \\varphi_k$. Let $W(t)$ be an additive Gaussian noise modeled as a $Q$-Wiener process on $L^2(D)$, diagonal in the basis $\\{\\varphi_k\\}$ with $Q\\varphi_k=q_k \\varphi_k$, where $q_k\\ge 0$ and $\\sum_{k=1}^\\infty \\dfrac{q_k}{\\lambda_k}\\infty$. Assume identical initial data and noise for the following two equations:\n\n- Stochastic wave equation without damping:\n$$\n\\partial_{tt} u(t,x)=\\Delta u(t,x)+\\dot{W}(t,x),\\quad u(0,x)=0,\\quad \\partial_t u(0,x)=0,\\quad x\\in D,\\ t\\ge 0.\n$$\n\n- Stochastic heat equation:\n$$\n\\mathrm{d}u(t,x)=\\Delta u(t,x)\\,\\mathrm{d}t+\\mathrm{d}W(t,x),\\quad u(0,x)=0,\\quad x\\in D,\\ t\\ge 0.\n$$\n\nUsing fundamental properties of the Laplacian eigenfunction expansion, linearity, and basic Itô calculus (in particular, Itô isometry for stochastic convolutions), determine which statement correctly describes the long-time behavior of the second moment $ \\mathbb{E}\\|u(t)\\|_{L^2(D)}^2$ for the two equations.\n\nChoose exactly one option:\n\nA. For the stochastic wave equation, $\\mathbb{E}\\|u(t)\\|_{L^2(D)}^2$ grows linearly in $t$; for the stochastic heat equation, $\\mathbb{E}\\|u(t)\\|_{L^2(D)}^2$ converges to a finite nonzero limit.\n\nB. For both equations, $\\mathbb{E}\\|u(t)\\|_{L^2(D)}^2$ grows linearly in $t$.\n\nC. For the stochastic wave equation, $\\mathbb{E}\\|u(t)\\|_{L^2(D)}^2$ remains uniformly bounded in $t$; for the stochastic heat equation, $\\mathbb{E}\\|u(t)\\|_{L^2(D)}^2$ grows without bound.\n\nD. For both equations, $\\mathbb{E}\\|u(t)\\|_{L^2(D)}^2$ converges to a finite limit.", "solution": "We work from first principles by projecting each equation onto the eigenbasis $\\{\\varphi_k\\}$ and using Itô calculus for each Fourier mode. Write $u(t,x)=\\sum_{k\\ge 1} x_k(t)\\,\\varphi_k(x)$. The $Q$-Wiener process $W$ admits the expansion $W(t,x)=\\sum_{k\\ge 1} \\sqrt{q_k}\\,\\beta_k(t)\\,\\varphi_k(x)$, where $\\{\\beta_k\\}_{k\\ge 1}$ are independent standard Brownian motions.\n\nStochastic wave equation without damping. The modal coefficients satisfy\n$$\nx_k''(t)+\\lambda_k x_k(t)=\\sqrt{q_k}\\,\\dot{\\beta}_k(t),\\qquad x_k(0)=0,\\quad x_k'(0)=0.\n$$\nThe deterministic homogeneous part is the harmonic oscillator with angular frequency $\\omega_k=\\sqrt{\\lambda_k}$. The variation of constants formula yields\n$$\nx_k(t)=\\frac{\\sqrt{q_k}}{\\omega_k}\\int_0^t \\sin\\big(\\omega_k (t-s)\\big)\\,\\mathrm{d}\\beta_k(s).\n$$\nUsing Itô isometry for stochastic integrals,\n$$\n\\mathbb{E}\\big[x_k(t)^2\\big]=\\frac{q_k}{\\omega_k^2}\\int_0^t \\sin^2\\big(\\omega_k (t-s)\\big)\\,\\mathrm{d}s.\n$$\nBy the change of variables $r=t-s$ and the identity $\\int_0^t \\sin^2(\\omega_k r)\\,\\mathrm{d}r=\\frac{t}{2}-\\frac{\\sin(2\\omega_k t)}{4\\omega_k}$, we get\n$$\n\\mathbb{E}\\big[x_k(t)^2\\big]=\\frac{q_k}{\\lambda_k}\\left(\\frac{t}{2}-\\frac{\\sin(2\\sqrt{\\lambda_k}\\, t)}{4\\sqrt{\\lambda_k}}\\right).\n$$\nTherefore,\n$$\n\\mathbb{E}\\|u(t)\\|_{L^2(D)}^2=\\sum_{k\\ge 1}\\mathbb{E}\\big[x_k(t)^2\\big]\n= \\frac{t}{2}\\sum_{k\\ge 1}\\frac{q_k}{\\lambda_k}\\;+\\;\\sum_{k\\ge 1}\\left(-\\frac{q_k}{\\lambda_k}\\cdot\\frac{\\sin(2\\sqrt{\\lambda_k}\\, t)}{4\\sqrt{\\lambda_k}}\\right).\n$$\nThe second sum is uniformly bounded in $t$ because $\\left|\\sin(2\\sqrt{\\lambda_k}\\, t)\\right|\\le 1$ and $\\sum_{k\\ge 1}\\frac{q_k}{\\lambda_k^{3/2}}\\infty$ follows from $\\sum_{k\\ge 1}\\frac{q_k}{\\lambda_k}\\infty$ and $\\lambda_k\\to\\infty$. Consequently, the dominant term is linear:\n$$\n\\mathbb{E}\\|u(t)\\|_{L^2(D)}^2=\\frac{t}{2}\\sum_{k\\ge 1}\\frac{q_k}{\\lambda_k}+\\mathcal{O}(1)\\quad\\text{as }t\\to\\infty.\n$$\nThus, for the stochastic wave equation without damping, the second moment of the $L^2(D)$-norm grows linearly in $t$.\n\nStochastic heat equation. The modal coefficients satisfy the scalar Ornstein–Uhlenbeck equation\n$$\n\\mathrm{d}x_k(t)=-\\lambda_k x_k(t)\\,\\mathrm{d}t+\\sqrt{q_k}\\,\\mathrm{d}\\beta_k(t),\\qquad x_k(0)=0.\n$$\nThe variation of constants formula gives\n$$\nx_k(t)=\\sqrt{q_k}\\int_0^t e^{-\\lambda_k (t-s)}\\,\\mathrm{d}\\beta_k(s).\n$$\nAgain by Itô isometry,\n$$\n\\mathbb{E}\\big[x_k(t)^2\\big]=q_k\\int_0^t e^{-2\\lambda_k (t-s)}\\,\\mathrm{d}s=\\frac{q_k}{2\\lambda_k}\\big(1-e^{-2\\lambda_k t}\\big).\n$$\nSumming over $k$ and using $\\sum_{k\\ge 1}\\frac{q_k}{\\lambda_k}\\infty$,\n$$\n\\mathbb{E}\\|u(t)\\|_{L^2(D)}^2=\\sum_{k\\ge 1}\\mathbb{E}\\big[x_k(t)^2\\big]=\\sum_{k\\ge 1}\\frac{q_k}{2\\lambda_k}\\big(1-e^{-2\\lambda_k t}\\big)\\xrightarrow[t\\to\\infty]{}\\sum_{k\\ge 1}\\frac{q_k}{2\\lambda_k}.\n$$\nHence the stochastic heat equation admits a finite stationary second moment of the $L^2(D)$-norm.\n\nConclusion and option-by-option analysis.\n\n- Option A: States that for the stochastic wave equation, $\\mathbb{E}\\|u(t)\\|_{L^2(D)}^2$ grows linearly in $t$, which we derived, and that for the stochastic heat equation, it converges to a finite nonzero limit, which we also derived. Verdict: Correct.\n\n- Option B: Claims linear growth in $t$ for both equations. This contradicts the convergence to a finite limit we obtained for the heat equation. Verdict: Incorrect.\n\n- Option C: Claims the wave equation remains uniformly bounded while the heat equation grows without bound. This reverses the actual behaviors and is inconsistent with the calculations. Verdict: Incorrect.\n\n- Option D: Claims convergence to a finite limit for both equations. The wave equation exhibits linear growth and does not converge. Verdict: Incorrect.", "answer": "$$\\boxed{A}$$", "id": "3081826"}, {"introduction": "Beyond quantitative measures like energy, the qualitative properties of solutions offer deep insights into the nature of an equation. This exercise [@problem_id:3081862] explores the failure of the maximum principle for the wave equation, a property that holds for parabolic equations like the heat equation and guarantees the preservation of positivity. By analyzing a specific counterexample, you will see how the oscillatory dynamics inherent in wave propagation can lead to sign changes, a fundamental distinction of hyperbolic systems.", "problem": "Consider the deterministic one-dimensional wave equation on the bounded interval with homogeneous Dirichlet boundary conditions,\n$$\nu_{tt}(x,t)=c^2\\,u_{xx}(x,t),\\quad x\\in(0,\\pi),\\ t0,\\qquad u(0,t)=u(\\pi,t)=0,\n$$\nwith smooth initial data\n$$\nu(x,0)=f(x),\\qquad u_t(x,0)=g(x).\n$$\nIn parabolic problems such as the heat equation, a classical maximum principle asserts that solutions with nonnegative initial and boundary data remain nonnegative. In contrast, hyperbolic dynamics do not generally enjoy such a principle. Your goal is to identify which statements correctly and rigorously justify the failure of a maximum principle for the wave equation by exhibiting sign-changing solutions even when the initial data are nonnegative, and to infer the implication for the stochastic wave equation, which is a stochastic partial differential equation (SPDE).\n\nSelect all statements that are correct.\n\nA. On $(0,\\pi)$ with $u_{tt}=c^2 u_{xx}$, $u(0,t)=u(\\pi,t)=0$, the initial data $f(x)=2\\sin x+\\sin(2x)\\ge 0$ for $x\\in(0,\\pi)$ and $g(x)=0$ produce the solution\n$$\nu(x,t)=2\\cos(ct)\\sin x+\\cos(2ct)\\sin(2x),\n$$\nwhich satisfies $u(\\pi/2,\\pi/c)0$. This explicitly shows that even with nonnegative initial displacement and velocity, the solution can become negative at later times, so a maximum principle fails on bounded domains.\n\nB. On $\\mathbb{R}$ with $u_{tt}=c^2 u_{xx}$, if $g(x)=0$ and $f(x)\\ge 0$ for all $x\\in\\mathbb{R}$, then there exist $t0$ and $x\\in\\mathbb{R}$ such that $u(x,t)0$ due to oscillatory propagation, so the maximum principle also fails on $\\mathbb{R}$ for nonnegative initial data.\n\nC. For the heat equation $v_t=c^2 v_{xx}$ on $(0,\\pi)$ with homogeneous Dirichlet boundary conditions and $v(x,0)\\ge 0$, sign changes can occur at later times, so no maximum principle holds in the parabolic case either.\n\nD. Consider the stochastic wave equation on $(0,\\pi)$ with homogeneous Dirichlet boundary conditions and additive Gaussian space-time white noise $\\dot{W}$,\n$$\nu_{tt}(x,t)=c^2 u_{xx}(x,t)+\\dot{W}(x,t),\\qquad u(x,0)=f(x),\\quad u_t(x,0)=g(x).\n$$\nWith the same deterministic initial data as in statement A, there is no pathwise (sample-wise) maximum principle in general: at a fixed time $t_0=\\pi/c$ and point $x_0=\\pi/2$, the deterministic homogeneous part is strictly negative, and the random forcing cannot almost surely compensate it to make $u(x_0,t_0)\\ge 0$. Hence no almost sure positivity-preserving maximum principle can hold in general for such stochastic wave equations.", "solution": "The problem asks to identify correct statements demonstrating the failure of a maximum principle for the one-dimensional wave equation. A maximum principle, in this context, would imply that for non-negative initial data and boundary conditions, the solution remains non-negative for all time. We will analyze each statement based on the properties of the wave equation.\n\nThe general solution to the homogeneous wave equation $u_{tt} = c^2 u_{xx}$ on the interval $x \\in (0, \\pi)$ with homogeneous Dirichlet boundary conditions $u(0,t) = u(\\pi,t) = 0$ can be found using separation of variables. The solution is expressed as a Fourier sine series:\n$$\nu(x,t) = \\sum_{n=1}^\\infty \\left[ A_n \\cos(nct) + B_n \\sin(nct) \\right] \\sin(nx)\n$$\nThe coefficients $A_n$ and $B_n$ are determined by the initial conditions $u(x,0) = f(x)$ and $u_t(x,0) = g(x)$:\n$$\nf(x) = \\sum_{n=1}^\\infty A_n \\sin(nx) \\implies A_n = \\frac{2}{\\pi} \\int_0^\\pi f(x) \\sin(nx) dx\n$$\n$$\ng(x) = \\sum_{n=1}^\\infty nc B_n \\sin(nx) \\implies nc B_n = \\frac{2}{\\pi} \\int_0^\\pi g(x) \\sin(nx) dx\n$$\n\nNow we evaluate each option.\n\n**A. On $(0,\\pi)$ with $u_{tt}=c^2 u_{xx}$, $u(0,t)=u(\\pi,t)=0$, the initial data $f(x)=2\\sin x+\\sin(2x)\\ge 0$ for $x\\in(0,\\pi)$ and $g(x)=0$ produce the solution $u(x,t)=2\\cos(ct)\\sin x+\\cos(2ct)\\sin(2x)$, which satisfies $u(\\pi/2,\\pi/c)0$. This explicitly shows that even with nonnegative initial displacement and velocity, the solution can become negative at later times, so a maximum principle fails on bounded domains.**\n\nFirst, we verify the non-negativity of the initial data.\nThe initial displacement is $f(x) = 2\\sin x + \\sin(2x)$. Using the identity $\\sin(2x) = 2\\sin x \\cos x$, we have $f(x) = 2\\sin x + 2\\sin x \\cos x = 2\\sin x (1 + \\cos x)$. For $x \\in (0, \\pi)$, we have $\\sin x  0$ and $\\cos x  -1$, which implies $1 + \\cos x  0$. Thus, $f(x)  0$ for all $x \\in (0,\\pi)$. The initial velocity is $g(x) = 0$, which is non-negative. The initial data are therefore non-negative.\n\nSecond, we verify the form of the solution. The initial displacement $f(x) = 2\\sin(x) + \\sin(2x)$ is already given as a finite Fourier sine series. From the general form $f(x) = \\sum A_n \\sin(nx)$, we identify the coefficients $A_1 = 2$, $A_2 = 1$, and $A_n = 0$ for $n \\ge 3$. Since $g(x) = 0$, all coefficients $B_n$ are zero. Substituting these coefficients into the general solution gives:\n$$\nu(x,t) = A_1 \\cos(ct) \\sin(x) + A_2 \\cos(2ct) \\sin(2x) = 2\\cos(ct)\\sin x + \\cos(2ct)\\sin(2x)\n$$\nThis matches the solution provided in the statement.\n\nThird, we check the value of the solution at the specified point $(x,t) = (\\pi/2, \\pi/c)$.\n$$\nu(\\pi/2, \\pi/c) = 2\\cos(c \\cdot \\pi/c) \\sin(\\pi/2) + \\cos(2c \\cdot \\pi/c) \\sin(2 \\cdot \\pi/2)\n$$\n$$\nu(\\pi/2, \\pi/c) = 2\\cos(\\pi) \\sin(\\pi/2) + \\cos(2\\pi) \\sin(\\pi)\n$$\nUsing the values $\\cos(\\pi) = -1$, $\\sin(\\pi/2) = 1$, $\\cos(2\\pi) = 1$, and $\\sin(\\pi) = 0$, we get:\n$$\nu(\\pi/2, \\pi/c) = 2(-1)(1) + (1)(0) = -2\n$$\nSince $u(\\pi/2, \\pi/c) = -2  0$, the solution, which started from non-negative initial data, becomes negative. This is a valid counterexample demonstrating that the wave equation on a bounded domain does not satisfy a maximum principle.\n\nThe statement is entirely correct.\n\n**Verdict: Correct**\n\n**B. On $\\mathbb{R}$ with $u_{tt}=c^2 u_{xx}$, if $g(x)=0$ and $f(x)\\ge 0$ for all $x\\in\\mathbb{R}$, then there exist $t0$ and $x\\in\\mathbb{R}$ such that $u(x,t)0$ due to oscillatory propagation, so the maximum principle also fails on $\\mathbb{R}$ for nonnegative initial data.**\n\nThe solution to the Cauchy problem for the wave equation on the entire real line $\\mathbb{R}$ is given by d'Alembert's formula:\n$$\nu(x,t) = \\frac{1}{2}[f(x-ct) + f(x+ct)] + \\frac{1}{2c} \\int_{x-ct}^{x+ct} g(s) ds\n$$\nThe statement specifies the conditions $g(x) = 0$ for all $x \\in \\mathbb{R}$ and $f(x) \\ge 0$ for all $x \\in \\mathbb{R}$. Under these conditions, the solution simplifies to:\n$$\nu(x,t) = \\frac{1}{2}[f(x-ct) + f(x+ct)]\n$$\nSince $f(y) \\ge 0$ for any argument $y$, both $f(x-ct)$ and $f(x+ct)$ must be non-negative. Their sum, and hence $u(x,t)$, must also be non-negative for all $x \\in \\mathbb{R}$ and $t \\ge 0$. The statement's claim that $u(x,t)  0$ for some $(x,t)$ is false. In this specific case (whole line, zero initial velocity), a positivity-preserving principle does hold. The failure of the maximum principle on a bounded domain arises from reflections at the boundaries, which can cause destructive interference not present in the same way on $\\mathbb{R}$.\n\nThe statement is incorrect.\n\n**Verdict: Incorrect**\n\n**C. For the heat equation $v_t=c^2 v_{xx}$ on $(0,\\pi)$ with homogeneous Dirichlet boundary conditions and $v(x,0)\\ge 0$, sign changes can occur at later times, so no maximum principle holds in the parabolic case either.**\n\nThis statement concerns the parabolic heat equation, $v_t = c^2 v_{xx}$. The Maximum Principle is a cornerstone theorem for parabolic equations. For the given problem setup, $v_t = c^2 v_{xx}$ on $x \\in (0,\\pi)$, with boundary conditions $v(0,t) = v(\\pi,t) = 0$ and initial condition $v(x,0) = f(x) \\ge 0$. The minimum principle (a direct consequence of the maximum principle) states that the minimum value of a solution $v(x,t)$ in the domain $[0,\\pi] \\times [0,T]$ for any $T0$ must be attained either at $t=0$ or on the spatial boundary $x \\in \\{0, \\pi\\}$.\nThe value of $v$ on the spatial boundary is $0$. The value of $v$ at the initial time is $f(x) \\ge 0$. Therefore, the minimum value of $v(x,t)$ for all $t \\ge 0$ must be greater than or equal to $0$. Hence, $v(x,t) \\ge 0$ for all $x \\in [0,\\pi]$ and $t \\ge 0$. No sign changes can occur.\nThis can also be seen through the Green's function representation of the solution, $v(x,t) = \\int_0^\\pi G(x,y,t) f(y) dy$. The Green's function $G(x,y,t)$ for the heat equation with these boundary conditions is strictly positive for $t0$ and $x,y \\in (0,\\pi)$. Since $f(y) \\ge 0$, the integral must be non-negative.\nThe statement claims the opposite, that a maximum principle does not hold. This is fundamentally incorrect.\n\nThe statement is incorrect.\n\n**Verdict: Incorrect**\n\n**D. Consider the stochastic wave equation on $(0,\\pi)$ with homogeneous Dirichlet boundary conditions and additive Gaussian space-time white noise $\\dot{W}$, $u_{tt}(x,t)=c^2 u_{xx}(x,t)+\\dot{W}(x,t)$, with $u(x,0)=f(x), u_t(x,0)=g(x)$. With the same deterministic initial data as in statement A, there is no pathwise (sample-wise) maximum principle in general: at a fixed time $t_0=\\pi/c$ and point $x_0=\\pi/2$, the deterministic homogeneous part is strictly negative, and the random forcing cannot almost surely compensate it to make $u(x_0,t_0)\\ge 0$. Hence no almost sure positivity-preserving maximum principle can hold in general for such stochastic wave equations.**\n\nThe solution to this linear stochastic partial differential equation (SPDE) can be written as the sum of a deterministic part and a stochastic part: $u(x,t) = u_h(x,t) + u_s(x,t)$.\nThe deterministic part, $u_h(x,t)$, solves the homogeneous equation with the given initial data: $u_{h,tt} = c^2 u_{h,xx}$ with $u_h(x,0) = f(x)$ and $u_{h,t}(x,0) = g(x)$.\nThe stochastic part, $u_s(x,t)$, solves the inhomogeneous equation with zero initial data: $u_{s,tt} = c^2 u_{s,xx} + \\dot{W}$ with $u_s(x,0) = 0$ and $u_{s,t}(x,0) = 0$.\n\nThe statement uses the initial data from A, for which $f(x) \\ge 0$ and $g(x) = 0$. A pathwise or almost sure maximum principle would require that for such non-negative initial data, $P( u(x,t) \\ge 0 \\text{ for all } x,t) = 1$. The statement shows this is false.\n\nAt the point $(x_0, t_0) = (\\pi/2, \\pi/c)$, the deterministic part is $u_h(x_0, t_0)$. From our analysis of statement A, we have $u_h(\\pi/2, \\pi/c) = -2$.\nThe total solution at this point is $u(\\pi/2, \\pi/c) = -2 + u_s(\\pi/2, \\pi/c)$.\nThe stochastic part $u_s(x,t)$ is the stochastic convolution of the Green's function with the white noise. For a fixed point $(x_0, t_0)$, $u_s(x_0,t_0)$ is a Gaussian random variable with mean $0$ (since the white noise has mean $0$). Let's call it $Z = u_s(\\pi/2, \\pi/c)$. In one spatial dimension, the variance of $Z$ is finite and positive, so $Z \\sim N(0, \\sigma^2)$ for some $\\sigma^2  0$.\n\nThe solution is non-negative at this point if $u_h + u_s \\ge 0$, which means $-2 + Z \\ge 0$, or $Z \\ge 2$.\nThe statement claims the random forcing \"cannot almost surely compensate\" to make the solution non-negative. This means that the event $Z \\ge 2$ does not happen with probability $1$.\nFor a centered Gaussian random variable $Z$ with positive variance, the probability $P(Z \\ge 2)$ is given by the tail of the normal distribution, which is strictly greater than $0$ but strictly less than $1/2$. In particular, $P(Z \\ge 2)  1$.\nThis means $P(u(\\pi/2, \\pi/c)  0) = P(Z  2)  0$.\nThe fact that there is a positive probability of the solution being negative at a point means that it is not almost surely non-negative everywhere. A single point is sufficient to break the principle. Therefore, an almost sure positivity-preserving maximum principle cannot hold for this SPDE. The reasoning is sound and rigorous.\n\nThe statement is correct.\n\n**Verdict: Correct**", "answer": "$$\\boxed{AD}$$", "id": "3081862"}]}