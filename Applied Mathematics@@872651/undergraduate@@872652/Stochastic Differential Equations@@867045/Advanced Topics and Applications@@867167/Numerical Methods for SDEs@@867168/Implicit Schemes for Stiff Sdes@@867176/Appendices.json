{"hands_on_practices": [{"introduction": "Before we can appreciate the power of implicit schemes, we must first understand the challenges they are designed to overcome. This first practice invites you to analyze the stability of the widely used explicit Euler-Maruyama method when applied to a stiff test equation. By deriving the step-size restriction for mean-square stability, you will see firsthand how stiff drift terms can render explicit methods impractical, thus motivating the need for more robust numerical techniques [@problem_id:3059094].", "problem": "Consider the scalar linear stochastic differential equation (SDE)\n$$\ndX_t = a X_t\\,dt + b X_t\\,dW_t,\n$$\nwhere $a \\in \\mathbb{R}$ and $b \\in \\mathbb{R}$ are constants, and $W_t$ is a standard Wiener process (standard Brownian motion). Assume $a0$ so that the deterministic drift is stabilizing, and the equation can be stiff when $|a|$ is large. Recall that in mean-square analysis, the exact solution is stable when $2a + b^2  0$.\n\nStarting from the definition of the explicit Euler–Maruyama (EM) method with uniform time step $h0$,\n$$\nX_{n+1} = X_n + a X_n h + b X_n \\Delta W_n,\n$$\nwhere $\\Delta W_n := W_{t_{n+1}} - W_{t_n}$ and $t_n := n h$, use the properties of Wiener increments ($\\Delta W_n \\sim \\mathcal{N}(0,h)$ and independent of $X_n$) to derive the mean-square amplification factor $G(h)$ defined by\n$$\nG(h) := \\frac{\\mathbb{E}\\big[|X_{n+1}|^2\\big]}{\\mathbb{E}\\big[|X_n|^2\\big]}.\n$$\nThen, under the assumption $2a + b^2  0$ and $a \\neq 0$, identify the maximal admissible step size $h_{\\max}0$ such that the explicit EM method is mean-square stable, i.e., $G(h)  1$ for all $h \\in (0,h_{\\max})$.\n\nProvide your final result as two closed-form analytic expressions: the amplification factor $G(h)$ and the maximal admissible step size $h_{\\max}$. No rounding is required, and no units are involved. Express both answers in terms of $a$, $b$, and $h$.", "solution": "The problem asks for the derivation of the mean-square amplification factor $G(h)$ for the explicit Euler-Maruyama (EM) method applied to a scalar linear SDE, and for the subsequent determination of the maximal time step $h_{\\max}$ that ensures mean-square stability.\n\nThe scalar linear SDE is given by:\n$$\ndX_t = a X_t\\,dt + b X_t\\,dW_t\n$$\nwhere $a, b \\in \\mathbb{R}$ are constants, $a0$, $a\\neq 0$, and $W_t$ is a standard Wiener process. The condition for mean-square stability of the exact solution is $2a + b^2  0$.\n\nThe explicit Euler-Maruyama (EM) method provides a discrete-time approximation $X_n \\approx X_{t_n}$ with a uniform time step $h  0$. The scheme is:\n$$\nX_{n+1} = X_n + a X_n h + b X_n \\Delta W_n\n$$\nwhere $\\Delta W_n = W_{t_{n+1}} - W_{t_n}$. The increments $\\Delta W_n$ are independent and identically distributed normal random variables with mean $\\mathbb{E}[\\Delta W_n] = 0$ and variance $\\mathbb{E}[(\\Delta W_n)^2] = h$. Also, $\\Delta W_n$ is independent of the information available at time $t_n$, represented by the $\\sigma$-algebra $\\mathcal{F}_{t_n}$, which includes $X_n$.\n\nFirst, we derive the mean-square amplification factor $G(h) := \\frac{\\mathbb{E}\\big[|X_{n+1}|^2\\big]}{\\mathbb{E}\\big[|X_n|^2\\big]}$. Since $X_t$ is a real-valued scalar process, $|X_t|^2 = X_t^2$.\nWe start by factoring $X_n$ from the EM scheme:\n$$\nX_{n+1} = X_n (1 + ah + b \\Delta W_n)\n$$\nSquaring both sides gives:\n$$\nX_{n+1}^2 = X_n^2 (1 + ah + b \\Delta W_n)^2\n$$\nNow, we take the expectation of both sides. Using the law of total expectation (tower property), we condition on $\\mathcal{F}_{t_n}$:\n$$\n\\mathbb{E}[X_{n+1}^2] = \\mathbb{E}\\left[\\mathbb{E}\\left[X_n^2 (1 + ah + b \\Delta W_n)^2 \\mid \\mathcal{F}_{t_n}\\right]\\right]\n$$\nSince $X_n$ is $\\mathcal{F}_{t_n}$-measurable, we can take it out of the inner conditional expectation:\n$$\n\\mathbb{E}[X_{n+1}^2] = \\mathbb{E}\\left[X_n^2 \\mathbb{E}\\left[(1 + ah + b \\Delta W_n)^2 \\mid \\mathcal{F}_{t_n}\\right]\\right]\n$$\nBecause $\\Delta W_n$ is independent of $\\mathcal{F}_{t_n}$, the conditional expectation becomes an unconditional expectation with respect to the distribution of $\\Delta W_n$:\n$$\n\\mathbb{E}\\left[(1 + ah + b \\Delta W_n)^2 \\mid \\mathcal{F}_{t_n}\\right] = \\mathbb{E}\\left[(1 + ah + b \\Delta W_n)^2\\right]\n$$\nLet's expand the squared term and compute this expectation:\n\\begin{align*} \\mathbb{E}\\left[(1 + ah + b \\Delta W_n)^2\\right] = \\mathbb{E}\\left[(1 + ah)^2 + 2b(1+ah)\\Delta W_n + b^2(\\Delta W_n)^2\\right] \\\\ = (1+ah)^2 + 2b(1+ah)\\mathbb{E}[\\Delta W_n] + b^2\\mathbb{E}[(\\Delta W_n)^2] \\end{align*}\nUsing the properties $\\mathbb{E}[\\Delta W_n] = 0$ and $\\mathbb{E}[(\\Delta W_n)^2] = h$, we get:\n$$\n\\mathbb{E}\\left[(1 + ah + b \\Delta W_n)^2\\right] = (1+ah)^2 + b^2h = 1 + 2ah + a^2h^2 + b^2h\n$$\nSubstituting this back into the expression for $\\mathbb{E}[X_{n+1}^2]$:\n$$\n\\mathbb{E}[X_{n+1}^2] = \\mathbb{E}\\left[X_n^2 (1 + 2ah + a^2h^2 + b^2h)\\right] = \\mathbb{E}[X_n^2] (1 + 2ah + a^2h^2 + b^2h)\n$$\nThe mean-square amplification factor $G(h)$ is the ratio of these expectations:\n$$\nG(h) = \\frac{\\mathbb{E}[X_{n+1}^2]}{\\mathbb{E}[X_n^2]} = 1 + 2ah + b^2h + a^2h^2\n$$\nArranging this as a polynomial in $h$, we get the first part of the answer:\n$$\nG(h) = a^2 h^2 + (2a + b^2)h + 1\n$$\nNext, we find the maximal admissible step size $h_{\\max}$ for mean-square stability. The condition for stability is $G(h)  1$.\n$$\na^2 h^2 + (2a + b^2)h + 1  1\n$$\nSubtracting $1$ from both sides yields:\n$$\na^2 h^2 + (2a + b^2)h  0\n$$\nWe can factor out $h$:\n$$\nh (a^2 h + (2a + b^2))  0\n$$\nSince the time step $h$ must be positive ($h0$), for the product to be negative, the second factor must be negative:\n$$\na^2 h + (2a + b^2)  0\n$$\nNow, we solve for $h$:\n$$\na^2 h  -(2a + b^2)\n$$\nThe problem states $a \\neq 0$, which implies $a^2  0$. We can divide by $a^2$ without changing the direction of the inequality:\n$$\nh  \\frac{-(2a + b^2)}{a^2}\n$$\nCombining this with the requirement that $h  0$, the EM method is mean-square stable for all $h$ in the interval:\n$$\n0  h  \\frac{-(2a + b^2)}{a^2}\n$$\nThe problem states that the exact solution is stable when $2a + b^2  0$. This condition ensures that the upper bound of the interval is positive, so a region of stability for the numerical method exists. The maximal admissible step size $h_{\\max}$ is the supremum of this interval.\n$$\nh_{\\max} = \\frac{-(2a + b^2)}{a^2}\n$$\nThis is the second part of the answer. We present the two results, $G(h)$ and $h_{\\max}$, as a row matrix.", "answer": "$$\n\\boxed{\\begin{pmatrix} a^{2}h^{2} + (2a+b^{2})h + 1  \\frac{-(2a+b^{2})}{a^{2}} \\end{pmatrix}}\n$$", "id": "3059094"}, {"introduction": "Having established the stability limitations of explicit methods, we now turn to a powerful alternative. This exercise tasks you with analyzing a drift-implicit Euler-Maruyama scheme applied to the very same stiff SDE from the previous practice. Deriving the mean-square amplification factor for this new scheme will demonstrate how treating the stiff drift term implicitly can remove the severe step-size restriction, leading to the desirable property of unconditional stability under certain conditions [@problem_id:3059170].", "problem": "Consider the scalar linear Stochastic Differential Equation (SDE), defined as $dX(t) = a\\,X(t)\\,dt + b\\,X(t)\\,dW(t)$, where $a \\in \\mathbb{R}$ and $b \\in \\mathbb{R}$ are constants, and $W(t)$ is a standard Wiener process (also called Brownian motion). Let $\\{t_n\\}_{n \\ge 0}$ be a uniform time grid with $t_{n+1} - t_n = h  0$, and let $\\Delta W_n := W(t_{n+1}) - W(t_n)$ denote the independent Wiener increments with $\\Delta W_n \\sim \\mathcal{N}(0,h)$.\n\nFormulate the drift-implicit Euler–Maruyama time-stepping scheme that treats the drift term implicitly and the diffusion term explicitly for this SDE, and from first principles derive the one-step random amplification factor $G_n$ such that $X_{n+1} = G_n\\,X_n$. Then compute the mean-square amplification factor $\\rho(h)$, defined by the relation $\\mathbb{E}\\!\\left[|X_{n+1}|^{2}\\right] = \\rho(h)\\,\\mathbb{E}\\!\\left[|X_n|^{2}\\right]$, in closed form as a function of $a$, $b$, and $h$.\n\nFinally, using only fundamental properties of Wiener increments and conditional expectation, prove that when $a  0$ there exists a threshold on $b$ such that the drift-implicit Euler–Maruyama scheme is mean-square stable for all step sizes $h  0$, in the sense that $\\rho(h)  1$ for every $h  0$. Identify this threshold explicitly in terms of $a$.\n\nReport the mean-square amplification factor $\\rho(h)$ as your final answer in a single closed-form analytic expression. No rounding is required.", "solution": "The problem statement presents a valid and well-posed question within the field of numerical analysis for stochastic differential equations. All provided information is self-contained, consistent, and scientifically grounded. We may therefore proceed with the solution.\n\nThe scalar linear Stochastic Differential Equation (SDE) is given by:\n$$ dX(t) = a\\,X(t)\\,dt + b\\,X(t)\\,dW(t) $$\nwhere $a, b \\in \\mathbb{R}$ are constants and $W(t)$ is a standard Wiener process. We discretize this SDE on a uniform time grid $\\{t_n\\}_{n \\ge 0}$ with a constant step size $h = t_{n+1} - t_n  0$. Let $X_n$ denote the numerical approximation of $X(t_n)$, and $\\Delta W_n = W(t_{n+1}) - W(t_n)$ be the Wiener increment, which is a random variable with distribution $\\mathcal{N}(0,h)$.\n\nFirst, we formulate the drift-implicit Euler–Maruyama scheme. This scheme treats the drift term, $a\\,X(t)\\,dt$, implicitly (evaluated at time $t_{n+1}$) and the diffusion term, $b\\,X(t)\\,dW(t)$, explicitly (evaluated at time $t_n$). The resulting difference equation is:\n$$ X_{n+1} - X_n = a\\,X_{n+1}\\,h + b\\,X_n\\,\\Delta W_n $$\nTo find the one-step random amplification factor $G_n$ such that $X_{n+1} = G_n X_n$, we rearrange the equation to solve for $X_{n+1}$:\n$$ X_{n+1} - a\\,h\\,X_{n+1} = X_n + b\\,X_n\\,\\Delta W_n $$\n$$ X_{n+1}(1 - a\\,h) = X_n(1 + b\\,\\Delta W_n) $$\nAssuming $1 - a\\,h \\neq 0$, we can write:\n$$ X_{n+1} = \\left( \\frac{1 + b\\,\\Delta W_n}{1 - a\\,h} \\right) X_n $$\nThus, the one-step random amplification factor is $G_n = \\frac{1 + b\\,\\Delta W_n}{1 - a\\,h}$. The case $a0$ and $h0$ ensures $1-ah1$, so the denominator is non-zero.\n\nNext, we compute the mean-square amplification factor $\\rho(h)$, defined by the relation $\\mathbb{E}[|X_{n+1}|^2] = \\rho(h)\\,\\mathbb{E}[|X_n|^2]$. Starting from the expression for $X_{n+1}$:\n$$ |X_{n+1}|^2 = \\left| \\left( \\frac{1 + b\\,\\Delta W_n}{1 - a\\,h} \\right) X_n \\right|^2 = \\frac{|1 + b\\,\\Delta W_n|^2}{(1 - a\\,h)^2} |X_n|^2 $$\nWe take the expectation of both sides. Using the law of total expectation with the filtration $\\mathcal{F}_{t_n}$ (the information available up to time $t_n$), we have:\n$$ \\mathbb{E}[|X_{n+1}|^2] = \\mathbb{E}\\left[ \\mathbb{E}\\left[ \\frac{|1 + b\\,\\Delta W_n|^2}{(1 - a\\,h)^2} |X_n|^2 \\bigg| \\mathcal{F}_{t_n} \\right] \\right] $$\nSince $X_n$ is $\\mathcal{F}_{t_n}$-measurable, $|X_n|^2$ and the deterministic constant $(1-ah)^2$ can be factored out of the inner conditional expectation:\n$$ \\mathbb{E}[|X_{n+1}|^2] = \\mathbb{E}\\left[ \\frac{|X_n|^2}{(1 - a\\,h)^2} \\mathbb{E}\\left[ |1 + b\\,\\Delta W_n|^2 \\bigg| \\mathcal{F}_{t_n} \\right] \\right] $$\nThe Wiener increment $\\Delta W_n$ is independent of the past filtration $\\mathcal{F}_{t_n}$. Therefore, any function of $\\Delta W_n$ is also independent of $\\mathcal{F}_{t_n}$, and its conditional expectation is equal to its unconditional expectation:\n$$ \\mathbb{E}\\left[ |1 + b\\,\\Delta W_n|^2 \\bigg| \\mathcal{F}_{t_n} \\right] = \\mathbb{E}[|1 + b\\,\\Delta W_n|^2] $$\nSubstituting this back and pulling the resulting deterministic term out of the outer expectation gives:\n$$ \\mathbb{E}[|X_{n+1}|^2] = \\frac{\\mathbb{E}[|1 + b\\,\\Delta W_n|^2]}{(1 - a\\,h)^2} \\mathbb{E}[|X_n|^2] $$\nComparing this to the definition of $\\rho(h)$, we find:\n$$ \\rho(h) = \\frac{\\mathbb{E}[|1 + b\\,\\Delta W_n|^2]}{(1 - a\\,h)^2} $$\nWe now compute the expectation in the numerator. We know $\\Delta W_n \\sim \\mathcal{N}(0,h)$, so its moments are $\\mathbb{E}[\\Delta W_n] = 0$ and $\\mathbb{E}[(\\Delta W_n)^2] = \\text{Var}(\\Delta W_n) + (\\mathbb{E}[\\Delta W_n])^2 = h + 0 = h$. Expanding the term and using linearity of expectation:\n$$ \\mathbb{E}[|1 + b\\,\\Delta W_n|^2] = \\mathbb{E}[1 + 2b\\,\\Delta W_n + b^2(\\Delta W_n)^2] = 1 + 2b\\,\\mathbb{E}[\\Delta W_n] + b^2\\,\\mathbb{E}[(\\Delta W_n)^2] $$\n$$ \\mathbb{E}[|1 + b\\,\\Delta W_n|^2] = 1 + 2b(0) + b^2(h) = 1 + b^2h $$\nSubstituting this result into the expression for $\\rho(h)$ yields the final closed form:\n$$ \\rho(h) = \\frac{1 + b^2h}{(1 - a\\,h)^2} $$\n\nFinally, we find the condition on $b$ for mean-square stability when $a  0$. The scheme is mean-square stable if $\\rho(h)  1$ for all step sizes $h  0$.\n$$ \\frac{1 + b^2h}{(1 - a\\,h)^2}  1 $$\nSince $a  0$ and $h  0$, we have $a\\,h  0$, which implies $1 - a\\,h  1$. Thus, the denominator $(1 - a\\,h)^2$ is always positive, and we can multiply both sides by it:\n$$ 1 + b^2h  (1 - a\\,h)^2 $$\n$$ 1 + b^2h  1 - 2ah + a^2h^2 $$\nSubtracting $1$ from both sides gives:\n$$ b^2h  -2ah + a^2h^2 $$\nSince $h  0$, we can divide by $h$:\n$$ b^2  -2a + a^2h $$\nThis inequality must hold for all $h  0$. The right-hand side, $f(h) = -2a + a^2h$, is a linear function of $h$. Since $a0$, $a^20$, so $f(h)$ is strictly increasing for $h0$. For the inequality $b^2  f(h)$ to hold for all $h0$, $b^2$ must be less than or equal to the infimum of $f(h)$ over the domain $h \\in (0, \\infty)$.\nThe infimum is approached as $h \\to 0^+$:\n$$ \\inf_{h0} f(h) = \\lim_{h \\to 0^+} (-2a + a^2h) = -2a $$\nTherefore, the condition for stability for all $h  0$ is $b^2 \\le -2a$. Let's check the strict inequality. We need $b^2  -2a+a^2h$ for all $h0$. This is equivalent to $b^2 - (-2a)  a^2h$ for all $h0$.\nLet $C = b^2+2a$. The condition is $C  a^2h$ for all $h0$. Since $a^2h$ can be arbitrarily close to $0$ (for small $h$), this condition can only be satisfied if $C \\le 0$. If $C=0$, we have $0  a^2h$, which is true for all $h0$ (since $a0 \\implies a\\neq 0$). If $C0$, we have a negative number less than a positive one, which is also true. Thus, the condition is $C \\le 0$.\n$$ b^2 + 2a \\le 0 \\implies b^2 \\le -2a $$\nThis confirms that for $a0$, the scheme is mean-square stable for all $h  0$ if and only if $b^2 \\le -2a$. This is the explicit threshold on $b$ in terms of $a$.", "answer": "$$\\boxed{\\frac{1 + b^2 h}{(1 - a h)^2}}$$", "id": "3059170"}, {"introduction": "Our theoretical analysis has shown the stability benefits of implicit schemes for linear SDEs, but real-world applications are often nonlinear. This brings new practical challenges, as each step now requires solving a nonlinear algebraic equation. This exercise guides you through the crucial implementation details and computational trade-offs, from selecting an appropriate nonlinear solver like Newton's method to managing its cost and balancing solver accuracy with the overall discretization error [@problem_id:3059087].", "problem": "Consider a stochastic differential equation (SDE) in $\\mathbb{R}^{d}$ of the form\n$$\n\\mathrm{d}X_{t} = f(X_{t})\\,\\mathrm{d}t + G(X_{t})\\,\\mathrm{d}W_{t},\n$$\nwhere $f:\\mathbb{R}^{d}\\to\\mathbb{R}^{d}$ is a drift field, $G:\\mathbb{R}^{d}\\to\\mathbb{R}^{d\\times m}$ is a diffusion coefficient, and $W_{t}$ is an $m$-dimensional Wiener process (also called standard Brownian motion). Assume $f$ is sufficiently smooth, globally Lipschitz, and exhibits stiffness in the sense that the Jacobian $J_{f}(x)$ has eigenvalues with large negative real parts near a stable equilibrium, and that $G$ is bounded and sufficiently smooth.\n\nA widely used time discretization for stiff problems is the drift-implicit Euler–Maruyama scheme with explicit diffusion:\n$$\nX_{n+1} = X_{n} + h\\, f(X_{n+1}) + G(X_{n})\\,\\Delta W_{n},\n$$\nwhere $h0$ is the time step and $\\Delta W_{n} \\sim \\mathcal{N}(0, h I_{m})$ are independent Gaussian increments. Implementation requires solving, at each time step, the nonlinear system for $X_{n+1}$ obtained by setting the residual\n$$\nR(y) := y - X_{n} - h\\, f(y) - G(X_{n})\\,\\Delta W_{n}\n$$\nto zero. A common choice is Newton’s method applied to $R(y) = 0$, whose iteration uses the Jacobian\n$$\nJ(y) := \\frac{\\partial R}{\\partial y}(y) = I_{d} - h\\, J_{f}(y),\n$$\nwhile fixed-point (Picard) iteration uses the map $T(y) := X_{n} + h\\, f(y) + G(X_{n})\\,\\Delta W_{n}$.\n\nAnswer the following multiple-choice question by selecting all statements that are correct. Your reasoning should be based on the core definitions above together with standard facts about Newton’s method, fixed-point iteration, and computational complexity of dense linear algebra.\n\nWhich of the following statements about implementing the drift-implicit Euler–Maruyama scheme for stiff SDEs are correct?\n\nA. When $G$ is treated explicitly as above, the Newton Jacobian $J(y) = I_{d} - h\\,J_{f}(y)$ does not depend on the Wiener increment $\\Delta W_{n}$. Reusing a Jacobian across inner Newton iterations within a single time step can be effective when $J_{f}(y)$ varies slowly near the solution, because the principal variation comes from $J_{f}$, not from $\\Delta W_{n}$.\n\nB. The fixed-point iteration $y^{(k+1)} = X_{n} + h\\, f\\!\\left(y^{(k)}\\right) + G(X_{n})\\,\\Delta W_{n}$ always converges for stiff drifts, regardless of the step size $h$, because the implicitness stabilizes the iteration.\n\nC. In dimension $d$ with dense Jacobians, forming and factorizing the Newton Jacobian $J(y)$ at each iteration has computational cost that scales on the order of $O(d^{3})$. Quasi-Newton methods that update an approximate inverse or factorization (such as a Broyden-type method) can reduce the per-iteration cost but may sacrifice some global convergence robustness.\n\nD. If the diffusion $G(x)$ is state-dependent but treated explicitly in the scheme $X_{n+1} = X_{n} + h f(X_{n+1}) + G(X_{n})\\,\\Delta W_{n}$, then the Newton linearization must include $\\frac{\\partial}{\\partial y}\\big(G(y)\\,\\Delta W_{n}\\big)$ to retain first-order strong accuracy; otherwise, the method’s strong order drops.\n\nE. For the scalar stiff linear SDE $\\mathrm{d}X_{t} = -\\lambda X_{t}\\,\\mathrm{d}t + \\sigma\\,\\mathrm{d}W_{t}$ with $\\lambda0$ and $\\sigma0$, the drift-implicit update is\n$$\nX_{n+1} = \\frac{X_{n} + \\sigma\\,\\Delta W_{n}}{1 + h\\,\\lambda},\n$$\nwhich requires no nonlinear solve. This update is unconditionally stable with respect to the drift in the sense that the deterministic amplification factor $1/(1 + h\\,\\lambda)$ lies strictly inside the unit disk for all $h0$.\n\nF. Choosing nonlinear solver tolerances (for Newton or fixed-point inner solves) much tighter than the strong discretization error of the overall method (which is $O(h^{1/2})$ for Euler–Maruyama under standard assumptions) typically yields negligible improvement in the pathwise accuracy while increasing computational cost per step.\n\nSelect all correct options.", "solution": "The problem statement is a valid exercise in the analysis of numerical methods for stiff stochastic differential equations. It is scientifically grounded, well-posed, and objective. All provided definitions are standard in the field.\n\nWe will now evaluate each statement.\n\n**Statement A: Correct**\nThe residual function for the nonlinear system is given by\n$$\nR(y) := y - X_{n} - h\\, f(y) - G(X_{n})\\,\\Delta W_{n}.\n$$\nThe Newton iteration for solving $R(y)=0$ involves the Jacobian of $R$ with respect to $y$. We compute this Jacobian:\n$$\nJ(y) = \\frac{\\partial R}{\\partial y}(y) = \\frac{\\partial}{\\partial y} \\left( y - X_{n} - h\\, f(y) - G(X_{n})\\,\\Delta W_{n} \\right).\n$$\nIn this context, $X_{n}$ and $\\Delta W_{n}$ are fixed values from the previous step and the current Wiener increment, respectively. The diffusion term $G(X_n)$ is evaluated at $X_n$ and is therefore constant with respect to the solver variable $y$. The derivatives of the terms are:\n- $\\frac{\\partial}{\\partial y} y = I_{d}$ (the $d \\times d$ identity matrix)\n- $\\frac{\\partial}{\\partial y} (-X_{n}) = 0$\n- $\\frac{\\partial}{\\partial y} (-h\\,f(y)) = -h\\, J_{f}(y)$, where $J_{f}(y)$ is the Jacobian of $f$.\n- $\\frac{\\partial}{\\partial y} (-G(X_{n})\\,\\Delta W_{n}) = 0$\n\nCombining these gives the Newton Jacobian:\n$$\nJ(y) = I_{d} - h\\, J_{f}(y).\n$$\nThis expression clearly does not depend on the Wiener increment $\\Delta W_{n}$. The variation in $J(y)$ during the Newton solve for a fixed time step $n$ comes only from the change in $y$ as it iterates towards $X_{n+1}$, which in turn affects $J_{f}(y)$. If $J_{f}(y)$ varies slowly with $y$, then $J(y)$ also varies slowly. In such cases, reusing the Jacobian computed at the start of the Newton solve (a \"frozen\" or \"sham\" Newton method) is a standard and effective technique to reduce computational cost, as the dominant cost is often the factorization of this matrix. The reasoning provided in the statement is entirely correct. Thus, this statement is **Correct**.\n\n**Statement B: Incorrect**\nThe fixed-point iteration is given by $y^{(k+1)} = T(y^{(k)})$, where the map is\n$$\nT(y) := X_{n} + h\\, f(y) + G(X_{n})\\,\\Delta W_{n}.\n$$\nAccording to the Banach fixed-point theorem, a sufficient condition for the convergence of this iteration from any starting point in a neighborhood is that the map $T$ is a contraction in that neighborhood. The contraction property is assessed by the Jacobian of $T$ with respect to $y$:\n$$\nJ_{T}(y) = \\frac{\\partial T}{\\partial y} = h\\, J_{f}(y).\n$$\nFor convergence, we require that an induced matrix norm of $J_{T}(y)$ is less than $1$, i.e., $\\|h\\, J_{f}(y)\\|  1$. This is related to the spectral radius condition $\\rho(h\\, J_{f}(y))  1$.\nThe problem states the drift is stiff, meaning the Jacobian $J_{f}(y)$ has eigenvalues $\\mu_{i}$ with large negative real parts. The eigenvalues of $J_{T}(y)$ are $h\\mu_{i}$. The condition for convergence becomes $|h\\mu_{i}|  1$ for all $i$. If there is a stiff eigenvalue with $|\\mu_{i}| = L \\gg 1$, then convergence requires $hL  1$, or $h  1/L$. This imposes a severe restriction on the step size $h$, which is precisely the type of restriction that implicit methods are designed to overcome for stability purposes.\nThe statement claims the iteration *always converges* regardless of $h$. This is false. While the underlying drift-implicit scheme is valuable for its stability properties on stiff problems, solving the resulting nonlinear equation with a simple fixed-point iteration re-introduces a stiffness-related constraint on $h$ for the *solver's* convergence. Thus, this statement is **Incorrect**.\n\n**Statement C: Correct**\nThe Newton iteration at step $k$ requires solving the linear system $J(y^{(k)}) \\delta y^{(k)} = -R(y^{(k)})$.\n1.  **Forming and factorizing the Jacobian:** For a general dense drift Jacobian $J_{f}(y)$, forming the $d \\times d$ matrix $J(y) = I_d - h J_f(y)$ costs $O(d^2)$. The main computational burden is solving the linear system. Using a direct solver like Gaussian elimination to compute an LU factorization of the dense $d \\times d$ matrix $J(y)$ has a computational cost of $O(d^3)$. Therefore, the per-iteration cost is dominated by this factorization and scales as $O(d^3)$.\n2.  **Quasi-Newton methods:** Methods like Broyden's method are designed to reduce this cost. Instead of recomputing and re-factorizing the Jacobian at every step, they maintain an approximation to the Jacobian (or its inverse) and update it at a lower cost. For example, a rank-$1$ update to an approximate inverse matrix can be performed in $O(d^2)$ operations. This reduces the per-iteration cost from $O(d^3)$ to $O(d^2)$.\n3.  **Trade-offs:** The benefit of reduced cost comes at the expense of the convergence rate, which is typically superlinear for quasi-Newton methods, compared to quadratic for Newton's method (near the solution). This can mean more iterations are needed. Furthermore, because an approximate Jacobian is used, the search directions may be less accurate, potentially making the method less robust and more prone to failure, especially when far from the solution (affecting global convergence).\nThe statement accurately describes both the cost scaling and the trade-offs involved. Thus, this statement is **Correct**.\n\n**Statement D: Incorrect**\nThe scheme is explicitly defined as $X_{n+1} = X_{n} + h f(X_{n+1}) + G(X_{n})\\,\\Delta W_{n}$. The order of accuracy is a property of this discretization formula itself, not the method used to solve the algebraic equation for $X_{n+1}$. Under standard assumptions (Lipschitz conditions on $f$ and $G$, etc.), the Euler-Maruyama scheme (both explicit and drift-implicit versions) has a strong order of convergence of $1/2$, meaning the expected pathwise error at a fixed time $T$ behaves as $E[|X_T - X(T)|] = O(h^{1/2})$. The scheme as stated does not have strong order $1$. To achieve strong order $1$, a higher-order scheme like the Milstein scheme is required, which includes correction terms involving derivatives of the diffusion coefficient $G$. The statement incorrectly suggests that this scheme can have strong order $1$ and that the method for solving the nonlinear equation affects the scheme's order. The \"Newton linearization\" is a tool to find $X_{n+1}$ satisfying the given equation; it cannot change the equation or its inherent accuracy properties. The statement is fundamentally confused. Thus, this statement is **Incorrect**.\n\n**Statement E: Correct**\nThe SDE is the scalar Ornstein-Uhlenbeck process: $\\mathrm{d}X_{t} = -\\lambda X_{t}\\,\\mathrm{d}t + \\sigma\\,\\mathrm{d}W_{t}$. Here, $f(x) = -\\lambda x$ and $G(x) = \\sigma$.\nThe drift-implicit Euler-Maruyama scheme is $X_{n+1} = X_n + h f(X_{n+1}) + G(X_n) \\Delta W_n$.\nSubstituting the specific forms of $f$ and $G$:\n$$\nX_{n+1} = X_{n} + h(-\\lambda X_{n+1}) + \\sigma \\Delta W_{n}.\n$$\nThis is a linear equation in $X_{n+1}$. We can solve for it algebraically:\n$$\nX_{n+1} + h\\lambda X_{n+1} = X_{n} + \\sigma\\Delta W_{n}\n$$\n$$\n(1 + h\\lambda)X_{n+1} = X_{n} + \\sigma\\Delta W_{n}\n$$\n$$\nX_{n+1} = \\frac{X_{n} + \\sigma\\Delta W_{n}}{1 + h\\lambda}.\n$$\nThis matches the formula in the statement and, being an explicit formula, requires no iterative nonlinear solve.\nFor stability analysis, we consider the deterministic part of the recursion (i.e., set $\\sigma=0$ or $\\Delta W_n = 0$), which gives $X_{n+1} = \\frac{1}{1+h\\lambda} X_n$. The term $R(h\\lambda) = \\frac{1}{1+h\\lambda}$ is the amplification factor. The method is considered stable with respect to the drift if $|R(h\\lambda)|  1$.\nGiven that $\\lambda  0$ and $h  0$, we have $h\\lambda  0$. Therefore, the denominator $1+h\\lambda  1$. This implies that $0  \\frac{1}{1+h\\lambda}  1$. This condition holds for all $h0$, demonstrating unconditional stability (in the sense of A-stability from ODEs). The amplification factor is always within the open unit disk $(-1, 1)$. Thus, this statement is **Correct**.\n\n**Statement F: Correct**\nThe total error in computing a path is an aggregate of two main error sources at each step:\n1.  **Discretization Error:** The error inherent to the scheme, which approximates a continuous process with a discrete one. For the Euler-Maruyama method, this leads to a global strong error of $O(h^{1/2})$.\n2.  **Solver Error:** The error from solving the implicit equation $R(y)=0$ approximately. The solver tolerance, $\\epsilon_{\\text{tol}}$, controls the accuracy of this inner solve, i.e., how close the computed $\\tilde{X}_{n+1}$ is to the true root $X_{n+1}$ of the algebraic equation.\n\nIt is a general principle in numerical analysis to balance error sources. There is no benefit in reducing one source of error far below the level of another, dominant source of error. In this case, the pathwise accuracy is fundamentally limited by the $O(h^{1/2})$ discretization error. If the nonlinear solver tolerance is set to be much smaller than this (e.g., $\\epsilon_{\\text{tol}} \\ll h^{1/2}$), the additional computations performed to achieve this high precision in the inner solve will be \"wasted,\" as the tiny improvement in the single-step algebraic solution will be completely overwhelmed by the much larger discretization error. This increases the cost per step (more Newton iterations) with no discernible improvement in the final global accuracy of the computed path. Therefore, it is computationally efficient to choose a solver tolerance that is matched to the discretization error, e.g., $\\epsilon_{\\text{tol}} = O(h)$ or $O(h^{3/2})$. The statement reflects this standard and important concept in scientific computing. Thus, this statement is **Correct**.", "answer": "$$\\boxed{ACEF}$$", "id": "3059087"}]}