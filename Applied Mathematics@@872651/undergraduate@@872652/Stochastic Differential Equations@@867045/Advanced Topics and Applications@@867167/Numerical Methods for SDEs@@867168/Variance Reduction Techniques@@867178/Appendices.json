{"hands_on_practices": [{"introduction": "The control variates technique is a powerful way to improve estimator precision by exploiting the correlation between our target quantity and another variable with a known mean. The key to the method is finding the optimal weighting coefficient, $\\beta^*$, that maximally reduces the variance. This practice problem [@problem_id:1348947] provides a concrete scenario for you to apply the formula for $\\beta^*$ and solidify your understanding of how it's derived from the covariance and variance of the involved random variables.", "problem": "In Monte Carlo methods, a common task is to estimate the value of an integral $I = \\int_a^b g(x) dx$. This is often achieved by reformulating the integral as an expected value, $E[f(X)]$, where $X$ is a random variable and $f$ is a related function. A standard 'crude' Monte Carlo estimator then uses the sample mean of $N$ independent draws of $f(X_i)$.\n\nTo improve the precision of the estimation for a given number of samples, variance reduction techniques are employed. One such technique is the method of control variates. This involves finding a random variable $C$ that is correlated with $f(X)$ and has a known expectation, $\\mu_C = E[C]$. A new, improved estimator is then formed as $Z(b) = f(X) - b(C - \\mu_C)$, where $b$ is a constant coefficient. The value of $b$ is chosen to minimize the variance of $Z(b)$. This optimal coefficient, denoted $b^*$, is given by the formula:\n$$b^* = \\frac{\\text{Cov}(f(X), C)}{\\text{Var}(C)}$$\n\nConsider the problem of estimating the integral $I = \\int_0^1 \\cos\\left(\\frac{\\pi x}{2}\\right) dx$. This is equivalent to finding the expected value of $Y = \\cos\\left(\\frac{\\pi X}{2}\\right)$ where $X$ is a random variable uniformly distributed on the interval $[0, 1]$. We will use the random variable $C = X$ as a control variate, since it is correlated with $Y$ and its properties are easily determined.\n\nYour task is to calculate the exact theoretical value of the optimal coefficient $b^*$ for this control variate. Express your answer as a single closed-form analytic expression in terms of $\\pi$.", "solution": "We have $X \\sim \\text{Unif}[0,1]$, $Y=\\cos\\left(\\frac{\\pi X}{2}\\right)$, and $C=X$. The optimal control variate coefficient is\n$$\nb^{*}=\\frac{\\text{Cov}(Y,C)}{\\text{Var}(C)}.\n$$\nFirst compute $\\text{Var}(C)$. Using $E[X]=\\int_{0}^{1}x\\,dx=\\frac{1}{2}$ and $E[X^{2}]=\\int_{0}^{1}x^{2}\\,dx=\\frac{1}{3}$, we obtain\n$$\n\\text{Var}(C)=E[X^{2}]-\\left(E[X]\\right)^{2}=\\frac{1}{3}-\\frac{1}{4}=\\frac{1}{12}.\n$$\nNext compute $E[Y]$:\n$$\nE[Y]=\\int_{0}^{1}\\cos\\left(\\frac{\\pi x}{2}\\right)\\,dx=\\left.\\frac{2}{\\pi}\\sin\\left(\\frac{\\pi x}{2}\\right)\\right|_{0}^{1}=\\frac{2}{\\pi}.\n$$\nNow compute $E[CY]=E\\!\\left[X\\cos\\left(\\frac{\\pi X}{2}\\right)\\right]$. Let $a=\\frac{\\pi}{2}$. Then\n$$\nE[CY]=\\int_{0}^{1}x\\cos(ax)\\,dx.\n$$\nUsing integration by parts with $u=x$, $dv=\\cos(ax)\\,dx$, so $du=dx$ and $v=\\frac{1}{a}\\sin(ax)$, we get\n$$\n\\int x\\cos(ax)\\,dx=\\frac{x\\sin(ax)}{a}+\\frac{\\cos(ax)}{a^{2}}.\n$$\nEvaluating from $0$ to $1$,\n$$\n\\int_{0}^{1}x\\cos(ax)\\,dx=\\left(\\frac{\\sin(a)}{a}+\\frac{\\cos(a)}{a^{2}}\\right) - \\left(0 + \\frac{\\cos(0)}{a^2}\\right) = \\frac{\\sin(a)}{a}+\\frac{\\cos(a)-1}{a^{2}}.\n$$\nWith $a=\\frac{\\pi}{2}$, we have $\\sin(a)=1$ and $\\cos(a)=0$, hence\n$$\nE[CY]=\\frac{1}{a}-\\frac{1}{a^{2}}=\\frac{2}{\\pi}-\\frac{4}{\\pi^{2}}.\n$$\nTherefore,\n$$\n\\text{Cov}(Y,C)=E[CY]-E[Y]E[C]=\\left(\\frac{2}{\\pi}-\\frac{4}{\\pi^{2}}\\right)-\\left(\\frac{2}{\\pi}\\right)\\left(\\frac{1}{2}\\right)=\\frac{1}{\\pi}-\\frac{4}{\\pi^{2}}=\\frac{\\pi-4}{\\pi^{2}}.\n$$\nFinally,\n$$\nb^{*}=\\frac{\\text{Cov}(Y,C)}{\\text{Var}(C)}=\\frac{\\frac{\\pi-4}{\\pi^{2}}}{\\frac{1}{12}}=\\frac{12(\\pi-4)}{\\pi^{2}}.\n$$", "answer": "$$\\boxed{\\frac{12(\\pi - 4)}{\\pi^{2}}}$$", "id": "1348947"}, {"introduction": "The conditional Monte Carlo method offers a guaranteed way to reduce variance by leveraging the power of conditional expectation, a concept sometimes referred to as \"Rao-Blackwellization.\" Instead of simulating all sources of randomness, we can analytically compute the expectation with respect to some of them, effectively averaging out part of the noise. This exercise [@problem_id:1348948] will guide you through the process of deriving a new estimator based on conditional expectation and then calculating its (smaller) variance.", "problem": "In a simplified model of a digital communications system, the detection of a bit depends on the relationship between a signal's amplitude, $X$, and a noise-dependent threshold. Both the signal amplitude $X$ and a noise-related variable $Y$ are modeled as independent random variables, uniformly distributed on the interval $[0, 1]$. A successful detection occurs if $X  Y^2$.\n\nWe wish to estimate the probability of successful detection, $\\theta = P(X  Y^2)$, using a Monte Carlo method. A standard approach involves defining an indicator random variable $I = \\mathbf{1}_{X  Y^2}$ and estimating its expectation. To improve upon this, we will use the conditional Monte Carlo technique.\n\nLet $Z$ be the new estimator obtained by taking the conditional expectation of $I$ with respect to the random variable $Y$. That is, $Z = E[I | Y]$. Your tasks are:\n1.  Determine the analytical expression for the random variable $Z$ as a function of $Y$.\n2.  Calculate the exact variance of this new estimator, $\\text{Var}(Z)$.\n\nProvide your answers as a pair of values: the expression for $Z$ and the numerical value for $\\text{Var}(Z)$.", "solution": "Let $X$ and $Y$ be independent and uniformly distributed on $[0,1]$. Define $I=\\mathbf{1}_{XY^{2}}$. The conditional Monte Carlo estimator is $Z=E[I\\mid Y]$.\n\n1) For a fixed $Y=y\\in[0,1]$, independence gives\n$$\nZ(y)=E[I\\mid Y=y]=P(Xy^{2}\\mid Y=y)=P(Xy^{2})=\\int_{0}^{1}\\mathbf{1}_{xy^{2}}\\,f_{X}(x)\\,dx.\n$$\nSince $f_{X}(x)=1$ on $[0,1]$, this becomes\n$$\nZ(y)=\\int_{y^{2}}^{1}1\\,dx=1-y^{2}.\n$$\nThus, as a random variable,\n$$\nZ=1-Y^{2}.\n$$\n\n2) The variance of $Z$ is\n$$\n\\operatorname{Var}(Z)=\\operatorname{Var}(1-Y^{2})=\\operatorname{Var}(Y^{2})=E[Y^{4}]-\\left(E[Y^{2}]\\right)^{2}.\n$$\nFor $Y\\sim\\text{Uniform}(0,1)$, $E[Y^{k}]=\\frac{1}{k+1}$ for integers $k\\geq 0$, hence $E[Y^{2}]=\\frac{1}{3}$ and $E[Y^{4}]=\\frac{1}{5}$. Therefore,\n$$\n\\operatorname{Var}(Z)=\\frac{1}{5}-\\left(\\frac{1}{3}\\right)^{2}=\\frac{1}{5}-\\frac{1}{9}=\\frac{9-5}{45}=\\frac{4}{45}.\n$$\nEquivalently, one can verify via $E[Z]=E[1-Y^{2}]=1-\\frac{1}{3}=\\frac{2}{3}$ and $E[Z^{2}]=E[(1-Y^{2})^{2}]=1-2E[Y^{2}]+E[Y^{4}]=1-\\frac{2}{3}+\\frac{1}{5}=\\frac{8}{15}$, yielding $\\operatorname{Var}(Z)=\\frac{8}{15}-\\left(\\frac{2}{3}\\right)^{2}=\\frac{4}{45}$.\n\nHence, $Z=1-Y^{2}$ and $\\operatorname{Var}(Z)=\\frac{4}{45}$.", "answer": "$$\\boxed{\\begin{pmatrix} 1 - Y^{2}  \\frac{4}{45} \\end{pmatrix}}$$", "id": "1348948"}, {"introduction": "Estimating the probability of a rare event is a classic challenge in Monte Carlo simulation, as most samples will fall outside the region of interest. Importance sampling tackles this by changing the underlying probability distribution to make the rare event more frequent, and then correcting the results with a weighting factor. The art of this method lies in choosing a good \"proposal\" distribution, a task you will explore in this conceptual problem [@problem_id:1348967] to develop your intuition for effective sampler design.", "problem": "In a Monte Carlo simulation exercise, we aim to estimate the probability $p$ that the sum of the outcomes of 20 independent rolls of a standard fair six-sided die exceeds 100. Let $X_i$ for $i=1, \\dots, 20$ be the outcome of the $i$-th roll, so $X_i$ is a random variable uniformly distributed on the set $\\{1, 2, 3, 4, 5, 6\\}$. We are interested in $p = P(\\sum_{i=1}^{20} X_i  100)$.\n\nSince this event is rare, a naive Monte Carlo simulation is inefficient. To improve efficiency, we can use importance sampling, a variance reduction technique. This involves sampling from a different, \"loaded\" Probability Mass Function (PMF), let's call it $q(k)$, for each die roll, instead of the original uniform PMF, $p(k) = 1/6$.\n\nWhich of the following choices for the loaded PMF $q(k)$ for a single die roll (where $k \\in \\{1, 2, 3, 4, 5, 6\\}$) would be the most suitable choice for implementing importance sampling to estimate $p$ with low variance?\n\nA. $q(k) = \\frac{1}{6}$ for $k \\in \\{1, 2, 3, 4, 5, 6\\}$\n\nB. $q(k) = \\frac{7-k}{21}$ for $k \\in \\{1, 2, 3, 4, 5, 6\\}$\n\nC. $q(k) = \\frac{1}{3}$ for $k \\in \\{4, 5, 6\\}$ and $q(k) = 0$ for $k \\in \\{1, 2, 3\\}$\n\nD. $q(k) = \\frac{k}{21}$ for $k \\in \\{1, 2, 3, 4, 5, 6\\}$", "solution": "Let $X_{1},\\dots,X_{20}$ be i.i.d. with the nominal PMF $p(k)=\\frac{1}{6}$ on $\\{1,2,3,4,5,6\\}$, and let $S=\\sum_{i=1}^{20}X_{i}$. We want $p^{\\star}=P(S100)$. Importance sampling estimates $p^{\\star}$ by sampling $Y_{1},\\dots,Y_{20}$ i.i.d. from a proposal PMF $q$ on $\\{1,\\dots,6\\}$ and using the unbiased estimator\n$$\n\\widehat{p}=\\mathbf{1}\\{Y_{1}+\\cdots+Y_{20}100\\}\\prod_{i=1}^{20}\\frac{p(Y_{i})}{q(Y_{i})}.\n$$\nUnbiasedness requires absolute continuity of $p$ restricted to the rare-event set with respect to $q$, which here amounts to $q(k)0$ for every $k\\in\\{1,\\dots,6\\}$ that can appear in any sequence contributing to $S100$. Since there exist sequences in $\\{S100\\}$ that include any of the values $1,2,3,4,5,6$, we need $q(k)0$ for all $k\\in\\{1,\\dots,6\\}$.\n\nVariance reduction for the rare event $S100$ requires proposing distributions that make large outcomes more likely, increasing $P_{q}(S100)$, while keeping likelihood ratios stable. For a single roll, the likelihood ratio is $L(k)=\\frac{p(k)}{q(k)}$. For rare events dominated by large $k$, it is beneficial that $L(k)$ decreases with $k$, so samples typical of the event receive smaller weights, reducing variance. Heuristically, the optimal proposal is an exponential tilt $q_{\\theta}(k)\\propto p(k)\\exp(\\theta k)$ with $\\theta0$, which places more mass on larger $k$ and has full support.\n\nEvaluate each option:\n\nA. $q(k)=\\frac{1}{6}$. This is the nominal PMF. It provides no variance reduction and hence is not the most suitable for a rare event.\n\nB. $q(k)=\\frac{7-k}{21}$. This proposal favors small $k$ (since $q(1)\\cdotsq(6)$), which moves mass away from the rare-event region. Its single-roll likelihood ratio is\n$$\nL_{B}(k)=\\frac{\\frac{1}{6}}{\\frac{7-k}{21}}=\\frac{7}{2(7-k)},\n$$\nwhich increases with $k$, giving large weights to large outcomes that are typical under $S100$, inflating variance. This is unsuitable.\n\nC. $q(k)=\\frac{1}{3}$ for $k\\in\\{4,5,6\\}$ and $q(k)=0$ for $k\\in\\{1,2,3\\}$. While this heavily favors large faces, it violates the absolute continuity requirement because there exist sequences with $S100$ that include values in $\\{1,2,3\\}$ and have positive probability under $p$ but zero under $q$. Consequently, $\\prod_{i}p(Y_{i})/q(Y_{i})$ is not well-defined on the entire rare-event set and an unbiased IS estimator for $P(S100)$ cannot be constructed with this $q$.\n\nD. $q(k)=\\frac{k}{21}$. This proposal favors large $k$ while maintaining full support. Its single-roll likelihood ratio is\n$$\nL_{D}(k)=\\frac{\\frac{1}{6}}{\\frac{k}{21}}=\\frac{7}{2k},\n$$\nwhich decreases with $k$, so samples typical of the event receive smaller weights, stabilizing the estimator and reducing variance. Moreover, the expected value under each PMF confirms the direction of tilt:\n$$\n\\mathbb{E}_{p}[X]=\\frac{1+2+3+4+5+6}{6}=\\frac{7}{2},\\quad\n\\mathbb{E}_{B}[X]=\\frac{7\\sum_{k=1}^{6}k-\\sum_{k=1}^{6}k^{2}}{21}=\\frac{56}{21}=\\frac{8}{3}\\frac{7}{2},\n$$\n$$\n\\mathbb{E}_{C}[X]=\\frac{4+5+6}{3}=5\\quad\\text{(but $q$ has zeros, invalid for unbiased IS)},\n$$\n$$\n\\mathbb{E}_{D}[X]=\\frac{\\sum_{k=1}^{6}k^{2}}{21}=\\frac{91}{21}=\\frac{13}{3}\\frac{7}{2}.\n$$\nThus D tilts in the correct direction, preserves full support, and yields a likelihood ratio that is smaller for large $k$, all of which contribute to lower variance for estimating $P(S100)$.\n\nTherefore, among the given choices, D is the most suitable for importance sampling with low variance.", "answer": "$$\\boxed{D}$$", "id": "1348967"}]}