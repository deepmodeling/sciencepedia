{"hands_on_practices": [{"introduction": "A cornerstone of studying diffusion processes is understanding their long-term or equilibrium behavior, which is captured by the invariant measure. The Ornstein-Uhlenbeck process provides a perfect setting to explore this, as it models many physical systems that revert to a mean. This practice will guide you through deriving this crucial invariant density and connect it to the deeper property of detailed balance by analyzing the symmetry of the process's generator [@problem_id:3048996].", "problem": "Consider the one-dimensional Ornstein–Uhlenbeck (OU) process defined by the Itô stochastic differential equation\n$$\ndX_t \\;=\\; -\\theta\\big(X_t - \\mu\\big)\\,dt \\;+\\; \\sigma\\,dW_t, \\quad t \\geq 0,\n$$\nwhere $W_t$ is a standard one-dimensional Brownian motion (BM), $\\theta0$ is the mean-reversion rate, $\\mu \\in \\mathbb{R}$ is the long-run mean, and $\\sigma0$ is the noise intensity. Let $\\pi(x)$ denote an invariant probability density (if it exists), and let $\\mathcal{L}$ denote the infinitesimal generator of this Markov diffusion acting on twice continuously differentiable functions $f:\\mathbb{R}\\to\\mathbb{R}$.\n\nStarting from the Kolmogorov forward equation (also called the Fokker–Planck equation) for Itô diffusions and the definition of invariance under the Markov semigroup, derive the invariant density $\\pi(x)$ for the OU process, including its normalization constant, by solving the appropriate stationary equation. Then, using the definition of the generator $\\mathcal{L}$ and the weighted inner product\n$$\n\\langle f, g\\rangle_{L^{2}(\\pi)} \\;=\\; \\int_{\\mathbb{R}} f(x)\\,g(x)\\,\\pi(x)\\,dx,\n$$\nverify the detailed balance condition by showing that $\\mathcal{L}$ is symmetric in $L^{2}(\\pi)$ on a core of smooth, compactly supported test functions. In your verification, justify any integration by parts and boundary term evaluations using the decay of $\\pi(x)$ and the support properties of the test functions.\n\nProvide the closed-form expression for the invariant density $\\pi(x)$ as your final answer. No numerical approximation is required.", "solution": "The problem is valid as it is scientifically grounded, well-posed, and objective. It is a standard problem in the theory of stochastic differential equations.\n\nThe Ornstein-Uhlenbeck (OU) process is described by the stochastic differential equation (SDE):\n$$\ndX_t = -\\theta(X_t - \\mu) dt + \\sigma dW_t\n$$\nThis is a one-dimensional Itô diffusion of the form $dX_t = \\mu(X_t) dt + \\sigma(X_t) dW_t$, with drift coefficient $\\mu(x) = -\\theta(x - \\mu)$ and diffusion coefficient $\\sigma(x) = \\sigma$. The parameters are given as $\\theta  0$, $\\mu \\in \\mathbb{R}$, and $\\sigma  0$.\n\n### Part 1: Derivation of the Invariant Density $\\pi(x)$\n\nThe evolution of the probability density function $p(x,t)$ of a one-dimensional Itô diffusion is governed by the Kolmogorov forward equation, also known as the Fokker-Planck equation:\n$$\n\\frac{\\partial p(x,t)}{\\partial t} = -\\frac{\\partial}{\\partial x} [\\mu(x) p(x,t)] + \\frac{1}{2} \\frac{\\partial^2}{\\partial x^2} [\\sigma(x)^2 p(x,t)]\n$$\nAn invariant (or stationary) density $\\pi(x)$ is a solution that does not change with time, i.e., $\\frac{\\partial \\pi(x)}{\\partial t} = 0$. For such a density, the Fokker-Planck equation becomes:\n$$\n0 = -\\frac{d}{dx} [\\mu(x) \\pi(x)] + \\frac{1}{2} \\frac{d^2}{dx^2} [\\sigma(x)^2 \\pi(x)]\n$$\nThis can be written as $\\frac{d}{dx} J(x) = 0$, where $J(x)$ is the probability current:\n$$\nJ(x) = \\mu(x) \\pi(x) - \\frac{1}{2} \\frac{d}{dx} [\\sigma(x)^2 \\pi(x)]\n$$\nThe condition $\\frac{d}{dx}J(x) = 0$ implies that $J(x)$ is a constant. For a process on the entire real line $\\mathbb{R}$, a normalizable probability density requires that $\\pi(x)$ and its derivatives vanish as $|x| \\to \\infty$. This implies the constant probability current must be zero, so $J(x) = 0$ for all $x \\in \\mathbb{R}$.\n\nSubstituting the expressions for $\\mu(x)$ and $\\sigma(x)$ for the OU process, we get:\n$$\n-\\theta(x-\\mu)\\pi(x) - \\frac{1}{2} \\frac{d}{dx} [\\sigma^2 \\pi(x)] = 0\n$$\nSince $\\sigma$ is a constant, this simplifies to a first-order ordinary differential equation (ODE) for $\\pi(x)$:\n$$\n-\\theta(x-\\mu)\\pi(x) - \\frac{\\sigma^2}{2} \\frac{d\\pi(x)}{dx} = 0\n$$\nThis is a separable ODE:\n$$\n\\frac{d\\pi}{\\pi} = -\\frac{2\\theta}{\\sigma^2}(x-\\mu) dx\n$$\nIntegrating both sides yields:\n$$\n\\int \\frac{d\\pi}{\\pi} = \\int -\\frac{2\\theta}{\\sigma^2}(x-\\mu) dx\n$$\n$$\n\\ln(\\pi(x)) = -\\frac{2\\theta}{\\sigma^2} \\frac{(x-\\mu)^2}{2} + C'\n$$\n$$\n\\ln(\\pi(x)) = -\\frac{\\theta}{\\sigma^2}(x-\\mu)^2 + C'\n$$\nExponentiating both sides gives the form of the invariant density:\n$$\n\\pi(x) = C \\exp\\left(-\\frac{\\theta}{\\sigma^2}(x-\\mu)^2\\right)\n$$\nwhere $C = \\exp(C')$ is a normalization constant. To find $C$, we use the condition that $\\pi(x)$ must be a probability density, so its integral over $\\mathbb{R}$ must be $1$:\n$$\n\\int_{-\\infty}^{\\infty} \\pi(x) dx = C \\int_{-\\infty}^{\\infty} \\exp\\left(-\\frac{\\theta}{\\sigma^2}(x-\\mu)^2\\right) dx = 1\n$$\nLet $y = x - \\mu$, so $dy = dx$. The integral becomes:\n$$\nC \\int_{-\\infty}^{\\infty} \\exp\\left(-\\frac{\\theta}{\\sigma^2}y^2\\right) dy = 1\n$$\nWe use the standard Gaussian integral formula $\\int_{-\\infty}^{\\infty} \\exp(-k y^2) dy = \\sqrt{\\frac{\\pi}{k}}$. Here, $k = \\frac{\\theta}{\\sigma^2}$.\n$$\nC \\sqrt{\\frac{\\pi}{\\theta/\\sigma^2}} = C \\sqrt{\\frac{\\pi\\sigma^2}{\\theta}} = 1\n$$\nSolving for $C$:\n$$\nC = \\sqrt{\\frac{\\theta}{\\pi\\sigma^2}}\n$$\nThus, the invariant density for the OU process is:\n$$\n\\pi(x) = \\sqrt{\\frac{\\theta}{\\pi\\sigma^2}} \\exp\\left(-\\frac{\\theta}{\\sigma^2}(x-\\mu)^2\\right)\n$$\nThis is the probability density function of a Gaussian distribution with mean $\\mu$ and variance $\\frac{\\sigma^2}{2\\theta}$.\n\n### Part 2: Verification of the Detailed Balance Condition\n\nThe detailed balance condition is equivalent to showing that the infinitesimal generator $\\mathcal{L}$ of the process is a self-adjoint (symmetric) operator in the Hilbert space $L^2(\\pi)$ with the weighted inner product $\\langle f, g\\rangle_{L^{2}(\\pi)} = \\int_{\\mathbb{R}} f(x)\\,g(x)\\,\\pi(x)\\,dx$. We need to verify that for any two smooth, compactly supported test functions $f$ and $g$:\n$$\n\\langle \\mathcal{L}f, g\\rangle_{L^{2}(\\pi)} = \\langle f, \\mathcal{L}g\\rangle_{L^{2}(\\pi)}\n$$\nThe generator for a one-dimensional Itô diffusion is $\\mathcal{L} = \\mu(x) \\frac{d}{dx} + \\frac{1}{2}\\sigma(x)^2 \\frac{d^2}{dx^2}$. For the OU process, this is:\n$$\n\\mathcal{L}f(x) = -\\theta(x-\\mu) \\frac{df}{dx} + \\frac{\\sigma^2}{2} \\frac{d^2f}{dx^2}\n$$\nWe evaluate the left-hand side of the symmetry condition:\n$$\n\\langle \\mathcal{L}f, g\\rangle_{L^{2}(\\pi)} = \\int_{-\\infty}^{\\infty} \\left( -\\theta(x-\\mu) f'(x) + \\frac{\\sigma^2}{2} f''(x) \\right) g(x) \\pi(x) dx\n$$\nWe split the integral into two parts and use integration by parts on the second term involving $f''(x)$:\n$$\nI_1 = \\int_{-\\infty}^{\\infty} -\\theta(x-\\mu) f'(x) g(x) \\pi(x) dx\n$$\n$$\nI_2 = \\int_{-\\infty}^{\\infty} \\frac{\\sigma^2}{2} f''(x) g(x) \\pi(x) dx\n$$\nFor $I_2$, let $u = \\frac{\\sigma^2}{2} g(x) \\pi(x)$ and $dv = f''(x) dx$. Then $du = \\frac{\\sigma^2}{2} (g'(x)\\pi(x) + g(x)\\pi'(x)) dx$ and $v = f'(x)$.\n$$\nI_2 = \\left[ \\frac{\\sigma^2}{2} g(x) \\pi(x) f'(x) \\right]_{-\\infty}^{\\infty} - \\int_{-\\infty}^{\\infty} f'(x) \\frac{\\sigma^2}{2} (g'(x)\\pi(x) + g(x)\\pi'(x)) dx\n$$\nThe boundary term vanishes because $f$ and $g$ (and thus their derivatives) have compact support, meaning they are zero outside a finite interval.\nSo, $\\langle \\mathcal{L}f, g\\rangle_{L^{2}(\\pi)} = I_1 + I_2$ becomes:\n$$\n\\int_{-\\infty}^{\\infty} \\left[ -\\theta(x-\\mu)f'g\\pi - \\frac{\\sigma^2}{2} f'g'\\pi - \\frac{\\sigma^2}{2} f'g\\pi' \\right] dx\n$$\nWe can factor out $f'(x)$:\n$$\n\\int_{-\\infty}^{\\infty} f'(x) \\left\\{ g(x) \\left[-\\theta(x-\\mu)\\pi(x) - \\frac{\\sigma^2}{2}\\pi'(x)\\right] - g'(x)\\frac{\\sigma^2}{2}\\pi(x) \\right\\} dx\n$$\nFrom the stationary Fokker-Planck equation derived in Part 1, we found that:\n$$\n-\\theta(x-\\mu)\\pi(x) - \\frac{\\sigma^2}{2}\\pi'(x) = 0\n$$\nSubstituting this into the expression, the term multiplying $g(x)$ becomes zero. We are left with:\n$$\n\\langle \\mathcal{L}f, g\\rangle_{L^{2}(\\pi)} = \\int_{-\\infty}^{\\infty} f'(x) \\left\\{ -g'(x)\\frac{\\sigma^2}{2}\\pi(x) \\right\\} dx = -\\frac{\\sigma^2}{2} \\int_{-\\infty}^{\\infty} f'(x)g'(x)\\pi(x) dx\n$$\nThis final expression is symmetric with respect to an interchange of $f$ and $g$. If we had started with $\\langle \\mathcal{L}g, f\\rangle_{L^{2}(\\pi)}$, we would have followed the same steps with the roles of $f$ and $g$ swapped, leading to the same result:\n$$\n\\langle f, \\mathcal{L}g\\rangle_{L^{2}(\\pi)} = \\langle \\mathcal{L}g, f\\rangle_{L^{2}(\\pi)} = -\\frac{\\sigma^2}{2} \\int_{-\\infty}^{\\infty} g'(x)f'(x)\\pi(x) dx\n$$\nTherefore, $\\langle \\mathcal{L}f, g\\rangle_{L^{2}(\\pi)} = \\langle f, \\mathcal{L}g\\rangle_{L^{2}(\\pi)}$, which confirms that the generator $\\mathcal{L}$ is symmetric in $L^2(\\pi)$ for the OU process. This verifies the detailed balance condition.\n\nThe full derivation above leads to the closed-form expression for the invariant density $\\pi(x)$.", "answer": "$$\n\\boxed{\\sqrt{\\frac{\\theta}{\\pi\\sigma^2}} \\exp\\left(-\\frac{\\theta}{\\sigma^2}(x-\\mu)^2\\right)}\n$$", "id": "3048996"}, {"introduction": "While the invariant measure describes a process's behavior within its state space, a complete picture requires understanding what happens at the boundaries. Feller's boundary classification provides a rigorous framework to determine if a process can enter from, exit to, or is repelled by the edges of its domain. This exercise provides hands-on practice with the fundamental tools of scale functions and speed measures, allowing you to classify the boundaries for a given diffusion and interpret their physical meaning [@problem_id:3049020].", "problem": "Consider the one-dimensional diffusion process defined by the stochastic differential equation (SDE) $dX_{t} = \\sqrt{X_{t}}\\, dW_{t}$, where $W_{t}$ is a standard one-dimensional Brownian motion and $X_{t} \\in (0,\\infty)$. Using only foundational definitions for the scale function and speed measure of a one-dimensional diffusion derived from its generator, classify the boundary points $0$ and $\\infty$ according to Feller’s boundary classification (regular, exit, entrance, natural). Your derivation must begin from the generator of the diffusion and proceed to the scale function and speed measure, and then to the boundary classification criteria.\n\nTo ensure a calculation-type final answer, encode the four boundary types as integers: regular $\\mapsto 0$, exit $\\mapsto 1$, entrance $\\mapsto 2$, natural $\\mapsto 3$. Express your final answer as a $1 \\times 2$ row matrix in the LaTeX $\\texttt{pmatrix}$ environment, with the first entry being the encoded type for $0$ and the second entry being the encoded type for $\\infty$. No rounding is required, and no units are involved.", "solution": "The problem asks for the classification of the boundaries $0$ and $\\infty$ for the one-dimensional diffusion process $X_t$ on the state space $(0, \\infty)$ defined by the stochastic differential equation (SDE):\n$$dX_{t} = \\sqrt{X_{t}}\\, dW_{t}$$\nThis is an SDE of the form $dX_t = \\mu(X_t)dt + \\sigma(X_t)dW_t$, with a drift coefficient $\\mu(x)=0$ and a diffusion coefficient $\\sigma(x)=\\sqrt{x}$. The classification will be performed using Feller's boundary classification scheme, which relies on the scale function and the speed measure of the diffusion. The derivation must proceed from the generator of the process.\n\nThe infinitesimal generator $\\mathcal{L}$ of a one-dimensional diffusion process is a second-order differential operator given by:\n$$\\mathcal{L}f(x) = \\mu(x)\\frac{df}{dx} + \\frac{1}{2}\\sigma(x)^2\\frac{d^2f}{dx^2}$$\nFor the given process, we have $\\mu(x)=0$ and $\\sigma(x)^2 = (\\sqrt{x})^2 = x$. Substituting these into the generator's formula yields:\n$$\\mathcal{L}f(x) = (0)\\frac{df}{dx} + \\frac{1}{2}x\\frac{d^2f}{dx^2} = \\frac{1}{2}x\\frac{d^2f}{dx^2}$$\nThis generator is defined for functions $f$ in a suitable domain, typically twice continuously differentiable functions with compact support in $(0, \\infty)$.\n\nThe scale function, denoted by $s(x)$, is a strictly increasing function defined on the state space of the diffusion that makes the process a local martingale when transformed by it. It is found by solving the differential equation $\\mathcal{L}s(x) = 0$.\n$$\\mathcal{L}s(x) = \\frac{1}{2}x\\frac{d^2s}{dx^2} = 0$$\nSince we are on the interval $(0, \\infty)$, $x \\neq 0$, so the equation simplifies to:\n$$\\frac{d^2s}{dx^2} = 0$$\nIntegrating this equation twice with respect to $x$ gives $s(x) = C_1x + C_2$, where $C_1$ and $C_2$ are integration constants. The scale function is unique up to an affine transformation, so we can select constants for simplicity, subject to the condition that $s(x)$ is strictly increasing ($C_1  0$). We choose $C_1 = 1$ and $C_2 = 0$, which gives the scale function:\n$$s(x) = x$$\nThe density of the scale function, denoted $s'(x)$, is therefore $s'(x) = 1$.\n\nThe speed measure, $m(dx)$, describes the amount of time the process spends in different regions of its state space. It has a density $m(x)$ with respect to the Lebesgue measure, which is related to the generator, diffusion coefficient, and scale function. The relationship is given by:\n$$m(x) = \\frac{2}{\\sigma(x)^2 s'(x)}$$\nSubstituting $\\sigma(x)^2 = x$ and $s'(x) = 1$, we find the speed measure density:\n$$m(x) = \\frac{2}{x \\cdot 1} = \\frac{2}{x}$$\n\nWith the scale density $s'(x)$ and speed measure density $m(x)$, we can proceed to Feller's boundary classification. For a diffusion on an interval $(a, b)$, we analyze the boundaries $a$ and $b$ by evaluating the convergence of certain integrals. Let $c$ be an arbitrary point in the interior of the state space, $(0, \\infty)$. We choose $c=1$ for convenience.\n\nFor a boundary point $b$, the classification depends on the finiteness of the following two integrals:\n$$\\sigma(b) = \\int_c^b s'(x)dx \\quad \\text{and} \\quad \\mu(b) = \\int_c^b m(x)dx$$\n(For the left boundary $a$, the integrals are $\\int_a^c f(x)dx$).\nThe boundary $b$ is classified as:\n- **Regular** if $\\sigma(b)  \\infty$ and $\\mu(b)  \\infty$.\n- **Exit** if $\\sigma(b)  \\infty$ and $\\mu(b) = \\infty$.\n- **Entrance** if $\\sigma(b) = \\infty$ and $\\mu(b)  \\infty$.\n- **Natural** if $\\sigma(b) = \\infty$ and $\\mu(b) = \\infty$.\n\nFirst, we classify the left boundary at $0$. We evaluate the integrals from $0$ to $c=1$:\n$$\\sigma(0) = \\int_{0^+}^1 s'(x)dx = \\int_{0^+}^1 1 dx = [x]_{0^+}^1 = 1 - 0 = 1$$\nThis integral is finite, $\\sigma(0)  \\infty$.\n$$\\mu(0) = \\int_{0^+}^1 m(x)dx = \\int_{0^+}^1 \\frac{2}{x} dx = 2[\\ln(x)]_{0^+}^1 = 2(\\ln(1) - \\lim_{x\\to 0^+}\\ln(x)) = 2(0 - (-\\infty)) = \\infty$$\nThis integral diverges, $\\mu(0) = \\infty$.\nSince $\\sigma(0)  \\infty$ and $\\mu(0) = \\infty$, the boundary at $0$ is an **exit** boundary.\n\nNext, we classify the right boundary at $\\infty$. We evaluate the integrals from $c=1$ to $\\infty$:\n$$\\sigma(\\infty) = \\int_1^\\infty s'(x)dx = \\int_1^\\infty 1 dx = [x]_1^\\infty = \\lim_{x\\to\\infty}x - 1 = \\infty$$\nThis integral diverges, $\\sigma(\\infty) = \\infty$.\n$$\\mu(\\infty) = \\int_1^\\infty m(x)dx = \\int_1^\\infty \\frac{2}{x} dx = 2[\\ln(x)]_1^\\infty = 2(\\lim_{x\\to\\infty}\\ln(x) - \\ln(1)) = 2(\\infty - 0) = \\infty$$\nThis integral also diverges, $\\mu(\\infty) = \\infty$.\nSince $\\sigma(\\infty) = \\infty$ and $\\mu(\\infty) = \\infty$, the boundary at $\\infty$ is a **natural** boundary.\n\nThe problem requires encoding the boundary types as integers: regular $\\mapsto 0$, exit $\\mapsto 1$, entrance $\\mapsto 2$, natural $\\mapsto 3$.\n- The boundary at $0$ is of type exit, which corresponds to the integer $1$.\n- The boundary at $\\infty$ is of type natural, which corresponds to the integer $3$.\n\nThe final answer is to be presented as a $1 \\times 2$ row matrix where the first entry is the code for the boundary at $0$ and the second is the code for the boundary at $\\infty$.", "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n1  3\n\\end{pmatrix}\n}\n$$", "id": "3049020"}, {"introduction": "Bridging the gap between analytical theory and computational practice is a vital skill in applied mathematics. This problem focuses on quantifying how well a numerical approximation, the Euler-Maruyama scheme, captures the dynamics of the exact Ornstein-Uhlenbeck process over a small time step. By deriving and comparing the local weak and strong errors, you will gain a concrete understanding of convergence rates and see how the structure of an SDE dictates the accuracy of its simulations [@problem_id:3049010].", "problem": "Consider the Ornstein–Uhlenbeck (OU) process defined by the stochastic differential equation (SDE)\n$$\n\\mathrm{d}X_{s} = -\\theta X_{s}\\,\\mathrm{d}s + \\sigma\\,\\mathrm{d}W_{s}, \\quad s \\in [t,t+h],\n$$\nwhere $\\theta  0$ and $\\sigma  0$ are constants, $W_{s}$ is a Wiener process (Brownian motion), and the initial condition $X_{t} = x$ is deterministic. The process is a time-homogeneous Markov diffusion with linear drift and constant diffusion. Using only fundamental definitions and properties of It\\^o stochastic calculus, the Markov property, and the Gaussianity of linear functionals of Brownian motion, perform the following tasks:\n\n1. Derive the exact one-step transition density of $X_{t+h}$ conditional on $X_{t} = x$, and identify its mean and variance as functions of $\\theta$, $\\sigma$, $h$, and $x$.\n\n2. Derive the one-step Euler–Maruyama (EM) approximation $\\bar{X}_{t+h}$ started from $x$ and its transition density conditional on $X_{t} = x$, and identify its mean and variance.\n\n3. Compare the two transition densities by expanding their means and variances in powers of $h$ and use this to determine the order of the local weak error, defined through expectations of bounded sufficiently smooth test functions, and the local strong error in root-mean-square, defined by $\\left(\\mathbb{E}\\!\\left[|X_{t+h} - \\bar{X}_{t+h}|^{2} \\mid X_{t} = x\\right]\\right)^{1/2}$.\n\n4. Using standard stability and accumulation arguments based on the Markov property and independence of Wiener increments, infer the corresponding global weak and strong convergence rates of the Euler–Maruyama method for the OU process over a fixed time interval partitioned into steps of size $h$.\n\nExpress the final answer as a row matrix containing, in order, the global weak convergence rate and the global strong convergence rate. No numerical approximation is required.", "solution": "The user wants to analyze the Ornstein-Uhlenbeck (OU) process and the convergence properties of the Euler-Maruyama (EM) method applied to it. This will be done in four parts: analyzing the exact solution, analyzing the EM approximation, comparing them to find local errors, and inferring global convergence rates.\n\nThe Ornstein-Uhlenbeck SDE is given by:\n$$\n\\mathrm{d}X_{s} = -\\theta X_{s}\\,\\mathrm{d}s + \\sigma\\,\\mathrm{d}W_{s}, \\quad s \\in [t,t+h]\n$$\nwith parameters $\\theta  0$, $\\sigma  0$, and a deterministic initial condition $X_{t} = x$.\n\n**1. Exact One-Step Transition Density**\n\nThe SDE is a linear first-order equation. We can solve it using an integrating factor, $e^{\\theta s}$. Let $Y_{s} = e^{\\theta s}X_{s}$. Using Itô's product rule, we find the differential of $Y_s$:\n$$\n\\mathrm{d}Y_{s} = \\mathrm{d}(e^{\\theta s} X_{s}) = (\\theta e^{\\theta s} X_{s})\\,\\mathrm{d}s + e^{\\theta s}\\,\\mathrm{d}X_{s}\n$$\nSubstituting the SDE for $\\mathrm{d}X_{s}$:\n$$\n\\mathrm{d}Y_{s} = \\theta e^{\\theta s} X_{s}\\,\\mathrm{d}s + e^{\\theta s}(-\\theta X_{s}\\,\\mathrm{d}s + \\sigma\\,\\mathrm{d}W_{s}) = \\sigma e^{\\theta s}\\,\\mathrm{d}W_{s}\n$$\nIntegrating from $s=t$ to $s=t+h$:\n$$\nY_{t+h} - Y_{t} = \\int_{t}^{t+h} \\sigma e^{\\theta s}\\,\\mathrm{d}W_{s}\n$$\nSubstituting back $Y_s = e^{\\theta s}X_s$ and using the initial condition $X_t=x$:\n$$\ne^{\\theta(t+h)}X_{t+h} - e^{\\theta t}x = \\sigma \\int_{t}^{t+h} e^{\\theta s}\\,\\mathrm{d}W_{s}\n$$\nSolving for $X_{t+h}$:\n$$\nX_{t+h} = x e^{-\\theta h} + \\sigma \\int_{t}^{t+h} e^{-\\theta(t+h-s)}\\,\\mathrm{d}W_{s}\n$$\nThe solution $X_{t+h}$ is the sum of a deterministic term and an Itô integral. An Itô integral of a deterministic function is a Gaussian random variable. Thus, $X_{t+h}$ conditional on $X_t=x$ is normally distributed.\n\nThe mean of $X_{t+h}$ is found by taking the expectation. The Itô integral has zero mean:\n$$\n\\mathbb{E}[X_{t+h} \\mid X_{t}=x] = \\mathbb{E}[x e^{-\\theta h}] + \\sigma \\mathbb{E}\\left[\\int_{t}^{t+h} e^{-\\theta(t+h-s)}\\,\\mathrm{d}W_{s}\\right] = x e^{-\\theta h}\n$$\nThe variance of $X_{t+h}$ is found using the Itô isometry property for the stochastic integral part:\n$$\n\\mathrm{Var}(X_{t+h} \\mid X_{t}=x) = \\mathrm{Var}\\left(\\sigma \\int_{t}^{t+h} e^{-\\theta(t+h-s)}\\,\\mathrm{d}W_{s}\\right) = \\sigma^2 \\int_{t}^{t+h} \\left(e^{-\\theta(t+h-s)}\\right)^2\\,\\mathrm{d}s\n$$\nLet $u = t+h-s$, so $\\mathrm{d}u = -\\mathrm{d}s$. The limits change from $s=t \\Rightarrow u=h$ to $s=t+h \\Rightarrow u=0$.\n$$\n\\mathrm{Var}(X_{t+h} \\mid X_{t}=x) = \\sigma^2 \\int_{h}^{0} e^{-2\\theta u}(-\\mathrm{d}u) = \\sigma^2 \\int_{0}^{h} e^{-2\\theta u}\\,\\mathrm{d}u = \\sigma^2 \\left[-\\frac{1}{2\\theta}e^{-2\\theta u}\\right]_{0}^{h} = \\frac{\\sigma^2}{2\\theta}(1 - e^{-2\\theta h})\n$$\nSo, the transition is Gaussian: $X_{t+h} \\mid X_{t}=x \\sim \\mathcal{N}(\\mu, v)$, where:\n- Mean: $\\mu(h) = x e^{-\\theta h}$\n- Variance: $v(h) = \\frac{\\sigma^2}{2\\theta}(1 - e^{-2\\theta h})$\nThe transition density is the probability density function of this normal distribution.\n\n**2. Euler–Maruyama Approximation and its Transition Density**\n\nThe Euler–Maruyama (EM) discretization of the SDE over a time step $h$ is:\n$$\n\\bar{X}_{t+h} = \\bar{X}_{t} + (-\\theta \\bar{X}_{t})h + \\sigma(W_{t+h} - W_{t})\n$$\nStarting from $\\bar{X}_{t} = x$, we get:\n$$\n\\bar{X}_{t+h} = x - \\theta x h + \\sigma \\Delta W_{t} = x(1-\\theta h) + \\sigma \\Delta W_{t}\n$$\nwhere $\\Delta W_{t} = W_{t+h} - W_{t}$ is a Wiener increment, which is a Gaussian random variable with mean $0$ and variance $h$, i.e., $\\Delta W_{t} \\sim \\mathcal{N}(0, h)$.\nSince $\\bar{X}_{t+h}$ is a linear transformation of a Gaussian variable, it is also Gaussian.\n\nThe mean of the EM approximation is:\n$$\n\\mathbb{E}[\\bar{X}_{t+h} \\mid X_{t}=x] = \\mathbb{E}[x(1-\\theta h) + \\sigma \\Delta W_{t}] = x(1-\\theta h) + \\sigma \\mathbb{E}[\\Delta W_{t}] = x(1-\\theta h)\n$$\nThe variance of the EM approximation is:\n$$\n\\mathrm{Var}(\\bar{X}_{t+h} \\mid X_{t}=x) = \\mathrm{Var}(x(1-\\theta h) + \\sigma \\Delta W_{t}) = \\sigma^2 \\mathrm{Var}(\\Delta W_{t}) = \\sigma^2 h\n$$\nSo, the EM transition is also Gaussian: $\\bar{X}_{t+h} \\mid X_{t}=x \\sim \\mathcal{N}(\\bar{\\mu}, \\bar{v})$, where:\n- Mean: $\\bar{\\mu}(h) = x(1-\\theta h)$\n- Variance: $\\bar{v}(h) = \\sigma^2 h$\n\n**3. Comparison and Local Errors**\n\nWe expand the exact mean and variance in powers of $h$ to compare with the EM moments.\n- **Means:** Using the Taylor series $e^{-z} = 1 - z + \\frac{z^2}{2!} - \\dots$:\n  $$\n  \\mu(h) = x e^{-\\theta h} = x\\left(1 - \\theta h + \\frac{\\theta^2 h^2}{2} + O(h^3)\\right)\n  $$\n  The difference between the exact and EM means is:\n  $$\n  \\mu(h) - \\bar{\\mu}(h) = x\\left(1 - \\theta h + \\frac{\\theta^2 h^2}{2} + O(h^3)\\right) - x(1-\\theta h) = \\frac{x\\theta^2}{2}h^2 + O(h^3) = O(h^2)\n  $$\n- **Variances:** Using the Taylor series $e^{-z} = 1 - z + \\frac{z^2}{2!} - \\dots$:\n  $$\n  v(h) = \\frac{\\sigma^2}{2\\theta}(1 - e^{-2\\theta h}) = \\frac{\\sigma^2}{2\\theta}\\left(1 - \\left(1 - 2\\theta h + \\frac{(2\\theta h)^2}{2} + O(h^3)\\right)\\right) = \\frac{\\sigma^2}{2\\theta}(2\\theta h - 2\\theta^2 h^2 + O(h^3)) = \\sigma^2 h - \\sigma^2\\theta h^2 + O(h^3)\n  $$\n  The difference between the exact and EM variances is:\n  $$\n  v(h) - \\bar{v}(h) = (\\sigma^2 h - \\sigma^2\\theta h^2 + O(h^3)) - \\sigma^2 h = -\\sigma^2\\theta h^2 + O(h^3) = O(h^2)\n  $$\n\nThe **local weak error** is of order $p$ if $|\\mathbb{E}[f(X_{t+h})] - \\mathbb{E}[f(\\bar{X}_{t+h})]| = O(h^{p+1})$ for smooth test functions $f$. Since the means and variances both match to order $h$ and differ at order $h^2$, the expectation of any sufficiently smooth function $f$ will also differ at order $h^2$. This implies the local weak error is $O(h^2)$. The local weak order is therefore $p=1$.\n\nThe **local strong error** is given by $(\\mathbb{E}[|X_{t+h} - \\bar{X}_{t+h}|^2 \\mid X_t=x])^{1/2}$. We compute the mean squared error (MSE):\n$$\nX_{t+h} - \\bar{X}_{t+h} = \\left(x e^{-\\theta h} - x(1-\\theta h)\\right) + \\sigma\\left(\\int_{t}^{t+h} e^{-\\theta(t+h-s)}\\,\\mathrm{d}W_{s} - \\int_{t}^{t+h} 1\\,\\mathrm{d}W_{s}\\right)\n$$\nLet the first term be $A$ and the second term be $B$. The terms are uncorrelated since $A$ is deterministic and $B$ is a zero-mean Itô integral. Thus, $\\mathbb{E}[(A+B)^2] = A^2 + \\mathbb{E}[B^2]$.\n- The deterministic part $A$:\n  $A = x(e^{-\\theta h} - 1 + \\theta h) = x\\left(\\left(1-\\theta h + \\frac{\\theta^2h^2}{2} + O(h^3)\\right) - 1 + \\theta h\\right) = \\frac{x\\theta^2}{2}h^2 + O(h^3) = O(h^2)$. Thus, $A^2 = O(h^4)$.\n- The stochastic part $B$: Using Itô isometry for $\\mathbb{E}[B^2]$:\n  $$\n  \\mathbb{E}[B^2] = \\sigma^2 \\int_{t}^{t+h} (e^{-\\theta(t+h-s)} - 1)^2\\,\\mathrm{d}s = \\sigma^2 \\int_{0}^{h} (e^{-\\theta u} - 1)^2\\,\\mathrm{d}u\n  $$\n  For small $u$, $(e^{-\\theta u} - 1)^2 = (-\\theta u + O(u^2))^2 = \\theta^2 u^2 + O(u^3)$.\n  $$\n  \\mathbb{E}[B^2] = \\sigma^2 \\int_{0}^{h} (\\theta^2 u^2 + O(u^3))\\,\\mathrm{d}u = \\sigma^2\\left(\\frac{\\theta^2 h^3}{3} + O(h^4)\\right) = O(h^3)\n  $$\nThe total MSE is $\\mathbb{E}[|X_{t+h} - \\bar{X}_{t+h}|^2] = A^2 + \\mathbb{E}[B^2] = O(h^4) + O(h^3) = O(h^3)$.\nThe local strong error is the root-mean-square, so it is $(O(h^3))^{1/2} = O(h^{1.5})$. The local strong order is $1.5$.\n\n**4. Global Convergence Rates**\n\nThe global rates of convergence can be inferred from the local error orders using standard accumulation arguments for stable numerical methods.\n- **Global Weak Convergence Rate:** A method with local weak order $p$ (i.e., one-step error of $O(h^{p+1})$) has a global weak convergence rate of $p$. Here, the local weak error is $O(h^2)$, so the local order is $p=1$. Thus, the global weak convergence rate is $1$.\n\n- **Global Strong Convergence Rate:** A method with local strong order $\\gamma$ (i.e., one-step RMSE of $O(h^{\\gamma})$) typically has a global strong convergence rate of $\\gamma - 0.5$. The factor $0.5$ arises from the accumulation of stochastic errors, which scales with the square root of the number of steps, $\\sqrt{N} = \\sqrt{T/h}$.\nIn our case, the local strong order is $\\gamma = 1.5$. Therefore, the global strong convergence rate is $1.5 - 0.5 = 1.0$.\n\nThis improved strong convergence rate (from the general EM rate of $0.5$ to $1.0$) is a known special case for SDEs with additive noise, where the diffusion coefficient $\\sigma(t,x)$ does not depend on the state $x$. The OU process SDE fits this case, as $\\sigma$ is a constant. For such SDEs, the Euler-Maruyama scheme is equivalent to the higher-order Milstein scheme, which generally has a strong convergence rate of $1.0$.\n\nThe final answer requires the global weak rate and the global strong rate.\n- Global weak rate: $1$\n- Global strong rate: $1$", "answer": "$$\n\\boxed{\\begin{pmatrix} 1  1 \\end{pmatrix}}\n$$", "id": "3049010"}]}