{"hands_on_practices": [{"introduction": "The connection between stochastic differential equations (SDEs) and parabolic partial differential equations (PDEs) is a cornerstone of modern probability theory. This first exercise provides a direct, hands-on verification of this link for a general Itô diffusion. By explicitly calculating the expected value of a functional of the process and then independently computing the terms of the associated PDE, you will confirm from first principles that the probabilistic representation indeed satisfies the Kolmogorov backward equation [@problem_id:3070563].", "problem": "Let $W_{t}$ be a standard Brownian motion (BM), and consider the one-dimensional Itô diffusion given by the Stochastic Differential Equation (SDE)\n$$\n\\mathrm{d}X_{t} \\;=\\; \\mu\\,\\mathrm{d}t \\;+\\; \\sigma\\,\\mathrm{d}W_{t}, \\qquad X_{0}=x,\n$$\nwhere $\\mu \\in \\mathbb{R}$ and $\\sigma0$ are constants. Let the infinitesimal generator $\\mathcal{L}$ of this diffusion act on twice continuously differentiable functions $\\varphi$ by\n$$\n\\mathcal{L}\\varphi(x) \\;=\\; \\mu\\,\\varphi'(x) \\;+\\; \\frac{1}{2}\\,\\sigma^{2}\\,\\varphi''(x).\n$$\nFix $\\alpha \\in \\mathbb{R}$ and define $f(y)=\\exp(\\alpha y)$. For $t\\geq 0$ and $x\\in\\mathbb{R}$, define\n$$\nu(t,x) \\;=\\; \\mathbb{E}^{x}\\!\\left[f\\!\\left(X_{t}\\right)\\right],\n$$\nwhere $\\mathbb{E}^{x}$ denotes expectation for the process started at $X_{0}=x$.\n\nUsing only foundational tools appropriate to this setting (notably, the definition of the generator for Itô diffusions, the distributional properties of Brownian motion, Itô's formula, and standard differentiation rules under the expectation justified by dominated convergence for this choice of $f$), perform the following:\n\n- Compute $u(t,x)$ explicitly.\n- Compute $u_{t}(t,x)$ and $\\mathcal{L}u(t,x)$.\n- Verify directly that $u_{t}(t,x)=\\mathcal{L}u(t,x)$ for all $t0$ and $x\\in\\mathbb{R}$, and that $u(0,x)=f(x)$.\n\nYour final answer must be the closed-form expression you obtain for $u(t,x)$. No numerical rounding is required.", "solution": "The problem is subjected to validation.\n\n### Step 1: Extract Givens\n- The stochastic process $X_t$ is an Itô diffusion described by the stochastic differential equation (SDE):\n$$\n\\mathrm{d}X_{t} \\;=\\; \\mu\\,\\mathrm{d}t \\;+\\; \\sigma\\,\\mathrm{d}W_{t}\n$$\n- The initial condition is $X_{0}=x$.\n- $W_{t}$ is a standard one-dimensional Brownian motion.\n- $\\mu \\in \\mathbb{R}$ and $\\sigma0$ are constant parameters.\n- The infinitesimal generator $\\mathcal{L}$ for a function $\\varphi \\in C^2(\\mathbb{R})$ is defined as:\n$$\n\\mathcal{L}\\varphi(x) \\;=\\; \\mu\\,\\varphi'(x) \\;+\\; \\frac{1}{2}\\,\\sigma^{2}\\,\\varphi''(x)\n$$\n- A function $f: \\mathbb{R} \\to \\mathbb{R}$ is defined by $f(y)=\\exp(\\alpha y)$ for a fixed constant $\\alpha \\in \\mathbb{R}$.\n- A function $u(t,x)$ is defined as the expectation of $f(X_t)$ conditional on the process starting at $x$:\n$$\nu(t,x) \\;=\\; \\mathbb{E}^{x}\\!\\left[f\\!\\left(X_{t}\\right)\\right]\n$$\n- The tasks are:\n    1. Compute $u(t,x)$ explicitly.\n    2. Compute the partial derivative $u_{t}(t,x)$ and the action of the generator $\\mathcal{L}u(t,x)$.\n    3. Verify that the partial differential equation (PDE) $u_{t}(t,x)=\\mathcal{L}u(t,x)$ and the initial condition $u(0,x)=f(x)$ are satisfied.\n\n### Step 2: Validate Using Extracted Givens\n- **Scientifically Grounded:** The problem is a standard exercise in stochastic calculus, illustrating the connection between SDEs and parabolic PDEs, a concept formalized by the Feynman-Kac formula. All definitions (SDE, generator, expectation) are standard and mathematically rigorous.\n- **Well-Posed:** The problem provides all necessary information and asks for a specific function and a verification. A unique, stable, and meaningful solution exists.\n- **Objective:** The problem is stated in precise mathematical language, free from any subjectivity or ambiguity.\n\n### Step 3: Verdict and Action\nThe problem is valid. A detailed solution will be provided.\n\n### Solution\n\nThe solution proceeds by first explicitly solving the SDE, then computing the expectation to find $u(t,x)$, and finally verifying the PDE and initial condition through direct differentiation.\n\n**1. Compute $u(t,x)$ explicitly.**\n\nThe SDE for $X_t$ is given by\n$$\n\\mathrm{d}X_{t} = \\mu\\,\\mathrm{d}t + \\sigma\\,\\mathrm{d}W_{t}, \\quad X_{0}=x.\n$$\nThis is a linear SDE with constant coefficients. We can integrate it directly from $0$ to $t$:\n$$\n\\int_{0}^{t} \\mathrm{d}X_{s} = \\int_{0}^{t} \\mu\\,\\mathrm{d}s + \\int_{0}^{t} \\sigma\\,\\mathrm{d}W_{s}\n$$\n$$\nX_{t} - X_{0} = \\mu t + \\sigma (W_{t} - W_{0})\n$$\nGiven that $X_{0}=x$ and $W_{0}=0$ almost surely for a standard Brownian motion, the explicit solution for the process $X_t$ is:\n$$\nX_{t} = x + \\mu t + \\sigma W_{t}\n$$\nA standard Brownian motion $W_t$ is a Gaussian process. For any fixed $t0$, the random variable $W_t$ is normally distributed with mean $0$ and variance $t$, i.e., $W_t \\sim \\mathcal{N}(0, t)$. Since $X_t$ is a linear transformation of the normally distributed random variable $W_t$, $X_t$ is also normally distributed. We compute its mean and variance:\nThe mean of $X_t$ is\n$$\n\\mathbb{E}^{x}[X_t] = \\mathbb{E}[x + \\mu t + \\sigma W_{t}] = x + \\mu t + \\sigma\\mathbb{E}[W_t] = x + \\mu t + \\sigma \\cdot 0 = x + \\mu t.\n$$\nThe variance of $X_t$ is\n$$\n\\mathrm{Var}^{x}(X_t) = \\mathrm{Var}(x + \\mu t + \\sigma W_{t}) = \\mathrm{Var}(\\sigma W_{t}) = \\sigma^2 \\mathrm{Var}(W_{t}) = \\sigma^2 t.\n$$\nThus, for a given starting point $x$, the random variable $X_t$ follows a normal distribution $X_t \\sim \\mathcal{N}(x + \\mu t, \\sigma^2 t)$.\n\nNow, we compute $u(t,x)$:\n$$\nu(t,x) = \\mathbb{E}^{x}[f(X_t)] = \\mathbb{E}^{x}[\\exp(\\alpha X_t)].\n$$\nThis is precisely the moment-generating function (MGF) of the normal random variable $X_t$, evaluated at $\\alpha$. The MGF of a random variable $Y \\sim \\mathcal{N}(m, s^2)$ is given by $M_Y(a) = \\mathbb{E}[\\exp(a Y)] = \\exp(am + \\frac{1}{2}a^2s^2)$.\nIn our case, $Y=X_t$, $a=\\alpha$, the mean is $m = x + \\mu t$, and the variance is $s^2 = \\sigma^2 t$. Substituting these into the MGF formula, we obtain the explicit form of $u(t,x)$:\n$$\nu(t,x) = \\exp\\left(\\alpha(x + \\mu t) + \\frac{1}{2}\\alpha^2(\\sigma^2 t)\\right) = \\exp\\left(\\alpha x + \\alpha \\mu t + \\frac{1}{2}\\alpha^2 \\sigma^2 t\\right).\n$$\n\n**2. Compute $u_t(t,x)$ and $\\mathcal{L}u(t,x)$.**\n\nWe first compute the partial derivative of $u(t,x)$ with respect to $t$. For clarity, we can write $u(t,x)$ as:\n$$\nu(t,x) = \\exp(\\alpha x) \\exp\\left(\\left(\\alpha \\mu + \\frac{1}{2}\\alpha^2 \\sigma^2\\right)t\\right).\n$$\nDifferentiating with respect to $t$:\n$$\nu_{t}(t,x) = \\frac{\\partial}{\\partial t}u(t,x) = \\exp(\\alpha x) \\cdot \\frac{\\mathrm{d}}{\\mathrm{d}t}\\left[\\exp\\left(\\left(\\alpha \\mu + \\frac{1}{2}\\alpha^2 \\sigma^2\\right)t\\right)\\right]\n$$\n$$\nu_{t}(t,x) = \\exp(\\alpha x) \\cdot \\exp\\left(\\left(\\alpha \\mu + \\frac{1}{2}\\alpha^2 \\sigma^2\\right)t\\right) \\cdot \\left(\\alpha \\mu + \\frac{1}{2}\\alpha^2 \\sigma^2\\right)\n$$\n$$\nu_{t}(t,x) = \\left(\\alpha \\mu + \\frac{1}{2}\\alpha^2 \\sigma^2\\right) u(t,x).\n$$\n\nNext, we compute $\\mathcal{L}u(t,x)$. The operator $\\mathcal{L}$ acts on the spatial variable $x$. We need the first and second partial derivatives of $u(t,x)$ with respect to $x$:\n$$\nu(t,x) = \\exp\\left(\\alpha x + \\alpha \\mu t + \\frac{1}{2}\\alpha^2 \\sigma^2 t\\right).\n$$\nThe first derivative with respect to $x$ is:\n$$\n\\frac{\\partial}{\\partial x}u(t,x) = u_x(t,x) = \\alpha \\cdot \\exp\\left(\\alpha x + \\alpha \\mu t + \\frac{1}{2}\\alpha^2 \\sigma^2 t\\right) = \\alpha u(t,x).\n$$\nThe second derivative with respect to $x$ is:\n$$\n\\frac{\\partial^2}{\\partial x^2}u(t,x) = u_{xx}(t,x) = \\alpha \\cdot \\frac{\\partial}{\\partial x}u(t,x) = \\alpha (\\alpha u(t,x)) = \\alpha^2 u(t,x).\n$$\nNow we apply the infinitesimal generator $\\mathcal{L}$:\n$$\n\\mathcal{L}u(t,x) = \\mu u_x(t,x) + \\frac{1}{2}\\sigma^2 u_{xx}(t,x)\n$$\nSubstituting the derivatives we found:\n$$\n\\mathcal{L}u(t,x) = \\mu (\\alpha u(t,x)) + \\frac{1}{2}\\sigma^2 (\\alpha^2 u(t,x))\n$$\n$$\n\\mathcal{L}u(t,x) = \\left(\\mu \\alpha + \\frac{1}{2}\\sigma^2 \\alpha^2\\right) u(t,x).\n$$\nThe differentiation under the expectation sign required for these calculations is justified by the dominated convergence theorem, as the resulting integrands are suitably bounded for any finite time interval.\n\n**3. Verify the PDE and Initial Condition.**\n\nBy comparing the expressions derived in step 2, we can directly verify the PDE:\n$$\nu_{t}(t,x) = \\left(\\alpha \\mu + \\frac{1}{2}\\alpha^2 \\sigma^2\\right) u(t,x)\n$$\n$$\n\\mathcal{L}u(t,x) = \\left(\\mu \\alpha + \\frac{1}{2}\\sigma^2 \\alpha^2\\right) u(t,x)\n$$\nIt is clear that for all $t0$ and $x\\in\\mathbb{R}$,\n$$\nu_{t}(t,x) = \\mathcal{L}u(t,x).\n$$\nThis equation is the Kolmogorov backward equation for this diffusion process.\n\nFinally, we verify the initial condition at $t=0$:\n$$\nu(0,x) = \\exp\\left(\\alpha x + \\alpha \\mu (0) + \\frac{1}{2}\\alpha^2 \\sigma^2 (0)\\right) = \\exp(\\alpha x).\n$$\nBy definition, $f(x) = \\exp(\\alpha x)$. Therefore, we have verified that\n$$\nu(0,x) = f(x).\n$$\nThe function $u(t,x)$ is thus the solution to the Cauchy problem for the PDE $\\frac{\\partial u}{\\partial t} = \\mathcal{L}u$ with initial condition $u(0,x)=f(x)$.\n\nThe final answer is the explicit form of $u(t,x)$.", "answer": "$$\\boxed{\\exp\\left(\\alpha x + \\alpha \\mu t + \\frac{1}{2}\\alpha^2 \\sigma^2 t\\right)}$$", "id": "3070563"}, {"introduction": "While the probabilistic method provides a powerful new perspective, it's essential to see how it aligns with classical techniques for solving PDEs. This practice problem focuses on the fundamental heat equation, challenging you to derive its solution in two distinct ways: first, using the traditional method of convolving the initial data with the heat kernel, and second, by computing the expectation of the initial data evaluated on a Brownian path [@problem_id:3070547]. Verifying that both paths lead to the identical result solidifies the equivalence of these two powerful viewpoints.", "problem": "Consider one-dimensional standard Brownian motion $B_{t}$ and the simple diffusion $X_{t} = x + B_{t}$ starting from $X_{0} = x \\in \\mathbb{R}$. Let $u(t,x)$ be the solution to the initial value problem for the parabolic partial differential equation (PDE)\n$$\n\\frac{\\partial}{\\partial t} u(t,x) = \\frac{1}{2} \\frac{\\partial^{2}}{\\partial x^{2}} u(t,x), \\quad u(0,x) = f(x),\n$$\nwhere the initial data is\n$$\nf(y) = \\exp\\!\\big(-\\alpha y^{2} + \\beta y\\big),\n$$\nwith $\\alpha  0$ and $\\beta \\in \\mathbb{R}$. The transition probability density $p(t,x,y)$ of $X_{t}$ is\n$$\np(t,x,y) = \\frac{1}{\\sqrt{2\\pi t}} \\exp\\!\\left(-\\frac{(y-x)^{2}}{2t}\\right), \\quad t0.\n$$\n\nStarting from foundational facts about Brownian motion and heat kernels, and without appealing to any pre-stated solution formulas for $u$, do the following:\n\n1. Compute $u(t,x)$ for $t0$ and $x \\in \\mathbb{R}$ by integrating the initial data $f$ against the transition density $p$, that is,\n$$\nu(t,x) = \\int_{\\mathbb{R}} f(y)\\, p(t,x,y)\\, \\mathrm{d}y.\n$$\nExpress your final result as a single closed-form analytic expression in terms of $t$, $x$, $\\alpha$, and $\\beta$.\n\n2. Using the probabilistic representation for parabolic PDEs, verify that the same $u(t,x)$ can be written as the expectation\n$$\nu(t,x) = \\mathbb{E}\\!\\left[f(X_{t})\\right],\n$$\nand evaluate the expectation directly to obtain the identical closed-form expression found in Part 1.\n\nYour final answer must be a single analytic expression for $u(t,x)$ with no units. No numerical rounding is required.", "solution": "The problem is validated as self-contained, scientifically grounded in the theory of stochastic differential equations and parabolic PDEs, and well-posed. The initial data is a smooth function ensuring the existence and uniqueness of the solution to the heat equation. The tasks are mathematically rigorous and do not contain any inconsistencies or ambiguities.\n\nThe solution will be derived in two parts as requested by the problem statement.\n\nPart 1: Computation via Convolution Integral\n\nThe solution $u(t,x)$ to the initial value problem is given by the convolution of the initial data $f(x)$ with the heat kernel, which is the transition probability density $p(t,x,y)$ of the underlying stochastic process $X_t = x+B_t$. The formula is:\n$$\nu(t,x) = \\int_{-\\infty}^{\\infty} f(y)\\, p(t,x,y)\\, \\mathrm{d}y\n$$\nSubstituting the given expressions for $f(y)$ and $p(t,x,y)$:\n$$\nf(y) = \\exp(-\\alpha y^{2} + \\beta y)\n$$\n$$\np(t,x,y) = \\frac{1}{\\sqrt{2\\pi t}} \\exp\\left(-\\frac{(y-x)^{2}}{2t}\\right)\n$$\nThe integral for $u(t,x)$ becomes:\n$$\nu(t,x) = \\int_{-\\infty}^{\\infty} \\exp(-\\alpha y^{2} + \\beta y) \\frac{1}{\\sqrt{2\\pi t}} \\exp\\left(-\\frac{(y-x)^{2}}{2t}\\right) \\mathrm{d}y\n$$\nWe can combine the arguments of the exponential functions:\n$$\n-\\alpha y^{2} + \\beta y - \\frac{(y-x)^{2}}{2t} = -\\alpha y^{2} + \\beta y - \\frac{y^2 - 2xy + x^2}{2t}\n$$\nGrouping terms by powers of $y$:\n$$\n= -\\left(\\alpha + \\frac{1}{2t}\\right)y^2 + \\left(\\beta + \\frac{2x}{2t}\\right)y - \\frac{x^2}{2t}\n$$\n$$\n= -\\left(\\frac{2t\\alpha + 1}{2t}\\right)y^2 + \\left(\\frac{t\\beta + x}{t}\\right)y - \\frac{x^2}{2t}\n$$\nTo evaluate the integral, we complete the square for the terms involving $y$. Let the exponent be written as $-A y^2 + B y + C$, where:\n$$\nA = \\frac{2t\\alpha + 1}{2t}, \\quad B = \\frac{t\\beta + x}{t}, \\quad C = -\\frac{x^2}{2t}\n$$\nThe expression $-A y^2 + B y$ can be rewritten as:\n$$\n-A\\left(y^2 - \\frac{B}{A}y\\right) = -A\\left(\\left(y - \\frac{B}{2A}\\right)^2 - \\frac{B^2}{4A^2}\\right) = -A\\left(y - \\frac{B}{2A}\\right)^2 + \\frac{B^2}{4A}\n$$\nSo the full exponent is $-A\\left(y - \\frac{B}{2A}\\right)^2 + \\frac{B^2}{4A} + C$. The integral becomes:\n$$\nu(t,x) = \\frac{1}{\\sqrt{2\\pi t}} \\int_{-\\infty}^{\\infty} \\exp\\left(-A\\left(y - \\frac{B}{2A}\\right)^2 + \\frac{B^2}{4A} + C\\right) \\mathrm{d}y\n$$\nThe term $\\exp\\left(\\frac{B^2}{4A} + C\\right)$ is constant with respect to $y$ and can be moved outside the integral:\n$$\nu(t,x) = \\frac{1}{\\sqrt{2\\pi t}} \\exp\\left(\\frac{B^2}{4A} + C\\right) \\int_{-\\infty}^{\\infty} \\exp\\left(-A\\left(y - \\frac{B}{2A}\\right)^2\\right) \\mathrm{d}y\n$$\nThe integral is a standard Gaussian integral of the form $\\int_{-\\infty}^{\\infty} \\exp(-A z^2) \\mathrm{d}z = \\sqrt{\\frac{\\pi}{A}}$, for $A > 0$. Here $A = \\frac{1+2t\\alpha}{2t} > 0$ since $t>0$ and $\\alpha>0$.\n$$\n\\int_{-\\infty}^{\\infty} \\exp\\left(-A\\left(y - \\frac{B}{2A}\\right)^2\\right) \\mathrm{d}y = \\sqrt{\\frac{\\pi}{A}}\n$$\nSubstituting this back into the expression for $u(t,x)$:\n$$\nu(t,x) = \\frac{1}{\\sqrt{2\\pi t}} \\exp\\left(\\frac{B^2}{4A} + C\\right) \\sqrt{\\frac{\\pi}{A}} = \\frac{1}{\\sqrt{2tA}} \\exp\\left(\\frac{B^2}{4A} + C\\right)\n$$\nNow, we substitute the expressions for $A$, $B$, and $C$.\nFirst, the pre-factor:\n$$\n\\frac{1}{\\sqrt{2tA}} = \\frac{1}{\\sqrt{2t \\left(\\frac{1+2t\\alpha}{2t}\\right)}} = \\frac{1}{\\sqrt{1+2t\\alpha}}\n$$\nNext, the argument of the exponential, $\\frac{B^2}{4A} + C$:\n$$\nB^2 = \\left(\\frac{t\\beta + x}{t}\\right)^2 = \\frac{t^2\\beta^2 + 2t\\beta x + x^2}{t^2}\n$$\n$$\n4A = 4\\left(\\frac{1+2t\\alpha}{2t}\\right) = \\frac{2(1+2t\\alpha)}{t}\n$$\n$$\n\\frac{B^2}{4A} = \\frac{t^2\\beta^2 + 2t\\beta x + x^2}{t^2} \\cdot \\frac{t}{2(1+2t\\alpha)} = \\frac{t^2\\beta^2 + 2t\\beta x + x^2}{2t(1+2t\\alpha)}\n$$\nNow adding $C = -\\frac{x^2}{2t}$:\n$$\n\\frac{B^2}{4A} + C = \\frac{t^2\\beta^2 + 2t\\beta x + x^2}{2t(1+2t\\alpha)} - \\frac{x^2}{2t} = \\frac{t^2\\beta^2 + 2t\\beta x + x^2 - x^2(1+2t\\alpha)}{2t(1+2t\\alpha)}\n$$\n$$\n= \\frac{t^2\\beta^2 + 2t\\beta x + x^2 - x^2 - 2t\\alpha x^2}{2t(1+2t\\alpha)} = \\frac{t^2\\beta^2 + 2t\\beta x - 2t\\alpha x^2}{2t(1+2t\\alpha)}\n$$\nDividing the numerator and denominator by $t$ (since $t>0$):\n$$\n= \\frac{t\\beta^2 + 2\\beta x - 2\\alpha x^2}{2(1+2t\\alpha)}\n$$\nCombining the pre-factor and the exponential part, we get the solution:\n$$\nu(t,x) = \\frac{1}{\\sqrt{1+2t\\alpha}} \\exp\\left(\\frac{t\\beta^2 + 2\\beta x - 2\\alpha x^2}{2(1+2t\\alpha)}\\right)\n$$\n\nPart 2: Computation via Probabilistic Representation\n\nThe Feynman-Kac formula provides a probabilistic representation for the solution of this parabolic PDE:\n$$\nu(t,x) = \\mathbb{E}\\left[f(X_t) \\mid X_0 = x\\right]\n$$\nGiven $X_t = x + B_t$, where $B_t$ is a standard one-dimensional Brownian motion, we have $X_t \\sim N(x, t)$. We need to calculate:\n$$\nu(t,x) = \\mathbb{E}\\left[ \\exp(-\\alpha X_t^2 + \\beta X_t) \\right]\n$$\nSubstituting $X_t = x + B_t$:\n$$\nu(t,x) = \\mathbb{E}\\left[ \\exp(-\\alpha (x+B_t)^2 + \\beta (x+B_t)) \\right]\n$$\nLet's expand the argument of the exponential:\n$$\n-\\alpha(x^2 + 2xB_t + B_t^2) + \\beta(x+B_t) = -\\alpha x^2 - 2\\alpha x B_t - \\alpha B_t^2 + \\beta x + \\beta B_t\n$$\n$$\n= (-\\alpha x^2 + \\beta x) + (\\beta - 2\\alpha x)B_t - \\alpha B_t^2\n$$\nThe term $(-\\alpha x^2 + \\beta x)$ is deterministic and can be factored out of the expectation:\n$$\nu(t,x) = \\exp(-\\alpha x^2 + \\beta x) \\, \\mathbb{E}\\left[ \\exp((\\beta - 2\\alpha x)B_t - \\alpha B_t^2) \\right]\n$$\nLet's compute the expectation. The random variable $B_t$ follows a normal distribution with mean $0$ and variance $t$, so its probability density function is $\\phi(z; t) = \\frac{1}{\\sqrt{2\\pi t}} \\exp\\left(-\\frac{z^2}{2t}\\right)$. The expectation is given by the integral:\n$$\n\\mathbb{E}[\\dots] = \\int_{-\\infty}^{\\infty} \\exp((\\beta - 2\\alpha x)z - \\alpha z^2) \\frac{1}{\\sqrt{2\\pi t}} \\exp\\left(-\\frac{z^2}{2t}\\right) \\mathrm{d}z\n$$\nLet's combine the exponents:\n$$\n(\\beta - 2\\alpha x)z - \\alpha z^2 - \\frac{z^2}{2t} = - \\left(\\alpha + \\frac{1}{2t}\\right)z^2 + (\\beta - 2\\alpha x)z\n$$\nThis is another Gaussian integral. Let the exponent be $-A'z^2 + B'z$, where:\n$$\nA' = \\alpha + \\frac{1}{2t} = \\frac{1+2t\\alpha}{2t}, \\quad B' = \\beta - 2\\alpha x\n$$\nCompleting the square: $-A'(z^2 - \\frac{B'}{A'}z) = -A'\\left(z - \\frac{B'}{2A'}\\right)^2 + \\frac{(B')^2}{4A'}$.\nThe integral for the expectation becomes:\n$$\n\\frac{1}{\\sqrt{2\\pi t}} \\int_{-\\infty}^{\\infty} \\exp\\left(-A'\\left(z - \\frac{B'}{2A'}\\right)^2 + \\frac{(B')^2}{4A'}\\right) \\mathrm{d}z\n$$\n$$\n= \\frac{1}{\\sqrt{2\\pi t}} \\exp\\left(\\frac{(B')^2}{4A'}\\right) \\int_{-\\infty}^{\\infty} \\exp\\left(-A'\\left(z - \\frac{B'}{2A'}\\right)^2\\right) \\mathrm{d}z\n$$\nThe integral evaluates to $\\sqrt{\\pi/A'}$. Thus, the expectation is:\n$$\n\\mathbb{E}[\\dots] = \\frac{1}{\\sqrt{2\\pi t}} \\exp\\left(\\frac{(B')^2}{4A'}\\right) \\sqrt{\\frac{\\pi}{A'}} = \\frac{1}{\\sqrt{2tA'}} \\exp\\left(\\frac{(B')^2}{4A'}\\right)\n$$\nSubstitute back $A'$ and $B'$. The pre-factor is:\n$$\n\\frac{1}{\\sqrt{2tA'}} = \\frac{1}{\\sqrt{2t\\left(\\frac{1+2t\\alpha}{2t}\\right)}} = \\frac{1}{\\sqrt{1+2t\\alpha}}\n$$\nThe argument of the exponential is:\n$$\n\\frac{(B')^2}{4A'} = \\frac{(\\beta-2\\alpha x)^2}{4\\left(\\frac{1+2t\\alpha}{2t}\\right)} = \\frac{t(\\beta-2\\alpha x)^2}{2(1+2t\\alpha)} = \\frac{t(\\beta^2 - 4\\alpha\\beta x + 4\\alpha^2 x^2)}{2(1+2t\\alpha)}\n$$\nSo the expectation is:\n$$\n\\mathbb{E}[\\dots] = \\frac{1}{\\sqrt{1+2t\\alpha}} \\exp\\left(\\frac{t\\beta^2 - 4t\\alpha\\beta x + 4t\\alpha^2 x^2}{2(1+2t\\alpha)}\\right)\n$$\nFinally, we multiply by the deterministic term we factored out earlier:\n$$\nu(t,x) = \\exp(-\\alpha x^2 + \\beta x) \\cdot \\frac{1}{\\sqrt{1+2t\\alpha}} \\exp\\left(\\frac{t\\beta^2 - 4t\\alpha\\beta x + 4t\\alpha^2 x^2}{2(1+2t\\alpha)}\\right)\n$$\n$$\nu(t,x) = \\frac{1}{\\sqrt{1+2t\\alpha}} \\exp\\left(-\\alpha x^2 + \\beta x + \\frac{t\\beta^2 - 4t\\alpha\\beta x + 4t\\alpha^2 x^2}{2(1+2t\\alpha)}\\right)\n$$\nLet's combine the exponents by finding a common denominator $2(1+2t\\alpha)$:\n$$\n\\text{Exponent} = \\frac{(-\\alpha x^2 + \\beta x) \\cdot 2(1+2t\\alpha) + t\\beta^2 - 4t\\alpha\\beta x + 4t\\alpha^2 x^2}{2(1+2t\\alpha)}\n$$\n$$\n= \\frac{-2\\alpha x^2 - 4t\\alpha^2 x^2 + 2\\beta x + 4t\\alpha\\beta x + t\\beta^2 - 4t\\alpha\\beta x + 4t\\alpha^2 x^2}{2(1+2t\\alpha)}\n$$\n$$\n= \\frac{-2\\alpha x^2 + 2\\beta x + t\\beta^2}{2(1+2t\\alpha)}\n$$\nThe final expression for $u(t,x)$ is:\n$$\nu(t,x) = \\frac{1}{\\sqrt{1+2t\\alpha}} \\exp\\left(\\frac{t\\beta^2 + 2\\beta x - 2\\alpha x^2}{2(1+2t\\alpha)}\\right)\n$$\nThis result is identical to the one obtained in Part 1, verifying the consistency of both approaches.", "answer": "$$\\boxed{\\frac{1}{\\sqrt{1+2t\\alpha}}\\exp\\left(\\frac{t\\beta^2 + 2\\beta x - 2\\alpha x^2}{2(1+2t\\alpha)}\\right)}$$", "id": "3070547"}, {"introduction": "The power of the probabilistic representation extends beyond homogeneous equations, which describe systems evolving without external influences. Real-world models often include source terms, leading to inhomogeneous PDEs. This exercise demonstrates how the Feynman-Kac framework elegantly incorporates such terms through an application of Duhamel's principle in a probabilistic setting [@problem_id:3070555]. You will construct the solution by combining the expectation of the initial condition with an integral over time of expectations involving the source term.", "problem": "Let $X_{s}$ be the one-dimensional solution to the stochastic differential equation (SDE) $dX_{s} = dW_{s}$ with $X_{0} = x$, where $W_{s}$ is a standard Brownian motion. Let $\\{P_{t}\\}_{t \\geq 0}$ denote the associated Markov semigroup acting on bounded measurable functions $\\varphi$ by $P_{t}\\varphi(x) = \\mathbb{E}^{x}[\\varphi(X_{t})]$. Consider the parabolic partial differential equation (PDE)\n$$\n\\partial_{t} u(t,x) = \\frac{1}{2}\\,\\partial_{xx} u(t,x) + g_{0}(x), \\qquad u(0,x) = f(x),\n$$\non $\\mathbb{R}$, where $V \\equiv 0$ (no potential term). Using the probabilistic representation of solutions based on the Markov semigroup and the Feynman–Kac formula (FK) for $V \\equiv 0$, derive $u(t,x)$ from first principles and compute it explicitly for the choice $f(x) = \\exp(a x)$ and $g_{0}(x) = \\exp(b x)$, where $a$ and $b$ are fixed real constants with $b \\neq 0$. Express your final answer as a single closed-form analytic expression in terms of $a$, $b$, $x$, and $t$. No rounding is required, and no units are involved.", "solution": "The problem statement is parsed and validated as follows.\n\n### Step 1: Extract Givens\n- Stochastic Differential Equation (SDE): $dX_{s} = dW_{s}$\n- Initial condition for the SDE: $X_{0} = x$\n- $W_{s}$ is a standard one-dimensional Brownian motion.\n- Markov semigroup definition: $P_{t}\\varphi(x) = \\mathbb{E}^{x}[\\varphi(X_{t})]$ for a bounded measurable function $\\varphi$.\n- Parabolic Partial Differential Equation (PDE): $\\partial_{t} u(t,x) = \\frac{1}{2}\\,\\partial_{xx} u(t,x) + g_{0}(x)$\n- Initial condition for the PDE: $u(0,x) = f(x)$\n- Domain: $(t,x) \\in [0, \\infty) \\times \\mathbb{R}$\n- Potential term: $V \\equiv 0$\n- Specific initial condition function: $f(x) = \\exp(ax)$\n- Specific source term function: $g_{0}(x) = \\exp(bx)$\n- Constants: $a, b \\in \\mathbb{R}$ with the constraint $b \\neq 0$.\n\n### Step 2: Validate Using Extracted Givens\nThe problem is scientifically and mathematically sound. It poses a standard question in the theory of stochastic differential equations and their connection to partial differential equations. The Feynman–Kac formula provides a well-established bridge between the solution of a parabolic PDE and the expectation of a functional of a stochastic process. The given SDE describes a standard Brownian motion, and the PDE is the inhomogeneous heat equation. The functions $f(x)$ and $g_{0}(x)$ are exponential functions, which are smooth and well-behaved, ensuring that the necessary expectations are well-defined (provided any growth conditions are met, which is implicitly handled by the probabilistic framework). All components of the problem are precisely defined, self-contained, and consistent. The problem is a standard exercise in applying the Feynman-Kac theorem and is neither trivial nor ill-posed.\n\n### Step 3: Verdict and Action\nThe problem is valid. A complete solution will be provided.\n\n### Derivation of the Solution\n\nThe problem asks for the solution $u(t,x)$ to the parabolic PDE:\n$$\n\\partial_{t} u(t,x) = \\frac{1}{2}\\,\\partial_{xx} u(t,x) + g_{0}(x), \\quad u(0,x) = f(x)\n$$\nThe generator of the stochastic process $X_s$ defined by $dX_s = dW_s$ is the operator $\\mathcal{L} = \\frac{1}{2}\\partial_{xx}$. The PDE can thus be written as $\\partial_t u = \\mathcal{L} u + g_0$.\n\nThe probabilistic representation of the solution to this initial value problem, which is a direct consequence of the Feynman-Kac formula (or can be seen as an application of Duhamel's principle for the semigroup $P_t$), is given by:\n$$\nu(t,x) = P_t f(x) + \\int_0^t P_s g_0(x) ds\n$$\nwhere $P_t$ is the Markov semigroup associated with the process $X_s$. Using the definition of the semigroup, $P_t \\varphi(x) = \\mathbb{E}^x[\\varphi(X_t)]$, we can write the solution as:\n$$\nu(t,x) = \\mathbb{E}^{x}[f(X_{t})] + \\int_{0}^{t} \\mathbb{E}^{x}[g_{0}(X_{s})] ds\n$$\nHere, $\\mathbb{E}^{x}[\\cdot]$ denotes the expectation conditional on the process starting at $X_0 = x$.\n\nFirst, we must characterize the process $X_s$. The SDE is $dX_s = dW_s$ with $X_0 = x$. Integrating from $0$ to $s$ yields:\n$$\nX_s - X_0 = \\int_0^s dW_u = W_s - W_0\n$$\nSince $W_s$ is a standard Brownian motion, $W_0=0$. Therefore, the solution to the SDE is $X_s = x + W_s$. The random variable $W_s$ is normally distributed with mean $0$ and variance $s$, i.e., $W_s \\sim \\mathcal{N}(0, s)$. Consequently, $X_s$ follows a normal distribution $X_s \\sim \\mathcal{N}(x, s)$.\n\nWe will now compute the two terms of the solution $u(t,x)$ separately.\n\n**Term 1: The homogeneous part**\n\nThe first term is $\\mathbb{E}^x[f(X_t)]$. With $f(x) = \\exp(ax)$ and $X_t = x + W_t$, this term becomes:\n$$\n\\mathbb{E}^{x}[f(X_{t})] = \\mathbb{E}[\\exp(a(x+W_t)) | X_0=x] = \\mathbb{E}[\\exp(ax)\\exp(aW_t)] = \\exp(ax) \\mathbb{E}[\\exp(aW_t)]\n$$\nThe expectation $\\mathbb{E}[\\exp(aW_t)]$ is the moment-generating function (MGF) of the random variable $W_t \\sim \\mathcal{N}(0, t)$, evaluated at $a$. The MGF of a general normal random variable $Y \\sim \\mathcal{N}(\\mu, \\sigma^2)$ is $M_Y(k) = \\mathbb{E}[\\exp(kY)] = \\exp(k\\mu + \\frac{1}{2}k^2\\sigma^2)$.\nFor $W_t$, we have $\\mu=0$ and $\\sigma^2=t$. Applying this formula with $k=a$:\n$$\n\\mathbb{E}[\\exp(aW_t)] = \\exp(a \\cdot 0 + \\frac{1}{2}a^2t) = \\exp(\\frac{1}{2}a^2t)\n$$\nSubstituting this back, the first term is:\n$$\n\\mathbb{E}^{x}[f(X_{t})] = \\exp(ax) \\exp(\\frac{1}{2}a^2t) = \\exp(ax + \\frac{1}{2}a^2t)\n$$\n\n**Term 2: The inhomogeneous part**\n\nThe second term is $\\int_{0}^{t} \\mathbb{E}^{x}[g_{0}(X_{s})] ds$. With $g_0(x) = \\exp(bx)$, the integrand is $\\mathbb{E}^{x}[\\exp(bX_s)]$.\nThe calculation is analogous to the one for Term 1, with the variable $s$ replacing the fixed time $t$ and the constant $b$ replacing $a$.\n$$\n\\mathbb{E}^{x}[g_{0}(X_{s})] = \\mathbb{E}^{x}[\\exp(bX_s)] = \\mathbb{E}[\\exp(b(x+W_s)) | X_0=x] = \\exp(bx)\\mathbb{E}[\\exp(bW_s)]\n$$\nUsing the MGF of $W_s \\sim \\mathcal{N}(0, s)$ evaluated at $b$:\n$$\n\\mathbb{E}[\\exp(bW_s)] = \\exp(b \\cdot 0 + \\frac{1}{2}b^2s) = \\exp(\\frac{1}{2}b^2s)\n$$\nThus, the integrand is:\n$$\n\\mathbb{E}^{x}[g_{0}(X_{s})] = \\exp(bx)\\exp(\\frac{1}{2}b^2s) = \\exp(bx + \\frac{1}{2}b^2s)\n$$\nNow, we integrate this expression with respect to $s$ from $0$ to $t$:\n$$\n\\int_{0}^{t} \\exp(bx + \\frac{1}{2}b^2s) ds = \\exp(bx) \\int_{0}^{t} \\exp(\\frac{1}{2}b^2s) ds\n$$\nThe problem specifies that $b \\neq 0$, so $\\frac{1}{2}b^2 \\neq 0$. The integral is elementary:\n$$\n\\int_{0}^{t} \\exp(\\frac{1}{2}b^2s) ds = \\left[ \\frac{1}{\\frac{1}{2}b^2} \\exp(\\frac{1}{2}b^2s) \\right]_{s=0}^{s=t} = \\frac{2}{b^2} \\left( \\exp(\\frac{1}{2}b^2t) - \\exp(0) \\right) = \\frac{2}{b^2} \\left( \\exp(\\frac{1}{2}b^2t) - 1 \\right)\n$$\nTherefore, the second term is:\n$$\n\\int_{0}^{t} \\mathbb{E}^{x}[g_{0}(X_{s})] ds = \\exp(bx) \\cdot \\frac{2}{b^2} \\left( \\exp(\\frac{1}{2}b^2t) - 1 \\right) = \\frac{2}{b^2} \\left( \\exp(bx + \\frac{1}{2}b^2t) - \\exp(bx) \\right)\n$$\n\n**Final Solution**\n\nCombining the two terms gives the complete solution $u(t,x)$:\n$$\nu(t,x) = \\mathbb{E}^{x}[f(X_t)] + \\int_{0}^{t} \\mathbb{E}^{x}[g_{0}(X_{s})] ds\n$$\n$$\nu(t,x) = \\exp(ax + \\frac{1}{2}a^2t) + \\frac{2}{b^2} \\left( \\exp(bx + \\frac{1}{2}b^2t) - \\exp(bx) \\right)\n$$\nThis expression is the closed-form analytical solution for $u(t,x)$ in terms of the given parameters $a$, $b$, $x$, and $t$.", "answer": "$$\\boxed{\\exp(ax + \\frac{1}{2}a^2t) + \\frac{2}{b^2} \\left( \\exp(bx + \\frac{1}{2}b^2t) - \\exp(bx) \\right)}$$", "id": "3070555"}]}