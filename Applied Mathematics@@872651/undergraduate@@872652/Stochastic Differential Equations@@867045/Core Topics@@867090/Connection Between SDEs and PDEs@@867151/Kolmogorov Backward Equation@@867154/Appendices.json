{"hands_on_practices": [{"introduction": "The heart of the Kolmogorov backward equation (KBE) is the infinitesimal generator, an operator that captures the expected instantaneous change of a function along the paths of a stochastic process. This first exercise provides essential practice in computing the generator directly from its definition and the underlying stochastic differential equation. Mastering this connection [@problem_id:3062743] is the first step toward wielding the full power of the KBE.", "problem": "Consider the one-dimensional stochastic differential equation (SDE) in $\\mathbb{R}$ given by\n$$\ndX_t = b X_t \\, dt + \\sigma \\, dW_t,\n$$\nwhere $b \\in \\mathbb{R}$ and $\\sigma  0$ are constants, and $W_t$ is a standard Brownian motion. Let $f:\\mathbb{R}\\to\\mathbb{R}$ be defined by $f(x)=|x|^2$. Using only foundational tools of stochastic calculus and the definition of the infinitesimal generator arising in the Kolmogorov backward equation (KBE), derive from first principles the explicit form of the infinitesimal generator $\\mathcal{L}$ applied to $f$, that is, compute $\\mathcal{L}f(x)$.\n\nExpress your final answer as a single simplified analytic expression in terms of $x$, $b$, and $\\sigma$. No numerical evaluation or rounding is required.", "solution": "The problem requires the derivation of the explicit form of the infinitesimal generator $\\mathcal{L}$ applied to the function $f(x) = |x|^2$ for the stochastic differential equation (SDE) $dX_t = b X_t \\, dt + \\sigma \\, dW_t$. The derivation must be from first principles, using the definition of the generator.\n\nThe infinitesimal generator $\\mathcal{L}$ of a time-homogeneous Markov process $X_t$ is defined by its action on a suitable function $f$. For a process starting at $X_0 = x$, the definition is:\n$$\n\\mathcal{L}f(x) = \\lim_{h \\to 0^+} \\frac{\\mathbb{E}[f(X_h) | X_0=x] - f(x)}{h}\n$$\nprovided this limit exists. The notation $\\mathbb{E}[ \\cdot | X_0=x]$ denotes the expectation conditioned on the process starting at the point $x \\in \\mathbb{R}$.\n\nThe given SDE is a one-dimensional Itô process:\n$$\ndX_t = b X_t \\, dt + \\sigma \\, dW_t\n$$\nThis has a drift coefficient $\\mu(X_t) = bX_t$ and a constant diffusion coefficient $\\nu(X_t) = \\sigma$. Note that the standard notation often uses $\\sigma(x)$ for the diffusion coefficient, but to avoid confusion with the given constant $\\sigma$, we will use $\\nu(x)$ and set $\\nu(x)=\\sigma$.\n\nThe function under consideration is $f(x) = |x|^2$. Since $x$ is a real variable, this is equivalent to $f(x) = x^2$. This function is in $C^2(\\mathbb{R})$, the space of twice continuously differentiable functions, which is typically the domain of the infinitesimal generator for diffusion processes. The derivatives of $f(x)$ are $f'(x) = 2x$ and $f''(x) = 2$.\n\nTo compute the expectation $\\mathbb{E}[f(X_h) | X_0=x]$, we can analyze the dynamics of the process $f(X_t)$ using Itô's lemma, which is a foundational tool in stochastic calculus. For a function $f(x)$ and an Itô process $X_t$ with drift $\\mu(X_t)$ and diffusion $\\nu(X_t)$, Itô's lemma states:\n$$\ndf(X_t) = \\left( \\mu(X_t) f'(X_t) + \\frac{1}{2} \\nu(X_t)^2 f''(X_t) \\right) dt + \\nu(X_t) f'(X_t) dW_t\n$$\nSubstituting our specific drift $\\mu(X_t) = bX_t$, diffusion $\\nu(X_t) = \\sigma$, and the function derivatives $f'(X_t) = 2X_t$ and $f''(X_t) = 2$, we get:\n$$\nd(f(X_t)) = \\left( (bX_t)(2X_t) + \\frac{1}{2} \\sigma^2 (2) \\right) dt + \\sigma(2X_t) dW_t\n$$\nSimplifying the expression gives the SDE for $f(X_t)$:\n$$\nd(f(X_t)) = (2bX_t^2 + \\sigma^2) dt + 2\\sigma X_t dW_t\n$$\nThis equation describes the infinitesimal change in $f(X_t)$. To relate this to the definition of the generator, we can write it in integral form from time $0$ to $h$:\n$$\nf(X_h) - f(X_0) = \\int_0^h (2bX_s^2 + \\sigma^2) ds + \\int_0^h 2\\sigma X_s dW_s\n$$\nNow, we take the expectation of both sides, conditioned on $X_0 = x$. This gives:\n$$\n\\mathbb{E}[f(X_h) | X_0=x] - \\mathbb{E}[f(X_0) | X_0=x] = \\mathbb{E}\\left[\\int_0^h (2bX_s^2 + \\sigma^2) ds \\bigg| X_0=x\\right] + \\mathbb{E}\\left[\\int_0^h 2\\sigma X_s dW_s \\bigg| X_0=x\\right]\n$$\nGiven the condition $X_0=x$, $f(X_0) = f(x)$ is a deterministic constant. A fundamental property of Itô integrals is that the expectation of an Itô integral with a suitable integrand (such as $2\\sigma X_s$, which is adapted to the filtration of $W_s$) is zero. Therefore, the last term vanishes:\n$$\n\\mathbb{E}\\left[\\int_0^h 2\\sigma X_s dW_s \\bigg| X_0=x\\right] = 0\n$$\nThe equation simplifies to:\n$$\n\\mathbb{E}[f(X_h) | X_0=x] - f(x) = \\mathbb{E}\\left[\\int_0^h (2bX_s^2 + \\sigma^2) ds \\bigg| X_0=x\\right]\n$$\nNow, we substitute this into the definition of the generator:\n$$\n\\mathcal{L}f(x) = \\lim_{h \\to 0^+} \\frac{1}{h} \\mathbb{E}\\left[\\int_0^h (2bX_s^2 + \\sigma^2) ds \\bigg| X_0=x\\right]\n$$\nBy Fubini's theorem, we can interchange the expectation and the time integral:\n$$\n\\mathcal{L}f(x) = \\lim_{h \\to 0^+} \\frac{1}{h} \\int_0^h \\mathbb{E}[2bX_s^2 + \\sigma^2 | X_0=x] ds\n$$\nThe function $g(s) = \\mathbb{E}[2bX_s^2 + \\sigma^2 | X_0=x]$ is continuous with respect to $s$, because the moments of the solution to the SDE are continuous in time. By the Fundamental Theorem of Calculus (specifically, the Leibniz integral rule for differentiation under the integral sign), the limit is the value of the integrand at $s=0$:\n$$\n\\mathcal{L}f(x) = g(0) = \\mathbb{E}[2bX_0^2 + \\sigma^2 | X_0=x]\n$$\nSince $X_0=x$ is a given deterministic value, the expectation evaluates directly:\n$$\n\\mathcal{L}f(x) = 2bx^2 + \\sigma^2\n$$\nThis derivation from first principles, using Itô's lemma to analyze the expected evolution of $f(X_t)$ over an infinitesimal time interval, yields the explicit form of the generator applied to $f(x)=|x|^2=x^2$. The result is consistent with the general formula for the generator of an Itô diffusion, $\\mathcal{L} = \\mu(x)\\frac{\\partial}{\\partial x} + \\frac{1}{2}\\nu(x)^2\\frac{\\partial^2}{\\partial x^2}$, which for this problem is $\\mathcal{L} = (bx)\\frac{d}{dx} + \\frac{1}{2}\\sigma^2\\frac{d^2}{dx^2}$, yielding $(bx)(2x) + \\frac{1}{2}\\sigma^2(2) = 2bx^2 + \\sigma^2$.", "answer": "$$\\boxed{2bx^{2} + \\sigma^{2}}$$", "id": "3062743"}, {"introduction": "With an understanding of the generator, we can now assemble and solve the full Kolmogorov backward equation to compute complex expectations. This practice demonstrates how the KBE transforms a probabilistic problem—finding the expected squared distance of a Brownian particle—into a more tractable partial differential equation problem. By solving the backward heat equation [@problem_id:3062740], you will see firsthand how this powerful tool simplifies calculations and provides deep insights into the process's behavior.", "problem": "Consider a standard $d$-dimensional Brownian motion $\\{X_{s}\\}_{s \\ge 0}$ solving the stochastic differential equation (SDE) $dX_{s} = dW_{s}$, where $W_{s}$ is a standard $d$-dimensional Brownian motion and $X_{t} = x \\in \\mathbb{R}^{d}$ at time $t$. Let $T  t$ be fixed. Define the function $u(t,x)$ by\n$$\nu(t,x) := \\mathbb{E}\\!\\left[\\,|X_{T}|^{2} \\,\\big|\\, X_{t} = x \\right].\n$$\nUsing the Kolmogorov backward equation (KBE) and the generator of Brownian motion, compute $u(t,x)$ in closed form, starting from fundamental definitions (such as the infinitesimal generator and Dynkin's formula) and without assuming any explicit formula for transition densities. Then use your expression to confirm the variance growth property of Brownian motion increments by identifying $\\mathbb{E}\\!\\left[\\,|X_{T} - x|^{2} \\,\\big|\\, X_{t} = x \\right]$.\n\nYour final answer must be a single closed-form analytic expression for $u(t,x)$; do not include any intermediate results in the final answer. No rounding is required.", "solution": "The problem asks for the computation of $u(t,x) = \\mathbb{E}[|X_T|^2 \\,|\\, X_t = x]$ for a process governed by the SDE $dX_s = dW_s$ with $X_t = x$. We are to use the Kolmogorov backward equation (KBE).\n\nThe connection between conditional expectations of functionals of a diffusion process and partial differential equations (PDEs) is established by the Feynman-Kac formula. For a general Itô process $dX_s = \\mu(s, X_s) ds + \\sigma(s, X_s) dW_s$ and a function $u(t,x) = \\mathbb{E}[\\psi(X_T) \\,|\\, X_t = x]$, the function $u(t,x)$ satisfies the KBE:\n$$\n\\frac{\\partial u}{\\partial t}(t,x) + \\mathcal{A}u(t,x) = 0, \\quad t \\in [0, T)\n$$\nwith the terminal condition $u(T,x) = \\psi(x)$. Here, $\\mathcal{A}$ is the infinitesimal generator of the process $X_s$.\n\nFirst, we must determine the generator $\\mathcal{A}$ for the given process. The SDE is $dX_s = dW_s$. Comparing this to the general form, the drift vector is $\\mu(x) = 0$ (a $d$-dimensional zero vector) and the diffusion matrix is $\\sigma(x) = I_d$, the $d \\times d$ identity matrix.\n\nThe general definition of the infinitesimal generator acting on a twice continuously differentiable function $f: \\mathbb{R}^d \\to \\mathbb{R}$ is:\n$$\n\\mathcal{A}f(x) = \\sum_{i=1}^{d} \\mu_i(x) \\frac{\\partial f}{\\partial x_i}(x) + \\frac{1}{2} \\sum_{i=1}^{d} \\sum_{j=1}^{d} (\\sigma(x)\\sigma(x)^T)_{ij} \\frac{\\partial^2 f}{\\partial x_i \\partial x_j}(x)\n$$\nFor our specific process, $\\mu(x) = 0$ and $\\sigma(x)\\sigma(x)^T = I_d I_d^T = I_d$. The term $(\\sigma\\sigma^T)_{ij}$ is the Kronecker delta, $\\delta_{ij}$. Substituting these into the generator formula gives:\n$$\n\\mathcal{A}f(x) = \\sum_{i=1}^{d} 0 \\cdot \\frac{\\partial f}{\\partial x_i}(x) + \\frac{1}{2} \\sum_{i=1}^{d} \\sum_{j=1}^{d} \\delta_{ij} \\frac{\\partial^2 f}{\\partial x_i \\partial x_j}(x) = \\frac{1}{2} \\sum_{i=1}^{d} \\frac{\\partial^2 f}{\\partial x_i^2}(x) = \\frac{1}{2}\\Delta f(x)\n$$\nwhere $\\Delta$ is the Laplacian operator in $\\mathbb{R}^d$. This is the well-known generator of standard Brownian motion.\n\nNow we can state the specific PDE problem for $u(t,x)$. The terminal function is $\\psi(x) = |x|^2 = \\sum_{i=1}^d x_i^2$. The KBE becomes the backward heat equation:\n$$\n\\frac{\\partial u}{\\partial t} + \\frac{1}{2}\\Delta u = 0, \\quad \\text{for } t \\in [0, T), x \\in \\mathbb{R}^d\n$$\nwith the terminal condition:\n$$\nu(T,x) = |x|^2\n$$\nThe terminal condition is a quadratic polynomial in the components of $x$. This suggests seeking a solution that is also a polynomial in $x$, with coefficients that depend on $t$. Let us propose the following ansatz, reflecting the rotational symmetry of the problem:\n$$\nu(t,x) = A(t)|x|^2 + B(t)\n$$\nwhere $A(t)$ and $B(t)$ are functions to be determined. We compute the necessary derivatives:\n$$\n\\frac{\\partial u}{\\partial t} = A'(t)|x|^2 + B'(t)\n$$\nThe spatial derivatives are:\n$$\n\\frac{\\partial u}{\\partial x_i} = 2A(t)x_i\n$$\n$$\n\\frac{\\partial^2 u}{\\partial x_i^2} = 2A(t)\n$$\nThe Laplacian is therefore:\n$$\n\\Delta u = \\sum_{i=1}^d \\frac{\\partial^2 u}{\\partial x_i^2} = \\sum_{i=1}^d 2A(t) = 2dA(t)\n$$\nSubstituting these expressions into the KBE:\n$$\n\\left( A'(t)|x|^2 + B'(t) \\right) + \\frac{1}{2}\\left( 2dA(t) \\right) = 0\n$$\n$$\nA'(t)|x|^2 + \\left( B'(t) + dA(t) \\right) = 0\n$$\nThis equation must hold for all $x \\in \\mathbb{R}^d$. This requires the coefficients of the powers of $|x|$ to be zero independently. This yields a system of ordinary differential equations (ODEs) for $A(t)$ and $B(t)$:\n1.  $A'(t) = 0$\n2.  $B'(t) + dA(t) = 0$\n\nNow we apply the terminal condition $u(T,x) = |x|^2$:\n$$\nu(T,x) = A(T)|x|^2 + B(T) = |x|^2\n$$\nBy comparing coefficients, we obtain the terminal conditions for our ODEs:\n1.  $A(T) = 1$\n2.  $B(T) = 0$\n\nWe solve the ODE system subject to these terminal conditions.\nFrom $A'(t) = 0$, we have $A(t) = C_1$ for some constant $C_1$. Using $A(T) = 1$, we find $C_1 = 1$. Thus, $A(t) = 1$ for all $t \\le T$.\n\nSubstituting $A(t)=1$ into the second ODE gives $B'(t) + d = 0$, or $B'(t) = -d$. Integrating with respect to $t$ gives $B(t) = -dt + C_2$. Using the terminal condition $B(T)=0$, we find $0 = -dT + C_2$, so $C_2 = dT$. Thus, $B(t) = -dt + dT = d(T-t)$.\n\nCombining these results, the solution for $u(t,x)$ is:\n$$\nu(t,x) = (1)|x|^2 + d(T-t) = |x|^2 + d(T-t)\n$$\n\nThe second part of the problem asks to use this expression to identify $\\mathbb{E}[|X_T - x|^2 \\,|\\, X_t = x]$. We can expand the term inside the expectation:\n$$\n|X_T - x|^2 = (X_T - x) \\cdot (X_T - x) = |X_T|^2 - 2X_T \\cdot x + |x|^2\n$$\nBy linearity of conditional expectation:\n$$\n\\mathbb{E}[|X_T - x|^2 \\,|\\, X_t = x] = \\mathbb{E}[|X_T|^2 \\,|\\, X_t = x] - 2\\mathbb{E}[X_T \\,|\\, X_t = x] \\cdot x + \\mathbb{E}[|x|^2 \\,|\\, X_t = x]\n$$\nThe first term is simply $u(t,x) = |x|^2 + d(T-t)$.\nThe vector $x$ is a constant with respect to the expectation, so the last term is $|x|^2$.\nFor the middle term, we need to compute $\\mathbb{E}[X_T \\,|\\, X_t = x]$. The process $X_s$ satisfying $dX_s = dW_s$ is a martingale. Therefore, for $s  t$, $\\mathbb{E}[X_s \\,|\\, \\mathcal{F}_t] = X_t$. With $X_t=x$, we have:\n$$\n\\mathbb{E}[X_T \\,|\\, X_t = x] = x\n$$\nSubstituting these components back into the expression:\n$$\n\\mathbb{E}[|X_T - x|^2 \\,|\\, X_t = x] = \\left( |x|^2 + d(T-t) \\right) - 2(x \\cdot x) + |x|^2\n$$\n$$\n\\mathbb{E}[|X_T - x|^2 \\,|\\, X_t = x] = |x|^2 + d(T-t) - 2|x|^2 + |x|^2 = d(T-t)\n$$\nThis result is the mean squared displacement of the Brownian particle from its position $x$ at time $t$ over the time interval $T-t$. It confirms the well-known property that the variance of the increment of a standard Brownian motion grows linearly with the duration of the time interval.", "answer": "$$\n\\boxed{|x|^{2} + d(T-t)}\n$$", "id": "3062740"}, {"introduction": "The connection between conditional expectations and partial differential equations, formalized by the Feynman-Kac formula, is a two-way street. In this final exercise, you will approach a problem from the opposite direction: first, by directly calculating an expectation using the properties of Brownian motion, and then by verifying that your result is indeed the unique solution to the corresponding KBE. This practice [@problem_id:3062785] offers a powerful confirmation of the theory and solidifies the profound link between stochastic analysis and the world of PDEs.", "problem": "Consider the one-dimensional Itô stochastic differential equation (SDE) for a process $X_{s}$, defined for $s \\in [t,T]$, given by $dX_{s}=\\mu\\,ds+\\sigma\\,dW_{s}$, where $\\mu \\in \\mathbb{R}$ and $\\sigma0$ are constants, and $W_{s}$ is a standard Brownian motion. Assume the initial condition $X_{t}=x$. Let the terminal payoff be $\\varphi(x)=x^{2}$, and define the function $u(t,x)=\\mathbb{E}\\!\\left[\\varphi\\!\\left(X_{T}\\right)\\mid X_{t}=x\\right]$.\n\nUsing only the fundamental properties of Itô integrals, Brownian motion increments, and expectations, compute the explicit analytical expression for $u(t,x)$ as a function of $x$, $t$, $T$, $\\mu$, and $\\sigma$. Then, verify directly by differentiation that the resulting function $u$ satisfies the Kolmogorov backward equation (KBE) with constant-coefficient generator $L f=\\mu\\,\\partial_{x} f+\\frac{\\sigma^{2}}{2}\\,\\partial_{xx} f$, that is,\n$$\n\\partial_{t}u(t,x)+\\mu\\,\\partial_{x}u(t,x)+\\frac{\\sigma^{2}}{2}\\,\\partial_{xx}u(t,x)=0,\n$$\nwith terminal condition $u(T,x)=x^{2}$. In particular, show that your $u(t,x)$ is a quadratic polynomial in $x$ and $T-t$ and that it solves the above partial differential equation.\n\nYour final answer must be a single closed-form analytical expression for $u(t,x)$.", "solution": "We start from the fundamental definition of an Itô stochastic differential equation (SDE) and the properties of Brownian motion. The SDE is\n$$\ndX_{s}=\\mu\\,ds+\\sigma\\,dW_{s},\\qquad s\\in[t,T],\\quad X_{t}=x,\n$$\nwhere $W_{s}$ is a standard Brownian motion. Integrating from $t$ to $T$, we obtain\n$$\nX_{T}-X_{t}=\\int_{t}^{T}\\mu\\,ds+\\int_{t}^{T}\\sigma\\,dW_{s}=\\mu\\,(T-t)+\\sigma\\,(W_{T}-W_{t}).\n$$\nUsing $X_{t}=x$, this gives the explicit representation\n$$\nX_{T}=x+\\mu\\,(T-t)+\\sigma\\,(W_{T}-W_{t}).\n$$\nDefine $\\Delta W:=W_{T}-W_{t}$. By the basic properties of Brownian motion, $\\Delta W$ is a Gaussian random variable with mean $0$ and variance $T-t$, and it is independent of $\\mathcal{F}_{t}$. Therefore,\n$$\nu(t,x)=\\mathbb{E}\\!\\left[X_{T}^{2}\\mid X_{t}=x\\right]=\\mathbb{E}\\!\\left[\\left(x+\\mu\\,(T-t)+\\sigma\\,\\Delta W\\right)^{2}\\right].\n$$\nLet $A:=x+\\mu\\,(T-t)$. Then\n$$\nu(t,x)=\\mathbb{E}\\!\\left[(A+\\sigma\\,\\Delta W)^{2}\\right]=\\mathbb{E}\\!\\left[A^{2}+2A\\sigma\\,\\Delta W+\\sigma^{2}\\,(\\Delta W)^{2}\\right].\n$$\nUsing linearity of expectation and $\\mathbb{E}[\\Delta W]=0$, $\\mathbb{E}[(\\Delta W)^{2}]=\\mathrm{Var}(\\Delta W)=T-t$, we obtain\n$$\nu(t,x)=A^{2}+\\sigma^{2}\\,(T-t)=\\left(x+\\mu\\,(T-t)\\right)^{2}+\\sigma^{2}\\,(T-t).\n$$\nThus,\n$$\nu(t,x)=x^{2}+2\\mu\\,x\\,(T-t)+\\mu^{2}\\,(T-t)^{2}+\\sigma^{2}\\,(T-t),\n$$\nwhich is manifestly a quadratic polynomial in $x$ and $T-t$.\n\nNext, we verify that $u$ solves the Kolmogorov backward equation (KBE) with terminal condition. Introduce $\\tau:=T-t$ so that $u$ can be written as\n$$\nu(t,x)=\\left(x+\\mu\\,\\tau\\right)^{2}+\\sigma^{2}\\,\\tau.\n$$\nDifferentiate $u$ with respect to $x$ and $t$. First compute spatial derivatives. Let $A:=x+\\mu\\,\\tau$. Then\n$$\n\\partial_{x}u(t,x)=\\partial_{x}\\left(A^{2}+\\sigma^{2}\\,\\tau\\right)=2A\\cdot\\partial_{x}A=2A,\n$$\nand\n$$\n\\partial_{xx}u(t,x)=\\partial_{x}(2A)=2.\n$$\nFor the time derivative, note that $\\tau=T-t$ so $\\partial_{t}\\tau=-1$. Compute\n$$\n\\partial_{\\tau}u(t,x)=\\partial_{\\tau}\\left(A^{2}+\\sigma^{2}\\,\\tau\\right)=2A\\cdot\\partial_{\\tau}A+\\sigma^{2}=2A\\mu+\\sigma^{2},\n$$\nhence\n$$\n\\partial_{t}u(t,x)=\\partial_{\\tau}u(t,x)\\cdot\\partial_{t}\\tau=-(2\\mu\\,A+\\sigma^{2}).\n$$\nNow substitute into the KBE:\n$$\n\\partial_{t}u+\\mu\\,\\partial_{x}u+\\frac{\\sigma^{2}}{2}\\,\\partial_{xx}u=-(2\\mu\\,A+\\sigma^{2})+\\mu\\,(2A)+\\frac{\\sigma^{2}}{2}\\,(2)=-(2\\mu\\,A+\\sigma^{2})+2\\mu\\,A+\\sigma^{2}=0.\n$$\nThus $u$ satisfies the Kolmogorov backward equation. For the terminal condition,\n$$\nu(T,x)=\\left(x+\\mu\\,(T-T)\\right)^{2}+\\sigma^{2}\\,(T-T)=x^{2},\n$$\nwhich matches $\\varphi(x)=x^{2}$. Therefore, the computed quadratic polynomial $u(t,x)$ both solves the KBE and satisfies the terminal condition.", "answer": "$$\\boxed{\\left(x+\\mu\\,(T-t)\\right)^{2}+\\sigma^{2}\\,(T-t)}$$", "id": "3062785"}]}