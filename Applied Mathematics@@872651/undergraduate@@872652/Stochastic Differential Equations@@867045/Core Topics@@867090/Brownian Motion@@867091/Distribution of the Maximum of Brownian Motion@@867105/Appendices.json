{"hands_on_practices": [{"introduction": "We begin our hands-on exploration by calculating the most fundamental statistical properties of the running maximum, $M_t$. This exercise will guide you through deriving the probability distribution of $M_t$ using the celebrated reflection principle, from which you will compute its first two moments. Mastering this calculation is essential, as the mean and variance provide the first-order description of any random variable, and the process reinforces the core connection between Brownian motion and the normal distribution [@problem_id:3049921].", "problem": "Let $\\{B_{s}\\}_{s \\ge 0}$ be a standard Brownian motion with $B_{0} = 0$, and define the running maximum up to time $t0$ by $M_{t} := \\sup_{0 \\le s \\le t} B_{s}$. Starting from fundamental properties of Brownian motion (stationary independent increments and $B_{t} \\sim \\mathcal{N}(0,t)$) and the reflection principle, derive the cumulative distribution function of $M_{t}$ for $m \\ge 0$, obtain its probability density function, and then compute the first and second moments $E[M_{t}]$ and $E[M_{t}^{2}]$. Use these to determine the variance $\\operatorname{Var}(M_{t})$. Express your final answer as a single closed-form analytic expression. No rounding is required.", "solution": "Let $\\{B_{s}\\}_{s \\ge 0}$ be a standard Brownian motion with $B_{0} = 0$. We are tasked with finding the variance of its running maximum, defined as $M_{t} = \\sup_{0 \\le s \\le t} B_{s}$ for a fixed time $t  0$. The derivation will proceed in steps: first, we find the cumulative distribution function (CDF) of $M_{t}$ using the reflection principle; second, we derive the probability density function (PDF); third, we compute the first and second moments of $M_{t}$; and finally, we calculate the variance.\n\n**1. Cumulative Distribution Function (CDF) of $M_{t}$**\n\nFor any level $m \\ge 0$, the CDF of $M_{t}$ is $F_{M_t}(m) = P(M_{t} \\le m)$. It is often more direct to first calculate the complementary CDF, $P(M_{t}  m)$. The event $\\{M_{t}  m\\}$ implies that the Brownian path has crossed the level $m$ at some time up to $t$. Let $\\tau_{m} = \\inf\\{s \\ge 0 : B_{s} = m\\}$ be the first hitting time of the level $m$. Then the event $\\{M_{t}  m\\}$ is identical to the event $\\{\\tau_{m} \\le t\\}$.\n\nWe can partition the event $\\{\\tau_m \\le t\\}$ based on the value of $B_t$:\n$$P(M_t  m) = P(\\tau_{m} \\le t) = P(\\tau_m \\le t, B_t  m) + P(\\tau_m \\le t, B_t = m) + P(\\tau_m \\le t, B_t  m)$$\nSince $B_t$ is a continuous random variable, the probability of it being exactly at level $m$ is zero, i.e., $P(B_t = m) = 0$.\nIf $B_t  m$, then due to the continuity of Brownian paths and the starting point $B_0=0$, the path must have crossed the level $m$ at some time $\\tau_m \\le t$. Therefore, the event $\\{B_t  m\\}$ is a subset of $\\{\\tau_m \\le t\\}$, which means $P(\\tau_m \\le t, B_t  m) = P(B_t  m)$.\nThe expression simplifies to:\n$$P(M_t  m) = P(B_t  m) + P(\\tau_m \\le t, B_t  m)$$\nTo evaluate the last term, we employ the reflection principle, a result stemming from the strong Markov property of Brownian motion. On the event $\\{\\tau_m \\le t\\}$, the process reflects on its state at time $\\tau_m$. The behavior of the process $B_s - m$ for $s  \\tau_m$ is symmetric around $0$. This implies that given the path has hit $m$ by time $t$, it is equally likely to end up above or below $m$. More formally:\n$$P(\\tau_m \\le t, B_t  m) = P(\\tau_m \\le t, B_t  m)$$\nSince $P(\\tau_m \\le t, B_t  m) = P(B_t  m)$, we have $P(\\tau_m \\le t, B_t  m) = P(B_t  m)$.\nSubstituting this into our equation for $P(M_t  m)$:\n$$P(M_t  m) = P(B_t  m) + P(B_t  m) = 2P(B_t  m)$$\nSince $M_t$ is a continuous random variable, $P(M_t  m) = P(M_t \\ge m)$, so for $m \\ge 0$:\n$$P(M_t \\ge m) = 2P(B_t \\ge m)$$\nA standard Brownian motion has the distribution $B_t \\sim \\mathcal{N}(0, t)$. Let $Z \\sim \\mathcal{N}(0, 1)$ be a standard normal random variable. Then $B_t$ has the same distribution as $\\sqrt{t}Z$.\n$$P(B_t \\ge m) = P(\\sqrt{t}Z \\ge m) = P\\left(Z \\ge \\frac{m}{\\sqrt{t}}\\right) = 1 - \\Phi\\left(\\frac{m}{\\sqrt{t}}\\right)$$\nwhere $\\Phi(\\cdot)$ is the CDF of the standard normal distribution.\nThe CDF of $M_t$ is then:\n$$F_{M_t}(m) = P(M_t \\le m) = 1 - P(M_t  m) = 1 - 2P(B_t  m) = 1 - 2\\left(1 - \\Phi\\left(\\frac{m}{\\sqrt{t}}\\right)\\right) = 2\\Phi\\left(\\frac{m}{\\sqrt{t}}\\right) - 1$$\nThis formula is valid for $m \\ge 0$. Since $M_t \\ge B_0 = 0$, for $m  0$, $F_{M_t}(m) = 0$.\n\n**2. Probability Density Function (PDF) of $M_{t}$**\n\nThe PDF, $f_{M_t}(m)$, is the derivative of the CDF with respect to $m$, for $m \\ge 0$.\n$$f_{M_t}(m) = \\frac{d}{dm} \\left[2\\Phi\\left(\\frac{m}{\\sqrt{t}}\\right) - 1\\right]$$\nLet $\\phi(x) = \\frac{d}{dx}\\Phi(x) = \\frac{1}{\\sqrt{2\\pi}} \\exp(-x^2/2)$ be the PDF of the standard normal distribution. Using the chain rule:\n$$f_{M_t}(m) = 2 \\cdot \\phi\\left(\\frac{m}{\\sqrt{t}}\\right) \\cdot \\frac{d}{dm}\\left(\\frac{m}{\\sqrt{t}}\\right) = 2 \\cdot \\phi\\left(\\frac{m}{\\sqrt{t}}\\right) \\cdot \\frac{1}{\\sqrt{t}}$$\nSubstituting the expression for $\\phi(\\cdot)$:\n$$f_{M_t}(m) = 2 \\left( \\frac{1}{\\sqrt{2\\pi}} \\exp\\left(-\\frac{1}{2}\\left(\\frac{m}{\\sqrt{t}}\\right)^2\\right) \\right) \\frac{1}{\\sqrt{t}} = \\frac{2}{\\sqrt{2\\pi t}} \\exp\\left(-\\frac{m^2}{2t}\\right) = \\sqrt{\\frac{2}{\\pi t}} \\exp\\left(-\\frac{m^2}{2t}\\right)$$\nThis PDF is for $m \\ge 0$, and $f_{M_t}(m) = 0$ for $m  0$. This is the PDF of a half-normal distribution with scale parameter $\\sigma = \\sqrt{t}$. A notable consequence is that $M_t$ has the same distribution as $|B_t|$.\n\n**3. First Moment $E[M_{t}]$**\n\nThe expected value of $M_t$ is found by integrating $m \\cdot f_{M_t}(m)$ over its support $[0, \\infty)$:\n$$E[M_{t}] = \\int_{0}^{\\infty} m f_{M_t}(m) dm = \\int_{0}^{\\infty} m \\sqrt{\\frac{2}{\\pi t}} \\exp\\left(-\\frac{m^2}{2t}\\right) dm$$\n$$E[M_t] = \\sqrt{\\frac{2}{\\pi t}} \\int_0^\\infty m \\exp\\left(-\\frac{m^2}{2t}\\right) dm$$\nWe perform a substitution with $u = \\frac{m^2}{2t}$, which gives $du = \\frac{m}{t} dm$, or $m \\, dm = t \\, du$. The integration limits remain $0$ to $\\infty$.\n$$E[M_t] = \\sqrt{\\frac{2}{\\pi t}} \\int_0^\\infty \\exp(-u) (t \\, du) = t \\sqrt{\\frac{2}{\\pi t}} \\int_0^\\infty \\exp(-u) du$$\nThe integral $\\int_0^\\infty \\exp(-u) du = 1$.\n$$E[M_t] = t \\sqrt{\\frac{2}{\\pi t}} = \\sqrt{\\frac{2t^2}{\\pi t}} = \\sqrt{\\frac{2t}{\\pi}}$$\n\n**4. Second Moment $E[M_{t}^{2}]$**\n\nThe second moment $E[M_{t}^{2}]$ can be calculated in two ways. First, by direct integration:\n$$E[M_t^2] = \\int_{0}^{\\infty} m^2 f_{M_t}(m) dm = \\sqrt{\\frac{2}{\\pi t}} \\int_{0}^{\\infty} m^2 \\exp\\left(-\\frac{m^2}{2t}\\right) dm$$\nA more direct path is to use the fact that $M_t$ has the same distribution as $|B_t|$. This implies that $M_t^2$ has the same distribution as $|B_t|^2 = B_t^2$. Therefore:\n$$E[M_t^2] = E[B_t^2]$$\nFor a standard Brownian motion $B_t \\sim \\mathcal{N}(0, t)$, the variance is $\\operatorname{Var}(B_t) = E[B_t^2] - (E[B_t])^2$.\nWe know that $E[B_t] = 0$ and $\\operatorname{Var}(B_t) = t$.\nSubstituting these values: $t = E[B_t^2] - 0^2$, which yields $E[B_t^2] = t$.\nHence, the second moment of the maximum is:\n$$E[M_t^2] = t$$\n\n**5. Variance $\\operatorname{Var}(M_{t})$**\n\nFinally, the variance is calculated using the standard formula $\\operatorname{Var}(M_t) = E[M_t^2] - (E[M_t])^2$.\nUsing the moments we derived:\n$$\\operatorname{Var}(M_t) = t - \\left(\\sqrt{\\frac{2t}{\\pi}}\\right)^2 = t - \\frac{2t}{\\pi}$$\nFactoring out $t$ gives the final closed-form expression for the variance:\n$$\\operatorname{Var}(M_t) = t\\left(1 - \\frac{2}{\\pi}\\right)$$", "answer": "$$\\boxed{t \\left( 1 - \\frac{2}{\\pi} \\right)}$$", "id": "3049921"}, {"introduction": "A defining feature of Brownian motion is its self-similarity, or scaling property, which means the process looks statistically the same at all time scales. This practice explores how this crucial property translates to the process's running maximum. You will rigorously prove that the distribution of the maximum at a scaled time, $M_{ct}$, is directly related to the distribution at time $t$, demonstrating that a time-and-space-scaled Brownian motion is itself a standard Brownian motion [@problem_id:3049947]. This reveals a deep structural symmetry and is a powerful tool for simplifying problems.", "problem": "Let $\\{B_t\\}_{t \\geq 0}$ be a standard Brownian motion (SBM), defined as a mean-zero Gaussian process with continuous sample paths and covariance $\\mathbb{E}[B_s B_t] = \\min\\{s,t\\}$. For a fixed $t0$, define the running maximum $M_t := \\sup_{0 \\leq s \\leq t} B_s$. Let $c0$ be a fixed constant.\n\n(a) Starting from the Gaussian process characterization of Brownian motion and its covariance structure, establish the scaling-in-law relationship for the maximum by proving that $M_{c t}$ is equal in distribution to $\\sqrt{c}\\, M_t$.\n\n(b) Using only first principles about how probability density functions (PDFs) transform under positive scalar multiplication of a random variable, express the PDF of $M_{c t}$, denoted $f_{M_{c t}}(m)$ for $m \\in \\mathbb{R}$, in terms of the PDF of $M_t$, denoted $f_{M_t}(m)$.\n\nYour final answer should be a single closed-form analytic expression for $f_{M_{c t}}(m)$ written in terms of $f_{M_t}$ only. No numerical approximation is required.", "solution": "The problem is divided into two parts. Part (a) requires proving a scaling property for the maximum of a standard Brownian motion, and part (b) requires using this property to relate the probability density functions (PDFs) of the maxima at different time scales.\n\n(a) Proving the scaling-in-law relationship $M_{c t} \\stackrel{d}{=} \\sqrt{c}\\, M_t$.\n\nLet $\\{B_t\\}_{t \\geq 0}$ be a standard Brownian motion (SBM). By definition, it is a stochastic process satisfying:\n1.  $B_0 = 0$ almost surely.\n2.  The sample paths $t \\mapsto B_t$ are continuous almost surely.\n3.  It is a Gaussian process with mean $\\mathbb{E}[B_t] = 0$ for all $t \\geq 0$.\n4.  It has covariance $\\mathbb{E}[B_s B_t] = \\min\\{s, t\\}$ for all $s, t \\geq 0$.\n\nWe are given a constant $c  0$. We define a new stochastic process $\\{X_s\\}_{s \\geq 0}$ by scaling the process $\\{B_t\\}$ in both time and space:\n$$ X_s = \\frac{1}{\\sqrt{c}} B_{c s} \\quad \\text{for } s \\geq 0 $$\nTo prove the scaling property of the maximum, we first demonstrate that $\\{X_s\\}_{s \\geq 0}$ is also a standard Brownian motion by verifying the four defining properties.\n\n1.  **Initial value:** At $s=0$, we have $X_0 = \\frac{1}{\\sqrt{c}} B_{c \\cdot 0} = \\frac{1}{\\sqrt{c}} B_0$. Since $B_0 = 0$, it follows that $X_0 = 0$.\n\n2.  **Continuity of paths:** The mapping $s \\mapsto cs$ is a continuous function. The process $\\{B_t\\}$ has continuous sample paths, meaning $u \\mapsto B_u$ is continuous. The composition of continuous functions is continuous, so $s \\mapsto B_{cs}$ is continuous. Scaling by the constant $\\frac{1}{\\sqrt{c}}$ preserves continuity. Therefore, the sample paths of $\\{X_s\\}$ are continuous.\n\n3.  **Gaussian process and mean:** Since $\\{B_t\\}$ is a Gaussian process, any finite linear combination of its random variables is normally distributed. For any set of times $s_1, s_2, \\dots, s_n$, the vector $(X_{s_1}, \\dots, X_{s_n}) = (\\frac{1}{\\sqrt{c}} B_{cs_1}, \\dots, \\frac{1}{\\sqrt{c}} B_{cs_n})$ is a linear transformation of the Gaussian vector $(B_{cs_1}, \\dots, B_{cs_n})$, and is therefore also a Gaussian vector. This establishes that $\\{X_s\\}$ is a Gaussian process.\nThe mean of $X_s$ is:\n$$ \\mathbb{E}[X_s] = \\mathbb{E}\\left[\\frac{1}{\\sqrt{c}} B_{cs}\\right] = \\frac{1}{\\sqrt{c}} \\mathbb{E}[B_{cs}] $$\nSince $\\mathbb{E}[B_t] = 0$ for all $t$, we have $\\mathbb{E}[B_{cs}] = 0$. Thus, $\\mathbb{E}[X_s] = 0$ for all $s \\geq 0$.\n\n4.  **Covariance structure:** We compute the covariance of $X_s$ and $X_u$ for any $s, u \\geq 0$.\n$$ \\mathbb{E}[X_s X_u] = \\mathbb{E}\\left[ \\left(\\frac{1}{\\sqrt{c}} B_{cs}\\right) \\left(\\frac{1}{\\sqrt{c}} B_{cu}\\right) \\right] = \\frac{1}{c} \\mathbb{E}[B_{cs} B_{cu}] $$\nUsing the covariance property of SBM, $\\mathbb{E}[B_a B_b] = \\min\\{a, b\\}$, we have:\n$$ \\mathbb{E}[B_{cs} B_{cu}] = \\min\\{cs, cu\\} $$\nSince $c  0$, we can factor it out of the minimum operator: $\\min\\{cs, cu\\} = c \\min\\{s, u\\}$.\nSubstituting this back into the covariance calculation for $X$:\n$$ \\mathbb{E}[X_s X_u] = \\frac{1}{c} (c \\min\\{s, u\\}) = \\min\\{s, u\\} $$\nThis is precisely the covariance structure of a standard Brownian motion.\n\nSince the process $\\{X_s\\}_{s \\geq 0}$ satisfies all four defining properties of a standard Brownian motion, it has the same probability law as the process $\\{B_s\\}_{s \\geq 0}$. This is denoted as $\\{X_s\\}_{s \\geq 0} \\stackrel{d}{=} \\{B_s\\}_{s \\geq 0}$, where $\\stackrel{d}{=}$ means equality in distribution.\n\nThis equality in distribution of the entire processes implies that any functional applied to the paths of these processes will also result in random variables that are equal in distribution. The running maximum is such a functional.\nLet $M_t = \\sup_{0 \\leq s \\leq t} B_s$. The running maximum of the process $\\{X_s\\}$ over the interval $[0, t]$ is $\\sup_{0 \\leq s \\leq t} X_s$. Due to the equality in law of the processes:\n$$ \\sup_{0 \\leq s \\leq t} X_s \\stackrel{d}{=} \\sup_{0 \\leq s \\leq t} B_s = M_t $$\nNow, we express $\\sup_{0 \\leq s \\leq t} X_s$ in terms of the original process $\\{B_t\\}$:\n$$ \\sup_{0 \\leq s \\leq t} X_s = \\sup_{0 \\leq s \\leq t} \\left(\\frac{1}{\\sqrt{c}} B_{cs}\\right) $$\nSince $\\sqrt{c}$ is a positive constant, we can move the scaling factor outside the supremum:\n$$ \\sup_{0 \\leq s \\leq t} X_s = \\frac{1}{\\sqrt{c}} \\sup_{0 \\leq s \\leq t} B_{cs} $$\nLet's perform a change of variable in the supremum. Let $u = cs$. As $s$ varies from $0$ to $t$, the variable $u$ varies from $0$ to $ct$. The expression becomes:\n$$ \\frac{1}{\\sqrt{c}} \\sup_{0 \\leq u \\leq ct} B_u $$\nBy definition, $\\sup_{0 \\leq u \\leq ct} B_u = M_{ct}$. Therefore, we have established:\n$$ \\frac{1}{\\sqrt{c}} M_{ct} \\stackrel{d}{=} M_t $$\nMultiplying by $\\sqrt{c}$ (which is a deterministic, positive constant), we arrive at the desired scaling relationship:\n$$ M_{ct} \\stackrel{d}{=} \\sqrt{c} M_t $$\nThis completes the proof for part (a).\n\n(b) Relating the PDFs of $M_{c t}$ and $M_t$.\n\nFrom part (a), we have the distributional equality $M_{ct} \\stackrel{d}{=} \\sqrt{c} M_t$. Let $Y = M_{ct}$ and $X = M_t$. Let the scaling factor be $a = \\sqrt{c}$. We have $Y \\stackrel{d}{=} aX$, with $a  0$. We need to find the PDF of $Y$, $f_Y(m)$, in terms of the PDF of $X$, $f_X(m)$. The problem asks us to use first principles.\n\nWe begin with the cumulative distribution function (CDF). Let $F_Y(m)$ be the CDF of $Y$ and $F_X(m)$ be the CDF of $X$.\n$$ F_Y(m) = P(Y \\leq m) $$\nDue to the equality in distribution, $P(Y \\leq m) = P(aX \\leq m)$.\nSince $a = \\sqrt{c}  0$, we can divide the inequality by $a$ without changing its direction:\n$$ P(aX \\leq m) = P\\left(X \\leq \\frac{m}{a}\\right) $$\nThe right-hand side is, by definition, the CDF of $X$ evaluated at the point $\\frac{m}{a}$:\n$$ F_Y(m) = F_X\\left(\\frac{m}{a}\\right) $$\nThe probability density function (PDF) is the derivative of the CDF with respect to its argument. So, $f_Y(m) = \\frac{d}{dm} F_Y(m)$. Applying this to our relationship:\n$$ f_Y(m) = \\frac{d}{dm} F_X\\left(\\frac{m}{a}\\right) $$\nUsing the chain rule for differentiation, with $u = \\frac{m}{a}$ so that $\\frac{du}{dm} = \\frac{1}{a}$:\n$$ f_Y(m) = \\frac{dF_X(u)}{du} \\cdot \\frac{du}{dm} = f_X(u) \\cdot \\frac{1}{a} $$\nSubstituting $u = \\frac{m}{a}$ back into the expression:\n$$ f_Y(m) = \\frac{1}{a} f_X\\left(\\frac{m}{a}\\right) $$\nFinally, we replace $Y$, $X$, and $a$ with their definitions in the context of the problem: $Y=M_{ct}$, $X=M_t$, and $a=\\sqrt{c}$. The PDFs are denoted $f_{M_{ct}}(m)$ and $f_{M_t}(m)$.\nThis yields the relationship between the two PDFs:\n$$ f_{M_{ct}}(m) = \\frac{1}{\\sqrt{c}} f_{M_t}\\left(\\frac{m}{\\sqrt{c}}\\right) $$\nThis expression gives the PDF of the maximum at time $ct$ in terms of the PDF of the maximum at time $t$. For any given value $m$, the probability density is scaled by $\\frac{1}{\\sqrt{c}}$, and the function is evaluated at the correspondingly scaled point $\\frac{m}{\\sqrt{c}}$.", "answer": "$$\\boxed{\\frac{1}{\\sqrt{c}} f_{M_t}\\left(\\frac{m}{\\sqrt{c}}\\right)}$$", "id": "3049947"}, {"introduction": "The distribution of the maximum is not just an abstract curiosity; it is a powerful tool for analyzing other key features of Brownian motion, such as first hitting times. This exercise establishes the direct equivalence between the event that the maximum exceeds a level $a$ and the event that the first hitting time $\\tau_a$ occurs before time $t$. This connection allows you to derive the probability distribution of $\\tau_a$ and culminates in the calculation of its expectation, leading to a famous and counter-intuitive result in stochastic theory [@problem_id:3049951].", "problem": "Let $\\{B_{t}\\}_{t \\geq 0}$ be a one-dimensional standard Brownian motion with $B_{0} = 0$. For a fixed level $a  0$, define the first hitting time $\\tau_{a} := \\inf\\{t \\geq 0 : B_{t} = a\\}$ and the running maximum $M_{t} := \\sup_{0 \\leq s \\leq t} B_{s}$. Assume the fundamental properties of Brownian motion: for each $t  0$, $B_{t}$ is Gaussian with mean $0$ and variance $t$, the process has stationary and independent increments, and paths are continuous. Using only these foundations and the reflection principle, proceed as follows:\n- Establish the relationship between the running maximum and the marginal distribution of $B_{t}$ by showing, for each $t  0$ and $a  0$, that $\\mathbb{P}(M_{t} \\geq a)$ can be expressed in terms of $\\mathbb{P}(B_{t} \\geq a)$.\n- Deduce from this relationship the cumulative distribution function (CDF) $F_{\\tau_{a}}(t) := \\mathbb{P}(\\tau_{a} \\leq t)$ of the hitting time $\\tau_{a}$ for $t  0$, and then differentiate to obtain its probability density function (PDF) $f_{\\tau_{a}}(t)$.\n- Evaluate the integral $\\int_{0}^{\\infty} t \\, f_{\\tau_{a}}(t) \\, dt$ and determine whether it converges or diverges, justifying your conclusion from first principles without appealing to any pre-stated shortcut formulas. Conclude the value of $\\mathbb{E}[\\tau_{a}]$.\n\nYour final answer must be the value of $\\mathbb{E}[\\tau_{a}]$ expressed as a single closed-form mathematical expression. No rounding is required, and no physical units are involved.", "solution": "The problem asks for a multi-step derivation concerning a standard one-dimensional Brownian motion $\\{B_t\\}_{t \\geq 0}$ starting at $B_0=0$. We are asked to first relate the probability of the running maximum $M_t = \\sup_{0 \\leq s \\leq t} B_s$ exceeding a level $a  0$ to the marginal probability of $B_t$ exceeding that level. Then, we are to find the distribution of the first hitting time $\\tau_a = \\inf\\{t \\geq 0: B_t = a\\}$ and finally compute its expectation $\\mathbb{E}[\\tau_a]$. The solution will proceed in three parts as requested.\n\n### Part 1: Distribution of the Running Maximum\n\nWe aim to find a relationship between $\\mathbb{P}(M_t \\geq a)$ and $\\mathbb{P}(B_t \\geq a)$ for any fixed $t0$ and $a0$. The event $\\{M_t \\geq a\\}$ means that the Brownian path has reached or exceeded the level $a$ at some time $s \\in [0, t]$.\n\nWe can partition the sample space based on the value of $B_t$. By the law of total probability, we can write:\n$$\n\\mathbb{P}(M_t \\geq a) = \\mathbb{P}(M_t \\geq a \\text{ and } B_t \\geq a) + \\mathbb{P}(M_t \\geq a \\text{ and } B_t  a)\n$$\nLet's analyze the first term. If the process is at or above level $a$ at time $t$, i.e., $B_t \\geq a$, then its maximum over the interval $[0, t]$ must also be at or above $a$, i.e., $M_t \\geq a$. This is because $M_t = \\sup_{0 \\leq s \\leq t} B_s \\geq B_t$. Therefore, the event $\\{B_t \\geq a\\}$ is a subset of the event $\\{M_t \\geq a\\}$. This implies that the intersection of these two events is simply the event $\\{B_t \\geq a\\}$ itself. So,\n$$\n\\mathbb{P}(M_t \\geq a \\text{ and } B_t \\geq a) = \\mathbb{P}(B_t \\geq a)\n$$\nNow we analyze the second term, $\\mathbb{P}(M_t \\geq a \\text{ and } B_t  a)$. This is the probability that the path reaches or exceeds level $a$ at some point but ends up below $a$ at time $t$. For this to happen, the path must have crossed level $a$ at some time $\\tau_a \\leq t$. This is where the reflection principle for Brownian motion is applied.\n\nThe reflection principle states that for any $a  0$, the probability of a path starting at $0$ reaching level $a$ before time $t$ and ending at $B_t  a$ is equal to the probability of a path starting at $0$ and ending at $B_t  a$. To see this, consider a path $\\omega$ for which $M_t(\\omega) \\geq a$ and $B_t(\\omega)  a$. Let $\\tau_a(\\omega)$ be the first time this path hits $a$. We define a new path $\\tilde{\\omega}$ by reflecting the original path after time $\\tau_a(\\omega)$:\n$$\n\\tilde{B}_s(\\omega) = \\begin{cases} B_s(\\omega)  \\text{if } s \\leq \\tau_a(\\omega) \\\\ a - (B_s(\\omega) - a) = 2a - B_s(\\omega)  \\text{if } s  \\tau_a(\\omega) \\end{cases}\n$$\nBy construction, since $B_t(\\omega)  a$, the reflected path's value at time $t$ is $\\tilde{B}_t(\\omega) = 2a - B_t(\\omega)  2a - a = a$. The map from $\\omega$ to $\\tilde{\\omega}$ is a bijection between the set of paths where $\\{M_t \\geq a, B_t  a\\}$ and the set of paths where $\\{B_t  a\\}$. The strong Markov property of Brownian motion and the symmetry of its increments imply that this map preserves probabilities. Therefore,\n$$\n\\mathbb{P}(M_t \\geq a \\text{ and } B_t  a) = \\mathbb{P}(B_t  a)\n$$\nSince $B_t$ follows a normal distribution, which is continuous, the probability of it being exactly equal to any value is $0$. Thus, $\\mathbb{P}(B_t  a) = \\mathbb{P}(B_t \\geq a)$.\n\nSubstituting these results back into our original equation:\n$$\n\\mathbb{P}(M_t \\geq a) = \\mathbb{P}(B_t \\geq a) + \\mathbb{P}(B_t  a) = \\mathbb{P}(B_t \\geq a) + \\mathbb{P}(B_t \\geq a)\n$$\nThis yields the fundamental relationship:\n$$\n\\mathbb{P}(M_t \\geq a) = 2 \\, \\mathbb{P}(B_t \\geq a)\n$$\n\n### Part 2: CDF and PDF of the First Hitting Time $\\tau_a$\n\nThe cumulative distribution function (CDF) of $\\tau_a$ is defined as $F_{\\tau_a}(t) = \\mathbb{P}(\\tau_a \\leq t)$. The event that the first hitting time $\\tau_a$ is less than or equal to $t$ is equivalent to the event that the running maximum $M_t$ is greater than or equal to $a$. This is because $B_0=0$ and the paths of a Brownian motion are continuous. If $M_t \\geq a$, the path must have visited $a$ at or before time $t$. Conversely, if $\\tau_a \\leq t$, then $B_{\\tau_a} = a$, so $M_t \\geq a$. Thus, $\\{\\tau_a \\leq t\\} = \\{M_t \\geq a\\}$.\n\nUsing the result from Part 1, we can write the CDF of $\\tau_a$ as:\n$$\nF_{\\tau_a}(t) = \\mathbb{P}(\\tau_a \\leq t) = \\mathbb{P}(M_t \\geq a) = 2 \\, \\mathbb{P}(B_t \\geq a)\n$$\nA standard Brownian motion $B_t$ at a fixed time $t$ is a normally distributed random variable with mean $0$ and variance $t$, i.e., $B_t \\sim \\mathcal{N}(0, t)$. We can express this in terms of a standard normal variable $Z \\sim \\mathcal{N}(0, 1)$ as $B_t = \\sqrt{t} Z$.\n$$\n\\mathbb{P}(B_t \\geq a) = \\mathbb{P}(\\sqrt{t} Z \\geq a) = \\mathbb{P}\\left(Z \\geq \\frac{a}{\\sqrt{t}}\\right)\n$$\nThe probability $\\mathbb{P}(Z \\geq z)$ can be written as an integral of the standard normal PDF, $\\phi(u) = \\frac{1}{\\sqrt{2\\pi}}\\exp\\left(-\\frac{u^2}{2}\\right)$:\n$$\n\\mathbb{P}\\left(Z \\geq \\frac{a}{\\sqrt{t}}\\right) = \\int_{a/\\sqrt{t}}^{\\infty} \\frac{1}{\\sqrt{2\\pi}} \\exp\\left(-\\frac{u^2}{2}\\right) du\n$$\nSo, the CDF of $\\tau_a$ is:\n$$\nF_{\\tau_a}(t) = 2 \\int_{a/\\sqrt{t}}^{\\infty} \\frac{1}{\\sqrt{2\\pi}} \\exp\\left(-\\frac{u^2}{2}\\right) du\n$$\nTo find the probability density function (PDF), $f_{\\tau_a}(t)$, we differentiate the CDF with respect to $t$. Using the Leibniz integral rule ($\\frac{d}{dx} \\int_{g(x)}^{h(x)} f(u) du = f(h(x))h'(x) - f(g(x))g'(x)$), we have:\n$$\nf_{\\tau_a}(t) = \\frac{d}{dt} F_{\\tau_a}(t) = \\frac{d}{dt} \\left( 2 \\int_{a/\\sqrt{t}}^{\\infty} \\frac{1}{\\sqrt{2\\pi}} \\exp\\left(-\\frac{u^2}{2}\\right) du \\right)\n$$\nThe upper limit is a constant, so its derivative is $0$. The lower limit is $g(t) = a t^{-1/2}$, and its derivative is $g'(t) = a(-\\frac{1}{2})t^{-3/2} = -\\frac{a}{2t^{3/2}}$.\n$$\nf_{\\tau_a}(t) = 2 \\left( 0 - \\left[ \\frac{1}{\\sqrt{2\\pi}} \\exp\\left(-\\frac{1}{2}\\left(\\frac{a}{\\sqrt{t}}\\right)^2\\right) \\right] \\cdot \\left( -\\frac{a}{2t^{3/2}} \\right) \\right)\n$$\n$$\nf_{\\tau_a}(t) = 2 \\left( \\frac{1}{\\sqrt{2\\pi}} \\exp\\left(-\\frac{a^2}{2t}\\right) \\frac{a}{2t^{3/2}} \\right)\n$$\nSimplifying this expression gives the PDF of the first hitting time $\\tau_a$:\n$$\nf_{\\tau_a}(t) = \\frac{a}{\\sqrt{2\\pi} t^{3/2}} \\exp\\left(-\\frac{a^2}{2t}\\right) \\quad \\text{for } t  0\n$$\n\n### Part 3: Expectation of the First Hitting Time $\\mathbb{E}[\\tau_a]$\n\nThe expectation of $\\tau_a$ is given by the integral of $t$ times its PDF over its support $(0, \\infty)$:\n$$\n\\mathbb{E}[\\tau_a] = \\int_{0}^{\\infty} t \\, f_{\\tau_a}(t) \\, dt\n$$\nSubstituting the derived PDF:\n$$\n\\mathbb{E}[\\tau_a] = \\int_{0}^{\\infty} t \\left( \\frac{a}{\\sqrt{2\\pi} t^{3/2}} \\exp\\left(-\\frac{a^2}{2t}\\right) \\right) dt\n$$\nWe can simplify the integrand:\n$$\n\\mathbb{E}[\\tau_a] = \\frac{a}{\\sqrt{2\\pi}} \\int_{0}^{\\infty} t \\cdot t^{-3/2} \\exp\\left(-\\frac{a^2}{2t}\\right) dt = \\frac{a}{\\sqrt{2\\pi}} \\int_{0}^{\\infty} t^{-1/2} \\exp\\left(-\\frac{a^2}{2t}\\right) dt\n$$\nWe must now evaluate this improper integral and determine if it converges. The integral must be analyzed at its limits $t \\to 0^+$ and $t \\to \\infty$.\n\n1.  Behavior as $t \\to 0^+$: Let $y = 1/t$. As $t \\to 0^+$, $y \\to \\infty$. The integrand becomes $y^{1/2} \\exp(-a^2 y/2)$. Using L'HÃ´pital's rule multiple times shows that $\\lim_{y\\to\\infty} y^{1/2} \\exp(-a^2 y/2) = 0$. The integrand approaches $0$ at the lower limit of integration, so the integral converges on any interval of the form $[0, K]$ for finite $K  0$.\n\n2.  Behavior as $t \\to \\infty$: As $t \\to \\infty$, the term $a^2/(2t) \\to 0$, and therefore $\\exp(-a^2/(2t)) \\to \\exp(0) = 1$.\n    For large $t$, the integrand behaves asymptotically like $t^{-1/2}$:\n    $$\n    t^{-1/2} \\exp\\left(-\\frac{a^2}{2t}\\right) \\sim t^{-1/2} \\quad \\text{as } t \\to \\infty\n    $$\n    We can use the limit comparison test for improper integrals. Consider the integral $\\int_{1}^{\\infty} t^{-p} dt$. This integral converges if and only if $p  1$. In our case, the power is $p = 1/2$. Since $p = 1/2 \\leq 1$, the integral $\\int_{1}^{\\infty} t^{-1/2} dt$ diverges.\n    Formally, let $g(t) = t^{-1/2} \\exp(-a^2/(2t))$ and $h(t) = t^{-1/2}$.\n    $$\n    \\lim_{t\\to\\infty} \\frac{g(t)}{h(t)} = \\lim_{t\\to\\infty} \\frac{t^{-1/2} \\exp(-a^2/(2t))}{t^{-1/2}} = \\lim_{t\\to\\infty} \\exp\\left(-\\frac{a^2}{2t}\\right) = 1\n    $$\n    Since this limit is a finite positive number and the integral $\\int_{1}^{\\infty} h(t) dt = \\int_{1}^{\\infty} t^{-1/2} dt$ diverges, the integral $\\int_{1}^{\\infty} g(t) dt$ must also diverge. The integral for the expectation can be split as $\\int_{0}^{1} g(t) dt + \\int_{1}^{\\infty} g(t) dt$. The first part is finite, but the second part diverges to infinity.\n\nTherefore, the integral for $\\mathbb{E}[\\tau_a]$ diverges to $+\\infty$.\n\nConclusion: The expected time for a standard Brownian motion to first hit any level $a  0$ is infinite.\n$$\n\\mathbb{E}[\\tau_a] = \\infty\n$$", "answer": "$$\\boxed{\\infty}$$", "id": "3049951"}]}