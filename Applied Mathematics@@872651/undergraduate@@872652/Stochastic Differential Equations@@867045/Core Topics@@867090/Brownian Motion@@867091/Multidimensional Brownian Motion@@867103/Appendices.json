{"hands_on_practices": [{"introduction": "A multidimensional Brownian motion is built from independent motions along orthogonal axes. But what happens when we observe this motion from different, non-orthogonal perspectives? This practice explores this question by examining projections of the Brownian path onto two arbitrary vectors. By deriving the joint distribution of these projections [@problem_id:3067398], you will uncover a fundamental link between the geometric angle of the vectors and the statistical correlation of the resulting one-dimensional processes.", "problem": "Let $d \\geq 2$ and let $\\{W_{t}\\}_{t \\geq 0}$ be a $d$-dimensional standard Brownian motion, meaning $W_{0}=\\mathbf{0}$ almost surely, increments are independent and stationary, and for each $t0$ the random vector $W_{t}$ is centered Gaussian with covariance matrix $\\mathbb{E}[W_{t}W_{t}^{\\top}]=t I_{d}$, where $I_{d}$ is the $d \\times d$ identity matrix. Fix a time $t0$ and fix two nonzero, linearly independent, non-orthogonal vectors $u, v \\in \\mathbb{R}^{d}$, with $u^{\\top}v \\neq 0$. Define the scalar random variables $X := u^{\\top}W_{t}$ and $Y := v^{\\top}W_{t}$.\n\nStarting from the defining properties of $d$-dimensional Brownian motion and standard facts about linear transformations of Gaussian random vectors, derive the joint law of $(X,Y)$. In particular, compute the joint probability density function (PDF) of $(X,Y)$ in closed form. Express your final result in terms of the quantities $a := u^{\\top}u$, $b := v^{\\top}v$, $c := u^{\\top}v$, and the time $t0$.\n\nAdditionally, explain how the covariance $\\mathbb{E}[XY]=t\\,u^{\\top}v$ determines the dependence or independence of $X$ and $Y$, and characterize the sign of their correlation in terms of $u^{\\top}v$.\n\nYour final answer must be a single closed-form analytic expression for the joint PDF of $(X,Y)$ in terms of $a$, $b$, $c$, and $t$. No numerical approximation is required.", "solution": "The problem is subjected to validation.\n\n### Step 1: Extract Givens\n-   $d \\geq 2$ is an integer.\n-   $\\{W_{t}\\}_{t \\geq 0}$ is a $d$-dimensional standard Brownian motion.\n-   $W_{0}=\\mathbf{0}$ almost surely.\n-   Increments are independent and stationary.\n-   For each $t0$, the random vector $W_{t}$ is centered Gaussian.\n-   The covariance matrix of $W_t$ is $\\mathbb{E}[W_{t}W_{t}^{\\top}]=t I_{d}$, where $I_{d}$ is the $d \\times d$ identity matrix.\n-   A fixed time $t0$ is considered.\n-   Two nonzero, linearly independent, non-orthogonal vectors $u, v \\in \\mathbb{R}^{d}$ are fixed.\n-   $u^{\\top}v \\neq 0$.\n-   Scalar random variables are defined as $X := u^{\\top}W_{t}$ and $Y := v^{\\top}W_{t}$.\n-   Constants are defined as $a := u^{\\top}u$, $b := v^{\\top}v$, and $c := u^{\\top}v$.\n\n### Step 2: Validate Using Extracted Givens\n-   **Scientifically Grounded:** The problem is firmly rooted in the theory of stochastic processes, specifically the properties of multidimensional Brownian motion and multivariate Gaussian distributions. These are standard and well-established mathematical concepts.\n-   **Well-Posed:** The problem provides all necessary information to determine the joint distribution of the random variables $X$ and $Y$. The conditions on the vectors $u$ and $v$ (nonzero, linearly independent) are crucial. The linear independence ensures that the resulting bivariate Gaussian distribution is non-degenerate. A unique solution exists and can be derived methodically.\n-   **Objective:** The problem is stated using precise, unambiguous mathematical language. There are no subjective or opinion-based elements.\n\n### Step 3: Verdict and Action\nThe problem is valid. It is a well-posed, scientifically grounded question in the field of stochastic processes. I will now proceed to derive the solution.\n\nThe core principle for this problem is that a linear transformation of a Gaussian random vector results in another Gaussian random vector. The random vector $W_{t}$ is, by definition, a $d$-dimensional Gaussian vector with mean $\\mathbf{0}$ and covariance matrix $tI_{d}$. We can write $W_{t} \\sim \\mathcal{N}(\\mathbf{0}, tI_{d})$.\n\nThe scalar random variables $X$ and $Y$ are defined as linear combinations of the components of $W_{t}$:\n$$X = u^{\\top}W_{t}$$\n$$Y = v^{\\top}W_{t}$$\nWe can express the pair $(X, Y)$ as a single $2$-dimensional random vector $Z = \\begin{pmatrix} X \\\\ Y \\end{pmatrix}$. This vector is obtained by a linear transformation of $W_{t}$:\n$$Z = \\begin{pmatrix} X \\\\ Y \\end{pmatrix} = \\begin{pmatrix} u^{\\top} \\\\ v^{\\top} \\end{pmatrix} W_{t}$$\nLet the transformation matrix be $M = \\begin{pmatrix} u^{\\top} \\\\ v^{\\top} \\end{pmatrix}$. $M$ is a $2 \\times d$ matrix. The random vector $Z$ is thus given by $Z = MW_{t}$.\n\nSince $W_{t}$ is a Gaussian vector, $Z$ must also be a Gaussian vector. We need to determine its mean vector $\\mu_{Z}$ and its covariance matrix $\\Sigma_{Z}$.\n\nThe mean of $Z$ is given by:\n$$\\mu_{Z} = \\mathbb{E}[Z] = \\mathbb{E}[MW_{t}] = M\\mathbb{E}[W_{t}]$$\nGiven that $W_{t}$ is centered, $\\mathbb{E}[W_{t}] = \\mathbf{0}$. Therefore,\n$$\\mu_{Z} = M\\mathbf{0} = \\mathbf{0} = \\begin{pmatrix} 0 \\\\ 0 \\end{pmatrix}$$\nThis shows that both $X$ and $Y$ are zero-mean random variables, i.e., $\\mathbb{E}[X] = 0$ and $\\mathbb{E}[Y] = 0$.\n\nThe covariance matrix of $Z$ is given by:\n$$\\Sigma_{Z} = \\mathbb{E}[(Z-\\mu_{Z})(Z-\\mu_{Z})^{\\top}] = \\mathbb{E}[ZZ^{\\top}] = \\mathbb{E}[(MW_{t})(MW_{t})^{\\top}]$$\nUsing properties of the transpose, this becomes:\n$$\\Sigma_{Z} = \\mathbb{E}[M W_{t} W_{t}^{\\top} M^{\\top}] = M \\mathbb{E}[W_{t} W_{t}^{\\top}] M^{\\top}$$\nWe are given that $\\mathbb{E}[W_{t}W_{t}^{\\top}] = tI_{d}$. Substituting this into the equation:\n$$\\Sigma_{Z} = M (tI_{d}) M^{\\top} = t(MM^{\\top})$$\nNow we compute the matrix product $MM^{\\top}$:\n$$M^{\\top} = \\begin{pmatrix} u  v \\end{pmatrix}$$\n$$MM^{\\top} = \\begin{pmatrix} u^{\\top} \\\\ v^{\\top} \\end{pmatrix} \\begin{pmatrix} u  v \\end{pmatrix} = \\begin{pmatrix} u^{\\top}u  u^{\\top}v \\\\ v^{\\top}u  v^{\\top}v \\end{pmatrix}$$\nUsing the provided definitions $a := u^{\\top}u$, $b := v^{\\top}v$, and $c := u^{\\top}v$ (and noting $v^{\\top}u = u^{\\top}v = c$), we get:\n$$MM^{\\top} = \\begin{pmatrix} a  c \\\\ c  b \\end{pmatrix}$$\nTherefore, the covariance matrix of $Z = (X,Y)^{\\top}$ is:\n$$\\Sigma_{Z} = t \\begin{pmatrix} a  c \\\\ c  b \\end{pmatrix} = \\begin{pmatrix} ta  tc \\\\ tc  tb \\end{pmatrix}$$\nThe components of this matrix are $\\text{Var}(X) = ta$, $\\text{Var}(Y) = tb$, and $\\text{Cov}(X,Y) = tc$.\n\nThe joint law of $(X,Y)$ is a bivariate normal distribution with mean $\\begin{pmatrix} 0 \\\\ 0 \\end{pmatrix}$ and covariance matrix $\\Sigma_{Z}$. The joint probability density function (PDF) for a bivariate normal vector $\\mathbf{z} = (x,y)^{\\top}$ with mean $\\mathbf{0}$ and covariance matrix $\\Sigma$ is given by:\n$$f(x,y) = \\frac{1}{2\\pi \\sqrt{\\det(\\Sigma)}} \\exp\\left(-\\frac{1}{2} \\mathbf{z}^{\\top} \\Sigma^{-1} \\mathbf{z}\\right)$$\nWe must compute the determinant and the inverse of $\\Sigma_{Z}$.\nThe determinant is:\n$$\\det(\\Sigma_{Z}) = (ta)(tb) - (tc)^2 = t^2ab - t^2c^2 = t^2(ab-c^2)$$\nBy the Cauchy-Schwarz inequality, $(u^{\\top}v)^2 \\leq (u^{\\top}u)(v^{\\top}v)$, which translates to $c^2 \\leq ab$. Since the vectors $u$ and $v$ are given to be linearly independent, the inequality is strict: $c^2  ab$, which implies $ab - c^2  0$. As $t0$, we have $\\det(\\Sigma_{Z})  0$, confirming the distribution is non-degenerate.\n\nThe inverse of $\\Sigma_{Z}$ is:\n$$\\Sigma_{Z}^{-1} = \\frac{1}{\\det(\\Sigma_{Z})} \\begin{pmatrix} tb  -tc \\\\ -tc  ta \\end{pmatrix} = \\frac{1}{t^2(ab-c^2)} \\begin{pmatrix} tb  -tc \\\\ -tc  ta \\end{pmatrix} = \\frac{1}{t(ab-c^2)} \\begin{pmatrix} b  -c \\\\ -c  a \\end{pmatrix}$$\nThe quadratic form in the exponent is $\\mathbf{z}^{\\top} \\Sigma_{Z}^{-1} \\mathbf{z}$ with $\\mathbf{z} = (x,y)^{\\top}$:\n$$\\begin{pmatrix} x  y \\end{pmatrix} \\frac{1}{t(ab-c^2)} \\begin{pmatrix} b  -c \\\\ -c  a \\end{pmatrix} \\begin{pmatrix} x \\\\ y \\end{pmatrix} = \\frac{1}{t(ab-c^2)} \\begin{pmatrix} x  y \\end{pmatrix} \\begin{pmatrix} bx - cy \\\\ -cx + ay \\end{pmatrix}$$\n$$= \\frac{1}{t(ab-c^2)} (x(bx-cy) + y(-cx+ay)) = \\frac{bx^2 - 2cxy + ay^2}{t(ab-c^2)}$$\nSubstituting all parts back into the PDF formula:\n$$f_{X,Y}(x,y) = \\frac{1}{2\\pi \\sqrt{t^2(ab-c^2)}} \\exp\\left( -\\frac{1}{2} \\frac{bx^2 - 2cxy + ay^2}{t(ab-c^2)} \\right)$$\nSimplifying the term in the denominator:\n$$f_{X,Y}(x,y) = \\frac{1}{2\\pi t \\sqrt{ab-c^2}} \\exp\\left( -\\frac{bx^2 - 2cxy + ay^2}{2t(ab-c^2)} \\right)$$\nThis is the closed-form expression for the joint PDF of $(X,Y)$.\n\nRegarding the second part of the question, the covariance between $X$ and $Y$ is the $(1,2)$-entry of the covariance matrix $\\Sigma_{Z}$, which we found to be $\\text{Cov}(X,Y) = \\mathbb{E}[XY] - \\mathbb{E}[X]\\mathbb{E}[Y]$. Since $\\mathbb{E}[X]=\\mathbb{E}[Y]=0$, we have $\\text{Cov}(X,Y) = \\mathbb{E}[XY] = tc = t u^{\\top}v$.\nFor jointly Gaussian random variables, independence is equivalent to being uncorrelated. Thus, $X$ and $Y$ are independent if and only if $\\text{Cov}(X,Y) = 0$.\nGiven $t  0$, this condition becomes $u^{\\top}v = 0$. This means $X$ and $Y$ are independent if and only if the vectors $u$ and $v$ are orthogonal. The problem states that $u$ and $v$ are non-orthogonal, so $u^{\\top}v \\neq 0$, which implies that $X$ and $Y$ are dependent.\n\nThe correlation coefficient $\\rho_{XY}$ is defined as:\n$$\\rho_{XY} = \\frac{\\text{Cov}(X,Y)}{\\sqrt{\\text{Var}(X)\\text{Var}(Y)}} = \\frac{tc}{\\sqrt{(ta)(tb)}} = \\frac{tc}{t\\sqrt{ab}} = \\frac{c}{\\sqrt{ab}}$$\nSince $a = \\|u\\|^2  0$ and $b = \\|v\\|^2  0$, the denominator $\\sqrt{ab}$ is a positive real number. Therefore, the sign of the correlation $\\rho_{XY}$ is determined entirely by the sign of $c = u^{\\top}v$.\n- If $u^{\\top}v  0$ (the angle between $u$ and $v$ is acute), then $\\rho_{XY}  0$, and $X$ and $Y$ are positively correlated.\n- If $u^{\\top}v  0$ (the angle between $u$ and $v$ is obtuse), then $\\rho_{XY}  0$, and $X$ and $Y$ are negatively correlated.\nThis completes the required analysis.", "answer": "$$\\boxed{\\frac{1}{2\\pi t \\sqrt{ab-c^2}} \\exp\\left(-\\frac{bx^2 - 2cxy + ay^2}{2t(ab-c^2)}\\right)}$$", "id": "3067398"}, {"introduction": "While a standard Brownian motion has an expected position of zero, a function of that position does not necessarily have a constant expectation. Itô's formula, the chain rule of stochastic calculus, is the essential tool for understanding how such functions evolve. This exercise [@problem_id:548895] asks you to apply the multidimensional Itô's formula to track the expected value of a potential energy function, highlighting the crucial role of the Laplacian term which accounts for the process's inherent randomness.", "problem": "In the study of stochastic processes, Itô's formula serves as a fundamental tool, acting as the chain rule for functions of a stochastic process. It provides a stochastic counterpart to the fundamental theorem of calculus, revealing how the evolution of a function depends not only on the first but also the second moments of the underlying process's increments.\n\n**Background:**\n\nAn $n$-dimensional standard Brownian motion $\\mathbf{B}_t = (B_{1,t}, \\dots, B_{n,t})$ is a stochastic process where each component $B_{i,t}$ is an independent one-dimensional standard Brownian motion. Key properties include:\n1.  $\\mathbf{B}_0 = \\mathbf{0}$.\n2.  For any $t, s \\geq 0$, the increment $\\mathbf{B}_{t+s} - \\mathbf{B}_t$ is independent of the process's history $\\{\\mathbf{B}_u\\}_{u \\le t}$.\n3.  Each component's increment $B_{i,t+s} - B_{i,t}$ follows a normal distribution $\\mathcal{N}(0, s)$.\n4.  The quadratic covariation between components is $d\\langle B_i, B_j \\rangle_t = \\delta_{ij} dt$, where $\\delta_{ij}$ is the Kronecker delta.\n\nFor a twice continuously differentiable function $\\phi: \\mathbb{R}^n \\to \\mathbb{R}$, Itô's formula for $\\phi(\\mathbf{B}_t)$ is given by:\n$$\nd\\phi(\\mathbf{B}_t) = \\nabla \\phi(\\mathbf{B}_t) \\cdot d\\mathbf{B}_t + \\frac{1}{2} \\Delta\\phi(\\mathbf{B}_t) dt\n$$\nwhere $\\nabla \\phi$ is the gradient of $\\phi$, and $\\Delta\\phi = \\sum_{i=1}^n \\frac{\\partial^2 \\phi}{\\partial x_i^2}$ is the Laplacian of $\\phi$.\n\n**Problem Statement:**\n\nConsider a point particle in an $n$-dimensional space whose position at time $t$ is described by a standard Brownian motion $\\mathbf{B}_t$, starting from the origin. The particle is influenced by a potential field $\\phi(\\mathbf{x}) = \\|\\mathbf{x}\\|^4$, where $\\|\\mathbf{x}\\|$ is the Euclidean norm.\n\nUsing Itô's formula, derive a closed-form expression for the expected total change in the potential energy of the particle from time $t=0$ to a final time $t=T$. This quantity is defined as $\\mathbb{E}[\\phi(\\mathbf{B}_T) - \\phi(\\mathbf{B}_0)]$. Your final answer should be in terms of the dimension $n$ and the final time $T$.", "solution": "We apply Itô’s formula to $\\phi(\\mathbf{B}_t)$ with $\\phi(\\mathbf{x})=(\\|\\mathbf{x}\\|^2)^2$.\n\n1. Itô’s formula:  \n$$\nd\\phi(\\mathbf{B}_t)=\\nabla\\phi(\\mathbf{B}_t)\\cdot d\\mathbf{B}_t+\\tfrac12\\,\\Delta\\phi(\\mathbf{B}_t)\\,dt.\n$$\n\n2. Compute gradient and Laplacian. Let $r^2=\\|\\mathbf{x}\\|^2$. Then\n$$\n\\frac{\\partial\\phi}{\\partial x_i}\n=\\frac{\\partial (r^4)}{\\partial x_i}\n=4x_i\\,r^2,\n$$\n$$\n\\frac{\\partial^2\\phi}{\\partial x_i^2}\n=\\frac{\\partial(4x_i\\,r^2)}{\\partial x_i}\n=4r^2+8x_i^2.\n$$\nHence\n$$\n\\Delta\\phi(\\mathbf{x})\n=\\sum_{i=1}^n\\bigl(4r^2+8x_i^2\\bigr)\n=4n\\,r^2+8r^2\n=4(n+2)\\,r^2.\n$$\n\n3. Integrate and take expectation. Since the martingale term has zero mean,\n$$\n\\mathbb{E}[\\phi(\\mathbf{B}_T)-\\phi(\\mathbf{B}_0)]\n=\\tfrac12\\int_0^T\\mathbb{E}[\\Delta\\phi(\\mathbf{B}_t)]\\,dt\n=2(n+2)\\int_0^T\\mathbb{E}[\\|\\mathbf{B}_t\\|^2]\\,dt.\n$$\nUsing $\\mathbb{E}[\\|\\mathbf{B}_t\\|^2]=nt$, we get\n$$\n\\mathbb{E}[\\phi(\\mathbf{B}_T)-\\phi(0)]\n=2(n+2)\\int_0^Tnt\\,dt\n=2n(n+2)\\,\\frac{T^2}{2}\n=n(n+2)T^2.\n$$", "answer": "$$\\boxed{n(n+2)T^2}$$", "id": "548895"}, {"introduction": "Stochastic differential equations (SDEs) are the language used to model systems evolving under random influences. This exercise introduces a common type of linear SDE with multiplicative noise, which appears in fields like mathematical finance and population dynamics. To solve for the system's average behavior [@problem_id:2988724], you will practice the essential skill of converting the SDE from its Stratonovich form to the mathematically convenient Itô form, revealing how the noise structure influences the system's expected trajectory.", "problem": "Let $\\{B_t\\}_{t \\geq 0}$ be a standard $m$-dimensional Brownian motion with $m \\geq 2$, whose components $B_{t}^{(1)}, \\dots, B_{t}^{(m)}$ are independent real-valued Brownian motions. Consider the $\\mathbb{R}^{n}$-valued process $X_{t}$ defined by the Stratonovich stochastic differential equation (SDE)\n$$\ndX_{t} \\;=\\; A\\,X_{t}\\,dt \\;+\\; \\sum_{i=1}^{m} S_{i}\\,X_{t} \\circ dB_{t}^{(i)}, \\qquad X_{0} = x_{0} \\in \\mathbb{R}^{n},\n$$\nwhere $A \\in \\mathbb{R}^{n \\times n}$ and $S_{1},\\dots,S_{m} \\in \\mathbb{R}^{n \\times n}$ are fixed deterministic matrices. Let $u \\in \\mathbb{R}^{n}$ be a fixed deterministic vector. Using only the core definitions of multidimensional Brownian motion, the Stratonovich integral, and the principle that relates Stratonovich and Itô interpretations, derive from first principles a closed-form analytic expression for the scalar quantity $u^{\\top} \\mathbb{E}[X_{T}]$ in terms of $T$, $A$, $\\{S_{i}\\}_{i=1}^{m}$, $x_{0}$, and $u$. Express your final answer as a single closed-form analytic expression. No rounding is required.", "solution": "The problem as stated is scientifically grounded, well-posed, objective, and internally consistent. All necessary information is provided to derive a unique, meaningful solution. Thus, we proceed with the derivation.\n\nThe stated objective is to find a closed-form analytic expression for the scalar quantity $u^{\\top} \\mathbb{E}[X_{T}]$, where the $\\mathbb{R}^{n}$-valued process $X_{t}$ is governed by the Stratonovich stochastic differential equation (SDE):\n$$\ndX_{t} \\;=\\; A\\,X_{t}\\,dt \\;+\\; \\sum_{i=1}^{m} S_{i}\\,X_{t} \\circ dB_{t}^{(i)}, \\qquad X_{0} = x_{0} \\in \\mathbb{R}^{n}\n$$\nHere, $\\{B_{t}\\}_{t \\geq 0}$ is a standard $m$-dimensional Brownian motion, $A, S_{1}, \\dots, S_{m}$ are constant $n \\times n$ matrices, and $u, x_{0}$ are constant $n$-dimensional vectors.\n\nThe problem requires a derivation from first principles. A foundational principle in stochastic calculus is that the expectation of an Itô integral with respect to a Brownian motion is zero. This property does not hold for the Stratonovich integral. Therefore, the most direct path to computing $\\mathbb{E}[X_{t}]$ is to first convert the given Stratonovich SDE into its equivalent Itô form.\n\nA general Stratonovich SDE for a process $Y_{t}$ of the form\n$$\ndY_{t} = a(Y_{t}) dt + \\sum_{i=1}^{m} b_{i}(Y_{t}) \\circ dB_{t}^{(i)}\n$$\nis equivalent to the Itô SDE\n$$\ndY_{t} = \\left( a(Y_{t}) + \\frac{1}{2} \\sum_{i=1}^{m} (Db_{i})(Y_{t}) b_{i}(Y_{t}) \\right) dt + \\sum_{i=1}^{m} b_{i}(Y_{t}) dB_{t}^{(i)}\n$$\nwhere $(Db_{i})(Y_{t})$ is the Jacobian matrix of the vector field $b_{i}$ evaluated at $Y_{t}$, and the term $\\frac{1}{2} \\sum_{i=1}^{m} (Db_{i})(Y_{t}) b_{i}(Y_{t})$ is a vector known as the Itô-Stratonovich correction term.\n\nFor the specific problem at hand, we identify the corresponding terms for the process $X_{t}$:\nThe drift term is $a(X_{t}) = A X_{t}$.\nThe diffusion terms are $b_{i}(X_{t}) = S_{i} X_{t}$ for $i=1, \\dots, m$.\n\nThe processes $b_{i}(X_{t})$ are linear transformations of $X_{t}$. The Jacobian matrix of the map $X_{t} \\mapsto S_{i} X_{t}$ is the constant matrix $S_{i}$ itself. That is, $(Db_{i})(X_{t}) = S_{i}$.\n\nWe can now compute the Itô-Stratonovich correction term:\n$$\n\\frac{1}{2} \\sum_{i=1}^{m} (Db_{i})(X_{t}) b_{i}(X_{t}) = \\frac{1}{2} \\sum_{i=1}^{m} S_{i} (S_{i} X_{t}) = \\left(\\frac{1}{2} \\sum_{i=1}^{m} S_{i}^2 \\right) X_{t}\n$$\nSubstituting this into the general conversion formula, the equivalent Itô SDE for $X_{t}$ is:\n$$\ndX_{t} = \\left( A X_{t} + \\left(\\frac{1}{2} \\sum_{i=1}^{m} S_{i}^2 \\right) X_{t} \\right) dt + \\sum_{i=1}^{m} S_{i} X_{t} dB_{t}^{(i)}\n$$\nLet us define a new constant matrix $\\tilde{A}$ that consolidates the drift terms:\n$$\n\\tilde{A} = A + \\frac{1}{2} \\sum_{i=1}^{m} S_{i}^2\n$$\nThe Itô SDE can now be written more compactly as:\n$$\ndX_{t} = \\tilde{A} X_{t} dt + \\sum_{i=1}^{m} S_{i} X_{t} dB_{t}^{(i)}\n$$\nTo find the dynamics of the mean vector $\\mu_{t} = \\mathbb{E}[X_{t}]$, we take the expectation of the Itô SDE. By the linearity of expectation and the ability to interchange expectation and differentiation under suitable conditions (Fubini's theorem), we have:\n$$\nd\\mathbb{E}[X_{t}] = \\mathbb{E}[dX_{t}] = \\mathbb{E}\\left[\\tilde{A} X_{t} dt + \\sum_{i=1}^{m} S_{i} X_{t} dB_{t}^{(i)}\\right]\n$$\n$$\nd\\mu_{t} = \\mathbb{E}[\\tilde{A} X_{t}] dt + \\mathbb{E}\\left[\\sum_{i=1}^{m} S_{i} X_{t} dB_{t}^{(i)}\\right]\n$$\nSince $\\tilde{A}$ is a deterministic matrix, $\\mathbb{E}[\\tilde{A} X_{t}] = \\tilde{A} \\mathbb{E}[X_{t}] = \\tilde{A} \\mu_{t}$.\nA fundamental property of the Itô integral is that for any suitable non-anticipating process $H_{t}$, the expectation of its integral with respect to Brownian motion is zero. In differential form, $\\mathbb{E}[H_{t} dB_{t}] = 0$. The processes $S_{i}X_{t}$ are non-anticipating because $X_{t}$ is adapted to the filtration generated by the Brownian motion. Therefore,\n$$\n\\mathbb{E}\\left[S_{i} X_{t} dB_{t}^{(i)}\\right] = 0 \\quad \\text{for each } i=1, \\dots, m.\n$$\nConsequently, the stochastic term vanishes upon taking the expectation:\n$$\nd\\mu_{t} = \\tilde{A} \\mu_{t} dt\n$$\nThis is a linear system of ordinary differential equations for the mean vector $\\mu_{t}$. The initial condition is $\\mu_{0} = \\mathbb{E}[X_{0}]$. Since $X_{0} = x_{0}$ is a deterministic vector, we have $\\mu_{0} = x_{0}$.\n\nThe solution to the initial value problem $\\frac{d\\mu_{t}}{dt} = \\tilde{A} \\mu_{t}$ with $\\mu_{0} = x_{0}$ is given by the matrix exponential:\n$$\n\\mu_{t} = \\exp(t\\tilde{A}) \\mu_{0} = \\exp(t\\tilde{A}) x_{0}\n$$\nSubstituting back the expression for $\\tilde{A}$, we get the mean of the process $X_{t}$:\n$$\n\\mathbb{E}[X_{t}] = \\exp\\left(t\\left(A + \\frac{1}{2} \\sum_{i=1}^{m} S_{i}^2\\right)\\right) x_{0}\n$$\nWe are asked to find the scalar quantity $u^{\\top} \\mathbb{E}[X_{T}]$. We evaluate the expression for the mean at time $t=T$ and pre-multiply by the transpose of the vector $u$:\n$$\nu^{\\top} \\mathbb{E}[X_{T}] = u^{\\top} \\exp\\left(T\\left(A + \\frac{1}{2} \\sum_{i=1}^{m} S_{i}^2\\right)\\right) x_{0}\n$$\nThis is the final closed-form analytic expression for the desired quantity.", "answer": "$$\\boxed{u^{\\top} \\exp\\left(T\\left(A + \\frac{1}{2} \\sum_{i=1}^{m} S_{i}^{2}\\right)\\right) x_{0}}$$", "id": "2988724"}]}