{"hands_on_practices": [{"introduction": "The Itô integral is the fundamental building block of stochastic calculus. This first exercise [@problem_id:3061832] provides a crucial first step by asking you to integrate one of the simplest possible processes—a deterministic step function. By working through this problem, you will see directly how the integral is constructed and gain intuition for one of its most important properties, the Itô isometry, which links the variance of the integral to the passage of time.", "problem": "Let $\\{W_{s}\\}_{s\\geq 0}$ be a standard Brownian motion (also known as a Wiener process) defined on a filtered probability space $(\\Omega,\\mathcal{F},\\{\\mathcal{F}_{s}\\}_{s\\geq 0},\\mathbb{P})$ satisfying the usual conditions. Fix $t0$ and numbers $0\\leq ab\\leq t$. Consider the process $H_{s}=\\mathbf{1}_{[a,b]}(s)$, where $\\mathbf{1}_{[a,b]}$ denotes the indicator function of the interval $[a,b]$. Starting from the definition of the Itô integral for simple processes and the basic properties of Brownian motion, evaluate the Itô integral $\\int_{0}^{t}H_{s}\\,dW_{s}$ explicitly in terms of $\\{W_{s}\\}$, and compute its variance $\\mathrm{Var}\\!\\left(\\int_{0}^{t}H_{s}\\,dW_{s}\\right)$. Express your final answer as a row matrix with two entries: the value of the integral and its variance. No rounding is required.", "solution": "The problem is well-posed and scientifically grounded within the mathematical framework of stochastic calculus. All provided information is clear, consistent, and sufficient for deriving a unique solution. We may therefore proceed with the evaluation.\n\nThe problem asks for the evaluation of the Itô integral $I = \\int_{0}^{t} H_{s} \\, dW_{s}$ and its variance, where $H_{s} = \\mathbf{1}_{[a,b]}(s)$ for $0 \\leq a  b \\leq t$. The process $H_s$ is a deterministic, elementary process.\n\nFirst, we evaluate the integral $I$. By the definition of the Itô integral, we can split the integration interval $[0,t]$ into subintervals where the integrand $H_s$ is constant. The process $H_s$ is defined as:\n$$\nH_s = \\begin{cases}\n1  \\text{if } s \\in [a,b] \\\\\n0  \\text{if } s \\notin [a,b]\n\\end{cases}\n$$\nThe integral can be decomposed as follows:\n$$\nI = \\int_{0}^{t} H_{s} \\, dW_{s} = \\int_{0}^{a} H_{s} \\, dW_{s} + \\int_{a}^{b} H_{s} \\, dW_{s} + \\int_{b}^{t} H_{s} \\, dW_{s}\n$$\nWe evaluate each term separately.\nFor the interval $[0, a)$, $H_s = 0$. The integral of a zero process is zero:\n$$\n\\int_{0}^{a} 0 \\, dW_{s} = 0\n$$\nFor the interval $[a, b]$, $H_s = 1$. The Itô integral of a constant $c$ over an interval $[t_1, t_2]$ is given by $\\int_{t_1}^{t_2} c \\, dW_s = c(W_{t_2} - W_{t_1})$. In our case, $c=1$, $t_1=a$, and $t_2=b$. Thus,\n$$\n\\int_{a}^{b} 1 \\, dW_{s} = W_{b} - W_{a}\n$$\nFor the interval $(b, t]$, $H_s = 0$. Similar to the first interval, the integral is zero:\n$$\n\\int_{b}^{t} 0 \\, dW_{s} = 0\n$$\nCombining these results, we find the value of the Itô integral:\n$$\nI = 0 + (W_{b} - W_{a}) + 0 = W_{b} - W_{a}\n$$\nThis is the first part of our answer.\n\nNext, we compute the variance of this integral, $\\mathrm{Var}(I) = \\mathrm{Var}(W_{b} - W_{a})$. We will use two methods to confirm the result.\n\nMethod 1: Using the Itô Isometry.\nFor a suitable (predictable and square-integrable) process $\\phi_s$, the Itô isometry property states:\n$$\n\\mathbb{E}\\left[\\left(\\int_{0}^{t} \\phi_{s} \\, dW_{s}\\right)^2\\right] = \\mathbb{E}\\left[\\int_{0}^{t} \\phi_{s}^2 \\, ds\\right]\n$$\nThe Itô integral of such a process has a mean of zero, i.e., $\\mathbb{E}\\left[\\int_{0}^{t} \\phi_{s} \\, dW_{s}\\right] = 0$. Therefore, its variance is equal to its second moment:\n$$\n\\mathrm{Var}\\left(\\int_{0}^{t} \\phi_{s} \\, dW_{s}\\right) = \\mathbb{E}\\left[\\left(\\int_{0}^{t} \\phi_{s} \\, dW_{s}\\right)^2\\right]\n$$\nOur process $H_s = \\mathbf{1}_{[a,b]}(s)$ is deterministic and bounded, thus it satisfies the conditions for the isometry to hold. We have:\n$$\n\\mathrm{Var}(I) = \\mathbb{E}\\left[\\left(\\int_{0}^{t} H_{s} \\, dW_{s}\\right)^2\\right] = \\mathbb{E}\\left[\\int_{0}^{t} H_{s}^2 \\, ds\\right]\n$$\nThe square of the integrand is $H_s^2 = (\\mathbf{1}_{[a,b]}(s))^2 = \\mathbf{1}_{[a,b]}(s)$, since the indicator function only takes values $0$ and $1$. The integral inside the expectation is a deterministic Riemann integral:\n$$\n\\int_{0}^{t} H_{s}^2 \\, ds = \\int_{0}^{t} \\mathbf{1}_{[a,b]}(s) \\, ds = \\int_{a}^{b} 1 \\, ds = b - a\n$$\nSince the result of this integral, $b-a$, is a constant, its expectation is the constant itself:\n$$\n\\mathrm{Var}(I) = \\mathbb{E}[b - a] = b - a\n$$\n\nMethod 2: Using the properties of Brownian motion.\nWe found that $I = W_b - W_a$. A fundamental property of standard Brownian motion $\\{W_s\\}_{s \\geq 0}$ is that for any $0 \\leq s_1  s_2$, the increment $W_{s_2} - W_{s_1}$ is a normally distributed random variable with mean $0$ and variance $s_2 - s_1$. That is,\n$$\nW_{s_2} - W_{s_1} \\sim \\mathcal{N}(0, s_2 - s_1)\n$$\nIn our case, since $0 \\leq a  b$, we can apply this property directly to the increment $W_b - W_a$. We have:\n$$\nW_b - W_a \\sim \\mathcal{N}(0, b-a)\n$$\nThe variance of a random variable with this distribution is, by definition, $b-a$.\n$$\n\\mathrm{Var}(I) = \\mathrm{Var}(W_b - W_a) = b - a\n$$\nBoth methods yield the same result, which confirms our calculation.\n\nThe two required quantities are the value of the integral, which is the random variable $W_b - W_a$, and its variance, which is the constant $b-a$.", "answer": "$$\n\\boxed{\\begin{pmatrix} W_b - W_a  b - a \\end{pmatrix}}\n$$", "id": "3061832"}, {"introduction": "Having explored the Itô integral, we now turn to the equations it defines: Stochastic Differential Equations (SDEs). A critical question before attempting to solve any SDE is whether a unique solution exists. This thought experiment [@problem_id:3061833] reveals that even for seemingly simple equations, the answer is not always yes, highlighting the importance of conditions like local Lipschitz continuity for the well-posedness of a problem.", "problem": "Consider the stochastic differential equation (SDE) on $\\mathbb{R}$ driven by a standard Brownian motion $W$ but with zero diffusion coefficient:\n$$\ndX_t = b(X_t)\\,dt,\\qquad X_0 = 0,\n$$\nwhere $b(x) = \\sqrt{|x|}$. Interpret any solution as an Itô process with drift $b$ and diffusion coefficient identically zero. Work on a filtered probability space supporting $W$ that satisfies the usual conditions. You may assume standard notions of strong solution, weak solution, pathwise (strong) uniqueness, and weak uniqueness.\n\nSelect all statements that are correct.\n\nA. There exists at least one strong solution adapted to any given Brownian filtration, and $X_t \\equiv 0$ for all $t \\ge 0$ is one such solution.\n\nB. For each deterministic $\\tau \\ge 0$, the process defined by $X_t^{(\\tau)} = 0$ for $t \\in [0,\\tau]$ and $X_t^{(\\tau)} = \\tfrac{1}{4}(t - \\tau)^2$ for $t \\ge \\tau$ is a strong solution, hence strong (pathwise) uniqueness fails at $X_0=0$.\n\nC. Pathwise (strong) uniqueness holds because $b$ is continuous and has sublinear growth.\n\nD. Weak uniqueness holds even though strong uniqueness fails.\n\nE. No solution exists beyond some finite time because any nonzero solution explodes in finite time.", "solution": "The problem statement is a valid, well-posed mathematical problem in the theory of stochastic differential equations, specifically concerning existence and uniqueness of solutions.\n\nThe stochastic differential equation (SDE) under consideration is:\n$$\ndX_t = b(X_t)\\,dt, \\qquad X_0 = 0,\n$$\nwhere the drift coefficient is $b(x) = \\sqrt{|x|}$ and the diffusion coefficient is $\\sigma(x) \\equiv 0$. The equation is to be interpreted for an Itô process $X_t$. The integral form of the SDE is:\n$$\nX_t = X_0 + \\int_0^t b(X_s)\\,ds + \\int_0^t \\sigma(X_s)\\,dW_s\n$$\nSubstituting the given values for $b$, $\\sigma$, and $X_0$:\n$$\nX_t = \\int_0^t \\sqrt{|X_s|}\\,ds\n$$\nSince the stochastic integral term involving the Brownian motion $W_t$ is absent, this equation is not truly stochastic. Any solution $X_t$ must be a deterministic function of time, say $X_t = f(t)$. The equation is equivalent to the ordinary differential equation (ODE):\n$$\n\\frac{dX_t}{dt} = \\sqrt{|X_t|}, \\qquad X_0 = 0.\n$$\nA strong solution to an SDE must be adapted to the filtration generated by a given Brownian motion $W_t$. Since any solution to our equation is deterministic, it is adapted to any filtration, including any Brownian filtration. Therefore, finding a strong solution is equivalent to solving the above ODE.\n\nWe first check the conditions for the existence and uniqueness of solutions to this ODE. The standard Picard-Lindelöf theorem guarantees local existence and uniqueness if the function $b(x) = \\sqrt{|x|}$ is locally Lipschitz continuous. Let's check this condition in a neighborhood of $x=0$. For $x  0$ and $y=0$:\n$$\n\\frac{|b(x) - b(y)|}{|x - y|} = \\frac{|\\sqrt{x} - \\sqrt{0}|}{|x - 0|} = \\frac{\\sqrt{x}}{x} = \\frac{1}{\\sqrt{x}}\n$$\nAs $x \\to 0^+$, this ratio diverges to $+\\infty$. Thus, the function $b(x)$ is not locally Lipschitz continuous at $x=0$, and the standard theorem for uniqueness does not apply. This suggests that uniqueness may fail.\n\nLet's evaluate each option:\n\n**A. There exists at least one strong solution adapted to any given Brownian filtration, and $X_t \\equiv 0$ for all $t \\ge 0$ is one such solution.**\n\nLet's test if $X_t \\equiv 0$ is a solution.\nThe initial condition is satisfied: $X_0 = 0$.\nThe ODE is also satisfied: $\\frac{d}{dt}(0) = 0$ and $\\sqrt{|0|} = 0$. So $\\frac{dX_t}{dt} = \\sqrt{|X_t|}$ holds for all $t \\ge 0$.\nThe process $X_t=0$ is a deterministic function. A deterministic process is measurable with respect to the trivial filtration $\\{\\emptyset, \\Omega\\}$ at any time $t$, and is therefore adapted to any filtration $(\\mathcal{F}_t)_{t \\ge 0}$ that satisfies the usual conditions, including any filtration generated by a Brownian motion $W_t$.\nSince $X_t=0$ solves the integral equation and is adapted to any given Brownian filtration, it is a strong solution. The statement claims that at least one such solution exists and provides an example. This is correct.\nVerdict: **Correct**.\n\n**B. For each deterministic $\\tau \\ge 0$, the process defined by $X_t^{(\\tau)} = 0$ for $t \\in [0,\\tau]$ and $X_t^{(\\tau)} = \\tfrac{1}{4}(t - \\tau)^2$ for $t \\ge \\tau$ is a strong solution, hence strong (pathwise) uniqueness fails at $X_0=0$.**\n\nLet's verify if $X_t^{(\\tau)}$ is a solution to the ODE $\\frac{dX_t}{dt} = \\sqrt{|X_t|}$ with $X_0 = 0$.\nThe initial condition $X_0^{(\\tau)} = 0$ is satisfied since $\\tau \\ge 0$.\nFor $t \\in (0, \\tau)$, we have $X_t^{(\\tau)} = 0$, so $\\frac{d}{dt}X_t^{(\\tau)} = 0$ and $\\sqrt{|X_t^{(\\tau)}|} = 0$. The equation holds.\nFor $t  \\tau$, we have $X_t^{(\\tau)} = \\frac{1}{4}(t - \\tau)^2 \\ge 0$.\nThe derivative is $\\frac{d}{dt}X_t^{(\\tau)} = \\frac{1}{4} \\cdot 2(t - \\tau) = \\frac{1}{2}(t - \\tau)$.\nThe right-hand side is $\\sqrt{|X_t^{(\\tau)}|} = \\sqrt{\\frac{1}{4}(t - \\tau)^2} = \\frac{1}{2}|t - \\tau| = \\frac{1}{2}(t - \\tau)$ since $t  \\tau$. The equation holds.\nAt $t = \\tau$, we check the derivative. The left-derivative is $0$. The right-derivative is $\\lim_{h \\to 0^+} \\frac{\\frac{1}{4}((\\tau+h)-\\tau)^2 - 0}{h} = \\lim_{h \\to 0^+} \\frac{h^2/4}{h} = 0$. The derivative is $0$. Also, $\\sqrt{|X_{\\tau}^{(\\tau)}|} = \\sqrt{0} = 0$. The equation holds at $t = \\tau$.\nThus, for every $\\tau \\ge 0$, $X_t^{(\\tau)}$ is a valid solution. As it is a deterministic process, it is a strong solution for any given Brownian filtration.\nWe have multiple distinct strong solutions for the same initial condition $X_0=0$ on the same filtered probability space. For example, $X_t \\equiv 0$ (which corresponds to the limit $\\tau \\to \\infty$) and $X_t^{(0)} = \\frac{1}{4}t^2$ are two different solutions.\nTherefore, strong (pathwise) uniqueness fails. The statement is correct.\nVerdict: **Correct**.\n\n**C. Pathwise (strong) uniqueness holds because $b$ is continuous and has sublinear growth.**\n\nAs demonstrated in the analysis of option B, pathwise uniqueness fails. The premise of this statement is false. The reason provided, \"because $b$ is continuous and has sublinear growth,\" is part of the conditions for existence of a weak solution (e.g., via the Skorokhod embedding theorem), but it is not sufficient for pathwise uniqueness. Pathwise uniqueness typically requires a Lipschitz or a similar condition (like the Osgood criterion for uniqueness), which $b(x)=\\sqrt{|x|}$ fails to satisfy at $x=0$.\nVerdict: **Incorrect**.\n\n**D. Weak uniqueness holds even though strong uniqueness fails.**\n\nWeak uniqueness means that any two weak solutions with the same initial condition have the same law (probability distribution). A weak solution is a pair $(X_t, W_t)$ on some filtered probability space.\nIn our case, the solutions are deterministic paths. Let's consider two of the solutions we found:\n$1$. $X_t^1 \\equiv 0$. The law of this process is a Dirac measure on the path that is identically zero.\n$2$. $X_t^2 = X_t^{(0)} = \\frac{1}{4}t^2$. The law of this process is a Dirac measure on the path $f(t) = \\frac{1}{4}t^2$.\nSince the paths are different, their laws are different. Therefore, weak uniqueness fails.\nIn general, for one-dimensional SDEs of the form $dX_t=b(X_t)dt + \\sigma(X_t)dW_t$, the Yamada-Watanabe theorem implies that pathwise uniqueness is equivalent to weak uniqueness coupled with existence of a weak solution. As pathwise uniqueness fails, weak uniqueness must also fail.\nVerdict: **Incorrect**.\n\n**E. No solution exists beyond some finite time because any nonzero solution explodes in finite time.**\n\nLet's examine the nonzero solutions we found: $X_t^{(\\tau)} = \\frac{1}{4}(t - \\tau)^2$ for $t \\ge \\tau$. This function is a quadratic polynomial in $t$. It is well-defined and finite for all $t \\in \\mathbb{R}$. It does not \"explode\" in finite time. Therefore, solutions exist for all time $t \\ge 0$.\nThe premise \"any nonzero solution explodes in finite time\" is false. Generally, solutions to $\\frac{dx}{dt} = f(x)$ may explode if $f(x)$ grows superlinearly (e.g., $f(x)=x^2$). Here, $b(x)=\\sqrt{|x|}$ has sublinear growth, which is associated with global existence of solutions.\nMore formally, by the Osgood criterion for non-explosion, a solution to $x'(t) = f(x(t))$ does not explode in finite time if the integral $\\int_{x_1}^{\\infty} \\frac{du}{f(u)}$ diverges for some $x_1$. For our problem (with $X_t0$), this is $\\int_{1}^{\\infty} \\frac{dx}{\\sqrt{x}} = [2\\sqrt{x}]_{1}^{\\infty} = \\infty$. The criterion is satisfied, confirming that solutions do not explode.\nVerdict: **Incorrect**.", "answer": "$$\\boxed{AB}$$", "id": "3061833"}, {"introduction": "While some SDEs have elegant analytical solutions, most require numerical methods to be solved in practice. This final exercise [@problem_id:3061787] bridges the gap between theory and application by introducing the Euler-Maruyama method, a foundational tool for simulating stochastic processes. By applying it to the famous Ornstein-Uhlenbeck process and comparing your results to the exact solution, you will gain a concrete understanding of how numerical approximations work and where their errors originate.", "problem": "Consider the Ornstein–Uhlenbeck process defined by the linear Stochastic Differential Equation (SDE)\n$$\n\\mathrm{d}X_{t}=\\theta\\left(\\mu - X_{t}\\right)\\mathrm{d}t+\\sigma\\,\\mathrm{d}W_{t}, \\quad X_{0}=x_{0},\n$$\nwhere $\\theta0$, $\\mu\\in\\mathbb{R}$, $\\sigma0$, and $\\{W_{t}\\}_{t\\geq 0}$ is a standard Wiener process (Brownian motion). Let $h0$ be a given time step.\n\nTasks:\n- Using the Euler–Maruyama discretization, compute the one-step approximation $X_{h}^{\\mathrm{EM}}$ from $X_{0}=x_{0}$ and determine its conditional mean and variance given $X_{0}=x_{0}$.\n- Using fundamental properties of linear SDEs and Itô isometry, derive the exact conditional mean and variance of $X_{h}$ given $X_{0}=x_{0}$.\n- Define the discrepancies\n$$\n\\Delta_{\\mathrm{mean}} \\equiv \\mathbb{E}\\!\\left[X_{h}^{\\mathrm{EM}}\\mid X_{0}=x_{0}\\right]-\\mathbb{E}\\!\\left[X_{h}\\mid X_{0}=x_{0}\\right], \n\\qquad\n\\Delta_{\\mathrm{var}} \\equiv \\mathrm{Var}\\!\\left(X_{h}^{\\mathrm{EM}}\\mid X_{0}=x_{0}\\right)-\\mathrm{Var}\\!\\left(X_{h}\\mid X_{0}=x_{0}\\right).\n$$\nProvide a single, closed-form analytic expression for the pair $\\left(\\Delta_{\\mathrm{mean}},\\Delta_{\\mathrm{var}}\\right)$ in terms of $\\theta$, $\\mu$, $\\sigma$, $h$, and $x_{0}$.\n\nAnswer format:\n- Your final answer must be a single row matrix using the $\\mathrm{pmatrix}$ environment that contains $\\Delta_{\\mathrm{mean}}$ and $\\Delta_{\\mathrm{var}}$ in closed form.", "solution": "The problem statement is subjected to validation.\n\n### Step 1: Extract Givens\n- The process is the Ornstein–Uhlenbeck process, defined by the Stochastic Differential Equation (SDE):\n$$\n\\mathrm{d}X_{t}=\\theta\\left(\\mu - X_{t}\\right)\\mathrm{d}t+\\sigma\\,\\mathrm{d}W_{t}\n$$\n- Initial condition: $X_{0}=x_{0}$\n- Parameters: $\\theta0$, $\\mu\\in\\mathbb{R}$, $\\sigma0$\n- $\\{W_{t}\\}_{t\\geq 0}$ is a standard Wiener process.\n- Time step: $h0$\n- Task 1: Compute the one-step Euler–Maruyama approximation $X_{h}^{\\mathrm{EM}}$ from $X_{0}=x_{0}$ and find its conditional mean $\\mathbb{E}\\!\\left[X_{h}^{\\mathrm{EM}}\\mid X_{0}=x_{0}\\right]$ and variance $\\mathrm{Var}\\!\\left(X_{h}^{\\mathrm{EM}}\\mid X_{0}=x_{0}\\right)$.\n- Task 2: Derive the exact conditional mean $\\mathbb{E}\\!\\left[X_{h}\\mid X_{0}=x_{0}\\right]$ and variance $\\mathrm{Var}\\!\\left(X_{h}\\mid X_{0}=x_{0}\\right)$.\n- Task 3: Define and compute the discrepancies:\n$$\n\\Delta_{\\mathrm{mean}} \\equiv \\mathbb{E}\\!\\left[X_{h}^{\\mathrm{EM}}\\mid X_{0}=x_{0}\\right]-\\mathbb{E}\\!\\left[X_{h}\\mid X_{0}=x_{0}\\right]\n$$\n$$\n\\Delta_{\\mathrm{var}} \\equiv \\mathrm{Var}\\!\\left(X_{h}^{\\mathrm{EM}}\\mid X_{0}=x_{0}\\right)-\\mathrm{Var}\\!\\left(X_{h}\\mid X_{0}=x_{0}\\right)\n$$\n- The final answer is the pair $(\\Delta_{\\mathrm{mean}}, \\Delta_{\\mathrm{var}})$ in a single row matrix.\n\n### Step 2: Validate Using Extracted Givens\nThe problem is scientifically grounded, well-posed, and objective.\n- **Scientific Grounding**: The Ornstein–Uhlenbeck process, Euler–Maruyama discretization, and Itô calculus are standard, well-established topics in the theory of stochastic differential equations. The SDE is linear and its properties are well-known.\n- **Well-Posedness**: The problem asks for the calculation of well-defined statistical moments (mean and variance) for both the exact solution and a numerical approximation. All parameters are clearly defined, and sufficient information is provided to derive a unique analytical solution for the requested quantities.\n- **Objectivity**: The problem is stated in precise mathematical language, free from ambiguity or subjective interpretation.\n\nThe problem does not exhibit any of the flaws listed in the validation criteria. It is a standard, formalizable exercise in stochastic calculus and numerical methods for SDEs.\n\n### Step 3: Verdict and Action\nThe problem is **valid**. A complete solution will be provided.\n\n### Solution Derivation\n\n**Part 1: Euler–Maruyama Approximation**\n\nThe Euler–Maruyama discretization scheme for a general SDE $\\mathrm{d}X_t = a(t, X_t)\\mathrm{d}t + b(t, X_t)\\mathrm{d}W_t$ is given by $X_{t+h} \\approx X_t + a(t, X_t)h + b(t, X_t)(W_{t+h}-W_t)$.\nFor the given Ornstein–Uhlenbeck process, the drift and diffusion coefficients are $a(t, X_t) = \\theta(\\mu - X_t)$ and $b(t, X_t) = \\sigma$.\nA single step of length $h$ from the initial condition $X_{0}=x_{0}$ yields the approximation $X_{h}^{\\mathrm{EM}}$:\n$$\nX_{h}^{\\mathrm{EM}} = X_{0} + \\theta(\\mu - X_{0})h + \\sigma(W_{h} - W_{0})\n$$\nGiven $X_{0}=x_{0}$ and the property that $W_{0}=0$ for a standard Wiener process, this becomes:\n$$\nX_{h}^{\\mathrm{EM}} = x_{0} + \\theta(\\mu - x_{0})h + \\sigma W_{h}\n$$\nNow, we compute the conditional mean and variance of $X_{h}^{\\mathrm{EM}}$ given $X_{0}=x_{0}$. The Wiener process increment $W_{h}$ is a random variable with distribution $W_{h} \\sim \\mathcal{N}(0, h)$, so its mean is $\\mathbb{E}[W_{h}]=0$ and its variance is $\\mathrm{Var}(W_{h})=h$.\n\nThe conditional mean is:\n$$\n\\mathbb{E}\\!\\left[X_{h}^{\\mathrm{EM}}\\mid X_{0}=x_{0}\\right] = \\mathbb{E}\\!\\left[x_{0} + \\theta(\\mu - x_{0})h + \\sigma W_{h}\\right] = x_{0} + \\theta(\\mu - x_{0})h + \\sigma \\mathbb{E}[W_{h}]\n$$\n$$\n\\mathbb{E}\\!\\left[X_{h}^{\\mathrm{EM}}\\mid X_{0}=x_{0}\\right] = x_{0} + \\theta(\\mu - x_{0})h\n$$\nThe conditional variance is:\n$$\n\\mathrm{Var}\\!\\left(X_{h}^{\\mathrm{EM}}\\mid X_{0}=x_{0}\\right) = \\mathrm{Var}\\!\\left(x_{0} + \\theta(\\mu - x_{0})h + \\sigma W_{h}\\right)\n$$\nSince $x_{0}$ is fixed by the condition, the first two terms are constants, so they do not contribute to the variance.\n$$\n\\mathrm{Var}\\!\\left(X_{h}^{\\mathrm{EM}}\\mid X_{0}=x_{0}\\right) = \\mathrm{Var}\\!\\left(\\sigma W_{h}\\right) = \\sigma^{2}\\mathrm{Var}\\!\\left(W_{h}\\right) = \\sigma^{2}h\n$$\n\n**Part 2: Exact Solution**\n\nTo find the exact solution for $X_{h}$, we solve the linear SDE. The SDE can be written as:\n$$\n\\mathrm{d}X_{t} + \\theta X_{t}\\mathrm{d}t = \\theta\\mu\\,\\mathrm{d}t + \\sigma\\,\\mathrm{d}W_{t}\n$$\nWe use an integrating factor $I_t = \\exp(\\theta t)$. Multiplying the SDE by $I_t$:\n$$\n\\exp(\\theta t)\\mathrm{d}X_{t} + \\theta\\exp(\\theta t) X_{t}\\mathrm{d}t = \\theta\\mu\\exp(\\theta t)\\,\\mathrm{d}t + \\sigma\\exp(\\theta t)\\,\\mathrm{d}W_{t}\n$$\nBy Itô's product rule, the left-hand side is the differential of $\\exp(\\theta t)X_{t}$:\n$$\n\\mathrm{d}(\\exp(\\theta t)X_{t}) = \\theta\\mu\\exp(\\theta t)\\,\\mathrm{d}t + \\sigma\\exp(\\theta t)\\,\\mathrm{d}W_{t}\n$$\nIntegrating from $t=0$ to $t=h$:\n$$\n\\int_{0}^{h}\\mathrm{d}(\\exp(\\theta s)X_{s}) = \\int_{0}^{h}\\theta\\mu\\exp(\\theta s)\\,\\mathrm{d}s + \\int_{0}^{h}\\sigma\\exp(\\theta s)\\,\\mathrm{d}W_{s}\n$$\n$$\n\\exp(\\theta h)X_{h} - X_{0} = \\theta\\mu\\left[\\frac{\\exp(\\theta s)}{\\theta}\\right]_{0}^{h} + \\sigma\\int_{0}^{h}\\exp(\\theta s)\\,\\mathrm{d}W_{s}\n$$\n$$\n\\exp(\\theta h)X_{h} - X_{0} = \\mu(\\exp(\\theta h) - 1) + \\sigma\\int_{0}^{h}\\exp(\\theta s)\\,\\mathrm{d}W_{s}\n$$\nSolving for $X_{h}$:\n$$\nX_{h} = X_{0}\\exp(-\\theta h) + \\mu(1 - \\exp(-\\theta h)) + \\sigma\\exp(-\\theta h)\\int_{0}^{h}\\exp(\\theta s)\\,\\mathrm{d}W_{s}\n$$\nThe stochastic integral can be rewritten as $\\sigma\\int_{0}^{h}\\exp(-\\theta(h-s))\\,\\mathrm{d}W_{s}$. Given $X_0 = x_0$, the solution is:\n$$\nX_{h} = x_{0}\\exp(-\\theta h) + \\mu(1 - \\exp(-\\theta h)) + \\sigma\\int_{0}^{h}\\exp(-\\theta(h-s))\\,\\mathrm{d}W_{s}\n$$\nThe conditional mean is found by taking the expectation. The Itô integral has zero mean.\n$$\n\\mathbb{E}\\!\\left[X_{h}\\mid X_{0}=x_{0}\\right] = x_{0}\\exp(-\\theta h) + \\mu(1 - \\exp(-\\theta h))\n$$\nThe conditional variance is found using the Itô isometry property, which states that for a deterministic function $f(t)$, $\\mathrm{Var}(\\int_{0}^{T} f(t)\\,\\mathrm{d}W_t) = \\int_{0}^{T} f(t)^2\\,\\mathrm{d}t$. The non-stochastic terms vanish when taking the variance.\n$$\n\\mathrm{Var}\\!\\left(X_{h}\\mid X_{0}=x_{0}\\right) = \\mathrm{Var}\\!\\left(\\sigma\\int_{0}^{h}\\exp(-\\theta(h-s))\\,\\mathrm{d}W_{s}\\right) = \\sigma^{2}\\int_{0}^{h}\\left(\\exp(-\\theta(h-s))\\right)^{2}\\mathrm{d}s\n$$\n$$\n\\mathrm{Var}\\!\\left(X_{h}\\mid X_{0}=x_{0}\\right) = \\sigma^{2}\\int_{0}^{h}\\exp(-2\\theta(h-s))\\,\\mathrm{d}s\n$$\nEvaluating the integral:\n$$\n\\int_{0}^{h}\\exp(-2\\theta h)\\exp(2\\theta s)\\,\\mathrm{d}s = \\exp(-2\\theta h)\\left[\\frac{\\exp(2\\theta s)}{2\\theta}\\right]_{0}^{h} = \\exp(-2\\theta h)\\left(\\frac{\\exp(2\\theta h) - 1}{2\\theta}\\right) = \\frac{1 - \\exp(-2\\theta h)}{2\\theta}\n$$\nSo, the exact conditional variance is:\n$$\n\\mathrm{Var}\\!\\left(X_{h}\\mid X_{0}=x_{0}\\right) = \\frac{\\sigma^{2}}{2\\theta}(1 - \\exp(-2\\theta h))\n$$\n\n**Part 3: Discrepancies**\n\nNow we compute the discrepancies $\\Delta_{\\mathrm{mean}}$ and $\\Delta_{\\mathrm{var}}$.\n\nFor the mean:\n$$\n\\Delta_{\\mathrm{mean}} = \\mathbb{E}\\!\\left[X_{h}^{\\mathrm{EM}}\\mid X_{0}=x_{0}\\right]-\\mathbb{E}\\!\\left[X_{h}\\mid X_{0}=x_{0}\\right]\n$$\n$$\n\\Delta_{\\mathrm{mean}} = \\left(x_{0} + \\theta(\\mu - x_{0})h\\right) - \\left(x_{0}\\exp(-\\theta h) + \\mu(1 - \\exp(-\\theta h))\\right)\n$$\n$$\n\\Delta_{\\mathrm{mean}} = x_{0} + \\theta\\mu h - \\theta x_{0}h - x_{0}\\exp(-\\theta h) - \\mu + \\mu\\exp(-\\theta h)\n$$\nRe-grouping terms with respect to $\\mu$ and $x_0$:\n$$\n\\Delta_{\\mathrm{mean}} = \\mu(\\theta h - 1 + \\exp(-\\theta h)) + x_{0}(1 - \\theta h - \\exp(-\\theta h))\n$$\n$$\n\\Delta_{\\mathrm{mean}} = \\mu(\\theta h - 1 + \\exp(-\\theta h)) - x_{0}(\\theta h - 1 + \\exp(-\\theta h))\n$$\n$$\n\\Delta_{\\mathrm{mean}} = (\\mu - x_{0})(\\theta h - 1 + \\exp(-\\theta h))\n$$\n\nFor the variance:\n$$\n\\Delta_{\\mathrm{var}} = \\mathrm{Var}\\!\\left(X_{h}^{\\mathrm{EM}}\\mid X_{0}=x_{0}\\right)-\\mathrm{Var}\\!\\left(X_{h}\\mid X_{0}=x_{0}\\right)\n$$\n$$\n\\Delta_{\\mathrm{var}} = \\sigma^{2}h - \\frac{\\sigma^{2}}{2\\theta}(1 - \\exp(-2\\theta h))\n$$\n$$\n\\Delta_{\\mathrm{var}} = \\sigma^{2}\\left(h - \\frac{1 - \\exp(-2\\theta h)}{2\\theta}\\right)\n$$\n\nThe pair $(\\Delta_{\\mathrm{mean}}, \\Delta_{\\mathrm{var}})$ is thus determined.", "answer": "$$\n\\boxed{\\begin{pmatrix} (\\mu - x_{0})(\\exp(-\\theta h) + \\theta h - 1)  \\sigma^{2}\\left(h - \\frac{1 - \\exp(-2\\theta h)}{2\\theta}\\right) \\end{pmatrix}}\n$$", "id": "3061787"}]}