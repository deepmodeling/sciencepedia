{"hands_on_practices": [{"introduction": "The Ornstein-Uhlenbeck process is fundamentally characterized by its tendency to revert to a long-term mean, $\\mu$. This exercise invites you to explore this core concept from a foundational perspective. By determining the specific initial condition under which the process's expected value remains constant, you will gain a deeper intuition for the role of $\\mu$ as the gravitational center or equilibrium point for the process's expected trajectory [@problem_id:772788].", "problem": "An Ornstein-Uhlenbeck (OU) process, often used to model mean-reverting phenomena like interest rates or particle velocities, is described by the following stochastic differential equation (SDE):\n$$\ndX_t = \\theta(\\mu - X_t)dt + \\sigma dW_t\n$$\nIn this equation, $X_t$ is the value of the process at time $t$. The parameters $\\theta  0$, $\\mu$, and $\\sigma  0$ are constants representing the speed of reversion, the long-term mean, and the volatility, respectively. $W_t$ is a standard Wiener process. The process starts from a known deterministic initial value $X_0 = x_0$.\n\nThe expected value of the process, $m(t) = E[X_t]$, evolves according to a deterministic ordinary differential equation (ODE) derived from the SDE.\n\nYour task is to derive the specific initial value $x_0$ for which the expected value of the process, $E[X_t]$, remains constant for all time $t \\ge 0$.", "solution": "1. From the SDE \n$$dX_t=\\theta(\\mu - X_t)\\,dt+\\sigma\\,dW_t$$\nthe expectation $m(t)=E[X_t]$ satisfies the deterministic ODE\n$$m'(t)=\\theta\\bigl(\\mu - m(t)\\bigr)\\,. $$\n\n2. Solve the linear ODE using an integrating factor or standard formula:\n$$m(t)=\\mu+\\bigl(x_0-\\mu\\bigr)e^{-\\theta t}\\,. $$\n\n3. For $m(t)$ to remain constant for all $t\\ge0$, the decaying exponential term must vanish:\n$$x_0-\\mu=0\\quad\\Longrightarrow\\quad x_0=\\mu\\,. $$", "answer": "$$\\boxed{\\mu}$$", "id": "772788"}, {"introduction": "While the classic Ornstein-Uhlenbeck model assumes a static long-term mean, many real-world phenomena exhibit reversion towards a target that is itself changing over time. This practice challenges you to extend your analysis to such a dynamic scenario, where the mean level $\\mu(t)$ is a linear function of time. Solving for the expected value of this generalized process will sharpen your skills in solving linear differential equations and deepen your understanding of how the process tracks a moving target [@problem_id:859261].", "problem": "The standard Ornstein-Uhlenbeck (OU) process is a stochastic process that describes the velocity of a massive Brownian particle under the influence of friction. It is characterized by a tendency to revert towards a long-term mean. A generalized version of this process can be constructed where the mean-reversion level is not constant but changes over time.\n\nConsider a modified Ornstein-Uhlenbeck process $X_t$ described by the following stochastic differential equation (SDE):\n$$\ndX_t = \\theta (\\mu(t) - X_t) dt + \\sigma dW_t\n$$\nwhere $t \\geq 0$. In this equation:\n- $X_t$ is the value of the process at time $t$.\n- $\\theta  0$ is the rate of reversion to the mean.\n- $\\sigma  0$ is the volatility.\n- $W_t$ is a standard Wiener process.\n- $\\mu(t)$ is the time-dependent mean-reversion level, which is given by a linear function of time:\n$$\n\\mu(t) = a + bt\n$$\nfor some real constants $a$ and $b$.\n\nThe process starts from a known deterministic value $X(0) = X_0$.\n\nDerive the expected value of the process, $\\mathbb{E}[X_t]$, for any time $t \\geq 0$.", "solution": "We denote $m(t)=\\mathbb{E}[X_t]$.  Taking expectations in the SDE\n$$dX_t=\\theta\\bigl(a+bt -X_t\\bigr)\\,dt+\\sigma\\,dW_t$$\ngives the ODE\n$$\\frac{dm}{dt}=\\theta\\bigl(a+bt -m(t)\\bigr)\\,. $$\n\n1. Rewrite in standard form:\n$$\\frac{dm}{dt}+\\theta\\,m(t)=\\theta\\bigl(a+bt\\bigr)\\,. $$\n\n2. Integrating factor: $\\mu(t)=e^{\\theta t}$.  Multiply both sides:\n$$\\frac{d}{dt}\\bigl(e^{\\theta t}m(t)\\bigr)\n=\\theta\\,e^{\\theta t}(a+bt)\\,. $$\n\n3. Integrate from $0$ to $t$:\n$$e^{\\theta t}m(t)-m(0)\n=\\theta\\int_0^t e^{\\theta s}(a+bs)\\,ds\n=\\theta\\Bigl[a\\int_0^te^{\\theta s}ds+b\\int_0^ts\\,e^{\\theta s}ds\\Bigr].$$\n\n4. Compute the integrals symbolically:\n$$\\int_0^te^{\\theta s}ds=\\frac{e^{\\theta t}-1}{\\theta},\\qquad\n\\int_0^ts\\,e^{\\theta s}ds\n=\\frac{t\\,e^{\\theta t}}{\\theta}-\\frac{e^{\\theta t}-1}{\\theta^2}.$$\n\n5. Substitute back and divide by $e^{\\theta t}$:\n\n$$\nm(t)=X_0e^{-\\theta t}\n+a\\bigl(1-e^{-\\theta t}\\bigr)\n+b\\Bigl(t-\\frac{1-e^{-\\theta t}}{\\theta}\\Bigr).\n$$", "answer": "$$\\boxed{X_0e^{-\\theta t}+a\\bigl(1-e^{-\\theta t}\\bigr)+b\\Bigl(t-\\frac{1-e^{-\\theta t}}{\\theta}\\Bigr)}$$", "id": "859261"}, {"introduction": "A crucial skill in quantitative modeling is bridging the gap between continuous-time theory and discrete-time implementation for simulation and data analysis. This comprehensive practice guides you through the exact discretization of the Ornstein-Uhlenbeck process, revealing its fundamental connection to the autoregressive model of order one, AR(1) [@problem_id:3069482]. By first deriving the discrete-time parameters and then implementing them in code, you will translate theoretical insights into a practical, computational understanding of the process.", "problem": "Consider the Ornstein–Uhlenbeck process defined by the stochastic differential equation\n$$\ndX_t = \\theta \\left(\\mu - X_t\\right)\\,dt + \\sigma\\,dW_t,\n$$\nwhere $X_t$ is a real-valued process, $\\theta \\ge 0$ is the mean-reversion rate, $\\mu \\in \\mathbb{R}$ is the long-run mean, $\\sigma  0$ is the diffusion coefficient, and $W_t$ is a standard Wiener process. Use only the following fundamental base: the definition of the Itô integral, the linearity of the Itô integral, the integrating factor method for linear stochastic differential equations, and the Itô isometry for computing variances of Itô integrals.\n\nTask A (derivation): Starting from the given stochastic differential equation and the stated fundamental base, derive the exact discrete-time transition for a fixed step size $\\Delta  0$. Specifically, express $X_{t+\\Delta}$ as an affine function of $X_t$ plus a mean-zero Gaussian innovation that is independent of $X_t$. Then, by sampling at times $t_n = n\\Delta$, show that the sampled process $\\{X_{t_n}\\}_{n \\in \\mathbb{N}}$ satisfies an autoregressive recursion of order one with independent Gaussian innovations, and identify the autoregressive coefficient and the innovation variance as explicit functions of $\\theta$, $\\mu$, $\\sigma$, and $\\Delta$. Your derivation must also identify the correct continuous limits for the boundary cases $\\theta = 0$ and $\\Delta = 0$.\n\nTask B (program): Implement a program that, for each parameter quadruple $(\\theta,\\mu,\\sigma,\\Delta)$ in the test suite below, computes:\n- the autoregressive coefficient $\\phi$ associated with the sampled process at interval $\\Delta$,\n- the innovation standard deviation $s_{\\varepsilon}$,\n- a boolean diagnostic $b$ defined as follows:\n  - If $\\Delta = 0$, set $b$ to true.\n  - Else if $\\theta  0$, compute both the stationary variance implied by the discrete-time recursion, $s_{\\varepsilon}^2/(1-\\phi^2)$, and the continuous-time stationary variance, $\\sigma^2/(2\\theta)$, and set $b$ to true if these two quantities are equal within absolute tolerance $10^{-12}$ or relative tolerance $10^{-10}$; otherwise set $b$ to false.\n  - Else (i.e., $\\theta = 0$ and $\\Delta  0$), set $b$ to true if $s_{\\varepsilon}^2$ equals $\\sigma^2 \\Delta$ within absolute tolerance $10^{-12}$ or relative tolerance $10^{-10}$; otherwise set $b$ to false.\n\nEdge-case handling and continuity requirements:\n- For $\\theta = 0$, your program must use the continuous limit of the innovation variance in place of any formula that involves division by $\\theta$.\n- For $\\Delta = 0$, your program must return $\\phi = 1$ and $s_{\\varepsilon} = 0$.\n\nTest suite:\nUse exactly the following five parameter sets (with the order preserved) to form the test suite:\n1. $(\\theta,\\mu,\\sigma,\\Delta) = (0.7,\\,1.2,\\,0.5,\\,0.1)$\n2. $(\\theta,\\mu,\\sigma,\\Delta) = (0,\\,0.0,\\,1.0,\\,0.25)$\n3. $(\\theta,\\mu,\\sigma,\\Delta) = (2.0,\\,-0.5,\\,0.3,\\,1.0)$\n4. $(\\theta,\\mu,\\sigma,\\Delta) = (1.1,\\,2.0,\\,0.8,\\,0)$\n5. $(\\theta,\\mu,\\sigma,\\Delta) = (5.0,\\,0.0,\\,2.0,\\,10^{-8})$\n\nRequired final output format:\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets. Each element of this list corresponds to one test case and must itself be a list $[\\phi, s_{\\varepsilon}, b]$, where $\\phi$ and $s_{\\varepsilon}$ are real numbers and $b$ is a boolean. For example, a valid output structure is\n$$\n[[\\phi_1, s_{\\varepsilon,1}, b_1],[\\phi_2, s_{\\varepsilon,2}, b_2],\\dots]\n$$\nwith no additional text before or after the line.", "solution": "The problem requires the derivation of the exact discrete-time transition for the Ornstein-Uhlenbeck (OU) process and its implementation in a program. The validation of the problem statement is the first step.\n\n### Problem Validation\n\n**Step 1: Extract Givens**\n-   **SDE**: $dX_t = \\theta (\\mu - X_t) dt + \\sigma dW_t$\n-   **Parameters**: $\\theta \\ge 0$ (mean-reversion rate), $\\mu \\in \\mathbb{R}$ (long-run mean), $\\sigma  0$ (diffusion coefficient), $W_t$ (standard Wiener process).\n-   **Methodological Constraints**: Use only the definition of the Itô integral, its linearity, the integrating factor method for linear SDEs, and the Itô isometry.\n-   **Task A (Derivation)**: Derive the exact discrete-time transition $X_{t+\\Delta} = f(X_t, \\text{innovation})$, show it is an AR(1) process for sampled times, identify the autoregressive coefficient $\\phi$ and innovation variance $\\sigma_\\varepsilon^2$, and find the limits for $\\theta = 0$ and $\\Delta = 0$.\n-   **Task B (Program)**: Compute $[\\phi, s_{\\varepsilon}, b]$ for given test cases, where $s_\\varepsilon$ is the innovation standard deviation and $b$ is a boolean diagnostic checking the consistency of stationary variances or limiting behavior.\n-   **Edge Cases**: Specific handling for $\\Delta=0$ ($\\phi=1, s_\\varepsilon=0, b=\\text{true}$) and $\\theta=0$ (use limit for innovation variance).\n-   **Test Suite**: Five quadruples of $(\\theta, \\mu, \\sigma, \\Delta)$ are provided.\n-   **Output Format**: A single line representing a list of lists: $[[\\phi_1, s_{\\varepsilon,1}, b_1], \\dots, [\\phi_5, s_{\\varepsilon,5}, b_5]]$.\n\n**Step 2: Validate Using Extracted Givens**\n-   **Scientific Grounding**: The Ornstein-Uhlenbeck process is a fundamental concept in stochastic processes, with well-established theory. The problem is scientifically and mathematically sound.\n-   **Well-Posedness**: The problem is well-posed. It asks for a standard derivation and a direct implementation of the derived formulas. All parameters, constraints, and objectives are clearly defined, leading to a unique solution.\n-   **Objectivity**: The language is formal and mathematical, free from subjectivity or ambiguity.\n-   **Overall Assessment**: The problem does not violate any of the invalidity criteria. It is a standard, self-contained, and non-trivial problem in applied stochastic calculus.\n\n**Step 3: Verdict and Action**\nThe problem is **valid**. A solution will be provided.\n\n### Task A: Derivation\n\nThe Ornstein-Uhlenbeck process is described by the stochastic differential equation (SDE):\n$$\ndX_t = \\theta (\\mu - X_t) dt + \\sigma dW_t\n$$\nThis SDE is a linear first-order equation. We can rewrite it as:\n$$\ndX_t + \\theta X_t dt = \\theta \\mu dt + \\sigma dW_t\n$$\nTo solve this, we use the integrating factor method. The integrating factor is $I(t) = e^{\\int \\theta ds} = e^{\\theta t}$. We consider the process $Y_t = e^{\\theta t} X_t$.\nUsing Itô's lemma for $f(t, X_t) = e^{\\theta t} X_t$, with $\\frac{\\partial f}{\\partial t} = \\theta e^{\\theta t} X_t$, $\\frac{\\partial f}{\\partial x} = e^{\\theta t}$, and $\\frac{\\partial^2 f}{\\partial x^2} = 0$, we find the differential of $Y_t$:\n$$\nd(e^{\\theta t} X_t) = (\\theta e^{\\theta t} X_t) dt + e^{\\theta t} dX_t\n$$\nSubstituting the expression for $dX_t$:\n$$\nd(e^{\\theta t} X_t) = \\theta e^{\\theta t} X_t dt + e^{\\theta t} (\\theta \\mu dt - \\theta X_t dt + \\sigma dW_t)\n$$\nThe terms involving $X_t$ cancel out:\n$$\nd(e^{\\theta t} X_t) = \\theta \\mu e^{\\theta t} dt + \\sigma e^{\\theta t} dW_t\n$$\nIntegrating both sides from a starting time $t$ to a future time $t+\\Delta$ (where $\\Delta  0$):\n$$\n\\int_t^{t+\\Delta} d(e^{\\theta s} X_s) = \\int_t^{t+\\Delta} \\theta \\mu e^{\\theta s} ds + \\int_t^{t+\\Delta} \\sigma e^{\\theta s} dW_s\n$$\n$$\ne^{\\theta (t+\\Delta)} X_{t+\\Delta} - e^{\\theta t} X_t = \\theta \\mu \\int_t^{t+\\Delta} e^{\\theta s} ds + \\sigma \\int_t^{t+\\Delta} e^{\\theta s} dW_s\n$$\nFor the case $\\theta  0$, the first integral on the right-hand side is:\n$$\n\\theta \\mu \\left[ \\frac{1}{\\theta} e^{\\theta s} \\right]_t^{t+\\Delta} = \\mu (e^{\\theta(t+\\Delta)} - e^{\\theta t})\n$$\nSubstituting this back and solving for $X_{t+\\Delta}$:\n$$\ne^{\\theta (t+\\Delta)} X_{t+\\Delta} = e^{\\theta t} X_t + \\mu (e^{\\theta(t+\\Delta)} - e^{\\theta t}) + \\sigma \\int_t^{t+\\Delta} e^{\\theta s} dW_s\n$$\nMultiplying by $e^{-\\theta(t+\\Delta)}$ isolates $X_{t+\\Delta}$:\n$$\nX_{t+\\Delta} = e^{-\\theta\\Delta} X_t + \\mu (1 - e^{-\\theta\\Delta}) + \\sigma e^{-\\theta(t+\\Delta)} \\int_t^{t+\\Delta} e^{\\theta s} dW_s\n$$\nThe last term can be rewritten by changing the integration variable in the stochastic integral:\n$$\nX_{t+\\Delta} = (1 - e^{-\\theta\\Delta})\\mu + e^{-\\theta\\Delta} X_t + \\sigma \\int_t^{t+\\Delta} e^{-\\theta(t+\\Delta-s)} dW_s\n$$\nThis equation expresses $X_{t+\\Delta}$ as an affine function of $X_t$ plus an innovation term. For a process sampled at discrete times $t_n = n\\Delta$, we have the recursion:\n$$\nX_{t_{n+1}} = c + \\phi X_{t_n} + \\varepsilon_{n+1}\n$$\nThis is an autoregressive process of order one, AR(1). The coefficients are:\n-   Autoregressive coefficient: $\\phi = e^{-\\theta\\Delta}$\n-   Constant term: $c = (1 - e^{-\\theta\\Delta})\\mu$\n-   Innovation term: $\\varepsilon_{n+1} = \\sigma \\int_{t_n}^{t_{n+1}} e^{-\\theta(t_{n+1}-s)} dW_s$\n\nThe innovation $\\varepsilon_{n+1}$ is an Itô integral of a deterministic function against a Wiener process. Thus, it is a Gaussian random variable with mean zero. Because the increments of the Wiener process are independent, the innovations $\\{\\varepsilon_n\\}$ form an independent and identically distributed sequence, and each $\\varepsilon_{n+1}$ is independent of $X_{t_n}$ (which depends on $W_s$ for $s \\le t_n$).\n\nTo find the variance of the innovation, $\\sigma_\\varepsilon^2 = E[\\varepsilon_{n+1}^2]$, we use the Itô isometry:\n$$\n\\sigma_\\varepsilon^2 = E\\left[ \\left( \\sigma \\int_{t_n}^{t_{n+1}} e^{-\\theta(t_{n+1}-s)} dW_s \\right)^2 \\right] = \\sigma^2 \\int_{t_n}^{t_{n+1}} \\left( e^{-\\theta(t_{n+1}-s)} \\right)^2 ds = \\sigma^2 \\int_{t_n}^{t_{n+1}} e^{-2\\theta(t_{n+1}-s)} ds\n$$\nLet $u = t_n - s$. The integral becomes: $\\int_{-\\Delta}^0 e^{-2\\theta(-\\Delta-u)} (-du) = \\int_0^{\\Delta} e^{-2\\theta(\\Delta-v)} dv$ by changing variables. A simpler substitution $u = s-t_n$ gives:\n$$\n\\sigma_\\varepsilon^2 = \\sigma^2 \\int_{0}^{\\Delta} e^{-2\\theta(\\Delta-u)} du = \\sigma^2 e^{-2\\theta\\Delta} \\int_{0}^{\\Delta} e^{2\\theta u} du = \\sigma^2 e^{-2\\theta\\Delta} \\left[ \\frac{e^{2\\theta u}}{2\\theta} \\right]_0^{\\Delta} = \\frac{\\sigma^2 e^{-2\\theta\\Delta}}{2\\theta}(e^{2\\theta\\Delta}-1)\n$$\nThus, for $\\theta  0$, the innovation variance is:\n$$\n\\sigma_\\varepsilon^2 = \\frac{\\sigma^2}{2\\theta} (1-e^{-2\\theta\\Delta})\n$$\n\n**Continuous Limits:**\n\n1.  **Case $\\Delta \\to 0$**:\n    -   $\\phi = e^{-\\theta\\Delta} \\to e^0 = 1$.\n    -   Using the Taylor expansion $e^{-x} \\approx 1-x$ for small $x$, the innovation variance becomes $\\sigma_\\varepsilon^2 \\approx \\frac{\\sigma^2}{2\\theta}(1-(1-2\\theta\\Delta)) = \\sigma^2\\Delta$. As $\\Delta \\to 0$, $\\sigma_\\varepsilon^2 \\to 0$. This gives $s_\\varepsilon=\\sqrt{\\sigma_\\varepsilon^2} \\to 0$. The problem specifies that for $\\Delta=0$, we must use $\\phi=1$ and $s_\\varepsilon=0$, which is consistent with this limit.\n\n2.  **Case $\\theta = 0$**:\n    The SDE simplifies to $dX_t = \\sigma dW_t$. The exact solution is $X_{t+\\Delta} = X_t + \\sigma(W_{t+\\Delta}-W_t)$. This is an AR(1) process with $\\phi=1$ and an innovation $\\varepsilon = \\sigma(W_{t+\\Delta}-W_t)$ which has variance $\\sigma^2 \\Delta$.\n    We can confirm this by taking the limit of our general formulas as $\\theta \\to 0$.\n    -   $\\phi = e^{-\\theta\\Delta} \\to e^0 = 1$.\n    -   For the variance, we have a $\\frac{0}{0}$ indeterminacy. Using L'Hôpital's rule on the ratio $f(\\theta)/g(\\theta) = (1-e^{-2\\theta\\Delta})/(2\\theta)$:\n        $$\n        \\lim_{\\theta \\to 0} \\sigma_\\varepsilon^2 = \\sigma^2 \\lim_{\\theta \\to 0} \\frac{\\frac{d}{d\\theta}(1-e^{-2\\theta\\Delta})}{\\frac{d}{d\\theta}(2\\theta)} = \\sigma^2 \\lim_{\\theta \\to 0} \\frac{-e^{-2\\theta\\Delta}(-2\\Delta)}{2} = \\sigma^2 \\Delta\n        $$\n    These results provide the formulas for the $\\theta=0$ edge case.\n\n**Stationary Variance Consistency Check**\nFor the AR(1) process to be stationary, we require $|\\phi|  1$, which holds for $\\theta0, \\Delta0$. The stationary variance $V$ of the discrete process is $V = \\frac{\\sigma_\\varepsilon^2}{1-\\phi^2}$. Substituting our derived expressions:\n$$\nV = \\frac{\\frac{\\sigma^2}{2\\theta}(1-e^{-2\\theta\\Delta})}{1-(e^{-\\theta\\Delta})^2} = \\frac{\\frac{\\sigma^2}{2\\theta}(1-e^{-2\\theta\\Delta})}{1-e^{-2\\theta\\Delta}} = \\frac{\\sigma^2}{2\\theta}\n$$\nThis is identical to the stationary variance of the continuous-time OU process. This analytical identity justifies the boolean diagnostic `b`, which checks if this equality holds numerically.\n\n**Summary of Formulas for Implementation:**\n-   If $\\Delta=0$: $\\phi=1$, $s_\\varepsilon=0$.\n-   If $\\Delta0$ and $\\theta=0$: $\\phi=1$, $s_\\varepsilon = \\sigma\\sqrt{\\Delta}$.\n-   If $\\Delta0$ and $\\theta0$: $\\phi=e^{-\\theta\\Delta}$, $s_\\varepsilon = \\sqrt{\\frac{\\sigma^2}{2\\theta}(1-e^{-2\\theta\\Delta})}$.\nThe boolean $b$ will be computed by checking the appropriate variance identities as specified in the problem statement.", "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Computes autoregressive parameters and a diagnostic for the discretized\n    Ornstein-Uhlenbeck process for a given set of test cases.\n    \"\"\"\n    \n    # Test suite: (theta, mu, sigma, delta)\n    test_cases = [\n        (0.7, 1.2, 0.5, 0.1),\n        (0.0, 0.0, 1.0, 0.25),\n        (2.0, -0.5, 0.3, 1.0),\n        (1.1, 2.0, 0.8, 0.0),\n        (5.0, 0.0, 2.0, 1e-8),\n    ]\n\n    results = []\n\n    def is_close(a, b, rtol, atol):\n        \"\"\"\n        Checks if two floats are close, with an 'or' condition for\n        absolute and relative tolerances, as specified in the problem.\n        \"\"\"\n        if abs(a - b) = atol:\n            return True\n        # The relative tolerance check is only meaningful if the reference value is non-zero\n        if b != 0:\n            if abs(a - b) / abs(b) = rtol:\n                return True\n        # If b is zero, the absolute tolerance check is the only one that applies.\n        return False\n\n    for case in test_cases:\n        theta, mu, sigma, delta = case\n        \n        phi = 0.0\n        s_varepsilon = 0.0\n        b = False\n        \n        # Absolute and relative tolerances for the diagnostic check\n        atol = 1e-12\n        rtol = 1e-10\n\n        # Handle edge cases and main logic based on problem statement\n        if delta == 0:\n            phi = 1.0\n            s_varepsilon = 0.0\n            b = True\n        elif theta == 0: # and delta  0\n            phi = 1.0\n            s_varepsilon_sq = sigma**2 * delta\n            s_varepsilon = np.sqrt(s_varepsilon_sq)\n            \n            # Diagnostic check for theta = 0 case\n            variance_limit = sigma**2 * delta\n            b = is_close(s_varepsilon_sq, variance_limit, rtol, atol)\n        else: # theta  0 and delta  0\n            phi = np.exp(-theta * delta)\n            \n            # Use a numerically stable way to compute (1 - exp(-x)) for small x\n            # This is equivalent to sigma**2/(2*theta) * (1 - np.exp(-2*theta*delta))\n            # Or sigma**2/(2*theta) * -np.expm1(-2*theta*delta)\n            s_varepsilon_sq = (sigma**2 / (2 * theta)) * (1 - phi**2)\n            s_varepsilon = np.sqrt(s_varepsilon_sq)\n            \n            # Diagnostic check for theta  0 case.\n            # The denominator (1 - phi**2) can be close to zero if theta*delta is small,\n            # but it is non-zero for theta  0 and delta  0.\n            if 1 - phi**2 == 0:\n                # This case should not be reached given theta0, delta0, but as a safeguard:\n                # if 1-phi^2 is numerically zero, the discrete variance is infinite.\n                # The continuous variance is finite. So they are not equal.\n                b = False\n            else:\n                discrete_stationary_var = s_varepsilon_sq / (1 - phi**2)\n                continuous_stationary_var = sigma**2 / (2 * theta)\n                b = is_close(discrete_stationary_var, continuous_stationary_var, rtol, atol)\n\n        results.append([phi, s_varepsilon, b])\n\n    # Format the final output string to match the required format exactly,\n    # without spaces inside the inner lists.\n    # str() of a list adds spaces, so we remove them.\n    final_output = str(results).replace(\" \", \"\")\n    print(final_output)\n\nsolve()\n```", "id": "3069482"}]}