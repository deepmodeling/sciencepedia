{"hands_on_practices": [{"introduction": "This first practice is about getting comfortable with the explicit solution of the Geometric Brownian Motion equation. By calculating the second moment of the process [@problem_id:1304906], you will directly engage with its statistical properties and see how the drift ($\\mu$) and volatility ($\\sigma$) parameters shape its long-term behavior. This exercise is a foundational step in quantitative analysis, as moments are key to understanding risk and return.", "problem": "A common model for the price of a non-dividend-paying stock, denoted by $S_t$ at time $t$, is the Geometric Brownian Motion (GBM). The price evolution is described by the equation:\n$$ S_t = S_0 \\exp\\left( \\left(\\mu - \\frac{1}{2}\\sigma^2\\right)t + \\sigma W_t \\right) $$\nHere, $S_0$ is the initial price of the stock at time $t=0$, which is a positive constant. The parameter $\\mu$ is the constant expected rate of return, and $\\sigma$ is the constant volatility of the stock price, with $\\sigma > 0$. The term $W_t$ represents a standard Wiener process (standard Brownian motion) starting at $W_0=0$. For any time $t>0$, the random variable $W_t$ is normally distributed with a mean of 0 and a variance of $t$.\n\nYour task is to calculate the second moment of the stock price at time $t$. Express your answer for $E[(S_t)^2]$ as an analytical function of the parameters $S_0$, $\\mu$, $\\sigma$, and $t$.", "solution": "We begin from the given geometric Brownian motion representation:\n$$\nS_{t} = S_{0} \\exp\\left(\\left(\\mu - \\frac{1}{2}\\sigma^{2}\\right)t + \\sigma W_{t}\\right).\n$$\nThe second moment is\n$$\nE\\left[S_{t}^{2}\\right] = E\\left[S_{0}^{2} \\exp\\left(2\\left(\\mu - \\frac{1}{2}\\sigma^{2}\\right)t + 2\\sigma W_{t}\\right)\\right].\n$$\nBy taking constants outside the expectation and splitting the exponential,\n$$\nE\\left[S_{t}^{2}\\right] = S_{0}^{2} \\exp\\left(2\\left(\\mu - \\frac{1}{2}\\sigma^{2}\\right)t\\right) E\\left[\\exp\\left(2\\sigma W_{t}\\right)\\right].\n$$\nUse the moment generating function of a normal random variable: since $W_{t} \\sim \\mathcal{N}(0,t)$, for any real $a$,\n$$\nE\\left[\\exp\\left(a W_{t}\\right)\\right] = \\exp\\left(\\frac{1}{2} a^{2} t\\right).\n$$\nSetting $a = 2\\sigma$ gives\n$$\nE\\left[\\exp\\left(2\\sigma W_{t}\\right)\\right] = \\exp\\left(\\frac{1}{2} (2\\sigma)^{2} t\\right) = \\exp\\left(2 \\sigma^{2} t\\right).\n$$\nTherefore,\n$$\nE\\left[S_{t}^{2}\\right] = S_{0}^{2} \\exp\\left(2\\left(\\mu - \\frac{1}{2}\\sigma^{2}\\right)t\\right) \\exp\\left(2 \\sigma^{2} t\\right) = S_{0}^{2} \\exp\\left((2\\mu + \\sigma^{2}) t\\right).\n$$", "answer": "$$\\boxed{S_{0}^{2} \\exp\\left((2 \\mu + \\sigma^{2}) t\\right)}$$", "id": "1304906"}, {"introduction": "Itô's lemma is the fundamental theorem of stochastic calculus, analogous to the chain rule in ordinary calculus. This exercise challenges you to apply it to a function of a GBM process, specifically $Y_t = (S_t)^k$ [@problem_id:1304922]. By doing so, you will discover an important closure property of GBM and gain practical mastery of a tool that is essential for deriving models for derivative securities.", "problem": "In financial mathematics, a common model for the price $S_t$ of a non-dividend-paying stock is the Geometric Brownian Motion (GBM), whose dynamics are described by the stochastic differential equation (SDE):\n$$dS_t = \\mu S_t dt + \\sigma S_t dW_t$$\nHere, $\\mu$ is the constant expected rate of return (drift), $\\sigma$ is the constant volatility, and $W_t$ is a standard Wiener process.\n\nConsider a derivative security whose value at time $t$ is given by the process $Y_t = (S_t)^k$, where $k$ is a non-zero real constant. This represents a leveraged position or a fractional claim on the underlying asset. It can be shown that the process $Y_t$ also follows a Geometric Brownian Motion, with an SDE of the form:\n$$dY_t = \\mu_Y Y_t dt + \\sigma_Y Y_t dW_t$$\nYour task is to determine the new drift coefficient $\\mu_Y$ and the new volatility coefficient $\\sigma_Y$ for the process $Y_t$.\n\nExpress your answer as a row matrix containing the expressions for $\\mu_Y$ and $\\sigma_Y$ in that order, in terms of $\\mu$, $\\sigma$, and $k$.", "solution": "We are given that $S_{t}$ follows the stochastic differential equation of a Geometric Brownian Motion:\n$$\ndS_{t}=\\mu S_{t}\\,dt+\\sigma S_{t}\\,dW_{t}.\n$$\nDefine $Y_{t}=f(S_{t})$ with $f(s)=s^{k}$ where $k\\neq 0$. By Itô's lemma for a twice continuously differentiable function $f$,\n$$\ndY_{t}=f'(S_{t})\\,dS_{t}+\\frac{1}{2}f''(S_{t})\\,(dS_{t})^{2},\n$$\nusing the stochastic calculus identities $(dW_{t})^{2}=dt$, $dt\\,dW_{t}=0$, and $(dt)^{2}=0$.\n\nCompute the derivatives:\n$$\nf'(s)=k s^{k-1},\\qquad f''(s)=k(k-1)s^{k-2}.\n$$\nCompute $(dS_{t})^{2}$ from the given SDE:\n$$\n(dS_{t})^{2}=(\\mu S_{t}\\,dt+\\sigma S_{t}\\,dW_{t})^{2}=(\\sigma S_{t}\\,dW_{t})^{2}=\\sigma^{2}S_{t}^{2}\\,dt.\n$$\nSubstitute into Itô's formula:\n\\begin{align*}\ndY_{t}\n=k S_{t}^{k-1}(\\mu S_{t}\\,dt+\\sigma S_{t}\\,dW_{t})+\\frac{1}{2}k(k-1)S_{t}^{k-2}\\left(\\sigma^{2}S_{t}^{2}\\,dt\\right)\\\\\n=k\\mu S_{t}^{k}\\,dt+k\\sigma S_{t}^{k}\\,dW_{t}+\\frac{1}{2}k(k-1)\\sigma^{2}S_{t}^{k}\\,dt\\\\\n=\\left(k\\mu+\\frac{1}{2}k(k-1)\\sigma^{2}\\right)S_{t}^{k}\\,dt+k\\sigma S_{t}^{k}\\,dW_{t}.\n\\end{align*}\nSince $Y_{t}=S_{t}^{k}$, we can write\n$$\ndY_{t}=\\mu_{Y}Y_{t}\\,dt+\\sigma_{Y}Y_{t}\\,dW_{t},\n$$\nwith the coefficients identified as\n$$\n\\mu_{Y}=k\\mu+\\frac{1}{2}k(k-1)\\sigma^{2},\\qquad \\sigma_{Y}=k\\sigma.\n$$\nThus, expressed as a row matrix in the order $(\\mu_{Y},\\sigma_{Y})$, the result is\n$$\n\\begin{pmatrix}\nk\\mu+\\frac{1}{2}k(k-1)\\sigma^{2}  k\\sigma\n\\end{pmatrix}.\n$$", "answer": "$$\\boxed{\\begin{pmatrix}k\\mu+\\frac{1}{2}k(k-1)\\sigma^{2}  k\\sigma\\end{pmatrix}}$$", "id": "1304922"}, {"introduction": "This final practice bridges the gap between theoretical derivation and practical implementation, a crucial skill for any modern quantitative analyst [@problem_id:3056767]. You will derive the exact simulation scheme for GBM, then write a program to generate sample paths and empirically verify the theoretical moments you've learned to calculate. This task not only reinforces the properties of the process but also equips you with the skills to test and validate stochastic models computationally.", "problem": "Consider a standard Brownian motion $W_t$ and a geometric Brownian motion $S_t$ defined as the unique strong solution to the stochastic differential equation (SDE) $dS_t = \\mu S_t \\, dt + \\sigma S_t \\, dW_t$, where $\\mu \\in \\mathbb{R}$ and $\\sigma \\ge 0$ are constants. Starting from core definitions and the Itô formula, derive an exact one-step simulation scheme that produces $S_{t+\\Delta}$ from a given $S_t$ for a fixed step size $\\Delta > 0$. Your derivation must transform the SDE into a form amenable to integration, justify the distributional form of the increment, and prove that the resulting scheme preserves strict positivity of $S_{t+\\Delta}$ whenever $S_t > 0$. Using the same derivation, obtain the analytic expressions for the first two moments $E[S_{t+\\Delta} \\mid S_t]$ and $\\operatorname{Var}(S_{t+\\Delta} \\mid S_t)$, expressed explicitly in terms of $S_t$, $\\mu$, $\\sigma$, and $\\Delta$.\n\nThen, write a complete, runnable program that implements the exact one-step simulation scheme you derived and empirically validates its correctness on a test suite. For each test case, generate $M$ independent samples of $S_{t+\\Delta}$ conditional on $S_t$, compute the sample mean and sample variance, and compare them to the analytic mean and variance from your derivation. Also verify that all simulated values satisfy strict positivity. Use a fixed random seed $42$ for reproducibility and set the number of samples to $M = 200000$.\n\nFor the comparison, use the following tolerances:\n- For the sample mean, require the relative error to be at most $10^{-3}$.\n- For the sample variance, require the relative error to be at most $2 \\times 10^{-2}$.\n- In any case where the analytic variance equals $0$, require the absolute error of the sample variance to be at most $10^{-10}$.\n\nYour program should produce a single line of output containing a list of Boolean values, one per test case, where each Boolean is $true$ if and only if: (i) the mean comparison passes within tolerance, (ii) the variance comparison passes within tolerance, and (iii) all simulated values are strictly positive. The final output must be a single line in the exact format specified at the end of this problem.\n\nTest suite parameter values:\n- Case $1$: $S_t = 100$, $\\mu = 0.05$, $\\sigma = 0.2$, $\\Delta = 0.25$.\n- Case $2$: $S_t = 100$, $\\mu = 0.0$, $\\sigma = 0.2$, $\\Delta = 0.0$.\n- Case $3$: $S_t = 80$, $\\mu = 0.03$, $\\sigma = 0.0$, $\\Delta = 2.0$.\n- Case $4$: $S_t = 120$, $\\mu = -0.1$, $\\sigma = 0.3$, $\\Delta = 0.5$.\n\nFinal output format:\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, for example $[result_1, result_2, result_3, result_4]$, where each $result_i$ is a Boolean value corresponding to Case $i$ in the order listed above.", "solution": "The problem requires the derivation of an exact one-step simulation scheme for a geometric Brownian motion (GBM), a proof of its positivity property, and the derivation of its first two conditional moments. Subsequently, an implementation must be provided to validate these theoretical results against an empirical simulation.\n\nThe stochastic differential equation (SDE) for a geometric Brownian motion $S_t$ is given as:\n$$ dS_t = \\mu S_t \\, dt + \\sigma S_t \\, dW_t $$\nwhere $\\mu \\in \\mathbb{R}$ is the constant drift, $\\sigma \\ge 0$ is the constant volatility, and $W_t$ is a standard Brownian motion.\n\nTo derive the exact simulation scheme, we first transform the process $S_t$ to simplify the SDE. Let's define a new process $X_t = \\ln(S_t)$. The goal is to find an SDE for $X_t$ using Itô's formula. The partial derivatives of $f(x) = \\ln(x)$ with respect to its arguments (time $t$ and state $x$) are:\n$$ \\frac{\\partial f}{\\partial t} = 0, \\quad \\frac{\\partial f}{\\partial x} = \\frac{1}{x}, \\quad \\frac{\\partial^2 f}{\\partial x^2} = -\\frac{1}{x^2} $$\nItô's formula for $dX_t = df(t, S_t)$ is:\n$$ dX_t = \\frac{\\partial f}{\\partial t} dt + \\frac{\\partial f}{\\partial S_t} dS_t + \\frac{1}{2} \\frac{\\partial^2 f}{\\partial S_t^2} (dS_t)^2 $$\nThe quadratic variation term $(dS_t)^2$ is computed using Itô's multiplication rules, where $(dW_t)^2 = dt$, $dt \\, dW_t = 0$, and $(dt)^2 = 0$:\n$$ (dS_t)^2 = (\\mu S_t \\, dt + \\sigma S_t \\, dW_t)^2 = (\\sigma S_t)^2 (dW_t)^2 = \\sigma^2 S_t^2 \\, dt $$\nSubstituting the derivatives and $(dS_t)^2$ into the formula for $dX_t$:\n$$ dX_t = (0) \\cdot dt + \\frac{1}{S_t} (\\mu S_t \\, dt + \\sigma S_t \\, dW_t) + \\frac{1}{2} \\left(-\\frac{1}{S_t^2}\\right) (\\sigma^2 S_t^2 \\, dt) $$\nSimplifying the terms, we get:\n$$ dX_t = (\\mu \\, dt + \\sigma \\, dW_t) - \\frac{1}{2} \\sigma^2 \\, dt $$\n$$ dX_t = \\left(\\mu - \\frac{\\sigma^2}{2}\\right) dt + \\sigma \\, dW_t $$\nThis SDE for $X_t$ is a generalized Wiener process with constant drift and diffusion coefficients, which can be integrated directly. Integrating from time $t$ to $t+\\Delta$:\n$$ \\int_t^{t+\\Delta} dX_s = \\int_t^{t+\\Delta} \\left(\\mu - \\frac{\\sigma^2}{2}\\right) ds + \\int_t^{t+\\Delta} \\sigma \\, dW_s $$\n$$ X_{t+\\Delta} - X_t = \\left(\\mu - \\frac{\\sigma^2}{2}\\right) \\Delta + \\sigma (W_{t+\\Delta} - W_t) $$\nThe increment of a standard Brownian motion, $W_{t+\\Delta} - W_t$, is a normally distributed random variable with mean $0$ and variance $\\Delta$. We can write this increment as $\\sqrt{\\Delta}Z$, where $Z \\sim \\mathcal{N}(0, 1)$ is a standard normal random variable.\nSubstituting $X_t = \\ln(S_t)$ back into the equation:\n$$ \\ln(S_{t+\\Delta}) - \\ln(S_t) = \\left(\\mu - \\frac{\\sigma^2}{2}\\right) \\Delta + \\sigma \\sqrt{\\Delta} Z $$\n$$ \\ln(S_{t+\\Delta}) = \\ln(S_t) + \\left(\\mu - \\frac{\\sigma^2}{2}\\right) \\Delta + \\sigma \\sqrt{\\Delta} Z $$\nExponentiating both sides yields the exact one-step simulation scheme for $S_t$:\n$$ S_{t+\\Delta} = S_t \\exp\\left( \\left(\\mu - \\frac{\\sigma^2}{2}\\right) \\Delta + \\sigma \\sqrt{\\Delta} Z \\right) $$\n\nTo prove the strict positivity of $S_{t+\\Delta}$ given $S_t > 0$, we observe that the argument of the exponential function, $\\left(\\mu - \\frac{\\sigma^2}{2}\\right) \\Delta + \\sigma \\sqrt{\\Delta} Z$, is a real-valued random variable. The exponential function $\\exp(x)$ is strictly positive for any real argument $x$. Therefore, the term $\\exp(\\dots)$ is always greater than $0$. Since $S_t > 0$ by assumption, the product $S_{t+\\Delta} = S_t \\cdot (\\text{a positive quantity})$ must also be strictly positive.\n\nNext, we derive the analytic expressions for the first two conditional moments, $E[S_{t+\\Delta} \\mid S_t]$ and $\\operatorname{Var}(S_{t+\\Delta} \\mid S_t)$.\nFrom the solution, $S_{t+\\Delta}$ is the product of $S_t$ (which is known at time $t$) and a log-normal random variable. Let the random variable in the exponent be $Y = \\left(\\mu - \\frac{\\sigma^2}{2}\\right) \\Delta + \\sigma \\sqrt{\\Delta} Z$. Since $Z \\sim \\mathcal{N}(0, 1)$, $Y$ is normally distributed. Its conditional mean and variance are:\n$$ m \\equiv E[Y \\mid \\mathcal{F}_t] = \\left(\\mu - \\frac{\\sigma^2}{2}\\right) \\Delta + \\sigma \\sqrt{\\Delta} E[Z] = \\left(\\mu - \\frac{\\sigma^2}{2}\\right) \\Delta $$\n$$ s^2 \\equiv \\operatorname{Var}(Y \\mid \\mathcal{F}_t) = \\operatorname{Var}\\left(\\sigma \\sqrt{\\Delta} Z\\right) = (\\sigma \\sqrt{\\Delta})^2 \\operatorname{Var}(Z) = \\sigma^2 \\Delta $$\nSo, $Y \\sim \\mathcal{N}(m, s^2)$. We have $S_{t+\\Delta} = S_t e^Y$. We use the moment generating function property for a normal variable: if $Y \\sim \\mathcal{N}(m, s^2)$, then $E[e^{kY}] = \\exp(km + \\frac{1}{2}k^2s^2)$.\n\nThe conditional mean of $S_{t+\\Delta}$ is:\n$$ E[S_{t+\\Delta} \\mid S_t] = E[S_t e^Y \\mid S_t] = S_t E[e^Y] $$\nUsing the property with $k=1$:\n$$ E[e^Y] = \\exp\\left(m + \\frac{s^2}{2}\\right) = \\exp\\left( \\left(\\mu - \\frac{\\sigma^2}{2}\\right) \\Delta + \\frac{\\sigma^2 \\Delta}{2} \\right) = \\exp(\\mu\\Delta) $$\nThus, the conditional mean is:\n$$ E[S_{t+\\Delta} \\mid S_t] = S_t e^{\\mu \\Delta} $$\n\nThe conditional variance of $S_{t+\\Delta}$ is $\\operatorname{Var}(S_{t+\\Delta} \\mid S_t) = E[S_{t+\\Delta}^2 \\mid S_t] - (E[S_{t+\\Delta} \\mid S_t])^2$.\nFirst, let's find the second moment $E[S_{t+\\Delta}^2 \\mid S_t]$:\n$$ E[S_{t+\\Delta}^2 \\mid S_t] = E[(S_t e^Y)^2 \\mid S_t] = S_t^2 E[e^{2Y}] $$\nUsing the property with $k=2$:\n$$ E[e^{2Y}] = \\exp\\left(2m + \\frac{1}{2}(2^2)s^2\\right) = \\exp(2m + 2s^2) $$\n$$ E[e^{2Y}] = \\exp\\left( 2\\left(\\mu - \\frac{\\sigma^2}{2}\\right)\\Delta + 2\\sigma^2\\Delta \\right) = \\exp(2\\mu\\Delta - \\sigma^2\\Delta + 2\\sigma^2\\Delta) = \\exp(2\\mu\\Delta + \\sigma^2\\Delta) $$\nSo, $E[S_{t+\\Delta}^2 \\mid S_t] = S_t^2 e^{2\\mu\\Delta + \\sigma^2\\Delta}$.\nNow, we compute the variance:\n$$ \\operatorname{Var}(S_{t+\\Delta} \\mid S_t) = S_t^2 e^{2\\mu\\Delta + \\sigma^2\\Delta} - (S_t e^{\\mu\\Delta})^2 $$\n$$ \\operatorname{Var}(S_{t+\\Delta} \\mid S_t) = S_t^2 e^{2\\mu\\Delta} e^{\\sigma^2\\Delta} - S_t^2 e^{2\\mu\\Delta} = S_t^2 e^{2\\mu\\Delta} (e^{\\sigma^2\\Delta} - 1) $$\nThis completes the required derivations. The implementation will use these formulae to perform the validation.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Implements the exact one-step simulation of Geometric Brownian Motion,\n    and validates sample moments against analytic moments for given test cases.\n    \"\"\"\n    \n    # Define the test cases from the problem statement.\n    test_cases = [\n        # (S_t, mu, sigma, delta)\n        (100, 0.05, 0.2, 0.25),\n        (100, 0.0, 0.2, 0.0),\n        (80, 0.03, 0.0, 2.0),\n        (120, -0.1, 0.3, 0.5),\n    ]\n\n    # Simulation parameters\n    M = 200000\n    SEED = 42\n    \n    # Validation tolerances\n    MEAN_REL_TOL = 1e-3\n    VAR_REL_TOL = 2e-2\n    VAR_ABS_TOL = 1e-10\n\n    # Initialize a random number generator for reproducibility\n    rng = np.random.default_rng(seed=SEED)\n\n    results = []\n    for case in test_cases:\n        S_t, mu, sigma, delta = case\n\n        # 1. Calculate analytic moments\n        # E[S_{t+d}] = S_t * exp(mu*d)\n        analytic_mean = S_t * np.exp(mu * delta)\n        # Var(S_{t+d}) = S_t^2 * exp(2*mu*d) * (exp(sigma^2*d) - 1)\n        analytic_var = S_t**2 * np.exp(2 * mu * delta) * (np.exp(sigma**2 * delta) - 1)\n\n        # 2. Perform the exact simulation\n        # Generate M standard normal random variables\n        Z = rng.standard_normal(size=M)\n        \n        # Apply the exact one-step simulation formula:\n        # S_{t+d} = S_t * exp( (mu - 0.5*sigma^2)*d + sigma*sqrt(d)*Z )\n        # Using np.sqrt with a non-negative scalar `delta` is safe.\n        exponent = (mu - 0.5 * sigma**2) * delta + sigma * np.sqrt(delta) * Z\n        S_tp_delta_samples = S_t * np.exp(exponent)\n\n        # 3. Validate the simulation results\n        # (i) Positivity check\n        positivity_check = np.all(S_tp_delta_samples  0)\n        \n        # Calculate sample moments\n        sample_mean = np.mean(S_tp_delta_samples)\n        # Use ddof=1 for unbiased sample variance estimator\n        sample_var = np.var(S_tp_delta_samples, ddof=1) if M  1 else 0\n\n        # (ii) Mean comparison\n        # Since S_t  0 and exp()  0, analytic_mean is always positive.\n        mean_rel_error = np.abs(sample_mean - analytic_mean) / np.abs(analytic_mean)\n        mean_check = mean_rel_error = MEAN_REL_TOL\n        \n        # (iii) Variance comparison\n        if np.isclose(analytic_var, 0):\n            # Use absolute error for cases where variance is theoretically zero\n            # This happens if sigma = 0 or delta = 0\n            var_abs_error = np.abs(sample_var - analytic_var)\n            var_check = var_abs_error = VAR_ABS_TOL\n        else:\n            # Use relative error for non-zero variance\n            var_rel_error = np.abs(sample_var - analytic_var) / analytic_var\n            var_check = var_rel_error = VAR_REL_TOL\n\n        # Combine all checks to get the final boolean result for the case\n        case_is_valid = positivity_check and mean_check and var_check\n        results.append(case_is_valid)\n\n    # Final print statement in the exact required format (lowercase booleans)\n    formatted_results = [str(res).lower() for res in results]\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```", "id": "3056767"}]}