{"hands_on_practices": [{"introduction": "The concept of orthogonality is grounded in a precise mathematical definition involving an inner product. This first practice invites you to apply this definition directly by finding a constant that makes two polynomial functions orthogonal with respect to a given weight function, demonstrating how this fundamental property can be engineered. [@problem_id:2190620]", "problem": "In the study of specialized function spaces, the concept of orthogonality is generalized using a weight function. Two functions, $f(x)$ and $g(x)$, are said to be orthogonal on an interval $[a, b]$ with respect to a weight function $w(x) > 0$ if the integral of their product weighted by $w(x)$ is zero, i.e., $\\int_{a}^{b} f(x)g(x)w(x)dx = 0$.\n\nConsider a system defined on the interval $[-L, L]$, where $L$ is a positive length parameter. The analysis of this system involves a set of basis functions that must be orthogonal with respect to the weight function $w(x) = |x|$. Let two of these basis functions be $f_1(x) = 1$ and $f_2(x) = x^2 + C$, where $C$ is a constant that needs to be determined.\n\nFind the value of the constant $C$ that makes the functions $f_1(x)$ and $f_2(x)$ orthogonal on the interval $[-L, L]$ with respect to the weight function $w(x) = |x|$. Express your answer as an analytic expression in terms of $L$.", "solution": "Orthogonality with respect to the weight function $w(x)=|x|$ on $[-L,L]$ requires\n$$\n\\int_{-L}^{L} f_{1}(x) f_{2}(x) w(x)\\,dx \\;=\\; \\int_{-L}^{L} \\left(1\\right)\\left(x^{2}+C\\right)|x|\\,dx \\;=\\; 0.\n$$\nThe integrand $(x^{2}+C)|x|$ is an even function because $x^{2}$ and $|x|$ are even, so\n$$\n\\int_{-L}^{L} (x^{2}+C)|x|\\,dx \\;=\\; 2\\int_{0}^{L} (x^{2}+C)x\\,dx \\;=\\; 2\\int_{0}^{L} \\left(x^{3}+Cx\\right)\\,dx.\n$$\nEvaluating the integral gives\n$$\n2\\left[\\frac{x^{4}}{4}+\\frac{C x^{2}}{2}\\right]_{0}^{L} \\;=\\; 2\\left(\\frac{L^{4}}{4}+\\frac{C L^{2}}{2}\\right) \\;=\\; \\frac{L^{4}}{2}+C L^{2}.\n$$\nSetting this equal to zero for orthogonality,\n$$\n\\frac{L^{4}}{2}+C L^{2}=0 \\quad \\Rightarrow \\quad C=-\\frac{L^{2}}{2}.\n$$", "answer": "$$\\boxed{-\\frac{L^{2}}{2}}$$", "id": "2190620"}, {"introduction": "While making two functions orthogonal is useful, we often need an entire set of mutually orthogonal functions to serve as a basis for representing more complex functions. This exercise guides you through the Gram-Schmidt process, a powerful algorithmic method for systematically constructing such a set from a simpler, non-orthogonal family of functions like monomials. [@problem_id:2123127]", "problem": "In the study of quantum mechanics and the solution of certain partial differential equations, constructing sets of orthogonal polynomials is a fundamental technique for building basis sets. We define the inner product of two real-valued functions, $f(x)$ and $g(x)$, on the interval $[0, \\infty)$ with respect to a weight function $w(x) = e^{-x}$ as:\n$$\n\\langle f, g \\rangle = \\int_0^\\infty f(x) g(x) e^{-x} dx\n$$\nYour task is to generate a sequence of orthogonal polynomials $\\{p_0(x), p_1(x), p_2(x), ...\\}$ by applying an orthogonalization process to the set of monomials $\\{1, x, x^2, ...\\}$. The resulting polynomials must satisfy two conditions:\n1. $p_n(x)$ must be a polynomial of degree $n$.\n2. Each $p_n(x)$ must be monic, meaning the coefficient of the $x^n$ term is 1.\n\nBased on this procedure, determine the second-degree polynomial, $p_2(x)$.", "solution": "We work in the inner product space with weight function $w(x)=\\exp(-x)$ on $[0,\\infty)$:\n$$\n\\langle f,g\\rangle=\\int_{0}^{\\infty} f(x)g(x)\\exp(-x)\\,dx.\n$$\nA key identity we will use for all nonnegative integers $k$ is\n$$\n\\int_{0}^{\\infty} x^{k}\\exp(-x)\\,dx = k!.\n$$\nApply Gramâ€“Schmidt to the monomials $\\{1,x,x^{2}\\}$ and require monicity at each step.\n\nFirst polynomial: choose $p_{0}(x)=1$, which is monic of degree $0$. Its norm is\n$$\n\\langle p_{0},p_{0}\\rangle=\\int_{0}^{\\infty}\\exp(-x)\\,dx=1.\n$$\n\nSecond polynomial: start with $x$ and subtract its projection onto $p_{0}$,\n$$\np_{1}(x)=x-\\frac{\\langle x,p_{0}\\rangle}{\\langle p_{0},p_{0}\\rangle}p_{0}(x).\n$$\nCompute the coefficient:\n$$\n\\langle x,p_{0}\\rangle=\\int_{0}^{\\infty}x\\exp(-x)\\,dx=1!,\\quad \\langle p_{0},p_{0}\\rangle=1,\n$$\nhence $p_{1}(x)=x-1$. Its norm is\n$$\n\\langle p_{1},p_{1}\\rangle=\\int_{0}^{\\infty}(x-1)^{2}\\exp(-x)\\,dx=\\int_{0}^{\\infty}(x^{2}-2x+1)\\exp(-x)\\,dx=2!-2\\cdot 1!+1=1.\n$$\n\nThird polynomial: start with $x^{2}$ and subtract projections onto $p_{1}$ and $p_{0}$ to ensure orthogonality while keeping the leading coefficient $1$:\n$$\np_{2}(x)=x^{2}-\\alpha\\,p_{1}(x)-\\beta\\,p_{0}(x).\n$$\nFirst compute $\\alpha$ from orthogonality to $p_{1}$:\n$$\n\\alpha=\\frac{\\langle x^{2},p_{1}\\rangle}{\\langle p_{1},p_{1}\\rangle},\\quad \\langle x^{2},p_{1}\\rangle=\\int_{0}^{\\infty}x^{2}(x-1)\\exp(-x)\\,dx=\\int_{0}^{\\infty}(x^{3}-x^{2})\\exp(-x)\\,dx=3!-2!=4,\n$$\nand since $\\langle p_{1},p_{1}\\rangle=1$, we get $\\alpha=4$. Define\n$$\nq(x)=x^{2}-4\\,p_{1}(x)=x^{2}-4(x-1)=x^{2}-4x+4.\n$$\nNow enforce orthogonality to $p_{0}$ by choosing\n$$\n\\beta=\\frac{\\langle q,p_{0}\\rangle}{\\langle p_{0},p_{0}\\rangle},\\quad \\langle q,p_{0}\\rangle=\\int_{0}^{\\infty}(x^{2}-4x+4)\\exp(-x)\\,dx=2!-4\\cdot 1!+4=2,\n$$\nhence $\\beta=2$. Therefore\n$$\np_{2}(x)=q(x)-2\\,p_{0}(x)=x^{2}-4x+4-2=x^{2}-4x+2.\n$$\nBy construction, $p_{2}(x)$ is monic of degree $2$ and satisfies $\\langle p_{2},p_{0}\\rangle=0$ and $\\langle p_{2},p_{1}\\rangle=0$.", "answer": "$$\\boxed{x^{2}-4x+2}$$", "id": "2123127"}, {"introduction": "Sturm-Liouville theory guarantees that eigenfunctions for distinct eigenvalues are orthogonal, but what about a set of different eigenfunctions sharing the same (degenerate) eigenvalue? This practice demonstrates how the orthogonalization technique you've learned can be used to construct an orthogonal basis even in these cases, a crucial step in ensuring a complete and well-behaved set of basis functions. [@problem_id:2190639]", "problem": "In the study of Sturm-Liouville theory, it is known that eigenfunctions corresponding to distinct eigenvalues are orthogonal with respect to a specific inner product. Consider a Sturm-Liouville problem defined on an interval $[a, b]$ with a continuous, positive weight function $r(x)$. The inner product of two real-valued functions $f(x)$ and $h(x)$ on this interval is defined as $\\langle f, h \\rangle = \\int_a^b f(x) h(x) r(x) \\,dx$.\n\nSuppose that for a particular degenerate eigenvalue $\\lambda_0$, there exist two linearly independent eigenfunctions, $y_1(x)$ and $y_2(x)$. Both functions have been normalized such that $\\langle y_1, y_1 \\rangle = 1$ and $\\langle y_2, y_2 \\rangle = 1$. However, these two eigenfunctions are not orthogonal to each other. Their inner product is given as $\\langle y_1, y_2 \\rangle = K$, where $K$ is a real constant satisfying $0 < |K| < 1$.\n\nYour task is to construct a new function, $g(x)$, that satisfies three conditions:\n1. It is an eigenfunction of the Sturm-Liouville problem corresponding to the same eigenvalue $\\lambda_0$.\n2. It is orthogonal to $y_1(x)$, i.e., $\\langle g, y_1 \\rangle = 0$.\n3. It is normalized, i.e., $\\langle g, g \\rangle = 1$.\n\nExpress $g(x)$ as a linear combination of $y_1(x)$ and $y_2(x)$.", "solution": "Because the Sturm-Liouville operator is linear and $y_{1}$, $y_{2}$ are eigenfunctions with the same eigenvalue $\\lambda_{0}$, any linear combination $g(x)=a\\,y_{2}(x)+b\\,y_{1}(x)$ is also an eigenfunction corresponding to $\\lambda_{0}$:\n$$\nL[g]=a\\,L[y_{2}]+b\\,L[y_{1}]=a\\,\\lambda_{0}\\,r\\,y_{2}+b\\,\\lambda_{0}\\,r\\,y_{1}=\\lambda_{0}\\,r\\,(a\\,y_{2}+b\\,y_{1})=\\lambda_{0}\\,r\\,g.\n$$\nImpose orthogonality to $y_{1}$:\n$$\n\\langle g,y_{1}\\rangle=\\langle a\\,y_{2}+b\\,y_{1},y_{1}\\rangle=a\\,\\langle y_{2},y_{1}\\rangle+b\\,\\langle y_{1},y_{1}\\rangle=a\\,K+b=0,\n$$\nwhich gives\n$$\nb=-aK.\n$$\nThus $g$ is proportional to $y_{2}-K\\,y_{1}$:\n$$\ng(x)=a\\big(y_{2}(x)-K\\,y_{1}(x)\\big).\n$$\nNormalize $g$ using the given inner products $\\langle y_{1},y_{1}\\rangle=\\langle y_{2},y_{2}\\rangle=1$ and $\\langle y_{1},y_{2}\\rangle=K$:\n$$\n\\langle g,g\\rangle=a^{2}\\langle y_{2}-K\\,y_{1},\\,y_{2}-K\\,y_{1}\\rangle\n=a^{2}\\big(\\langle y_{2},y_{2}\\rangle-2K\\langle y_{2},y_{1}\\rangle+K^{2}\\langle y_{1},y_{1}\\rangle\\big)\n=a^{2}\\big(1-2K^{2}+K^{2}\\big)=a^{2}(1-K^{2}).\n$$\nImposing $\\langle g,g\\rangle=1$ yields\n$$\na^{2}(1-K^{2})=1 \\quad\\Longrightarrow\\quad a=\\frac{1}{\\sqrt{1-K^{2}}}.\n$$\nChoosing the positive normalization constant, the required function is\n$$\ng(x)=\\frac{y_{2}(x)-K\\,y_{1}(x)}{\\sqrt{1-K^{2}}}.\n$$\nThis $g$ is an eigenfunction for $\\lambda_{0}$, satisfies $\\langle g,y_{1}\\rangle=0$, and is normalized with $\\langle g,g\\rangle=1$.", "answer": "$$\\boxed{\\frac{y_{2}(x)-K\\,y_{1}(x)}{\\sqrt{1-K^{2}}}}$$", "id": "2190639"}]}