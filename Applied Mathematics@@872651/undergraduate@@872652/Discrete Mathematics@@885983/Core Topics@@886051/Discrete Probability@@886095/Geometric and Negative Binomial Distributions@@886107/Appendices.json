{"hands_on_practices": [{"introduction": "A core application of the geometric distribution is modeling the 'waiting time' for a success. This first exercise explores the expected waiting time, a fundamental concept, through a scenario that cleverly highlights the distribution's memoryless property [@problem_id:1371840]. By considering an archer who has already experienced failures, you'll see how past events do—or do not—influence future expectations.", "problem": "An aspiring archer is practicing their skills. The probability that they hit the bullseye on any given shot is $p$, where $0  p  1$. Each shot is an independent event. The archer has just completed a frustrating sequence of exactly $n$ consecutive misses. Undeterred, they decide to continue shooting arrows until they successfully hit the bullseye for the first time. Let $T$ represent the total number of shots taken by the archer, counting both the initial $n$ misses and all subsequent shots up to and including the first bullseye.\n\nDetermine the expected value of $T$ as an expression in terms of $n$ and $p$.", "solution": "Let $p$ be the success probability per shot with $0p1$, and suppose the archer has already taken exactly $n$ consecutive misses. By independence of shots, the number of additional shots needed until the first hit after these $n$ misses, call it $X$, follows a geometric distribution on $\\{1,2,\\dots\\}$ with parameter $p$, so\n$$\n\\Pr(X=k)=(1-p)^{k-1}p \\quad \\text{for } k\\geq 1.\n$$\nThe total number of shots counted, including the initial $n$ misses and the subsequent shots up to and including the first hit, is\n$$\nT=n+X.\n$$\nBy linearity of expectation,\n$$\n\\mathbb{E}[T]=n+\\mathbb{E}[X].\n$$\nCompute $\\mathbb{E}[X]$ from its series:\n$$\n\\mathbb{E}[X]=\\sum_{k=1}^{\\infty}k(1-p)^{k-1}p\n= p\\sum_{k=1}^{\\infty}k r^{k-1}, \\quad \\text{where } r=1-p.\n$$\nUsing the identity, obtained by differentiating the geometric series $\\sum_{k=0}^{\\infty}r^{k}=\\frac{1}{1-r}$ for $|r|1$,\n$$\n\\sum_{k=1}^{\\infty}k r^{k-1}=\\frac{1}{(1-r)^{2}},\n$$\nwe get, with $r=1-p$,\n$$\n\\sum_{k=1}^{\\infty}k r^{k-1}=\\frac{1}{p^{2}},\n\\quad \\text{hence} \\quad\n\\mathbb{E}[X]=p\\cdot \\frac{1}{p^{2}}=\\frac{1}{p}.\n$$\nTherefore,\n$$\n\\mathbb{E}[T]=n+\\frac{1}{p}.\n$$", "answer": "$$\\boxed{n+\\frac{1}{p}}$$", "id": "1371840"}, {"introduction": "While the geometric distribution tracks the wait for the first success, the negative binomial distribution generalizes this to the wait for the $r$-th success. This practice problem provides a concrete scenario involving a deep-space probe, allowing you to apply the negative binomial probability formula directly [@problem_id:1371878]. Mastering this calculation is a key step in understanding processes where multiple successes are the goal.", "problem": "A deep-space probe is tasked with transmitting a crucial set of scientific data packages back to Earth. Due to cosmic-ray interference, each data packet has a constant and independent probability of successful transmission and acknowledgement, given by $p = 0.82$. A transmission is considered a failure if the packet is corrupted or its acknowledgement is not received. The probe's protocol dictates that it will repeatedly transmit packets until exactly $r = 5$ successful acknowledgements have been received.\n\nCalculate the probability that the probe needs to transmit a total of exactly $k = 9$ packets to complete its task. Express your answer as a numerical value, rounded to four significant figures.", "solution": "Each transmission attempt is an independent Bernoulli trial with success probability $p=0.82$ and failure probability $q=1-p=0.18$. Let $K$ be the total number of transmissions required to observe exactly $r=5$ successful acknowledgements. The event $\\{K=k\\}$ occurs if and only if there are exactly $r-1$ successes in the first $k-1$ trials and the $k$-th trial is a success. By independence and the binomial counting of the positions of the $r-1$ successes among the first $k-1$ trials, the probability mass function is the negative binomial form\n$$\n\\Pr(K=k)=\\binom{k-1}{r-1}p^{r}q^{\\,k-r}, \\quad k=r,r+1,\\ldots\n$$\nSubstituting $r=5$, $k=9$, $p=0.82$, and $q=0.18$ gives\n$$\n\\Pr(K=9)=\\binom{8}{4}(0.82)^{5}(0.18)^{4}.\n$$\nCompute each factor:\n$$\n\\binom{8}{4}=70,\\quad (0.82)^{5}=0.3707398432,\\quad (0.18)^{4}=0.00104976.\n$$\nMultiply to obtain\n$$\n\\Pr(K=9)=70\\times 0.3707398432\\times 0.00104976=0.02724315004583424.\n$$\nRounding this value to four significant figures yields $0.02724$.", "answer": "$$\\boxed{0.02724}$$", "id": "1371878"}, {"introduction": "Beyond calculating expectations and probabilities, we can explore the fascinating relationships between random variables. This advanced problem delves into conditional probability, asking what we can infer about one event given information about a related one [@problem_id:1371894]. By analyzing semiconductor test failures, you will uncover a surprising and elegant connection between the geometric distribution and the discrete uniform distribution.", "problem": "A technology company manufactures a specialized type of Gallium Nitride (GaN) semiconductor. During quality control, each semiconductor undergoes a stress test. There is an unknown, but constant, probability $p$ that any given semiconductor will fail the test, where $0  p  1$. The manufacturing and testing process can be modeled as a sequence of independent Bernoulli trials.\n\nLet the random variable $X_1$ denote the number of semiconductors tested until the first failure is observed. After this first failure, the testing process is reset, and a new sequence of tests on a new batch of semiconductors begins. Let the random variable $X_2$ denote the number of semiconductors tested in this second sequence until the first failure is observed. Assume that $X_1$ and $X_2$ are independent and identically distributed.\n\nAn analyst reviewing historical testing data discovers a particular case where the total number of semiconductors tested to observe these two failures was exactly $k$, where $k$ is a known integer and $k \\geq 2$. In other words, it is given that the event $X_1 + X_2 = k$ occurred.\n\nBased on this information, determine the expected trial number of the first failure, $X_1$. Your final answer should be a closed-form expression in terms of $k$.", "solution": "Let $X_{1}$ and $X_{2}$ be independent geometric random variables with parameter $p$, supported on $\\{1,2,\\ldots\\}$, so that for $n \\in \\{1,2,\\ldots\\}$,\n$$\n\\mathbb{P}(X_{j}=n)=(1-p)^{n-1}p \\quad \\text{for } j \\in \\{1,2\\}.\n$$\nDefine $S=X_{1}+X_{2}$ and condition on the event $\\{S=k\\}$ with $k \\geq 2$. For any $i \\in \\{1,2,\\ldots,k-1\\}$, by independence,\n$$\n\\mathbb{P}(X_{1}=i, X_{2}=k-i)=\\mathbb{P}(X_{1}=i)\\mathbb{P}(X_{2}=k-i)=(1-p)^{i-1}p\\,(1-p)^{k-i-1}p=p^{2}(1-p)^{k-2}.\n$$\nThis value does not depend on $i$, hence for $i \\in \\{1,\\ldots,k-1\\}$ the conditional distribution is uniform:\n$$\n\\mathbb{P}(X_{1}=i \\mid S=k)=\\frac{\\mathbb{P}(X_{1}=i, X_{2}=k-i)}{\\sum_{j=1}^{k-1}\\mathbb{P}(X_{1}=j, X_{2}=k-j)}=\\frac{p^{2}(1-p)^{k-2}}{(k-1)p^{2}(1-p)^{k-2}}=\\frac{1}{k-1}.\n$$\nTherefore,\n$$\n\\mathbb{E}[X_{1} \\mid S=k]=\\sum_{i=1}^{k-1} i \\,\\mathbb{P}(X_{1}=i \\mid S=k)=\\frac{1}{k-1}\\sum_{i=1}^{k-1} i=\\frac{1}{k-1}\\cdot \\frac{(k-1)k}{2}=\\frac{k}{2}.\n$$\nEquivalently, by symmetry and the fact that $X_{1}+X_{2}=k$ implies $\\mathbb{E}[X_{1}\\mid S=k]=\\mathbb{E}[X_{2}\\mid S=k]$ and $2\\mathbb{E}[X_{1}\\mid S=k]=k$, the same result follows.", "answer": "$$\\boxed{\\frac{k}{2}}$$", "id": "1371894"}]}